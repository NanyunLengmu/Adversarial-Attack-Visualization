Authors,Author(s) ID,Title,Year,Source title,Volume,Issue,Art. No.,Page start,Page end,Page count,Cited by,DOI,Link,Affiliations,Authors with affiliations,Abstract,Author Keywords,Index Keywords,Molecular Sequence Numbers,Chemicals/CAS,Tradenames,Manufacturers,References,Correspondence Address,Editors,Sponsors,Publisher,Conference name,Conference date,Conference location,Conference code,ISSN,ISBN,CODEN,PubMed ID,Language of Original Document,Abbreviated Source Title,Document Type,Publication Stage,Open Access,Source,EID
"Liu J., Zhang Q., Mo K., Xiang X., Li J., Cheng D., Gao R., Liu B., Chen K., Wei G.",57216375940;57226596120;57219608352;57219626462;57376441100;57223672585;57375684000;57375385300;57375531400;57375992000;,An efficient adversarial example generation algorithm based on an accelerated gradient iterative fast gradient,2022,Computer Standards and Interfaces,82,,103612,,,,,10.1016/j.csi.2021.103612,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121350915&doi=10.1016%2fj.csi.2021.103612&partnerID=40&md5=94227b447d809a435efdf68652e5d8f3,"Information Security Research Center, CEPREI, NO.110, Dongguanzhuang Road, Guangzhou, China; Key Laboratory of Ministry of Industry and Information Technology, CEPREI, NO.110, Dongguanzhuang Road, Guangzhou, China; School of Computer Science, Guangzhou University, Guangzhou, 510006, China","Liu, J., Information Security Research Center, CEPREI, NO.110, Dongguanzhuang Road, Guangzhou, China, Key Laboratory of Ministry of Industry and Information Technology, CEPREI, NO.110, Dongguanzhuang Road, Guangzhou, China; Zhang, Q., Information Security Research Center, CEPREI, NO.110, Dongguanzhuang Road, Guangzhou, China, Key Laboratory of Ministry of Industry and Information Technology, CEPREI, NO.110, Dongguanzhuang Road, Guangzhou, China; Mo, K., School of Computer Science, Guangzhou University, Guangzhou, 510006, China; Xiang, X., Information Security Research Center, CEPREI, NO.110, Dongguanzhuang Road, Guangzhou, China, Key Laboratory of Ministry of Industry and Information Technology, CEPREI, NO.110, Dongguanzhuang Road, Guangzhou, China; Li, J., School of Computer Science, Guangzhou University, Guangzhou, 510006, China; Cheng, D., Information Security Research Center, CEPREI, NO.110, Dongguanzhuang Road, Guangzhou, China, Key Laboratory of Ministry of Industry and Information Technology, CEPREI, NO.110, Dongguanzhuang Road, Guangzhou, China; Gao, R., Information Security Research Center, CEPREI, NO.110, Dongguanzhuang Road, Guangzhou, China, Key Laboratory of Ministry of Industry and Information Technology, CEPREI, NO.110, Dongguanzhuang Road, Guangzhou, China; Liu, B., Information Security Research Center, CEPREI, NO.110, Dongguanzhuang Road, Guangzhou, China, Key Laboratory of Ministry of Industry and Information Technology, CEPREI, NO.110, Dongguanzhuang Road, Guangzhou, China; Chen, K., School of Computer Science, Guangzhou University, Guangzhou, 510006, China; Wei, G., Information Security Research Center, CEPREI, NO.110, Dongguanzhuang Road, Guangzhou, China, Key Laboratory of Ministry of Industry and Information Technology, CEPREI, NO.110, Dongguanzhuang Road, Guangzhou, China","Most existing deep neural networks are susceptible to the influence of adversarial examples, which may cause them to output incorrect prediction results. An adversarial example is the addition of small noise disturbances to the input data samples, which will deceive the classification. Generally, these modifications are very small noise disturbances, which are not easily noticed by the human eye. However, most existing adversarial attacks achieve only low success rates in typical black-box settings, where the attackers have no prior knowledge about the model structures and/or model parameters. To tackle this problem, we propose an iterative algorithm based on an acceleration gradient to enhance the adversary attack. Our method accumulates the gradient of the loss function in each iteration and uses the next gradient information to influence the future gradient. We also introduce the scaling invariance principle of a deep neural network to optimize the input images for black-box attacks. In addition, to handle the drawbacks of a traditional iterative fast gradient sign method, we further present two gradient optimization methods. Experimental results on the ImageNet dataset show that our attack methods can achieve good transferability. In addition, those models obtained by integrated adversarial training with strong defense capability are also quite vulnerable to our black-box attack. © 2021",Adversarial examples; Iterative fast gradient; Transferable,Iterative methods; Model structures; Adversarial example; Black boxes; Data sample; Generation algorithm; Human eye; Input datas; Iterative fast gradient; Noise disturbance; Prior-knowledge; Transferable; Deep neural networks,,,,,"Silver, D., Huang, A., Maddison, C.J., Guez, A., Sifre, L., Van Den Driessche, G., Schrittwieser, J., Lanctot, M., Mastering the game of go with deep neural networks and tree search (2016) Nature, 529 (7587), pp. 484-489; Silver, D., Schrittwieser, J., Simonyan, K., Antonoglou, I., Huang, A., Guez, A., Hubert, T., Bolton, A., Mastering the game of go without human knowledge (2017) Nature, 550 (7676), pp. 354-359; Huang, T., Zhang, Q., Liu, J., Hou, R., Li, Y., Adversarial attacks on deep-learning-based sar image target recognition (2020) Journal of Network and Computer Applications, 162, p. 102632; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2017) Commun ACM, 60 (6), pp. 84-90; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., Adversarial examples for semantic segmentation and object detection (2017) Proceedings of the IEEE International Conference on Computer Vision, pp. 1369-1378; Redmon, J., Farhadi, A., Yolo9000: better, faster, stronger (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 7263-7271; Ren, S., He, K., Girshick, R., Sun, J., Faster r-cnn: towards real-time object detection with region proposal networks (2016) IEEE Trans Pattern Anal Mach Intell, 39 (6), pp. 1137-1149; Postolache, O., Ramos, H.G., Ribeiro, A.L., Detection and characterization of defects using gmr probes and artificial neural networks (2011) Computer Standards & Interfaces, 33 (2), pp. 191-200. , https://www.sciencedirect.com/science/article/pii/S0920548910000899; Saon, G., Kuo, H.-K.J., Rennie, S., Picheny, M., The ibm 2015 english conversational telephone speech recognition system (2015) Sixteenth Annual Conference of the International Speech Communication Association; Wu, T., Liu, X., Gong, Z., Zhang, H., Herrera, F., The minimum cost consensus model considering the implicit trust of opinions similarities in social network group decision-making (2020) Int. J. Intell. Syst., 35 (3), pp. 470-493; Küçük, D., Automatic compilation of language resources for named entity recognition in turkish by utilizing wikipedia article titles (2015) Computer Standards & Interfaces, 41, pp. 1-9. , https://www.sciencedirect.com/science/article/pii/S0920548915000197; Sutskever, I., Vinyals, O., Le, Q.V., Sequence to sequence learning with neural networks (2014) Advances in Neural Information Processing Systems, pp. 3104-3112; García-Magariño, I., Towards the integration of the agent-oriented modeling diversity with a powertype-based language (2014) Computer Standards & Interfaces, 36 (6), pp. 941-952. , https://www.sciencedirect.com/science/article/pii/S0920548914000282; van den Oord, A., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A., Kalchbrenner, N., Kavukcuoglu, K., Wavenet: a generative model for raw audio (2016) arXiv, pp. arXiv-1609; Canovas, A., Tomás, J., Lloret, J., García, M., Statistical speech translation system based on voice recognition optimization using multimodal sources of knowledge and characteristics vectors (2013) Computer Standards & Interfaces, 35 (5), pp. 490-506. , https://www.sciencedirect.com/science/article/pii/S0920548912001079; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2013) arXiv, pp. arXiv-1312; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) Stat, 1050, p. 20; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 9185-9193; Kwon, H., Yoon, H., Park, K.-W., Acoustic-decoy: Detection of adversarial examples through audio modification on speech recognition system (2020), 417, pp. 357-370; Hu, C., Wu, X.-J., Li, Z.-Y., Generating adversarial examples with elastic-net regularized boundary equilibrium generative adversarial network (2020) Pattern Recognit Lett, 140, pp. 281-287; Martin, J., Elster, C., Inspecting adversarial examples using the fisher information (2020) Neurocomputing, 382, pp. 80-86; Zhang, B., Tondi, B., Barni, M., Adversarial examples for replay attacks against cnn-based face recognition with anti-spoofing capability (2020) Comput. Vision Image Understanding, 197-198, p. 102988; Wang, Y., an Tan, Y., Zhang, W., Zhao, Y., Kuang, X., An adversarial attack on dnn-based black-box object detectors (2020) Journal of Network and Computer Applications, 161, p. 102634; Kanwal, T., Anjum, A., Malik, S.U., Khan, A., Khan, M.A., Privacy preservation of electronic health records with adversarial attacks identification in hybrid cloud (2021) Computer Standards & Interfaces, 78, p. 103522. , https://www.sciencedirect.com/science/article/pii/S0920548921000179; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2017), 1050, p. 30; Mądry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2017) Stat, 1050, p. 9; Song, C., He, K., Wang, L., Hopcroft, J.E., Improving the generalization of adversarial training with domain adaptation (2018) International Conference on Learning Representations; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial machine learning at scale (2017) InICLR, 1, p. 1; Zhang, L., Wang, X., Lu, K., Peng, S., Wang, X., An efficient framework for generating robust adversarial examples (2020) Int. J. Intell. Syst., 35 (9), pp. 1433-1449; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2016) arXiv, pp. arXiv-1607; Xie, C., Zhang, Z., Zhou, Y., Bai, S., Wang, J., Ren, Z., Yuille, A.L., Improving transferability of adversarial examples with input diversity (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2730-2739; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2013) arXiv, pp. arXiv-1312; Zhai, R., Cai, T., He, D., Dan, C., He, K., Hopcroft, J., Wang, L., Adversarially robust generalization just requires more unlabeled data (2019) arXiv e-prints, pp. arXiv-1906; Song, C., He, K., Lin, J., Wang, L., Hopcroft, J.E., Robust local features for improving the generalization of adversarial training (2019) International Conference on Learning Representations; Yin, Z., Wang, H., Wang, J., Tang, J., Wang, W., Defense against adversarial attacks by low-level image transformations (2020) Int. J. Intell. Syst., 35 (10), pp. 1453-1466; Huang, R., Xu, B., Schuurmans, D., Szepesvari, C., Learning with a strong adversary (2015) arXiv e-prints, pp. arXiv-1511; Wu, Y., Bamman, D., Russell, S., Adversarial training for relation extraction (2017) Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pp. 1778-1783; Dhillon, G.S., Azizzadenesheli, K., Lipton, Z.C., Bernstein, J., Kossaifi, J., Khanna, A., Anandkumar, A., Stochastic activation pruning for robust adversarial defense (2018) arXiv, pp. arXiv-1803; Prakash, A., Moran, N., Garber, S., DiLillo, A., Storer, J., Deflecting adversarial attacks with pixel deflection (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 8571-8580; Cohen, J.M., Rosenfeld, E., Zico Kolter, J., Certified adversarial robustness via randomized smoothing (2019) arXiv, pp. arXiv-1902; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP), pp. 39-57. , IEEE; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP), pp. 39-57; Duchi, J., Hazan, E., Singer, Y., Adaptive subgradient methods for online learning and stochastic optimization (2011) Journal of machine learning research, 12, p. 7; Hinton, G., Srivastava, N., Swersky, K., Lecture 6d-a separate, adaptive learning rate for each connection (2012) Slides of lecture neural networks for machine learning, p. 5; Lin, J., Song, C., He, K., Wang, L., Hopcroft, J.E., Nesterov accelerated gradient and scale invariance for adversarial attacks (2019) International Conference on Learning Representations; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A., Inception-v4, inception-resnet and the impact of residual connections on learning (2017) Proceedings of the AAAI Conference on Artificial Intelligence, 31; He, K., Zhang, X., Ren, S., Sun, J., Identity mappings in deep residual networks (2016) European Conference on Computer Vision, pp. 630-645. , Springer","Cheng, D.; Information Security Research Center, CEPREI, NO.110, Dongguanzhuang Road, China; 电子邮件: chengdb@ceprei.com",,,Elsevier B.V.,,,,,9205489,,CSTIE,,English,Comput Stand Interfaces,Article,Final,,Scopus,2-s2.0-85121350915
"Sarkar P., Sahoo S.K., Goswami C., Adhikari A.",56646812600;57464355400;57464060400;7004542987;,Connectivity invariant lightweight resiliency improvement strategies for CRT-subset scheme,2022,Ad Hoc Networks,129,,102803,,,,,10.1016/j.adhoc.2022.102803,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125145417&doi=10.1016%2fj.adhoc.2022.102803&partnerID=40&md5=f46b31f2a39f8c57c6671e139b4cae18,"Former, University of Calcutta, West Bengal, India; Indian Institute of Science Education and Research, Mohanpur, West Bengal, Kalyani, India; Presidency University, West Bengal, Kolkata, India","Sarkar, P., Former, University of Calcutta, West Bengal, India; Sahoo, S.K., Indian Institute of Science Education and Research, Mohanpur, West Bengal, Kalyani, India; Goswami, C., Presidency University, West Bengal, Kolkata, India; Adhikari, A., Presidency University, West Bengal, Kolkata, India","It has been found in the literature of key management for IoT devices that most of the schemes do not consider the attacking behavior of the adversary. Considering the effect of adversarial attacks on system nodes, we observe that when an adversary captures a node, it can read all the secret information from the memory of the node, resulting a partial disclosure of key pool and exposes a part of other node's keyrings. Thereby, usage of these links that are made secure by these keys is no longer permitted. The situation worsens with the compromise of more nodes. So, it becomes important to study the robustness of a system against such attacks. In this regard, it is important to define a parameter that measures the security of sensor networks in an adversarial situation. Resiliency is one of such important parameters. Keeping the connectivity property intact, this paper presents a black-box approach to improve the resiliency of a class of lightweight combinatorial subset schemes, known as CRT-Subset schemes. We have developed unidirectional hash chains for CRT-Subset (HC(CRT-Subset)) by using key doublets through the use of a hash chaining mechanism. The idea extends to a key triplet to manufacture the bidirectional hash chains for CRT-Subset (2HC(CRT-Subset)) scheme. These ideas are explained through four Algorithms. Given the number of nodes required for a system to be implemented for practical purposes, our algorithms are capable of finding suitable parameters to efficiently construct the key rings for future cryptographic communications. They also provide efficient mechanisms to find common keys between two nodes. Furthermore, we have shown that both of our proposed methods are more resilient than the vast majority of existing schemes. Schematic analyses and comparisons exhibit the improvement achieved and thus ensure the practicality in (distributed) deployment for large (low-cost) networks. We observe that in a multi-key scenario, like our proposed resiliency improved variants of CRT-Subset schemes, the standard resiliency measure, fail(s), does not cover the full picture. So, we additionally introduce a new security parameter Ts to measure the robustness of a network. It is mathematically a challenging problem to calculate the exact values of Ts as well as fail(s). We compute a bound of Ts for CRT-Subset and find the exact mathematical expression of fail(s) and Ts for the CRT-KPS scheme. In addition, we come up with a compact expression of T1 for the CRT-Subset Scheme. © 2022 Elsevier B.V.",Chinese Remainder Theory; Hash chains; Key Predistribution; Resiliency; Subset scheme,Network security; Public key cryptography; Set theory; Chinese remainder theory; Hash chains; Improvement strategies; Key pool; Key pre-distribution; Key-management; Resiliency; Secret information; Sensors network; Subset scheme; Sensor networks,,,,,"Rivest, R.L., Shamir, A., Adleman, L., A method for obtaining digital signatures and public-key cryptosystems (1978) Commun. ACM, 21 (2), pp. 120-126; Eschenauer, L., Gligor, V.D., A key-management scheme for distributed sensor networks (2002), pp. 41-47. , Proceedings of the 9th ACM Conference on Computer and Communications Security, Kyoto, Japan; Daemen, J., Rijmen, V., The block cipher rijndael (1998) International Conference on Smart Card Research and Advanced Applications, pp. 277-284. , Springer Louvain-Ln-Neuve, Belgium; Lee, J., Stinson, D.R., A combinatorial approach to key predistribution for distributed sensor networks (2005) IEEE Wireless Communications and Networking Conference, 2005, Vol. 2, pp. 1200-1205. , IEEE New Orleans, la, USA; Sarkar, P., Chowdhury, M.U., Key predistribution scheme using finite fields and reed muller codes (2011) Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing 2011, pp. 67-79. , Springer Sydney, Australia; Kendall, M., Martin, K.M., Graph-theoretic design and analysis of key predistribution schemes (2016) Des. Codes Cryptogr., 81 (1), pp. 11-34; Paterson, M.B., Stinson, D.R., A unified approach to combinatorial key predistribution schemes for sensor networks (2014) Des. Codes Cryptogr., 71 (3), pp. 433-457; Camtepe, S.A., Yener, B., Combinatorial design of key distribution mechanisms for wireless sensor networks (2004) European Symposium on Research in Computer Security, pp. 293-308. , Springer Sophia Antipolis, France; Bechkit, W., Bouabdallah, A., Challal, Y., Enhancing resilience of probabilistic key pre-distribution schemes for WSNs through hash chaining (2010), pp. 642-644. , Proceedings of the 17th ACM Conference on Computer and Communications Security, Chicago Lllinois USA; Bechkit, W., Challal, Y., Bouabdallah, A., A new class of hash-chain based key pre-distribution schemes for WSN (2013) Comput. Commun., 36 (3), pp. 243-255; Camtepe, S.A., Yener, B., Key Distribution Mechanisms for Wireless Sensor Networks: A Survey: Technical Report (2005), pp. 05-07. , Rensselaer Polytechnic Institute Troy, New York; Chan, H., Perrig, A., Song, D., Random key predistribution schemes for sensor networks (2003) 2003 Symposium on Security and Privacy, pp. 197-213. , IEEE Berkeley, CA, USA; Cicho, J., Grzl lewicz, J., Kutyowski, M., Key levels and securing key predistribution against node captures (2009) International Symposium on Algorithms and Experiments for Sensor Systems, Wireless Networks and Distributed Robotics, pp. 64-75. , Springer Rhodos, Greece; Erdös, P., Rényi, A., On the Evolution of Random Graphs, Vol. 5 (1960), pp. 17-61. , Publ. Math. Inst. Hung. Acad. Science; Gennaro, R., Halevi, S., Krawczyk, H., Rabin, T., Reidt, S., Wolthusen, S.D., Strongly-resilient and non-interactive hierarchical key-agreement in MANETs (2008) European Symposium on Research in Computer Security, pp. 49-65. , Springer Málaga, Spain; Ramkumar, M., Memon, N., An efficient key predistribution scheme for ad hoc network security (2005) IEEE J. Sel. Areas Commun., 23 (3), pp. 611-621; Bag, S., Dhar, A., Sarkar, P., 100% connectivity for location aware code based KPD in clustered WSN: merging blocks (2012) International Conference on Information Security, pp. 136-150. , Springer Passau, Germany; Dalai, D.K., Sarkar, P., Key predistribution schemes using bent functions in distributed sensor networks (2016) International Conference on Information Security and Cryptology, pp. 367-385. , Springer Seoul, South Korea; Dalai, D.K., Sarkar, P., Porto, SENSORNETS., Sensornet-A Key Predistribution Scheme for Distributed Sensors using Nets (2017), pp. 49-58. , Portugal; Dalai, D.K., Sarkar, P., Bidirectional hash chains generically enhances resilience of key predistribution schemes (2020) IET Wirel. Sens. Syst., 10 (4), pp. 154-165; Lee, J., Stinson, D.R., Deterministic key predistribution schemes for distributed sensor networks (2004) International Workshop on Selected Areas in Cryptography, pp. 294-307. , Springer Waterloo, Canada; Sarkar, P., Lightweight deterministic non interactive (NI) hierarchical key agreement scheme (KAS) (2017) Helsinki Finland, International Conference on Network and System Security, pp. 315-331. , Springer Helsinki Finland; Sarkar, P., Strongly-resilient, well connected, non-interactive and gateway-free hierarchical deterministic key agreement schemes using Chinese remainder theorem (2020) J. Ambient Intell. Humaniz. Comput., pp. 1-20; Sarkar, P., Nandi, S., A class of key-node indexed hash chains based key predistribution (KPS): signed weighted graphs (2019) Comput. Netw., 164; Al-Qerem, A., Alauthman, M., Almomani, A., Gupta, B., IoT transaction processing through cooperative concurrency control on fog–cloud computing environment (2020) Soft Comput., 24 (8), pp. 5695-5711; Chelliah, P.R., Surianarayanan, C., Multi-cloud adoption challenges for the cloud-native era: Best practices and solution approaches (2021) Int. J. Cloud Appl. Comput. (IJCAC), 11 (2), pp. 67-96; Elrotub, M., Bali, A., Gherbi, A., Sharing VM resources with using prediction of future user requests for an efficient load balancing in cloud computing environment (2021) Int. J. Softw. Sci. Comput. Intell. (IJSSCI), 13 (2), pp. 37-64; Sangaiah, A.K., Hosseinabadi, A.A.R., Shareh, M.B., Bozorgi Rad, S.Y., Zolfagharian, A., Chilamkurti, N., IoT resource allocation and optimization based on heuristic algorithm (2020) Sensors, 20 (2), p. 539; Sangaiah, A.K., Medhane, D.V., Han, T., Hossain, M.S., Muhammad, G., Enforcing position-based confidentiality with machine learning paradigm through mobile edge computing in real-time industrial informatics (2019) IEEE Trans. Ind. Inf., 15 (7), pp. 4189-4196; Soltani, B., Ghenai, A., Zeghib, N., Execution of long-duration multi-cloud serverless functions using selective migration-based approach (2020) Int. J. Cloud Appl. Comput. (IJCAC), 10 (4), pp. 70-97; Sarkar, P., Baranwal, M., Nandi, S., Crt-kps: A key predistribution schemes using crt (2018) Australasian Conference on Information Security and Privacy, pp. 821-830. , Springer Wollongong, NSW, Australia; Ruj, S., Roy, B., Key pre-distribution using partially balanced designs in wireless sensor networks (2011) Int. J. High Perform. Comput. Netw., 7 (1), pp. 19-28; Dalai, D.K., Sarkar, P., Enhancing resilience of kps using bidirectional hash chains and application on sensornet (2017) International Conference on Network and System Security, pp. 683-693. , Springer Helsinki, Finland; Adhikari, M.R., Adhikari, A., Basic Modern Algebra with Applications (2014), Springer; Naor, M., Reingold, O., Number-theoretic constructions of efficient pseudo-random functions (2004) J. ACM, 51 (2), pp. 231-262; Diffie, W., Hellman, M., New directions in cryptography (1976) IEEE Trans. Inform. Theory, 22 (6), pp. 644-654; ElGamal, T., A public key cryptosystem and a signature scheme based on discrete logarithms (1985) IEEE Trans. Inform. Theory, 31 (4), pp. 469-472; Bellare, M., Rogaway, P., Entity authentication and key distribution (1993) Annual International Cryptology Conference, pp. 232-249. , Springer Santa Barbara, CA, USA; Ramkumar, M., Memon, N., Simha, R., A hierarchical key pre-distribution scheme (2005) 2005 IEEE International Conference on Electro Information Technology, pp. 6-pp. , IEEE Lincoln, NE, USA; Chakrabarti, D., Seberry, J., Combinatorial structures for design of wireless sensor networks (2006) International Conference on Applied Cryptography and Network Security, pp. 365-374. , Springer Singapore; Kumar, A., Pais, A.R., A new combinatorial design based key pre-distribution scheme for wireless sensor networks (2019) J. Ambient Intell. Humaniz. Comput., 10 (6), pp. 2401-2416; Ruj, S., Roy, B., Key predistribution using combinatorial designs for grid-group deployment scheme in wireless sensor networks (2010) ACM Trans. Sensor Netw., 6 (1), pp. 1-28","Goswami, C.; Presidency University, West Bengal, India; 电子邮件: 7cgoswami@gmail.com",,,Elsevier B.V.,,,,,15708705,,,,English,Ad Hoc Netw.,Article,Final,,Scopus,2-s2.0-85125145417
"Duan Y., Zou J., Zhou X., Zhang W., Zhang J., Pan Z.",57213271181;57193922285;57190391397;57223032197;55969153700;8426014800;,Enhancing transferability of adversarial examples via rotation-invariant attacks,2022,IET Computer Vision,16,1,,1,11,,,10.1049/cvi2.12054,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123288393&doi=10.1049%2fcvi2.12054&partnerID=40&md5=d53500d6286169fba65418667312a24c,"Command and Control Engineering College, Army Engineering University of PLA, Nanjing, China; Army Military Transportation University of PLA, Zhenjiang Campus, Zhenjiang, China; Communication Engineering College, Army Engineering University of PLA, Nanjing, China","Duan, Y., Command and Control Engineering College, Army Engineering University of PLA, Nanjing, China, Army Military Transportation University of PLA, Zhenjiang Campus, Zhenjiang, China; Zou, J., Command and Control Engineering College, Army Engineering University of PLA, Nanjing, China; Zhou, X., Communication Engineering College, Army Engineering University of PLA, Nanjing, China; Zhang, W., Command and Control Engineering College, Army Engineering University of PLA, Nanjing, China; Zhang, J., Army Military Transportation University of PLA, Zhenjiang Campus, Zhenjiang, China; Pan, Z., Command and Control Engineering College, Army Engineering University of PLA, Nanjing, China","Deep neural networks are vulnerable to adversarial examples. However, existing attacks exhibit relatively low efficacy in generating transferable adversarial examples. Improved transferability to address this issue is proposed via a rotation-invariant attack method that maximizes the loss function w.r.t the random rotated image instead of the original input at each iteration, thus mitigating the high correlation between the adversarial examples and the source models and making the adversarial examples more transferable. Extensive experiments show that the proposed method can significantly improve the transferability of the adversarial examples with almost no extra computational cost and can be integrated into various methods. In addition, when this method is easily applied through a plug-in, the average attack success rate against six robustly trained models increases by 5.4% over the state-of-the-art baseline method, demonstrating its effectiveness and efficiency. The codes used are publicly available at https://github.com/YeXinD/Rotation-Invariant-Attack. © 2021 The Authors. IET Computer Vision published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.",,Computer vision; Image enhancement; Iterative methods; Rotation; Attack methods; Baseline methods; Computational costs; Effectiveness and efficiencies; Loss functions; Plug-ins; Rotated images; Rotation invariant; Source models; State of the art; Deep neural networks,,,,,"Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in neural information processing systems, pp. 1097-1105. , Lake Tahoe, Nevada; Szegedy, C., Intriguing properties of neural networks (2014) 2nd International Conference on Learning Representations, , ICLR, Banff, Canada; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) 3rd International Conference on Learning Representations, , ICLR, San Diego, CA; Xie, C., Adversarial examples for semantic segmentation and object detection (2017) Proceedings of the IEEE International Conference on Computer Vision, pp. 1369-1378. , Venice, Italy; Chen, P.Y., Zoo: zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 15-26. , Dallas, TX; Brendel, W., Rauber, J., Bethge, M., Decision-based adversarial attacks: reliable attacks against black-box machine learning models (2018) 6th International Conference on Learning Representations, , ICLR, Vancouver, Canada; Liu, Y., Delving into transferable adversarial examples and black-box attacks (2017) 5th International Conference on Learning Representations, , ICLR, Toulon, France; Seyed-Mohsen, M.D., Universal adversarial perturbations (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1765-1773. , Honolulu, HI; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2017) 5th International Conference on Learning Representations, , ICLR, Toulon, France; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2017) 5th International Conference on Learning Representations, , ICLR, Toulon, France; Dong, Y., Boosting adversarial attacks with momentum (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 9185-9193. , CVPR, Salt Lake City, UT; Xie, C., Improving transferability of adversarial examples with input diversity (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2730-2739. , CVPR, Long Beach, CA; Dong, Y., Evading defenses to transferable adversarial examples by translation-invariant attacks (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4312-4321. , CVPR, Long Beach, CA; Tramèr, F., Ensemble adversarial training: attacks and defenses (2018) 6th International Conference on Learning Representations, , ICLR, Vancouver, Canada; Liao, F., Defense against adversarial attacks using high-level representation guided denoiser (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1778-1787. , Salt Lake City, UT; Xie, C., Mitigating adversarial effects through randomization (2018) 6th International Conference on Learning Representations, , ICLR, Vancouver, Canada; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) 3rd International Conference on Learning Representations, , ICLR, San Diego, CA; Eykholt, K., Robust physical-world attacks on deep learning visual classification (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1625-1634. , Salt Lake City, UT; Jacobsen, J.H., (2018) Excessive Invariance Causes Adversarial Vulnerability, , arXiv, preprint; Meng, D., Chen, H., Magnet: a two-pronged defense against adversarial examples (2017) Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pp. 135-147. , ACM, Dallas, TX; Papernot, N., Distillation as a defense to adversarial perturbations against deep neural networks (2016) 2016 IEEE Symposium on Security and Privacy (SP), pp. 582-597. , IEEE, San Jose, CA; Guo, C., Countering adversarial images using input transformations (2018) 6th International Conference on Learning Representations, , ICLR, Vancouver, Canada; Shi, Y., Wang, S., Han, Y., Curls & whey: boosting black-box adversarial attacks (2019) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition pp, pp. 6519-6527. , Long Beach, CA; Seyed-Mohsen, M.D., Fawzi, A., Pascal, F., Deepfool: a simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582. , Las Vegas, NV; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy (SP), pp. 39-57. , IEEE, San Jose, CA; Athalye, A., Synthesizing robust adversarial examples (2018) International Conference on Machine Learning (ICML), pp. 284-293. , PMLR, Stockholm, Sweden; Athalye, A., Carlini, N., Wagner, D., (2018) Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples, , arXiv, preprint; Cohen, T., Welling, M., Group equivariant convolutional networks (2016) International conference on machine learning, pp. 2990-2999. , New York, NY; Szegedy, C., Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826. , Las Vegas, NV; Szegedy, C., Inception-v4, inception-resnet and the impact of residual connections on learning (2017) Thirty-First AAAI Conference on Artificial Intelligence, , San Francisco, CA; He, K., Identity mappings in deep residual networks (2016) European conference on computer vision, pp. 630-645. , Springer, Amsterdam, The Netherlands; Huang, G., Densely connected convolutional networks (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4700-4708. , Honolulu, HI; Chollet, F., Xception: deep learning with depthwise separable convolutions (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1251-1258. , Honolulu, HI; Liu, C., Progressive neural architecture search (2018) Proceedings of the European Conference on Computer Vision, pp. 19-35. , ECCV, Munich, Germany","Pan, Z.; Command and Control Engineering College, China; 电子邮件: hotpzs@hotmail.com
Zhang, J.; Army Military Transportation University of PLA, China; 电子邮件: zhang_jin_1115@163.com",,,John Wiley and Sons Inc,,,,,17519632,,,,English,IET Comput. Vision,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85123288393
"Zhu J., Dai F., Yu L., Xie H., Wang L., Wu B., Zhang Y.",57402973500;57403146500;56879585300;35732457100;57403836400;57226540066;57215882960;,Attention-guided transformation-invariant attack for black-box adversarial examples,2022,International Journal of Intelligent Systems,,,,,,,,10.1002/int.22808,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122474022&doi=10.1002%2fint.22808&partnerID=40&md5=0c0028300bb0f782bef3cb1b29664b15,"School of Information Science and Technology, University of Science and Technology of China, Hefei, China; Key Laboratory of Intelligent Information Processing, Chinese Academy of Sciences, Beijing, China; Institute of Artificial Intelligence, Hefei Comprehensive National Science Center, Hefei, China; Beijing Radio and TV Station, Beijing, China; MIT-IBM Watson AI Lab, Cambridge, MA, United States","Zhu, J., School of Information Science and Technology, University of Science and Technology of China, Hefei, China; Dai, F., Key Laboratory of Intelligent Information Processing, Chinese Academy of Sciences, Beijing, China; Yu, L., School of Information Science and Technology, University of Science and Technology of China, Hefei, China, Institute of Artificial Intelligence, Hefei Comprehensive National Science Center, Hefei, China; Xie, H., School of Information Science and Technology, University of Science and Technology of China, Hefei, China; Wang, L., Beijing Radio and TV Station, Beijing, China; Wu, B., MIT-IBM Watson AI Lab, Cambridge, MA, United States; Zhang, Y., School of Information Science and Technology, University of Science and Technology of China, Hefei, China","With the development of media convergence, information acquisition is no longer limited to traditional media, such as newspapers and televisions, but more from digital media on the Internet, where media contents should be under supervision by platforms. At present, the media content analysis technology of Internet platforms relies on deep neural networks (DNNs). However, DNNs show vulnerability to adversarial examples, which results in security risks. Therefore, it is necessary to adequately study the internal mechanism of adversarial examples to build more effective supervision models. When coming to practical applications, supervision models are mostly faced with black-box attacks, where cross-model transferability of adversarial examples has attracted increasing attention. In this paper, to improve the transferability of adversarial examples, we propose an attention-guided transformation-invariant adversarial attack method, which incorporates an attention mechanism to disrupt the most distinctive features and simultaneously ensures adversarial attack invariance under different transformations. Specifically, we dynamically weight the latent features according to an attention mechanism and disrupt them accordingly. Meanwhile, considering the lack of semantics in low-level features, high-level semantics are introduced as spatial guidance to make low-level feature perturbations concentrate on the most discriminative regions. Moreover, since the attention heatmaps may vary significantly across different models, a transformation-invariant aggregated attack strategy is proposed to alleviate overfitting to the proxy model attention. Comprehensive experimental results show that the proposed method can significantly improve the transferability of adversarial examples. © 2022 Wiley Periodicals LLC.",,Digital storage; Semantics; Attention mechanisms; Black boxes; Content analysis; Information acquisitions; Low-level features; Media content; Media convergence; Security risks; Supervision models; Transformation invariants; Deep neural networks,,,,,"Peil, C., Sparviero, S., Media convergence meets deconvergence (2017) Media Convergence and Deconvergence, pp. 3-30. , Springer; Erdal, J.I., Researching media convergence and crossmedia news production (2017) Nordicom Rev, 28 (2), pp. 51-61; Duan, P., Prospects for media convergence (2020) Media Convergence and the Development Strategies of Radio and Television in China, pp. 145-166. , Springer; Wang, M., Li, H., Tao, D., Lu, K., Wu, X., Multimodal graph-based reranking for web image search (2012) IEEE Trans Image Process, 21 (11), pp. 4649-4661; Wang, Y., Ma, F., Jin, Z., EANN: event adversarial neural networks for multi-modal fake news detection (2018) Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pp. 849-857; Shang, Z., Xie, H., Zha, Z., Yu, L., Li, Y., Zhang, Y., Prrnet: pixel-region relation network for face forgery detection (2021) Pattern Recognition, 116; Wang, M., Hong, R., Li, G., Zha, Z.J., Yan, S., Chua, T.S., Event driven web video summarization by tag localization and key-shot identification (2012) IEEE Trans Multimedia, 14 (4), pp. 975-985; Liu, J., Zhu, K., Lu, W., Luo, X., Zhao, X., A lightweight 3D convolutional neural network for deepfake detection (2021) Int J Intell Syst, 36 (9), pp. 4990-5004; Sultani, W., Chen, C., Shah, M., Real-world anomaly detection in surveillance videos (2018) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 6479-6488; Yang, X., Wang, M., Tao, D., Person re-identification with metric learning using privileged information (2017) IEEE Trans Image Process, 27 (2), pp. 791-805; Li, J., Xie, H., Li, J., Wang, Z., Zhang, Y., Frequency-aware discriminative feature learning supervised by single-center loss for face forgery detection (2021) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 6458-6467; Li, J., Xie, H., Yu, L., Gao, X., Zhang, Y., Discriminative feature mining based on frequency information and metric learning for face forgery detection (2021) IEEE Transactions on Knowledge and Data Engineering, , doi:10.1109/TKDE.2021.3117003; Szegedy, C., Zaremba, W., Sutskever, I., Intriguing properties of neural networks (2014) 2nd International Conference on Learning Representations; Zhang, L., Wang, X., Lu, K., Peng, S., Wang, X., An efficient framework for generating robust adversarial examples (2020) Int J Intell Syst, 35 (9), pp. 1433-1449; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy, pp. 39-57; Baluja, S., Fischer, I., Adversarial transformation networks: learning to generate adversarial examples (2017) arXiv preprint arXiv:1703.09387; Song, C., Shmatikov, V., Fooling OCR systems with adversarial text images (2018) arXiv preprint arXiv:1802.05385; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) 3rd International Conference on Learning Representations, , Bengio Y, LeCun Y, eds; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial machine learning at scale (2017) 5th International Conference on Learning Representations; Akhtar, N., Mian, A., Threat of adversarial attacks on deep learning in computer vision: a survey (2018) IEEE Access, 6, pp. 14410-14430; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) 6th International Conference on Learning Representations; Yu, Y., Gao, X., Xu, C.Z., LAFEAT: piercing through adversarial defenses with latent features (2021) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 5735-5745; Li, Q., Guo, Y., Chen, H., Yet another intermediate-level attack (2020) Proceedings of the European Conference on Computer Vision, 12361, pp. 241-257. , Springer; Ilyas, A., Engstrom, L., Athalye, A., Lin, J., Black-box adversarial attacks with limited queries and information (2018) Proceedings of the 35th International Conference on Machine Learning, pp. 2137-2146. , In Dy JG, Krause A, eds., PMLR; Brendel, W., Rauber, J., Bethge, M., Decision-based adversarial attacks: reliable attacks against black-box machine learning models (2018) 6th International Conference on Learning Representations; Bhagoji, A.N., He, W., Li, B., Song, D., Practical black-box attacks on deep neural networks using efficient query mechanisms (2018) Proceedings of the European Conference on Computer Vision, 11216, pp. 154-169. , In Ferrari V, Hebert M, Sminchisescu C, Weiss Y, eds., Springer; Zhou, W., Hou, X., Chen, Y., Transferable adversarial perturbations (2018) Proceedings of the European Conference on Computer Vision, 11218, pp. 452-467. , In Ferrari V, Hebert M, Sminchisescu C, Weiss Y, eds., Springer; Li, M., Deng, C., Li, T., Yan, J., Gao, X., Huang, H., Towards transferable targeted attack (2020) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 641-649; Huang, Q., Katsman, I., He, H., Gu, Z., Belongie, S., Lim, S.N., Enhancing adversarial example transferability with an intermediate level attack (2019) Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 4733-4742; Inkawhich, N., Liang, K.J., Wang, B., Inkawhich, M., Carin, L., Chen, Y., Perturbing across the feature hierarchy to improve standard and strict blackbox attack transferability (2020) Annual Conference on Neural Information Processing Systems, , In Larochelle H, Ranzato M, Hadsell R, Balcan MF, Lin HT, eds; Huang, T., Menkovski, V., Pei, Y., Wang, Y., Pechenizkiy, M., Direction-aggregated attack for transferable adversarial examples (2021) arXiv preprint arXiv:2104.09172; Ganeshan, A., Bs, V., Babu, R.V., FDA: Feature disruptive attack (2019) Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 8069-8079; Wu, W., Su, Y., Chen, X., Boosting the transferability of adversarial samples via attention (2020) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 1161-1170; Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., Torralba, A., Learning deep features for discriminative localization (2016) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 2921-2929; Selvaraju, R.R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., Batra, D., Grad-CAM: visual explanations from deep networks via gradient-based localization (2017) Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 618-626; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 2818-2826; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., Inception-v4, inception-ResNet and the impact of residual connections on learning (2017) Thirty-First AAAI Conference on Artificial Intelligence, , In Singh SP, Markovitch S, eds; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 770-778; He, K., Zhang, X., Ren, S., Sun, J., Identity mappings in deep residual networks (2016) Proceedings of the European Conference on Computer Vision, pp. 630-645. , In Leibe B, Matas J, Sebe N, Welling M, eds., Springer; Kurakin, A., (2018), https://git.dst.etit.tu-chemnitz.de/external/tf-models/-/tree/master/research/adv_imagenet_models, Adversarially trained ImageNet models; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) IEEE European Symposium on Security and Privacy, pp. 372-387; Guo, C., Gardner, J., You, Y., Wilson, A.G., Weinberger, K., Simple black-box adversarial attacks (2019) Proceedings of the 36th International Conference on Machine Learning, pp. 2484-2493. , In Chaudhuri K, Salakhutdinov R, eds., PMLR; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519. , Karri R, Sinanoglu O, Sadeghi AR, Yi X, eds; Dong, Y., Liao, F., Pang, T., Boosting adversarial attacks with momentum (2018) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 9185-9193; Xie, C., Zhang, Z., Zhou, Y., Improving transferability of adversarial examples with input diversity (2019) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 2730-2739. , Springer; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) 5th International Conference on Learning Representations; Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I.J., Boneh, D., McDaniel, P.D., Ensemble adversarial training: attacks and defenses (2018) 6th International Conference on Learning Representations; Inkawhich, N., Wen, W., Li, H.H., Chen, Y., Feature space perturbations yield more transferable adversarial examples (2019) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 7066-7074; Yin, Z., Wang, H., Wang, J., Tang, J., Wang, W., Defense against adversarial attacks by low-level image transformations (2020) Int J Intell Syst, 35 (10), pp. 1453-1466; Xie, C., Wu, Y., Maaten, L., Yuille, A.L., He, K., Feature denoising for improving adversarial robustness (2019) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 501-509; Guo, C., Rana, M., Cissé, M., Maaten, V., Countering adversarial images using input transformations (2018) 6th International Conference on Learning Representations; Ma, X., Li, B., Wang, Y., Characterizing adversarial subspaces using local intrinsic dimensionality (2018) 6th International Conference on Learning Representations; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A.L., Mitigating adversarial effects through randomization (2018) 6th International Conference on Learning Representations; Shafahi, A., Najibi, M., Ghiasi, A., , pp. 3353-3364. , Adversarial training for free! In Wallach HM, Larochelle H, Beygelzimer A, d'Alché-Buc F, Fox EB, Garnett R, eds., Annual Conference on Neural Information Processing Systems, 2019; Perronnin, F., Sánchez, J., Mensink, T., Improving the fisher kernel for large-scale image classification (2020) Proceedings of the European Conference on Computer Vision, 6314, pp. 143-156. , In Daniilidis K, Maragos P, Paragios N, eds., Springer; LeCun, Y., Bengio, Y., Convolutional networks for images, speech, and time series (1995) The Handbook of Brain Theory and Neural Networks, 3361, p. 1995. , 10; Escalera, S., Weimer, M., (2017), https://github.com/cleverhans-lab/cleverhans/tree/master/examples/nips17_adversarial_competition/dataset, The nips '17 competition; (2016), https://github.com/tensorflow/models/tree/master/research/slim, Tensorflow-slim image classification model library","Xie, H.; School of Information Science and Technology, China; 电子邮件: htxie@ustc.edu.cn",,,John Wiley and Sons Ltd,,,,,8848173,,IJISE,,English,Int J Intell Syst,Article,Article in Press,,Scopus,2-s2.0-85122474022
"Xie P., Shi S., Yang S., Qiao K., Liang N., Wang L., Chen J., Hu G., Yan B.",57225707574;57224929858;57216501846;57188641013;57203978839;57225973684;57256011400;57382557700;35188444100;,Improving the Transferability of Adversarial Examples With a Noise Data Enhancement Framework and Random Erasing,2021,Frontiers in Neurorobotics,15,,784053,,,,,10.3389/fnbot.2021.784053,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121635140&doi=10.3389%2ffnbot.2021.784053&partnerID=40&md5=450b2c3accf1fd15610ef7e415d968e5,"Henan Key Laboratory of Imaging and Intelligent Processing, PLA Strategy Support Force Information Engineering University, Zhengzhou, China","Xie, P., Henan Key Laboratory of Imaging and Intelligent Processing, PLA Strategy Support Force Information Engineering University, Zhengzhou, China; Shi, S., Henan Key Laboratory of Imaging and Intelligent Processing, PLA Strategy Support Force Information Engineering University, Zhengzhou, China; Yang, S., Henan Key Laboratory of Imaging and Intelligent Processing, PLA Strategy Support Force Information Engineering University, Zhengzhou, China; Qiao, K., Henan Key Laboratory of Imaging and Intelligent Processing, PLA Strategy Support Force Information Engineering University, Zhengzhou, China; Liang, N., Henan Key Laboratory of Imaging and Intelligent Processing, PLA Strategy Support Force Information Engineering University, Zhengzhou, China; Wang, L., Henan Key Laboratory of Imaging and Intelligent Processing, PLA Strategy Support Force Information Engineering University, Zhengzhou, China; Chen, J., Henan Key Laboratory of Imaging and Intelligent Processing, PLA Strategy Support Force Information Engineering University, Zhengzhou, China; Hu, G., Henan Key Laboratory of Imaging and Intelligent Processing, PLA Strategy Support Force Information Engineering University, Zhengzhou, China; Yan, B., Henan Key Laboratory of Imaging and Intelligent Processing, PLA Strategy Support Force Information Engineering University, Zhengzhou, China","Deep neural networks (DNNs) are proven vulnerable to attack against adversarial examples. Black-box transfer attacks pose a massive threat to AI applications without accessing target models. At present, the most effective black-box attack methods mainly adopt data enhancement methods, such as input transformation. Previous data enhancement frameworks only work on input transformations that satisfy accuracy or loss invariance. However, it does not work for other transformations that do not meet the above conditions, such as the transformation which will lose information. To solve this problem, we propose a new noise data enhancement framework (NDEF), which only transforms adversarial perturbation to avoid the above issues effectively. In addition, we introduce random erasing under this framework to prevent the over-fitting of adversarial examples. Experimental results show that the black-box attack success rate of our method Random Erasing Iterative Fast Gradient Sign Method (REI-FGSM) is 4.2% higher than DI-FGSM in six models on average and 6.6% higher than DI-FGSM in three defense models. REI-FGSM can combine with other methods to achieve excellent performance. The attack performance of SI-FGSM can be improved by 22.9% on average when combined with REI-FGSM. Besides, our combined version with DI-TI-MI-FGSM, i.e., DI-TI-MI-REI-FGSM can achieve an average attack success rate of 97.0% against three ensemble adversarial training models, which is greater than the current gradient iterative attack method. We also introduce Gaussian blur to prove the compatibility of our framework. Copyright © 2021 Xie, Shi, Yang, Qiao, Liang, Wang, Chen, Hu and Yan.",adversarial examples; black-box attack; data enhancement; transfer-based attack; transferability,Iterative methods; Metadata; Adversarial example; Attack methods; Black boxes; Black-box attack; Data enhancement; Enhancement framework; Input transformation; Noise data; Transfer-based attack; Transferability; Deep neural networks; article; noise,,,,,"Behzadan, V., Munir, A., Vulnerability of deep reinforcement learning to policy induction attacks (2017) International Conference on Machine Learning and Data Mining in Pattern Recognition, pp. 262-275. , Cham, Springer; Bochkovskiy, A., Wang, C.-Y., Liao, H.Y.M., Yolov4: Optimal speed and accuracy of object detection (2020) arXiv [Preprint] arXiv:2004.10934, , 34300543; Bojarski, M., Del Testa, D., Dworakowski, D., Firner, B., Flepp, B., Goyal, P., End to end learning for self-driving cars (2016) arXiv [Preprint] arXiv:1604.07316, , 30325645; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) arXiv [Preprint] arXiv: 1608.04644, , 27295638; Carlini, N., Wagner, D., Audio adversarial examples: Targeted attacks on speech-to-text (2018) 2018 IEEE Security and Privacy Workshops (SPW), pp. 1-7. , San Francisco, CA, IEEE; Dai, H., Li, H., Tian, T., Huang, X., Wang, L., Zhu, J., Adversarial attack on graph structured data (2018) International Conference on Machine Learning, pp. 1115-1124. , Stockholm, PMLR; Deng, J., Guo, J., Xue, N., Zafeiriou, S., Arcface: Additive angular margin loss for deep face recognition (2019) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 4690-4699. , Long Beach, CA, IEEE, 34106845; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Boosting adversarial attacks with momentum (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 9185-9193. , Salt Lake City, UT, IEEE; Dong, Y., Pang, T., Su, H., Zhu, J., Evading defenses to transferable adversarial examples by translation-invariant attacks (2019) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 4312-4321. , IEEE; Fischer, M., Baader, M., Vechev, M., Certified defense to image transformations via randomized smoothing (2020) arXiv [Preprint] arXiv:2002.12463; Gao, L., Cheng, Y., Zhang, Q., Xu, X., Song, J., Feature space targeted attacks by statistic alignment (2021) Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, pp. 671-677. , Montreal, Canada. International Joint Conferences on Artificial Intelligence Organization; Gao, L., Zhang, Q., Song, J., Liu, X., Shen, H.T., Patch-wise attack for fooling deep neural network (2020) European Conference on Computer Vision, pp. 307-322. , Cham, Springer; Gedraite, E.S., Hadad, M., Investigation on the effect of a gaussian blur in image filtering and segmentation (2011) In Proceedings ELMAR-2011, pp. 393-396. , IEEE, pages; Gehring, J., Auli, M., Grangier, D., Yarats, D., Dauphin, Y.N., Convolutional sequence to sequence learning (2017) International Conference on Machine Learning, pp. 1243-1252. , PMLR; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) arXiv [Preprint] arXiv: 1412.6572; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778. , Las Vegas, NV, IEEE, 32166560; Inkawhich, N., Liang, K.J., Carin, L., Chen, Y., Transferable perturbations of deep feature distributions (2020) arXiv [preprint]; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2016) arXiv [preprint]; Li, Y., Bai, S., Zhou, Y., Xie, C., Zhang, Z., Yuille, A., Learning transferable adversarial examples via ghost networks (2020) Proceedings of the AAAI Conference on Artificial Intelligence, Vol, 34, pp. 11458-11465. , in; Lin, J., Song, C., He, K., Wang, L., Hopcroft, J.E., Nesterov accelerated gradient and scale invariance for adversarial attacks (2019) arXiv [Preprint] arXiv:1908.06281; Liu, W., Li, Z., Enhancing adversarial examples with flip-invariance and brightness-invariance (2020) International Conference on Security and Privacy in Digital Economy, pp. 469-481. , Quzhou, Springer; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) arXiv[Preprint] arXiv: 1611.02770; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2019) arXiv [Preprint] arXiv: 1706.06083; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: a simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582. , Las Vegas, NV, IEEE; Papernot, N., McDaniel, P., Goodfellow, I., Transferability in machine learning: from phenomena to black-box attacks using adversarial samples (2016) arXiv [Preprint] arXiv:1605.07277; Raghunathan, A., Steinhardt, J., Liang, P., Certified defenses against adversarial examples (2018) arXiv [Preprint] arXiv:1801.09344; Redmon, J., Farhadi, A., Yolov3: An incremental improvement (2018) arXiv arXiv [Preprint] arXiv:1801.09344; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A., Inception-v4, inception-resnet and the impact of residual connections on learning (2017) Proceedings of the AAAI Conference on Artificial Intelligence, Vo, p. 31. , in; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826. , Las Vegas, NV, IEEE; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Intriguing properties of neural networks (2013) arXiv [Preprint] arXiv:1312.6199; Tramér, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., Ensemble adversarial training: attacks and defenses (2017) arXiv [Preprint] arXiv:1705.07204; Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Attention is all you need (2017) In Advances in neural information processing systems, pages, pp. 5998-6008; Wang, X., He, K., Enhancing the transferability of adversarial attacks through variance tuning (2021) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 1924-1933. , IEEE; Wang, X., He, X., Wang, J., He, K., Admix: enhancing the transferability of adversarial attacks (2021) arXiv [Preprint] arXiv: 2102.00436, , a, 27295638; Wang, Z., Guo, H., Zhang, Z., Liu, W., Qin, Z., Ren, K., Feature importance-aware transferable adversarial attacks (2021) arXiv [Preprint] arXiv: 2107.14185, , b; Wu, D., Wang, Y., Xia, S.-T., Bailey, J., Ma, X., Skip connections matter: on the transferability of adversarial examples generated with resnets (2020) arXiv [Preprint] arXiv: 2002.05990, , a; Wu, L., Zhu, Z., Tai, C., Understanding and enhancing the transferability of adversarial examples (2018) arXiv [Preprint] arXiv:1802.09707, , others; Wu, W., Su, Y., Chen, X., Zhao, S., King, I., Lyu, M.R., Boosting the transferability of adversarial samples via attention (2020) 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1158-1167. , b, Seattle, WA, IEEE; Wu, W., Su, Y., Lyu, M.R., King, I., Improving the transferability of adversarial samples with adversarial transformations (2021) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 9024-9033. , in; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., Mitigating adversarial effects through randomization (2017) arXiv [Preprint] arXiv:1711.01991; Xie, C., Zhang, Z., Zhou, Y., Bai, S., Wang, J., Ren, Z., Improving transferability of adversarial examples with input diversity (2019) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 2730-2739. , in; Xie, P., Wang, L., Qin, R., Qiao, K., Shi, S., Hu, G., Improving the transferability of adversarial examples with new iteration framework and input dropout (2021) arXiv [Preprint] arXiv:2106.01617; Zhong, Z., Zheng, L., Kang, G., Li, S., Yang, Y., Random erasing data augmentation (2020) Proc. AAAI Conf. Artif. Intell, 34, pp. 13001-13008; Zou, J., Pan, Z., Qiu, J., Liu, X., Rui, T., Li, W., Improving the transferability of adversarial examples with resized-diverse-inputs, diversity-ensemble and region fitting (2020) Computer Vision – ECCV 2020, 12367, pp. 563-579. , Vedaldi A., Bischof H., Brox T., Frahm J.-M., (eds), Cham, Springer International Publishing,., eds","Yan, B.; Henan Key Laboratory of Imaging and Intelligent Processing, China; 电子邮件: ybspace@hotmail.com",,,Frontiers Media S.A.,,,,,16625218,,,,English,Front. Neurorobotics,Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85121635140
"Li H., Zhang B., Zhang Y., Dang X., Han Y., Wei L., Mao Y., Weng J.",57201676218;57281817800;57203830396;57224127527;57224118833;35174077900;57198508165;35363338200;,A defense method based on attention mechanism against traffic sign adversarial samples,2021,Information Fusion,76,,,55,65,,,10.1016/j.inffus.2021.05.005,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107060989&doi=10.1016%2fj.inffus.2021.05.005&partnerID=40&md5=145e549b88ad34e4fda86aca8d89064b,"College of Information Science and Technology/College of Cyber Security, Jinan University, No. 601, West Huangpu Avenue, Guangzhou, Guangdong, China; College of Mathematics and Informatics, South China Agricultural University, No. 483, Wushan Street Five Road, Guanzhou, China","Li, H., College of Information Science and Technology/College of Cyber Security, Jinan University, No. 601, West Huangpu Avenue, Guangzhou, Guangdong, China; Zhang, B., College of Information Science and Technology/College of Cyber Security, Jinan University, No. 601, West Huangpu Avenue, Guangzhou, Guangdong, China; Zhang, Y., College of Information Science and Technology/College of Cyber Security, Jinan University, No. 601, West Huangpu Avenue, Guangzhou, Guangdong, China; Dang, X., College of Information Science and Technology/College of Cyber Security, Jinan University, No. 601, West Huangpu Avenue, Guangzhou, Guangdong, China; Han, Y., College of Information Science and Technology/College of Cyber Security, Jinan University, No. 601, West Huangpu Avenue, Guangzhou, Guangdong, China; Wei, L., College of Information Science and Technology/College of Cyber Security, Jinan University, No. 601, West Huangpu Avenue, Guangzhou, Guangdong, China; Mao, Y., College of Mathematics and Informatics, South China Agricultural University, No. 483, Wushan Street Five Road, Guanzhou, China; Weng, J., College of Information Science and Technology/College of Cyber Security, Jinan University, No. 601, West Huangpu Avenue, Guangzhou, Guangdong, China","A traditional neural network cannot realize the invariance of image rotation and distortion well, so an attacker can fool the neural network by adding tiny disturbances to an image. If traffic signs are attacked, automatic driving will probably be misguided, leading to disastrous consequences. Inspired by the principle of human vision, this paper proposes a defense method based on an attentional mechanism for traffic sign adversarial samples. In this method, the affine coordinate parameters of the target objects in the images are extracted by a CNN, and then the target objects are redrawn by the coordinate mapping model. In this process, the key areas in the image are extracted by the attention mechanism, and the pixels are filtered by interpolation. Our model simulates the daily behavior of human beings, making it more intelligent in the defense against the adversarial samples. Experiments show that our method has a strong defense ability for traffic sign adversarial samples generated by various attack methods. Compared with other defense methods, our method is more universal and has a strong defense ability against a variety of attacks. Moreover, our model is portable and can be easily implanted into neural networks in the form of defense plug-ins. © 2021 Elsevier B.V.",Adversarial sample; Attention mechanism; Defense model; Traffic sign,Automobile drivers; Behavioral research; Image processing; Network security; Traffic signs; Affine coordinates; Attention mechanisms; Attentional mechanism; Automatic driving; Coordinate mapping; Daily behaviors; Image rotation; Various attacks; Neural networks,,,,,"LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), pp. 436-444; Reichstein, M., Camps-Valls, G., Stevens, B., Jung, M., Denzler, J., Carvalhais, N., Deep learning and process understanding for data-driven earth system science (2019) Nature, 566 (7743), pp. 195-204; Ren, L., Lu, J., Feng, J., Zhou, J., Uniform and variational deep learning for RGB-D object recognition and person re-identification (2019) IEEE Trans. Image Process., PP (99), p. 1; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014), arXiv preprint; Heo, B., Lee, M., Yun, S., Choi, J.Y., Knowledge distillation with adversarial samples supporting decision boundary (2019), 33, pp. 3771-3778. , Proceedings of the AAAI Conference on Artificial Intelligence; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy, SP, pp. 39-57. , IEEE; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) 2016 IEEE European Symposium on Security and Privacy, EuroS&P, pp. 372-387. , IEEE; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., Adversarial examples for semantic segmentation and object detection (2017), pp. 1369-1378. , Proceedings of the IEEE International Conference on Computer Vision; Geiger, A., Lenz, P., Urtasun, R., Are we ready for autonomous driving? the kitti vision benchmark suite (2012) 2012 IEEE Conference on Computer Vision and Pattern Recognition, pp. 3354-3361. , IEEE; Teichmann, M., Weber, M., Zoellner, M., Cipolla, R., Urtasun, R., Multinet: Real-time joint semantic reasoning for autonomous driving (2018) 2018 IEEE Intelligent Vehicles Symposium (IV), pp. 1013-1020. , IEEE; Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Xiao, C., Prakash, A., Song, D., Robust physical-world attacks on deep learning models (2018), arXiv preprint; Ungerleider, K., Sabine, K.G., Mechanisms of visual attention in the human cortex (2003) Ann. Rev. Neuroence, 23 (1), pp. 315-341; Lopez, P.R., Dorta, D.V., Preixens, G.C., Sitjes, J.M.G., Marva, F.X.R., Gonzalez, J., Pay attention to the activations: a modular attention mechanism for fine-grained image recognition (2019) IEEE Trans. Multimed., 22 (2), pp. 502-514; Eykholt, K., Evtimov, I., Fernandes, E., (2018), pp. 1625-1634. , Li, Robust physical-world attacks on deep learning visual classification, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Papernot, N., McDaniel, P., Goodfellow, I., Transferability in machine learning: from phenomena to black-box attacks using adversarial samples (2016), arXiv preprint; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2014), arXiv preprint; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2016), arXiv preprint; Su, J., Vargas, D.V., Sakurai, K., One pixel attack for fooling deep neural networks (2019) IEEE Trans. Evol. Comput., 23 (5), pp. 828-841; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2013), arXiv preprint; Fawzi, A., Moosavi-Dezfooli, S.-M., Frossard, P., Robustness of classifiers: from adversarial to random noise (2016) Advances in Neural Information Processing Systems, pp. 1632-1640; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015), pp. 427-436. , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017), pp. 1765-1773. , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Miyato, T., Dai, A.M., Goodfellow, I., Adversarial training methods for semi-supervised text classification (2016), arXiv preprint; Dziugaite, G.K., Ghahramani, Z., Roy, D.M., A study of the effect of jpg compression on adversarial images (2016), arXiv preprint; Ross, A.S., Doshi-Velez, F., Improving the adversarial robustness and interpretability of deep neural networks by regularizing their input gradients (2018), Thirty-Second AAAI Conference on Artificial Intelligence; Akhtar, N., Mian, A., Threat of adversarial attacks on deep learning in computer vision: A survey (2018) IEEE Access, 6, pp. 14410-14430; Luo, Y., Boix, X., Roig, G., Poggio, T., Zhao, Q., Foveation-based mechanisms alleviate adversarial examples (2015), arXiv preprint; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2017), arXiv preprint; Sankaranarayanan, S., Jain, A., Chellappa, R., Lim, S.N., Regularizing deep networks using efficient layerwise adversarial training (2018), Thirty-Second AAAI Conference on Artificial Intelligence; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) 2016 IEEE Symposium on Security and Privacy, SP, pp. 582-597. , IEEE; Gao, J., Wang, B., Lin, Z., Xu, W., Qi, Y., Deepcloak: Masking deep neural network models for robustness against adversarial samples (2017), arXiv preprint; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., On detecting adversarial perturbations (2017), arXiv preprint; Akhtar, N., Liu, J., Mian, A., Defense against universal adversarial perturbations (2018), pp. 3389-3398. , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Keshari, R., Vatsa, M., Singh, R., Noore, A., Learning structure and strength of CNN filters for small sample size training (2018), 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR; Diaz, M., Ferrer, M.A., Eskander, G.S., Sabourin, R., Generation of duplicated off-line signature images for verification systems (2017) IEEE Trans. Pattern Anal. Mach. Intell., 39 (5), pp. 951-964; Akiba, T., Suzuki, S., Fukuda, K., Extremely large minibatch sgd: Training resnet-50 on imagenet in 15 minutes (2017), arXiv preprint; Rauber, J., Brendel, W., Bethge, M., Foolbox v0. 8.0: A python toolbox to benchmark the robustness of machine learning models (2017), arXiv preprint; Man vs. computer: Benchmarking machine learning algorithms for traffic sign recognition (2012) Neural Netw., 32, pp. 323-332; Mogelmose, A., Trivedi, M.M., Moeslund, T.B., Vision-based traffic sign detection and analysis for intelligent driver assistance systems: Perspectives and survey (2012) IEEE Trans. Intell. Transp. Syst., 13 (4), pp. 1484-1497; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., Imagenet: A large-scale hierarchical image database (2009) 2009 IEEE Conference on Computer Vision and Pattern Recognition, pp. 248-255. , Ieee; Zeiler, M.D., Fergus, R., Visualizing and understanding convolutional networks (2014) European Conference on Computer Vision, pp. 818-833. , Springer; Buckman, J., Roy, A., Raffel, C., Goodfellow, I., Thermometer encoding: One hot way to resist adversarial examples (2018), 6th International Conference on Learning Representations; Samangouei, P., Kabkab, M., Chellappa, R., Defense-gan: Protecting classifiers against adversarial attacks using generative models (2018), arXiv preprint; Santhanam, G.K., Grnarova, P., Defending against adversarial attacks by leveraging an entire gan (2018), arXiv preprint; Deng, L., The mnist database of handwritten digit images for machine learning research [best of the web] (2012) IEEE Signal Process. Mag., 29 (6), pp. 141-142; Li, H., Liu, H., Ji, X., Li, G., Shi, L., Cifar10-dvs: an event-stream dataset for object classification (2017) Front. Neurosci., 11, p. 309","Weng, J.; College of Information Science and Technology/College of Cyber Security, No. 601, West Huangpu Avenue, China; 电子邮件: wj_jinanu@163.com",,,Elsevier B.V.,,,,,15662535,,,,English,Inf. Fusion,Article,Final,,Scopus,2-s2.0-85107060989
"Chen H., Lu K., Wang X., Li J.",57306602000;57306602100;57202257637;57202722689;,Generating transferable adversarial examples based on perceptually-aligned perturbation,2021,International Journal of Machine Learning and Cybernetics,12,11,,3295,3307,,,10.1007/s13042-020-01240-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117732595&doi=10.1007%2fs13042-020-01240-1&partnerID=40&md5=5262877feaacbe86d9fc8d0d42f8d526,"Institute of Artificial Intelligence and Blockchain, Guangzhou University, Guangzhou, 510006, China; State Key Laboratory of Information Security, Chinese Academy of Sciences, Beijing, China","Chen, H., Institute of Artificial Intelligence and Blockchain, Guangzhou University, Guangzhou, 510006, China; Lu, K., Institute of Artificial Intelligence and Blockchain, Guangzhou University, Guangzhou, 510006, China; Wang, X., Institute of Artificial Intelligence and Blockchain, Guangzhou University, Guangzhou, 510006, China, State Key Laboratory of Information Security, Chinese Academy of Sciences, Beijing, China; Li, J., Institute of Artificial Intelligence and Blockchain, Guangzhou University, Guangzhou, 510006, China","Neural networks (NNs) are known to be susceptible to adversarial examples (AEs), which are intentionally designed to deceive a target classifier by adding small perturbations to the inputs. And interestingly, AEs crafted for one NN can mislead another model. Such a property is referred to as transferability, which is often leveraged to perform attacks in black-box settings. To mitigate the transferability of AEs, many approaches are explored to enhance the NN’s robustness. Especially, adversarial training (AT) and its variants are shown be the strongest defense to resist such transferable AEs. To boost the transferability of AEs against the robust models that have undergone AT, a novel AE generating method is proposed in this paper. The motivation of our method is based on the observation that robust models with AT is more sensitive to the perceptually-relevant gradients, hence it is reasonable to synthesize the AEs by the perturbations that have the perceptually-aligned features. The detailed process of the proposed method is given as below. First, by optimizing the loss function over an ensemble of random noised inputs, we obtain perceptually-aligned perturbations that have the noise-invariant property. Second, we employ Perona–Malik (P–M) filter to smooth the derived adversarial perturbations, such that the perceptually-relevant feature of the perturbation is significantly reinforced and the local oscillation of the perturbation is substantially suppressed. Our method can be generally applied to any gradient-based attack method. We carry out extensive experiments under ImageNet dataset for various robust and non-robust models, and the experimental results demonstrate the effectiveness of our method. Particularly, by combining our method with diverse inputs method and momentum iterative fast gradient sign method, we can achieve state-of-the-art performance in terms of fooling the robust models. © 2021, Springer-Verlag GmbH Germany, part of Springer Nature.",Adversarial example; Perceptually-aligned perturbation; Robust model; Transferability,Artificial intelligence; Software engineering; Adversarial example; Black boxes; Example based; Generating methods; Neural-networks; Perceptually-aligned perturbation; Property; Robust modeling; Small perturbations; Transferability; Iterative methods,,,,,"Athalye, A., Carlini, N., Wagner, D., (2018) Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples; Balduzzi, D., Frean, M., Leary, L., Lewis, J.P., Ma, K.W., McWilliams, B., The shattered gradients problem: If resnets are the answer, then what is the question? (2017) Neural and Evolutionary Computing; Brendel, W., Rauber, J., Bethge, M., Decision-based adversarial attacks: Reliable attacks against black-box machine learning models (2017) Machine Learning; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 Ieee Symposium on Security and Privacy (Sp), pp. 39-57; Chan, A., Tay, Y., Ong, Y.S., Fu, J., (2019) Jacobian Adversarially Regularized Networks for Robustness; Chen, J., Su, M., Shen, S., Xiong, H., Zheng, H., POBA-GA: perturbation optimized black-box adversarial attacks via genetic algorithm (2019) Comput Secur, 85, pp. 89-106; Chen, P.Y., Zhang, H., Yi, J., Hsieh, C.J., (2017) Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models, pp. 15-26. , https://doi.org/10.1145/3128572.3140448; Dhillon, G.S., Azizzadenesheli, K., Lipton, Z.C., (2018) Stochastic activation pruning for robust adversarial defense; Dong, Y., Liao, F., Pang, T., Boosting adversarial attacks with momentum (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 9185-9193; Dong, Y., Pang, T., Su, H., Evading defenses to transferable adversarial examples by translation-invariant attacks (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4312-4321; Feng, W., Chen, Z., Gursoy, M.C., Velipasalar, S., Defense strategies against adversarial jamming attacks via deep reinforcement learning (2020) 2020 54Th Annual Conference on Information Sciences and Systems (CISS); Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2014) Machine Learning; Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., On the (Statistical) detection of adversarial examples (2017) Cryptography and Security; Gu, X., Angelov, P.P., Soares, E.A., A self-adaptive synthetic over-sampling technique for imbalanced classification (2020) Int J Intell Syst, 35 (6), pp. 923-943; Guo, C., Rana, M., Cisse, M., der Maaten, L.V., Countering adversarial images using input transformations (2017) Computer Vision and Pattern Recognition; He, K., Zhang, X., Ren, S., Identity mappings in deep residual networks (2016) European conference on computer vision, pp. 630-645. , Springer, Cham; Huan, Z., Wang, Y., Zhang, X., Data-free adversarial perturbations for practical black-box attack (2020) Pacific-Asia conference on knowledge discovery and data mining, pp. 127-138. , Springer, Cham; Iyyer, M., Wieting, J., Gimpel, K., Zettlemoyer, L., (2018) Adversarial Example Generation with Syntactically Controlled Paraphrase Networks, 1, pp. 1875-1885; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2016) Computer Vision and Pattern Recognition; Li, J., Kuang, X., Lin, S., Ma, X., Tang, Y., Privacy preservation for machine learning training and classification based on homomorphic encryption schemes (2020) Inf Sci, 526, pp. 166-179; Li, X., Li, F., Adversarial examples detection in deep networks with convolutional filter statistics (2017) Proceedings of the IEEE International Conference on Computer Vision, pp. 5764-5772; Li, Y., Li, L., Wang, L., (2019) Nattack: Learning the distributions of adversarial examples for an improved black-box attack on deep neural networks; Liu, X., Cheng, M., Zhang, H., Towards robust neural networks via random self-ensemble (2018) Proceedings of the European Conference on Computer Vision (ECCV), pp. 369-385; Liu, Y., Chen, X., Liu, C., Song, D., (2016) Delving into transferable adversarial examples and black-box attacks, , Learning; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2017) Machine Learning; Meng, L., Lin, C.T., Jung, T.P., White-box target attack for EEG-based BCI regression problems (2019) International conference on neural information processing, pp. 476-488. , Springer, Cham; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., (2017) On detecting adversarial perturbations; Moosavidezfooli, S., Fawzi, A., Fawzi, O., Frossard, P., Soatto, S., Analysis of universal adversarial perturbations (2017) Computer Vision and Pattern Recognition; Mopuri, K.R., Garg, U., Babu, R.V., Fast feature fool: A data independent approach to universal adversarial perturbations (2017) Computer Vision and Pattern Recognition; Nazemi, A., Fieguth, P., (2019) Potential adversarial samples for white-box attacks; Papernot, N., McDaniel, P., Goodfellow, I., Transferability in machine learning: From phenomena to black-box attacks using adversarial samples (2016) Cryptography and Security; Papernot, N., McDaniel, P., Wu, X., Distillation as a defense to adversarial perturbations against deep neural networks (2016) 2016 IEEE Symposium on Security and Privacy (SP), pp. 582-597; He, X., Yan, S., Hu, Y., Face recognition using laplacianfaces (2005) IEEE Trans Pattern Anal Mach Intell, 27 (3), pp. 328-340; Smilkov, D., Thorat, N., Kim, B., Viegas, F.B., Wattenberg, M., (2017) Smoothgrad: Removing noise by adding noise, , Learning; Sun, L., Wang, J., Yu, P.S., Li, B., Adversarial attack and defense on graph data: A survey (2018) Cryptography and Security; Sutanto, R.E., Lee, S., Adversarial attack defense based on the deep image prior network (2020) Information science and applications, pp. 519-526. , Springer, Singapore; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., (2016) Inception-v4, inception-resnet and the impact of residual connections on learning, pp. 4278-4284; Szegedy, C., Vanhoucke, V., Ioffe, S., Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826; Tang, P., Wang, C., Wenyu, X., Wenjun, L., Jingdong, Z., Object detection in videos by high quality object linking (2019) IEEE Trans Pattern Anal Mach Intel, 42 (5), pp. 1272-1278; Tramer, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2017) Machine Learning; Wang, X., Kuang, X., Li, J., Oblivious transfer for privacy-preserving in VANET's feature matching (2020) IEEE Transactions on Intelligent Transportation Systems; Wang, X., Li, J., Kuang, X., Tan, Y., Li, J., The security of machine learning in an adversarial setting: a survey (2019) J Parallel Distrib Comput, 130, pp. 12-23; Weickert, J., Romeny, B.T.H., Viergever, M., Efficient and reliable schemes for nonlinear diffusion filtering (1998) IEEE Trans Image Process, 7 (3), pp. 398-410; Wu, L., Zhu, Z., Tai, C., Weinan, E., Understanding and enhancing the transferability of adversarial examples (2018) Machine Learning; Xie, C., Zhang, Z., Zhou, Y., Improving transferability of adversarial examples with input diversity (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2730-2739; Zhang, F., Chen, Y., Li, Z., Hong, Z., Liu, J., Ma, F., Han, J., Ding, E., Acfnet: Attentional class feature network for semantic segmentation (2019) 2019 IEEE International Conference on Image Processing (ICIP); Zhang, Y., Liang, P., (2019) Defending against whitebox adversarial attacks via randomized discretization; Zhao, Q., Zhao, C., Cui, S., PrivateDL: Privacy ‐ preserving collaborative deep learning against leakage from gradient sharing (2020) Int J Intell Syst","Wang, X.; Institute of Artificial Intelligence and Blockchain, China; 电子邮件: xianmin@gzhu.edu.cn
Li, J.; Institute of Artificial Intelligence and Blockchain, China; 电子邮件: jinli71@gmail.com",,,Springer Science and Business Media Deutschland GmbH,,,,,18688071,,,,English,Intl. J. Mach. Learn. Cybern.,Article,Final,,Scopus,2-s2.0-85117732595
"Demetrio L., Coull S.E., Biggio B., Lagorio G., Armando A., Roli F.",57205738855;23566653400;23090165100;56618171700;57190072464;57194734588;,Adversarial EXEmples: A Survey and Experimental Evaluation of Practical Attacks on Machine Learning for Windows Malware Detection,2021,ACM Transactions on Privacy and Security,24,4,27,,,,,10.1145/3473039,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116399529&doi=10.1145%2f3473039&partnerID=40&md5=40fd1ec9bc90fba4ac39362454b06e7b,"UniversitÃ Degli Studi di Cagliari, Cagliari, Italy; FireEye, Inc., Milpitas, United States; Pluribus One, Cagliari, Italy; UniversitÃ Degli Studi di Genova, Italy","Demetrio, L., UniversitÃ Degli Studi di Cagliari, Cagliari, Italy; Coull, S.E., FireEye, Inc., Milpitas, United States; Biggio, B., UniversitÃ Degli Studi di Cagliari, Cagliari, Italy, Pluribus One, Cagliari, Italy; Lagorio, G., UniversitÃ Degli Studi di Genova, Italy; Armando, A., UniversitÃ Degli Studi di Genova, Italy; Roli, F., UniversitÃ Degli Studi di Genova, Italy","Recent work has shown that adversarial Windows malware samples - referred to as adversarial EXEmples in this article - can bypass machine learning-based detection relying on static code analysis by perturbing relatively few input bytes. To preserve malicious functionality, previous attacks either add bytes to existing non-functional areas of the file, potentially limiting their effectiveness, or require running computationally demanding validation steps to discard malware variants that do not correctly execute in sandbox environments. In this work, we overcome these limitations by developing a unifying framework that does not only encompass and generalize previous attacks against machine-learning models, but also includes three novel attacks based on practical, functionality-preserving manipulations to the Windows Portable Executable file format. These attacks, named Full DOS, Extend, and Shift, inject the adversarial payload by respectively manipulating the DOS header, extending it, and shifting the content of the first section. Our experimental results show that these attacks outperform existing ones in both white-box and black-box scenarios, achieving a better tradeoff in terms of evasion rate and size of the injected payload, while also enabling evasion of models that have been shown to be robust to previous attacks. To facilitate reproducibility of our findings, we open source our framework and all the corresponding attack implementations as part of the secml-malware Python library. We conclude this work by discussing the limitations of current machine learning-based malware detectors, along with potential mitigation strategies based on embedding domain knowledge coming from subject-matter experts directly into the learning process. © 2021 ACM.",Adversarial examples; evasion; malware detection; semantics-invariant manipulations,Machine learning; Malware; Adversarial example; Evasion; Experimental evaluation; Functional areas; Machine-learning; Malware detection; Non-functional; On-machines; Semantic-invariant manipulation; Static code analysis; Semantics,,,,,"Aghakhani, H., Gritti, F., Mecca, F., Lindorfer, M., Ortolani, S., Balzarotti, D., Vigna, G., Kruegel, C., When malware is packin'heat; Limits of machine learning classifiers based on static analysis features (2020) Proceedings of the Network and Distributed Systems Security (NDSS'20) Symposium 2020; Anderson, H.S., Kharkar, A., Filar, B., Roth, P., Evading machine learning malware detection (2017) Black Hat; Anderson, H.S., Roth, P., (2018) Ember: An Open Dataset for Training Static Pe Malware Machine Learning Models, , https://arxiv.org/abs/1804.04637; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Srndi, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Proceedings of the European Conference on Machine Learning and Knowledge Discovery in Databases (ECML PKDD'13), 8190, pp. 387-402. , Hendrik Blockeel, Kristian Kersting, Siegfried Nijssen, and Filip Ẑelezný (Eds.), Lecutre Notes in Computer Science,. Springer, Berlin; Biggio, B., Fumera, G., Roli, F., Security evaluation of pattern classifiers under attack (2014) IEEE Trans. Knowl. Data Eng., 26 (4), pp. 984-996. , Apr. 2014; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Proceedings of the 2017 IEEE Symposium on Security and Privacy (SP'17), pp. 39-57; Labaca Castro, R., Schmitt, C., Dreo, G., AIMED: Evolving malware with genetic programming to evade detection (2019) Proceedings of the 18th IEEE International Conference on Trust, Security and Privacy in Computing and Communications/13th IEEE International Conference on Big Data Science and Engineering (TrustCom/BigDataSE'19), pp. 240-247; Chen, P., Zhang, H., Sharma, Y., Yi, J., Hsieh, C., ZOO: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security (AISec'17), pp. 15-26. , ACM, New York, NY; Coull, S.E., Gardner, C., Activation analysis of a byte-based deep neural network for malware classification (2019) Proceedings of the 2019 IEEE Security and Privacy Workshops (SPW), pp. 21-27; David, O.E., Netanyahu, N.S., Deepsign: Deep learning for automatic malware signature generation and classification (2015) Proceedings of the 2015 International Joint Conference on Neural Networks (IJCNN), pp. 1-8; Demetrio, L., Biggio, B., (2021) Secml-malware: A Python Library for Adversarial Robustness Evaluation of Windows Malware Classifiers, , https://arxiv.org/abs/cs.CR/2104.12848; Demetrio, L., Biggio, B., Lagorio, G., Roli, F., Armando, A., Explaining vulnerabilities of deep learning to adversarial malware binaries (2019) Proceedings of the 3rd Italian Conference on CyberSecurity (ITASEC'19); Demetrio, L., Biggio, B., Lagorio, G., Roli, F., Armando, A., Functionalitypreserving black-box optimization of adversarial Windows malware (2021) IEEE Transactions on Information Forensics and Security, 16, pp. 3469-3478; Demontis, A., Melis, M., Pintor, M., Jagielski, M., Biggio, B., Oprea, A., Nita-Rotaru, C., Roli, F., Why do adversarial attacks transfer? explaining transferability of evasion and poisoning attacks (2019) Proceedings of the 28th USENIX Security Symposium (USENIX Security'19), , USENIX Association; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2014) Proceedings of the 3th International Conference on Learning Representations (ICLR'15); Hardy, W., Chen, L., Hou, S., Ye, Y., Li, X., DL4MD: A deep learning framework for intelligent malware detection (2016) Proceedings of the International Conference on Data Mining (DMIN'16), p. 61. , The Steering Committee of The World Congress in Computer Science; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B., Tygar, J.D., Adversarial machine learning (2011) Proceedings of the 4th ACM Workshop on Artificial Intelligence and Security (AISec'11), pp. 43-57; Ilyas, A., Engstrom, L., Athalye, A., Lin, J., Black-box adversarial attacks with limited queries and information (2018) Proceedings of the 35th International Conference on Machine Learning (ICML'18), 80, pp. 2137-2146. , Jennifer Dy and Andreas Krause (Eds.),. PMLR; Incer, I., Theodorides, M., Afroz, S., Wagner, D., Adversarially robust malware detection using monotonic classification (2018) Proceedings of the 4th ACMInternationalWorkshop on Security and Privacy Analytics, pp. 54-63; Klambauer, G., Unterthiner, T., Mayr, A., Hochreiter, S., Self-normalizing neural networks (2017) Advances in Neural Information Processing Systems, pp. 971-980; Kolosnjaji, B., Demontis, A., Biggio, B., Maiorca, D., Giacinto, G., Eckert, C., Roli, F., Adversarial malware binaries: Evading deep learning for malware detection in executables (2018) Proceedings of the 2018 26th European Signal Processing Conference (EUSIPCO'18), pp. 533-537; Kolosnjaji, B., Zarras, A., Webster, G., Eckert, C., Deep learning for classification of malware system call sequences (2016) Proceedings of the Australasian Joint Conference on Artificial Intelligence, pp. 137-149. , Springer; Král, M., Svec, O., Bálek, M., Jaŝek, O., Deep convolutionalmalware classifiers can learn from raw executables and labels only (2018) Proceedings of the 6th International Conference on Learning Representations (ICLR'18) Workshop; Kreuk, F., Barak, A., Aviv-Reuven, S., Baruch, M., Pinkas, B., Keshet, J., Deceiving endto-end deep learning malware detectors using adversarial examples (2018) Workshop on Security in Machine Learning (NeurIPS); Melacci, S., Ciravegna, G., Sotgiu, A., Demontis, A., Biggio, B., Gori, M., Roli, F., (2020) Can Domain Knowledge Alleviate Adversarial Attacks Inmulti-label Classifiers?, , https://arxiv.org/abs/cs.LG/2006.03833; Melis, M., Demontis, A., Pintor, M., Sotgiu, A., Biggio, B., (2019) Secml: A Python Library for Secure and Explainable Machine Learning, , https://arxiv.org/abs/cs.LG/1912.10013; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples, , https://arxiv.org/abs/1605.07277; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the ACM on Asia Conference on Computer and Communications Security (Asia CCS'17), pp. 506-519. , ACM, New York, NY; Pierazzi, F., Pendlebury, F., Cortellazzi, J., Cavallaro, L., Intriguing properties of adversarial ML attacks in the problem space (2020) Proceedings of the IEEE Symposium on Security and Privacy (SP'20), pp. 1332-1349; Raff, E., Barker, J., Sylvester, J., Brandon, R., Catanzaro, B., Nicholas, C.K., Malware detection by eating a whole exe (2018) Proceedings of the Workshops at the 32nd AAAI Conference on Artificial Intelligence; Saxe, J., Berlin, K., Deep neural network based malware detection using two dimensional binary program features (2015) Proceedings of the 2015 10th International Conference on Malicious and Unwanted Software (MALWARE'15), pp. 11-20; Sharif, M., Lucas, K., Bauer, L., Reiter, M.K., Shintre, S., (2019) Optimization-guided Binary Diversification to Mislead Neural Networks for Malware Detection, , https://arxiv.org/abs/1912.09064; Song, W., Li, X., Afroz, S., Garg, D., Kuznetsov, D., Yin, H., (2020) Automatic Generation of Adversarial Examples for Interpreting Malware Classifiers, , https://arxiv.org/abs/2003.03100; Suciu, O., Coull, S.E., Johns, J., Exploring adversarial examples in malware detection (2019) Proceedings of the 2019 IEEE Security and Privacy Workshops (SPW'19), pp. 8-14; Suciu, O., Marginean, R., Kaya, Y., Daume, H., Dumitras, T., When does machine learning FAIL?: Generalized transferability for evasion and poisoning attacks (2018) Proceedings of the 27th USENIX Security Symposium (USENIX Security'18), pp. 1299-1316. , USENIX Association; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) Proceedings of the International Conference on Learning Representations; Wenzl, M., Merzdovnik, G., Ullrich, J., Weippl, E., From hack to elaborate technique-A survey on binary rewriting (2019) ACM Comput. Surv., 52 (3), pp. 1-37; Wierstra, D., Schaul, T., Glasmachers, T., Sun, Y., Peters, J., Schmidhuber, J., Natural evolution strategies (2014) J. Mach. Learn. Res., 15, pp. 949-980",,,,Association for Computing Machinery,,,,,24712566,,,,English,ACM Trans. Priv. Secur.,Article,Final,"All Open Access, Green",Scopus,2-s2.0-85116399529
"Jia Y., Wang J., Poskitt C.M., Chattopadhyay S., Sun J., Chen Y.",57203035197;57191964922;36698287200;57190658613;56153273100;57192062465;,Adversarial attacks and mitigation for anomaly detectors of cyber-physical systems,2021,International Journal of Critical Infrastructure Protection,34,,100452,,,,2,10.1016/j.ijcip.2021.100452,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107972529&doi=10.1016%2fj.ijcip.2021.100452&partnerID=40&md5=f7f31fdfd9b98a8b598a4ba66714d89e,"Singapore University of Technology and Design, Singapore; Zhejiang University, China; Singapore Management University, Singapore","Jia, Y., Singapore University of Technology and Design, Singapore; Wang, J., Zhejiang University, China; Poskitt, C.M., Singapore Management University, Singapore; Chattopadhyay, S., Singapore University of Technology and Design, Singapore; Sun, J., Singapore Management University, Singapore; Chen, Y., Singapore Management University, Singapore","The threats faced by cyber-physical systems (CPSs) in critical infrastructure have motivated research into a multitude of attack detection mechanisms, including anomaly detectors based on neural network models. The effectiveness of anomaly detectors can be assessed by subjecting them to test suites of attacks, but less consideration has been given to adversarial attackers that craft noise specifically designed to deceive them. While successfully applied in domains such as images and audio, adversarial attacks are much harder to implement in CPSs due to the presence of other built-in defence mechanisms such as rule checkers (or invariant checkers). In this work, we present an adversarial attack that simultaneously evades the anomaly detectors and rule checkers of a CPS. Inspired by existing gradient-based approaches, our adversarial attack crafts noise over the sensor and actuator values, then uses a genetic algorithm to optimise the latter, ensuring that the neural network and the rule checking system are both deceived. We implemented our approach for two real-world critical infrastructure testbeds, successfully reducing the classification accuracy of their detectors by over 50% on average, while simultaneously avoiding detection by rule checkers. Finally, we explore whether these attacks can be mitigated by training the detectors on adversarial samples. © 2021 Elsevier B.V.",Adversarial attacks; Anomaly detectors; Cyber-physical systems; Industrial control systems; Neural networks; Testing defence mechanisms,Critical infrastructures; Cyber Physical System; Embedded systems; Genetic algorithms; Public works; Anomaly detector; Attack detection; Classification accuracy; Cyber physical systems (CPSs); Defence mechanisms; Gradient based; Neural network model; Sensor and actuators; Neural networks,,,,,"Adepu, S., Mathur, A., Using process invariants to detect cyber attacks on a water treatment system (2016) Proc. International Conference on ICT Systems Security and Privacy Protection (SEC 2016), IFIP AICT, 471, pp. 91-104. , Springer; Feng, C., Palleti, V.R., Mathur, A., Chana, D., A systematic framework to generate invariants for anomaly detection in industrial control systems (2019) Proc. Annual Network and Distributed System Security Symposium (NDSS 2019), , The Internet Society; Yoong, C.H., Palleti, V.R., Silva, A., Poskitt, C.M., Towards systematically deriving defence mechanisms from functional requirements of cyber-physical systems (2020) Proc. ACM Cyber-Physical System Security Workshop (CPSS 2020), pp. 11-22. , ACM; Yoong, C.H., Palleti, V.R., Maiti, R.R., Silva, A., Poskitt, C.M., Deriving invariant checkers for critical infrastructure using axiomatic design principles (2021) Cybersecurity, 4 (1), p. 6; Valente, J., Barreto, C.A., Cárdenas, A.A., Cyber-physical systems attestation (2014) Proc. IEEE International Conference on Distributed Computing in Sensor Systems (DCOSS 2014), pp. 354-357. , IEEE Computer Society; Roth, T.P., McMillin, B.M., Physical attestation in the smart grid for distributed state verification (2017) Proc. IEEE Annual Computer Software and Applications Conference (COMPSAC 2017), pp. 626-627. , IEEE Computer Society; Chen, Y., Poskitt, C.M., Sun, J., Learning from mutants: using code mutation to learn and monitor invariants of a cyber-physical system (2018) Proc. IEEE Symposium on Security and Privacy (S&P 2018), pp. 648-660. , IEEE Computer Society; Formby, D., Srinivasan, P., Leonard, A.M., Rogers, J.D., Beyah, R.A., Who's in control of your control system? Device fingerprinting for cyber-physical systems (2016) Proc. Annual Network and Distributed System Security Symposium (NDSS 2016), , The Internet Society; Ahmed, C.M., Mathur, A.P., Ochoa, M., NoiSense print: detecting data integrity attacks on sensor measurements using hardware-based fingerprints (2020) ACM Trans. Privacy Secur., 24 (1); Chandola, V., Banerjee, A., Kumar, V., Anomaly detection: a survey (2009) ACM Comput. Surv., 41 (3), pp. 151-15:58; Inoue, J., Yamagata, Y., Chen, Y., Poskitt, C.M., Sun, J., Anomaly detection for a water treatment system using unsupervised machine learning (2017) Proc. IEEE International Conference on Data Mining Workshops (ICDMW 2017): Data Mining for Cyberphysical and Industrial Systems (DMCIS 2017), pp. 1058-1065. , IEEE; Goh, J., Adepu, S., Tan, M., Lee, Z.S., Anomaly detection in cyber physical systems using recurrent neural networks (2017) 2017 IEEE 18th International Symposium on High Assurance Systems Engineering (HASE), pp. 140-145. , IEEE; Cheng, F., Li, T., Deeph, C., Bloom filters and LSTM networks for anomaly detection in industrial control systems (2017) 47th IEEE/IFIP International Conference on Dependable Systems and Networks (DSN 2017), pp. 1-12. , IEEE Washington D.C., USA; Zohrevand, Z., Glasser, U., Shahir, H.Y., Tayebi, M.A., Costanzo, R., Hidden Markov based anomaly detection for water supply systems (2016) 2016 IEEE International Conference on Big Data (Big Data), pp. 1551-1560; Das, T.K., Adepu, S., Zhou, J., Anomaly detection in industrial control systems using logical analysis of data (2020) Comput. Secur., 96; Schmidt, T., Hauer, F., Pretschner, A., Automated anomaly detection in CPS log files—A time series clustering approach (2020) Proc. International Conference on Computer Safety, Reliability, and Security (SAFECOMP 2020), LNCS, 12234, pp. 179-194. , Springer; Luo, Y., Xiao, Y., Cheng, L., Peng, G., Yao, D.D., Deep learning-based anomaly detection in cyber-physical systems: progress and opportunities ; Goh, J., Adepu, S., Junejo, K.N., Mathur, A., A dataset to support research in the design of secure water treatment systems (2016) International Conference on Critical Information Infrastructures Security, pp. 88-99. , Springer; Adepu, S., Mathur, A., Assessing the effectiveness of attack detection at a hackfest on industrial control systems (2018) IEEE Transactions on Sustainable Computing, pp, p. 1; Chen, Y., Poskitt, C.M., Sun, J., Adepu, S., Zhang, F., Learning-guided network fuzzing for testing cyber-physical system defences (2019) Proc. IEEE/ACM International Conference on Automated Software Engineering (ASE 2019), pp. 962-973. , IEEE Computer Society; Chen, Y., Xuan, B., Poskitt, C.M., Sun, J., Zhang, F., Active fuzzing for testing and securing cyber-physical systems (2020) Proc. ACM SIGSOFT International Symposium on Software Testing and Analysis (ISSTA 2020), pp. 14-26. , ACM; Hodo, E., Bellekens, X., Hamilton, A., Dubouilh, P.-L., Iorkyase, E., Tachtatzis, C., Atkinson, R., Threat analysis of IoT networks using artificial neural network intrusion detection system (2016) 2016 International Symposium on Networks, Computers and Communications (ISNCC), pp. 1-6. , IEEE; Kosek, A.M., Contextual anomaly detection for cyber-physical security in smart grids based on an artificial neural network model (2016) 2016 Joint Workshop on Cyber- Physical Security and Resilience in Smart Grids (CPSR-SG), pp. 1-6. , IEEE Vienna, Austria; Sargolzaei, A., Crane, C.D., Abbaspour, A., Noei, S., A machine learning approach for fault detection in vehicular cyber-physical systems (2016) 2016 15th IEEE International Conference on Machine Learning and Applications (ICMLA), pp. 636-640. , IEEE Anaheim, CA, USA; Canizo, M., Triguero, I., Conde, A., Onieva, E., Multi-head CNN–RNN for multi-time series anomaly detection: an industrial case study (2019) Neurocomputing, 363, pp. 246-260; Li, Z., Li, J., Wang, Y., Wang, K., A deep learning approach for anomaly detection based on SAE and LSTM in mechanical equipment (2019) Int. J. Adv. Manuf. Technol., 103 (1-4), pp. 499-510; Kravchik, M., Shabtai, A., Detecting cyber attacks in industrial control systems using convolutional neural networks (2018) Proc. Workshop on Cyber-Physical Systems Security and PrivaCy (CPS-SPC 2018), pp. 72-83. , ACM; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world ; Carlini, N., Wagner, D., Audio Adversarial Examples: Targeted Attacks on Speech-to-Text (2018), pp. 1-7. , IEEE San Francisco, CA; Grosse, K., Papernot, N., Manoharan, P., Backes, M., McDaniel, P., Adversarial examples for malware detection (2017) European Symposium on Research in Computer Security, pp. 62-79. , Springer; Feng, C., Li, T., Zhu, Z., Chana, D., (2017), A deep learning-based framework for conducting stealthy attacks in industrial control systems, CoRR; Erba, A., Taormina, R., Galelli, S., Pogliani, M., Carminati, M., Zanero, S., Tippenhauer, N.O., Constrained concealment attacks against reconstruction-based anomaly detectors in industrial control systems (2020) Proc. Annual Computer Security Applications Conference (ACSAC 2020), pp. 480-495. , ACM; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) 2016 IEEE European Symposium on Security and Privacy (EuroS&P), pp. 372-387. , IEEE; Mathur, A.P., Tippenhauer, N.O., SWaT: a water treatment testbed for research and training on ICS security (2016) Proc. International Workshop on Cyber-physical Systems for Smart Water Networks (CySWATER 2016), pp. 31-36. , IEEE Computer Society; Ahmed, C.M., Palleti, V.R., Mathur, A.P., WADI: a water distribution testbed for research in the design of secure cyber physical systems (2017) Proc. International Workshop on Cyber-Physical Systems for Smart Water Networks (CySWATER 2017), pp. 25-28. , ACM Press Pittsburgh, Pennsylvania; Alur, R., Principles of Cyber-Physical Systems (2015), MIT Press; Giraldo, J., Urbina, D.I., Cardenas, A., Valente, J., Faisal, M.A., Ruths, J., Tippenhauer, N.O., Candell, R., A survey of physics-based attack detection in cyber-physical systems (2018) ACM Comput. Surv., 51 (4), pp. 761-76:36; Papernot, N., McDaniel, P., Swami, A., Harang, R., Crafting adversarial input sequences for recurrent neural networks (2016) MILCOM 2016-2016 IEEE Military Communications Conference, pp. 49-54. , IEEE; Nanduri, A., Sherry, L., Anomaly detection in aircraft data using recurrent neural networks (RNN) (2016) 2016 Integrated Communications Navigation and Surveillance (ICNS), , IEEE Herndon, VA, USA 5C2–1–5C2–8; Filonov, P., Kitashov, F., Lavrentyev, A., RNN-based early cyber-attack detection for the Tennessee Eastman process ; Sheikhan, M., Jadidi, Z., Farrokhi, A., Intrusion detection using reduced-size RNN based on feature grouping (2012) Neural Comput. Appl., 21 (6), pp. 1185-1190; Singh, A., (2017), Anomaly detection for temporal data using long short-term memory (LSTM); Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput., 9 (8), pp. 1735-1780; Bray, J.R., Curtis, J.T., An ordination of the upland forest communities of southern Wisconsin (1957) Ecol. Monogr., 27 (4), pp. 325-349; Gong, Y., Poellabauer, C., Crafting adversarial examples for speech paralinguistics applications ; Marra, F., Gragnaniello, D., Verdoliva, L., On the vulnerability of deep learning to adversarial attacks for camera model identification (2018) Signal Process., 65, pp. 240-248; Usama, M., Qadir, J., Al-Fuqaha, A., Adversarial attacks on cognitive self-organizing networks: the challenge and the way forward (2018) 2018 IEEE 43rd Conference on Local Computer Networks Workshops (LCN Workshops), pp. 90-97. , IEEE; Huang, S., Papernot, N., Goodfellow, I., Duan, Y., Abbeel, P., Adversarial attacks on neural network policies ; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples ; Mitra, S., Wongpiromsarn, T., Murray, R.M., Verifying cyber-physical interactions in safety-critical systems (2013) IEEE Secur. Privacy, 11 (4), pp. 28-37; Akella, R., McMillin, B.M., Model-checking BNDC properties in cyber-physical systems (2009) 2009 33rd Annual IEEE International Computer Software and Applications Conference, 1, pp. 660-663. , IEEE; Goldberg, D.E., Genetic Algorithms in Search Optimization and Machine Learning (1989); https://itrust.sutd.edu.sg/dataset/, iTrust, Dataset and models, (); Wang, J., Sun, J., Jia, Y., Qin, S., Xu, Z., Towards ‘verifying’ a water treatment system (2018) International Symposium on Formal Methods, pp. 73-92. , Springer; Raman, M.R.G., Somu, N., Mathur, A.P., Anomaly detection in critical infrastructure using probabilistic neural network (2019) International Conference on Applications and Techniques in Information Security, pp. 129-141. , Springer; Chen, Y., Poskitt, C.M., Sun, J., Towards learning and verifying invariants of cyber-physical systems by code mutation (2016) Proc. International Symposium on Formal Methods (FM 2016), LNCS, 9995, pp. 155-163. , Springer; Shalyga, D., Filonov, P., Lavrentyev, A., Anomaly detection for water treatment system based on neural network with automatic architecture optimization ; Chollet, F., (2015), https://github.com/fchollet/keras, Keras (); Jia, Y., (2020), https://github.com/jiayifan21/aa_rnn_cps, Supplementary materials (); Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Duchesnay, E., Scikit-learn: machine learning in python (2011) J. Mach. Learn. Res., 12, pp. 2825-2830; Cheng, L., Tian, K., Yao, D.D., Orpheus: enforcing cyber-physical execution semantics to defend against data-oriented attacks (2017) Proc. Annual Computer Security Applications Conference (ACSAC 2017), pp. 315-326. , ACM; Harada, Y., Yamagata, Y., Mizuno, O., Choi, E.-H., Log-based anomaly detection of CPS using a statistical method (2017) Proc. International Workshop on Empirical Software Engineering in Practice (IWESEP 2017), pp. 1-6. , IEEE; Pasqualetti, F., Dorfler, F., Bullo, F., Cyber-physical attacks in power networks: models, fundamental limitations and monitor design (2011) Proc. IEEE Conference on Decision and Control and European Control Conference (CDC-ECC 2011), pp. 2195-2201. , IEEE; Aggarwal, E., Karimibiuki, M., Pattabiraman, K., Ivanov, A., CORGIDS: a correlation-based generic intrusion detection system (2018) Proc. Workshop on Cyber-Physical Systems Security and PrivaCy (CPS-SPC 2018), pp. 24-35. , ACM; Aoudi, W., Iturbe, M., Almgren, M., Truth will out: departure-based process-level detection of stealthy attacks on control systems (2018) Proc. ACM SIGSAC Conference on Computer and Communications Security (CCS 2018), pp. 817-831. , ACM; He, Z., Raghavan, A., Hu, G., Chai, S.M., Lee, R.B., Power-grid controller anomaly detection with enhanced temporal deep learning (2019) Proc. IEEE International Conference On Trust, Security And Privacy In Computing And Communications (TrustCom 2019), pp. 160-167. , IEEE; Lin, Q., Adepu, S., Verwer, S., Mathur, A., TABOR: a graphical model-based approach for anomaly detection in industrial control systems (2018) Proc. Asia Conference on Computer and Communications Security (AsiaCCS 2018), pp. 525-536. , ACM; Narayanan, V., Bobba, R.B., Learning based anomaly detection for industrial arm applications (2018) Proc. Workshop on Cyber-Physical Systems Security and PrivaCy (CPS-SPC 2018), pp. 13-23. , ACM; Schneider, P., Böttinger, K., High-performance unsupervised anomaly detection for cyber-physical system networks (2018) Proc. Workshop on Cyber-Physical Systems Security and PrivaCy (CPS-SPC 2018), pp. 1-12. , ACM; Choi, H., Lee, W.-C., Aafer, Y., Fei, F., Tu, Z., Zhang, X., Xu, D., Xinyan, X., Detecting attacks against robotic vehicles: acontrol invariant approach (2018) Proc. ACM SIGSAC Conference on Computer and Communications Security (CCS 2018), pp. 801-816. , ACM; Quinonez, R., Giraldo, J., Salazar, L.E., Bauman, E., Cárdenas, A.A., Lin, Z., SAVIOR: securing autonomous vehicles with robust physical invariants (2020) Proc. USENIX Security Symposium (USENIX 2020), pp. 895-912. , USENIX Association; Kosek, A.M., Contextual anomaly detection for cyber-physical security in smart grids based on an artificial neural network model (2016) 2016 Joint Workshop on Cyber-Physical Security and Resilience in Smart Grids (CPSR-SG), pp. 1-6. , IEEE; Filonov, P., Lavrentyev, A., Vorontsov, A., Multivariate Industrial Time Series with Cyber-Attack Simulation: Fault Detection Using an LSTM-based Predictive Data Model ; Eiteneuer, B., Niggemann, O., LSTM for model-based anomaly detection in cyber-physical systems (2018) DX@ Safeprocess; Lv, C., Xing, Y., Zhang, J., Na, X., Li, Y., Liu, T., Cao, D., Wang, F.-Y., Levenberg–marquardt backpropagation training of multilayer neural networks for state estimation of a safety-critical cyber-physical system (2017) IEEE Trans. Ind. Inform., 14 (8), pp. 3436-3446; Sargolzaei, A., Crane, C.D., Abbaspour, A., Noei, S., A machine learning approach for fault detection in vehicular cyber-physical systems (2016) 2016 15th IEEE International Conference on Machine Learning and Applications (ICMLA), pp. 636-640. , IEEE; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I.P., Tygar, J.D., Adversarial machine learning (2011) Proc. ACM Workshop on Security and Artificial Intelligence (AISec 2011), pp. 43-58. , ACM; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: a simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2574-2582; Goodman, D., Xin, H., Yang, W., Yuesheng, W., Junfeng, X., Huan, Z., Advbox: a toolbox to generate adversarial examples that fool neural networks ; Carlini, N., Mishra, P., Vaidya, T., Zhang, Y., Sherr, M., Shields, C., Wagner, D., Zhou, W., Hidden voice commands (2016) 25th USENIX Security Symposium (USENIX Security 16), pp. 513-530; Smith, D.F., Wiliem, A., Lovell, B.C., Face recognition on consumer devices: reflections on replay attacks (2015) IEEE Trans. Inf. Forensics Secur., 10 (4), pp. 736-745; Erba, A., Tippenhauer, N.O., (2020), No need to know physics: resilience of process-based model-free anomaly detection for industrial control systems, CoRR; Zizzo, G., Hankin, C., Maffeis, S., Jones, K., (2019), Intrusion detection for industrial control systems: Evaluation analysis and adversarial attacks, CoRR; Kravchik, M., Biggio, B., Shabtai, A., Poisoning attacks on cyber attack detectors for industrial control systems (2021) Proc. ACM/SIGAPP Symposium on Applied Computing (SAC 2021), pp. 116-125. , ACM","Jia, Y.; Singapore University of Technology and DesignSingapore; 电子邮件: yifan_jia@mymail.sutd.edu.sg",,,Elsevier B.V.,,,,,18745482,,,,English,Int. J. Crit. Infrastruct. Prot.,Article,Final,"All Open Access, Green",Scopus,2-s2.0-85107972529
"Jia Y., Zhang J., Shan S., Chen X.",57219695485;56336414000;22235341500;57215374943;,Unified unsupervised and semi-supervised domain adaptation network for cross-scenario face anti-spoofing,2021,Pattern Recognition,115,,107888,,,,3,10.1016/j.patcog.2021.107888,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101164295&doi=10.1016%2fj.patcog.2021.107888&partnerID=40&md5=693a29078edb8067606b0ad5f4335aa4,"Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing  100190, China; University of Chinese Academy of Sciences, Beijing, 100049, China; CAS Center for Excellence in Brain Science and Intelligence Technology, Shanghai, 200031, China","Jia, Y., Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing  100190, China, University of Chinese Academy of Sciences, Beijing, 100049, China; Zhang, J., Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing  100190, China, University of Chinese Academy of Sciences, Beijing, 100049, China; Shan, S., Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing  100190, China, University of Chinese Academy of Sciences, Beijing, 100049, China, CAS Center for Excellence in Brain Science and Intelligence Technology, Shanghai, 200031, China; Chen, X., Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing  100190, China, University of Chinese Academy of Sciences, Beijing, 100049, China","Due to the environmental differences, many face anti-spoofing methods fail to generalize to unseen scenarios. In light of this, we propose a unified unsupervised and semi-supervised domain adaptation network (USDAN) for cross-scenario face anti-spoofing, aiming at minimizing the distribution discrepancy between the source and the target domains. Specifically, two modules, i.e., marginal distribution alignment module (MDA) and conditional distribution alignment module (CDA), are designed to seek a domain-invariant feature space via adversarial learning and make the features of the same class compact, respectively. By adding/removing the CDA module, the network can be easily switched for semi-supervised/unsupervised setting, in which sense our method is named with “unified”. Moreover, the adaptive cross-entropy loss and normalization techniques are further incorporated to improve the generalization. Extensive experimental results show that the proposed USDAN outperforms state-of-the-art methods on several public datasets. © 2021 Elsevier Ltd",Deep learning; Domain adaptation; Face anti-spoofing; Face presentation attack detection,Pattern recognition; Software engineering; Adversarial learning; Conditional distribution; Domain adaptation; Environmental difference; Invariant features; Marginal distribution; Semi-supervised; State-of-the-art methods; Alignment,,,,,"Deng, J., Guo, J., Xue, N., Zafeiriou, S., ArcFace: additive angular margin loss for deep face recognition (2019) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4690-4699. , IEEE; Li, Y., Wang, G., Nie, L., Wang, Q., Tan, W., Distance metric optimization driven convolutional neural network for age invariant face recognition (2018) Pattern Recognit., pp. 51-62; Määttä, J., Hadid, A., Pietikäinen, M., Face spoofing detection from single images using micro-texture analysis (2011) IEEE International Joint Conference on Biometrics (IJCB), pp. 1-7. , IEEE; de Freitas Pereira, T., Anjos, A., De Martino, J.M., Marcel, S., LBP-TOP based countermeasure against face spoofing attacks (2012) Asian Conference on Computer Vision (ACCV), pp. 121-132. , Springer; Gragnaniello, D., Poggi, G., Sansone, C., Verdoliva, L., An investigation of local descriptors for biometric spoofing detection (2015) IEEE Trans. Inf. Forensics Secur.(TIFS), pp. 849-863; Boulkenafet, Z., Komulainen, J., Hadid, A., Face antispoofing using speeded-up robust features and fisher vector encoding (2016) IEEE Signal Process. Lett. (SPL), pp. 141-145; Patel, K., Han, H., Jain, A.K., Secure face unlock: spoof detection on smartphones (2016) IEEE Trans. Inf. Forensics Secur.(TIFS), pp. 2268-2283; Atoum, Y., Liu, Y., Jourabloo, A., Liu, X., Face anti-spoofing using patch and depth-based CNNs (2017) IEEE International Joint Conference on Biometrics (IJCB), pp. 319-328. , IEEE; Liu, Y., Jourabloo, A., Liu, X., Learning deep models for face anti-spoofing: binary or auxiliary supervision (2018) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 389-398. , IEEE; Yang, J., Lei, Z., Li, S.Z., (2014), Learn convolutional neural network for face anti-spoofing, arXiv:; Torralba, A., Efros, A.A., Unbiased look at dataset bias. (2011) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), p. 7. , IEEE; Maaten, L.V.D., Hinton, G., Visualizing data using t-SNE (2008) J. Mach. Learn. Res. (JLMR), pp. 2579-2605; Wen, D., Han, H., Jain, A.K., Face spoof detection with image distortion analysis (2015) IEEE Trans. Inf. Forensics Secur.(TIFS), pp. 746-761; Zhang, Z., Yan, J., Liu, S., Lei, Z., Dong, Y., Li, S.Z., A face antispoofing database with diverse attacks (2012) IAPR International Conference on Biometrics (ICB), pp. 26-31. , IEEE; Yang, J., Lei, Z., Yi, D., Li, S.Z., Person-specific face antispoofing with subject domain adaptation (2015) IEEE Trans. Inf. Forensics Secur.(TIFS), pp. 797-809; Li, H., Li, W., Cao, H., Wang, S., Huang, F., Kot, A.C., Unsupervised domain adaptation for face anti-spoofing (2018) IEEE Trans. Inf. Forensics Secur.(TIFS), pp. 1794-1809; Wang, G., Han, H., Shan, S., Chen, X., Improving cross-database face presentation attack detection via adversarial domain adaptation (2019) IAPR International Conference on Biometrics (ICB), pp. 1-8. , IEEE; Tan, X., Li, Y., Liu, J., Jiang, L., Face liveness detection from a single image with sparse low rank bilinear discriminative model (2010) European Conference on Computer Vision (ECCV), pp. 504-517. , Springer; Pan, G., Sun, L., Wu, Z., Lao, S., Eyeblink-based anti-spoofing in face recognition from a generic webcamera (2007) IEEE International Conference on Computer Vision (ICCV), pp. 1-8. , IEEE; Kollreider, K., Fronthaler, H., Faraj, M.I., Bigun, J., Real-time face detection and motion analysis with application in ǣlivenessǥ assessment (2007) IEEE Trans. Inf. Forensics Secur.(TIFS), pp. 548-558; Anjos, A., Chakka, M.M., Marcel, S., Motion-based counter-measures to photo attacks in face recognition (2013) IET Biom., pp. 147-158; Bharadwaj, S., Dhamecha, T.I., Vatsa, M., Singh, R., Computationally efficient face spoofing detection with motion magnification (2013) IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), pp. 105-110. , IEEE; Siddiqui, T.A., Bharadwaj, S., Dhamecha, T.I., Agarwal, A., Vatsa, M., Singh, R., Ratha, N., Face anti-spoofing with multifeature videolet aggregation (2016) International Conference on Pattern Recognition (ICPR), pp. 1035-1040. , IEEE; Galbally, J., Marcel, S., Fierrez, J., Image quality assessment for fake biometric detection: application to iris, fingerprint, and face recognition (2013) IEEE Trans. Image Process. (TIP), pp. 710-724; Peng, J., Chan, P.P., Face liveness detection for combating the spoofing attack in face recognition (2014) International Conference on Wavelet Analysis and Pattern Recognition (ICWAPR), pp. 176-181. , IEEE; Patel, K., Han, H., Jain, A.K., Cross-database face antispoofing with robust feature representation (2016) Chinese Conference on Biometric Recognition (CCBR), pp. 611-619. , Springer; Jourabloo, A., Liu, Y., Liu, X., Face de-spoofing: anti-spoofing via noise modeling (2018) European Conference on Computer Vision (ECCV), pp. 290-306. , Springer; Song, X., Zhao, X., Fang, L., Lin, T., Discriminative representation combinations for accurate face spoofing detection (2019) Pattern Recognit., pp. 220-231; Ma, Y., Wu, L., Li, Z., A novel face presentation attack detection scheme based on multi-regional convolutional neural networks (2020) Pattern Recognit. Lett., pp. 261-267; Fatemifar, S., Arashloo, S.R., Awais, M., Kittler, J., Client-specific anomaly detection for face presentation attack detection (2020) Pattern Recognit., p. 107696; Qin, Y., Zhang, W., Shi, J., Wang, Z., Yan, L., One-class adaptation face anti-spoofing with loss function search (2020) Neurocomputing, pp. 384-395; Liu, Y., Stehouwer, J., Jourabloo, A., Liu, X., Deep tree learning for zero-shot face anti-spoofing (2019) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4680-4689. , IEEE; Qin, Y., Zhao, C., Zhu, X., Wang, Z., Yu, Z., Fu, T., Zhou, F., Lei, Z., Learning meta model for zero-and few-shot face anti-spoofing (2020) AAAI Conference on Artificial Intelligence, pp. 11916-11923; Xu, Z., Li, S., Deng, W., Learning temporal features using LSTM-CNN architecture for face anti-spoofing (2015) IAPR Asian Conference on Pattern Recognition (ACPR), pp. 141-145. , IEEE; Liu, S., Yuen, P.C., Zhang, S., Zhao, G., 3D mask face anti-spoofing with remote photoplethysmography (2016) European Conference on Computer Vision (ECCV), pp. 85-100. , Springer; Liu, S.-Q., Lan, X., Yuen, P.C., Remote photoplethysmography correspondence feature for 3D mask face presentation attack detection (2018) European Conference on Computer Vision (ECCV), pp. 558-573. , Springer; Shao, R., Lan, X., Yuen, P.C., Deep convolutional dynamic texture learning with adaptive channel-discriminability for 3D mask face anti-spoofing (2017) IEEE International Joint Conference on Biometrics (IJCB), pp. 748-755. , IEEE; Jia, S., Guo, G., Xu, Z., A survey on 3D mask presentation attack detection and countermeasures (2020) Pattern Recognit., p. 107032; Yang, X., Luo, W., Bao, L., Gao, Y., Gong, D., Zheng, S., Li, Z., Liu, W., Face anti-spoofing: model matters, so does data (2019) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 3507-3516. , IEEE; Ganin, Y., Lempitsky, V., (2014), Unsupervised domain adaptation by backpropagation, arXiv:; Tzeng, E., Hoffman, J., Saenko, K., Darrell, T., Adversarial discriminative domain adaptation (2017) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 7167-7176. , IEEE; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Neural Information Processing Systems (NIPS), pp. 2672-2680; Wang, F., Cheng, J., Liu, W., Liu, H., Additive margin softmax for face verification (2018) IEEE Signal Process. Lett. (SPL), pp. 926-930; Pan, S.J., Yang, Q., A survey on transfer learning (2009) IEEE Trans. Knowl. Data Eng. (TKDE), pp. 1345-1359; Lin, T.-Y., Goyal, P., Girshick, R., He, K., Dollár, P., Focal loss for dense object detection (2017) IEEE International Conference on Computer Vision (ICCV), pp. 2980-2988. , IEEE; Grandvalet, Y., Bengio, Y., Semi-supervised learning by entropy minimization (2005) Neural Information Processing Systems (NIPS), pp. 529-536; Xia, Z., Feng, X., Peng, J., Wu, J., Fan, J., A regularized optimization framework for tag completion and image retrieval (2015) Neurocomputing, pp. 500-508; Wen, Y., Zhang, K., Li, Z., Qiao, Y., A discriminative feature learning approach for deep face recognition (2016) European Conference on Computer Vision (ECCV), pp. 499-515. , Springer; Chingovska, I., Anjos, A., Marcel, S., On the effectiveness of local binary patterns in face anti-spoofing (2012) International Conference of Biometrics Special Interest Group (BIOSIG), pp. 1-7. , IEEE; Zhang, S., Wang, X., Liu, A., Zhao, C., Wan, J., Escalera, S., Shi, H., Li, S.Z., A dataset and benchmark for large-scale multi-modal face anti-spoofing (2019) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 919-928. , IEEE; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 770-778. , IEEE; Zhang, K., Zhang, Z., Li, Z., Qiao, Y., Joint face detection and alignment using multitask cascaded convolutional networks (2016) IEEE Signal Process. Lett. (SPL), pp. 1499-1503","Shan, S.; Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS), China; 电子邮件: sgshan@ict.ac.cn",,,Elsevier Ltd,,,,,313203,,PTNRA,,English,Pattern Recogn.,Article,Final,,Scopus,2-s2.0-85101164295
"Yin H., Zhang H., Li Z., Liu Z.",57225668982;36601759800;57225183738;57225172367;,Improving the Transferability of Adversarial Examples with Image Affine Transformation,2021,Journal of Physics: Conference Series,1955,1,12052,,,,,10.1088/1742-6596/1955/1/012052,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109409132&doi=10.1088%2f1742-6596%2f1955%2f1%2f012052&partnerID=40&md5=efa2cdccfe43a172347a2469b9f62942,"PLA SSF Information Engineering University, Zhengzhou, 450001, China","Yin, H., PLA SSF Information Engineering University, Zhengzhou, 450001, China; Zhang, H., PLA SSF Information Engineering University, Zhengzhou, 450001, China; Li, Z., PLA SSF Information Engineering University, Zhengzhou, 450001, China; Liu, Z., PLA SSF Information Engineering University, Zhengzhou, 450001, China","Deep learning is widely regarded as a black-box technology. We all know its performance is very good, but we have limited understanding of why it is so good. At present, there are many researches on the interpretability of deep neural network. By studying adversarial example, we can understand the internal semantics of neural network and find the decision boundary with problems, which in turn helps to improve the robustness and performance of neural network and its interpretability. With the development of adversarial example research, more and more adversarial example generation methods are proposed. Although the attack from adversarial example poses a great security threat to the deep learning system, it can also be used as an effective tool to measure the robustness and reliability of the model, and the attack and defense are two mutually promoting processes. Therefore, how to generate adversarial example with stronger attack ability is worth further study. And this study proposes a method named Affine-Invariant Method, aimed to improve the transferability of adversarial examples in black-box environment. © Published under licence by IOP Publishing Ltd.",,Big data; Deep learning; Deep neural networks; Image enhancement; Learning systems; Semantics; Affine invariant; Affine transformations; Black-box technology; Decision boundary; Effective tool; Generation method; Interpretability; Security threats; Neural networks,,,,,"Russell, S J, Norvig, P., (2003) Artificial Intelligence: A Modern Approach[M]; Krizhevsky, A, Sutskever, I, Hinton, G E, Imagenet classification with deep convolutional neural networks (2012) Advances in neural information processing systems, 25, pp. 1097-1105. , [J]; Szegedy, C, Liu, W, Jia, Y, Going deeper with convolutions (2015) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 1-9. , [C]; Senior, A, Vanhoucke, V, Nguyen, P, Deep neural networks for acoustic modeling in speech recognition (2012) IEEE Signal processing magazine, , [J]; Simonyan, K, Zisserman, A, Very deep convolutional networks for large-scale image recognition (2014), [J] arXiv preprint arXiv:1409.1556; He, K, Zhang, X, Ren, S, Deep residual learning for image recognition (2016) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770-778. , [C]; Bojarski, M, Del Testa, D, Dworakowski, D, End to end learning for self-driving cars (2016), [J] arXiv preprint arXiv:1604.07316; Szegedy, C, Zaremba, W, Sutskever, I, Intriguing properties of neural networks (2013), [J] arXiv preprint arXiv:1312.6199; Wierstra, D, Schaul, T, Glasmachers, T, Natural evolution strategies (2014) The Journal of Machine Learning Research, 15, pp. 949-980. , [J]; Alzantot, M, Sharma, Y, Chakraborty, S, Genattack: Practical black-box attacks with gradientfree optimization (2019) Proceedings of the Genetic and Evolutionary Computation Conference, p. 11111119. , [C]; Brendel, W, Rauber, J, Bethge, M, Decision-based adversarial attacks: Reliable attacks against blackbox machine learning models (2017), [J] arXiv preprint arXiv:1712.04248; Papernot, N, McDaniel, P, Goodfellow, I, Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia conference on computer and communications security, pp. 506-519. , [C]; Dong, Y, Liao, F, Pang, T, Boosting adversarial attacks with momentum (2018) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 9185-9193. , [C]; Xie, C, Zhang, Z, Zhou, Y, Improving transferability of adversarial examples with input diversity (2019) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 2730-2739. , [C]; Madry, A, Makelov, A, Schmidt, L, Towards deep learning models resistant to adversarial attacks (2017), [J] arXiv preprint arXiv:1706.06083; Buckman, J, Roy, A, Raffel, C, Thermometer encoding: One hot way to resist adversarial examples (2018) International Conference on Learning Representations, , [C]; Guo, C, Rana, M, Cisse, M, Countering adversarial images using input transformations (2017), [J] arXiv preprint arXiv:1711.00117; Samangouei, P, Kabkab, M, Chellappa, R, Defense-gan: Protecting classifiers against adversarial attacks using generative models (2018), [J] arXiv preprint arXiv:1805.06605; Tramèr, F, Kurakin, A, Papernot, N, Ensemble adversarial training: Attacks and defenses (2017), [J] arXiv preprint arXiv:1705.07204; Jin, J, Dundar, A, Culurciello, E, Robust convolutional neural networks under adversarial noise (2015), [J] arXiv preprint arXiv:1511.06306; Lee, H, Han, S, Lee, J, (2017) Generative adversarial trainer: Defense to adversarial perturbations with gan[J], , arXiv preprint arXiv:1705.03387","Zhang, H.; PLA SSF Information Engineering UniversityChina; 电子邮件: zhw11qd@aliyun.com",,,IOP Publishing Ltd,"2021 4th International Symposium on Big Data and Applied Statistics, ISBDAS 2021",21 May 2021 through 23 May 2021,,169951,17426588,,,,English,J. Phys. Conf. Ser.,Conference Paper,Final,"All Open Access, Bronze",Scopus,2-s2.0-85109409132
"Zhang X., Wang J., Wang T., Jiang R., Xu J., Zhao L.",35232030000;57212656375;57281933900;57208102805;55801927200;57204286578;,Robust feature learning for adversarial defense via hierarchical feature alignment,2021,Information Sciences,560,,,256,270,,25,10.1016/j.ins.2020.12.042,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101180191&doi=10.1016%2fj.ins.2020.12.042&partnerID=40&md5=e03cce8be54d7975e57b4172d6fd8e70,"College of Computer Science and Artificial Intelligence, Wenzhou University, Wenzhou, 325035, China","Zhang, X., College of Computer Science and Artificial Intelligence, Wenzhou University, Wenzhou, 325035, China; Wang, J., College of Computer Science and Artificial Intelligence, Wenzhou University, Wenzhou, 325035, China; Wang, T., College of Computer Science and Artificial Intelligence, Wenzhou University, Wenzhou, 325035, China; Jiang, R., College of Computer Science and Artificial Intelligence, Wenzhou University, Wenzhou, 325035, China; Xu, J., College of Computer Science and Artificial Intelligence, Wenzhou University, Wenzhou, 325035, China; Zhao, L., College of Computer Science and Artificial Intelligence, Wenzhou University, Wenzhou, 325035, China","Deep neural networks have demonstrated excellent performance in most computer vision tasks in recent years. However, they are vulnerable to adversarial perturbations generated by adversarial attacks. These human-imperceptible perturbations often lead to severe distortion in the high-dimensional intermediate feature space, which is one of the major reasons for the vulnerabilities in deep neural networks. Therefore, input images with perturbations can completely change the predictions of the networks in the decision space. To overcome this drawback, we propose to progressively align the intermediate feature representations extracted from the adversarial domain with feature representations extracted from a clean domain through domain adaptation. The difference between two feature distributions can be accurately measured via an optimal transport-based Wasserstein distance. Thus, the deep networks are forced to learn robust and domain-invariant feature representations, so that the gap between the different domains is minimized and that the networks are no longer easily fooled by diverse adversaries. Extensive evaluations are conducted on four classification benchmark datasets in white-box attack scenarios. The evaluation results demonstrate a significant performance improvement over several state-of-the-art defense methods. © 2020 Elsevier Inc.",Adversarial defense; Domain adaptation; Feature alignment; Optimal transport,Classification (of information); Deep learning; Deep neural networks; Network security; Benchmark datasets; Domain adaptation; Evaluation results; Feature distribution; Feature representation; Hierarchical features; Invariant features; Wasserstein distance; Neural networks,,,,,"Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy, pp. 39-57. , IEEE; Chen, S., He, Z., Sun, C., Yang, J., Huang, X., Universal adversarial attack on attention and the resulting dataset damagenet (2020) IEEE Transactions on Pattern Analysis and Machine, , Intelligence; Chen, Y., Rohrbach, M., Yan, Z., Shuicheng, Y., Feng, J., Kalantidis, Y., Graph-based global reasoning networks (2019) Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, pp. 433-442; Coates, A., Ng, A., Lee, H., An analysis of single-layer networks in unsupervised feature learning (2011) Proceedings of Conference on Artificial Intelligence and Statistics, pp. 215-223; Courty, N., Flamary, R., Tuia, D., Rakotomamonjy, A., Optimal transport for domain adaptation (2017) IEEE Transactions on Pattern Analysis and Machine Intelligence, 39, pp. 1853-1865; Cuturi, M., Sinkhorn distances: Lightspeed computation of optimal transport (2013) Advances in Neural Information Processing Systems, pp. 2292-2300; Dabouei, A., Soleymani, S., Taherkhani, F., Dawson, J., Nasrabadi, N.M., Exploiting joint robustness to adversarial perturbations (2020) Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, pp. 1122-1131; Das, N., Shanbhogue, M., Chen, S.T., Hohman, F., Chen, L., Kounavis, M.E., Chau, D.H., (2017), Keeping the bad guys out: Protecting and vaccinating deep learning with jpeg compression arXiv preprint arXiv:1705.02900; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2018) Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, pp. 9185-9193; Dziugaite, G.K., Ghahramani, Z., Roy, D.M., (2016), A study of the effect of jpg compression on adversarial images arXiv preprint arXiv:1608.00853; Goodfellow, I., (2016), Nips 2016 tutorial: Generative adversarial networks arXiv preprint arXiv:1701.00160; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014), Explaining and harnessing adversarial examples arXiv preprint arXiv:1412.6572; Guo, C., Rana, M., Cisse, M., van der Maaten, L., Countering adversarial images using input transformations (2018) Proceedings of International Conference on Learning Representations; Guo, F., Zhao, Q., Li, X., Kuang, X., Zhang, J., Han, Y., Tan, Y.A., Detecting adversarial examples via prediction difference for deep neural networks (2019) Information Sciences, 501, pp. 182-192; Huang, Z., Wang, J., Fu, X., Yu, T., Guo, Y., Wang, R., Dc-spp-yolo: Dense connection and spatial pyramid pooling based yolo for object detection (2020) Information Sciences; Jeddi, A., Shafiee, M.J., Karg, M., Scharfenberger, C., Wong, A., Learn2perturb: an end-to-end feature perturbation learning to improve adversarial robustness (2020) Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, pp. 1241-1250; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Kurakin, A., Goodfellow, I., Bengio, S., (2016), Adversarial examples in the physical world arXiv preprint arXiv:1607.02533; Luo, Y., Boix, X., Roig, G., Poggio, T., Zhao, Q., (2015), Foveation-based mechanisms alleviate adversarial examples arXiv preprint arXiv:1511.06292; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017), Towards deep learning models resistant to adversarial attacks arXiv preprint arXiv:1706.06083; Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P., Deepfool: a simple and accurate method to fool deep neural networks (2016) Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Mustafa, A., Khan, S.H., Hayat, M., Goecke, R., Shen, J., Shao, L., Deeply supervised discriminative learning for adversarial defense (2020) IEEE Transactions on Pattern Analysis and Machine Intelligence; Mustafa, A., Khan, S.H., Hayat, M., Shen, J., Shao, L., Image super-resolution as a defense against adversarial attacks (2019) IEEE Transactions on Image Processing, 29, pp. 1711-1724; Peyré, G., Cuturi, M., (2018), Computational optimal transport arXiv preprint arXiv:1803.00567; Ren, S., He, K., Girshick, R., Sun, J., Faster r-cnn: Towards real-time object detection with region proposal networks (2015) Advances in Neural Information Processing Systems, pp. 91-99; Samangouei, P., Kabkab, M., Chellappa, R., (2018), Defense-gan: Protecting classifiers against adversarial attacks using generative models arXiv preprint arXiv:1805.06605; Shi, Y., Han, Y., Tian, Q., Polishing decision-based adversarial noise with a customized sampling (2020) Proceedings of IEEE Conference on Computer Vision and Pattern Recognition; Shi, Y., Han, Y., Zhang, Q., Kuang, X., Adaptive iterative attack towards explainable adversarial robustness (2020) Pattern Recognition, , 107309; Shi, Y., Wang, S., Han, Y., Curls & whey: Boosting black-box adversarial attacks (2019) Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, pp. 6519-6527; Song, C., He, K., Wang, L., Hopcroft, J.E., (2018), Improving the generalization of adversarial training with domain adaptation arXiv preprint arXiv:1810.00740; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2013), arXiv preprint arXiv:1312.6199; Tolstikhin, I., Bousquet, O., Gelly, S., Schoelkopf, B., (2017), Wasserstein auto-encoders arXiv preprint arXiv:1711.01558; Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., Ensemble adversarial training: attacks and defenses (2017), arXiv preprint arXiv:1705.07204; Villani, C., (2008) Optimal Transport: Old and New, 338. , Springer Science & Business Media; Xiao, Y., Pun, C.M., Liu, B., Adversarial example generation with adaptive gradient search for single and ensemble deep neural network (2020) Information Sciences; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., (2017), Mitigating adversarial effects through randomization arXiv preprint arXiv:1711.01991; Xu, J., Liu, H., Wu, D., Zhou, F., Gao, C.Z., Jiang, L., Generating universal adversarial perturbation with resnet (2020) Information Sciences; Zhang, X., Jiang, R., Wang, T., Huang, P., Zhao, L., Attention-based interpolation network for video deblurring (2020) Neurocomputing; Zhang, X., Wang, D., Zhou, Z., Ma, Y., Robust low-rank tensor recovery with rectification and alignment (2019) IEEE Transactions on Pattern Analysis and Machine Intelligence; Zhang, X., Wang, T., Wang, J., Tang, G., Zhao, L., Pyramid channel-based feature attention network for image dehazing (2020) Computer Vision and Image Understanding, , 103003; Zhu, X., Li, Z., Li, X., Li, S., Dai, F., Attention-aware perceptual enhancement nets for low-resolution image classification (2020) Information Sciences, 515, pp. 233-247","Zhao, L.; College of Computer Science and Artificial Intelligence, China; 电子邮件: lizhao@wzu.edu.cn",,,Elsevier Inc.,,,,,200255,,ISIJB,,English,Inf Sci,Article,Final,,Scopus,2-s2.0-85101180191
"Xuan Y., Naghnaeian M.",57218567364;36183905100;,Detection and Identification of CPS Attacks with Application in Vehicle Platooning: A Generalized Luenberger Approach,2021,Proceedings of the American Control Conference,2021-May,,9483074,4013,4020,,,10.23919/ACC50511.2021.9483074,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111924668&doi=10.23919%2fACC50511.2021.9483074&partnerID=40&md5=172ba9bb04b010f277419e6173a04d98,"Clemson University, Department of Mechanical Engineering, Clemson, SC  29634, United States","Xuan, Y., Clemson University, Department of Mechanical Engineering, Clemson, SC  29634, United States; Naghnaeian, M., Clemson University, Department of Mechanical Engineering, Clemson, SC  29634, United States","This paper considers the security of distributed Cyber-Physical Systems (CPS) under malicious attacks, where the CPS components interact over a communication network. We consider the deception attacks both at the individual component level as well as the network level. At the individual level, false-data-injection corrupts sensor measurements and/or actuator signals. While at the network level, the communication between CPS components may be altered by adversarial false-data. We develop a robust model-based detection and identification algorithm for a class of discrete Linear Time Invariant (LTI) systems with delays via a Luenberger-like observer termed Generalized Luenberger Observer (GLO). The optimal GLO provides a tight bound for the residue between the monitor signals and their estimation so that it could distinguish the attack signals from intrinsic bounded noises and modeling uncertainties. Furthermore, a structurally constrained optimal GLO could also identify the place where such CPS attacks take place. Finally, we apply it to an application of the longitudinal platoon with four vehicles. © 2021 American Automatic Control Council.",,Embedded systems; Network security; Cyber-physical systems (CPS); Detection and identifications; False data injection; Individual components; Linear time-invariant system; Luenberger observers; Model uncertainties; Sensor measurements; Uncertainty analysis,,,,,"Amin, S., Cárdenas, A.A., Shankar Sastry, S., Safe and secure networked control systems under denial-of-service attacks (2009) International Workshop on Hybrid Systems: Computation and Control, pp. 31-45. , Springer; Cardenas, A.A., Amin, S., Sastry, S., Secure control: Towards survivable cyberphysical systems (2008) 2008 the 28th International Conference on Distributed Computing Systems Workshops, pp. 495-500; Dahleh, M.A., Diaz-Bobillo, I.J., (1994) Control of Uncertain Systems: a Linear Programming Approach, , Prentice-Hall, Inc; Elia, N., Dahleh, M.A., (1998) Computational Methods for Controller Design, 238. , Springer; Gupta, A., Langbort, C., Basar, T., Optimal control in the presence of an intelligent jammer with limited actions (2010) 49th Ieee Conference on Decision and Control (CDC). Ieee, pp. 1096-1101; Huang, S., Cyber-physical system security for networked industrial processes (2015) International Journal of Automation and Computing, 12 (6), pp. 567-578; Jia, D., A survey on platoon-based vehicular cyber-physical systems (2015) Ieee Communications Surveys & Tutorials, 18 (1), pp. 263-284; Kwon, C., Liu, W., Hwang, I., Security analysis for cyber-physical systems against stealthy deception attacks (2013) 2013 American Control Conference, pp. 3344-3349; Li, Y., Jamming attacks on remote state estimation in cyber-physical systems: A game-theoretic approach (2015) Ieee Transactions on Automatic Control, 60 (10), pp. 2831-2836; Naghnaeian, M., (2019) Optimal State Estimation Synthesis over Unreliable Network in Presence of Denial-of-Service Attack: An Operator Framework Approach; Naghnaeian, M., Hirzallah, N.H., Voulgaris, P.G., Security via multirate control in cyber-physical systems (2019) Systems & Control Letters, 124, pp. 12-18; Naghnaeian, M., Voulgaris, P.G., Dullerud, G.E., L-p analysis and synthesis of linear switched systems: A unified input-output and state-space approach (2018) Siam Journal on Control and Optimization, 56 (2), pp. 1181-1205; Naghnaeian, M., Xuan, Y., Optimal state estimation under the denial-of-service attack: An operator approach (2020) 2020 American Control Conference (ACC), pp. 5334-5339; Pasqualetti, F., Dörfler, F., Bullo, F., Attack detection and identification in cyberphysical systems (2013) Ieee Transactions on Automatic Control, 58 (11), pp. 2715-2729; Ploeg, J., Design and experimental evaluation of cooperative adaptive cruise control (2011) 2011 14th International Ieee Conference on Intelligent Transportation Systems (ITSC). Ieee, pp. 260-265; Rajkumar, R., Cyber-physical systems: The next computing revolution (2010) Design Automation Conference, pp. 731-736; Sheikholeslam, S., Desoer, C.A., Longitudinal control of a platoon of vehicles with no communication of lead vehicle information: A system level study (1993) Ieee Transactions on Vehicular Technology, 42 (4), pp. 546-554; Sridhar, S., Hahn, A., Govindarasu, M., Cyber-physical system security for the electric power grid (2011) Proceedings of the Ieee, 100 (1), pp. 210-224; Sun, C., Cyber-physical systems for realtime management in the urban water cycle (2018) 2018 International Workshop on Cyber-physical Systems for Smart Water Networks (CySWater), pp. 5-8",,,et al.;Halliburton;MathWorks;Mitsubishi Electric Research Laboratory (MERL);US National Member Organization (NMO) of the International Federation of Automatic Control (IFAC);Wiley,Institute of Electrical and Electronics Engineers Inc.,"2021 American Control Conference, ACC 2021",25 May 2021 through 28 May 2021,,170611,7431619,9.78E+12,PRACE,,English,Proc Am Control Conf,Conference Paper,Final,,Scopus,2-s2.0-85111924668
"Kantaros Y., Carpenter T., Sridhar K., Yang Y., Lee I., Weimer J.",55308274900;57215189188;57222904233;57222900433;56876051600;23394173400;,Real-time detectors for digital and physical adversarial inputs to perception systems,2021,ICCPS 2021 - Proceedings of the 2021 ACM/IEEE 12th International Conference on Cyber-Physical Systems (with CPS-IoT Week 2021),,,3450535,67,76,,,10.1145/3450267.3450535,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104201187&doi=10.1145%2f3450267.3450535&partnerID=40&md5=d50e66bd8fe4910f8d5a652c759df9ac,"University of Pennsylvania, United States","Kantaros, Y., University of Pennsylvania, United States; Carpenter, T., University of Pennsylvania, United States; Sridhar, K., University of Pennsylvania, United States; Yang, Y., University of Pennsylvania, United States; Lee, I., University of Pennsylvania, United States; Weimer, J., University of Pennsylvania, United States","Deep neural network (DNN) models have proven to be vulnerable to adversarial digital and physical attacks. In this paper, we propose a novel attack- and dataset-agnostic and real-time detector for both types of adversarial inputs to DNN-based perception systems. In particular, the proposed detector relies on the observation that adversarial images are sensitive to certain label-invariant transformations. Specifically, to determine if an image has been adversarially manipulated, the proposed detector checks if the output of the target classifier on a given input image changes significantly after feeding it a transformed version of the image under investigation. Moreover, we show that the proposed detector is computationally-light both at runtime and design-time which makes it suitable for real-time applications that may also involve large-scale image domains. To highlight this, we demonstrate the efficiency of the proposed detector on ImageNet, a task that is computationally challenging for the majority of relevant defenses, and on physically attacked traffic signs that may be encountered in real-time autonomy applications. Finally, we propose the first adversarial dataset, called AdvNet that includes both clean and physical traffic sign images. Our extensive comparative experiments on the MNIST, CIFAR10, ImageNet, and AdvNet datasets show that VisionGuard outperforms existing defenses in terms of scalability and detection performance. We have also evaluated the proposed detector on field test data obtained on a moving vehicle equipped with a perception-based DNN being under attack. © 2021 ACM.",adversarial detectors; adversarial examples; deep neural networks; perception systems,Deep neural networks; Embedded systems; Internet of things; Signal detection; Traffic signs; Comparative experiments; Detection performance; Field test data; Invariant transformations; Perception systems; Perception-based; Physical attacks; Real-time application; Real time systems,,,,,"Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks; Karmon, D., Zoran, D., Goldberg, Y., (2018) Lavan: Localized and Visible Adversarial Noise; Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Xiao, C., Prakash, A., Song, D., Robust physical-world a. acks on deep learning visual classication (2018) Proceedings of the IEEE Conference on Computer Vision and Pa. Ern Recognition, pp. 1625-1634; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Zantedeschi, V., Nicolae, M.-I., Rawat, A., Ecient defenses against adversarial a. acks (2017) Proceedings of the 10th ACM Workshop on Articial Intelligence and Security. ACM, pp. 39-49; Guo, C., Pleiss, G., Sun, Y., Weinberger, K.Q., On calibration of modern neural networks (2017) Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. Org, pp. 1321-1330; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP), pp. 39-57; Chen, S., Huang, X., He, Z., Sun, C., (2019) Damagenet: A Universal Adversarial Dataset; Stallkamp, J., Schlipsing, M., Salmen, J., Igel, C., Man vs. computer: Benchmarking machine learning algorithms for tra?c sign recognition (2012) Neural Networks, 32, pp. 323-332; Guo, C., Rana, M., Cisse, M., Maaten Der, L.Van, (2017) Countering Adversarial Images Using Input Transformations; Das, N., Shanbhogue, M., Chen, S.-T., Hohman, F., Li, S., Chen, L., Kounavis, M.E., Chau, D.H., Shield: Fast, practical defense and vaccination for deep learning using jpeg compression (2018) Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. ACM, pp. 196-204; Samangouei, P., Kabkab, M., Chellappa, R., (2018) Defense-gan: Protecting Classi Ers against Adversarial A. Acks Using Generative Models; Yin, Z., Wang, H., Wang, J., Tang, J., Wang, W., Defense against adversarial a. acks by low-level image transformations (2020) International Journal of Intelligent Systems, 35 (10), pp. 1453-1466; Zheng, S., Song, Y., Leung, T., Goodfellow, I., Improving the robustness of deep neural networks via stability training (2016) Proceedings of the Ieee Conference on Computer Vision and Pa. Ern Recognition, pp. 4480-4488; Kou, C., Lee, H.K., Chang, E.-C., Ng, T.K., Enhancing transformation-based defenses against adversarial a. acks with a distribution classier (2019) International Conference on Learning Representations; Tian, S., Yang, G., Cai, Y., Detecting adversarial examples through image transformation (2018) Irty-Second AAAI Conference on Articial Intelligence; Meng, D., Chen, H., Magnet: A two-pronged defense against adversarial examples (2017) Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security. ACM, pp. 135-147; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts; Jha, S., Jang, U., Jha, S., Jalaian, B., Detecting adversarial examples using data manifolds (2018) IEEE Military Communications Conference (MILCOM), pp. 547-552. , Norfolk, VA; Fidel, G., Bion, R., Shabtai, A., When explainability meets adversarial learning: Detecting adversarial examples using shap signatures (2020) 2020 International Joint Conference on Neural Networks (IJCNN), pp. 1-8; Pang, T., Du, C., Dong, Y., Zhu, J., Towards robust detection of adversarial examples (2018) Advances in Neural Information Processing Systems, pp. 4584-4594; Cohen, G., Sapiro, G., Giryes, R., Detecting adversarial samples using in. uence functions and nearest neighbors (2020) Proceedings of the IEEE/CVF Conference on Computer Vision and Pa. Ern Recognition, pp. 14453-14462; Liu, J., Zhang, W., Zhang, Y., Hou, D., Liu, Y., Zha, H., Yu, N., Detection based defense against adversarial examples from the steganalysis point of view (2019) Proceedings of the IEEE Conference on Computer Vision and Pa. Ern Recognition, pp. 4825-4834; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) Proceedings of the 10th ACM Workshop on Articial Intelligence and Security. ACM, pp. 3-14; Cai, F., Koutsoukos, X., Real-time out-of-distribution detection in learningenabled cyber-physical systems (2020) 2020 ACM/IEEE 11th International Conference on Cyber-Physical Systems (ICCPS), pp. 174-183; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pa. Ern Recognition, pp. 2574-2582; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Machine Learning at Scale; Hinton, G., Vinyals, O., Dean, J., (2015) Distilling the Knowledge in A Neural Network; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks 2016 IEEE Symposium on Security and Privacy (SP), 2016, pp. 582-597; Warde-Farley, D., Goodfellow, I., 11 adversarial perturbations of deep neural networks (2016) Perturbations, Optimization, and Statistics, p. 311; Yuan, X., He, P., Zhu, Q., Li, X., Adversarial examples: A. acks and defenses for deep learning (2019) IEEE Transactions on Neural Networks and Learning Systems; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-box A. Acks Using Adversarial Samples; Gilmer, J., Metz, L., Faghri, F., Schoenholz, S.S., Raghu, M., Wa Enberg, M., Goodfellow, I., Adversarial Spheres, (2018); Carlini, N., Wagner, D., Magnet and e?cient defenses against adversarial a. acks are not robust to adversarial examples (2017); Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., E limitations of deep learning in adversarial se. ings 2016 IEEE European Symposium on Security and Privacy (EuroS&P), 2016, pp. 372-387; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition Proceedings of the IEEE Conference on Computer Vision and Pa. Ern Recognition, 2016, pp. 770-778; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World; Chiou, P.T., Sun, Y., Young, G., A complexity analysis of the jpeg image compression algorithm 2017 9th Computer Science and Electronic Engineering (CEEC), 2017, pp. 65-70; Redmon, J., Divvala, S., Girshick, R., Farhadi, A., You only look once: Unied, real-time object detection Proceedings of the IEEE Conference on Computer Vision and Pa. Ern Recognition, 2016, pp. 779-788; Yurtsever, E., Lambert, J., Carballo, A., Takeda, K., A survey of autonomous driving: Common practices and emerging technologies (2020) IEEE Access, 8, pp. 58443-58469",,,ACM SIGBED;IEEE TCRTS,"Association for Computing Machinery, Inc","12th ACM/IEEE International Conference on Cyber-Physical Systems, ICCPS 2021, part of CPS-IoT Week 2021",19 May 2021 through 21 May 2021,,168186,,9.78E+12,,,English,ICCPS - Proc. ACM/IEEE Int. Conf. Cyber-Phys. Syst. CPS-IoT Week,Conference Paper,Final,,Scopus,2-s2.0-85104201187
"Yang T., Murguia C., Kuijper M., Nesic D.",57207037830;55734645200;7003535680;35551435400;,An unknown input multiobserver approach for estimation and control under adversarial attacks,2021,IEEE Transactions on Control of Network Systems,8,1,9214921,475,486,,4,10.1109/TCNS.2020.3029160,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092903092&doi=10.1109%2fTCNS.2020.3029160&partnerID=40&md5=85918cd3eba91cb1bd389ffe69b92308,"Department of Electrical and Electronics Engineering, University of Melbourne, Parkville, VIC  3010, Australia","Yang, T., Department of Electrical and Electronics Engineering, University of Melbourne, Parkville, VIC  3010, Australia; Murguia, C., Department of Electrical and Electronics Engineering, University of Melbourne, Parkville, VIC  3010, Australia; Kuijper, M., Department of Electrical and Electronics Engineering, University of Melbourne, Parkville, VIC  3010, Australia; Nesic, D., Department of Electrical and Electronics Engineering, University of Melbourne, Parkville, VIC  3010, Australia","We address the problem of state estimation, attack isolation, and control of discrete-time linear time-invariant systems under (potentially unbounded) actuator and sensor false data injection attacks. Using a bank of unknown input observers, each observer leading to an exponentially stable estimation error (in the attack-free case), we propose an observer-based estimator that provides exponential estimates of the system state despite actuator and sensor attacks. Exploiting sensor and actuator redundancy, the estimation scheme is guaranteed to work if a sufficiently small subset of sensors and actuators is under attack. Using the proposed estimator, we provide tools for reconstructing and isolating actuator and sensor attacks, and a control scheme capable of stabilizing the closed-loop dynamics by switching off isolated actuators. Simulation results are presented to illustrate the performance of our tools. © 2014 IEEE.",Control; cyber-physical systems; linear systems; sensor and actuator attacks; unknown input observers,Actuators; Invariance; Linear control systems; Linear systems; Nonlinear control systems; Time varying control systems; Closed loop dynamic; Discrete-time linear time-invariant systems; Exponential estimates; Exponentially stable; False data injection attacks; Sensor and actuators; Sensors and actuators; Unknown input observer; Discrete time control systems,,,,,"Liu, Y., Ning, P., Reiter, M.K., False data injection attacks against state estimation in electric power grids (2009) ACM Trans. Inform. Syst. Secur., 14 (1), pp. 21-32; Fawzi, H., Tabuada, P., Diggavi, S., Secure estimation and control for cyber-physical systems under adversarial attacks (2014) IEEE Trans. Autom. Control, 59 (6), pp. 1454-1467. , Jan; Vamvoudakis, K.G., Hespanha, J.P., Sinopoli, B., Mo, Y., Detection in adversarial environments (2014) IEEE Trans. Autom. Control, 59 (12), pp. 3209-3223. , Dec; Shoukry, Y., Nuzzo, P., Puggelli, A., Sangiovanni-Vincentelli, A., Seshia, S.A., Tabuada, P., Secure state estimation for cyber physical systems under sensor attacks: A Satisfiability Modulo Theory approach (2017) IEEE Trans. Autom. Control, 62 (10), pp. 4917-4932. , Oct; Teixeira, A., Shames, I., Sandberg, H., Johansson, K.H., Revealing stealthy attacks in control systems (2012) Proc. 50th Annu. Allerton Conf. Commun. Control Comput., pp. 1806-1813; Pasqualetti, F., Dorfler, F., Bullo, F., Attack detection and identification in cyber-physical systems (2013) IEEE Trans. Autom. Control, 58 (11), pp. 2715-2729. , Nov; Kafash, S.H., Giraldo, J., Murguia, C., Cardenas, A.A., Ruths, J., Constraining attacker capabilities through actuator saturation (2017) Proc. Amer. Control Conf., pp. 986-991; Murguia, C., Ruths, J., Characterization of a CUSUM model-based sensor attack detector (2016) Proc. IEEE 55th Conf. Decis. Control, pp. 1303-1309; Chong, M.S., Wakaiki, M., Hespanha, J.P., Observability of linear systems under adversarial attacks (2015) Proc. Amer. Control Conf., pp. 2439-2444; Tang, Z., Kuijper, M., Chong, M.S., Mareels, I., Leckie, C., Linear system security-detection and correction of adversarial sensor attacks in the noise-free case (2019) Automatica, 101, pp. 53-59; Hu, Q., Fooladivanda, D., Chang, Y.H., Tomlin, C.J., Secure state estimation and control for cyber security of the nonlinear power systems (2018) IEEE Trans. Control Netw. Syst., 5 (3), pp. 1310-1321. , Sep; Kim, J., Lee, C., Shim, H., Eun, Y., Seo, J.H., Detection of sensor attack and resilient state estimation for uniformly observable nonlinear systems (2016) Proc. IEEE 55th Conf. Decis. Control, pp. 1297-1302; Shoukry, Y., Nuzzo, P., Bezzo, N., Sangiovanni-Vincentelli, A.L., Seshia, S.A., Tabuada, P., Secure state reconstruction in differentially flat systems under sensor attacks using satisfiability modulo theory solving (2015) Proc. 54th IEEE Conf. Decis. Control, pp. 3804-3809; Yang, T., Murguia, C., Kuijper, M., Nešíc, D., A robust circle-criterion observer-based estimator for discrete-time nonlinear systems in the presence of sensor attacks (2018) Proc. IEEE 57th Conf. Decis. Control, pp. 571-576; Yang, T., Murguia, C., Kuijper, M., Nešíc, D., Attack detection and isolation for discrete-time nonlinear systems (2018) Proc. Aust. New Zealand Control Conf., pp. 346-351; Djouadi, S.M., Melin, A.M., Ferragut, E.M., Laska, J.A., Dong, J., Drira, A., Finite energy and bounded actuator attacks on cyber-physical systems (2015) Proc. Eur. Control Conf., pp. 3659-3664; Jin, X., Haddad, W.M., Yucelen, T., An adaptive control architecture formitigating sensor and actuator attacks in cyber-physical systems (2017) IEEE Trans. Autom. Control, 62 (11), pp. 6058-6064. , Nov; Fawzi, H., Tabuada, P., Diggavi, S., Secure estimation and control for cyber-physical systems under adversarial attacks (2014) IEEE Trans. Autom. Control, 59 (6), pp. 1454-1467. , Jun; Showkatbakhsh, M., Shoukry, Y., Chen, R.H., Diggavi, S., Tabuada, P., An SMT-based approach to secure state estimation under sensor and actuator attacks (2017) Proc. IEEE 56th Annu. Conf. Decis. Control, pp. 157-162; Shoukry, Y., Nuzzo, P., Puggelli, A., Sangiovanni-Vincentelli, A.L., Seshia, S.A., Tabuada, P., Secure state estimation for cyber-physical systems under sensor attacks: A satisfiability modulo theory approach (2017) IEEE Trans. Autom. Control, 62 (10), pp. 4917-4932. , Oct; Mo, Y., Sinopoli, B., Secure estimation in the presence of integrity attacks (2015) IEEE Trans. Autom. Control, 60 (4), pp. 1145-1151. , Apr; Moya, J.M., Improving security for SCADA sensor networks with reputation systems and self-organizing maps (2009) Sensors, 9 (11), pp. 9380-9397; Darms, M., Rybski, P., Urmson, C., Classification and tracking of dynamic objects with multiple sensors for autonomous driving in urban environments (2008) Proc. IEEE Intell. Vehicles Symp., pp. 1197-1202; Van Wyk, F., Wang, Y., Khojandi, A., Masoud, N., Real-time sensor anomaly detection and identification in automated vehicles (2020) IEEE Trans. Intell. Transp. Syst., 21 (3), pp. 1264-1276. , Mar; Liu, Q., Mo, Y., Mo, X., Lv, C., Mihankhah, E., Wang, D., Secure pose estimation for autonomous vehicles under cyber attacks (2019) Proc. Intell. Veh. Symp., pp. 1401-1406; Laszka, A., Abbas, W., Vorobeychik, Y., Koutsoukos, X., Synergic security for smart water networks: Redundancy, diversity, and hardening (2017) Proc. 3rd Int. Workshop Cyber-Phys. Syst. Smart Water Netw., pp. 21-24; Preis, A., Ostfeld, A., Multiobjective contaminant response modeling for water distribution systems security (2008) J. Hydroinf., 10 (4), pp. 267-274; Sontag, E.D., Input to state stability: Basic concepts and results (2008) Lecture Notes Math., 1932, pp. 163-220; Ding, S.X., (2008) Model-Based Fault Diagnosis Techniques: Design Schemes, Algorithms, and Tools, , Berlin, Germany: Springer; Showkatbakhsh, M., Shoukry, Y., Chen, R.H., Diggavi, S., Tabuada, P., An SMT-based approach to secure state estimation under sensor and actuator attacks (2017) Proc. IEEE 56th Annu. Conf. Decis. Control, pp. 157-162; Shoukry, Y., Tabuada, P., Event-triggered state observers for sparse sensor noise/attacks (2016) IEEE Trans. Autom. Control, 61 (8), pp. 2079-2091. , Aug; Shoukry, Y., SMT-based observer design for cyber-physical systems under sensor attacks (2016) Proc. ACM/IEEE 7th Int. Conf. Cyber-Phys. Syst., pp. 1-27; Wu, C., Hu, Z., Liu, J., Wu, L., Secure estimation for cyber-physical systems via sliding mode (2018) IEEE Trans. Cybern., 48 (12), pp. 3420-3431. , Dec; Chong, E.K., Zak, S.H., (2004) An Introduction to Optimization, , New York, NY, USA: Wiley; Ploeg, J., Van Dewouw, N., Nijmeijer, H., LPstring stability of cascaded systems: Application to vehicle platooning (2014) IEEE Trans. Control Syst. Technol., 22 (2), pp. 786-793. , Mar; Öncü, S., Ploeg, J., De Van Wouw, N., Nijmeijer, H., Cooperative adaptive cruise control: Network-aware analysis of string stability (2014) IEEE Trans. Intell. Transp. Syst., 15 (4), pp. 1527-1537. , Aug; Harfouch, Y.A., Yuan, S., Baldi, S., An adaptive switched control approach to heterogeneous platooning with intervehicle communication losses (2018) IEEE Trans. ControlNetw. Syst., 5, pp. 1434-1444. , Sep; Chen, J., Patton, R., (2012) Robust Model-Based Fault Diagnosis for Dynamic Systems., , New York, NY, USA: Springer; Watanabe, K., Himmelblau, D.M., Fault diagnosis in nonlinear chemical processes. Part II. Application to a chemical reactor (1983) AIChE J., 29, pp. 250-261; Murguia, C., Ruths, J., On model-based detectors for linear timeinvariant stochastic systems under sensor attacks (2019) IET Control Theory Appl., 13, pp. 1051-1061; Chen, W., Saif, M., An actuator fault isolation strategy for linear and nonlinear systems (2005) Proc. Amer. Control Conf., pp. 3321-3326. , Portland, OR, USA; Chen, W., Saif, M., Actuator fault diagnosis for uncertain linear systems using a high-order sliding-mode robust differentiator (HOSMRD) (2008) Int. J. Robust Nonlinear Control, 18, pp. 413-426. , Apr; Shames, I., Teixeira, A.M., Sandberg, H., Johansson, K.H., Distributed fault detection for interconnected second-order systems (2011) Automatica, 47 (12), pp. 2757-2764; Jiang, Z.-P., Wang, Y., Input-to-state stability for discrete-time nonlinear systems (2001) Automatica, 37 (6), pp. 857-869; Daafouz, J., Riedinger, P., Iung, C., Stability analysis and control synthesis for switched systems: A switched Lyapunov function approach (2002) IEEE Trans. Autom. Control, 47 (11), pp. 1883-1887. , Nov","Yang, T.; Department of Electrical and Electronics Engineering, Australia; 电子邮件: yangtianci2012@163.com",,,Institute of Electrical and Electronics Engineers Inc.,,,,,23255870,,,,English,IEEE Trans. Control Netw. Syst.,Article,Final,"All Open Access, Green",Scopus,2-s2.0-85092903092
"Zhang X., Zhang L., Jin B., Lu X.",57221836705;57218522951;57203386365;56017221800;,A Multi-view Confidence-calibrated Framework for Fair and Stable Graph Representation Learning,2021,"Proceedings - IEEE International Conference on Data Mining, ICDM",2021-December,,,1493,1498,,,10.1109/ICDM51629.2021.00194,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125192560&doi=10.1109%2fICDM51629.2021.00194&partnerID=40&md5=a3203c896c0c2e2d28682f7cdfdbd3fb,"Dalian University of Technology, Dalian, China; Dongbei University of Finance and Economics, Dalian, China; Business Intelligence Lab, Baidu Research, Beijing, China","Zhang, X., Dalian University of Technology, Dalian, China; Zhang, L., Dongbei University of Finance and Economics, Dalian, China; Jin, B., Dalian University of Technology, Dalian, China; Lu, X., Business Intelligence Lab, Baidu Research, Beijing, China","Graph Neural Networks (GNNs) are prone to adversarial attacks and discriminatory biases. The cutting-edge studies usually adopt a perturbation-invariant consistency regularization strategy without considering the inherent prediction uncertainties, which can lead to unsatisfactory overconfidence for incorrect prediction under intent graph topology or node features attacks. Besides, operating on the complete graph structure is biased towards global level graph noise and brings severe computational issues. In this work, we develop a multi-view confidence-calibrated framework, called MCCNIFTY, for unified fair and stable graph representation learning. At its core is a multi-view uncertainty-aware node embedding learning module derived from evidential theory, including an intra-view evidence calibration, an inter-view evidence fusion, and an uncertainty-aware message passing process in a GNN architecture, which simultaneously optimizes for counterfactual fairness and stability at the sub-graph level. Experimental results on three real-world datasets demonstrate that our method is capable of adequately capturing inherent uncertainties while improving the fairness and stability via subgraph-induced multiview confidence calibration. © 2021 IEEE.",Evidential Uncertainty; Fairness; Graph Neural Network; Stability,Calibration; Computation theory; Computer vision; Graph neural networks; Message passing; Cutting edges; Evidential uncertainty; Fairness; Graph neural networks; Graph representation; Multi-views; Prediction uncertainty; Regularization strategies; Subgraphs; Uncertainty; Graph theory,,,,,"Wang, H., Leskovec, J., (2020) Unifying Graph Convolutional Neural Networks and Label Propagation; Kipf, T.N., Welling, M., Semi-supervised classification with graph convolutional networks (2017) International Conference on Learning Representations (ICLR); Xu, K., Hu, W., Leskovec, J., Jegelka, S., (2018) How Powerful Are Graph Neural Networks?; Agarwal, C., Lakkaraju, H., Zitnik, M., (2021) Towards A Unified Framework for Fair and Stable Graph Representation Learning; Jin, B., Cheng, K., Qu, Y., Zhang, L., Xiao, K., Lu, X., Wei, X., Fast sparse connectivity network adaption via meta-learning (2020) 2020 IEEE International Conference on Data Mining (ICDM). IEEE, pp. 232-241; Bose, A., Hamilton, W., Compositional fairness constraints for graph embeddings (2019) International Conference on Machine Learning. PMLR, pp. 715-724; Dai, E., Wang, S., (2020) Fairgnn: Eliminating the Discrimination in Graph Neural Networks with Limited Sensitive Attribute Information; Zhu, D., Zhang, Z., Cui, P., Zhu, W., Robust graph convolutional networks against adversarial attacks (2019) Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 1399-1407; Wang, D., Wang, P., Liu, K., Zhou, Y., Hughes, C., Fu, Y., (2021) Reinforced Imitative Graph Representation Learning for Mobile User Profiling: An Adversarial Training Perspective; Velickovic, P., Fedus, W., Hamilton, W.L., Liò, P., Bengio, Y., Hjelm, R.D., Deep graph infomax (2019) ICLR (Poster); Sensoy, M., Kaplan, L., Kandemir, M., Evidential deep learning to quantify classification uncertainty (2018) Advances in Neural Information Processing Systems; Malinin, A., Gales, M., Predictive uncertainty estimation via prior networks (2018) Proceedings of the 32nd International Conference on Neural Information Processing Systems, pp. 7047-7058; Liu, Z.-Y., Li, S.-Y., Chen, S., Hu, Y., Huang, S.-J., Uncertainty aware graph Gaussian process for semi-supervised learning (2020) Proceedings of the AAAI Conference on Artificial Intelligence, pp. 4957-4964; Zhao, X., Chen, F., Hu, S., Cho, J.-H., Uncertainty aware semisupervised learning on graph data (2020) Advances in Neural Information Processing Systems, pp. 12827-12836; Shanthamallu, U.S., Thiagarajan, J.J., Spanias, A., Uncertaintymatching graph neural networks to defend against poisoning attacks (2021) Proceedings of the AAAI Conference on Artificial Intelligence, pp. 9524-9532; Jiao, Y., Xiong, Y., Zhang, J., Zhang, Y., Zhang, T., Zhu, Y., Sub-graph contrast for scalable self-supervised graph representation learning (2020) 20th IEEE International Conference on Data Mining, pp. 222-231; Qiu, J., Chen, Q., Dong, Y., Zhang, J., Yang, H., Ding, M., Wang, K., Tang, J., GCC: Graph contrastive coding for graph neural network pre-training (2020) Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pp. 1150-1160; Sensoy, M., Kaplan, L., Kandemir, M., (2018) Evidential Deep Learning to Quantify Classification Uncertainty; Han, Z., Zhang, C., Fu, H., Zhou, J.T., Trusted multi-view classification (2021) International Conference on Learning Representations; Kingma, D.P., Ba, J., (2017) Adam: A Method for Stochastic Optimization; He, K., Zhang, X., Ren, S., Sun, J., Delving deep into rectifiers: Surpassing human-level performance on imagenet classification (2015) Proceedings of the IEEE International Conference on Computer Vision (ICCV), , December; Velickovíc, P., Cucurull, G., Casanova, A., Romero, A., Lio, P., Bengio, Y., (2017) Graph Attention Networks; Feng, B., Wang, Y., Ding, Y., Uag: Uncertainty-aware attention graph neural network for defending adversarial attacks (2021) Proceedings of the AAAI Conference on Artificial Intelligence, pp. 7404-7412","Jin, B.; Dalian University of TechnologyChina; 电子邮件: jinbo@dlut.edu.cn",Bailey J.Miettinen P.Koh Y.S.Tao D.Wu X.,Google;IEEE Technical Committee on Intelligent Informatics;School of Computer Science - The University of Auckland;Two Sigma;US National Science Foundation (NSF),Institute of Electrical and Electronics Engineers Inc.,"21st IEEE International Conference on Data Mining, ICDM 2021",7 December 2021 through 10 December 2021,,176603,15504786,9.78E+12,,,English,Proc. IEEE Int. Conf. Data Min. ICDM,Conference Paper,Final,,Scopus,2-s2.0-85125192560
"Alesiani F., Yu S., Yu X.",56085653900;56438265200;57226063684;,Gated Information Bottleneck for Generalization in Sequential Environments,2021,"Proceedings - IEEE International Conference on Data Mining, ICDM",2021-December,,,1,10,,,10.1109/ICDM51629.2021.00010,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125190243&doi=10.1109%2fICDM51629.2021.00010&partnerID=40&md5=b0fc211352400bfbd639a3e6ec3e37f8,"NEC Laboratories Europe, Germany; UiT - the Arctic University of Norway, Norway; Xi'an Jiaotong University, China; University of Florida, United States","Alesiani, F., NEC Laboratories Europe, Germany; Yu, S., UiT - the Arctic University of Norway, Norway, Xi'an Jiaotong University, China; Yu, X., University of Florida, United States","Deep neural networks suffer from poor generalization to unseen environments when the underlying data distribution is different from that in the training set. By learning minimum sufficient representations from training data, the information bottleneck (IB) approach has demonstrated its effectiveness to improve generalization in different AI applications. In this work, we propose a new neural network-based IB approach, termed gated information bottleneck (GIB), that dynamically drops spurious correlations and progressively selects the most task-relevant features across different environments by a trainable soft mask (on raw features). GIB enjoys a simple and tractable objective, without any variational approximation or distributional assumption. We empirically demonstrate the superiority of GIB over other popular neural network-based IB approaches in adversarial robustness and out-of-distribution (OOD) detection. Meanwhile, we also establish the connection between IB theory and invariant causal representation learning, and observed that GIB demonstrates appealing performance when different environments arrive sequentially, a more practical scenario where invariant risk minimization (IRM) fails. © 2021 IEEE.",Adversarial Attack; Causal Learning; Deep Learning; Generalization; Information Bottleneck; Information Theory; Out of distribution; Sequential Learning,Deep neural networks; Risk perception; Adversarial attack; Causal learning; Data distribution; Deep learning; Generalisation; Information bottleneck; Network-based; Neural-networks; Out of distribution; Sequential learning; Information theory,,,,,"Shwartz-Ziv, R., Tishby, N., (2017) Opening the Black Box of Deep Neural Networks Via Information; Yu, S., Principe, J.C., Understanding autoencoders with information theoretic concepts (2019) Neural Networks, 117, pp. 104-123; Alemi, A.A., Fischer, I., Dillon, J.V., Murphy, K., Deep variational information bottleneck (2017) International Conference on Learning Representations; Kolchinsky, A., Tracey, B.D., Wolpert, D.H., Nonlinear information bottleneck (2019) Entropy, 21 (12), p. 1181; Fischer, I., The conditional entropy bottleneck (2020) Entropy, 22 (9), p. 999; Mahabadi, R.K., Belinkov, Y., Henderson, J., Variational information bottleneck for effective low-resource fine-tuning (2021) International Conference on Learning Representations; Kim, J., Kim, M., Woo, D., Kim, G., (2021) Drop-bottleneck: Learning Discrete Compressed Representation for Noiserobust Exploration; Fischer, I., Alemi, A.A., Ceb improves model robustness (2020) Entropy, 22 (10), p. 1081; Giraldo, L.G.S., Rao, M., Principe, J.C., Measures of entropy from data using infinitely divisible kernels (2014) IEEE Transactions on Information Theory, 61 (1), pp. 535-548; Yu, S., Alesiani, F., Yu, X., Jenssen, R., Principe, J., Measuring dependence with matrix-based entropy functional (2021) Proceedings of the AAAI Conference on Artificial Intelligence, 35 (12), pp. 10781-10789; Arjovsky, M., Bottou, L., Gulrajani, I., Lopez-Paz, D., (2019) Invariant Risk Minimization; Gilad-Bachrach, R., Navot, A., Tishby, N., An information theoretic tradeoff between complexity and accuracy (2003) Learning Theory and Kernel Machines, pp. 595-609. , Springer; Chechik, G., Globerson, A., Tishby, N., Weiss, Y., Dayan, P., Information bottleneck for Gaussian variables (2005) Journal of Machine Learning Research, 6 (1); Tishby, N., Pereira, F.C., Bialek, W., (2000) The Information Bottleneck Method, , physics/0004057; Dai, B., Zhu, C., Guo, B., Wipf, D., Compressing neural networks using the variational information bottleneck (2018) International Conference on Machine Learning. PMLR, pp. 1135-1144; Mitrovic, J., McWilliams, B., Walker, J., Buesing, L., Blundell, C., (2020) Representation Learning Via Invariant Causal Mechanisms; Ahuja, K., Shanmugam, K., Varshney, K., Dhurandhar, A., (2020) Invariant Risk Minimization Games; Pearl, J., (2009) Causality, , Cambridge university press; Peters, J., Bühlmann, P., Meinshausen, N., Causal inference by using invariant prediction: Identification and confidence intervals (2016) Journal of the Royal Statistical Society. Series B (Statistical Methodology), pp. 947-1012; Moyer, D., Gao, S., Brekelmans, R., Steeg, G.V., Galstyan, A., (2018) Invariant Representations Without Adversarial Training; Achille, A., Soatto, S., Emergence of invariance and disentanglement in deep representations (2018) The Journal of Machine Learning Research, 19 (1), pp. 1947-1980; Amjad, R.A., Geiger, B.C., Learning representations for neural network-based classification using the information bottleneck principle (2019) IEEE Transactions on Pattern Analysis and Machine Intelligence, 42 (9), pp. 2225-2239; Bengio, Y., Léonard, N., Courville, A., (2013) Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) International Conference on Learning Representations; Hendrycks, D., Gimpel, K., A baseline for detecting misclassified and out-of-distribution examples in neural networks (2017) International Conference on Learning Representations; Clanuwat, T., Bober-Irizar, M., Kitamoto, A., Lamb, A., Yamamoto, K., Ha, D., (2018) Deep Learning for Classical Japanese Literature; Cohen, G., Afshar, S., Tapson, J., Van Schaik, A., Emnist: Extending mnist to handwritten letters (2017) 2017 International Joint Conference on Neural Networks (IJCNN). IEEE, pp. 2921-2926; Kirkpatrick, J., Pascanu, R., Rabinowitz, N., Veness, J., Desjardins, G., Rusu, A.A., Milan, K., Grabska-Barwinska, A., Overcoming catastrophic forgetting in neural networks (2017) Proceedings of the National Academy of Sciences, 114 (13), pp. 3521-3526; Lopez-Paz, D., Ranzato, M., Gradient episodic memory for continual learning (2017) Advances in Neural Information Processing Systems, pp. 6467-6476; Riemer, M., Cases, I., Ajemian, R., Liu, M., Rish, I., Tu, Y., Tesauro, G., (2018) Learning to Learn Without Forgetting by Maximizing Transfer and Minimizing Interference; Tishby, N., Zaslavsky, N., Deep learning and the information bottleneck principle (2015) 2015 IEEE Information Theory Workshop (ITW). IEEE, pp. 1-5; Zaidi, A., Estella-Aguerri, I., On the information bottleneck problems: Models, connections, applications and information theoretic views (2020) Entropy, 22 (2), p. 151; Goldfeld, Z., Polyanskiy, Y., The information bottleneck problem and its applications in machine learning (2020) IEEE Journal on Selected Areas in Information Theory, 1 (1), pp. 19-38; Achille, A., Soatto, S., Information dropout: Learning optimal representations through noisy computation (2018) IEEE Transactions on Pattern Analysis and Machine Intelligence, 40 (12), pp. 2897-2905; Yu, S., Sanchez Giraldo, L., Principe, J., Informationtheoretic methods in deep neural networks: Recent advances and emerging opportunities (2021) International Joint Conference on Artificial Intelligence, pp. 4669-4678; Kolchinsky, A., Tracey, B.D., Estimating mixture entropy with pairwise distances (2017) Entropy, 19 (7), p. 361; Belghazi, M.I., Baratin, A., Rajeshwar, S., Ozair, S., Bengio, Y., Courville, A., Hjelm, D., Mutual information neural estimation (2018) International Conference on Machine Learning. PMLR, pp. 531-540; Elad, A., Haviv, D., Blau, Y., Michaeli, T., Direct validation of the information bottleneck principle for deep nets (2019) Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops; Strouse, D., Schwab, D.J., The deterministic information bottleneck (2017) Neural Computation, 29 (6), pp. 1611-1630; Kolchinsky, A., Tracey, B.D., Van Kuyk, S., Caveats for information bottleneck in deterministic scenarios (2019) International Conference on Learning Representations; Bengio, Y., Deleu, T., Rahaman, N., Ke, R., Lachapelle, S., Bilaniuk, O., Goyal, A., Pal, C., (2019) A Meta-transfer Objective for Learning to Disentangle Causal Mechanisms; Krueger, D., Caballero, E., Jacobsen, J.-H., Zhang, A., Binas, J., Zhang, D., Priol, R.L., Courville, A., (2020) Out-of-distribution Generalization Via Risk Extrapolation (Rex); Javed, K., White, M., Bengio, Y., (2020) Learning Causal Models Online; Ahuja, K., Caballero, E., Zhang, D., Bengio, Y., Mitliagkas, I., Rish, I., (2021) Invariance Principle Meets Information Bottleneck for Out-of-distribution Generalization; Romano, S., Chelly, O., Nguyen, V., Bailey, J., Houle, M.E., Measuring dependency via intrinsic dimensionality (2016) 2016 23rd International Conference on Pattern Recognition (ICPR). IEEE, pp. 1207-1212",,Bailey J.Miettinen P.Koh Y.S.Tao D.Wu X.,Google;IEEE Technical Committee on Intelligent Informatics;School of Computer Science - The University of Auckland;Two Sigma;US National Science Foundation (NSF),Institute of Electrical and Electronics Engineers Inc.,"21st IEEE International Conference on Data Mining, ICDM 2021",7 December 2021 through 10 December 2021,,176603,15504786,9.78E+12,,,English,Proc. IEEE Int. Conf. Data Min. ICDM,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85125190243
"El-Din Y.S., Moustafa M.N., Mahdi H.",55557632100;7101946942;8311730700;,Adversarial Unsupervised Domain Adaptation Guided with Deep Clustering for Face Presentation Attack Detection,2021,"Proceedings of the International Conference on Image Processing and Vision Engineering, IMPROVE 2021",,,,36,45,,,10.5220/0010432900360045,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125182819&doi=10.5220%2f0010432900360045&partnerID=40&md5=6cf9b733dddd2d62d84647b04eb6de2c,"Computer and Systems Engineering Department, Ain Shams University, Cairo, Egypt; Department of Computer Science and Engineering, The American University in Cairo, New Cairo, Egypt","El-Din, Y.S., Computer and Systems Engineering Department, Ain Shams University, Cairo, Egypt; Moustafa, M.N., Department of Computer Science and Engineering, The American University in Cairo, New Cairo, Egypt; Mahdi, H., Computer and Systems Engineering Department, Ain Shams University, Cairo, Egypt","Face Presentation Attack Detection (PAD) has drawn increasing attentions to secure the face recognition systems that are widely used in many applications. Conventional face anti-spoofing methods have been proposed, assuming that testing is from the same domain used for training, and so cannot generalize well on unseen attack scenarios. The trained models tend to overfit to the acquisition sensors and attack types available in the training data. In light of this, we propose an end-to-end learning framework based on Domain Adaptation (DA) to improve PAD generalization capability. Labeled source-domain samples are used to train the feature extractor and classifier via cross-entropy loss, while unsupervised data from the target domain are utilized in adversarial DA approach causing the model to learn domain-invariant features. Using DA alone in face PAD fails to adapt well to target domain that is acquired in different conditions with different devices and attack types than the source domain. And so, in order to keep the intrinsic properties of the target domain, deep clustering of target samples is performed. Training and deep clustering are performed end-to-end, and experiments performed on several public benchmark datasets validate that our proposed Deep Clustering guided Unsupervised Domain Adaptation (DCDA) can learn more generalized information compared with the state-of-the-art classification error on the target domain. Copyright © 2021 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved",Biometrics; Deep Clustering; Domain Adaptation; Face Presentation Attack Detection; MobileNet,Biometrics; Classification (of information); Computer graphics; Face recognition; Well testing; Attack detection; Clusterings; Deep clustering; Domain adaptation; End to end; Face presentation attack detection; Face recognition systems; Learn+; Mobilenet; Target domain; Computer vision,,,,,"Anjos, A., Shafey, L. E., Wallace, R., Günther, M., Mc-Cool, C., Marcel, S., Bob: a free signal processing and machine learning toolbox for researchers (2012) 20th ACM Conference on Multimedia Systems (ACMMM), , Nara, Japan; Boulkenafet, Z., Komulainen, J., Hadid, A., Face spoofing detection using colour texture analysis (2016) IEEE Transactions on Information Forensics and Security, 11 (8), pp. 1818-1830; Boulkenafet, Z., Komulainen, J., Hadid, A., Face antispoofing using speeded-up robust features and fisher vector encoding (2017) IEEE Signal Processing Letters, 24 (2), pp. 141-145; Chingovska, I., Anjos, A., Marcel, S., On the effectiveness of local binary patterns in face antispoofing (2012) 2012 BIOSIG - Proceedings of the International Conference of Biometrics Special Interest Group (BIOSIG), pp. 1-7; Costa-Pazo, A., Bhattacharjee, S., Vazquez-Fernandez, E., Marcel, S., The replay-mobile face presentation-attack database (2016) 2016 International Conference of the Biometrics Special Interest Group (BIOSIG), pp. 1-7; Dizaji, K. G., Herandi, A., Deng, C., Cai, W., Huang, H., Deep clustering via joint convolutional autoencoder embedding and relative entropy minimization (2017) IEEE international conference on Computer Vision, pp. 5747-5756; El-Din, Y. S., Moustaf, M. N., Mahdi, H., On the effectiveness of adversarial unsupervised domain adaptation for iris presentation attack detection in mobile devices (2020) ICMV’20; El-Din, Y. S., Moustafa, M. N., Mahdi, H., Deep convolutional neural networks for face and iris presentation attack detection: survey and case study (2020) IET Biometrics, 9, pp. 179-193. , (14); Feng, L., Po, L.-M., Li, Y., Xu, X., Yuan, F., Cheung, T. C.-H., Cheung, K.-W., Integration of image quality and motion cues for face anti-spoofing: A neural network approach (2016) Journal of Visual Communication and Image Representation, 38, pp. 451-460; Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette, F., Marchand, M., Lempitsky, V., Domain-adversarial training of neural networks (2016) J. Mach. Learn. Res, 17 (1), pp. 2096-2030; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, 27, pp. 2672-2680. , Ghahramani, Z., Welling, M., Cortes, C., Lawrence, N. D., and Weinberger, K. Q., editors, pages Curran Associates, Inc; Guo, X., Zhu, E., Liu, X., Yin, J., Deep embedded clustering with data augmentation (2018) volume 95 of Proceedings of Machine Learning Research, pp. 550-565. , PMLR; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 770-778; Howard, A., Sandler, M., Chen, B., Wang, W., Chen, L., Tan, M., Chu, G., Le, Q., Searching for mobilenetv3 (2019) 2019 IEEE/CVF International Conference on Computer Vision (ICCV), pp. 1314-1324; Jia, Y., Zhang, J., Shan, S., Chen, X., Single-side domain generalization for face anti-spoofing (2020) Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Kang, G., Jiang, L., Wei, Y., Yang, Y., Hauptmann, A. G., Contrastive adaptation network for single-and multi-source domain adaptation (2020) IEEE transactions on pattern analysis and machine intelligence; Krause, A., Perona, P., Gomes, R. G., Discriminative clustering by regularized information maximization (2010) Advances in Neural Information Processing Systems, 23, pp. 775-783. , Lafferty, J. D., Williams, C. K. I., Shawe-Taylor, J., Zemel, R. S., and Culotta, A., editors, pages Curran Associates, Inc; Kurmi, V. K., Namboodiri, V. P., Looking back at labels: A class based domain adaptation technique (2019) International Joint Conference on Neural Networks (IJCNN); Li, H., He, P., Wang, S., Rocha, A., Jiang, X., Kot, A. C., Learning generalized deep feature representation for face anti-spoofing (2018) IEEE Transactions on Information Forensics and Security, 13 (10), pp. 2639-2652; Li, H., Li, W., Cao, H., Wang, S., Huang, F., Kot, A. C., Unsupervised domain adaptation for face anti-spoofing (2018) IEEE Transactions on Information Forensics and Security, 13 (7), pp. 1794-1809; Li, H., Pan, S. J., Wang, S., Kot, A. C., Domain generalization with adversarial feature learning (2018) 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 5400-5409. , pages; Long, M., CAO, Z., Wang, J., Jordan, M. I., Conditional Adversarial Domain Adaptation (2018) Advances in Neural Information Processing Systems, 31, pp. 1640-1650. , Bengio, S., Wallach, H., Larochelle, H., Grauman, K., Cesa-Bianchi, N., and Garnett, R., editors, pages Curran Associates, Inc; Mohammadi, A., Bhattacharjee, S., Marcel, S., Domain adaptation for generalization of face presentation attack detection in mobile settengs with minimal information (2020) ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 1001-1005; Nagpal, C., Dubey, S. R., A performance evaluation of convolutional neural networks for face anti spoofing (2018) CoRR; Patel, K., Han, H., Jain, A. K., Cross-database face antispoofing with robust feature representation (2016) Biometric Recognition, pp. 611-619. , You, Z., Zhou, J., Wang, Y., Sun, Z., Shan, S., Zheng, W., Feng, J., and Zhao, Q., editors, pages Cham. Springer International Publishing; Patel, K., Han, H., Jain, A. K., Secure face unlock: Spoof detection on smartphones (2016) IEEE Transactions on Information Forensics and Security, 11 (10), pp. 2268-2283; Pei, Z., Cao, Z., Long, M., Wang, J., (2018) Multiadversarial domain adaptation; Saito, K., Ushiku, Y., Harada, T., Saenko, K., Adversarial dropout regularization (2018) International Conference on Learning Representations; Saito, K., Watanabe, K., Ushiku, Y., Harada, T., Maximum classifier discrepancy for unsupervised domain adaptation (2018) 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 3723-3732. , pages; Shao, R., Lan, X., Li, J., Yuen, P. C., Multiadversarial discriminative deep domain generalization for face presentation attack detection (2019) 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 10015-10023; Tang, H., Chen, K., Jia, K., Unsupervised domain adaptation via structurally regularized deep clustering (2020) IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Tang, H., Jia, K., (2020) Discriminative adversarial domain adaptation, , ArXiv, abs/1911.12036; Wang, G., Han, H., Shan, S., Chen, X., Improving cross-database face presentation attack detection via adversarial domain adaptation (2019) 2019 International Conference on Biometrics (ICB), pp. 1-8; Wang, G., Han, H., Shan, S., Chen, X., Cross-domain face presentation attack detection via multidomain disentangled representation learning (2020) 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 6677-6686; Wang, G., Han, H., Shan, S., Chen, X., Unsupervised adversarial domain adaptation for cross-domain face presentation attack detection (2021) IEEE Transactions on Information Forensics and Security, 16, pp. 56-69; Wang, R., Wang, G., Henao, R., (2019) Discriminative clustering for robust unsupervised domain adaptation, , ArXiv, abs/1905.13331; Wang, Z., Zhao, C., Qin, Y., Zhou, Q., Lei, Z., Exploiting temporal and depth information for multiframe face anti-spoofing (2018) CoRR; Wen, D., Han, H., Jain, A. K., Face spoof detection with image distortion analysis (2015) IEEE Transactions on Information Forensics and Security, 10 (4), pp. 746-761; Xie, J., Girshick, R., Farhadi, A., Unsupervised deep embedding for clustering analysis (2016) International conference on machine learning, volume 48 of Proceedings of Machine Learning Research, pp. 478-487. , Balcan, M. F. and Weinberger, K. Q., editors, pages New York, New York, USA. PMLR; Xu, Z., Li, S., Deng, W., Learning temporal features using lstm-cnn architecture for face antispoofing (2015) 2015 3rd IAPR Asian Conference on Pattern Recognition (ACPR), pp. 141-145; Zhang, Y., Tang, H., Jia, K., Tan, M., (2019) Domain-symmetric networks for adversarial domain adaptation",,Imai F.Distante C.Battiato S.,"Institute for Systems and Technologies of Information, Control and Communication (INSTICC)",SciTePress,"2021 International Conference on Image Processing and Vision Engineering, IMPROVE 2021",28 April 2021 through 30 April 2021,,177061,,9.79E+12,,,English,"Proc. Int. Conf. Image Process. Vis. Eng., IMPROVE",Conference Paper,Final,"All Open Access, Hybrid Gold, Green",Scopus,2-s2.0-85125182819
"Lennon M., Drenkow N., Burlina P.",57219741602;55617567100;6603713214;,Patch Attack Invariance: How Sensitive are Patch Attacks to 3D Pose?,2021,Proceedings of the IEEE International Conference on Computer Vision,2021-October,,,112,121,,,10.1109/ICCVW54120.2021.00018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123053621&doi=10.1109%2fICCVW54120.2021.00018&partnerID=40&md5=4bf7c92ecba559525e41f402e0a5ce5c,"Johns Hopkins University, Applied Physics Laboratory, Laurel, MD  20723, United States","Lennon, M., Johns Hopkins University, Applied Physics Laboratory, Laurel, MD  20723, United States; Drenkow, N., Johns Hopkins University, Applied Physics Laboratory, Laurel, MD  20723, United States; Burlina, P., Johns Hopkins University, Applied Physics Laboratory, Laurel, MD  20723, United States","Perturbation-based attacks, while not physically realizable, have been the main emphasis of adversarial machine learning (ML) research. Patch-based attacks by contrast are physically realizable, yet most work has focused on 2D domain with recent forays into 3D. Characterizing the robustness properties of patch attacks and their invariance to 3D pose is important, yet not fully elucidated, and is the focus of this paper. To this end, several contributions are made here: A) we develop a new metric called mean Attack Success over Transformations (mAST) to evaluate patch attack robustness and invariance; and B), we systematically assess robustness of patch attacks to 3D position and orientation for various conditions; in particular, we conduct a sensitivity analysis which provides important qualitative insights into attack effectiveness as a function of the 3D pose of a patch relative to the camera (rotation, translation) and sets forth some properties for patch attack 3D invariance; and C), we draw novel qualitative conclusions including: 1) we demonstrate that for some 3D transformations, namely rotation and loom, increasing the training distribution support yields an increase in patch success over the full range at test time. 2) We provide new insights into the existence of a fundamental cutoff limit in patch attack effectiveness that depends on the extent of out-of-plane rotation angles. These findings should collectively guide future design of 3D patch attacks and defenses. © 2021 IEEE.",,Computer vision; 3D orientation; 3D positions; 3D transformations; Camera rotations; Condition; Machine learning research; Patch based; Position and orientations; Property; Robustness properties; Sensitivity analysis,,,,,"Athalye, A., Engstrom, L., Ilyas, A., Kwok, K., (2017) Synthesizing Robust Adversarial Examples, , 2; Brown, T.B., Mané, D., Roy, A., Abadi, M., Gilmer, J., (2017) Adversarial Patch, , 1, 2, 3; Burlina, P., Chellappa, R., Lin, C., Zhang, X., Context-based exploitation of aerial imagery (1995) Proc. Workshop on Model-Based Vision (Boston, MA), , 1; Burlina, P., Joshi, N., Pacheco, K.D., Freund, D.E., Kong, J., Bressler, N.M., Utility of deep learning methods for referability classification of age-related macular degeneration (2018) JAMA Ophthalmology, 136 (11), pp. 1305-1307. , 1; Burlina, P., Joshi, N., Paul, W., Pacheco, K.D., Bressler, N.M., (2020) Addressing Artificial Intelligence Bias in Retinal Disease Diagnostics, , 1; Burlina, P., Paul, W., Mathew, P., Joshi, N., Pacheco, K.D., Bressler, N.M., Low-shot deep learning of diabetic retinopathy with potential applications to address artificial intelligence bias in retinal diagnostics and rare ophthalmic diseases (2020) JAMA Ophthalmology, 138 (10), pp. 1070-1077. , 1; Burlina, P.M., Joshi, N.J., Ng, E., Billings, S.D., Rebman, A.W., Aucott, J.N., Automated detection of erythema migrans and other confounding skin lesions via deep learning (2019) Computers in Biology and Medicine, 105, pp. 151-156. , 1; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 3-14. , 1; Chen, S., Cornelius, C., Martin, J., Horng Polo Chau, D., Shapeshifter: Robust physical adversarial attack on faster r-cnn object detector (2018) Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 52-68. , Springer 2; Czaja, W., Fendley, N., Pekala, M., Ratto, C., Wang, I., Adversarial examples in remote sensing (2018) Proceedings of the 26th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems, pp. 408-411. , 1; Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Xiao, C., Prakash, A., Song, D., Robust physical-world attacks on deep learning visual classification (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1625-1634. , 2; Fendley, N., Lennon, M., Wang, I., Burlina, P., Drenkow, N., (2019) Jacks of All Trades, Masters of None: Addressing Distributional Shift and Obtrusiveness Via Transparent Patch Attacks, , 3, 5, 7; Geng, C., Huang, S., Chen, S., Recent advances in open set recognition: A survey (2020) IEEE Transactions on Pattern Analysis and Machine Intelligence, , 1; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , 1; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778. , 1, 3; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2017) Communications of the ACM, 60 (6), pp. 84-90. , 1; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , 2; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), p. 436. , 1; Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.A., Veness, J., Bellemare, M.G., Graves, A., Ostrovski, G., Human-level control through deep reinforcement learning (2015) Nature, 518 (7540), p. 529. , 1; Moosavi-Dezfooli, S., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1765-1773. , 1; Moosavi-Dezfooli, S., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582. , 1; Pekala, M., Joshi, N., Alvin Liu, T.Y., Bressler, N.M., Cabrera Debuc, D., Burlina, P., Deep learning based retinal oct segmentation (2019) Computers in Biology and Medicine, 114, p. 103445. , 1; Ravi, S., Larochelle, H., (2016) Optimization As A Model for Few-shot Learning, , 1; Redmon, J., Kumar Divvala, S., Girshick, R.B., Farhadi, A., You only look once: Unified, real-time object detection (2015) 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 779-788. , 1; Ren, S., He, K., Girshick, R.B., Sun, J., Faster r-cnn: Towards real-time object detection with region proposal networks (2015) IEEE Transactions on Pattern Analysis and Machine Intelligence, 39, pp. 1137-1149. , 1; Ronneberger, O., Fischer, P., Brox, T., Unet: Convolutional networks for biomedical image segmentation (2015) International Conference on Medical Image Computing and Computer-assisted Intervention, pp. 234-241. , Springer 1; Scheirer, W.J., De Rezende Rocha, A., Sapkota, A., Boult, T.E., Toward open set recognition (2012) IEEE Transactions on Pattern Analysis and Machine Intelligence, 35 (7), pp. 1757-1772. , 1; Shah, A., Lynch, S., Niemeijer, M., Amelon, R., Clarida, W., Folk, J., Russell, S., Abràmoff, M.D., Susceptibility to misdiagnosis of adversarial images by deep learning based reti-nal image analysis algorithms (2018) 2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018), pp. 1454-1457. , IEEE 1; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proceedings of the 2016 Acm Sigsac Conference on Computer and Communications Security, pp. 1528-1540. , 2; Shokri, R., Stronati, M., Song, C., Shmatikov, V., Membership inference attacks against machine learning models (2017) 2017 IEEE Symposium on Security and Privacy (SP), pp. 3-18. , IEEE 1; Silver, D., Schrittwieser, J., Simonyan, K., Antonoglou, I., Huang, A., Guez, A., Hubert, T., Bolton, A., Mastering the game of go without human knowledge (2017) Nature, 550 (7676), pp. 354-359. , 1; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , 1; Thys, S., Van Ranst, W., Goedemé, T., Fooling automated surveillance cameras: Adversarial patches to attack person detection (2019) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, , 2; Vyas, S., Banerjee, A., Burlina, P., Estimating physiological skin parameters from hyperspectral signatures (2013) Journal of Biomedical Optics, 18 (5), p. 057008. , 1; Wu, S., Dai, T., Xia, S., (2020) Dpattack: Diffused Patch Attacks Against Universal Object Detection, , 2; Wu, T., Ning, X., Li, W., Huang, R., Yang, H., Wang, Y., (2020) Physical Adversarial Attack on Vehicle Detector in the Carla Simulator, , 1, 2; Wu, Z., Lim, S., Davis, L.S., Goldstein, T., Making an invisibility cloak: Real world adversarial attacks on object detectors (2020) European Conference on Computer Vision, pp. 1-17. , Springer 2; Zhao, Y., Yan, H., Wei, X., (2020) Object Hider: Adversarial Patch Attack Against Object Detectors, , 2; Zolfi, A., Kravchik, M., Elovici, Y., Shabtai, A., The translucent patch: A physical and universal attack on object detectors (2021) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 15232-15241. , 2",,,CVF;IEEE,Institute of Electrical and Electronics Engineers Inc.,"18th IEEE/CVF International Conference on Computer Vision Workshops, ICCVW 2021",11 October 2021 through 17 October 2021,,174685,15505499,9.78E+12,PICVE,,English,Proc IEEE Int Conf Comput Vision,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85123053621
[无可用作者姓名],[无可用的作者 ID],"1st CAAI International Conference on Artificial Intelligence, CICAI 2021",2021,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),13069 LNAI,,,,,1226,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122596270&partnerID=40&md5=ab79fbba11953344bcc6a78171203e19,,,The proceedings contain 101 papers. The special focus in this conference is on Artificial Intelligence. The topics include: Diagnosis of Childhood Autism Using Multi-modal Functional Connectivity via Dynamic Hypergraph Learning; CARNet: Automatic Cerebral Aneurysm Classification in Time-of-Flight MR Angiography by Leveraging Recurrent Neural Networks; White-Box Attacks on the CNN-Based Myoelectric Control System; MMG-HCI: A Non-contact Non-intrusive Real-Time Intelligent Human-Computer Interaction System; DSGSR: Dynamic Semantic Generation and Similarity Reasoning for Image-Text Matching; phase Partition Based Virtual Metrology for Material Removal Rate Prediction in Chemical Mechanical Planarization Process; SAR Target Recognition Based on Model Transfer and Hinge Loss with Limited Data; Neighborhood Search Acceleration Based on Deep Reinforcement Learning for SSCFLP; GBCI: Adaptive Frequency Band Learning for Gender Recognition in Brain-Computer Interfaces; DiffGNN: Capturing Different Behaviors in Multiplex Heterogeneous Networks for Recommendation; hybrid Domain Convolutional Neural Network for Memory Efficient Training; brightening the Low-Light Images via a Dual Guided Network; learning Multi-scale Underexposure Image Correction; optimizing Loss Function for Uni-modal and Multi-modal Medical Registration; registration of 3D Point Clouds Based on Voxelization Simplify and Accelerated Iterative Closest Point Algorithm; few-shot Weighted Style Matching for Glaucoma Detection; Lightweight Convolutional SNN for Address Event Representation Signal Recognition; in-the-Wild Facial Highlight Removal via Generative Adversarial Networks; A Cross-Layer Fusion Multi-target Detection and Recognition Method Based on Improved FPN Model in Complex Traffic Environment; various Plug-and-Play Algorithms with Diverse Total Variation Methods for Video Snapshot Compressive Imaging; graph-Based Exercise- and Knowledge-Aware Learning Network for Student Performance Prediction; EEG Signals Classification in Time-Frequency Images by Fusing Rotation-Invariant Local Binary Pattern and Gray Level Co-occurrence Matrix Features; reduced-reference Perceptual Discrepancy Learning for Image Restoration Quality Assessment; EFENet: Reference-Based Video Super-Resolution with Enhanced Flow Estimation.,,,,,,,,,Fang L.Chen Y.Zhai G.Wang J.Wang R.Dong W.,,Springer Science and Business Media Deutschland GmbH,"1st CAAI International Conference on Artificial Intelligence, CICAI 2021",5 June 2021 through 6 June 2021,,270479,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Review,Final,,Scopus,2-s2.0-85122596270
[无可用作者姓名],[无可用的作者 ID],"1st CAAI International Conference on Artificial Intelligence, CICAI 2021",2021,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),13070 LNAI,,,,,1226,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122582092&partnerID=40&md5=9721a83a263d65a3ae1a42e37275dbc4,,,The proceedings contain 101 papers. The special focus in this conference is on Artificial Intelligence. The topics include: Diagnosis of Childhood Autism Using Multi-modal Functional Connectivity via Dynamic Hypergraph Learning; CARNet: Automatic Cerebral Aneurysm Classification in Time-of-Flight MR Angiography by Leveraging Recurrent Neural Networks; White-Box Attacks on the CNN-Based Myoelectric Control System; MMG-HCI: A Non-contact Non-intrusive Real-Time Intelligent Human-Computer Interaction System; DSGSR: Dynamic Semantic Generation and Similarity Reasoning for Image-Text Matching; phase Partition Based Virtual Metrology for Material Removal Rate Prediction in Chemical Mechanical Planarization Process; SAR Target Recognition Based on Model Transfer and Hinge Loss with Limited Data; Neighborhood Search Acceleration Based on Deep Reinforcement Learning for SSCFLP; GBCI: Adaptive Frequency Band Learning for Gender Recognition in Brain-Computer Interfaces; DiffGNN: Capturing Different Behaviors in Multiplex Heterogeneous Networks for Recommendation; hybrid Domain Convolutional Neural Network for Memory Efficient Training; brightening the Low-Light Images via a Dual Guided Network; learning Multi-scale Underexposure Image Correction; optimizing Loss Function for Uni-modal and Multi-modal Medical Registration; registration of 3D Point Clouds Based on Voxelization Simplify and Accelerated Iterative Closest Point Algorithm; few-shot Weighted Style Matching for Glaucoma Detection; Lightweight Convolutional SNN for Address Event Representation Signal Recognition; in-the-Wild Facial Highlight Removal via Generative Adversarial Networks; A Cross-Layer Fusion Multi-target Detection and Recognition Method Based on Improved FPN Model in Complex Traffic Environment; various Plug-and-Play Algorithms with Diverse Total Variation Methods for Video Snapshot Compressive Imaging; graph-Based Exercise- and Knowledge-Aware Learning Network for Student Performance Prediction; EEG Signals Classification in Time-Frequency Images by Fusing Rotation-Invariant Local Binary Pattern and Gray Level Co-occurrence Matrix Features; reduced-reference Perceptual Discrepancy Learning for Image Restoration Quality Assessment; EFENet: Reference-Based Video Super-Resolution with Enhanced Flow Estimation.,,,,,,,,,Fang L.Chen Y.Zhai G.Wang J.Wang R.Dong W.,,Springer Science and Business Media Deutschland GmbH,"1st CAAI International Conference on Artificial Intelligence, CICAI 2021",5 June 2021 through 6 June 2021,,270479,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Review,Final,,Scopus,2-s2.0-85122582092
"Chen X., Xie X., Bi Z., Ye H., Deng S., Zhang N., Chen H.",57247642100;57222379771;57223797329;57221148832;57201556430;55923601900;35268022500;,Disentangled Contrastive Learning for Learning Robust Textual Representations,2021,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),13070 LNAI,,,215,226,,,10.1007/978-3-030-93049-3_18,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122563577&doi=10.1007%2f978-3-030-93049-3_18&partnerID=40&md5=8014e804e59535db2d1833a7e5ee65ed,"Zhejiang University & AZFT Joint Lab for Knowledge Engine, Hangzhou, China; Hangzhou Innovation Center, Zhejiang University, Hangzhou, China","Chen, X., Zhejiang University & AZFT Joint Lab for Knowledge Engine, Hangzhou, China, Hangzhou Innovation Center, Zhejiang University, Hangzhou, China; Xie, X., Zhejiang University & AZFT Joint Lab for Knowledge Engine, Hangzhou, China, Hangzhou Innovation Center, Zhejiang University, Hangzhou, China; Bi, Z., Zhejiang University & AZFT Joint Lab for Knowledge Engine, Hangzhou, China, Hangzhou Innovation Center, Zhejiang University, Hangzhou, China; Ye, H., Zhejiang University & AZFT Joint Lab for Knowledge Engine, Hangzhou, China, Hangzhou Innovation Center, Zhejiang University, Hangzhou, China; Deng, S., Zhejiang University & AZFT Joint Lab for Knowledge Engine, Hangzhou, China, Hangzhou Innovation Center, Zhejiang University, Hangzhou, China; Zhang, N., Zhejiang University & AZFT Joint Lab for Knowledge Engine, Hangzhou, China, Hangzhou Innovation Center, Zhejiang University, Hangzhou, China; Chen, H., Zhejiang University & AZFT Joint Lab for Knowledge Engine, Hangzhou, China, Hangzhou Innovation Center, Zhejiang University, Hangzhou, China","Although the self-supervised pre-training of transformer models has resulted in the revolutionizing of natural language processing (NLP) applications and the achievement of state-of-the-art results with regard to various benchmarks, this process is still vulnerable to small and imperceptible permutations originating from legitimate inputs. Intuitively, the representations should be similar in the feature space with subtle input permutations, while large variations occur with different meanings. This motivates us to investigate the learning of robust textual representation in a contrastive manner. However, it is non-trivial to obtain opposing semantic instances for textual samples. In this study, we propose a disentangled contrastive learning method that separately optimizes the uniformity and alignment of representations without negative sampling. Specifically, we introduce the concept of momentum representation consistency to align features and leverage power normalization while conforming the uniformity. Our experimental results for the NLP benchmarks demonstrate that our approach can obtain better results compared with the baselines, as well as achieve promising improvements with invariance tests and adversarial attacks. The code is available in https://github.com/zxlzr/DCL. © 2021, Springer Nature Switzerland AG.",Adversarial attack; Contrastive learning; Natural language processing,Benchmarking; Learning systems; Semantics; Adversarial attack; Contrastive learning; Feature space; Learning methods; Natural language processing applications; Non-trivial; Pre-training; State of the art; Textual representation; Transformer modeling; Natural language processing systems,,,,,"Abe, F., Josh, A., Understanding Self-Supervised and Contrastive Learning with Bootstrap Your Own Latent (BYOL), , https://untitled-ai.github.io/understanding-self-supervised-contrastive-learning.html; Arora, S., Khandeparkar, H., Khodak, M., Plevrakis, O., Saunshi, N., (2019) A Theoretical Analysis of Contrastive Unsupervised Representation Learning. Arxiv Preprint Arxiv, 1902, p. 09229; Chen, T., Kornblith, S., Norouzi, M., Hinton, G., A simple framework for contrastive learning of visual representations (2020) Proceedings of Machine Learning and Systems 2020, Pp. 10719–10729; Chi, Z., (2020) Infoxlm: An Information-Theoretic Framework for Cross-Lingual Language Model Pre-Training. Arxiv Preprint Arxiv, 2007, p. 07834; Devlin, J., Chang, M.W., Lee, K., Toutanova, K., BERT: Pre-training of deep bidirectional transformers for language understanding (2019) Proceedings of NAACL, pp. 4171-4186. , https://doi.org/10.18653/v1/N19-1423, , pp. , Minneapolis, Minnesota, June; Fang, H., Xie, P., (2020) CERT: Contrastive Self-Supervised Learning for Language Understanding. Arxiv Preprint Arxiv, 2005, p. 12766; Giorgi, J.M., Nitski, O., Bader, G.D., Wang, B., (2020) Declutr: Deep Contrastive Learning for Unsupervised Textual Representations. Arxiv Preprint Arxiv, 2006, p. 03659; Grill, J.B., (2020) Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning. Arxiv Preprint Arxiv, 2006, p. 07733; Gunel, B., Du, J., Conneau, A., Stoyanov, V., (2020) Supervised Contrastive Learning for Pre-Trained Language Model Fine-Tuning. Arxiv Preprint Arxiv, 2011, p. 01403; He, K., Fan, H., Wu, Y., Xie, S., Girshick, R.B., Momentum contrast for unsupervised visual representation learning (2019) Corr Abs/1911, p. 05722; Jin, D., Jin, Z., Zhou, J.T., Szolovits, P., (2019) Is BERT Really Robust ? A Strong Baseline for Natural Language Attack on Text Classification and Entailment. Arxiv, p. 1907; Li, L., Qiu, X., (2020) Textat: Adversarial Training for Natural Language Understanding with Token-Level Perturbation. Arxiv Preprint Arxiv, 2004, p. 14543; Li, L., (2021) Normal Vs. Adversarial: Salience-Based Analysis of Adversarial Samples for Relation Extraction. Arxiv Preprint Arxiv, 2104, p. 00312; Liu, T., Moore, A.W., Yang, K., Gray, A.G., An investigation of practical approximate nearest neighbor algorithms (2005) Advances in Neural Information Processing Systems, pp. 825-832. , , pp; Maaten, L.V.D., Hinton, G., Visualizing data using t-SNE (2008) J. Mach. Learn. Res, 9 (Nov), pp. 2579-2605; Meng, Y., Zhang, Y., Huang, J., Zhang, Y., Zhang, C., Han, J., Hierarchical topic mining via joint spherical tree and text embedding (2020) Proceedings of the 26Th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pp. 1908-1917. , , pp; Mikolov, T., Sutskever, I., Chen, K., Corrado, G.S., Dean, J., Distributed representations of words and phrases and their compositionality (2013) Advances in Neural Information Processing Systems, 26, pp. 3111-3119. , , pp; Mnih, A., Kavukcuoglu, K., Learning word embeddings efficiently with noise-contrastive estimation (2013) Advances in Neural Information Processing Systems, 26, pp. 2265-2273. , , pp; Ren, S., Deng, Y., He, K., Che, W., Generating natural language adversarial examples through probability weighted word saliency (2019) Proceedings of the 57Th Annual Meeting of the Association for Computational Linguistics, pp. 1085-1097. , , pp; Rethmeier, N., Augenstein, I., (2021) A Primer on Contrastive Pretraining in Language Processing: Methods, Lessons Learned and Perspectives. Arxiv Preprint Arxiv, 2102, p. 12982; Ribeiro, M.T., Wu, T., Guestrin, C., Singh, S., Beyond accuracy: Behavioral testing of NLP models with checklist (2020) Jurafsky, D., Chai, J., Schluter, N., Tetreault, J.R. (Eds.) Proceedings of the 58Th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online, 5–10 July 2020, Pp. 4902–4912. Association for Computational Linguistics, , https://www.aclweb.org/anthology/2020.acl-main.442/; Santurkar, S., Tsipras, D., Ilyas, A., Madry, A., (2018) How Does Batch Normalization Help Optimization? In: Advances in Neural Information Processing Systems, pp. 2483-2493. , , pp; Saunshi, N., Plevrakis, O., Arora, S., Khodak, M., Khandeparkar, H., A theoretical analysis of contrastive unsupervised representation learning (2019) Proceedings of the 36Th International Conference on Machine Learning, 97, pp. 5628-5637. , http://proceedings.mlr. press/v97/saunshi19a.html, , vol., pp. , PMLR, 9–15 June, Long Beach, California, USA; Shen, S., Yao, Z., Gholami, A., Mahoney, M.W., Keutzer, K., PowerNorm: Rethinking batch normalization in transformers (2020) The Proceedings of the International Conference on Machine Learning (ICML); Tian, Y., Krishnan, D., Isola, P.: Contrastive multiview coding. CoRR abs/1906.05849 (2019). arxiv:1906.05849; Wang, A., Singh, A., Michael, J., Hill, F., Levy, O., Bowman, S.R., GLUE: A multi-task benchmark and analysis platform for natural language understanding (2019) 7Th International Conference on Learning Representations, ICLR 2019. Open-Review.Net, , https://openreview.net/forum?id=rJ4km2R5t7; Wang, T., Isola, P., (2020) Understanding Contrastive Representation Learning through Alignment and Uniformity on the Hypersphere. Arxiv Preprint Arxiv, 2005, p. 10242; Wei, X., Hu, Y., Weng, R., Xing, L., Yu, H., Luo, W., (2020) On Learning Universal Representations across Languages. Arxiv Preprint Arxiv, 2007, p. 15960; Wen, Y., Li, S., Jia, K., (2019) Towards Understanding the Regularization of Adversarial Robustness on Neural Networks; Wu, Z., Xiong, Y., Yu, S.X., Lin, D., Unsupervised feature learning via non-parametric instance discrimination (2018) 2018 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2018, Pp. 3733–3742. IEEE Computer Society; Wu, Z., Wang, S., Gu, J., Khabsa, M., Sun, F., Ma, H., (2020) CLEAR: Contrastive Learning for Sentence Representation. Arxiv Preprint Arxiv, 2012, p. 15466; Xiong, L., (2020) Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval. Arxiv Preprint Arxiv, 2007, p. 00808; Ye, H., (2020) Contrastive Triple Extraction with Generative Transformer. Arxiv Preprint Arxiv, 2009, p. 06207; Ye, M., Zhang, X., Yuen, P.C., Chang, S., Unsupervised embedding learning via invariant and spreading instance feature (2019) IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2019, Pp. 6210–6219. Computer Vision Founda-Tion/Ieee","Zhang, N.; Zhejiang University & AZFT Joint Lab for Knowledge EngineChina; 电子邮件: zhangningyu@zju.edu.cn",Fang L.Chen Y.Zhai G.Wang J.Wang R.Dong W.,,Springer Science and Business Media Deutschland GmbH,"1st CAAI International Conference on Artificial Intelligence, CICAI 2021",5 June 2021 through 6 June 2021,,270479,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85122563577
"Luo J., Guo J., Qiu W., Huang Z., Hui H.",57305262600;56589265100;8284570700;55494527200;7005913289;,Scale Invariant Domain Generalization Image Recapture Detection,2021,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),13111 LNCS,,,75,86,,,10.1007/978-3-030-92273-3_7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121924872&doi=10.1007%2f978-3-030-92273-3_7&partnerID=40&md5=ffc400cec79c3ae875b81f0dde3fccb4,"Institute of Cyber Science and Technology, Shanghai Jiao Tong University, 800 Dongchuan Road, Shanghai, 200240, China; School of Cyber Science and Engineering, Shanghai Jiao Tong University, 800 Dongchuan Road, Shanghai, 200240, China","Luo, J., Institute of Cyber Science and Technology, Shanghai Jiao Tong University, 800 Dongchuan Road, Shanghai, 200240, China; Guo, J., School of Cyber Science and Engineering, Shanghai Jiao Tong University, 800 Dongchuan Road, Shanghai, 200240, China; Qiu, W., School of Cyber Science and Engineering, Shanghai Jiao Tong University, 800 Dongchuan Road, Shanghai, 200240, China; Huang, Z., School of Cyber Science and Engineering, Shanghai Jiao Tong University, 800 Dongchuan Road, Shanghai, 200240, China; Hui, H., Institute of Cyber Science and Technology, Shanghai Jiao Tong University, 800 Dongchuan Road, Shanghai, 200240, China","Recapturing and rebroadcasting of images are common attack methods in insurance frauds and face identification spoofing, and an increasing number of detection techniques were introduced to handle this problem. However, most of them ignored the domain generalization scenario and scale variances, with an inferior performance on domain shift situations, and normally were exacerbated by intra-domain and inter-domain scale variances. In this paper, we propose a scale alignment domain generalization framework (SADG) to address these challenges. First, an adversarial domain discriminator is exploited to minimize the discrepancies of image representation distributions among different domains. Meanwhile, we exploit triplet loss as a local constraint to achieve a clearer decision boundary. Moreover, a scale alignment loss is introduced as a global relationship regularization to force the image representations of the same class across different scales to be undistinguishable. Experimental results on four databases and comparison with state-of-the-art approaches show that better performance can be achieved using our framework. © 2021, Springer Nature Switzerland AG.",Domain generalization; Image processing and computer vision; Recapture detection; Scale variance,Computer vision; Attack methods; Domain generalization; Generalisation; Image processing and computer vision; Image representations; Insurance frauds; Performance; Recapture detection; Scale variance; Scale-invariant; Image representation,,,,,"Agarwal, S., Fan, W., Farid, H., A diverse large-scale dataset for evaluating rebroadcast attacks (2018) 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Pp. 1997–2001. IEEE; Anjum, A., Islam, S., Recapture detection technique based on edge-types by analysing high-frequency components in digital images acquired through LCD screens (2019) Multimedia Tools Appl, pp. 1-21; Awati, C., Alzende, N.H., Classification of singly captured and recaptured images using sparse dictionaries (2017) Int. J., 5 (7); Cao, H., Kot, A.C., Identification of recaptured photographs on LCD screens (2010) 2010 IEEE International Conference on Acoustics, Speech and Signal Processing, Pp. 1790–1793. IEEE; Choi, H.-Y., Jang, H.-U., Son, J., Kim, D., Lee, H.-K., (2017) Content Recapture Detection Based on Convolutional Neural Networks, 424, pp. 339-346. , https://doi.org/10.1007/978-981-10-4154-940, In: Kim, K., Joukov, N. (eds.) ICISA 2017. LNEE, vol., pp., Springer, Singapore; Dou, Q., Castro, D.C., Kamnitsas, K., Glocker, B., Domain generalization via model-agnostic learning of semantic features (2019) Advances in Neural Information Processing Systems (Neurips), 32. , vol., Vancouver, BC, Canada; Farid, H., Lyu, S., Higher-order wavelet statistics and their application to digital forensics (2003) 2003 Conference on Computer Vision and Pattern Recognition Workshop, Vol. 8, Pp. 94–94. IEEE; Ganin, Y., Lempitsky, V., Unsupervised domain adaptation by backpropagation (2015) International Conference on Machine Learning, pp. 1180-1189. , pp., PMLR; Gao, X., Ng, T.T., Qiu, B., Chang, S.F., Single-view recaptured image detection based on physics-based features (2010) 2010 IEEE International Conference on Multimedia and Expo, pp. 1469-1474. , pp., IEEE; Gluckman, J., Scale variant image pyramids (2006) 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR 2006), Vol. 1, Pp. 1069–1075. IEEE; Hong, C., (2011) Statistical Image Source Model Identification and Forgery Detection, , Ph.D. thesis; Jia, Y., Zhang, J., Shan, S., Chen, X., Single-side domain generalization for face anti-spoofing (2020) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 8484-8493. , pp; Li, H., Wang, S., Kot, A.C., Image recapture detection with convolutional and recurrent neural networks (2017) Electron. Imaging, 2017 (7), pp. 87-91; Li, J., Wu, G.: Image recapture detection through residual-based local descriptors and machine learning. In: Sun, X., Chao, H.-C., You, X., Bertino, E. (eds.) ICCCS 2017. LNCS, vol. 10603, pp. 653–660. Springer, Cham (2017). https://doi.org/10. 1007/978-3-319-68542-7 56; Li, R., Ni, R., Zhao, Y.: An effective detection method based on physical traits of recaptured images on LCD screens. In: Shi, Y.-Q., Kim, H.J., Pérez-González, F., Echizen, I. (eds.) IWDW 2015. LNCS, vol. 9569, pp. 107–116. Springer, Cham (2016). https://doi.org/10.1007/978-3-319-31960-5 10; Muammar, H., Dragotti, P.L., An investigation into aliasing in images recaptured from an LCD monitor using a digital camera (2013) 2013 IEEE International Conference on Acoustics, Speech and Signal Processing, Pp. 2242–2246. IEEE; Noord, N.V., Postma, E., Learning scale-variant and scale-invariant features for deep image classification (2017) Pattern Recogn, 61, pp. 583-592; Pan, S.J., Yang, Q., A survey on transfer learning (2010) IEEE Trans. Knowl. Data Eng., 22 (10), pp. 1345-1359; Park, D., Ramanan, D., Fowlkes, C.: Multiresolution models for object detection. In: Daniilidis, K., Maragos, P., Paragios, N. (eds.) ECCV 2010. LNCS, vol. 6314, pp. 241–254. Springer, Heidelberg (2010). https://doi.org/10.1007/978-3-642-15561-1 18; Shao, R., Lan, X., Li, J., Yuen, P.C., Multi-adversarial discriminative deep domain generalization for face presentation attack detection (2019) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition; Sun, Y., Shen, X., Lv, Y., Liu, C., Recaptured image forensics algorithm based on multi-resolution wavelet transformation and noise analysis (2018) Int. J. Pattern Recog-Nit. Artif. Intell., 32 (2); Thongkamwitoon, T., Muammar, H., Dragotti, P.L., An image recapture detection algorithm based on learning dictionaries of edge profiles (2015) IEEE Trans. Inf. Forensics Secur., 10 (5), pp. 953-968; Torralba, A., Efros, A.A., Unbiased look at dataset bias (2011) CVPR 2011, Pp. 1521–1528. IEEE; Yang, P., Li, R., Ni, R., Zhao, Y.: Recaptured image forensics based on quality aware and histogram feature. In: Kraetzer, C., Shi, Y.-Q., Dittmann, J., Kim, H.J. (eds.) IWDW 2017. LNCS, vol. 10431, pp. 31–41. Springer, Cham (2017). https://doi.org/10.1007/978-3-319-64185-0 3; Yang, P., Ni, R., Zhao, Y.: Recapture image forensics based on Laplacian convolutional neural networks. In: Shi, Y.Q., Kim, H.J., Perez-Gonzalez, F., Liu, F. (eds.) IWDW 2016. LNCS, vol. 10082, pp. 119–128. Springer, Cham (2017). https://doi. org/10.1007/978-3-319-53465-7 9; Yin, J., Fang, Y., Markov-based image forensics for photographic copying from printed picture (2012) Proceedings of the 20Th ACM International Conference on Multimedia, pp. 1113-1116. , pp; Zhu, N., Li, Z.: Recaptured image detection through enhanced residual-based correlation coefficients. In: Sun, X., Pan, Z., Bertino, E. (eds.) ICCCS 2018. LNCS, vol. 11068, pp. 624–634. Springer, Cham (2018). https://doi.org/10.1007/978-3-030-00021-9 55","Guo, J.; School of Cyber Science and Engineering, 800 Dongchuan Road, China; 电子邮件: guojie@sjtu.edu.cn",Mantoro T.Lee M.Ayu M.A.Wong K.W.Hidayanto A.N.,,Springer Science and Business Media Deutschland GmbH,"28th International Conference on Neural Information Processing, ICONIP 2021",8 December 2021 through 12 December 2021,,269629,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85121924872
"Zhao C., Li H.",57220883619;36696835700;,Condition-Invariant Physical Adversarial Attacks via Pixel-Wise Adversarial Learning,2021,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),13109 LNCS,,,369,380,,,10.1007/978-3-030-92270-2_32,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121918372&doi=10.1007%2f978-3-030-92270-2_32&partnerID=40&md5=a7988c723565ca8a4961e280d31e3c6d,"Department of Automation, Shanghai Jiao Tong University, Shanghai, China; SPEIT, Shanghai Jiao Tong University, Shanghai, China","Zhao, C., Department of Automation, Shanghai Jiao Tong University, Shanghai, China; Li, H., Department of Automation, Shanghai Jiao Tong University, Shanghai, China, SPEIT, Shanghai Jiao Tong University, Shanghai, China","Research has validated that deep neural networks are vulnerable to a series of methods named adversarial attacks. Such methods greatly impair performance of target networks by manipulating data with perturbations imperceptible to human. However, digital adversarial examples are vulnerable to various physical disturbances, while existing physical attack methods are strictly condition-variant and cannot generate adversarial data maintaining effectiveness with unforeseen disturbances. In this paper, we propose a physical adversarial attack method named Pixel-wise Adversarial Learning in Physical Attacks (P-ALPhA) to generate effective condition-invariant adversarial examples. Each adversarial example is decoupled into two separate clusters of pixels. Pixels in the first cluster are perturbed for adversarial purposes, while pixels in the second cluster are manipulated with a competitive optimization criterion against the adversarial aim. ALPhA enhances aggressiveness of the first cluster of pixels through intra-competition. Moreover, the original benign optimizations on the second cluster of pixels guide stochastic environmental disturbances to have adversarial impacts on the data. Experimental results show that P-ALPhA greatly enhances effectiveness of digital adversarial examples in establishments or simulations of multiple physical conditions. Success of P-ALPhA increases hazardness of adversarial attacks in physical applications of neural networks. © 2021, Springer Nature Switzerland AG.",Adversarial attack; Adversarial learning; Physical attack,Deep neural networks; Stochastic systems; Adversarial attack; Adversarial learning; Attack methods; Condition; Optimisations; Optimization criteria; Performance; Physical attacks; Physical disturbance; Stochastics; Pixels,,,,,"Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples. Arxiv Preprint Arxiv, 1412, p. 6572; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks. Arxiv Preprint Arxiv, 1706, p. 06083; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) 2016 IEEE European Symposium on Security and Privacy (EuroS&P), Pp. 372–387. IEEE; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP), Pp. 39–57. IEEE; Inkawhich, N., Wen, W., Li, H.H., Chen, Y., Feature space perturbations yield more transferable adversarial examples (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 7066-7074. , pp; Inkawhich, N., Liang, K.J., Carin, L., Chen, Y., (2020) Transferable Perturbations of Deep Feature Distributions. Arxiv Preprint Arxiv, 2004, p. 12519; Szegedy, C., (2013) Intriguing Properties of Neural Networks. Arxiv Preprint Arxiv, 1312, p. 6199; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World. Arxiv Preprint Arxiv, 1607, p. 02533; Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P., DeepFool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582. , pp; Su, J., Vargas, D.V., Sakurai, K., One pixel attack for fooling deep neural networks (2019) IEEE Trans. Evol. Comput., 23 (5), pp. 828-841; Athalye, A., Engstrom, L., Ilyas, A., Kwok, K., Synthesizing robust adversarial examples (2018) International Conference on Machine Learning, pp. 284-293. , pp., PMLR; Komkov, S., Petiushko, A., (2019) Advhat: Real-World Adversarial Attack on Arcface Face ID System. Arxiv Preprint Arxiv, 1908, p. 08705; Brown, T.B., Mané, D., Roy, A., Abadi, M., Gilmer, J., (2017) Adversarial Patch. Arxiv Preprint Arxiv, 1712, p. 09665; Zhao, Y., Zhu, H., Liang, R., Shen, Q., Zhang, S., Chen, K., (2018) Seeing isn’t Believing: Practical Adversarial Attack against Object Detectors. Arxiv Preprint Arxiv, 1812, p. 10217; Thys, S., van Ranst, W., Goedemé, T., Fooling automated surveillance cameras: Adversarial patches to attack person detection (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., A general framework for adversarial examples with objectives (2019) ACM Trans. Priv. Secur. (TOPS), 22 (3), pp. 1-30; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540. , pp; Mahendran, A., Vedaldi, A., Understanding deep image representations by inverting them (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 5188-5196. , pp; Geiger, A., Lenz, P., Urtasun, R., Are we ready for autonomous driving? The KITTI vision benchmark suite (2012) 2012 IEEE Conference on Computer Vision and Pattern Recognition, Pp. 3354–3361. IEEE; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778. , pp; Chen, S., He, Z., Sun, C., Yang, J., Huang, X., Universal adversarial attack on attention and the resulting dataset damagenet (2020) IEEE Trans. Pattern Anal. Mach. Intell.; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-Scale Image Recognition. Arxiv Preprint Arxiv, 1409, p. 1556","Li, H.; Department of Automation, China; 电子邮件: haoli@sjtu.edu.cn",Mantoro T.Lee M.Ayu M.A.Wong K.W.Hidayanto A.N.,,Springer Science and Business Media Deutschland GmbH,"28th International Conference on Neural Information Processing, ICONIP 2021",8 December 2021 through 12 December 2021,,269629,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,,Scopus,2-s2.0-85121918372
"Fan Y., Li Y., Cui H., Yang H., Zhang Y., Wang W.",57218847424;57224744826;57192212989;57207949350;57214252546;57272010000;,An Intrusion Detection Framework for IoT Using Partial Domain Adaptation,2021,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),13005 LNCS,,,36,50,,,10.1007/978-3-030-89137-4_3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118117887&doi=10.1007%2f978-3-030-89137-4_3&partnerID=40&md5=3883635e03fa81bac0bb8c8ebb45154f,"Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China","Fan, Y., Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China, School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; Li, Y., Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China, School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; Cui, H., Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Yang, H., Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Zhang, Y., Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China, School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; Wang, W., Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China, School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China","With the rapid development of the Internet of Things (IoT), the security problem of IoT is becoming increasingly prominent. Deep learning (DL) has achieved success in network intrusion detection systems (NIDS) for IoT. Its capability of automatically extracting high-dimensional features from data and finding the association between data make it easy to identify abnormal activity from network traffic. However, DL method requires a large amount of labeled data, which is very time-consuming and expensive. Due to the privacy of IoT data, it is hard to collect enough data to train models. Also, the heterogeneity of IoT makes the NID model trained from the data collected from one IoT unable to be directly applied to another one. To address the problem, domain adaptation (DA) has been used by transferring the knowledge from the domain with huge amounts of labeled data to the domain with less or unlabeled data. However, previous DA methods generally assume the same label spaces between source and target domain, which is not feasible in a complex real environment of IoT. In this paper, we propose a NID framework using a weighted adversarial nets-based partial domain adaptation method to address this problem of inconsistent label spaces by mapping two domains to a domain-invariant feature space. The proposal can train a highly accurate NID model through the knowledge transfer from the abundant public labeled dataset of the traditional Internet to the unlabeled dataset of IoT. In addition, the proposed scheme can detect unknown attacks in the IoT with the help of knowledge from the traditional Internet. Moreover, the proposed scheme is an online NID detection which is more suitable for real IoT application. The experiments results demonstrate that our proposed scheme can achieve a good performance to detect attacks. © 2021, Springer Nature Switzerland AG.",Intrusion detection; IoT; Partial domain adaptation,Deep learning; Internet of things; Knowledge management; Adaptation methods; Detection framework; Domain adaptation; In networks; Intrusion-Detection; Label space; Labeled data; Network intrusion detection systems; Partial domain adaptation; Security problems; Intrusion detection,,,,,"Gubbi, J., Buyya, R., Marusic, S., Palaniswami, M., Internet of Things (IoT): A vision, architectural elements, and future directions (2013) Futur. Gener. Comput. Syst., 29 (7), pp. 1645-1660; Chaabouni, N., Network intrusion detection for IoT security based on learning techniques (2019) IEEE Commun. Surv. Tutor., 21 (3), pp. 2671-2701; Tavallaee, M., Bagheri, E., Lu, W., Ghorbani, A.A., A detailed analysis of the KDD CUP 99 data set (2009) Proceedings of the Second IEEE Symposium on Computational Intelligence for Security and Defence Applications, pp. 1-6. , pp; Lippmann, R., Haines, J.W., Fried, D.J., Korba, J., Das, K., DARPA off-line intrusion detection evaluation (2000) Comput. Netw., 34 (4), pp. 579-595; Bostani, H., Sheikhan, M., Hybrid of anomaly-based and specification-based IDS for Internet of Things using unsupervised OPF based on MapReduce approach (2017) Comput. Commun., 98, pp. 52-71; Pajouh, H.H., A two-layer dimension reduction and two-tier classification model for anomaly-based intrusion detection in IoT backbone networks (2016) IEEE Trans. Emerg. Top. Comput., 7, pp. 314-323; Lopez-Martin, M., Carro, B., Sanchez-Esguevillas, A., Lloret, J., Conditional vari-ational autoencoder for prediction and feature recovery applied to intrusion detection in IoT (2017) Sensors, 17 (9), p. 1967; Mirsky, Y., Doitshman, T., Elovici, Y., Shabtai, A., (2018) Kitsune: An Ensemble of Autoencoders for Online Network Intrusion Detection. Arxiv Preprint Arxiv, 1802, p. 09089; Hodo, E., Threat analysis of IoT networks using artificial neural network intrusion detection system (2016) 2016 International Symposium on Networks, Computers and Communications (ISNCC), Pp. 1–6. IEEE; Zhao, J., Shetty, S., Pan, J.W., Feature-based transfer learning for network security (2017) MILCOM 2017-2017 IEEE Military Communications Conference; Zhao, J., Shetty, S., Pan, J.W., Kamhoua, C., Kwiat, K., Transfer learning for detecting unknown network attacks. EURASIP J. Inf. Secur. 2019 (2019) Article No, p. 1; Singla, A., Bertino, E., Verma, D., Preparing network intrusion detection deep learning models with minimal data using adversarial domain adaptation (2020) The 15Th ACM Asia Conference on Computer and Communications Security, pp. 127-140. , pp; Pan, S.J., Yang, Q., A survey on transfer learning (2009) IEEE Trans. Knowl. Data Eng., 22 (10), pp. 1345-1359; Wang, M., Deng, W., Deep visual domain adaptation: A survey (2018) Neurocomputing, 312, pp. 135-153; Tzeng, E., Hoffman, J., Zhang, N., Saenko, K., Darrell, T., (2014) Deep Domain Confusion: Maximizing for Domain Invariance, , arXiv preprint arXiv; Ben-David, S., A theory of learning from different domains (2010) Mach. Learn., 79 (1), pp. 151-175; Sun, B., Saenko, K.: Deep CORAL: correlation alignment for deep domain adaptation. In: Hua, G., Jégou, H. (eds.) ECCV 2016. LNCS, vol. 9915, pp. 443–450. Springer, Cham (2016). https://doi.org/10.1007/978-3-319-49409-8 35; Fan, C., A review of deep domain adaptation: General situation and complex situation (2020) Acta Automatica Sinica, 46, pp. 1-34; Zhang, J., Ding, Z.W., Li, W.Q., Ogunbona, P., Importance weighted adversarial nets for partial domain adaptation (2018) IEEE Conference on Computer Vision and Pattern Recognition; Ganin, Y., Domain-adversarial training of neural networks (2016) J. Mach. Learn. Res., 17 (1), pp. 2096-2030; Goodfellow, I., Generative adversarial nets (2014) Advances in Neural Information Processing Systems; Sharafaldin, I., Habibi Lashkari, A., Ghorbani, A.A., Toward generating a new intrusion detection dataset and intrusion traffic characterization (2018) 4Th International Conference on Information Systems Security and Privacy (ICISSP); Palatucci, M., Pomerleau, D., Hinton, G.E., Mitchell, T.M., Zero-shot learning with semantic output codes (2009) 23Rd Annual Conference on Neural Information Processing Systems, pp. 1401-1408. , pp","Fan, Y.; Institute of Information Engineering, China; 电子邮件: fanyulin@iie.ac.cn",Lu W.Sun K.Yung M.Liu F.,,Springer Science and Business Media Deutschland GmbH,"3rd International Conference on Science of Cyber Security, SciSec 2021",13 August 2021 through 15 August 2021,,266909,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,,Scopus,2-s2.0-85118117887
"Xie N., Wan X.",57263770800;57263400700;,Residual Vector Capsule: Improving Capsule by Pose Attention,2021,IEEE Access,9,,,129626,129634,,,10.1109/ACCESS.2021.3113176,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115187885&doi=10.1109%2fACCESS.2021.3113176&partnerID=40&md5=4032949990dfa2966721995ae034b345,"School of Printing and Packaging, Wuhan University, Wuhan, China","Xie, N., School of Printing and Packaging, Wuhan University, Wuhan, China; Wan, X., School of Printing and Packaging, Wuhan University, Wuhan, China","The convolutional neural network has significantly improved the accuracy of image recognition; however, it performs in a fragile manner when we apply viewpoint transformation or add noise to the image. Recent studies have proposed new neural networks named capsule. Capsule build the part-whole relationship in the entity through instantiation parameters, and they cluster instantiation parameters layer by layer through routing-by-agreement; therefore, capsule has stronger representational ability and robustness than convolutional neural networks. However, the routing-by-agreement of the capsule network is limited by the prior probability assumption, which performs in an unstable way in recognition accuracy and robustness. To remove the restriction of the prior probability assumption in the routing-by-agreement, we propose a new capsule named the residual vector capsule (RVC), which constructs the routing-by-agreement with self-attention. The experimental results show that compared with other capsule networks, RVC achieves competitive classification accuracy on MNIST, Fashion-MNIST, CIFAR-10 and SVHN, improves the viewpoint invariance of the model on SmallNorb, and significantly improves the robustness of the model against white box attacks on CIFAR-10 and SVHN. © 2013 IEEE.",adversarial robustness; Capsule network; self attention; viewpoint invariance,Convolution; Convolutional neural networks; Image enhancement; Image recognition; Network routing; Classification accuracy; Layer by layer; Prior probability; Recognition accuracy; Residual vectors; Viewpoint transformation; White box; Multilayer neural networks,,,,,"Lowe, D.G., Distinctive image features from scale-invariant keypoints (2004) Int. J. Comput. Vis, 60 (2), pp. 91-110. , Nov; Bay, H., Tuytelaars, T., Van Gool, L., SURF: Speeded up robust features in (2006) Computer Vision ECCV, pp. 404-417; Sabour, S., Frosst, N., Hinton, G.E., Dynamic routing between capsules in (2017) Proc. Adv. Neural Inf. Process. Syst, pp. 3856-3866; Hinton, G.E., Sabour, S., Frosst, N., Matrix capsules withEMrouting in (2018) Proc. Int. Conf. Learn. Represent, pp. 1-15; Hubert Tsai, Y.-H., Srivastava, N., Goh, H., Salakhutdinov, R., Capsules with inverted dot-product attention routing (2020) arXiv:2002 04764, , http://arxiv.org/abs/2002.04764; Hahn, T., Pyeon, M., Kim, G., Self-routing capsule networks in (2019) Proc. Adv. Neural Inf. Process. Syst, pp. 7658-7667; Ahmed, K., Torresani, L., STAR-caps: Capsule networks with straightthrough attentive routing in (2019) Proc. Adv. Neural Inf. Process. Syst, pp. 9101-9110; De, S.R.F., Leontidis, G., Kollias, S., Capsule routing via variational Bayes in (2020) Proc. 34th AAAI Conf. Artif. Intell, pp. 3749-3756; Kosiorek, A.R., Sabour, S., Teh, Y.W., Hinton, G.E., Stacked capsule autoencoders in (2019) Proc. Adv. Neural Inf. Process. Syst, pp. 15512-15522; Gu, J., Tresp, V., Interpretable graph capsule networks for object recognition in (2020) Proc. 34th AAAI Conf. Artif. Intell, pp. 1-9; Wang, X., Girshick, R., Gupta, A., He, K., Non-local neural networks in (2018) Proc IEEE/CVF Conf. Comput. Vis. Pattern Recognit, pp. 7794-7803. , Jun; Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez Kaiser, A.N., Polosukhin, I., Attention is all you need in (2017) Proc. Adv. Neural Inf. Process. Syst, pp. 5998-6008; Zhang, H., Dana, K., Shi, J., Zhang, Z., Wang, X., Tyagi, A., Agrawal, A., Context encoding for semantic segmentation in (2018) Proc IEEE/CVF Conf. Comput. Vis. Pattern Recognit, pp. 7151-7160. , Jun; Fu, J., Liu, J., Tian, H., Li, Y., Bao, Y., Fang, Z., Lu, H., Dual attention network for scene segmentation in (2019) Proc IEEE/CVF Conf. Comput. Vis. Pattern Recognit. CVPR, pp. 3146-3154. , Jun; Chi, L., Yuan, Z., Mu, Y., Wang, C., Non-local neural networks with grouped bilinear attentional transforms in (2020) Proc IEEE/CVF Conf. Com-put. Vis. Pattern Recognit. (CVPR, , Jun; Geirhos, R., Temme, C.R.M., Rauber, J., Schött, H.H., Bethge, M., Wichmann, F.A., Generalisation in humans and deep neural networks in (2018) Proc. Adv. Neural Inf. Process. Syst; Engstrom, L., Tran, B., Tsipras, D., Schmidt, L., Madry, A., Exploring the landscape of spatial robustness in (2019) Proc. 36th Int. Conf. Mach. Learn; Ian Goodfellow, J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples in (2015) Proc. 5th Int. Conf. Learn. Represent, , May; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2016) arXiv:1607 02533, , http://arxiv.org/abs/1607.02533; Wu, W., Su, Y., Chen, X., Zhao, S., King, I., Lyu, M.R., Tai, Y.-W., Boosting the transferability of adversarial samples via attention in (2020) Proc IEEE/CVF Conf. Comput. Vis. Pattern Recognit. CVPR, pp. 1158-1167. , Jun; Pang, T., Du, C., Zhu, J., Max-mahalanobis linear discriminant analysis networks in (2018) Proc. 35th Int. Conf. Mach. Learn, pp. 4016-4025; Rajasegaran, J., Jayasundara, V., Jayasekara, S., Jayasekara, H., Seneviratne, S., Rodrigo, R., DeepCaps: Going deeper with capsule networks in (2019) Proc IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR, , Jun; He, K., Zhang, X., Ren, S., Sun, J., Identity mappings in deep residual networks (2016) arXiv:1603 05027, , http://arxiv.org/abs/1603.05027; Radosavovic, I., Kosaraju, R.P., Girshick, R., He, K., Dollár, P., Designing network design spaces in (2020) Proc IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR, , Jun; Tan, M., Le, Q., EfficientNet: Rethinking model scaling for convolutional neural networks in (2019) Proc. 36th Int. Conf. Mach. Learn; Hinton, G., How to represent part-whole hierarchies in a neural network 2021 arXiv:2102 12627, , http://arxiv.org/abs/2102.12627; Kim, H., Papamakarios, G., Mnih, A., The Lipschitz constant of self-Attention (2020) arXiv:2006 04710, , http://arxiv.org/abs/2006.04710","Wan, X.; School of Printing and Packaging, China; 电子邮件: wan@whu.edu.cn",,,Institute of Electrical and Electronics Engineers Inc.,,,,,21693536,,,,English,IEEE Access,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85115187885
"Ye N., Tang J., Deng H., Zhou X.-Y., Li Q., Li Z., Yang G.-Z., Zhu Z.",57202057254;57419281900;57419813900;57190124424;57200083741;55707052900;57211728432;57200340512;,Adversarial invariant learning,2021,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,,,,12441,12449,,,10.1109/CVPR46437.2021.01226,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113869527&doi=10.1109%2fCVPR46437.2021.01226&partnerID=40&md5=fb6071124657b1cf83dfcd163c42d4ea,"Shanghai Jiao Tong University, Shanghai, China; Peking University, Beijing, China; PAH Inc, Rockville, United States; National University of Singapore, Singapore; Huawei Noah's Ark Lab, Hong Kong","Ye, N., Shanghai Jiao Tong University, Shanghai, China; Tang, J., Peking University, Beijing, China; Deng, H., Shanghai Jiao Tong University, Shanghai, China; Zhou, X.-Y., PAH Inc, Rockville, United States; Li, Q., National University of Singapore, Singapore; Li, Z., Huawei Noah's Ark Lab, Hong Kong; Yang, G.-Z., Shanghai Jiao Tong University, Shanghai, China; Zhu, Z., Peking University, Beijing, China","Though machine learning algorithms are able to achieve pattern recognition from the correlation between data and labels, the presence of spurious features in the data decreases the robustness of these learned relationships with respect to varied testing environments. This is known as out-of-distribution (OoD) generalization problem. Recently, invariant risk minimization (IRM) attempts to tackle this issue by penalizing predictions based on the unstable spurious features in the data collected from different environments. However, similar to domain adaptation or domain generalization, a prevalent non-trivial limitation in these works is that the environment information is assigned by human specialists, i.e. a priori, or determined heuristically. However, an inappropriate group partitioning can dramatically deteriorate the OoD generalization and this process is expensive and time-consuming. To deal with this issue, we propose a novel theoretically principled min-max framework to iteratively construct a worst-case splitting, i.e. creating the most challenging environment splittings for the backbone learning paradigm (e.g. IRM) to learn the robust feature representation. We also design a dijferentiable training strategy to facilitate the feasible gradient-based computation. Numerical experiments show that our algorithmic framework has achieved superior and stable performance in various datasets, such as Colored MNIST and Punctuated Stanford sentiment treebank (SST). Furthermore, we also find our algorithm to be robust even to a strong data poisoning attack. To the best of our knowledge, this is one of the first to adopt differentiable environment splitting method to enable stable predictions across environments without environment index information, which achieves the state-of-the-art performance on datasets with strong spurious correlation, such as Colored MNIST. © 2021 IEEE",,Computer vision; Learning algorithms; Machine learning; Domain adaptation; Environment information; Generalisation; Invariant learning; Machine learning algorithms; Non-trivial; Prediction-based; Risk minimization; Spurious features; Testing environment; Iterative methods,,,,,"Ahuja, K., Shanmugam, K., Varshney, K.R., Dhurandhar, A., (2020) Invariant Risk Minimization Games, , 5; Systematic generalisation with group invariant predictions (2021) Submitted to International Conference on Learning Representations, , Anonymous. under review. 12; Arjovsky, M., Bottou, L., Gulrajani, I., Lopez-Paz, D., (2019) Invariant Risk Minimization, , 2,3, 5, 6,12, 13; Bai, H., Sun, R., Hong, L., Zhou, F., Ye, N., Ye, H.-J., Chan, S.H.G., Li, Z., (2020) Decaug: Out-of-Distribution Generalization Via Decomposed Feature Representation and Semantic Augmentation, , 13; Carlucci, F.M., D'Innocente, A., Bucci, S., Caputo, B., Tommasi, T., Domain generalization by solving jigsaw puzzles (2019) 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2224-2233. , 2; Carlucci, F.M., D'Innocente, A., Bucci, S., Caputo, B., Tommasi, T., Domain generalization by solving jigsaw puzzles (2019) CVPR, , 6,13; Cartwright, N., Two theorems on invariance and causality (2003) Philosophy of Science, 70, pp. 203-224. , 5; Choe, Y.J., Ham, J., Park, K., (2020) An Empirical Study of Invariant Risk Minimization, , 7; Dou, Q., Castro, D.C., Kamnitsas, K., Glocker, B., Domain generalization via model-agnostic learning of semantic features (2019) NeurlPS, , 2, 13; Gulrajani, I., Lopez-Paz, D., (2020) In Search of Lost Domain Generalization, , 8,12; Gururangan, S., Swayamdipta, S., Levy, O., Schwartz, R., Bowman, S., Smith, N.A., Annotation artifacts in natural language inference data (2018) Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers), pp. 107-112. , New Orleans, Louisiana, June Association for Computational Linguistics. 7; Huang, Z., Wang, H., Xing, E.P., Huang, D., Self-challenging improves cross-domain generalization (2020) ECCV, , 6,12; Jagielski, M., Oprea, A., Biggio, B., Liu, C., Nita-Rotaru, C., Li, B., Manipulating machine learning: Poisoning attacks and countermeasures for regression learning (2018) 2018 IEEE Symposium on Security and Privacy (SP), pp. 19-35. , 7; Johansson, F.D., Sontag, D., Ranganath, R., Support and invertibility in domain-invariant representations (2019) Proceedings of Machine Learning Research, Volume 89 of Proceedings of Machine Learning Research, pp. 527-536. , Kamalika Chaudhuri and Masashi Sugiyama, editors, PMLR, 16-18 Apr 6, 7; Kingma, D.P., Welling, M., (2013) Auto-Encoding Variational Bayes, 2, p. 4; Krueger, D., Caballero, E., Jacobsen, J.-H., Zhang, A., Binas, J., Le Priol, R., Courville, A., (2020) Out-of-Distribution Generalization Via Risk Extrapolation (Rex), , 4, 12, 13; Kuang, K., Xiong, R., Cui, P., Athey, S., Li, B., Stable prediction across unknown environments (2018) Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, , 2, 6, 7; Li, D., Yang, Y., Song, Y.-Z., Timothy, M., (2017) Hospedales. Deeper, Broader and Artier Domain Generalization, , CoRR, abs 13; Mancini, M., Akata, Z., Ricci, E., Caputo, B., Towards recognizing unseen categories in unseen domains (2020) ECCV, , August 2,13; Matsuura, T., Harada, T., (2019) Domain Generalization Using a Mixture of Multiple Latent Domains, , 2; McCoy, T., Pavlick, E., Linzen, T., Right for the wrong reasons: Diagnosing syntactic heuristics in natural language inference (2019) Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pp. 3428-3448. , Florence, Italy, July Association for Computational Linguistics. 7; Niven, T., Kao, H.-Y., Probing neural network comprehension of natural language arguments (2019) Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pp. 4658-4664. , Florence, Italy, July Association for Computational Linguistics. 7; Pearl, J., Glymour, M., Jewell, N., (2016) Causal Inference in Statistics: A Primer, , John Wiley & Sons, 3, 11; Peters, J., Biihlmann, P., Meinshausen, N., (2015) Causal Inference Using Invariant Prediction: Identification and Confidence Intervals, , 2; Recht, B., Roelofs, R., Schmidt, L., Shankar, V., (2019) Do Imagenet Classifiers Generalize to Imagenet?, , CoRR, abs 3; Sagawa, S., Koh, P.W., Hashimoto, T.B., Liang, P., (2019) Distributionally Robust Neural Networks for Group Shifts: On the Importance of Regularization for Worst-Case Generalization, , 2,13; Shafahi, A., Huang, W.R., Najibi, M., Suciu, O., Studer, C., Dumitras, T., Goldstein, T., (2018) Poison Frogs! Targeted Clean-Label Poisoning Attacks on Neural Networks, , CoRR, abs 7; Sinha, A., Namkoong, H., Duchi, J., Certifiable distributional robustness with principled adversarial training (2018) International Conference on Learning Representations, , 6; Zhang, D., Zhang, H., Tang, J., Hua, X., Sun, Q., (2020) Causal Intervention for Weakly-Supervised Semantic Segmentation, , 11","Zhu, Z.; Peking UniversityChina; 电子邮件: zhanxing.zhu@pku.edu.en",,,IEEE Computer Society,"2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2021",19 June 2021 through 25 June 2021,,174911,10636919,9.78E+12,PIVRE,,English,Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit,Conference Paper,Final,,Scopus,2-s2.0-85113869527
"Pony R., Naeh I., Mannor S.",57226118512;14024764600;8218747000;,Over-the-Air Adversarial Flickering Attacks against Video Recognition Networks,2021,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,,,,515,524,,2,10.1109/CVPR46437.2021.00058,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113663317&doi=10.1109%2fCVPR46437.2021.00058&partnerID=40&md5=2fdada6cfcf81ccce312c8734472a233,"Department of Electrical Engineering, Technion Institute of Technology, Haifa, Israel; Rafael - Advanced Defense Systems Ltd., Israel; Nvidia Research","Pony, R., Department of Electrical Engineering, Technion Institute of Technology, Haifa, Israel; Naeh, I., Rafael - Advanced Defense Systems Ltd., Israel; Mannor, S., Department of Electrical Engineering, Technion Institute of Technology, Haifa, Israel, Nvidia Research","Deep neural networks for video classification, just like image classification networks, may be subjected to adversarial manipulation. The main difference between image classifiers and video classifiers is that the latter usually use temporal information contained within the video. In this work we present a manipulation scheme for fooling video classifiers by introducing a flickering temporal perturbation that in some cases may be unnoticeable by human observers and is implementable in the real world. After demonstrating the manipulation of action classification of single videos, we generalize the procedure to make universal adversarial perturbation, achieving high fooling ratio. In addition, we generalize the universal perturbation and produce a temporal-invariant perturbation, which can be applied to the video without synchronizing the perturbation to the input. The attack was implemented on several target models and the transferability of the attack was demonstrated. These properties allow us to bridge the gap between simulated environment and real-world application, as will be demonstrated in this paper for the first time for an over-the-air flickering attack. © 2021 IEEE",,Classification (of information); Computer vision; Deep neural networks; Flickering; Classification networks; Human observers; Image Classifiers; Images classification; Over the airs; Real-world; Temporal information; Temporal perturbations; Video classification; Video recognition; Image classification,,,,,"Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 Ieee Symposium on Security and Privacy (Sp), pp. 39-57. , IEEE, 3; Carreira, J., Zisserman, A., Quo vadis, action recognition? A new model and the kinetics dataset (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 6299-6308. , 1, 2, 4; Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Xiao, C., Prakash, A., Song, D., Robust physical-world attacks on deep learning visual classification (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1625-1634. , 7; Feichtenhofer, C., Fan, H., Malik, J., He, K., Slowfast networks for video recognition (2019) Proceedings of the IEEE International Conference on Computer Vision, pp. 6202-6211. , 1; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations, , 1, 3; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778. , 6; Ilg, E., Mayer, N., Saikia, T., Keuper, M., Dosovitskiy, A., Brox, T., FlowNet 2.0: Evolution of optical flow estimation with deep networks (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2462-2470. , 3; Inkawhich, N., Inkawhich, M., Chen, Y., Li, H., (2018) Adversarial Attacks for Optical Flow-Based Action Recognition Classifiers, , arXiv preprint 1, 3; Ji, S., Xu, W., Yang, M., Yu, K., 3D convolutional neural networks for human action recognition (2013) IEEE Trans. Pattern Anal. Mach. Intell., 35, pp. 221-231. , 2; Jiang, L., Ma, X., Chen, S., Bailey, J., Jiang, Y.-G., (2019) Black-Box Adversarial Attacks on Video Recognition Models, , 1, 3; Kay, W., Carreira, J., Simonyan, K., Zhang, B., Hillier, C., Vijayanarasimhan, S., Viola, F., Natsev, P., (2017) The Kinetics Human Action Video Dataset, , arXiv preprint 2, 5; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, 25, pp. 1097-1105. , F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger, editors, Curran Associates, Inc, 1; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial machine learning at scale (2017) 5th International Conference on Learning Representations, ICLR 2017, , Toulon, France, April 24-26, 2017, Conference Track Proceedings, 3; Li, J., Schmidt, F., Kolter, Z., Adversarial camera stickers: A physical camera-based attack on deep learning systems (2019) International Conference on Machine Learning, pp. 3896-3904. , PMLR, 7; Li, S., Neupane, A., Paul, S., Song, C., Krishnamurthy, S.V., Roy-Chowdhury, A.K., Swami, A., Stealthy adversarial perturbations against real-time video classification systems (2019) 26th Annual Network and Distributed System Security Symposium, NDSS 2019, San Diego, California, USA, February 24-27, 2019, , 3; Litjens, G., Kooi, T., Bejnordi, B.E., Setio, A.A.A., Ciompi, F., Ghafoorian, M., van der Laak, J.A.W.M., Sánchez, C.I., A survey on deep learning in medical image analysis (2017) Medical Image Analysis, 42, pp. 60-88. , 1; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) 2016 IEEE European Symposium on Security and Privacy (EuroS&P), pp. 372-387. , IEEE, 1; Ren, S., He, K., Girshick, R., Sun, J., Faster R-CNN: Towards real-time object detection with region proposal networks (2015) Advances in Neural Information Processing Systems, 28, pp. 91-99. , C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors, Curran Associates, Inc, 1; Rey-De Castro, R., Rabitz, H., (2018) Targeted Nonlinear Adversarial Perturbations in Images and Videos, , arXiv preprint 3; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Bernstein, M., Imagenet large scale visual recognition challenge (2015) International Journal of Computer Vision, 115 (3), pp. 211-252. , 2; Sak, H., Senior, A.W., Beaufays, F., Long short-term memory recurrent neural network architectures for large scale acoustic modeling (2014) INTERSPEECH 2014, 15th Annual Conference of the International Speech Communication Association, Singapore, September 14-18, 2014, pp. 338-342. , 2; Shelhamer, E., Long, J., Darrell, T., Fully convolutional networks for semantic segmentation (2017) IEEE Trans. Pattern Anal. Mach. Intell., 39 (4), pp. 640-651. , 1; Simonyan, K., Zisserman, A., Two-stream convolutional networks for action recognition in videos (2014) Advances in Neural Information Processing Systems, pp. 568-576. , 2; Sultani, W., Chen, C., Shah, M., Real-world anomaly detection in surveillance videos (2018) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , June 1; Sun, Y., Chen, Y., Wang, X., Tang, X., Deep learning face representation by joint identification-verification (2014) Advances in Neural Information Processing Systems, 27, pp. 1988-1996. , Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger, editors, Curran Associates, Inc, 1; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) Computer Vision and Pattern Recognition (CVPR), , 2; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations, , 1, 6, 7; Tran, D., Bourdev, L., Fergus, R., Torresani, L., Paluri, M., Learning spatiotemporal features with 3d convolutional networks (2015) Proceedings of the IEEE International Conference on Computer Vision, pp. 4489-4497. , 2; Tran, D., Wang, H., Torresani, L., Ray, J., LeCun, Y., Paluri, M., A closer look at spatiotemporal convolutions for action recognition (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 6450-6459. , 2, 6; Varol, G., Laptev, I., Schmid, C., Long-term temporal convolutions for action recognition (2017) IEEE Transactions on Pattern Analysis and Machine Intelligence, 40 (6), pp. 1510-1517. , 2; Wang, L., Xu, Y., Cheng, J., Xia, H., Yin, J., Wu, J., Human action recognition by learning spatio-temporal features with deep neural networks (2018) IEEE Access, 6, pp. 17913-17922. , 2; Wang, X., Girshick, R.B., Gupta, A., He, K., Non-local neural networks (2017) 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 7794-7803. , 1; Wei, X., Zhu, J., Yuan, S., Su, H., Sparse adversarial perturbations for videos (2019) The Thirty-Third AAAI Conference on Artificial Intelligence, AAAI 2019, the Thirty-First Innovative Applications of Artificial Intelligence Conference, IAAI 2019, the Ninth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2019, Honolulu, Hawaii, USA, January 27 - February 1, 2019, pp. 8973-8980. , 1, 3; Wei, Z., Chen, J., Wei, X., Jiang, L., Chua, T.-S., Zhou, F., Jiang, Y.-G., Heuristic black-box adversarial attacks on video recognition models (2020) AAAI, pp. 12338-12345. , 1, 3",,,,IEEE Computer Society,"2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2021",19 June 2021 through 25 June 2021,,174911,10636919,9.78E+12,PIVRE,,English,Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85113663317
"Zhang X., Gupta R., Mian A., Rahnavard N., Shah M.",57239266000;57205390094;7006066881;6507969392;7402047527;,Cassandra: Detecting Trojaned Networks from Adversarial Perturbations,2021,IEEE Access,9,,,135856,135867,,,10.1109/ACCESS.2021.3101289,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111581101&doi=10.1109%2fACCESS.2021.3101289&partnerID=40&md5=291d7eb674db6c21606b437a9b1b9f47,"Department of Computer Science, University of Central Florida, Orlando, FL  32816, United States; Center for Research in Computer Vision, University of Central Florida, Orlando, FL  32816, United States; Department of Computer Science and Software Engineering, University of Western Australia, Perth, WA  6009, Australia; Department of Electrical Engineering, University of Central Florida, Orlando, FL  32816, United States","Zhang, X., Department of Computer Science, University of Central Florida, Orlando, FL  32816, United States; Gupta, R., Center for Research in Computer Vision, University of Central Florida, Orlando, FL  32816, United States; Mian, A., Department of Computer Science and Software Engineering, University of Western Australia, Perth, WA  6009, Australia; Rahnavard, N., Department of Electrical Engineering, University of Central Florida, Orlando, FL  32816, United States; Shah, M., Center for Research in Computer Vision, University of Central Florida, Orlando, FL  32816, United States","Deep neural networks are being widely deployed for critical tasks. In many cases, pre-trained models are sourced from vendors who may have disrupted the training pipeline to insert Trojan behaviors. These malicious behaviors can be triggered at the adversary's will, which is a serious security threat. To verify the integrity of a deep model, we propose a method that captures its fingerprint with adversarial perturbations. Inserting backdoors into a network alters its decision boundaries which are effectively encoded by adversarial perturbations. Our proposed Trojan detection network learns features from adversarial patterns and its properties to encode the unknown trigger shape and deviations in the decision boundaries caused by backdoors. Our method works completely without or with limited clean samples for improved performance. Our method also performs anomaly detection to identify the target class of a Trojaned network and is invariant to the trigger type, trigger size, network architecture and does not require any triggered samples. Experiments are performed on MNIST, NIST-TrojAI and Odysseus datasets, with 5000 pre-trained models in total, making this the largest study to date on Trojaned detection and the new state-of-the-art accuracy is achieved. © 2013 IEEE.",adversarial attack; backdoor detection; computer vision; Deep learning,Deep neural networks; Malware; Network architecture; Cassandras; Critical tasks; Decision boundary; Malicious behavior; Security threats; State of the art; Target class; Trojan detections; Anomaly detection,,,,,"Akhtar, N., Liu, J., Mian, A., Defense against universal adversarial perturbations (2018) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., pp. 3389-3398. , Jun; Akhtar, N., Mian, A., Threat of adversarial attacks on deep learning in computer vision: A survey (2018) Ieee Access, 6, pp. 14410-14430; Chen, B., Carvalho, W., Baracaldo, N., Ludwig, H., Edwards, B., Lee, T., Molloy, I., Srivastava, B., (2018) Detecting Backdoor Attacks on Deep Neural Networks by Activation Clustering, , http://arxiv.org/abs/1811.03728, arXiv:1811.03728. [Online]; Chen, H., Fu, C., Zhao, J., Koushanfar, F., DeepInspect: A black-box Trojan detection and mitigation framework for deep neural networks (2019) Proc. 28th Int. Joint Conf. Artif. Intell. Aaai Press, pp. 4658-4664. , Aug; Chen, X., Liu, C., Li, B., Lu, K., Song, D., (2017) Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning, , http://arxiv.org/abs/1712.05526, arXiv:1712.05526.[Online]; Chou, E., Tramèr, F., Pellegrino, G., (2018) SentiNet: Detecting Localized Universal Attacks against Deep Learning Systems, , http://arxiv.org/abs/1812.00292, arXiv:1812.00292.[Online]; Edraki, M., Karim, N., Rahnavard, N., Mian, A., Shah, M., (2020) Odyssey: Creation, Analysis and Detection of Trojan Models, , https://arxiv.org/abs/2007.08142, arXiv:2007.08142. [Online]; Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Xiao, C., Prakash, A., Song, D., Robust physical-world attacks on deep learning visual classification (2018) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., pp. 1625-1634. , Jun; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts, , http://arxiv.org/abs/1703.00410, arXiv:1703.00410. [Online]; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) Proc. 3rd Int. Conf. Learn. Represent. (ICLR), , Y. Bengio and Y. LeCun, Eds. San Diego, CA, USA, May; Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., (2017) On the (Statistical) Detection of Adversarial Examples, , http://arxiv.org/abs/1702.06280, arXiv:1702.06280. [Online]; Gu, T., Liu, K., Dolan-Gavitt, B., Garg, S., BadNets: Evaluating backdooring attacks on deep neural networks (2019) Ieee Access, 7, pp. 47230-47244; Guo, W., Wang, L., Xing, X., Du, M., Song, D., (2019) TABOR: a Highly Accurate Approach to Inspecting and Restoring Trojan Backdoors in Ai Systems, , http://arxiv.org/abs/1908.01763, arXiv:1908.01763. [Online]; Hampel, F.R., The in-uence curve and its role in robust estimation (1974) J. Amer. Statist. Assoc., 69 (346), pp. 383-393; Hendrycks, D., Gimpel, K., (2016) Early Methods for Detecting Adversarial Images, , http://arxiv.org/abs/1608.00530, arXiv:1608.00530. [Online]; Howard, A., Sandler, M., Chen, B., Wang, W., Chen, L.-C., Tan, M., Chu, G., Le, Q., Searching for MobileNetV3 (2019) Proc. IEEE/CVF Int. Conf. Comput. Vis. (ICCV), pp. 1314-1324. , , Oct; Huang, X., Alzantot, M., Srivastava, M., (2019) NeuronInspect: Detecting Backdoors in Neural Networks Via Output Explanations, , http://arxiv.org/abs/1911.07399, arXiv:1911.07399. [Online]; Oseledets, I., Khrulkov, V., Art of singular vectors and universal adversarial perturbations (2018) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit, pp. 8562-8570. , Jun; Kolouri, S., Saha, A., Pirsiavash, H., Hoffmann, H., Universal litmus patterns: Revealing backdoor attacks in CNNs (2020) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 301-310. , Jun; Liao, F., Liang, M., Dong, Y., Pang, T., Hu, X., Zhu, J., Defense against adversarial attacks using high-level representation guided denoiser (2018) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., pp. 1778-1787. , Jun; Liu, K., Dolan-Gavitt, B., Garg, S., Fine-pruning: Defending against backdooring attacks on deep neural networks (2018) Proc. Int. Symp. Res. Attacks, Intrusions, Defenses, pp. 273-294. , Cham, Switzerland: Springer; Liu, Y., Ma, S., Aafer, Y., Lee, W.-C., Zhai, J., Wang, W., Zhang, X., Trojaning attack on neural networks (2018) Proc. Netw. Distrib. Syst. Secur. Symp., San Diego, , CA, USA: The Internet Society; Liu, Y., Mondal, A., Chakraborty, A., Zuzak, M., Jacobsen, N., Xing, D., Srivastava, A., A survey on neural Trojans (2020) Proc. 21st Int. Symp. Qual. Electron. Design (ISQED), , Mar; Lu, J., Issaranon, T., Forsyth, D., SafetyNet: Detecting and rejecting adversarial examples robustly (2017) Proc. Ieee Int. Conf. Comput. Vis. (ICCV), pp. 446-454. , Oct; Meng, D., Chen, H., MagNet: A two-pronged defense against adversarial examples (2017) Proc. Acm Sigsac Conf. Comput. Commun. Secur, pp. 135-147. , Oct; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., On detecting adversarial perturbations (2017) Proc. Int. Conf. Learn. Represent.; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) Proc. Ieee Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 1765-1773. , , Jul; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., DeepFool: A simple and accurate method to fool deep neural networks (2016) Proc. Ieee Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 2574-2582. , Jun; Mopuri, K.R., Garg, U., Babu, R.V., (2017) Fast Feature Fool: a Data Independent Approach to Universal Adversarial Perturbations, , http://arxiv.org/abs/1707.05572, arXiv:1707.05572. [Online]; (2020) Nist TrojAI Round 0 Dataset, , https://pages.nist.gov/trojai/docs/data.html#round-0-dry-run, NIST. . [Online]; (2020) Nist TrojAI Round 1 Dataset, , https://pages.nist.gov/trojai/docs/data.html#round-1, NIST. . [Online]; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) Proc. Int. Conf. Learn. Represent; Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2018) Int. Conf. Learn. Represent; Wang, B., Yao, Y., Shan, S., Li, H., Viswanath, B., Zheng, H., Zhao, B.Y., Neural cleanse: Identifying and mitigating backdoor attacks in neural networks (2019) Proc. Ieee Symp. Secur. Privacy (SP), pp. 707-723. , May; Wang, R., Zhang, G., Liu, S., Chen, P.-Y., Xiong, J., Wang, M., Practical detection of Trojan neural networks: Data-limited and data-free cases (2020) Proc. 16th Eur. Conf. Comput. Vis. (ECCV), pp. 222-238. , Glasgow, U.K.: Springer, Aug; Xie, C., Wu, Y., Maaten, L.V.D., L.yuille, A., He, K., Feature denoising for improving adversarial robustness (2019) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 501-509. , Jun; Yuan, X., He, P., Zhu, Q., Li, X., Adversarial examples: Attacks and defenses for deep learning (2019) Ieee Trans. Neural Netw. Learn. Syst., 30 (9), pp. 2805-2824. , Sep","Gupta, R.; Center for Research in Computer Vision, United States; 电子邮件: rohitg@knights.ucf.edu",,,Institute of Electrical and Electronics Engineers Inc.,,,,,21693536,,,,English,IEEE Access,Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85111581101
"IR D., K S.",57226185092;57226183897;,DAD: Domain Adversarial Defense System against DDoS attacks in Cloud,2021,IEEE Transactions on Network and Service Management,,,,,,,,10.1109/TNSM.2021.3097903,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110836009&doi=10.1109%2fTNSM.2021.3097903&partnerID=40&md5=b79e9925f3ecccb07cdd4f8ed835857e,"Department of computer science and engg., CEG campus, Anna University, Chennai, India. (e-mail: divyasree.i.r@outlook.com); Department of computer science and engg., CEG campus, Anna University, Chennai, India.","IR, D., Department of computer science and engg., CEG campus, Anna University, Chennai, India. (e-mail: divyasree.i.r@outlook.com); K, S., Department of computer science and engg., CEG campus, Anna University, Chennai, India.","The DDoS attack nullifies the data availability in cloud by primarily exploiting the security vulnerabilities of the network protocol and cloud services. The emergence of deep-learning based defense systems have delivered outstanding success in handling the DDoS attacks. However, the deep-learning based systems relies on having similar attack features during training and evaluation. In this paper, we propose a domain adversarial defense (DAD) system to reduce the domain mismatch and generalize the model to handle real-time attacks in cloud. Two novel strategies are applied into our proposed DAD system. 1) Latent feature extractor to extract domain invariant features across multiple domains. 2) Adversarial training algorithm to perform unsupervised adaptation over a defense system using real-time attack samples. The capability of the DAD model is empirically substantiated across four datasets to understand its effectiveness across both known and unknown attacks. The experimental analysis shows that the proposed DAD model achieves substantial improvements with minimum overhead, reduced latency and better efficacy over existing defense mechanisms. IEEE",Adversarial Training; Cloud Computing; Computer crime; DDoS; Deep learning; Deep Learning; Denial-of-service attack; Feature extraction; Fog computing; Latent features.; Real-time systems; Support vector machines; Training,Deep learning; Denial-of-service attack; Learning systems; Network protocols; Defense mechanism; Experimental analysis; Feature extractor; Invariant features; Reduced latencies; Security vulnerabilities; Training algorithms; Unsupervised adaptation; Network security,,,,,,,,,Institute of Electrical and Electronics Engineers Inc.,,,,,19324537,,,,English,IEEE Trans. Netw. Serv. Manage.,Article,Article in Press,,Scopus,2-s2.0-85110836009
"Ibn-Khedher H., Khedher M.I., Hadji M.",56997434300;55250380600;36185483100;,Mathematical programming approach for adversarial attack modelling,2021,ICAART 2021 - Proceedings of the 13th International Conference on Agents and Artificial Intelligence,2,,,343,350,,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103852147&partnerID=40&md5=e0a4d2f63a321042422cfd52c8d5e0e8,"Université de Paris, LIPADE, Paris, F-75006, France; IRT - SystemX, 8 Avenue de la Vauve, Palaiseau, 91120, France","Ibn-Khedher, H., Université de Paris, LIPADE, Paris, F-75006, France; Khedher, M.I., IRT - SystemX, 8 Avenue de la Vauve, Palaiseau, 91120, France; Hadji, M., IRT - SystemX, 8 Avenue de la Vauve, Palaiseau, 91120, France","An adversarial attack is defined as the minimal perturbation that change the model decision. Machine learning (ML) models such as Deep Neural Networks (DNNs) are vulnerable to different adversarial examples where malicious perturbed inputs lead to erroneous model outputs. Breaking neural networks with adversarial attack requires an intelligent approach that decides about the maximum allowed margin in which the neural network decision (output) is invariant. In this paper, we propose a new formulation based on linear programming approach modelling adversarial attacks. Our approach considers noised inputs while reaching the optimal perturbation. To assess the performance of our approach, we discuss two main scenarios quantifying the algorithm's decision behavior in terms of total perturbation cost, percentage of perturbed inputs, and other cost factors. Then, the approach is implemented and evaluated under different neural network scales. © 2021 by SCITEPRESS - Science and Technology Publications, Lda.",Adversarial attack; Linear programming (LP); Neural network,Deep neural networks; Linear programming; Attack modelling; Cost factors; Model outputs; Modeling decisions; Optimal perturbation; Neural networks,,,,,"Akhtar, N., Mian, A., (2018) Threat of adversarial attacks on deep learning in computer vision: A survey, , CoRR, abs/1801.00553; Aung, A. M., Fadila, Y., Gondokaryono, R., Gonzalez, L., Building robust deep neural networks for road sign detection (2017), CoRR, abs/1712.09327; Bunel, R., Turkaslan, I., Torr, P. H., Kohli, P., Kumar, M. P., A unified view of piecewise linear neural network verification (2018) Proceedings of the 32Nd International Conference on Neural Information Processing Systems, NIPS'18, pp. 4795-4804. , USA. Curran Associates Inc; Cao, Y., Xiao, C., Cyr, B., Zhou, Y., Park, W., Rampazzi, S., Chen, Q. A., Mao, Z. M., Adversarial Sensor Attack on LiDAR-based Perception in Autonomous Driving (2019) Proceedings of the 26th ACM Conference on Computer and Communications Security (CCS'19), , London, UK; Carlini, N., Wagner, D., Audio adversarial examples: Targeted attacks on speech-to-text (2018) 2018 IEEE Security and Privacy Workshops (SPW), pp. 1-7; Chakraborty, A., Alam, M., Dey, V., Chattopadhyay, A., Mukhopadhyay, D., Adversarial attacks and defences: A survey (2018), CoRR, abs/1810.00069; Goodfellow, I. J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR, , 1412.6572v3; Jmila, H., Khedher, M. I., Blanc, G., El-Yacoubi, M. A., Siamese network based feature learning for improved intrusion detection (2019) Neural Information Processing - 26th International Conference, ICONIP 2019, Sydney, NSW, Australia, December 12-15, 2019, Proceedings, Part I, volume 11953 of Lecture Notes in Computer Science, pp. 377-389. , Gedeon, T., Wong, K. W., and Lee, M., editors, pages Springer; Jmila, H., Khedher, M. I., El-Yacoubi, M. A., Estimating VNF resource requirements using machine learning techniques (2017) Neural Information Processing - 24th International Conference, ICONIP 2017, Guangzhou, China, November 14-18, 2017, Proceedings, Part I, volume 10634 of Lecture Notes in Computer Science, pp. 883-892. , Liu, D., Xie, S., Li, Y., Zhao, D., and El-Alfy, E. M., editors, pages Springer; Khedher, M. I., El Yacoubi, M. A., Local sparse representation based interest point matching for person re-identification (2015) Neural Information Processing, pp. 241-250. , Arik, S., Huang, T., Lai, W. K., and Liu, Q., editors, pages Cham. Springer International Publishing; Khedher, M. I., El-Yacoubi, M. A., Dorizzi, B., Probabilistic matching pair selection for surf-based person re-identification (2012) 2012 BIOSIG - Proceedings of the International Conference of Biometrics Special Interest Group (BIOSIG), pp. 1-6; Khedher, M. I., Jmila, H., Yacoubi, M. A. E., Fusion of interest point/image based descriptors for efficient person re-identification (2018) 2018 International Joint Conference on Neural Networks (IJCNN), pp. 1-7; Kisacanin, B., Deep learning for autonomous vehicles (2017) 2017 IEEE 47th International Symposium on Multiple-Valued Logic (ISMVL), pp. 142-142; Kurabin, A., Goodfellow, I. J., Bengio, S., Adversarial examples in the physical world (2017) ICLR, , 1607.02533v4; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards deep learning models resistant to adversarial attacks; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2015) IEEE, , 1511.07528v1; Rao, Q., Frtunikj, J., Deep learning for self-driving cars: Chances and challenges (2018) 2018 IEEE/ACM 1st International Workshop on Software Engineering for AI in Autonomous Systems (SEFAIAS), pp. 35-38; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M. K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, CCS'16, pp. 1528-1540. , New York, NY, USA. ACM; Shrestha, A., Mahmood, A., Review of deep learning algorithms and architectures (2019) IEEE Access, 7, pp. 53040-53065",,Rocha A.P.Steels L.van den Herik J.,"Institute for Systems and Technologies of Information, Control and Communication (INSTICC)",SciTePress,"13th International Conference on Agents and Artificial Intelligence, ICAART 2021",4 February 2021 through 6 February 2021,,167493,,9.79E+12,,,English,ICAART - Proc. Int. Conf. Agents Artif. Intell.,Conference Paper,Final,,Scopus,2-s2.0-85103852147
"Apte A., Bandyopadhyay A., Shenoy K.A., Andrews J.P., Rathod A., Agnihotri M., Jajodia A.",57219314655;57219306142;57219310973;57219318397;57213232197;57208397550;57205455005;,Countering Inconsistent Labelling by Google’s Vision API for Rotated Images,2021,Advances in Intelligent Systems and Computing,1189,,,202,213,,,10.1007/978-981-15-6067-5_23,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092207673&doi=10.1007%2f978-981-15-6067-5_23&partnerID=40&md5=a809910f98bf74542ee81689381dc66d,"Manipal Institute of Technology, Manipal Academy of Higher Education, Manipal, India","Apte, A., Manipal Institute of Technology, Manipal Academy of Higher Education, Manipal, India; Bandyopadhyay, A., Manipal Institute of Technology, Manipal Academy of Higher Education, Manipal, India; Shenoy, K.A., Manipal Institute of Technology, Manipal Academy of Higher Education, Manipal, India; Andrews, J.P., Manipal Institute of Technology, Manipal Academy of Higher Education, Manipal, India; Rathod, A., Manipal Institute of Technology, Manipal Academy of Higher Education, Manipal, India; Agnihotri, M., Manipal Institute of Technology, Manipal Academy of Higher Education, Manipal, India; Jajodia, A., Manipal Institute of Technology, Manipal Academy of Higher Education, Manipal, India","Google’s Vision API analyses images and provides a variety of output predictions, one such type is context-based labelling. In this paper, it is shown that adversarial examples that cause incorrect label prediction and spoofing can be generated by rotating the images. Due to the black-boxed nature of the API, a modular context-based pre-processing pipeline is proposed consisting of a ResNet50 model that predicts the angle by which the image must be rotated to correct its orientation. The pipeline successfully performs the correction whilst maintaining the image’s resolution and feeds it to the API which generates labels similar to the original correctly oriented image, and using a percentage error metric, the performance of the corrected images as compared to its rotated counterparts is found to be significantly higher. These observations imply that the API can benefit from such a pre-processing pipeline to increase robustness to rotational perturbances. © 2021, Springer Nature Singapore Pte Ltd.",Adversarial attack; Convolutional neural network; ResNet50; Rotation invariance; Vision API,Intelligent computing; Pipeline processing systems; Pipelines; Context-based; Corrected image; Label predictions; Percentage error; Pre-processing; Rotated images; Computer vision,,,,,"Athey, S., (2018) The Impact of Machine Learning on Economics. The Economics of Artificial Intelligence: An Agenda, , (University of Chicago Press); Janai, J., (2017) Computer vision for autonomous vehicles: Problems, datasets and state-of-the-art, , arXiv preprint arXiv:1704.05519; Google Cloud Vision, , https://cloud.google.com/vision/, Google. Internet: 08 March 2019; Choi, M., Jeong, Y.-S., Park, J.H., Improving performance through rest open API grouping for wireless sensor network (2013) Int. J. Distrib. Sensor Networks, 9 (11), p. 958241; Mulfari, D., Celesti, A., Fazio, M., Villari, M., Puliafito, A., Using Google cloud vision in assistive technology scenarios (2016) Symposium on Computers and Communication (ISCC), , (IEEE, New York); Poursaeed, O., Enerative adversarial perturbations (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Nelson, B., Biggio, B., Laskov, P., Understanding the risk factors of learning in adversarial environments (2011) Proceedings of the 4th ACM Workshop on Security and Artificial Intelligence, , (ACM, New York); Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the ACM on Asia Conference on Computer and Communications Security, pp. 506-519. , (ACM, New York); Brendel, W., Rauber, J., Bethge, M., Decision-based adversarial attacks: reliable attacks against black-box machine learning models (2018) Sixth International Conference on Learning Representations, ICLR; Jo, K., Precise localization of an autonomous car based on probabilistic noise models of road surface marker features using multiple cameras (2015) IEEE Trans. Intell. Transp. Syst, 16 (6), pp. 3377-3392; Khan, A., Hebert, M., Learning safe recovery trajectories with deep neural networks for unmanned aerial vehicles (2018) 2018 IEEE Aerospace Conference, , (IEEE, New York); Shen, D., Guorong, W., Suk, H.-I., Deep learning in medical image analysis (2017) Annu. Rev. Biomed. Eng, 19, pp. 221-248; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial examples in the physical world, , arXiv preprint arXiv:1607.02533; Datar, M., Qi, X., Automatic image orientation detection using the supervised self-organizing map (2006) Imaging Technologies Lab-GE Global Research–Bangalore; Adversarial attacks: How to trick computer vision, , https://hackernoon.com/adversarial-attacks-how-totrick-computer-vision7484c4e85dc0onwww.medium.com, Iflexion, 14 Dec 2018, [08 March 2019]; Deng, H., Clausi, D.A., Gaussian MRF rotation invariant features for image classification (2004) Trans. Pattern Anal. Mach. Intell, 26. , (07); Laskov, P., Lippmann, R., (2010) Machine learning in adversarial environments, pp. 115-119; Wang, L., Image orientation detection with integrated human perception cues (or which way is up) (2003) Proceedings 2003 International Conference on Image Processing (Cat. No. 03CH37429), 2. , (IEEE, New York); Sun, C., Si, D., Skew and slant correction for document images using gradient direction (2002) Proceedings of the Fourth International Conference on Document Analysis and Recognition, , (IEEE, New York); Zhang, X., Rotation invariant local binary convolution neural networks (2017) Proceedings of the IEEE International Conference on Computer Vision; Cheng, G., Zhou, P., Han, J., Learning rotation-invariant convolutional neural networks for object detection in VHR optical remote sensing images (2016) IEEE Trans. Geosci. Remote Sens, 54 (12), p. 74057415; Papliński, A.P., Rotation-invariant categorization of colour images using the Radon transform (2012) The 2012 International Joint Conference on Neural Networks (IJCNN), pp. 1-6. , Brisbane, QLD; Fasel, B., Gatica-Perez, D., Rotation-invariant neoperceptron (2006) 18th International Conference on Pattern Recognition (ICPR’06), pp. 336-339. , Hong Kong; Ciocca, G., Cusano, C., Schettini, R., Image orientation detection using LBP-based features and logistic regression (2015) Multimedia Tools Appl, 74 (9), pp. 3013-3034; Carlini, N., Wagner, Adversarial examples are not easily detected: Bypassing ten detection methods (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 3-14. , (ACM, New York, November); Gu, S., Rigazio, L., (2014) Towards deep neural network architectures robust to adversarial examples, , arXiv preprint arXiv:1412.5068; Metzen, J.H., (2017) On detecting adversarial perturbations, , arXiv preprint arXiv:1702.04267; Wang, L., Liu, X., Xia, L., Xu, G., Bruckstein, A., Image orientation detection with integrated human perception cues (or which way is up) (2003) Proceedings 2003 International Conference on Image Processing (Cat. No. 03CH37429), 2, pp. II-539. , (IEEE, New York, September); Papernot, N., The limitations of deep learning in adversarial settings (2016) 2016 IEEE European Symposium on Security and Privacy (EuroS&P), , (IEEE, New York); Egmont-Petersen, M., de Ridder, D., Handels, H., (2002) Image Processing with Neural Networks—A Review, , (Elsevier) (pusblished in Pattern Recognition); https://cloud.google.com/, Google, Google Cloud. 08 Mar 2019; Perez, L., Wang, J., (2017) The effectiveness of data augmentation in image classification using deep learning, , arXiv preprint arXiv:1712.04621; Saez, D., Rotnet, , https://github.com/d4nst/RotNet, 29 June 29 [08 March 2019]","Apte, A.; Manipal Institute of Technology, India; 电子邮件: amanapte@gmail.com",Sharma M.K.Dhaka V.S.Perumal T.Dey N.Tavares J.M.R.S.,,Springer Science and Business Media Deutschland GmbH,"International Conference on Innovations in Computational Intelligence and Computer Vision, ICICV 2020",17 January 2020 through 19 January 2020,,249229,21945357,9.79E+12,,,English,,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85092207673
"Bai X., Yang M., Liu Z.",36623350900;57218086499;57219282756;,On the robustness of skeleton detection against adversarial attacks,2020,Neural Networks,132,,,416,427,,1,10.1016/j.neunet.2020.09.018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092035349&doi=10.1016%2fj.neunet.2020.09.018&partnerID=40&md5=c49504ea379162a4dba6f86cfe13267c,"School of Software Engineering, Xi'an Jiaotong University, Xi'an, 710049, China","Bai, X., School of Software Engineering, Xi'an Jiaotong University, Xi'an, 710049, China; Yang, M., School of Software Engineering, Xi'an Jiaotong University, Xi'an, 710049, China; Liu, Z., School of Software Engineering, Xi'an Jiaotong University, Xi'an, 710049, China","Human perception of an object's skeletal structure is particularly robust to diverse perturbations of shape. This skeleton representation possesses substantial advantages for parts-based and invariant shape encoding, which is essential for object recognition. Multiple deep learning-based skeleton detection models have been proposed, while their robustness to adversarial attacks remains unclear. (1) This paper is the first work to study the robustness of deep learning-based skeleton detection against adversarial attacks, which are only slightly unlike the original data but still imperceptible to humans. We systematically analyze the robustness of skeleton detection models through exhaustive adversarial attacking experiments. (2) We propose a novel Frequency attack, which can directly exploit the regular and interpretable perturbations to sharply disrupt skeleton detection models. Frequency attack consists of an excitatory-inhibition waveform with high frequency attribution, which confuses edge-sensitive convolutional filters due to the sudden contrast between crests and troughs. Our comprehensive results verify that skeleton detection models are also vulnerable to adversarial attacks. The meaningful findings will inspire researchers to explore more potential robust models by involving explicit skeleton features. © 2020 Elsevier Ltd",Adversarial attacks; Convolutional neural network; Robustness; Skeleton detection,"Deep learning; Object recognition; Detection models; High frequency HF; Human perception; Robust models; Shape encoding; Skeletal structures; Wave forms; Musculoskeletal system; adversarial attack; Article; black box attack; convolutional neural network; deep learning; deep neural network; excitatory junction potential; experimental study; frequency; gray box attack; human; machine learning; priority journal; skeleton detection; white box attack; automated pattern recognition; biometry; pattern recognition; procedures; skeleton; Biometric Identification; Deep Learning; Humans; Pattern Recognition, Automated; Pattern Recognition, Visual; Skeleton",,,,,"Arnab, A., Miksik, O., Torr, P., (2018), H. On the robustness of semantic segmentation models to adversarial attacks. In: Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 888–897); Athalye, A., Carlini, N., Wagner, D., Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples (2018), arXiv preprint; Ayzenberg, V., Chen, Y., Yousif, S.R., Lourenco, S.F., Skeletal representations of shape in human vision: Evidence for a pruned medial axis model (2019) Journal of Vision, 19 (6), pp. 1-21; Ayzenberg, V., Lourenco, S.F., Skeletal descriptions of shape provide unique perceptual information for object recognition (2019) Scientific Reports, 9 (1), p. 9359; Bai, X., Ye, L., Zhu, J., Zhu, L., Komura, T., Skeleton filter: A self-symmetric filter for skeletonization in noisy text images (2020) IEEE Transactions on Image Processing, 29, pp. 1815-1826; Borenstein, E., Ullman, S., Class-specific, top-down segmentation (2002) European conference on computer vision, pp. 109-122. , Springer; Brendel, W., Bethge, M., Approximating cnns with bag-of-local-features models works surprisingly well on imagenet (2019) International conference on learning representations; Brochu, F., Increasing shape bias in imagenet-trained networks using transfer learning and domain-adversarial methods. (2019) arXiv: Computer Vision and Pattern Recognition; Chen, X., Fang, H., Lin, T.-Y., Vedantam, R., Gupta, S., Dollár, P., Microsoft coco captions: Data collection and evaluation server (2015), arXiv preprint; Chen, L.-C., Papandreou, G., Kokkinos, I., Murphy, K., Yuille, A.L., Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs (2017) IEEE Transactions on Pattern Analysis and Machine Intelligence, 40 (4), pp. 834-848; Choi, J.-H., Zhang, H., Kim, J.-H., Hsieh, C.-J., (2019), Lee, J.-S. Evaluating robustness of deep image super-resolution against adversarial attacks. In: Proceedings of the IEEE international conference on computer vision (pp. 303–311); Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., (2018), Boosting adversarial attacks with momentum. In: Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 9185–9193); Everingham, M., Van Gool, L., Williams, C.K., Winn, J., Zisserman, A., The pascal visual object classes (voc) challenge (2010) International Journal of Computer Vision, 88 (2), pp. 303-338; Ganeshan, A., Babu, R.V.F., (2019), Feature disruptive attack. In: Proceedings of the IEEE international conference on computer vision (pp. 8069–8079); Geirhos, R., Rubisch, P., Michaelis, C., Bethge, M., Wichmann, F.A., Brendel, W., Imagenet-trained cnns are biased towards texture; increasing shape bias improves accuracy and robustness (2019) International conference on learning representations; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR; Guo, C., Gardner, J.R., You, Y., Wilson, A.G., Weinberger, K.Q., Simple black-box adversarial attacks (2019) International conference on machine learning, pp. 2484-2493; Hofstadter, D.R., Metamagical themas: Questing for the essence of mind and pattern (1985), Basic Books; Hung, C.-C., Carlson, E.T., Connor, C.E., Medial axis shape coding in macaque inferotemporal cortex (2012) Neuron, 74 (6), pp. 1099-1113; Janai, J., Güney, F., Behl, A., Geiger, A., Computer vision for autonomous vehicles: Problems, datasets and state-of-the-art (2017), arXiv preprint; Jones, J.P., Palmer, L.A., An evaluation of the two-dimensional gabor filter model of simple receptive fields in cat striate cortex (1987) Journal of Neurophysiology, 58 (6), pp. 1233-1258; Ke, W., Chen, J., Jiao, J., Zhao, G., Ye, Q.S., (2017), side-output residual network for object symmetry detection in the wild. In: Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 1068–1076); Kovacs, I., Julesz, B., Perceptual sensitivity maps within globally defined visual shapes (1994) Nature, 370 (6491), pp. 644-646; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2016), arXiv preprint; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2017) ICLR; Lake, B.M., Salakhutdinov, R., Tenenbaum, J.B., Human-level concept learning through probabilistic program induction (2015) Science, 350 (6266), pp. 1332-1338; Lescroart, M.D., Biederman, I., Cortical representation of medial axis structure (2013) Cerebral Cortex, 23 3, pp. 629-637; Liu, C., Ke, W., Qin, F., Ye, Q., (2018), Linear span network for object skeleton detection. In: Proceedings of the European conference on computer vision (ECCV) (pp. 133–148); Liu, J., Wang, Z., Liu, H., Hds-sp: A novel descriptor for skeleton-based human action recognition (2020) Neurocomputing, 385, pp. 22-32; Marr, D., Nishihara, H.K., Representation and recognition of the spatial organization of three-dimensional shapes (1978) Proceedings of the Royal Society of London B: Biological Sciences, 200 (1140), pp. 269-294; Martin, D., Fowlkes, C., Tal, D., Malik, J., A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics (2001), Iccv Vancouver; Metzen, J.H., Kumar, M.C., Brox, T., Fischer, V., Universal adversarial perturbations against semantic image segmentation (2017) 2017 IEEE international conference on computer vision (ICCV), pp. 2774-2783. , IEEE; Mignotte, M., Symmetry detection based on multiscale pairwise texture boundary segment interactions (2016) Pattern Recognition Letters, 74, pp. 53-60; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., (2016), Deepfool: a simple and accurate method to fool deep neural networks. In: Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 2574–2582); Mygdalis, V., Tefas, A., Pitas, I., K-anonymity inspired adversarial attack and multiple one-class classification defense (2020) Neural Networks, 124, pp. 296-307; Oregi, I., Ser, J.D., Pérez, A., Lozano, J.A., Robust image classification against adversarial attacks using elastic similarity measures between edge count sequences (2020) Neural Networks, 128, pp. 61-72; Ritter, S., Barrett, D.G.T., Santoro, A., Botvinick, M., Cognitive psychology for deep neural networks: a shape bias case study (2017) International conference on machine learning, pp. 2940-2949; Shen, W., Bai, X., Hu, Z., Zhang, Z., Multiple instance subspace learning via partial random projection tree for local reflection symmetry in natural images (2016) Pattern Recognition, 52, pp. 306-316; Shen, W., Zhao, K., Jiang, Y., Wang, Y., Bai, X., Yuille, A., Deepskeleton: Learning multi-task scale-associated deep side outputs for object skeleton extraction in natural images (2017) IEEE Transactions on Image Processing, 26 (11), pp. 5298-5311; Shen, W., Zhao, K., Jiang, Y., Wang, Y., Zhang, Z., Bai, X., (2016), Object skeleton extraction in natural images by fusing scale-associated deep side outputs. In: Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 222–230); Sing Lee, T., Mumford, D., Romero, R., Lamme, V., The role of the primary cortex in higher level vision (1998) Vision Research, 38, pp. 2429-2454; Sironi, A., Lepetit, V., Fua, P., (2014), Multiscale centerline detection by learning a scale-space distance transform. In: Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 2697–2704); Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Intriguing properties of neural networks (2013), arXiv preprint; Tsogkas, S., Dickinson, S., Amat: Medial axis transform for natural images (2017) Computer vision (ICCV), 2017 IEEE international conference on, pp. 2727-2736. , IEEE; Tsogkas, S., Kokkinos, I., Learning-based symmetry detection in natural images (2012) European conference on computer vision, pp. 41-54. , Springer; Vidnerová, P., Neruda, R., Vulnerability of classifiers to evolutionary generated adversarial examples (2020) Neural Networks, 127, pp. 168-181; Wang, Y., Xu, Y., Tsogkas, S., Bai, X., Dickinson, S., Siddiqi, K., (2019), DeepFlux for Skeletons in the Wild. In: Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 5287–5296); Xiao, Q., Qin, M., Yin, Y., Skeleton-based chinese sign language recognition and generation for bidirectional communication between deaf and hearing people (2020) Neural Networks, 125, pp. 41-55; Xie, S., Tu, Z., (2015), Holistically-nested edge detection. In: Proceedings of the IEEE international conference on computer vision (pp. 1395–1403); Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., (2017), Adversarial examples for semantic segmentation and object detection. In: Proceedings of the IEEE international conference on computer vision (pp. 1369–1378); Xie, C., Wu, Y., Maaten, L., (2019), v. d., Yuille, A. L., & He, K. Feature denoising for improving adversarial robustness. In: Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 501–509); Yu, Z., Lee, M., Real-time human action classification using a dynamic neural model (2015) Neural Networks, 69, pp. 29-43; Zhao, K., Shen, W., Gao, S., Li, D., Cheng, M.-M., Hi-fi: hierarchical feature integration for skeleton detection (2018) Proceedings of the 27th international joint conference on artificial intelligence, pp. 1191-1197. , AAAI Press; Zhu, J., Zou, W., Zhu, Z., Hu, Y., Convolutional relation network for skeleton-based action recognition (2019) Neurocomputing, 370, pp. 109-117","Bai, X.; School of Software Engineering, China; 电子邮件: xiubai@xjtu.edu.cn",,,Elsevier Ltd,,,,,8936080,,NNETE,33022470,English,Neural Netw.,Article,Final,,Scopus,2-s2.0-85092035349
Chen Y.Y.,57225201218;,Dog and Cat Classification with Deep Residual Network,2020,ACM International Conference Proceeding Series,,,,137,141,,,10.1145/3393822.3432321,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099387312&doi=10.1145%2f3393822.3432321&partnerID=40&md5=2bf83ce3772a7e7d93f5f966d139b993,"Software School of North University, China","Chen, Y.Y., Software School of North University, China","I With the development of artificial intelligence, the deep neural network(DNN) has achieved excellent results in image processing domain such as image classification[1] and objct detection[2]. The convolution neural networks(CNN) [3] is a Representative algorithm of DNN which have the representation learning ability. According to its convolutional structure, input information is extracted with translation invariance. Based on the widely used CNN, there are many efficient models. For image classification there are Lenet-5[4], VGG[5], Resnet[6] and so on. For object detection, the yolo series[7] is well-known. Also few well known datasets are proposed to measure their performance such as ImageNet and Cifar-10[8]. These data sets are dedicated to the classification of multiple objects in natural scenes. Nowadays, pets play an increasingly important role in our life, so we built a cat and dog dataset, each of which categories with 12500 samples which is larger then 1260 in Imagenet. For our dataset, we trained an image classification model. We focus on the performance of distinguish dog and cat In different scenes, lighting and noise. Our method achieved an accuracy of 92.7 percent and remained robust under adversarial attack. © 2020 ACM.",adversarial attack; convolution neural networks(CNN); image classification; Neural network,Classification (of information); Convolution; Deep neural networks; Neural networks; Object detection; Software engineering; Convolution neural network; Learning abilities; Multiple objects; Natural scenes; Translation invariance; Image classification,,,,,"Alex, K., Sutskever, I., Hinton, G., ImageNet Classification with Deep Convolutional Neural Networks (2012) Advances in Neural Information Processing Systems, 25 (2); Mark, E., The Pascal Visual Object Classes (VOC) Challenge (2010) International Journal of Computer Vision, 88 (2), pp. 303-338; Christian, S., (2016) Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning; El-Sawy, A., El-Bakry, H., Loey, M., CNN for Handwritten Arabic Digits Recognition Based on LeNet (2016), 5; Karen, S., Zisserman, A., Very Deep Convolutional Networks for Large-Scale Image Recognition (2014) Computer Ence; He, K., Deep Residual Learning for Image Recognition (2016) 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) IEEE; Joseph, R., Farhadi, A., (2018) YOLOv3: An Incremental Improvement; Benjamin, R., (2018) Do CIFAR-10 Classifiers Generalize to CIFAR-10; Thorsten, J., Making large-scale SVM learning practical (1998) Technical Reports, 8 (3), pp. 499-526; Deng, L., The MNIST Database of Handwritten Digit Images for Machine Learning Research [Best of the Web] (2012) Processing Magazine, IEEE, 29 (6), pp. 141-142; Dongwon, P., Chun, S.Y., (2018) Classification Based Grasp Detection Using Spatial Transformer Network; Tjerk, B.P., A Tutorial on the Cross-Entropy Method (2005) Annals of Operations Research, 134 (1), pp. 19-67; Kingma Diederik, P., Ba, J., Adam: A Method for Stochastic Optimization (2014) Computer Ence; Goodfellow Ian, J., Jonathon, S., Christian, S., Explaining and Harnessing Adversarial Examples (2014) Computer Ence; Park, M., L1-regularization path algorithm for generalized linear models (2007) Journal of the Royal Statistical Society, 69 (4), pp. 659-677; Wei, Y., Visualizing and Comparing Convolutional Neural Networks (2014) Computer Science","Chen, Y.Y.; Software School of North UniversityChina; 电子邮件: image_cl@163.com",,University of Bologna,Association for Computing Machinery,2020 European Symposium on Software Engineering. ESSE 2020,6 November 2020 through 8 November 2020,,165923,,9.78E+12,,,English,ACM Int. Conf. Proc. Ser.,Conference Paper,Final,,Scopus,2-s2.0-85099387312
"Grosz S.A., Chugh T., Jain A.K.",57207568529;56031923100;36071504600;,Fingerprint presentation attack detection: A sensor and material agnostic approach,2020,IJCB 2020 - IEEE/IAPR International Joint Conference on Biometrics,,,9304863,,,,3,10.1109/IJCB48548.2020.9304863,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095479159&doi=10.1109%2fIJCB48548.2020.9304863&partnerID=40&md5=cf812b3069cf3631b87419fbd163a098,"Michigan State University, East Lansing, MI  48824, United States","Grosz, S.A., Michigan State University, East Lansing, MI  48824, United States; Chugh, T., Michigan State University, East Lansing, MI  48824, United States; Jain, A.K., Michigan State University, East Lansing, MI  48824, United States","The vulnerability of automated fingerprint recognition systems to presentation attacks (PAs), i.e., spoof or altered fingers, has been a growing concern, warranting the development of accurate and efficient presentation attack detection (PAD) methods. However, one major limitation of the existing PAD solutions is their poor generalization to new PA materials and fingerprint sensors, not used in training. In this study, we propose a robust PAD solution with improved cross-material and cross-sensor generalization. Specifically, we build on top of any CNN-based architecture trained for fingerprint spoof detection combined with cross-material spoof generalization using a style transfer network wrapper. We also incorporate adversarial representation learning (ARL) in deep neural networks (DNN) to learn sensor and material invariant representations for PAD. Experimental results on LivDet 2015 and 2017 public domain datasets exhibit the effectiveness of the proposed approach. © 2020 IEEE.",,Biometrics; Deep neural networks; Attack detection; CNN-based architecture; Fingerprint recognition systems; Fingerprint sensors; Invariant representation; Public domains; Spoof detection; Transfer network; Palmprint recognition,,,,,"Auksorius, E., Boccara, A.C., Internal fingerprint imaging with visible light full-field optical coherence tomography (2016) Clinical and Translational Biophotonics, pp. TTh1B-4. , 2. Optical Society of America; Baldisserra, D., Franco, A., Maio, D., Maltoni, D., Fake fingerprint detection by odor analysis (2006) International Conference on Biometrics, pp. 265-272. , 1. Springer; Bengio, Y., Courville, A., Vincent, P., Representation learning: A review and new perspectives (2013) IEEE Transactions on Pattern Analysis and Machine Intelligence, 35 (8), pp. 1798-1828. , 2; Cao, K., Jain, A.K., (2016) Hacking Mobile Phones Using 2d Printed Fingerprints, , https://www.youtube.com/watch?v=fZJI_BrMZXU&feature=youtu.be, 1; Cheng, Y., Larin, K.V., Artificial fingerprint recognition by using optical coherence tomography with autocorrelation analysis (2006) Applied Optics, 45 (36), pp. 9238-9245. , 2; Chugh, T., Cao, K., Jain, A.K., Fingerprint spoof buster: Use of minutiae-centered patches (2018) IEEE Transactions on Information Forensics and Security, 13 (9), pp. 2190-2202. , 1, 2, 4, 6; Chugh, T., Jain, A.K., (2018) Fingerprint Presentation Attack Detection: Generalization and Efficiency, , 2; Chugh, T., Jain, A.K., (2019) Fingerprint Spoof Generalization, , 2, 5, 6, 7, 8; Chugh, T., Jain, A.K., (2019) Oct Fingerprints: Resilience to Presentation Attacks., , 2; Csurka, G., (2017) Domain Adaptation for Visual Applications: A Comprehensive Survey, , 3; Ding, Y., Ross, A., An ensemble of one-class svms for fingerprint spoof detection across different fabrication materials (2016) 2016 IEEE International Workshop on Information Forensics and Security (WIFS), pp. 1-6. , 2; Edwards, H., Storkey, A., (2015) Censoring Representations with An Adversary, , 3; Engelsma, J.J., Arora, S.S., Jain, A.K., Paulter, N.G., Universal 3d wearable fingerprint targets: Advancing fingerprint reader evaluations (2018) IEEE Transactions on Information Forensics and Security, 13 (6), pp. 1564-1578. , 1; Engelsma, J.J., Cao, K., Jain, A.K., Raspireader: Open source fingerprint reader (2018) IEEE Transactions on Pattern Analysis and Machine Intelligence, 41 (10), pp. 2511-2524. , 1; Engelsma, J.J., Jain, A.K., Generalizing fingerprint spoof detector: Learning a one-class classifier (2019) 2019 International Conference on Biometrics (ICB), , 2; Evans, N., (2019) Handbook of Biometric Anti-spoofing: Presentation Attack Detection, , 1. Springer; Gajawada, R., Popli, A., Chugh, T., Namboodiri, A., Jain, A.K., Universal material translator: Towards spoof fingerprint generalization (2019) 2019 International Conference on Biometrics (ICB), , 2; Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette, F., Marchand, M., Lempitsky, V., Domainadversarial training of neural networks (2016) The Journal of Machine Learning Research, 17 (1), pp. 2030-2096. , 3; Ghiani, L., Hadid, A., Marcialis, G.L., Roli, F., Fingerprint liveness detection using binarized statistical image features (2013) 2013 IEEE Sixth International Conference on Biometrics: Theory, Applications and Systems (BTAS), pp. 1-6. , 2; Ghiani, L., Marcialis, G.L., Roli, F., Fingerprint liveness detection by local phase quantization (2012) Proceedings of the 21st International Conference on Pattern Recognition, pp. 537-540. , 2; Ghiani, L., Yambay, D., Mura, V., Tocco, S., Marcialis, G.L., Roli, F., Schuckcrs, S., Livdet 2013 fingerprint liveness detection competition 2013 (2013) 2013 International Conference on Biometrics (ICB), pp. 1-6. , 1; González-Soler, L.J., Gomez-Barrero, M., Chang, L., Pérez-Suárez, A., Busch, C., (2019) Fingerprint Presentation Attack Detection Based on Local Features Encoding for Unknown Attacks, , 2; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, pp. 2672-2680. , 3; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778. , 6, 7; Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H., (2017) Mobilenets: Efficient Convolutional Neural Networks for Mobile Vision Applications, , 4, 7, 8; Information Technology-Biometric Presentation Attack Detection-Part 1: Framework, , https://www.iso.org/standard/53227.html.1, International Standards Organization iso/iec 30107-1 2016; Khutlang, R., Khanyile, N.P., Makinana, S., Nelwamondo, F.V., High resolution feature extraction from optical coherence tomography acquired internal fingerprint (2016) 2016 17th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/ Distributed Computing (SNPD), pp. 637-641. , 2. IEEE; Lapsley, P.D., Lee, J.A., Pare, D.F., Jr., Hoffman, N., (1998) Antifraud Biometric Scanner That Accurately Detects Blood Flow, , Apr 7; Maaten L, V.D., Hinton, G., Visualizing data using t-sne (2008) Journal of Machine Learning Research, 9, pp. 2579-2605. , 6 (Nov); Maltoni, D., Maio, D., Jain, A.K., Prabhakar, S., (2009) Handbook of Fingerprint Recognition, , 1. Springer Science & Business Media, 2nd edition; Marasco, E., Ross, A., A survey on antispoofing schemes for fingerprint recognition systems (2014) ACM Computing Surveys, 47 (2), pp. 1-36. , 1; Marasco, E., Sansone, C., On the robustness of fingerprint liveness detection algorithms against new materials used for spoofing (2011) BIOSIGNALS, 8, pp. 553-555. , 2; Marasco, E., Sansone, C., Combining perspiration-and morphology-based static features for fingerprint liveness detection (2012) Pattern Recognition Letters, 33 (9), pp. 1148-1156. , 2; Marcialis, G.L., Lewicke, A., Tan, B., Coli, P., Grimberg, D., Congiu, A., Tidu, A., Schuckers, S., First international fingerprint liveness detection competition-livdet 2009 (2009) International Conference on Image Analysis and Processing, pp. 12-23. , 1. Springer; Marcialis, G.L., Roli, F., Tidu, A., Analysis of fingerprint pores for vitality detection (2010) 2010 20th International Conference on Pattern Recognition, pp. 1289-1292. , 2; Matsumoto, T., Matsumoto, H., Yamada, K., Hoshino, S., Impact of artificial"" gummy"" fingers on fingerprint systems (2002) Optical Security and Counterfeit Deterrence Techniques IV, 4677, pp. 275-289. , 1; Mura, V., Ghiani, L., Marcialis, G.L., Roli, F., Yambay, D.A., Schuckers, S.A., Livdet 2015 fingerprint liveness detection competition 2015 (2015) 2015 International Conference on Biometrics Theory, Applications, and Systems, , 1; Mura, V., Orrù, G., Casula, R., Sibiriu, A., Loi, G., Tuveri, P., Ghiani, L., Marcialis, G.L., Livdet 2017 fingerprint liveness detection competition 2017 (2018) 2018 International Conference on Biometrics (ICB), pp. 297-302. , 1; Nogueira, R.F., De Lotufo Alencar, R., Machado, R.C., Fingerprint liveness detection using convolutional neural networks (2016) IEEE Transactions on Information Forensics and Security, 11 (6), pp. 1206-1213. , 2; IARPA-BAA-16-04, , https://www.iarpa.gov/index.php/research-programs/odin/odin-baa, ODNI, IARPA. 1; Orrù, G., Casula, R., Tuveri, P., Bazzoni, C., Dessalvi, G., Micheletto, M., Ghiani, L., Marcialis, G.L., (2019) Livdet in Action-fingerprint Liveness Detection Competition 2019, , 1; Pala, F., Bhanu, B., Deep triplet embedding representations for liveness detection (2017) Deep Learning for Biometrics, pp. 287-307. , 2. Springer; Rattani, A., Scheirer, W.J., Ross, A., Open set fingerprint spoof detection across, Novel fabrication materials (2015) IEEE Transactions on Information Forensics and Security, 10 (11), pp. 2447-2460. , 2; Roy, P.C., Boddeti, V.N., Mitigating information leakage in image representations: A maximum entropy approach (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2586-2594. , 4; Sousedik, C., Busch, C., Quality of fingerprint scans captured using optical coherence tomography (2014) IEEE International Joint Conference on Biometrics, pp. 1-8. , 2. IEEE; Tan, B., Lewicke, A., Yambay, D., Schuckers, S., The effect of environmental conditions and, Novel spoofing methods on fingerprint anti-spoofing algorithms (2010) 2010 IEEE International Workshop on Information Forensics and Security, pp. 1-6. , 2; Tolosana, R., Gomez-Barrero, M., Busch, C., Ortega-Garcia, J., Biometric presentation attack detection: Beyond the visible spectrum (2019) IEEE Transactions on Information Forensics and Security, 15, pp. 1261-1275. , 2; Tzeng, E., Hoffman, J., Saenko, K., Darrell, T., Adversarial discriminative domain adaptation (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 7167-7176. , 3; Wang, M., Deng, W., Deep visual domain adaptation: A survey (2018) Neurocomputing, 312, pp. 135-153. , 3; Xie, Q., Dai, Z., Du, Y., Hovy, E., Neubig, G., Controllable invariance through adversarial feature learning (2017) Advances in Neural Information Processing Systems, pp. 585-596. , 3; Yambay, D., Ghiani, L., Denti, P., Marcialis, G.L., Roli, F., Schuckers, S., Livdet 2011-fingerprint liveness detection competition 2011 (2012) 2012 5th IAPR International Conference on Biometrics (ICB), pp. 208-215. , 1; Yoon, S., Feng, J., Jain, A.K., Altered fingerprints: Analysis and detection (2012) IEEE Transactions on Pattern Analysis and Machine Intelligence, 34 (3), pp. 451-464. , 1; Zhang, B.H., Lemoine, B., Mitchell, M., Mitigating unwanted biases with adversarial learning (2018) Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society, pp. 335-340. , 3",,,,Institute of Electrical and Electronics Engineers Inc.,"2020 IEEE/IAPR International Joint Conference on Biometrics, IJCB 2020",28 September 2020 through 1 October 2020,,166343,,9.78E+12,,,English,IJCB - IEEE/IAPR Int. Jt. Conf. Biom.,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85095479159
"Xiang Z., Miller D.J., Wang H., Kesidis G.",57202504337;55494841200;57216152795;7003540724;,"Revealing perceptible backdoors in DNNs, without the training set, via the maximum achievable misclassification fraction statistic",2020,"IEEE International Workshop on Machine Learning for Signal Processing, MLSP",2020-September,,9231861,,,,2,10.1109/MLSP49062.2020.9231861,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096464113&doi=10.1109%2fMLSP49062.2020.9231861&partnerID=40&md5=8fa396559625c633b07ea2c2d4ba63d5,"Pennsylvania State University, State College, PA, United States","Xiang, Z., Pennsylvania State University, State College, PA, United States; Miller, D.J., Pennsylvania State University, State College, PA, United States; Wang, H., Pennsylvania State University, State College, PA, United States; Kesidis, G., Pennsylvania State University, State College, PA, United States","Recently, a backdoor data poisoning attack was proposed, which adds mislabeled examples to the training set, with an embedded backdoor pattern, aiming to have the classifier learn to classify to a target class whenever the backdoor pattern is present in a test sample. We address post-training detection of innocuous perceptible backdoors in DNN image classifiers, wherein the defender does not have access to the poisoned training set. This problem is challenging because without the poisoned training set, we have no hint about the actual backdoor pattern used during training. We identify two properties of perceptible backdoor patterns - spatial invariance and robustness - based upon which we propose a novel detector using the maximum achievable misclassification fraction (MAMF) statistic. We detect whether the trained DNN has been backdoor-attacked and infer the source and target classes. Our detector outperforms other existing detectors experimentally. © 2020 IEEE.",Adversarial learning; Anomaly detection; Backdoor attacks; Data poisoning; DNNs,Deep neural networks; Machine learning; Signal processing; Backdoors; Image Classifiers; Misclassifications; Poisoning attacks; Spatial invariance; Target class; Test samples; Training sets; Classification (of information),,,,,"Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) Proc. ICLR; Miller, D.J., Xiang, Z., Kesidis, G., Adversarial learning in statistical classification: A comprehensive review of defenses against attacks (2020) Proceedings of the Ieee, 108, pp. 402-433. , March; Chen, X., Liu, C., Li, B., Lu, K., Song, D., (2017) Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning, , https://arxiv.org/abs/1712.05526v1; Gu, T., Liu, K., Dolan-Gavitt, B., Garg, S., Badnets: Evaluating backdooring attacks on deep neural networks (2019) Ieee Access, 7, pp. 47230-47244; Liao, C., Zhong, H., Squicciarini, A., Zhu, S., Miller, D.J., (2018) Backdoor Embedding in Convolutional Neural Network Models Via Invisible Perturbation, , http://arxiv.org/abs/1808.10307; Tran, B., Li, J., Madry, A., Spectral signatures in backdoor attacks (2018) Proc. Nips; Xiang, Z., Miller, D.J., Kesidis, G., A benchmark study of backdoor data poisoning defenses for deep neural network classifiers and a novel defense only legitimate samples (2019) Proc. Ieee MLSP, Pittsburgh, , Oct; Xiang, Z., Miller, D.J., Kesidis, G., (2019) Revealing Backdoors, Post-Training, in Dnn Classifiers Via Novel Inference on Optimized Perturbations Inducing Group Misclassification, , https://arxiv.org/abs/1908.10498; Wang, B., Yao, Y., Shan, S., Li, H., Viswanath, B., Zheng, H., Zhao, B.Y., Neural cleanse: Identifying and mitigating backdoor attacks in neural networks (2019) Proc. Ieee Symposium on Security and Privacy; Chen, B., Carvalho, W., Baracaldo, N., Ludwig, H., Edwards, B., Lee, T., Molloy, I., Srivastava, B., (2018) Detecting Backdoor Attacks on Deep Neural Networks by Activation Clustering, , http://arxiv.org/abs/1811.03728, Nov. 8; Liu, K., Doan-Gavitt, B., Garg, S., Fine-pruning: Defending against backdoor attacks on deep neural networks (2018) Proc. Raid; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. Cvpr; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) Iclr; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Nips, pp. 1097-1105; Sermanet, P., Chintala, S., LeCun, Y., Convolutional neural networks applied to house numbers digit classification (2012) Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012), , Nov; Albanie, S., Pretrained Vgg-face Model, , http://www.robots.ox.ac.uk/albanie/pytorchmodels.html",,,,IEEE Computer Society,"30th IEEE International Workshop on Machine Learning for Signal Processing, MLSP 2020",21 September 2020 through 24 September 2020,,164216,21610363,9.78E+12,,,English,"IEEE Int. Workshop Mach. Learn. Signal Process., MLSP",Conference Paper,Final,,Scopus,2-s2.0-85096464113
"Afonso Pereira J., Sequeira A.F., Pernes D., Cardoso J.S.",57219712140;55748352600;56516981600;9245302400;,A robust fingerprint presentation attack detection method against unseen attacks through adversarial learning,2020,BIOSIG 2020 - Proceedings of the 19th International Conference of the Biometrics Special Interest Group,,,9210972,,,,2,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094888793&partnerID=40&md5=408d95b2a53ed59f8559c519a6257627,"Inesc Tec, Porto, Portugal; Universidade Do Porto, Faculdade de Ciencias, Porto, Portugal; Faculdade de Engenharia da Universidade Do Porto, Porto, Portugal","Afonso Pereira, J., Inesc Tec, Porto, Portugal; Sequeira, A.F., Inesc Tec, Porto, Portugal; Pernes, D., Universidade Do Porto, Faculdade de Ciencias, Porto, Portugal; Cardoso, J.S., Inesc Tec, Porto, Portugal, Faculdade de Engenharia da Universidade Do Porto, Porto, Portugal","Fingerprint presentation attack detection (PAD) methods present a stunning performance in current literature. However, the fingerprint PAD generalisation problem is still an open challenge requiring the development of methods able to cope with sophisticated and unseen attacks as our eventual intruders become more capable. This work addresses this problem by applying a regularisation technique based on an adversarial training and representation learning specifically designed to to improve the PAD generalisation capacity of the model to an unseen attack. In the adopted approach, the model jointly learns the representation and the classifier from the data, while explicitly imposing invariance in the high-level representations regarding the type of attacks for a robust PAD. The application of the adversarial training methodology is evaluated in two different scenarios: i) a handcrafted feature extraction method combined with a Multilayer Perceptron (MLP); and ii) an end-to-end solution using a Convolutional Neural Network (CNN). The experimental results demonstrated that the adopted regularisation strategies equipped the neural networks with increased PAD robustness. The adversarial approach particularly improved the CNN models' capacity for attacks detection in the unseen-attack scenario, showing remarkable improved APCER error rates when compared to state-of-the-art methods in similar conditions. © 2020 German Computer Association (Gesellschaft für Informatik e.V.).",,Biometrics; Convolutional neural networks; Multilayer neural networks; Palmprint recognition; Adversarial learning; Attack detection; Attack scenarios; End-to-end solutions; Feature extraction methods; Generalisation; Multi layer perceptron; State-of-the-art methods; Learning systems,,,,,"Sequeira, A.F., Cardoso, J.S., Fingerprint liveness detection in the presence of capable intruders (2015) Sensors, 15, pp. 14615-14638; Marasco, E., Sansone, C., On the robustness of fingerprint liveness detect. alg. Against new materials used for spoofing (2011) BIOSIGNALS, pp. 553-558; Rattani, A., Scheirer, W., Ross, A., Open set fingerprint spoof detection across novel fabrication materials (2015) IEEE TIFS, 10 (11), pp. 2447-2460. , Nov; Menotti, D., Chiachia, G., Pinto, A., Robson Schwartz, W., Pedrini, H., Xavier Falcao, A., Rocha, A., Deeprep. iris, face, and fingerp. spoof. det (2015) TIFS, 10 (4), pp. 864-879; Pinto, A., Pedrini, H., Krumdick, M., Becker, B., Czajka, A., Bowyer, K.W., Rocha, A., Counteracting presentation attacks in face, fingerprint, and iris recognition (2018) Deep Learning in Biometrics, 245; Tolosana, R., Gomez-Barrero, M., Kolberg, J., Morales, A., Busch, C., Ortega-Garcia, J., Towards fingerprint pad based on cnn and short wave infrared imaging (2018) 2018 BIOSIG. IEEE, pp. 1-5; Mura, V., Ghiani, L., Marcialis, G., Roli, F., Yambay, D., Schuckers, S.S., (2015) Livdet2015-fingerprint Liveness Detect. Competition, , 09; Sequeira, A.F., Thavalengal, S., Ferryman, J., Corcoran, P., Cardoso, J.S., A realistic evaluation of iris presentation attack detection (2016) 39th TSP, pp. 660-664. , June; Ferreira, P., Sequeira, A.F., Pernes, D., Rebelo, A., Cardoso, J.S., Adversarial learning for a robust iris presentation attack detection method against unseen attack presentations (2019) Proceedings of the 18th BIOSIG, , publications/conferences/2019PedroFerreiraBIOSIG.pdf; Ferreira, P.M., Pernes, D., Rebelo, A., Cardoso, J.S., Learning signer invariant representations with adversarial training (2019) 12th ICMV; Ganin, Y., Lempitsky, V., Unsupervised domain adaptation by backpropagation (2015) Proc. 32nd Int. Conf. ML, 37, pp. 1180-1189. , http://proceedings.mlr.press/v37/ganin15.html, Lille, France; Feutry, C., Piantanida, P., Bengio, Y., Duhamel, P., (2018) Learning Anonymized Representations with Adversarial Neural Networks; Information technology-biometrics-presentation attack detection part 3: Testing and reporting (2017) ISO Int. Organization for Standardization, , ISO/IEC JTC1 SC37; Ojala, T., Pietikainen, M., Maenpaa, T., Multiresolution gray-scale and rotation invariant texture classification with local binary patterns (2002) IEEE Transactions on Pattern Analysis and Machine Intelligence, 24 (7), pp. 971-987. , July; Ojansivu, V., Heikkilä, J., Blur insensitive texture classification using local phase quantization (2008) Image and Signal Processing, A. Elmoataz, pp. 236-243. , O. Lezoray, F. Nouboud, and D. Mammass, Eds. Berlin, Heidelberg: Springer Berlin Heidelberg; Ghiani, L., Yambay, D.A., Mura, V., Marcialis, G.L., Roli, F., Schuckers, S.A., Review of the fingerprint liveness detection (livdet) competition series: 2009 to 2015 (2017) Image and Vision Computing, 58, pp. 110-128. , http://www.sciencedirect.com/science/article/pii/S0262885616301111; Park, E., Cui, X., Nguyen, T.H.B., Kim, H., Presentation attack detection using a tiny fully convolutional network (2019) IEEE Transactions on Information Forensics and Security, 14 (11), pp. 3016-3025",,Bromme A.Dantcheva A.Rathgeb C.Busch C.Raja K.Uhl A.,,Institute of Electrical and Electronics Engineers Inc.,"19th International Conference of the Biometrics Special Interest Group, BIOSIG 2020",16 September 2020 through 18 September 2020,,163673,,9.78E+12,,,English,BIOSIG - Proc. Int. Conf. Biom. Spec. Interest Group,Conference Paper,Final,,Scopus,2-s2.0-85094888793
"Calzavara S., Lucchese C., Tolomei G., Abebe S.A., Orlando S.",36630085200;8873518400;12784026600;57217231777;35305588800;,Treant: training evasion-aware decision trees,2020,Data Mining and Knowledge Discovery,34,5,,1390,1420,,5,10.1007/s10618-020-00694-9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086857055&doi=10.1007%2fs10618-020-00694-9&partnerID=40&md5=6111688bb0fad8c118c6c3c70784a6eb,"Università Ca’ Foscari Venezia, Venice, Italy; Sapienza Università di Roma, Roma, Italy","Calzavara, S., Università Ca’ Foscari Venezia, Venice, Italy; Lucchese, C., Università Ca’ Foscari Venezia, Venice, Italy; Tolomei, G., Sapienza Università di Roma, Roma, Italy; Abebe, S.A., Università Ca’ Foscari Venezia, Venice, Italy; Orlando, S., Università Ca’ Foscari Venezia, Venice, Italy","Despite its success and popularity, machine learning is now recognized as vulnerable to evasion attacks, i.e., carefully crafted perturbations of test inputs designed to force prediction errors. In this paper we focus on evasion attacks against decision tree ensembles, which are among the most successful predictive models for dealing with non-perceptual problems. Even though they are powerful and interpretable, decision tree ensembles have received only limited attention by the security and machine learning communities so far, leading to a sub-optimal state of the art for adversarial learning techniques. We thus propose Treant, a novel decision tree learning algorithm that, on the basis of a formal threat model, minimizes an evasion-aware loss function at each step of the tree construction. Treant is based on two key technical ingredients: robust splitting and attack invariance, which jointly guarantee the soundness of the learning process. Experimental results on publicly available datasets show that Treant is able to generate decision tree ensembles that are at the same time accurate and nearly insensitive to evasion attacks, outperforming state-of-the-art adversarial learning techniques. © 2020, The Author(s), under exclusive licence to Springer Science+Business Media LLC, part of Springer Nature.",Adversarial machine learning; Decision tree ensembles; Robust learning,Decision trees; Machine learning; Trees (mathematics); Adversarial learning; Decision tree learning algorithm; Force predictions; Limited attentions; Machine learning communities; Predictive models; State of the art; Tree construction; Learning algorithms,,,,,"Biggio, B., Roli, F., Wild patterns: ten years after the rise of adversarial machine learning (2018) Pattern Recognit, 84, pp. 317-331; Biggio, B., Fumera, G., Roli, F., Multiple classifier systems for robust classifier design in adversarial environments (2010) Int J Mach Learn Cybern, 1 (1-4), pp. 27-41; Biggio, B., Nelson, B., Laskov, P., Support vector machines under adversarial label noise (2011) ACML Asian Conference on Machine Learning, pp. 97-112; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Srndic, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Machine Learning and Knowledge Discovery in databases—European Conference, ECML PKDD, pp. 387-402; Biggio, B., Fumera, G., Roli, F., Security evaluation of pattern classifiers under attack (2014) IEEE Trans Knowl Data Eng, 26 (4), pp. 984-996; Breiman, L., Random forests (2001) Mach Learn, 45 (1), pp. 5-32; Breiman, L., Friedman, J.H., Olshen, R.A., Stone, C.J., (1984) Classification and Regression Trees. Wadsworth, , . ISBN 0-534-98053-8; Calzavara, S., Lucchese, C., Tolomei, G., Adversarial training of gradient-boosted decision trees (2019) Proceedings of the 28Th ACM International Conference on Information and Knowledge Management, CIKM 2019, pp. 2429-2432. , Zhu W, Tao D, Cheng X, Cui P, Runden-steiner EA, Carmel D, He Q, Yu JX (eds), Beijing, China, November 3–7, 2019, ACM; Carlini, N., Wagner, D.A., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy S&P, pp. 39-57; Chen, H., Zhang, H., Boning, D.S., Hsieh, C., Robust decision trees against adversarial examples (2019) International Conference on Machine Learning ICML, pp. 1122-1131; Chollet, F., (2017) Deep learning with python, 1st edn. Manning Publications Co., Greenwich, CT, USA, , . ISBN 1617294438, 9781617294433; Dang, H., Huang, Y., Chang, E., Evading classifiers by morphing in the dark (2017) ACM SIGSAC Conference on Computer and Communications Security, pp. 119-133; Friedman, J.H., Greedy function approximation: a gradient boosting machine (2001) Ann Stat, 29, pp. 1189-1232; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations ICLR; Gu, S., Rigazio, L., (2015) Towards Deep Neural Network Architectures Robust to Adversarial Examples, , In; He, W., Wei, J., Chen, X., Carlini, N., Song, D., Adversarial example defense: Ensembles of weak defenses are not strong (2017) USENIX Workshop on Offensive Technologies WOOT; Hershkop, S., Stolfo, S.J., Combining email models for false positive reduction (2005) ACM SIGKDD International Conference on Knowledge Discovery in Data Mining, pp. 98-107. , https://doi.org/10.1145/1081870.1081885; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I.P., Tygar, J.D., Adversarial machine learning (2011) ACM Workshop on Security and Artificial Intelligence Aisec, pp. 43-58; Hunt, E.B., Marin, J., Stone, P.J., (1966) Experiments in Induction, , Academic Press, New York; Hyafil, L., Rivest, R.L., Constructing optimal binary decision trees is np-complete (1976) Inf Process Lett, 5 (1), pp. 15-17; Kantchelian, A., Tygar, J.D., Joseph, A.D., Evasion and hardening of tree ensemble classifiers (2016) International Conference on Machine Learning ICML, pp. 2387-2396; Kraft, D., Algorithm 733: Tomp-fortran modules for optimal control calculations (1994) ACM Trans Math Softw TOMS, 20 (3), pp. 262-281. , https://doi.org/10.1145/192115.192124, ISSN 0098-3500; Lash, M.T., Lin, Q., Street, W.N., Robinson, J.G., A budget-constrained inverse classification framework for smooth classifiers (2017) IEEE International Conference on Data Mining Workshops ICDMW, pp. 1184-1193; Lowd, D., Meek, C., Adversarial learning (2005) ACM SIGKDD International Conference on Knowledge Discovery in Data Mining, pp. 641-647; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) International Conference on Learning Representations ICLR; Mehta, M., Agrawal, R., Rissanen, J., Sliq: A fast scalable classifier for data mining (1996) International Conference on Extending Database Technology, pp. 18-32. , Springer; Moosavi-Dezfooli, S., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) IEEE Conference on Computer Vision and Pattern Recognition CVPR, pp. 2574-2582; Murthy, S.K., Automatic construction of decision trees from data: a multi-disciplinary survey (1998) Data Min Knowl Discov, 2 (4), pp. 345-389; Nawar, S., Mouazen, A., Comparison between random forests, artificial neural networks and gradient boosted machines methods of on-line vis-nir spectroscopy measurements of soil total nitrogen and total carbon (2017) Sensors, 17 (10), p. 2428; Nelson, B., Rubinstein, B.I.P., Huang, L., Joseph, A.D., Lau, S., Lee, S.J., Rao, S., Tygar, J.D., Near-optimal evasion of convex-inducing classifiers (2010) International Conference on Artificial Intelligence and Statistics AISTATS, pp. 549-556; Nguyen, A.M., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) IEEE Conference on Computer Vision and Pattern Recognition CVPR, pp. 427-436; Papernot, N., McDaniel, P.D., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) In IEEE European Symposium on Security and Privacy EuroS&P, pp. 372-387; Papernot, N., McDaniel, P.D., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) In IEEE Symposium on Security and Privacy S&P, pp. 582-597; Perdisci, R., Gu, G., Lee, W., Using an ensemble of one-class SVM classifiers to harden payload-based anomaly detection systems (2006) IEEE International Conference on Data Mining ICDM, pp. 488-498. , https://doi.org/10.1109/ICDM.2006.165; Quinlan, J.R., Induction of decision trees (1986) Mach Learn, 1 (1), pp. 81-106; Srndic, N., Laskov, P., Practical evasion of a learning-based classifier: A case study (2014) IEEE Symposium on Security and Privacy S&P, pp. 197-211; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations ICLR; Tolomei, G., Silvestri, F., Haines, A., Lalmas, M., Interpretable predictions of tree-based ensembles via actionable feature tweaking (2017) ACM SIGKDD International Conference on Knowledge Discovery in Data Mining, pp. 465-474; Tran, T.P., Tsai, P., Jan, T., An adjustable combination of linear regression and modified probabilistic neural network for anti-spam filtering (2008) International Conference on Pattern Recognition ICPR, pp. 1-4. , https://doi.org/10.1109/ICPR.2008.4761358; Tyler, D.E., Robust Statistics: Theory and Methods (2008) J Am Stat Assoc, 103 (482), pp. 888-889; Vapnik, V., Principles of Risk Minimization for Learning Theory (1992) Adv Neural Inf Process Syst, 4, pp. 831-838; Xiao, H., Biggio, B., Nelson, B., Xiao, H., Eckert, C., Roli, F., Support vector machines under adversarial label contamination (2015) Neurocomputing, 160, pp. 53-62; Zhang, F., Wang, Y., Liu, S., Wang, H., Decision-based evasion attacks on tree ensemble classifiers (2020) World Wide Web, pp. 1-21","Lucchese, C.; Università Ca’ Foscari VeneziaItaly; 电子邮件: claudio.lucchese@unive.it",,,Springer,,,,,13845810,,,,English,Data Min. Knowl. Discov.,Article,Final,"All Open Access, Green",Scopus,2-s2.0-85086857055
"Ishikawa T., Liu Y.-L., Shepard D.L., Shin K.",57202419274;57193558941;57197389141;13105938700;,Machine learning for tree structures in fake site detection,2020,ACM International Conference Proceeding Series,,,,,,,,10.1145/3407023.3407035,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123041940&doi=10.1145%2f3407023.3407035&partnerID=40&md5=dd9f4f8cc80262aa0e0a0ecf7582f66e,"Carnegie Mellon University, United States; Rakuten, Inc, Japan; Evidation Health, United States; Gakushuin University, Japan","Ishikawa, T., Carnegie Mellon University, United States; Liu, Y.-L., Rakuten, Inc, Japan; Shepard, D.L., Evidation Health, United States; Shin, K., Gakushuin University, Japan","Tree data analysis has many applications in information security. In particular, HTML pages' DOM trees are an important target of analysis because web pages can be vectors for, and targets of, major cyberattacks like phishing. Previous attempts to incorporate tree data analysis into security applications, however, have been hampered by the lack of efficient methods for tree data analysis in machine learning. As such, most security research has focused on data representable as vectors of real numbers, like most machine learning work. Recent work, however, has yielded several efficiency break-throughs in tree analysis. One example is kernel methods, a methodological bridge that fills the gap between discretely-structured data (like trees) and multivariate analysis. Kernel methods enable applying a variety of multivariate analysis techniques such as SVM and PCA to trees. The method we are interested in is the subpath kernel. The subpath kernel offers the following advantages: (1) it is invariant over ordered and unordered trees; (2) it can be computed using an extremely fast linear-time algorithm compared to the quadratic time required to compute values of most tree kernels; (3) its excellent prediction accuracy has been proven through intensive experiments. This paper proposes a subpath kernel-based method for tree-structured security data. To demonstrate the effectiveness of our method, we apply it to the problem of detecting fake e-commerce sites, a sub-problem of phishing detection with a significant real-world financial cost. In an experiment on a real dataset of fake sites provided by a major e-commerce company, our method exhibited accuracy as high as 0.998 when training SVM with as few as 1,000 instances. Its generalization efficiency is also excellent: with only 100 training instances, the accuracy score reaches 0.996. While previous phishing detection methods relied on textual content, URL components, and blacklists, our approach is the first to leverage DOM trees, which makes it both more effective and more robust against adversarial attacks. Unlike URL or content changes, changing a page's DOM structure incurs large costs to criminals. © 2020 ACM.",Fake sites detection; Kernel method; Web security,Clustering algorithms; Computer crime; Efficiency; Electronic commerce; Information analysis; Learning systems; Multivariant analysis; Security of data; Support vector machines; Websites; Kernel based methods; Linear-time algorithms; Multi variate analysis; Multivariate analysis techniques; Phishing detections; Prediction accuracy; Security application; Security research; Trees (mathematics),,,,,"Abbasi, A., Chen, H., A comparison of tools for detecting fake websites (2009) Computer, , June; Berg, C., Christensen, J.P.R., Ressel, R., (1984) Harmonic Analysis on Semigroups. Theory of Positive Definite and Related Functions, , Springer; Chang, C.-C., Lin, C.-J., (2001) Libsvm: A Library for Support Vector Machines, , http://www.csie.ntu.edu.tw/cjlin/libsvm/; Collins, M., Duffy, N., Convolution kernels for natural language (2001) Advances in Neural Information Processing Systems 14 [Neural Information Processing Systems: Natural and Synthetic, NIPS 2001], pp. 625-632. , MIT Press; Corona, I., Biggio, B., Contini, M., Piras, L., Corda, R., Mereu, M., Mureddu, G., Roli, F., Deltaphish: Detecting phishing webpages in compromised websites (2017) ESORICS, (1), pp. 370-388. , 10492 of Lecture Notes in Computer Science, Springer; Cristianini, N., Shawe-Taylor, J., (2000) An Introduction to Support Vector Machines and Other Kernel-based Learning Methods, , Cambridge University Press; Demšar, J., Statistical comparisons of classifiers over multiple data sets (2006) Journal of Machine Learning Theory, 7, pp. 1-30; Gerbet, T., Kumar, A., Lauradoux, C., (2014) Un Safe Browsing, , Tech. Rep. RR-8594, INRIA; Haussler, D., (1999) Convolution Kernels on Discrete Structures, , UCSC-CRL 99-10, Dept. of Computer Science, University of California at Santa Cruz; Hommel, G., A stagewise rejective multiple test procedure based on a modified bonferroni tests (1988) Biometrika, 75, pp. 383-386; Kashima, H., Koyanagi, T., Kernels for semi-structured data (2002) The 9th International Conference on Machine Learning (ICML 2002), pp. 291-298; Kimura, D., Kashima, H., Fast computation of subpath kernel for trees (2012) ICML; Levenshtein, V.I., Binary codes capable of correcting deletions, insertions, and reversals (1966) Soviet Physics Doklady, 10 (8), pp. 707-710. , February; Li, L., Helenius, M., Usability evaluation of anti-phishing toolbars (2007) J. Computer Virology, 3, pp. 163-184; Liu, W., An antiphishing strategy based on visual similarity assessment (2006) IEEE Internet Computing, pp. 58-65; Lu, S.Y., A tree-to-tree distance and its application to cluster analysis (1979) IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI) 1, pp. 219-224; Marchal, S., Asokan, N., On designing and evaluating phishing webpage detection techniques for the real world (2018) 11th USENIX Workshop on Cyber Security Experimentation and Test (CSET 18), , (Baltimore, MD,, USENIX Association; Marchal, S., François, J., State, R., Engel, T., Phishstorm: Detecting phishing with streaming analytics (2014) IEEE Trans. Network and Service Management 11, 4, pp. 458-471; Marchal, S., Saari, K., Singh, N., Asokan, N., Know your phish: Novel techniques for detecting phishing sites and their targets (2016) ICDCS, pp. 323-333. , IEEE Computer Society; Satish, S., Babu, K.S., Phishing websites detection based on web source code and url in the webpage (2013) International Journal of Computer Science and Engineering Communications, 1; Shin, K., A theory of subtree matching and tree kernels based on the edit distance concept (2015) Annals of Mathematics and Artificial Intelligence; Shin, K., Ishikawa, T., Linear-time algorithms for the subpath kernel (2018) Proceedings of 29th Annual Symposium on Combinatorial Pattern Matching (CPM 2018), pp. 221-2213; Shin, K., Kuboyama, T., A generalization of haussler's convolution kernel-mapping kernel (2008) ICML 2008; Shin, K., Kuboyama, T., A comprehensive study of tree kernels (2014) JSAIisAI Post-Workshop Proceedings, Lecture Notes in Articial Intelligence, 8417, pp. 329-343. , Springer; Taï, K.C., The tree-to-tree correction problem (1979) Journal of the ACM, 26 (3), pp. 422-433. , July; Whittaker, C., Ryner, B., Nazif, M., Large-scale automatic classification of phishing pages (2010) NDSS '10; Zhang, K., Algorithms for the constrained editing distance between ordered labeled trees and related problems (1995) Pattern Recognition, 28 (3), pp. 463-474. , March; Zhang, K., Wang, J.T.L., Shasha, D., On the editing distance between undirected acyclic graphs (1996) International Journal of Foundations of Computer Science, 7 (1), pp. 43-58; Zhang, Y., Egelman, S., Cranor, L., Hong, J., Phinding phish: Evaluating anti-phishing tools (2007) Proceedings of 14th Anual Network and Distributed System Security Symposium, , Internet Society; Zhang, Y., Hong, J.I., Cranor, L.F., Cantina: A content-based approach to detecting phishing web sites Proceedings of the 16th International Conference on World Wide Web (New York, NY, USA, 2007), WWW '07, pp. 639-648. , ACM",,,,Association for Computing Machinery,"15th International Conference on Availability, Reliability and Security, ARES 2020",25 August 2020 through 28 August 2020,,162046,,9.78E+12,,,English,ACM Int. Conf. Proc. Ser.,Conference Paper,Final,,Scopus,2-s2.0-85123041940
"Baniamerian A., Khorasani K., Meskin N.",35172504200;26642977400;24172813000;,Monitoring and detection of malicious adversarial zero dynamics attacks in cyber-physical systems,2020,CCTA 2020 - 4th IEEE Conference on Control Technology and Applications,,,9206295,726,731,,,10.1109/CCTA41146.2020.9206295,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094115759&doi=10.1109%2fCCTA41146.2020.9206295&partnerID=40&md5=8f5e064eab3c92692d8682a804b30943,"Concordia University, Department of Electrical and Computer Engineering, Quebec, Canada; Qatar University, Department of Electrical Engineering, Doha, Qatar","Baniamerian, A., Concordia University, Department of Electrical and Computer Engineering, Quebec, Canada; Khorasani, K., Concordia University, Department of Electrical and Computer Engineering, Quebec, Canada; Meskin, N., Qatar University, Department of Electrical Engineering, Doha, Qatar","This paper is mainly concerned with monitoring and detection of zero dynamics (ZD) cyber attacks that are injected by malicious hackers and adversaries to safety critical cyber-physical systems (CPS). We consider a CPS system where the physical system (i.e., the plant) is represented by a linear time-invariant dynamical process. Specifically, we propose and provide a methodology for detecting zero dynamics cyber attacks through introducing an auxiliary system and detection filters. When compared to the currently available methods in the literature, the key advantage of our proposed strategy is that even if the attacker has complete knowledge of the CPS system including knowledge of our proposed approach, the introduced auxiliary system and filters, the attacker cannot design an undetectable attack that significantly and adversely impact stability and performance of the CPS system. © 2020 IEEE.",Cyber attack monitoring and detection; Cyber attacks; Cyber-physical systems (CPS); Resilience Control; Zero dynamics,Auxiliary equipment; Crime; Cyber Physical System; Dynamics; Embedded systems; Network security; Personal computing; Safety engineering; Auxiliary systems; Cyber-attacks; Cyber-physical systems (CPS); Detection filter; Dynamical process; Linear time invariant; Physical systems; Zero dynamics; Computer crime,,,,,"Giraldo, J., Sarkar, E., Cardenas, A.A., Maniatakos, M., Kantarcioglu, M., Security and privacy in cyber-physical systems: A survey of surveys (2017) IEEE Design & Test, 34, pp. 7-17; Tricaud, C., Chen, Y., (2011) Optimal Mobile Sensing and Actuation Policies in Cyber-physical Systems, , Springer Science & Business Media; Wan, J., Yan, H., Suo, H., Li, F., Advances in cyber-physical systems research KSII Transactions on Internet and Information Systems, 5; Kim, K.-D., Kumar, P.R., Cyber-physical systems: A perspective at the centennial (2012) Special Centennial Issue, 100, pp. 1287-1308; Giese, H., Rumpe, B., Schätz, B., Sztipanovits, J., Science and engineering of cyber-physical systems (dagstuhl seminar 11441) (2012) Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik; Ilic, M.D., Xie, L., Khan, U.A., Modeling future cyber-physical energy systems (2008) Power and Energy Society General Meeting-Conversion and Delivery of Electrical Energy in the 21st Century. IEEE, pp. 1-9; Ilic, M.D., Xie, L., Khan, U.A., Moura, J.M., Modeling of future cyber-physical energy systems for distributed sensing and control IEEE Transactions on Systems, Man, and Cybernetics-Part A: Systems and Humans, 40; Atkins, E.M., Bradley, J.M., Aerospace cyber-physical systems education (2013) AIAA Infotech Aerospace Conference, p. 4809; Khaitan, S.K., McCalley, J.D., Design techniques and applications of cyberphysical systems: A survey (2015) IEEE Systems Journal, 9 (2), pp. 350-365; Tang, B., (2014) New Approaches to Smart Grid Security with Scada Systems, , Ph. D. dissertation, Louisiana State University; Pasqualetti, F., Dörfler, F., Bullo, F., Attack detection and identification in cyber-physical systems (2013) IEEE Transactions on Automatic Control, 58, pp. 2715-2729; Pasqualetti, F., Dorfler, F., Bullo, F., Control-theoretic methods for cyberphysical security: Geometric principles for optimal cross-layer resilient control systems (2015) IEEE Control Systems, 35, pp. 110-127; Leitão, P., Colombo, A.W., Karnouskos, S., Industrial automation based on cyber-physical systems technologies: Prototype implementations and challenges (2016) Computers in Industry, 81, pp. 11-25; Teixeira, A., Pérez, D., Sandberg, H., Johansson, K.H., Attack models and scenarios for networked control systems (2012) Proceedings of the 1st International Conference on High Confidence Networked Systems. ACM, pp. 55-64; Sandberg, H., Teixeira, A.M., From control system security indices to attack identifiability (2016) Science of Security for Cyber-Physical Systems Workshop. IEEE, pp. 1-6; Teixeira, A., (2014) Toward Cyber-secure and Resilient Networked Control Systems, , Ph. D. dissertation, KTH Royal Institute of Technology; Baniamerian, A., Khorasani, K., Meskin, N., Determination of security index for linear cyber-physical systems subject to malicious cyber attacks (2019) Conference on Decision and Control. IEEE; Milosevic, J., Sandberg, H., Johansson, K.H., (2018) A Security Index for Actuators Based on Perfect Undetectability: Properties and Approximation; Schellenberger, C., Zhang, P., Detection of covert attacks on cyberphysical systems by extending the system dynamics with an auxiliary system (2017) Conference on Decision and Control. IEEE, pp. 1374-1379; Hoehn, A., Zhang, P., Detection of covert attacks and zero dynamics attacks in cyber-physical systems (2016) 2016 American Control Conference (ACC). IEEE, pp. 302-307; Trentelman, H.L., Stoorvogel, A.A., Hautus, M., (2001) Control Theory for Linear Systems, , Springer Science & Business Media; Sain, M.K., Massey, J.L., Invertibility of linear time-invariant dynamical systems (1969) IEEE Transactions on Automatic Control, 14, pp. 141-149; Massoumnia, M.-A., (1986) A Geometric Approach to Failure Detection and Identification in Linear Systems, , Ph. D. dissertation, Massachusetts Institute of Technology; Massoumnia, M.A., Verghese, G.C., Willsky, A., Failure detection and identification (1989) IEEE Transactions on Automatic Control, 34, pp. 316-321; Johansson, K.H., The quadruple-tank process: A multivariable laboratory process with an adjustable zero (2000) IEEE Transactions on Control Systems Technology, 8 (3), pp. 456-465",,,"IEEE Control Systems Society (CSS);Spiri Robotics, Inc.",Institute of Electrical and Electronics Engineers Inc.,"4th IEEE Conference on Control Technology and Applications, CCTA 2020",24 August 2020 through 26 August 2020,,163560,,9.78E+12,,,English,CCTA - IEEE Conf. Control Technol. Appl.,Conference Paper,Final,,Scopus,2-s2.0-85094115759
"Xu L., Zeng X., Zhang H., Li W., Lei J., Huang Z.",57210788847;54920639100;57210801226;36067507500;55837949300;57193565509;,BPGAN: Bidirectional CT-to-MRI prediction using multi-generative multi-adversarial nets with spectral normalization and localization,2020,Neural Networks,128,,,82,96,,3,10.1016/j.neunet.2020.05.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084751454&doi=10.1016%2fj.neunet.2020.05.001&partnerID=40&md5=574d52a8043e2cf8c85e02b7ff302ae2,"Chongqing Key Laboratory of Image Cognition, College of Computer Science and Technology, Chongqing University of Posts and Telecommunications, Chongqing, 400065, China; School of Medical Information and Engineering, Southwest Medical University, Luzhou, 646000, China; Center for Medical Informatics, Peking University, Beijing, 100191, China","Xu, L., Chongqing Key Laboratory of Image Cognition, College of Computer Science and Technology, Chongqing University of Posts and Telecommunications, Chongqing, 400065, China; Zeng, X., Chongqing Key Laboratory of Image Cognition, College of Computer Science and Technology, Chongqing University of Posts and Telecommunications, Chongqing, 400065, China; Zhang, H., Chongqing Key Laboratory of Image Cognition, College of Computer Science and Technology, Chongqing University of Posts and Telecommunications, Chongqing, 400065, China; Li, W., Chongqing Key Laboratory of Image Cognition, College of Computer Science and Technology, Chongqing University of Posts and Telecommunications, Chongqing, 400065, China; Lei, J., School of Medical Information and Engineering, Southwest Medical University, Luzhou, 646000, China, Center for Medical Informatics, Peking University, Beijing, 100191, China; Huang, Z., School of Medical Information and Engineering, Southwest Medical University, Luzhou, 646000, China","Magnetic Resonance Imaging (MRI) and Computed Tomography (CT) are widely used detection technology in screening, diagnosis, and image-guided therapy for both clinical and research. However, CT imposes ionizing radiation to patients during acquisition. Compared to CT, MRI is much safer and does not involve any radiations, but it is more expensive and has prolonged acquisition time. Therefore, it is necessary to estimate one modal image from another given modal image of the same subject for the case of radiotherapy planning. Considering that there is currently no bidirectional prediction model between MRI and CT images, we propose a bidirectional prediction by using multi-generative multi-adversarial nets (BPGAN) for the prediction of any modal from another modal image in paired and unpaired fashion. In BPGAN, two nonlinear maps are learned by projecting same pathological features from one domain to another with cycle consistency strategy. Technologically, pathological prior information is introduced to constrain the feature generation to attack the potential risk of pathological variance, and edge retention metric is adopted to preserve geometrically distortion and anatomical structure. Algorithmically, spectral normalization is designed to control the performance of discriminator and to make predictor learn better and faster, and the localization is proposed to impose regularizer on predictor to reduce generalization error. Experimental results show that BPGAN generates better predictions than recently state-of-the-art methods. Specifically, BPGAN achieves average increment of MAE 33.2% and 37.4%, and SSIM 24.5% and 44.6% on two baseline datasets than comparisons. © 2020 Elsevier Ltd",Bidirectional prediction; Cross modality; Generative adversarial nets; Pathological invariance; Spectral normalization,"Clinical research; Diagnosis; Forecasting; Ionizing radiation; Magnetic resonance imaging; Anatomical structures; Bi-directional predictions; Detection technology; Generalization Error; Image guided therapy; Radiotherapy planning; Spectral normalization; State-of-the-art methods; Computerized tomography; algorithm; anatomical concepts; article; computer assisted tomography; controlled study; human; nuclear magnetic resonance imaging; prediction; radiotherapy; image processing; nuclear magnetic resonance imaging; procedures; radiotherapy planning system; software; x-ray computed tomography; Deep Learning; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Radiotherapy Planning, Computer-Assisted; Software; Tomography, X-Ray Computed",,,,,"Arjovsky, M., Chintala, S., Bottou, L., Wasserstein GAN (2017) International conference on machine learning, pp. 214-223; Arora, S., Ge, R., Liang, Y., Ma, T., Zhang, Y., Generalization and equilibrium in generative adversarial nets(GANs) (2017) International conference on machine learning, pp. 1439-1461; Burgos, N., Cardoso, J., Thielemans, K., Modat, M., Pedemonte, S., Dickson, J., Attenuation correction synthesis for hybrid PET-MR scanners: Application to brain studies (2014) IEEE Transactions on Medical Imaging, 33 (12), pp. 2332-2341; Desideri, J., Multiple-gradient descent algorithm (MGDA) for multiobjective optimization (2012) Comptes Rendus Mathematique, 350 (5), pp. 313-318; Dmitry, U., Andrea, V., Victor, L., Instance normalization: The missing ingredient for fast stylization (2016); Donahue, J., Krahenbühl, P., Darrell, T., Adversarial feature learning (2017) International conference on learning representations, pp. 174-191; Dong, C., Loy, C.C., He, K., Tang, X., Image super-resolution using deep convolutional networks (2016) IEEE Transactions on Pattern Analysis and Machine Intelligence, 38 (2), pp. 295-307; Durugkar, I., Gemp, I., Mahadevan, S., Generative multi-adversarial networks (2017) International conference on learning representations, pp. 601-614; Edmund, J., Kjer, H., Leemput, K., Hansen, R., Andersen, J., Andreasen, D., A voxel-based investigation for MRI-only radiotherapy of the brain using ultra short echo times (2014) Physics in Medicine and Biology, 59 (23), pp. 7501-7519; Fu, J., Yang, Y., Singhrao, K., Ruan, D., Low, D., Lewis, J., (0000). Male pelvic synthetic CT generation from T1-weighted MRI using 2D and 3D convolutional neural networks,; Gao, H., Zhuang, L., Weinberger, K., Densely connected convolutional networks (2017) IEEE conference on computer vision and pattern recognition, pp. 2261-2269; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Bing, X., Warde-Farley, D., Ozair, S., Generative adversarial nets (2014) International conference on neural information processing systems, pp. 2672-2680; Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., Courville, A., Improved training of wasserstein GANs (2017) International conference on neural information processing systems, pp. 294-303; Habib, Z., Marie-Louise, M., Daniel, S., Magnetic resonance imaging-guided attenuation and scatter corrections in three-dimensional brain positron emission tomography (2003) Medical Physics, 30 (5), pp. 937-948; Han, X., MR-based synthetic CT generation using a deep convolutional neural network method (2017) Medical Physics, 44 (4), pp. 1408-1419; He, K., Zhang, X., Ren, S., Jian, S., Deep residual learning for image recognition (2016) IEEE conference on computer vision and pattern recognition, pp. 770-781; He, T., Zhang, Z., Zhang, H., Zhang, Z., Xie, J., Li, M., Bag of tricks for image classification with convolutional neural networks (2018) IEEE conference on computer vision and pattern recognition, pp. 558-567; Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., Klambauer, G., Hochreiter, S., GANs trained by a two time-scale update rule converge to a Nash equilibrium (2017) International conference on neural information processing systems, pp. 2672-2680; Hiasa, Y., Otake, Y., Takao, M., Matsuoka, T., Takashima, K., Carass, A., Cross-modality image synthesis from unpaired data using cycleGAN: Effects of gradient consistency loss and training data size (2018) International conference on medical image computing and computer assisted intervention, pp. 31-41; Hoang, Q., Tu, D., Le, T., Phung, D., MGAN: Training generative adversarial nets with multiple generators (2018) International conference on learning representations, pp. 1-24; Hofmann, M., Steinke, F., Scheel, V., Charpiat, G., Farquhar, J., Aschoff, P., MRI-based attenuation correction for PET/MRI: A novel approach combining pattern recognition and atlas registration (2008) The Journal of Nuclear Medicine, 49 (11), pp. 1875-1883; Hsu, S., Cao, Y., Huang, K., Feng, M., Balter, J., Investigation of a method for generating synthetic CT models from MRI scans of the head and neck for radiation therapy (2013) Physics in Medicine and Biology, 58 (23), pp. 1419-1441; Huang, X., Li, Y., Poursaeed, O., Hopcroft, J., Belongie, S., Stacked generative adversarial networks (2017) IEEE conference on computer vision and pattern recognition, pp. 1866-1875; Izquierdo-Garcia1, D., Hansen, A., Forster, S., Benoit, D., Schachoff, S., Furst, S., An SPM8-based approach for attenuation correction combining segmentation and nonrigid template formation: Application to simultaneous PET/MR brain imaging (2014) Journal of Nuclear Medicine, 55 (11), pp. 1825-1830; Jin, C., Kim, H., Jung, W., Joo, S., Park, E., Saem, A., Deep CT to MR synthesis using paired and unpaired data (2018); Johansson, A., Karlsson, M., Nyholm, T., CT substitute derived from MRI sequences with ultrashort echo time (2011) Medical Physics, 38 (5), pp. 2708-2714; Karras, T., Aila, T., Laine, S., Lehtinen, J., Progressive growing of GANs for improved quality, stability, and variation (2017) International conference on learning representations, pp. 1-26; Keereman, V., Fierens, Y., Broux, T., Deene, Y., Lonneux, M., Vandenberghe, S., MRI-based attenuation correction for PET/MRI using ultrashort echo time sequences (2010) The Journal of Nuclear Medicine, 51 (5), pp. 812-818; Kingma, D., Ba, J., Adam: A method for stochastic optimization (2015) ICCS, pp. 1-15; Krizhevsky, A., Sutskever, I., Hinton, G., Imagenet classification with deep convolutional neural networks (2012), pp. 1097-1105; Ledig, C., Theis, L., Huszar, F., Caballero, J., Aitken, A., Tejani, A., Photo-realistic single image super-resolution using a generative adversarial network (2017) IEEE conference on computer vision and pattern recognition, pp. 105-123; Lei, N., Su, K., Cui, L., Yau, S., Gu, X., A geometric view of optimal transportation and generative model (2017); Levin, A., Lischinski, D., Weiss, Y., A closed-form solution to natural image matting (2008) IEEE Transactions on Pattern Analysis and Machine Intelligence, 30 (2), pp. 228-242; Lukaszyk, S., A new concept of probability metric and its applications in approximation of scattered data sets (2004) Computational Mechanics, 33 (4), pp. 299-304; Mérida, I., Costes, N., Heckemann, R., Drzezga, A., Förster, S., Hammers, A., Evaluation of several multi-atlas methods for PSEUDO-CT generation in brain MRI-PET attenuation correction (2015) IEEE international symposium on biomedical imaging, pp. 1431-1434; Nie, D., Trullo, R., Lian, J., Petitjean, C., Ruan, S., Wang, Q., Medical image synthesis with context-aware generative adversarial networks (2017) International conference on medical image computing and computer assisted intervention, pp. 417-425; Odena, A., Olah, C., Shlens, J., Conditional image synthesis with auxiliary classifier GANs (2016) International conference on machine learning, pp. 2642-2651; Pan, X., Zhang, M., Ding, D., Theoretical analysis of image-to-image translation with adversarial learning (2017) International conference on machine learning, pp. 4006-4015; Qi, G., Zhang, L., Hu, H., Edraki, M., Wang, J., Hua, X., Global versus localized generative adversarial nets (2018) IEEE conference on computer vision and pattern recognition, pp. 1517-1525; Roy, S., Carass, A., Prince, J., A compressed sensing approach for MR tissue contrast synthesis (2011) International conference on information processing in medical imaging, pp. 371-383; Shmelkov, K., Schmid, C., Alahari, K., How good is my GAN? (2018) IEEE conference on computer vision and pattern recognition, pp. 3654-3668; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) International conference on learning representations, pp. 1-14; Wang, Z., Simoncelli, E., Bovik, A., Multiscale structural similarity for image quality assessment (2003) IEEE Asilomar conference on signals, systems and computers, pp. 1398-1412; Wolterink, J., Dinkla, A., Savenije, M., Seevinck, P., Berg, C., Isgum, I., Deep MR to CT synthesis using unpaired data (2017); Wu, Y., Yang, W., Lu, L., Lu, Z., Zhong, L., Huang, M., Prediction of CT substitutes from MR images based on local diffeomorphic mapping for brain PET attenuation correction (2016) The Journal of Nuclear Medicine, 57 (10), pp. 1635-1641; Wu, Y., Yang, W., Lu, L., Lu, Z., Zhong, L., Yang, R., Prediction of CT substitutes from MR images based on local sparse correspondence combination (2015) International conference on medical image computing and computer assisted intervention, pp. 93-100; Xiang, L., Wang, Q., Nie, D., Zhang, L., Jin, X., Qiao, Y., Deep embedding convolutional neural network for synthesizing CT image from T1-Weighted MR image (2018) Medical Image Analysis, 47, pp. 31-44; Yang, H., Sun, J., Carass, A., Zhao, C., Lee, J., Xu, Z., Unpaired brain MR-to-CT synthesis using a structure-constrained cyclegan (2018); Yang, J., Wright, J., Huang, T., Ma, Y., Image super-resolution as sparse representation of raw image patches (2008) IEEE conference on computer vision and pattern recognition, pp. 1-8; Yang, G., Yu, S., Dong, H., Slabaugh, G., Dragotti, P., Ye, X., DAGAN: Deep de-aliasing generative adversarial networks for fast compressedsensing MRI reconstruction (2018) IEEE Transactions on Medical Imaging, 37 (6), pp. 1310-1321; Yang, W., Zhong, L., Chen, Y., Lin, L., Lu, Z., Liu, S., Predicting CT image from MRI data through feature matching with learned nonlinear local descriptors (2018) IEEE Transactions on Medical Imaging, 37 (4), pp. 977-987; Yoshida, Y., Miyato, T., Spectral norm regularization for improving the generalizability of deep learning (2018) International conference on neural information processing systems, pp. 1539-1550; Zhang, Z., Yang, L., Zheng, Y., Translating and segmenting multimodal medical volumes with cycle- and shape-consistency generative adversarial network (2018) IEEE conference on computer vision and pattern recognition, pp. 9242-9251; Zhang, L., Zhang, L., Mou, X., Zhang, D., FSIM: a feature similarity index for image quality assessment (2011) IEEE Transactions on Image Processing, 20 (8), pp. 2378-2386; Zhu, J., Park, T., Isola, P., Efros, A., Unpaired image-to-image translation using cycle-consistent adversarial networks (2017) IEEE international conference on computer vision, pp. 2242-2251","Zeng, X.; Chongqing Key Laboratory of Image Cognition, China; 电子邮件: zengxh@cqupt.edu.cn",,,Elsevier Ltd,,,,,8936080,,NNETE,32442629,English,Neural Netw.,Article,Final,,Scopus,2-s2.0-85084751454
"Zhang H., Jia F., Zhang Q., Han Y., Kuang X., Tan Y.-A.",57218836915;57218836438;15049993600;55489219500;7006865075;35197214100;,Two-way feature-aligned and attention-rectified adversarial training,2020,Proceedings - IEEE International Conference on Multimedia and Expo,2020-July,,9102777,,,,1,10.1109/ICME46284.2020.9102777,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090381059&doi=10.1109%2fICME46284.2020.9102777&partnerID=40&md5=e084785dab7be23813a8223a28b9a09a,"Tianjin University, College of Intelligence and Computing, Tianjin, China; Tianjin Key Lab of Machine Learning, College of Intelligence and Computing, Tianjin, China; Beijing Institute of Technology, China; National Key Laboratory of Science and Technology on Information System Security, China","Zhang, H., Tianjin University, College of Intelligence and Computing, Tianjin, China, Tianjin Key Lab of Machine Learning, College of Intelligence and Computing, Tianjin, China; Jia, F., Tianjin University, College of Intelligence and Computing, Tianjin, China, Tianjin Key Lab of Machine Learning, College of Intelligence and Computing, Tianjin, China; Zhang, Q., Beijing Institute of Technology, China; Han, Y., Tianjin University, College of Intelligence and Computing, Tianjin, China, Tianjin Key Lab of Machine Learning, College of Intelligence and Computing, Tianjin, China; Kuang, X., National Key Laboratory of Science and Technology on Information System Security, China; Tan, Y.-A., Beijing Institute of Technology, China","Adversarial training increases robustness by augmenting training data with adversarial examples. However, vanilla adversarial training may be overfitting to certain adversarial attacks. Small perturbations in images bring in error which is gradually amplified when forwarded through the model so that the error leads to wrong classification. Besides, small perturbations will also distract classifier's attention to significant features that are relevant to the true label. In this paper, we propose a novel two-way feature-aligned and attention-rectified adversarial training (FAAR) to improve adversarial training (AT). FAAR utilizes two-way feature alignment and attention rectification to mitigate the problems mentioned above. FAAR effectively suppresses perturbations in lowlevel, high-level and global features by moving features of perturbed images towards those of clean images with twoway feature alignment. It also leads the model into focusing more on useful features which are correlated with true label through rectifying gradient-weighted attention. Besides, feature alignment activates attention rectification by reducing perturbations in high-level feature. Our proposed method FAAR surpasses other existing AT methods in three aspects. First, it pushes the model to keep invariant when dealing with different adversarial attacks and different magnitude of perturbations. Second, it can be applied to any convolution neural networks. Third, the training process is end-to-end. For experiments, FAAR shows promising defense performance on CIFAR-10 and ImageNet. © 2020 IEEE.",Adversarial training; Attention rectification; Feature alignment,Clean images; Convolution neural network; Feature alignment; Global feature; High-level features; Small perturbations; Training data; Training process; Alignment,,,,,"Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R., Intriguing properties of neural networks (2014) ICLR; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR; Wang, D., Li, C., Wen, S., Nepal, S., Xiang, Y., (2019) Daedalus: Breaking Non-maximum Suppression in Object Detection Via Adversarial Examples; Li, J., Qu, S., Li, X., Szurley, J., Zico Kolter, J., Metze, F., Adversarial music: Real world audio adversary against wake-word detection system (2019) NeurIPS, pp. 11908-11918; Finlayson, S.G., Bowers, J.D., Ito, J., Zittrain, J.L., Beam, A.L., Kohane, I.S., Adversarial attacks on medical machine learning (2019) Science, 363 (6433), pp. 1287-1289; Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2018) ICLR; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) ICLR; Ilyas, A., Santurkar, S., Tsipras, D., Engstrom, L., Tran, B., Madry, A., Adversarial examples are not bugs, they are features (2019) NeurIPS, pp. 125-136; Liao, F., Liang, M., Dong, Y., Pang, T., Hu, X., Zhu, J., Defense against adversarial attacks using high-level representation guided denoiser (2018) CVPR, pp. 1778-1787; Xu, W., Evans, D., Qi, Y., Feature squeezing: Detecting adversarial examples in deep neural networks (2018) NDSS; Vincent, P., Larochelle, H., Bengio, Y., Manzagol, P., Extracting and composing robust features with denoising autoencoders (2008) ICML, pp. 1096-1103; Gu, S., Rigazio, L., (2014) Towards Deep Neural Network Architectures Robust to Adversarial Examples; Selvaraju, R.R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., Batra, D., Grad-cam: Visual explanations from deep networks via gradient-based localization (2017) ICCV, pp. 618-626; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy, pp. 39-57; Na, T., Hwan Ko, J., Mukhopadhyay, S., Cascade adversarial machine learning regularized with a unified embedding (2018) ICLR",,,et al.;IEEE;Springer;Tencent Media Lab;The Institution of Engineering and Technology (IET);YouTube,IEEE Computer Society,"2020 IEEE International Conference on Multimedia and Expo, ICME 2020",6 July 2020 through 10 July 2020,,162356,19457871,9.78E+12,,,English,Proc. IEEE Int. Conf. Multimedia Expo,Conference Paper,Final,,Scopus,2-s2.0-85090381059
"Hou X., Liu J., Xu B., Wang X., Liu B., Qiu G.",57194454615;57207461944;56911419400;57141185000;56828269600;7103292111;,Class-aware domain adaptation for improving adversarial robustness,2020,Image and Vision Computing,99,,103926,,,,1,10.1016/j.imavis.2020.103926,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084337140&doi=10.1016%2fj.imavis.2020.103926&partnerID=40&md5=8ab022c4bb026fd4c2ea98ee0781353e,"College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; College of Electronic and Information Engineering, Guangdong Key Laboratory of Intelligent Information Processing, Shenzhen University, Shenzhen, China; IBM, San Jose, CA, United States; Shenzhen Institute of Artificial Intelligence and Robotics for Society, Shenzhen, China; School of Computer Science, University of Nottingham, Nottingham, United Kingdom","Hou, X., College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China, College of Electronic and Information Engineering, Guangdong Key Laboratory of Intelligent Information Processing, Shenzhen University, Shenzhen, China; Liu, J., College of Electronic and Information Engineering, Guangdong Key Laboratory of Intelligent Information Processing, Shenzhen University, Shenzhen, China; Xu, B., College of Electronic and Information Engineering, Guangdong Key Laboratory of Intelligent Information Processing, Shenzhen University, Shenzhen, China; Wang, X., IBM, San Jose, CA, United States; Liu, B., College of Electronic and Information Engineering, Guangdong Key Laboratory of Intelligent Information Processing, Shenzhen University, Shenzhen, China; Qiu, G., College of Electronic and Information Engineering, Guangdong Key Laboratory of Intelligent Information Processing, Shenzhen University, Shenzhen, China, Shenzhen Institute of Artificial Intelligence and Robotics for Society, Shenzhen, China, School of Computer Science, University of Nottingham, Nottingham, United Kingdom","Recent works have demonstrated convolutional neural networks are vulnerable to adversarial examples, i.e., inputs to machine learning models that an attacker has intentionally designed to cause the models to make a mistake. To improve the adversarial robustness of neural networks, adversarial training has been proposed to train networks by injecting adversarial examples into the training data. However, adversarial training could overfit to a specific type of adversarial attack and also lead to standard accuracy drop on clean images. To this end, we propose a novel Class-Aware Domain Adaptation (CADA) method for adversarial defense without directly applying adversarial training. Specifically, we propose to learn domain-invariant features for adversarial examples and clean images via a domain discriminator. Furthermore, we introduce a class-aware component into the discriminator to increase the discriminative power of the network for adversarial examples. We evaluate our newly proposed approach using multiple benchmark datasets. The results demonstrate that our method can significantly improve the state-of-the-art of adversarial robustness for various attacks and maintain high performances on clean images. © 2020 Elsevier B.V.",Adversarial robustness; Domain adaptation,Convolutional neural networks; Benchmark datasets; Discriminative power; Domain adaptation; Invariant features; Machine learning models; State of the art; Training data; Various attacks; Image enhancement,,,,,"Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) ICLR; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) NIPS; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) ICLR; Sitawarin, C., Bhagoji, A.N., Mosenia, A., Chiang, M., Mittal, P., Darts: Deceiving Autonomous Cars With Toxic Signs arXiv preprint; Dong, Y., Su, H., Wu, B., Li, Z., Liu, W., Zhang, T., Zhu, J., Efficient decision-based black-box adversarial attacks on face recognition (2019) CVPR; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards Deep Learning Models Resistant to Adversarial Attacks (2018); Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I.J., Boneh, D., McDaniel, P.D., Ensemble adversarial training: Attacks and defenses (2018) ICLR; Liao, F., Liang, M., Dong, Y., Pang, T., Hu, X., Zhu, J., Defense against adversarial attacks using high-level representation guided denoiser (2018) CVPR; Ben-David, S., Blitzer, J., Crammer, K., Pereira, F., Analysis of representations for domain adaptation (2007) NIPS; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial Machine Learning at Scale arXiv preprint; Su, J., Vargas, D.V., Sakurai, K., One pixel attack for fooling deep neural networks, IEEE Trans. Evol. Comput; Engstrom, L., Tran, B., Tsipras, D., Schmidt, L., Madry, A., Rotation, A., a Translation Suffice: Fooling cnns With Simple Transformations, arXiv preprint ; Dong, Y., Pang, T., Su, H., Zhu, J., Evading defenses to transferable adversarial examples by translation-invariant attacks (2019) CVPR; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial examples in the physical world (2017) ICLR (Workshop); Wang, Y., Wang, K., Zhu, Z., Wang, F.-Y., Adversarial attacks on faster r-cnn object detector (2020) Neurocomputing, 382, pp. 87-95; Kannan, H., Kurakin, A., Goodfellow, I., Adversarial Logit Pairing arXiv preprint; Xie, C., Wu, Y., Maaten, L.V.D., Yuille, A.L., He, K., Feature denoising for improving adversarial robustness (2019) CVPR; Zhang, H., Yu, Y., Jiao, J., Xing, E.P., Ghaoui, L.E., Jordan, M.I., Theoretically principled trade-off between robustness and accuracy (2019) ICLR; Liu, G., Khalil, I., Khreishah, A., Gandef: A gan based adversarial training defense for neural network classifier (2019) IFIP International Conference on ICT Systems Security and Privacy Protection, pp. 19-32. , Springer; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) 2016 IEEE Symposium on Security and Privacy (SP), pp. 582-597. , IEEE; Moosavi-Dezfooli, S.-M., Shrivastava, A., Tuzel, O., Divide, Denoise, and Defend Against Adversarial Attacks arXiv preprint; He, Z., Rakin, A.S., Fan, D., Parametric noise injection: trainable randomness to improve deep neural network robustness against adversarial attack (2019) CVPR; Sun, B., Tsai, N.-H., Liu, F., Yu, R., Su, H., Adversarial defense by stratified convolutional sparse coding (2019) CVPR; Song, C., He, K., Wang, L., Hopcroft, J.E., Improving the generalization of adversarial training with domain adaptation (2019) ICLR; Ben-David, S., Blitzer, J., Crammer, K., Kulesza, A., Pereira, F., Vaughan, J.W., A theory of learning from different domains (2010) Mach. Learn., 79 (1-2), pp. 151-175; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) NIPS; Chen, Y., Li, W., Sakaridis, C., Dai, D., Van Gool, L., Domain adaptive faster r-cnn for object detection in the wild (2018) CVPR; Mao, X., Li, Q., Xie, H., Lau, R.Y., Wang, Z., Paul Smolley, S., Least squares generative adversarial networks (2017) ICCV; Nicolae, M.-I., Sinn, M., Tran, M.N., Buesser, B., Rawat, A., Wistuba, M., Zantedeschi, V., Edwards, B., Adversarial Robustness Toolbox v0.10.0, CoRR 1807.01069 (2020); Kingma, D.P., Ba, J.L., Adam: A method for stochastic optimization (2015) ICLR; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324; He, K., Zhang, X., Ren, S., Sun, J., Identity mappings in deep residual networks (2016) ECCV; Maaten, L.V.D., Hinton, G., Visualizing data using t-sne (2008) Journal of Machine Learning Research, pp. 2579-2605. , 9 (Nov)","Qiu, G.; College of Electronic and Information Engineering, China; 电子邮件: guoping.qiu@nottingham.ac.uk",,,Elsevier Ltd,,,,,2628856,,IVCOD,,English,Image Vision Comput,Article,Final,"All Open Access, Green",Scopus,2-s2.0-85084337140
"Sun Q., Zhang K., Shi Y.",57199812632;57193017083;35105958600;,Resilient Model Predictive Control of Cyber-Physical Systems under DoS Attacks,2020,IEEE Transactions on Industrial Informatics,16,7,8946762,4920,4927,,40,10.1109/TII.2019.2963294,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082995347&doi=10.1109%2fTII.2019.2963294&partnerID=40&md5=a24f1568070fef0384a7af6006171b33,"Department of Mechanical Engineering, University of Victoria, Victoria, BC  V8W 2Y2, Canada","Sun, Q., Department of Mechanical Engineering, University of Victoria, Victoria, BC  V8W 2Y2, Canada; Zhang, K., Department of Mechanical Engineering, University of Victoria, Victoria, BC  V8W 2Y2, Canada; Shi, Y., Department of Mechanical Engineering, University of Victoria, Victoria, BC  V8W 2Y2, Canada","This article presents a resilient model predictive control (MPC) framework to attenuate adverse effects of denial-of-service (DoS) attacks for cyber-physical systems (CPSs), where the system dynamics is modeled by a linear time-invariant system. A DoS attacker targets at blocking the controller to actuator (C-A) communication channel by launching adversarial jamming signals. We show that, in order to guarantee exponential stability of the closed-loop system, several conditions for resilient MPC should be satisfied. And these established conditions are explicitly related to the duration of DoS attacks and MPC parameters such as the prediction horizon and the terminal constraint. Two key techniques, including the μ-step positively invariant set and the modified initial feasible set are exploited for achieving exponential stability in the presence of DoS attacks. Moreover, the maximum allowable duration of the DoS attacker is also obtained by using the μ-step positively invariant set. Finally, the effectiveness of the proposed MPC algorithm is verified by simulated studies and comparisons. © 2005-2012 IEEE.",Cyber-physical system (CPS); denial-of-service (DoS) attack; networked control system; resilient model predictive control (MPC),Closed loop systems; Cyber Physical System; Embedded systems; Invariance; Linear control systems; Linear systems; Model predictive control; Networked control systems; Predictive control systems; Time varying control systems; Cyber physical systems (CPSs); Cyber-physical systems (CPS); Denial of Service; Jamming signals; Linear time invariant systems; Positively invariant sets; Prediction horizon; Terminal constraint; Denial-of-service attack,,,,,"Gupta, R.A., Chow, M.-Y., Networked control system: Overview and research trends (2010) IEEE Trans. Ind. Informat., 57 (7), pp. 2527-2535. , Jul; Rajkumar, R.R., Lee, I., Sha, L., Stankovic, J., Cyber-physical systems: The next computing revolution (2010) Proc. 47th Des. Autom. Conf.Anaheim, pp. 731-736. , California, USA Jun; Cárdenas, A.A., Amin, S., Sastry, S., Research challenges for the security of control systems (2008) Proc. 3rd Conf. Hot Topics Secur., pp. 1-6; Cheminod, M., Durante, L., Valenzano, A., Reviewof security issues in industrial networks (2013) IEEE Trans. Ind. Informat., 9 (1), pp. 277-293. , Feb; Rieger, C.G., Gertman, D.I., McQueen, M.A., Resilient control systems: Next generation design research (2009) Proc. 2nd Conf. Human Syst. Interact., pp. 632-636; Cárdenas, A.A., Amin, S., Sastry, S., Secure control: Towards surviv-able cyber-physical systems (2008) Proc. 28th Int. Conf. Distrib. Comput. Syst, pp. 495-500. , Beijing, China Jun; Long, M., Wu, C.-H., Hung, J.Y., Denial of service attacks on network-based control systems: Impact and mitigation (2005) IEEE Trans. Ind. Informat., 1 (2), pp. 85-96. , May; Amin, S., Cárdenas, A.A., Sastry, S.S., Safe and secure networked control systems under denial-of-service attacks (2009) Proc. Int. Workshop Hybrid Syst.: Comput. Control, pp. 31-45. , Springer; Mo, Y., Sinopoli, B., Secure control against replay attacks (2009) Proc. 47th Annu. Allerton Conf. Commun., Control, Comput, pp. 911-918. , Monticello, IL, USA, Oct; Teixeira, A., Shames, I., Sandberg, H., Johansson, K.H., A secure control framework for resource-limited adversaries (2015) Automatica, 51, pp. 135-148; De Persis, C., Tesi, P., Input-to-state stabilizing control under denial-of-service (2015) IEEE Trans. Autom. Control, 60 (11), pp. 2930-2944. , Nov; Yuan, Y., Yuan, H., Guo, L., Yang, H., Sun, S., Resilient control of networked control system under DoS attacks: A unified game approach (2016) IEEE Trans. Ind. Informat., 12 (5), pp. 1786-1794. , Oct; Lu, A.-Y., Yang, G.-H., Input-to-state stabilizing control for cyber-physical systems with multiple transmission channels under denial of service (2018) IEEE Trans. Autom. Control, 63 (6), pp. 1813-1820. , Jun; Qin, S.J., Badgwell, T.A., A survey of industrial model predictive control technology (2003) Control Eng. Pract., 11 (7), pp. 733-764; Hrovat, D., Di Cairano, S., Tseng, H.E., Kolmanovsky, I.V., The development of model predictive control in automotive industry: A survey (2012) Proc. IEEE Intl. Conf. Control Appl, pp. 295-302. , Dubrovnik, Croatia, Oct; Mayne, D.Q., Rawlings, J.B., Rao, C.V., Scokaert, P.O., Constrained model predictive control: Stability and optimality (2000) Automatica, 36 (6), pp. 789-814; Mo, Y., Sinopoli, B., On the performance degradation of cyber-physical systems under stealthy integrity attacks (2016) IEEE Trans. Autom. Control, 61 (9), pp. 2618-2624. , Sep; Feng, S., Tesi, P., Resilient control under denial-of-service: Robust design (2017) Automatica, 79, pp. 42-51; Gupta, A., Langbort, C., Başar, T., Optimal control in the presence of an intelligent jammer with limited actions (2010) Proc. 49th IEEE Conf. Decis. Control, pp. 1096-1101. , Atlanta, GA, USA, Dec; Amin, S., Schwartz, G.A., Sastry, S.S., Security of interdependent and identical networked control systems (2013) Automatica, 49 (1), pp. 186-192; Chisci, L., Lombardi, A., Mosca, E., Dual-receding horizon control of constrained discrete time systems (1996) Eur. J. Control, 2 (4), pp. 278-285; Chen, H., Allgöwer, F., A quasi-infinite horizon nonlinear model predictive control scheme with guaranteed stability (1998) Automatica, 34 (10), pp. 1205-1217; Scokaert, P.O., Mayne, D.Q., Rawlings, J.B., Suboptimal model predictive control (feasibility implies stability) (1999) IEEE Trans. Autom. Control, 44 (3), pp. 648-654. , Mar; Michalska, H., Mayne, D.Q., Robust receding horizon control of constrained nonlinear systems (1993) IEEE Trans. Autom. Control, 38 (11), pp. 1623-1633. , Nov; Blanchini, F., Set invariance in control (1999) Automatica, 35 (11), pp. 1747-1767; Golub, G.H., Van Loan, C.F., (2012) Matrix Computations, , Baltimore, MD, USA: JHU Press; Herceg, M., Kvasnica, M., Jones, C., Morari, M., Multi-parametric toolbox 3.0 (2013) Proc. Eur. Control Conf, pp. 502-510. , http://control.ee.ethz.ch/mpt, Zürich, Switzerland Jul. [Online]; Ferreau, H.J., Kirches, C., Potschka, A., Bock, H.G., Diehl, M., QpOASES: A parametric active-set algorithm for quadratic programming (2014) Math. Program. Comput., 6 (4), pp. 327-363","Shi, Y.; Department of Mechanical Engineering, Canada; 电子邮件: yshi@uvic.ca",,,IEEE Computer Society,,,,,15513203,,,,English,IEEE Trans. Ind. Inf.,Article,Final,,Scopus,2-s2.0-85082995347
"Nguyen D.-L., Arora S.S., Wu Y., Yang H.",57214528483;55368324800;57218711862;57195956258;,Adversarial light projection attacks on face recognition systems: A feasibility study,2020,IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops,2020-June,,9150692,3548,3556,,6,10.1109/CVPRW50498.2020.00415,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090166405&doi=10.1109%2fCVPRW50498.2020.00415&partnerID=40&md5=612cc10f6963fb1a90350e9617c01659,"Visa Research, Palo Alto, CA, United States; Michigan State University, East Lansing, MI  48824, United States","Nguyen, D.-L., Visa Research, Palo Alto, CA, United States, Michigan State University, East Lansing, MI  48824, United States; Arora, S.S., Visa Research, Palo Alto, CA, United States; Wu, Y., Visa Research, Palo Alto, CA, United States; Yang, H., Visa Research, Palo Alto, CA, United States","Deep learning-based systems have been shown to be vulnerable to adversarial attacks in both digital and physical domains. While feasible, digital attacks have limited applicability in attacking deployed systems, including face recognition systems, where an adversary typically has access to the input and not the transmission channel. In such setting, physical attacks that directly provide a malicious input through the input channel pose a bigger threat. We investigate the feasibility of conducting real-time physical attacks on face recognition systems using adversarial light projections. A setup comprising a commercially available web camera and a projector is used to conduct the attack. The adversary uses a transformation-invariant adversarial pattern generation method to generate a digital adversarial pattern using one or more images of the target available to the adversary. The digital adversarial pattern is then projected onto the adversary's face in the physical domain to either impersonate a target (impersonation) or evade recognition (obfuscation). We conduct preliminary experiments using two open-source and one commercial face recognition system on a pool of 50 subjects. Our experimental results demonstrate the vulnerability of face recognition systems to light projection attacks in both white-box and black-box attack settings. © 2020 IEEE.",,Computer vision; Deep learning; Open systems; Real time systems; Deployed systems; Face recognition systems; Feasibility studies; Light projection; Pattern Generation; Physical attacks; Transformation invariants; Transmission channels; Face recognition,,,,,"(2019) Pico Mini Portable Projector, , https://www.amazon.com/Portable-Projector-Haidiscool-Smartphone-Entertainment/dp/B07DWX5FGM/, [Online; accessed 10-September-2019]. 2; Athalye, A., Engstrom, L., Ilyas, A., Kwok, K., (2017) Synthesizing Robust Adversarial Examples, , 3, 5; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP), pp. 39-57. , IEEE, 1, 3; Chen, S., Cornelius, C., Martin, J., Chau, D., Shapeshifter: Robust physical adversarial attack on faster R-CNN object detector (2018) Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 52-68. , Springer, 3; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 9185-9193. , 2; Dong, Y., Pang, T., Su, H., Zhu, J., Evading defenses to transferable adversarial examples by translation-invariant attacks (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4312-4321. , 5; Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Xiao, C., Prakash, A., Song, D., Robust physicalworld attacks on deep learning visual classification (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1625-1634. , 1, 3; Goodfellow, I., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , 1, 2; Huang, G., Mattar, M., Berg, T., Learned-Miller, E., (2008) Labeled Faces in the Wild: A Database for Studying Face Recognition in Unconstrained Environments., , 8; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , 1, 2, 3; Li, J., Schmidt, F., Kolter, Z., Adversarial camera stickers: A physical camera-based attack on deep learning systems (2019) International Conference on Machine Learning, pp. 3896-3904. , 3; Liu, W., Wen, Y., Yu, Z., Li, M., Raj, B., Song, L., Sphereface: Deep hypersphere embedding for face recognition (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 212-220. , 3, 7, 8; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) Proceedings of the International Conference on Learning Representations, , 1, 3; Marcel, S., Nixon, M., Li, S., Handbook of biometric antispoofing (2014) Springer, 1. , 1; Modas, A., Moosavi-Dezfooli, S., Frossard, P., Sparsefool: A few pixels make a big difference (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 9087-9096. , 3; Moosavi-Dezfooli, S., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582. , 1, 3; Nichols, N., Jasper, R., (2018) Projecting Trouble: Light Based Adversarial Attacks on Deep Learning Classifiers, , 2, 3; Schroff, F., Kalenichenko, D., Philbin, J., Facenet: A unified embedding for face recognition and clustering (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 815-823. , 1, 3, 6, 7; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M., Accessorize to a crime: Real and stealthy attacks on state-ofthe-art face recognition (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540. , ACM, 1, 6; Shi, Y., Wang, S., Han, Y., Curls & whey: Boosting blackbox adversarial attacks (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, , 2; Song, D., Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Tramer, F., Kohno, T., Physical adversarial examples for object detectors (2018) 12th {USENIX} Workshop on Offensive Technologies ({WOOT} 18), , 3; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) Proceedings of the International Conference on Learning Representations, , 1, 2; Thys, S., Van Ranst, W., Goedemé, T., Fooling automated surveillance cameras: Adversarial patches to attack person detection (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, , 3; Wu, L., Zhu, Z., Tai, C., (2018) Understanding and Enhancing the Transferability of Adversarial Examples, , 2; Xie, C., Zhang, Z., Zhou, Y., Bai, S., Wang, J., Ren, Z., Yuille, A., Improving transferability of adversarial examples with input diversity (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2730-2739. , 2; Zhang, K., Zhang, Z., Li, Z., Qiao, Y., Joint face detection and alignment using multitask cascaded convolutional networks (2016) IEEE Signal Processing Letters, 23 (10), pp. 1499-1503. , 7; Zhao, Y., Zhu, H., Shen, Q., Liang, R., Chen, K., Zhang, S., (2018) Practical Adversarial Attack Against Object Detector, , 3; Zhou, Z., Tang, D., Wang, X., Han, W., Liu, X., Zhang, K., (2018) Invisible Mask: Practical Attacks on Face Recognition with Infrared, , 2, 3","Arora, S.S.; Visa ResearchUnited States; 电子邮件: sunarora@visa.com",,,IEEE Computer Society,"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, CVPRW 2020",14 June 2020 through 19 June 2020,,162075,21607508,9.78E+12,,,English,IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recogn. Workshops,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85090166405
"Chen J., Konrad J., Ishwar P.",57189458230;7102355164;6602873044;,A cyclically-trained adversarial network for invariant representation learning,2020,IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops,2020-June,,9150707,3393,3402,,,10.1109/CVPRW50498.2020.00399,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090115119&doi=10.1109%2fCVPRW50498.2020.00399&partnerID=40&md5=1bc32b9d9c8a5a35316eb72b276fd340,"Boston University, United States","Chen, J., Boston University, United States; Konrad, J., Boston University, United States; Ishwar, P., Boston University, United States","Recent studies show that deep neural networks are vulnerable to adversarial examples which can be generated via certain types of transformations. Being robust to a desired family of adversarial attacks is then equivalent to being invariant to a family of transformations. Learning invariant representations then naturally emerges as an important goal to achieve which we explore in this paper within specific application contexts. Specifically, we propose a cyclically-trained adversarial network to learn a mapping from image space to latent representation space and back such that the latent representation is invariant to a specified factor of variation (e.g., identity). The learned mapping assures that the synthesized image is not only realistic, but has the same values for unspecified factors (e.g., pose and illumination) as the original image and a desired value of the specified factor. Unlike disentangled representation learning, which requires two latent spaces, one for specified and another for unspecified factors, invariant representation learning needs only one such space. We encourage invariance to a specified factor by applying adversarial training using a variational autoencoder in the image space as opposed to the latent space. We strengthen this invariance by introducing a cyclic training process (forward and backward cycle). We also propose a new method to evaluate conditional generative networks. It compares how well different factors of variation can be predicted from the synthesized, as opposed to real, images. In quantitative terms, our approach attains state-of-the-art performance in experiments spanning three datasets with factors such as identity, pose, illumination or style. Our method produces sharp, high-quality synthetic images with little visible arte-facts compared to previous approaches. © 2020 IEEE.",,Computer vision; Deep neural networks; Mapping; Adversarial networks; Application contexts; Forward-and-backward; Invariant representation; Representation space; State-of-the-art performance; Synthesized images; Synthetic images; Deep learning,,,,,"Ariz, M., Bengoechea, J.J., Villanueva, A., Cabeza, R., A novel 2d/3d database with automatic face annotation for head tracking and pose estimation (2016) Computer Vision and Image Understanding, 148, pp. 201-210. , 4; Athalye, A., Engstrom, L., Ilyas, A., Kwok, K., (2017) Synthesizing Robust Adversarial Examples, , 1; Aubry, M., Maturana, D., Efros, A.A., Russell, B.C., Sivic, J., Seeing 3D chairs: Exemplar partbased 2d-3D alignment using a large dataset of cad models (2014) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3762-3769. , 4; Bao, J., Chen, D., Wen, F., Li, H., Hua, G., Cvae-gan: Fine-grained image generation through asymmetric training (2017) Proceedings of the IEEE International Conference on Computer Vision, pp. 2745-2754. , 3; Bengio, Y., Courville, A., Vincent, P., Representation learning: A review and new perspectives (2013) IEEE Transactions on Pattern Analysis and Machine Intelligence, 35 (8), pp. 1798-1828. , 1, 2; Calders, T., Verwer, S., Three naive bayes approaches for discrimination-free classification (2010) Data Mining and Knowledge Discovery, 21 (2), pp. 277-292. , 2; Chen, J., Konrad, J., Ishwar, P., Vganbased image representation learning for privacy-preserving facial expression recognition (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, pp. 1570-1579. , 2, 3; Chen, J., Wu, J., Konrad, J., Ishwar, P., Semi-coupled two-stream fusion convnets for action recognition at extremely low resolutions (2017) 2017 IEEE Winter Conference on Applications of Computer Vision (WACV), pp. 139-147. , IEEE, 2; Chen, J., Wu, J., Richter, K., Konrad, J., Ishwar, P., Estimating head pose orientation using extremely low resolution images (2016) 2016 IEEE Southwest Symposium on Image Analysis and Interpretation (SSIAI), pp. 65-68. , IEEE, 2; Chen, X., Duan, Y., Houthooft, R., Schulman, J., Sutskever, I., Abbeel, P., Infogan: Interpretable representation learning by information maximizing generative adversarial nets (2016) Advances in Neural Information Processing Systems, pp. 2172-2180. , 3; Cheng, G., Zhou, P., Han, J., Learning rotation-invariant convolutional neural networks for object detection in vhr optical remote sensing images (2016) IEEE Transactions on Geoscience and Remote Sensing, 54 (12), pp. 7405-7415. , 2; Choi, Y., Choi, M., Kim, M., Ha, J., Kim, S., Choo, J., Stargan: Unified generative adversarial networks for multi-domain image-to-image translation (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 8789-8797. , 6; Cohen, T., Welling, M., Group equivariant convolutional networks (2016) International Conference on Machine Learning, pp. 2990-2999. , 2; Dalal, N., Triggs, B., Histograms of oriented gradients for human detection (2005) International Conference on Computer Vision & Pattern Recognition (CVPR'05), 1, pp. 886-893. , IEEE Computer Society, 2; Edwards, H., Storkey, A., (2015) Censoring Representations with An Adversary, , 2; Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette, F., Marchand, M., Lempitsky, V., Domain-adversarial training of neural networks (2016) The Journal of Machine Learning Research, 17 (1), pp. 2030-2096. , 2; Ghahramani, Z., Factorial learning and the em algorithm (1995) Advances in Neural Information Processing Systems, pp. 617-624. , 3; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, pp. 2672-2680. , 2; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , 1; Hadad, N., Wolf, L., Wolf, L., Shahar, M., A two-step disentanglement method (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 772-780. , 2, 3, 4, 5, 6, 7, 8; Harsh Jha, A., Anand, S., Singh, M., Veeravasarapu, V., Disentangling factors of variation with cycleconsistent variational auto-encoders (2018) Proceedings of the European Conference on Computer Vision (ECCV), pp. 805-820. , 2, 3, 4, 5, 6, 7, 8; Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., Hochreiter, S., Gans trained by a two time-scale update rule converge to a local nash equilibrium (2017) Advances in Neural Information Processing Systems, pp. 6626-6637. , 6; Hoffman, J., Rodner, E., Donahue, J., Darrell, T., Saenko, K., (2013) Efficient Learning of Domain-invariant Image Representations, , 2; Hu, Q., Szabó, A., Portenier, T., Favaro, P., Zwicker, M., Disentangling factors of variation by mixing them (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3399-3407. , 3; Hwang, U., Park, J., Jang, H., Yoon, S., Ik Cho, N., Puvae: A variational autoencoder to purify adversarial examples (2019) IEEE Access, 7, pp. 126582-126593. , 1; Jin, Y., Zhang, J., Li, M., Tian, Y., Zhu, H., Fang, Z., (2017) Towards the Automatic Anime Characters Creation with Generative Adversarial Networks, , 2; Kingma, D.P., Welling, M., (2013) Auto-encoding Variational Bayes, , 2; Lample, G., Zeghidour, N., Usunier, N., Bordes, A., Denoyer, L., Fader networks: Manipulating images by sliding attributes (2017) Advances in Neural Information Processing Systems, pp. 5967-5976. , 2; Boesen Lindbo Larsen, A., Kaae Sønderby, S., Larochelle, H., Winther, O., (2015) Autoencoding beyond Pixels Using A Learned Similarity Metric, , 3; Lee, K.C., Ho, J., Kriegman, D., Acquiring linear subspaces for face recognition under variable lighting (2005) IEEE Trans. Pattern Anal. Mach. Intelligence, 27 (5), pp. 684-698. , 4; Li, Y., Gong, M., Tian, X., Liu, T., Tao, D., Domain generalization via conditional invariant representations (2018) Thirty-Second AAAI Conference on Artificial Intelligence, , 2; Li, Y., Swersky, K., Zemel, R., (2014) Learning Unbiased Features, , 2; Liu, Y., Chen, X., Liu, C., Song, D., (2016) Delving into Transferable Adversarial Examples and Blackbox Attacks, , 1; Lowe, D.G., Object recognition from local scaleinvariant features (1999) ICCV, 99, pp. 1150-1157. , 2; Mathieu, M.F., Jake Zhao, J., Zhao, J., Ramesh, A., Sprechmann, P., LeCun, Y., Disentangling factors of variation in deep representation using adversarial training (2016) Advances in Neural Information Processing Systems, pp. 5040-5048. , 3; Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., Chen, X., Improved techniques for training gans (2016) Advances in Neural Information Processing Systems, pp. 2234-2242. , 6; Soatto, S., Chiuso, A., (2014) Visual Representations: Defining Properties and Deep Approximations, , 2; Tenenbaum, J.B., Freeman, W.T., Separating style and content with bilinear models (2000) Neural Computation, 12 (6), pp. 1247-1283. , 3; Tran, L., Yin, X., Liu, X., Disentangled representation learning gan for pose-invariant face recognition (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1415-1424. , 2, 3; Xie, Q., Dai, Z., Du, Y., Hovy, E., Neubig, G., Controllable invariance through adversarial feature learning (2017) Advances in Neural Information Processing Systems, pp. 585-596. , 2; Bilal Zafar, M., Valera, I., Gomez Rodriguez, M., Gummadi, K.P., (2015) Fairness Constraints: Mechanisms for Fair Classification, , 2; Zhang, R., Isola, P., Efros, A.A., Colorful image colorization (2016) European Conference on Computer Vision, pp. 649-666. , Springer, 6",,,,IEEE Computer Society,"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, CVPRW 2020",14 June 2020 through 19 June 2020,,162075,21607508,9.78E+12,,,English,IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recogn. Workshops,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85090115119
"Showkatbakhsh M., Shoukry Y., Diggavi S.N., Tabuada P.",55640653000;35776891900;7003736362;6603754297;,Securing state reconstruction under sensor and actuator attacks: Theory and design,2020,Automatica,116,,108920,,,,8,10.1016/j.automatica.2020.108920,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082103236&doi=10.1016%2fj.automatica.2020.108920&partnerID=40&md5=54301ac7a30cff1e62e0f27d64d9798e,"Electrical & Computer Engineering Department, UCLA, Los Angeles, CA, United States; Department of Electrical Engineering and Computer Science, University of California, IrvineCA, United States","Showkatbakhsh, M., Electrical & Computer Engineering Department, UCLA, Los Angeles, CA, United States; Shoukry, Y., Department of Electrical Engineering and Computer Science, University of California, IrvineCA, United States; Diggavi, S.N., Electrical & Computer Engineering Department, UCLA, Los Angeles, CA, United States; Tabuada, P., Electrical & Computer Engineering Department, UCLA, Los Angeles, CA, United States","This paper discusses the problem of reconstructing the state of a linear time invariant system when some of its actuators and sensors are compromised by an adversarial agent. In the model considered in this paper, the adversarial agent attacks an input (output) by manipulating its value arbitrarily, i.e., we impose no constraints (statistical or otherwise) on how control commands (sensor measurements) are changed by the adversary other than a bound on the number of attacked actuators and sensors In the first part of this paper, we introduce the notion of sparse strong observability and we show that is a necessary and sufficient condition for correctly reconstructing the state despite the considered attacks. In the second half of this work, we propose an observer to harness the complexity of this intrinsically combinatorial problem, by leveraging satisfiability modulo theory solving. Numerical simulations illustrate the effectiveness and scalability of our observer. © 2020 Elsevier Ltd",Cyber–physical security; Security monitoring; State reconstruction,Invariance; Linear systems; Time varying control systems; Actuators and sensors; Combinatorial problem; Linear time invariant systems; Physical security; Satisfiability modulo Theories; Security monitoring; State reconstruction; Strong observabilities; Actuators,,,,,"Amin, S., Schwartz, G.A., Hussain, A., In quest of benchmarking security risks to cyber-physical systems (2013) IEEE Network, 27 (1), pp. 19-24; Bai, C.-Z., Gupta, V., Pasqualetti, F., On kalman filtering with compromised sensors: Attack stealthiness and performance bounds (2017) IEEE Trans. Automat. Control, 62 (12), pp. 6641-6648; Bai, C.-Z., Pasqualetti, F., Gupta, V., Data-injection attacks in stochastic control systems: Detectability and performance tradeoffs (2017) Automatica, 82, pp. 251-260; Barrett, C.W., Sebastiani, R., Seshia, S.A., Tinelli, C., Satisfiability modulo theories (2009) Handbook of Satisfiability, 185, pp. 825-885; Cárdenas, A.A., Amin, S., Sastry, S., Research challenges for the security of control systems (2008) Conference on hot topics in security (hotsec); Chong, M.S., Wakaiki, M., Hespanha, J.P., Observability of linear systems under adversarial attacks (2015) American control conference (ACC), pp. 2439-2444; De Persis, C., Tesi, P., Input-to-state stabilizing control under denial-of-service (2015) IEEE Trans. Automat. Control, 60 (11), pp. 2930-2944; Downs, J.J., Vogel, E.F., A plant-wide industrial process control problem (1993) Computers & Chemical Engineering, 17 (3), pp. 245-255; Fawzi, H., Tabuada, P., Diggavi, S., Secure estimation and control for cyber-physical systems under adversarial attacks (2014) IEEE Trans. Automat. Control, 59 (6), pp. 1454-1467; Giraldo, J., Urbina, D., Cardenas, A., Valente, J., Faisal, M., Ruths, J., A survey of physics-based attack detection in cyber-physical systems (2018) ACM Comput. Surv., 51 (4), p. 76; Greenberg, A., Hackers remotely kill a jeep on the highway, with me in it (2015), http://www.wired.com/2015/07/hackers-remotely-kill-jeep-highway, [online]; Gupta, A., Langbort, C., Basar, T., Optimal control in the presence of an intelligent jammer with limited actions (2010) 49th IEEE conference on decision and control (CDC), pp. 1096-1101; Harirchi, F., Ozay, N., Guaranteed model-based fault detection in cyber-physical systems: A model invalidation approach (2016), arXiv preprint; Hautus, M.L.J., Strong detectability and observers (1983) Linear Algebra Appl., 50, pp. 353-368; Junker, U., Quickxplain: Conflict detection for arbitrary constraint propagation algorithms (2001) IJCAI'01 workshop on modelling and solving problems with constraints; Kelion, L., Nissan leaf electric cars hack vulnerability disclosed (2016), http://www.bbc.com/news/technology-35642749, [online]; Langner, R., Stuxnet: Dissecting a cyberwarfare weapon (2011) IEEE Security & Privacy, 9 (3), pp. 49-51; Le Berre, D., Parrain, A., The sat4j library, release 2.2, system description (2010) J. Satisf. Boolean Model. Comput., 7, pp. 59-64; Mishra, S., Shoukry, Y., Karamchandani, N., Diggavi, S., Tabuada, P., Secure state estimation: Optimal guarantees against sensor attacks in the presence of noise (2017) IEEE Trans. Control Netw. Syst., 4 (1), pp. 49-59; Mo, Y., Chabukswar, R., Sinopoli, B., Detecting integrity attacks on scada systems (2014) IEEE Trans. Control Syst. Technol., 22 (4), pp. 1396-1407; Mo, Y., Garone, E., Casavola, A., Sinopoli, B., False data injection attacks against state estimation in wireless sensor networks (2010) 49th IEEE conference on decision and control (CDC), pp. 5967-5972; Mo, Y., Kim, T.H.-J., Brancik, K., Dickinson, D., Lee, H., Perrig, A., Cyber–physical security of a smart grid infrastructure (2012) Proc. IEEE, 100 (1), pp. 195-209; Mo, Y., Sinopoli, B., Secure control against replay attacks (2009) Allerton conference on communication, control, and computing, pp. 911-918; Mo, Y., Sinopoli, B., On the performance degradation of cyber-physical systems under stealthy integrity attacks (2016) IEEE Trans. Automat. Control, 61 (9), pp. 2618-2624; Nakahira, Y., Mo, Y., Dynamic state estimation in the presence of compromised sensory data (2015) 54th annual conference on decision and control (CDC), pp. 5808-5813; Pajic, M., Weimer, J., Bezzo, N., Tabuada, P., Sokolsky, O., Lee, I., Robustness of attack-resilient state estimators (2014) ICCPS'14: ACM/IEEE 5th international conference on cyber-physical systems (with CPS Week 2014), pp. 163-174; Pasqualetti, F., Dorfler, F., Bullo, F., Attack detection and identification in cyber-physical systems (2013) IEEE Trans. Automat. Control, 58 (11), pp. 2715-2729; Ricker, L., Model predictive control of a continuous, nonlinear, two-phase reactor (1993) J. Process Control, 3 (2), pp. 109-123; Sandberg, H., Teixeira, A.M.H., From control system security indices to attack identifiability (2016) Science of security for cyber-physical systems workshop (SOSCYPS), pp. 1-6; Senejohnny, D., Tesi, P., De Persis, C., A jamming-resilient algorithm for self-triggered network coordination (2016), arXiv preprint; Shoukry, Y., Nuzzo, P., Puggelli, A., Sangiovanni-Vincentelli, A.L., Seshia, S.A., Tabuada, P., Secure state estimation for cyber physical systems under sensor attacks: a satisfiability modulo theory approach (2017) IEEE Trans. Automat. Control, 62 (10), pp. 4917-4932; Shoukry, Y., Tabuada, P., Event-triggered state observers for sparse sensor noise/attacks (2016) IEEE Trans. Automat. Control, 61 (8), pp. 2079-2091; Showkatbakhsh, M., Shoukry, Y., Chen, R., Diggavi, S., Tabuada, P., An SMT-based approach to secure state estimation under sensor and actuator attacks (2017) IEEe conference on decision and control (CDC), pp. 7177-7182; Showkatbakhsh, M., Tabuada, P., Diggavi, S., Secure system identification (2016) 54th annual allerton conference on communication, control, and computing, pp. 1137-1141; Showkatbakhsh, M., Tabuada, P., Diggavi, S., System identification in the presence of adversarial outputs (2016) IEEE conference on decision and control (CDC), pp. 7177-7182; Smith, R.S., Covert misappropriation of networked control systems: Presenting a feedback structure (2015) Control Systems Magazine, IEEE, 35 (1), pp. 82-92; Sundaram, S., Pajic, M., Hadjicostis, C.N., Mangharam, R., Pappas, G.J., The wireless control network: monitoring for malicious behavior (2010) 49th IEEE conference on decision and control (CDC), pp. 5979-5984; (2014), Tiwari, Ashish, Dutertre, Bruno, Jovanović, Dejan, de Candia, Thomas, Lincoln, Patrick D., & Rushby, John, et al. Safety envelope for security. In ACM proceedings of the 3rd international conference on high confidence networked systems (pp. 85–94); Yong, S.Z., Foo, M.Q., Frazzoli, E., Robust and resilient estimation for cyber-physical systems under adversarial attacks (2016) American control conference (ACC), 2016, pp. 308-315; Yoshikawa, T., Bhattacharyya, S., Partial uniqueness: Observability and input identifiability (1975) IEEE Trans. Automat. Control, 20 (5), pp. 713-714; Zhu, M., Martinez, S., On the performance analysis of resilient networked control systems under replay attacks (2014) IEEE Trans. Automat. Control, 59 (3), pp. 804-808","Tabuada, P.; Electrical & Computer Engineering Department, United States; 电子邮件: tabuada@ee.ucla.edu",,,Elsevier Ltd,,,,,51098,,ATCAA,,English,Automatica,Article,Final,"All Open Access, Bronze, Green",Scopus,2-s2.0-85082103236
"Ebrahimi M., Samtani S., Chai Y., Chen H.",56208183900;57188838077;57196466678;8871373800;,Detecting cyber threats in non-english hacker forums: An adversarial cross-lingual knowledge transfer approach,2020,"Proceedings - 2020 IEEE Symposium on Security and Privacy Workshops, SPW 2020",,,9283883,20,26,,1,10.1109/SPW50608.2020.00021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099724665&doi=10.1109%2fSPW50608.2020.00021&partnerID=40&md5=35e58fc5f754397c8c0c42271fd79fae,"Artificial Intelligence Lab, Information Systems, University of Arizona, Department of Management, Tucson, AZ, United States; Indiana University, Department of Operations and Decision Technologies, Bloomington, IN, United States; Tsinghua University, Beijing, China","Ebrahimi, M., Artificial Intelligence Lab, Information Systems, University of Arizona, Department of Management, Tucson, AZ, United States; Samtani, S., Indiana University, Department of Operations and Decision Technologies, Bloomington, IN, United States; Chai, Y., Tsinghua University, Beijing, China; Chen, H., Artificial Intelligence Lab, Information Systems, University of Arizona, Department of Management, Tucson, AZ, United States","The regularity of devastating cyber-attacks has made cybersecurity a grand societal challenge. Many cybersecurity professionals are closely examining the international Dark Web to proactively pinpoint potential cyber threats. Despite its potential, the Dark Web contains hundreds of thousands of non-English posts. While machine translation is the prevailing approach to process non-English text, applying MT on hacker forum text results in mistranslations. In this study, we draw upon Long-Short Term Memory (LSTM), Cross-Lingual Knowledge Transfer (CLKT), and Generative Adversarial Networks (GANs) principles to design a novel Adversarial CLKT (A-CLKT) approach. A-CLKT operates on untranslated text to retain the original semantics of the language and leverages the collective knowledge about cyber threats across languages to create a language invariant representation without any manual feature engineering or external resources. Three experiments demonstrate how A-CLKT outperforms state-of-the-art machine learning, deep learning, and CLKT algorithms in identifying cyber-threats in French and Russian forums. © 2020 IEEE.",Adversarial learning; Cross-lingual knowledge transfer; Generative adversarial networks; Hacker forums; Long short-term memory,Computer aided language translation; Deep learning; Knowledge management; Network security; Personal computing; Privacy by design; Semantics; Adversarial networks; Cyber security; External resources; Feature engineerings; Invariant representation; Knowledge transfer; Machine translations; State of the art; Long short-term memory,,,,,"Chen, H., (2012) Dark Web: Exploring and Data Mining the Dark Side of the Web, , New York: Springer; Du, P.-Y., Identifying, collecting, and presenting hacker community data: Forums, irc, carding shops, and dnms (2018) IEEE International Conference on Intelligence and Security Informatics (ISI), , Miami, FL; Nunes, E., Darknet and deepnet mining for proactive cybersecurity threat intelligence (2016) IEEE Conference on Intelligence and Security Informatics (ISI), pp. 7-12. , Tucson, AZ; Arnold, N., Dark-net ecosystem cyber-threat intelligence (cti) tool (2019) IEEE International Conference on Intelligence and Security Informatics (ISI), pp. 92-97; Li, W., Chen, H., Nunamaker, J.F., Jr., Identifying and profiling key sellers in cyber carding community: Azsecure text mining system (2016) Journal of Management Information Systems, 33 (4), pp. 1059-1086; Tavabi, N., Goyal, P., Almukaynizi, M., Shakarian, P., Lerman, K., Darkembed: Exploit prediction with neural language models (2018) Thirty-Second AAAI Conference on Artificial Intelligence; Schäfer, M., Fuchs, M., Strohmeier, M., Engel, M., Liechti, M., Lenders, V., Blackwidow: Monitoring the dark web for cyber security information (2019) International Conference on Cyber Conflict (CyCon), 900, pp. 1-21; Grisham, J., Samtani, S., Patton, M., Chen, H., Identifying mobile malware and key threat actors in online hacker forums for proactive cyber threat intelligence (2017) IEEE International Conference on Intelligence and Security Informatics (ISI), pp. 13-18. , Beijing, China; Li, W., Chen, H., Identifying top sellers in underground economy using deep learning-based sentiment analysis (2014) Intelligence and Security Informatics Conference (JISIC), 2014 IEEE Joint, pp. 64-67; Samtani, S., Chinn, R., Chen, H., Nunamaker, J.F., Jr., Exploring emerging hacker assets and key hackers for proactive cyber threat intelligence (2017) Journal of Management Information Systems, 34 (4), pp. 1023-1053; Samtani, S., Chinn, R., Chen, H., Exploring hacker assets in underground forums (2015) IEEE International Conference on Intelligence and Security Informatics (ISI), pp. 31-36. , Baltimore, MD; Weiss, K., Khoshgoftaar, T.M., Wang, D., A survey of transfer learning (2016) Journal of Big Data, 3 (1), p. 9; Abdalla, M., Hirst, G., Cross-lingual sentiment analysis without (good) translation (2017) The 8th International Joint Conference on Natural Language Processing (IJCNLP), pp. 506-515. , Taiwan; Li, N., Zhai, S., Zhang, Z., Liu, B., Structural correspondence learning for cross-lingual sentiment classification with one-to-many mappings (2017) AAAI Conference on Artificial Intelligence, pp. 3490-3496. , San Francisco; Wang, M., Deng, W., Deep visual domain adaptation: A survey (2018) Neurocomputing; Goodfellow, I., Generative adversarial nets (2014) Advances in Neural Information Processing Systems (NeurIPS), pp. 2672-2680. , Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger, Eds. Curran Associates, Inc; Johnson, R., Zhang, T., Supervised and semisupervised text categorization using lstm for region embeddings (2016) International Conference on Machine Learning (ICML), 48, pp. 526-534. , New York, NY; Goodfellow, I., Bengio, Y., Courville, A., Bengio, Y., (2016) Deep Learning, 1. , MIT Press Cambridge; Goldberg, Y., Neural network methods for natural language processing (2017) Synthesis Lectures on Human Language Technologies, 10 (1), pp. 1-309; Ebrahimi, M., Surdeanu, M., Samtani, S., Chen, H., Detecting cyber threats in non-english dark net markets: A cross-lingual transfer learning approach (2018) IEEE International Conference on Intelligence and Security Informatics (ISI), pp. 85-90; Hastie, T., Tibshirani, R., Friedman, J., (2017) The Elements of Statistical Learning, , Springer series in statistics New York","Chai, Y.; Department of Management Science and Engineering, China; 电子邮件: chaiyd14@mails.tsinghua.edu.cn",,,Institute of Electrical and Electronics Engineers Inc.,"2020 IEEE Symposium on Security and Privacy Workshops, SPW 2020",21-May-20,,165937,,9.78E+12,,,English,"Proc. - IEEE Symp. Secur. Priv. Workshops, SPW",Conference Paper,Final,"All Open Access, Bronze",Scopus,2-s2.0-85099724665
"Bevendorff J., Wenzel T., Potthast M., Hagen M., Stein B.",57201362871;57215847846;23012600600;16309692700;23013265500;,On divergence-based author obfuscation: An attack on the state of the art in statistical authorship verification,2020,IT - Information Technology,62,2,,99,115,,3,10.1515/itit-2019-0046,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082061089&doi=10.1515%2fitit-2019-0046&partnerID=40&md5=4628198f0c5abd9d1c8c9358251645ed,"Bauhaus-Universität Weimar, Weimar, Germany; Leipzig University, Leipzig, Germany; Martin-Luther-Universität Halle-Wittenberg, Halle, Germany","Bevendorff, J., Bauhaus-Universität Weimar, Weimar, Germany; Wenzel, T., Leipzig University, Leipzig, Germany; Potthast, M., Leipzig University, Leipzig, Germany; Hagen, M., Martin-Luther-Universität Halle-Wittenberg, Halle, Germany; Stein, B., Bauhaus-Universität Weimar, Weimar, Germany","Authorship verification is the task of determining whether two texts were written by the same author based on a writing style analysis. Author obfuscation is the adversarial task of preventing a successful verification by altering a text's style so that it does not resemble that of its original author anymore. This paper introduces new algorithms for both tasks and reports on a comprehensive evaluation to ascertain the merits of the state of the art in authorship verification to withstand obfuscation. After introducing a new generalization of the well-known unmasking algorithm for short texts, thus completing our collection of state-of-the-art algorithms for verification, we introduce an approach that (1) models writing style difference as the Jensen-Shannon distance between the character n-gram distributions of texts, and (2) manipulates an author's writing style in a sophisticated manner using heuristic search. For obfuscation, we explore the huge space of textual variants in order to find a paraphrased version of the to-be-obfuscated text that has a sufficiently high Jensen-Shannon distance at minimal costs in terms of text quality loss. We analyze, quantify, and illustrate the rationale of this approach, define paraphrasing operators, derive text length-invariant thresholds for termination, and develop an effective obfuscation framework. Our authorship obfuscation approach defeats the presented state-of-the-art verification approaches, while keeping text changes at a minimum. As a final contribution, we discuss and experimentally evaluate a reverse obfuscation attack against our obfuscation approach as well as possible remedies. © 2020 Walter de Gruyter GmbH, Berlin/Boston 2020.",authorship obfuscation; authorship verification; computational ethics; privacy,Data privacy; Privacy by design; Adversarial task; authorship obfuscation; Authorship verification; Comprehensive evaluation; Heuristic search; State of the art; State-of-the-art algorithms; Text qualities; Heuristic algorithms,,,,,"Abbasi, A., Chen, H., Writeprints: A stylometric approach to identity-level identification and similarity detection in cyberspace (2008) Acm Trans. Inf. Syst., 26 (2). , Apr; Bagnall, D., CLEF 2015 Evaluation Labs and Workshop-Working Notes Papers, , Author Identification using multi-headed Recurrent Neural Networks-Notebook for PAN at CLEF 2015; Bevendorff, J., Potthast, M., Hagen, M., Stein, B., (2019) 57th Annual Meeting of the Association for Computational Linguistics (ACL 2019), pp. 1098-1108. , Heuristic Authorship Obfuscation Association for Computational Linguistics July; Bevendorff, J., Stein, B., Hagen, M., Potthast, M., (2019) 14th Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL 2019), pp. 654-659. , Generalizing Unmasking for Short Texts Association for Computational Linguistics June; Bevendorff, J., Stein, B., Hagen, M., Potthast, M., (2019) 57th Annual Meeting of the Association for Computational Linguistics (ACL 2019), pp. 6301-6306. , Bias Analysis and Mitigation in the Evaluation of Authorship Verification Association for Computational Linguistics July; H. Bo, S. H. H. Ding, B. C. M. Fung, and F. Iqbal. ER-AE: Differentially-private Text Generation for Authorship Anonymization. CoRR, 2019., , abs/1907.08736; B. T. Boenninghoff, S. Hessler, D. Kolossa, and R. M. Nickel. Explainable Authorship Verification in Social Media Via Attention-based Similarity Learning. CoRR, 2019., , abs/1910.08144; D. Boumber, Y. Zhang, M. Hosseinia, and A. Mukherjee. Robust Authorship Verification with Transfer Learning, 2019.; Bourne, E.G., The authorship of the federalist (1897) The American Historical Review, 2 (3), pp. 443-460; Brennan, M., Afroz, S., Greenstadt, R., Adversarial Stylometry: Circumventing Authorship Recognition to Preserve Privacy and Anonymity (2012) Acm Trans. Inf. Syst. Secur., 15 (3), p. 12; Brown, P.F., Pietra, S.D., Pietra, V.J.D., Lai, J.C., Mercer, R.L., An estimate of an upper bound for the entropy of English (1992) Computational Linguistics, 18 (1), pp. 31-40; D. Castro, Y. Adame, M. Pelaez, and R. Munõz. Authorship Verification, Combining Linguistic Features and Different Similarity Functions-Notebook for Pan at CLEF 2015. In CLEF 2015 Evaluation Labs and Workshop-Working Notes Papers.; Emmery, C., Arévalo, E.M., Chrupala, G., (2018) Proceedings of the 27th International Conference on Computational Linguistics, Coling 2018, pp. 984-996. , Style obfuscation by invariance Santa Fe, New Mexico, USA August 20-26, 2018; Endres, D.M., Schindelin, J.E., A new metric for probability distributions (2003) Ieee Trans. Information Theory, 49 (7), pp. 1858-1860; J. Fréry, C. Largeron, and M. Juganaru-Mathieu. Ujm at CLEF in Author Identification-Notebook for Pan at CLEF 2014. In CLEF 2014 Evaluation Labs and Workshop-Working Notes Papers.; D. Grangier and M. Auli. Quickedit: Editing Text & Translations Via Simple Delete Actions. CoRR, 2017., , abs/1711.04805; K. Guu, T. B. Hashimoto, Y. Oren, and P. Liang. Generating Sentences by Editing Prototypes. CoRR, 2017., , abs/1709.08878; M. Hagen, M. Potthast, and B. Stein. Overview of the Author Obfuscation Task at Pan 2017: Safety Evaluation Revisited. In Working Notes Papers of the CLEF 2017 Evaluation Labs, Volume 1866 of Ceur Workshop Proceedings.; O. Halvani, C. Winter, and L. Graner. Authorship Verification Based on Compression-models. CoRR, 2017., , abs/1706.00516; Halvani, O., Winter, C., Graner, L., (2019) Proceedings of the 14th International Conference on Availability, Reliability and Security, Ares 2019, , Assessing the applicability of authorship verification methods Canterbury, UK August 26-29, 2019; Howard, P.G., (1993) The Design and Analysis of Efficient Lossless Data Compression Systems, , Brown University; Iqbal, F., Hadjidj, R., Fung, B.C., Debbabi, M., A novel approach of mining write-prints for authorship attribution in e-mail forensics (2008) Digital Investigation, 5, pp. S42-S51; Juola, P., Authorship Attribution (2006) Foundations and Trends Information Retrieval, 1 (3), pp. 233-334. , Dec; Juola, P., Stamatatos, E., Forner, P., Navigli, R., Tufis, D., (2013) CLEF 2013 Evaluation Labs and Workshop-Working Notes Papers, , CEUR-WS.org, 23-26 September Valencia, Spain Sept; P. Juola and D. Vescovi. Analyzing Stylometric Approaches to Author Obfuscation. In Advances in Digital Forensics VII-7th Ifip Wg 11.9 International Conference on Digital Forensics, Revised Selected Papers, Orlando, FL, USA, January 31-February 2, 2011, Volume 361 of Ifip Advances in Information and Communication Technology, Pages 115-125.; G. Kacmarcik and M. Gamon. Obfuscating Document Stylometry to Preserve Author Anonymity. In Acl 2006, 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference, Sydney, Australia, 17-21 July 2006.; Kestemont, M., Luyckx, K., Daelemans, W., Crombez, T., Cross-genre authorship verification using unmasking (2012) English Studies, 93 (3), pp. 340-356; D. V. Khmelev and W. J. Teahan. A Repetition Based Measure for Verification of Text Collections and for Text Categorization. In Sigir 2003: Proceedings of the 26th Annual International Acm Sigir Conference on Research and Development in Information Retrieval, July 28-August 1, 2003, Toronto, Canada, Pages 104-110.; M. Khonji and Y. Iraqi. A Slightly-modified GI-based Author-verifier with Lots of Features (ASGALF)-Notebook for Pan at CLEF 2014. In CLEF 2014 Evaluation Labs and Workshop-Working Notes Papers.; M. Kocher and J. Savoy. UniNE at CLEF 2015: Author Identification-Notebook for Pan at CLEF 2015. In CLEF 2015 Evaluation Labs and Workshop-Working Notes Papers.; Kocher, M., Savoy, J., A simple and efficient algorithm for authorship verification (2017) Jasist, 68 (1), pp. 259-269; Kocher, M., Savoy, J., Distance measures in author profiling (2017) Inf. Process. Manage., 53 (5), pp. 1103-1119; M. Koppel and J. Schler. Authorship Verification As a One-Class Classification Problem. In C. Brodley, Editor, Proceedings of the Twenty-First International Conference on Machine Learning, Pages 1-7.; Mahmood, A., Ahmad, F., Shafiq, Z., Srinivasan, P., Zaffar, F., A girl has no name: Automated authorship obfuscation using mutant-x (2019) PoPETs, 2019 (4), pp. 54-71; A. McDonald, S. Afroz, A. Caliskan, A. Stolerman, and R. Greenstadt. Use Fewer Instances of the Letter ""i"": Toward Writing Style Anonymization. In S. Fischer-Hübner and M. Wright, Editors, Privacy Enhancing Technologies-12th International Symposium, Pets 2012, Vigo, Spain, July 11-13, 2012, Volume 7384 of Lecture Notes in Computer Science, Pages 299-318.; Miller, G.A., Wordnet: A lexical database for english (1995) Commun. Acm, 38 (11), pp. 39-41. , Nov; A. Narayanan, H. S. Paskov, N. Z. Gong, J. Bethencourt, E. Stefanov, E. C. R. Shin, and D. Song. On the Feasibility of Internet-scale Author Identification. On Ieee Symposium on Security and Privacy, Sp 2012, 21-23 May 2012, San Francisco, California, USA, Pages 300-314.; J. Pearl. Heuristics-intelligent Search Strategies for Computer Problem Solving. Addison-Wesley Series in Artificial Intelligence.; Potha, N., Stamatatos, E., Improved algorithms for extrinsic author verification (2019) Knowledge and Information Systems, , Oct; M. Potthast, M. Hagen, and B. Stein. Author Obfuscation: Attacking the State of the Art in Authorship Verification. In Working Notes Papers of the CLEF 2016 Evaluation Labs, Volume 1609 of Ceur Workshop Proceedings.; M. Potthast, F. Schremmer, M. Hagen, and B. Stein. Overview of the Author Obfuscation Task at Pan 2018: A New Approach to Measuring Safety. In L. Cappellato, N. Ferro, J.-Y. Nie, and L. Soulier, Editors, Working Notes Papers of the CLEF 2018 Evaluation Labs, Volume 2125 of Ceur Workshop Proceedings.; Rao, J., Rohatgi, P., Bellovin, S., Rose, G., (2000) 9th Usenix Security Symposium, , Denver, Colorado, USA August 14-17, 2000 USENIX Association; Rosso, P., Rangel, F., Potthast, M., Stamatatos, E., Tschuggnall, M., Stein, B., (2016) Experimental Ir Meets Multilinguality, Multimodality, and Interaction. 7th International Conference of the CLEF Initiative (CLEF 2016), , Overview of PAN 2016-New Challenges for Authorship Analysis: Cross-genre Profiling, Clustering, Diarization, and Obfuscation Berlin Heidelberg New York Sept; Sanderson, C., Guenter, S., (2006) Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pp. 482-491. , Short text authorship attribution via sequence kernels, markov chains and author unmasking: An investigation July; Sculley, D., Brodley, C.E., (2006) 2006 Data Compression Conference (DCC 2006), p. 332. , Compression and machine learning: A new perspective on feature space vectors 28-30 March 2006 Snowbird, UT, USA IEEE Computer Society; Stamatatos, E., A Survey of Modern Authorship Attribution Methods (2009) Journal of the American Society for Information Science and Technology, 60 (3), pp. 538-556. , Mar; Stamatatos, E., Daelemans, W., Verhoeven, B., Potthast, M., Stein, B., Juola, P., Sanchez-Perez, M., Barrón-Cedenõ, A., (2014) Working Notes Papers of the CLEF 2014 Evaluation Labs, , Overview of the Author Identification Task at PAN 2014 CEUR Workshop Proceedings. CLEF and CEUR-WS.org Sept; E. Stamatatos, W. Daelemans, B. Verhoeven, M. Potthast, B. Stein, P. Juola, M. Sanchez-Perez, and A. Barrón-Cedenõ. Overview of the Author Identification Task at Pan 2014. In CLEF 2014 Evaluation Labs and Workshop-Working Notes Papers.; E. Stamatatos, W. D. Amd Ben Verhoeven, P. Juola, A. López-López, M. Potthast, and B. Stein. Overview of the Author Identification Task at Pan 2015. In CLEF 2015 Evaluation Labs and Workshop-Working Notes Papers.; E. Stamatatos, W. Daelemans, B. Verhoeven, P. Juola, A. López López, M. Potthast, and B. Stein. Overview of the Author Identification Task at Pan 2015. In Working Notes Papers of the CLEF 2015 Evaluation Labs, Ceur Workshop Proceedings.; Stein, B., Lipka, N., Meyer Zu Eißen, S., Tjoa, A., Wagner, R., (2008) 5th International Workshop on Text-Based Information Retrieval (TIR 2008) at Dexa, pp. 34-39. , IEEE Sept; Stein, B., Potthast, M., Trenkmann, M., Gurrin, C., He, Y., Kazai, G., Kruschwitz, U., Van Rijsbergen, K., (2010) Advances in Information Retrieval. 32nd European Conference on Information Retrieval (ECIR 2010), 5993, pp. 631-635. , Lecture Notes in Computer Science Berlin Heidelberg New York Mar; Stein, B., Hagen, M., Braütigam, C., Tsujii, J., Hajic, J., (2014) 25th International Conference on Computational Linguistics (COLING 2014), pp. 2014-2029. , Association for Computational Linguistics Aug; Teahan, W.J., Harper, D.J., Language Modeling for Information Retrieval, pp. 141-165. , Using compression-based language models for text categorization; Wu, C., Ren, X., Luo, F., Sun, X., (2019) Proceedings of the 57th Conference of the Association for Computational Linguistics, Acl 2019, 1, pp. 4873-4883. , A Hierarchical Reinforced Sequence Operation Method for Unsupervised Text Style Transfer Florence, Italy July 28-August 2, 2019 Long Papers July; Xu, W., Ritter, A., Dolan, B., Grishman, R., Cherry, C., (2012) Proceedings of Coling 2012, pp. 2899-2914. , Paraphrasing for style Mumbai, India December; Zhao, Y., Zobel, J., (2007) Computer Science 2007. Proceedings of the Thirtieth Australasian Computer Science Conference (ACSC2007), pp. 59-68. , Searching with style: Authorship attribution in classic literature Ballarat, Victoria, Australia January 30-February 2, 2007; Y. Zhao, J. Zobel, and P. Vines. Using Relative Entropy for Authorship Attribution. In H. T. Ng, M. Leong, M. Kan, and D. Ji, Editors, Information Retrieval Technology, Third Asia Information Retrieval Symposium, Airs 2006, Singapore, October 16-18, 2006, Volume 4182 of Lecture Notes in Computer Science, Pages 92-105.; Zheng, R., Li, J., Chen, H., Huang, Z., A framework for authorship identification of online messages: Writing-style features and classification techniques (2006) Journal of the American Society for Information Science and Technology, 57 (3), pp. 378-393","Bevendorff, J.; Bauhaus-Universität WeimarGermany; 电子邮件: janek.bevendorff@uni-weimar.de",,,De Gruyter Oldenbourg,,,,,16112776,,,,English,IT Info. Tech.,Article,Final,,Scopus,2-s2.0-85082061089
"Yan F., Zhang M., Zhang L.",56890300500;57222002150;55709301200;,Adversarial examples detection method based on boundary values invariants,2020,Chinese Journal of Network and Information Security,6,1,,38,45,,,10.11959/j.issn.2096-109x.2020012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100883489&doi=10.11959%2fj.issn.2096-109x.2020012&partnerID=40&md5=e02810a4157da9da4d81ce53c13c109f,"Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University, Wuhan, 430072, China","Yan, F., Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University, Wuhan, 430072, China; Zhang, M., Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University, Wuhan, 430072, China; Zhang, L., Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University, Wuhan, 430072, China","Nowadays, deep learning has become one of the most widely studied and applied technologies in the computer field. Deep neural networks(DNNs) have achieved greatly noticeable success in many applications such as image recognition, speech, self-driving and text translation. However, deep neural networks are vulnerable to adversarial examples that are generated by perturbing correctly classified inputs to cause DNN modes to misbehave. A boundary check method based on traditional programs by fitting the distribution to find the invariants in the deep neural network was proposed and it use the invariants to detect adversarial examples. The selection of training sets was irrelevant to adversarial examples. The experiment results show that proposed method can effectively detect the current adversarial example attacks on LeNet, vgg19 model, Mnist, Cifar10 dataset, and has a low false positive rate. © 2020, Beijing Xintong Media Co., Ltd.. All rights reserved.",Adversarial examples detecting; Boundary checking; Deep neuron network; Invariant,,,,,,"KRIZHEVSKY, A, SUTSKEVER, I, HINTON, G E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105. , [C]; BOJARSKI, M, Del TESTA, D, DWORAKOWSKI, D, End to end learning for self-driving cars (2016), [J]. arXiv preprint arXiv:1604.07316; DAHL, G E, STOKES, J W, DENG, L, Large-scale malware classification using random projections and neural networks (2013) 2013 IEEE International Conference on Acoustics, Speech and Signal Processing, pp. 3422-3426. , [C]; MIRSKY, Y, DOITSHMAN, T, ELOVICI, Y, Kitsune: an ensemble of autoencoders for online network intrusion detection (2018), [J]. arXiv preprint arXiv:1802.09089; SZEGEDY, C, ZAREMBA, W, SUTSKEVER, I, Intriguing properties of neural networks (2013), [J]. arXiv preprint arXiv:1312.6199; DHILLON, G S, AZIZZADENESHELI, K, LIPTON, Z C, Stochastic activation pruning for robust adversarial defense (2018), [J]. ar Xiv preprint arXiv:1803.01442; GOODFELLOW, I J, SHLENS, J, SZEGEDY, C., Explaining and harnessing adversarial examples (2014), [J]. arXiv: preprint arXiv: 1412. 6572; KURAKIN, A, GOODFELLOW, I, BENGIO, S., Adversarial examples in the physical world (2016), [J]. arXiv preprint arXiv:1607.02533; CARLINI, N, WAGNER, D., Defensive distillation is not robust to adversarial examples (2016), [J]. arXiv preprint arXiv:1607.04311; PAPERNOT, N, MCDANIEL, P, JHA, S, The limitations of deep learning in adversarial settings (2016) 2016 IEEE European Symposium on Security and Privacy (EuroS&P), pp. 372-387. , [C]; LIU, Y, MA, S, AAFER, Y, Trojaning attack on neural networks (2018) Network and Distributed System Security Symposium, , [C]; GU, S, RIGAZIO, L., Towards deep neural network architectures robust to adversarial examples (2014), [J]. arXiv preprint arXiv:1412.5068; FEINMAN, R, CURTIN, R R, SHINTRE, S, Detecting adversarial samples from artifacts (2017), [J]. arXiv preprint arXiv:1703.00410; GROSSE, K, MANOHARAN, P, PAPERNOT, N, On the (statistical) detection of adversarial examples (2017), [J]. arXiv preprint arXiv:1702.06280; MA, X, LI, B, WANG, Y, Characterizing adversarial subspaces using local intrinsic dimensionality (2018), [J]. arXiv preprint arXiv: 1801.02613; XU, W, EVANS, D, QI, Y., Feature squeezing: detecting adversarial examples in deep neural networks (2017), [J]. arXiv preprint arXiv: 1704.01155; MENG, D, CHEN, H., Magnet: a two-pronged defense against adversarial examples (2017) The 2017 ACM SIGSAC Conference on Computer and Communications Security, pp. 135-147. , [C]; LIAO, F, LIANG, M, DONG, Y, Defense against adversarial attacks using high-level representation guided denoiser (2018) The IEEE Conference on Computer Vision and Pattern Recognition, pp. 1778-1787. , [C]; LECUN, Y, BOTTOU, L, BENGIO, Y, Gradient-based learning applied to document recognition (1998) Proceedings of the IEEE, 86 (11), pp. 2278-2324. , [J]; BROWN, T B, MANÉ, D, ROY, A, Adversarial patch (2017), [J]. arXiv preprint arXiv:1712.09665; EYKHOLT, K, EVTIMOV, I, FERNANDES, E, Robust physical-world attacks on deep learning models (2017), [J]. arXiv preprint arXiv:1707.08945; PEI, K, CAO, Y, YANG, J, Deepxplore: automated whitebox testing of deep learning systems (2017) The 26th Symposium on Operating Systems Principles, pp. 1-18. , [C]; BIGGIO, B, ROLI, F., Wild patterns: ten years after the rise of adversarial machine learning (2018) Pattern Recognition, 84, pp. 317-331. , [J]; MOOSAVI-DEZFOOLI, S M, FAWZI, A, FROSSARD, P., DeepFool: a simple and accurate method to fool deep neural networks (2016) IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582. , [C]; CARLINI, N, WAGNER, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP), pp. 39-57. , [C]; KINGMA, D P, BA, J., Adam: a method for stochastic optimization (2014), [J]. arXiv preprint arXiv:1412.6980; ROUHANI, B D, SAMRAGH, M, JAVAHERIPIM, Deepfense: online accelerated defense against adversarial deep learning (2018) IEEE/ACM International Conference on Computer-Aided Design (ICCAD), pp. 1-8. , [C]; SONG, Y, KIM, T, NOWOZIN, S, Pixeldefend: leveraging generative models to understand and defend against adversarial examples (2017), [J]. arXiv preprint arXiv:1710.10766; XIE, C, WANG, J, ZHANG, Z, Mitigating adversarial effects through randomization (2017), [J]. arXiv preprint arXiv:1711.01991; PAPERNOT, N, MCDANIEL, P, SINHA, A, Towards the science of security and privacy in machine learning (2016), [J]. arXiv preprint arXiv:1611.03814; PAPERNOT, N, MCDANIEL, P, WU, X, Distillation as a defense to adversarial perturbations against deep neural networks (2016) 2016 IEEE Symposium on Security and Privacy (SP), pp. 582-597. , [C]; PAPERNOT, N, MCDANIEL, P, GOODFELLOW, I, Practical black-box attacks against machine learning (2017) ACM on Asia Conference on Computer and Communications Security, pp. 506-519. , [C]; ATHALYE, A, CARLINI, N, WAGNER, D., Obfuscated gradients give a false sense of security: circumventing defenses to adversarial examples (2018), [J]. arXiv preprint arXiv:1802.00420; BHAGOJI, A N, CULLINA, D, MITTAL, P., Dimensionality reduction as a defense against evasion attacks on machine learning classifiers (2017), [J]. arXiv preprint arXiv:1704.02654; GONG, Z, WANG, W, KU, W S., Adversarial and clean data are not twins (2017), [J]. arXiv preprint arXiv:1704.04960; HENDRYCKS, D, GIMPEL, K., Early methods for detecting adversarial images (2016), [J]. arXiv preprint arXiv:1608.00530; TAX, D M J, DUIN, R P W., Support vector domain description (1999) Pattern Recognition Letters, 20 (11-13), pp. 1191-1199. , [J]; CARLINI, N, WAGNER, D., Adversarial examples are not easily detected: bypassing ten detection methods (2017) The 10th ACM Workshop on Artificial Intelligence and Security, pp. 3-14. , [C]; LU, P H, CHEN, P Y, YU, C M., On the limitation of local intrinsic dimensionality for characterizing the subspaces of adversarial examples (2018), [J]. arXiv preprint arXiv:1803.09638; GUO, C, RANA, M, CISSE, M, Countering adversarial images using input transformations (2017), [J]. arXiv preprint arXiv:1711.00117; TAO, G, MA, S, LIU, Y, Attacks meet interpretability: attribute-steered detection of adversarial samples (2018) Advances in Neural Information Processing Systems, pp. 7717-7728. , [C]; GILMER, J, METZ, L, FAGHRI, F, Adversarial spheres (2018), [J]. arXiv preprint arXiv:1801.02774; PERERA, P, PATEL, V M., Learning deep features for one-class classification (2019) IEEE Transactions on Image Processing, 28 (11), pp. 5450-5463. , [J]; TAX, D M J, DUIN, R P W., Data domain description using support vectors (1999) ESANN, 99, pp. 251-256. , [C]; KRIZHEVSKY, A, HINTON, G., Learning multiple layers of features from tiny images (2009), [R]. Technical Report, University of Toronto; RAUBER, J, BRENDEL, W, BETHGE, M., Foolbox: a Python toolbox to benchmark the robustness of machine learning models (2017), [J]. arXiv preprint arXiv:1707.04131; SIMONYAN, K, ZISSERMAN, A., Very deep convolutional networks for large-scale image recognition (2014), [J]. arXiv preprint arXiv:1409.1556","Zhang, L.; Key Laboratory of Aerospace Information Security and Trusted Computing, China; 电子邮件: zhanglq@whu.edu.cn",,,"Beijing Xintong Media Co., Ltd.",,,,,2096109X,,,,Chinese,Ch. J. Netw. Inf. Secur.,Article,Final,,Scopus,2-s2.0-85100883489
"Safaa El-Din Y., Moustafa M.N., Mahdi H.",57236040600;7101946942;8311730700;,On the effectiveness of adversarial unsupervised domain adaptation for iris presentation attack detection in mobile devices,2020,Proceedings of SPIE - The International Society for Optical Engineering,11605,,116050W,,,,,10.1117/12.2586901,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113747168&doi=10.1117%2f12.2586901&partnerID=40&md5=0375c4e97a5f4caed23092ddef7ccf1d,"Department of Computer and Systems Engineering, Ain Shams University, Cairo, Egypt; Department of Computer Science and Engineering, The American University in Cairo, New Cairo, Egypt","Safaa El-Din, Y., Department of Computer and Systems Engineering, Ain Shams University, Cairo, Egypt; Moustafa, M.N., Department of Computer Science and Engineering, The American University in Cairo, New Cairo, Egypt; Mahdi, H., Department of Computer and Systems Engineering, Ain Shams University, Cairo, Egypt","The growing usage of smart mobile devices have made authentication with biometric data more convenient. On the other side, videos and photos of users are becoming more available online. This makes it easier for attackers to spoof the authentication systems which rely on face and eye-region data for instance. One major problem with current Presentation Attack Detection (PAD) systems is their lack of generalization to data captured by different sensors or in different environments. In this paper, we propose the use of unsupervised domain adaptation to solve this PAD problem, specifically the iris PAD. Our model is composed of symmetric classifiers and two per-class domain discriminators. Interaction between class probabilities and domain classification is utilized to jointly adversarialy train a mobile-oriented feature extraction network, capable of generating domain-invariant features. The approach is evaluated on three benchmark iris PAD datasets. Results show up to 40% improvement in cross-dataset Average Classification Error Rate (ACER) proving the effectiveness of the approach in increasing the robustness and generalization of biometric PAD systems. © 2021 SPIE.",Adversarial training; Biometrics; Deep neural networks; Domain adaptation; Iris presentation attack detection; SymNets,Authentication; Biometrics; Computer vision; Attack detection; Authentication systems; Biometric data; Class probabilities; Classification error rate; Domain adaptation; Invariant features; Mobile-oriented; Classification (of information),,,,,"Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette, F., Marchand, M., Lempitsky, V., Domain-adversarial training of neural networks (2016) J. Mach. Learn. Res., 17, pp. 2030-2096. , Jan; Pei, Z., Cao, Z., Long, M., Wang, J., (2018) Multi-adversarial Domain Adaptation; Long, M., Cao, Z., Wang, J., Jordan, M.I., Conditional adversarial domain adaptation Advances in Neural Information Processing Systems 31, , Bengio, S., Wallach, H., Larochelle, H., Grauman, K., Cesa-Bianchi, N., and Garnett, R., eds., 1640-1650, Curran Associates, Inc. (2018); Saito, K., Watanabe, K., Ushiku, Y., Harada, T., Maximum classifier discrepancy for unsupervised domain adaptation (2018) 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition], pp. 3723-3732; Saito, K., Ushiku, Y., Harada, T., Saenko, K., Adversarial dropout regularization (2018) International Conference on Learning Representations]; Kurmi, V.K., Namboodiri, V., Looking back at labels: A class based domain adaptation technique International Joint Conference on Neural Networks (IJCNN)], (July 2019); Zhang, Y., Tang, H., Jia, K., Tan, M., (2019) Domain-symmetric Networks for Adversarial Domain Adaptation; Tang, H., Jia, K., (2020) Discriminative Adversarial Domain Adaptation; Howard, A., Sandler, M., Chen, B., Wang, W., Chen, L., Tan, M., Chu, G., Le, Q., Searching for mobilenetv3 (2019) 2019 IEEE/CVF International Conference on Computer Vision (ICCV)], pp. 1314-1324; Czajka, A., Bowyer, K.W., Presentation attack detection for iris recognition: An assessment of the state-of-theart Acm Computing Surveys, 51, pp. 861-8635. , July 2018; SafaaElDin, Y., Deep convolutional neural networks for face and iris presentation attack detection: Survey and case study (2020) Iet Biometrics, , April; Nguyen, D., Rae Baek, N., Pham, T., Ryoung Park, K., Presentation attack detection for iris recognition system using nir camera sensor Sensors, 18, p. 1315. , 04 2018); Nguyen, D.T., Pham, T.D., Lee, Y.W., Park, K.R., Deep learning-based enhanced presentation attack detection for iris recognition by combining features from local and global regions based on nir camera sensor (2018) Sensors, 18 (8); Menotti, D., Chiachia, G., Pinto, A., Schwartz, W.R., Pedrini, H., Falcao, A.X., Rocha, A., Deep representations for iris, face, and fingerprint spoofing detection Ieee Transactions on Information Forensics and Security 10, pp. 864-879. , April 2015; Silva, P., Luz, E., Baeta, R., Pedrini, H., Falcao, A., Menotti, D., An approach to iris contact lens detection based on deep image representations 2015 28th Sibgrapi Conference on Graphics, , Patterns and Images], 157-164 (08 2015); Kuehlkamp, A., Da Silva Pinto, A., Rocha, A., Bowyer, K.W., Czajka, A., Ensemble of multi-view learning classifiers for cross-domain iris presentation attack detection (2018) CoRR; Hoffman, S., Sharma, R., Ross, A., Convolutional neural networks for iris presentation attack detection: Toward cross-dataset and cross-sensor generalization 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)], pp. 1701-17018. , June 2018; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets Advances in Neural Information Processing Systems 27], , Ghahramani, Z., Welling, M., Cortes, C., Lawrence, N. D., and Weinberger, K. Q., eds., 2672-2680, Curran Associates, Inc. (2014); Li, H., Li, W., Cao, H., Wang, S., Huang, F., Kot, A.C., Unsupervised domain adaptation for face antispoofing (2018) Ieee Transactions on Information Forensics and Security, 13 (7), pp. 1794-1809; Wang, G., Han, H., Shan, S., Chen, X., Improving cross-database face presentation attack detection via adversarial domain adaptation (2019) 2019 International Conference on Biometrics (ICB)], pp. 1-8; Tu, X., Zhao, J., Xie, M., Du, G., Zhang, H., Li, J., Ma, Z., Feng, J., (2019) Learning Generalizable and Identitydiscriminative Representations for Face Anti-spoofing; Shao, R., Lan, X., Li, J., Yuen, P.C., Multi-adversarial discriminative deep domain generalization for face presentation attack detection (2019) 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)], pp. 10015-10023; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) 2016 Ieee Conference on Computer Vision and Pattern Recognition (CVPR)], pp. 770-778; Grandvalet, Y., Bengio, Y., Semi-supervised learning by entropy minimization (2004) Proceedings of the 17th International Conference on Neural Information Processing Systems], , NIPS'04, 529-536, MIT Press, Cambridge, MA, USA; Galbally, J., Ortiz-Lopez, J., Fierrez, J., Ortega-Garcia, J., Iris liveness detection based on quality related features 2012 5th Iapr International Conference on Biometrics (ICB)], pp. 271-276. , March 2012; Czajka, A., Database of iris printouts and its application: Development of liveness detection method for iris recognition 2013 18th International Conference on Methods Models in Automation Robotics (MMAR, pp. 28-33. , Aug 2013; Sequeira, A.F., Murari, J., Cardoso, J.S., Iris liveness detection methods in mobile applications 2014 International Conference on Computer Vision Theory and Applications (VISAPP)], 3, pp. 22-33. , Jan 2014; Anjos, A., Shafey, L.E., Wallace, R., Günther, M., McCool, C., Marcel, S., Bob: A free signal processing and machine learning toolbox for researchers 20th Acm Conference on Multimedia Systems (ACMMM), Nara, Japan], (Oct. 2012)",,Osten O.Nikolaev D.P.Zhou J.,American Science and Engineering Institute,SPIE,"13th International Conference on Machine Vision, ICMV 2020",2 November 2020 through 6 November 2020,,166385,0277786X,9.78E+12,PSISD,,English,Proc SPIE Int Soc Opt Eng,Conference Paper,Final,,Scopus,2-s2.0-85113747168
"Welbl J., Minervini P., Bartolo M., Stenetorp P., Riedel S.",56352539600;36617521100;57212149387;36663192600;36562438800;,Undersensitivity in neural reading comprehension,2020,Findings of the Association for Computational Linguistics Findings of ACL: EMNLP 2020,,,,1152,1165,,3,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107930887&partnerID=40&md5=4a9d30460abfbcb4a33355cc0d7ecd21,"University College London, United Kingdom","Welbl, J., University College London, United Kingdom; Minervini, P., University College London, United Kingdom; Bartolo, M., University College London, United Kingdom; Stenetorp, P., University College London, United Kingdom; Riedel, S., University College London, United Kingdom","Current reading comprehension methods generalise well to in-distribution test sets, yet perform poorly on adversarially selected data. Prior work on adversarial inputs typically studies model oversensitivity: semantically invariant text perturbations that cause a model’s prediction to change. Here we focus on the complementary problem: excessive prediction undersensitivity, where input text is meaningfully changed but the model’s prediction does not, even though it should. We formulate an adversarial attack which searches among semantic variations of the question for which a model erroneously predicts the same answer, and with even higher probability. We demonstrate that models trained on both SQuAD2.0 and NewsQA are vulnerable to this attack, and then investigate data augmentation and adversarial training as defences. Both substantially decrease adversarial vulnerability, which generalises to held-out data and held-out attack spaces. Addressing undersensitivity furthermore improves model robustness on the previously introduced ADDSENT and ADDONESENT datasets, and models generalise better when facing train/evaluation distribution mismatch: they are less prone to overly rely on shallow predictive cues present only in the training set, and outperform a conventional model by as much as 10.9% F1 ©2020 Association for Computational Linguistics",,Computational linguistics; Semantics; 'current; Attack spaces; Complementary problems; Conventional modeling; Data augmentation; High probability; Model robustness; Reading comprehension; Test sets; Training sets; Forecasting,,,,,"Alberti, Chris, Andor, Daniel, Pitler, Emily, Devlin, Jacob, Collins, Michael, Synthetic QA corpora generation with roundtrip consistency (2019) ACL, (1), pp. 6168-6173. , pages Association for Computational Linguistics; Alzantot, Moustafa, Sharma, Yash, Elgohary, Ahmed, Ho, Bo-Jhang, Srivastava, Mani, Chang, Kai-Wei, Generating natural language adversarial examples (2018) Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 2890-2896. , Brussels, Belgium. Association for Computational Linguistics; Belinkov, Yonatan, Bisk, Yonatan, Synthetic and natural noise both break neural machine translation (2018) International Conference on Learning Representations; Devlin, Jacob, Chang, Ming-Wei, Lee, Kenton, Toutanova, Kristina, BERT: Pre-training of deep bidirectional transformers for language understanding (2019) Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 1, pp. 4171-4186. , (Long and Short Papers), pages Minneapolis, Minnesota. Association for Computational Linguistics; Ebrahimi, Javid, Rao, Anyi, Lowd, Daniel, Dou, Dejing, HotFlip: White-box adversarial examples for text classification (2018) Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, 2, pp. 31-36. , Short Papers), pages Melbourne, Australia. Association for Computational Linguistics; Ettinger, Allyson, Rao, Sudha, Daumé, Hal, Bender, Emily M., Towards linguistically generalizable NLP systems: A workshop and shared task (2017) Proceedings of the First Workshop on Building Linguistically Generalizable NLP Systems; Feng, Shi, Wallace, Eric, Grissom, Alvin, Iyyer, Mohit, Rodriguez, Pedro, Boyd-Graber, Jordan, Pathologies of neural models make interpretations difficult (2018) Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 3719-3728. , Brussels, Belgium. Association for Computational Linguistics; Gardner, Matt, Artzi, Yoav, Basmova, Victoria, Berant, Jonathan, Bogin, Ben, Chen, Sihao, Dasigi, Pradeep, Zhou, Ben, (2020) Evaluating nlp models via contrast sets; Gururangan, Suchin, Swayamdipta, Swabha, Levy, Omer, Schwartz, Roy, Bowman, Samuel R., Smith, Noah A., Annotation artifacts in natural language inference data (2018) NAACL-HLT, (2), pp. 107-112. , pages Association for Computational Linguistics; Hosseini, Hossein, Xiao, Baicen, Poovendran, Radha, Deceiving google’s cloud video intelligence API built for summarizing videos (2017) CVPR Workshops, pp. 1305-1309. , IEEE Computer Society; Hu, Minghao, Wei, Furu, Peng, Yuxing, Huang, Zhen, Yang, Nan, Li, Dongsheng, Read + verify: Machine reading comprehension with unanswerable questions (2019) AAAI, pp. 6529-6537. , AAAI Press; Iyyer, Mohit, Wieting, John, Gimpel, Kevin, Zettlemoyer, Luke, Adversarial example generation with syntactically controlled paraphrase networks (2018) Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 1, pp. 1875-1885. , a (Long Papers), pages New Orleans, Louisiana. Association for Computational Linguistics; Iyyer, Mohit, Wieting, John, Gimpel, Kevin, Zettlemoyer, Luke, Adversarial example generation with syntactically controlled paraphrase networks (2018) NAACL-HLT, pp. 1875-1885. , b pages Association for Computational Linguistics; Jacobsen, Joern-Henrik, Behrmann, Jens, Zemel, Richard, Bethge, Matthias, Excessive invariance causes adversarial vulnerability (2019) International Conference on Learning Representations; Jia, Robin, Liang, Percy, Adversarial examples for evaluating reading comprehension systems (2017) Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pp. 2021-2031. , Copenhagen, Denmark. Association for Computational Linguistics; Kaushik, Divyansh, Hovy, Eduard, Lipton, Zachary, Learning the difference that makes a difference with counterfactually-augmented data (2020) International Conference on Learning Representations; Kurakin, Alexey, Goodfellow, Ian, Bengio, Samy, (2016) Adversarial examples in the physical world, , arXiv preprint arXiv:1607.02533; Lewis, Mike, Fan, Angela, Generative question answering: Learning to answer the whole question (2019) International Conference on Learning Representations; Liu, Yinhan, Ott, Myle, Goyal, Naman, Du, Jingfei, Joshi, Mandar, Chen, Danqi, Levy, Omer, Stoyanov, Veselin, Roberta: A robustly optimized BERT pretraining approach (2019), CoRR, abs/1907.11692; Lu, Kaiji, Mardziel, Piotr, Wu, Fangjing, Amancharla, Preetam, Datta, Anupam, (2018) Gender bias in neural natural language processing, , ArXiv, abs/1807.11714; Mikolov, Tomas, Sutskever, Ilya, Chen, Kai, Corrado, Greg S, Dean, Jeff, Distributed representations of words and phrases and their compositionality (2013) Advances in Neural Information Processing Systems, 26, pp. 3111-3119. , C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger, editors, pages Curran Associates, Inc; Niu, Tong, Bansal, Mohit, Adversarial oversensitivity and over-stability strategies for dialogue models (2018) Proceedings of the 22nd Conference on Computational Natural Language Learning, pp. 486-496. , Brussels, Belgium. Association for Computational Linguistics; Rajpurkar, Pranav, Jia, Robin, Liang, Percy, Know what you don’t know: Unanswerable questions for SQuAD (2018) Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, 2, pp. 784-789. , Short Papers), pages Melbourne, Australia. Association for Computational Linguistics; Ribeiro, Marco Tulio, Singh, Sameer, Guestrin, Carlos, Anchors: High-precision model-agnostic explanations (2018) AAAI Conference on Artificial Intelligence (AAAI); Ribeiro, Marco Tulio, Singh, Sameer, Guestrin, Carlos, Semantically equivalent adversarial rules for debugging NLP models (2018) Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, 1, pp. 856-865. , b Long Papers), pages Association for Computational Linguistics; Ribeiro, Marco Tulio, Wu, Tongshuang, Guestrin, Carlos, Singh, Sameer, Beyond accuracy: Behavioral testing of NLP models with CheckList (2020) Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 4902-4912. , Online. Association for Computational Linguistics; Seo, Min Joon, Kembhavi, Aniruddha, Farhadi, Ali, Hajishirzi, Hannaneh, Bidirectional attention flow for machine comprehension (2017) ICLR; Sugawara, Saku, Inui, Kentaro, Sekine, Satoshi, Aizawa, Akiko, What makes reading comprehension questions easier? (2018) Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 4208-4219. , Brussels, Belgium. Association for Computational Linguistics; Szegedy, Christian, Zaremba, Wojciech, Sutskever, Ilya, Bruna, Joan, Erhan, Dumitru, Goodfellow, Ian, Fergus, Rob, (2013) Intriguing properties of neural networks, , arXiv preprint arXiv:1312.6199; Talmor, Alon, Berant, Jonathan, MultiQA: An empirical investigation of generalization and transfer in reading comprehension (2019) Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pp. 4911-4921. , Florence, Italy. Association for Computational Linguistics; Trischler, Adam, Wang, Tong, Yuan, Xingdi, Harris, Justin, Sordoni, Alessandro, Bachman, Philip, Suleman, Kaheer, NewsQA: A machine comprehension dataset (2017) Proceedings of the 2nd Workshop on Representation Learning for NLP, pp. 191-200. , Vancouver, Canada. Association for Computational Linguistics; Tsipras, Dimitris, Santurkar, Shibani, Engstrom, Logan, Turner, Alexander, Madry, Aleksander, Robustness may be at odds with accuracy (2019) International Conference on Learning Representations; Wallace, Eric, Feng, Shi, Kandpal, Nikhil, Gardner, Matt, Singh, Sameer, (2019) Universal adversarial triggers for NLP, , CoRR, abs/1908.07125; Wang, Yicheng, Bansal, Mohit, Robust machine comprehension models via adversarial training (2018) Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 2, pp. 575-581. , (Short Papers), pages New Orleans, Louisiana. Association for Computational Linguistics; Welbl, Johannes, Huang, Po-Sen, Stanforth, Robert, Gowal, Sven, Krishnamurthy, Dvijotham, Martin Szummer, Kohli, Pushmeet, Towards verified robustness under text deletion interventions (2020) International Conference on Learning Representations, , (Dj) and; Yu, Adams Wei, Dohan, David, Le, Quoc, Luong, Thang, Zhao, Rui, Chen, Kai, Fast and accurate reading comprehension by combining self-attention and convolution (2018) International Conference on Learning Representations; Zhang, Wei Emma, Sheng, Quan Z., Alhazmi, Ahoud Abdulrahmn F., (2019) Generating textual adversarial examples for deep learning models: A survey, , CoRR, abs/1901.06796; Zhao, Jieyu, Wang, Tianlu, Yatskar, Mark, Ordonez, Vicente, Chang, Kai-Wei, Gender bias in coreference resolution: Evaluation and debiasing methods (2018) Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 2, pp. 15-20. , (Short Papers), pages New Orleans, Louisiana. Association for Computational Linguistics; Zhu, Haichao, Dong, Li, Wei, Furu, Wang, Wenhui, Qin, Bing, Liu, Ting, Learning to ask unanswerable questions for machine reading comprehension (2019) Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pp. 4238-4248. , Florence, Italy. Association for Computational Linguistics",,,,Association for Computational Linguistics (ACL),"Findings of the Association for Computational Linguistics, ACL 2020: EMNLP 2020",16 November 2020 through 20 November 2020,,172733,,9.78E+12,,,English,Findings Assoc. Comp. Linguist. Findings ACL: EMNLP,Conference Paper,Final,,Scopus,2-s2.0-85107930887
"Wang Y.S., Weng T.W., Daniel L.",56108794600;56448283400;7102917670;,Neural network control policy verification with persistent adversarial perturbations,2020,"37th International Conference on Machine Learning, ICML 2020",PartF168147-13,,,9992,10001,,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105259982&partnerID=40&md5=cbd66d77e4f87685d860d437ab479a3e,"Argo Ai, Pittsburgh, PA, United States; Department of Eecs, Massachusetts Institute of Technology, Cambridge, MA, United States","Wang, Y.S., Argo Ai, Pittsburgh, PA, United States; Weng, T.W., Department of Eecs, Massachusetts Institute of Technology, Cambridge, MA, United States; Daniel, L., Department of Eecs, Massachusetts Institute of Technology, Cambridge, MA, United States","Deep neural networks are known to be fragile to small adversarial perturbations, which raises serious concerns when a neural network policy is interconnected with a physical system in a closed loop. In this paper, we show how to combine recent works on static neural network certification tools with robust control theory to certify a neural network policy in a control loop. We give a sufficient condition and an algorithm to ensure that the closed loop state and control constraints are satisfied when the persistent adversarial perturbation is `1 norm bounded. Our method is based on finding a positively invariant set of the closed loop dynamical system, and thus we do not require the continuity of the neural network policy. Along with the verification result, we also develop an effective attack strategy for neural network control systems that outperforms exhaustive Monte-Carlo search significantly. We show that our certification algorithm works well on learned models and could achieve 5 times better result than the traditional Lipschitz-based method to certify the robustness of a neural network policy on the cart-pole balance control problem. © 2020 by the Authors.",,Deep learning; Deep neural networks; Dynamical systems; Learning systems; Robust control; Attack strategies; Balance control; Neural network control; Physical systems; Positively invariant sets; State and control constraints; Static neural networks; Verification results; Neural networks,,,,,"Aström, K. J., Murray, R. M., (2010) Feedback systems: An introduction for scientists and engineers, , Princeton university press; Athalye, A., Carlini, N., Wagner, D., Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples (2018) ICML; Berkenkamp, F., Turchetta, M., Schoellig, A., Krause, A., Safe model-based reinforcement learning with stability guarantees (2017) Advances in neural information processing systems, pp. 908-918; Blondel, V., Tsitsiklis, J. N., Np-hardness of some linear control design problems (1997) SIAM Journal on Control and Optimization, 35 (6), pp. 2118-2127; Boopathy, A., Weng, T.-W., Chen, P.-Y., Liu, S., Daniel, L., Cnn-cert: An efficient framework for certifying robustness of convolutional neural networks (2019) AAAI, , Jan; Brockman, G., Cheung, V., Pettersson, L., Schneider, J., Schulman, J., Tang, J., Zaremba, W., (2016) Openai gym; Bunel, R. R., Turkaslan, I., Torr, P., Kohli, P., Mudigonda, P. K., A unified view of piecewise linear neural network verification (2018) Advances in Neural Information Processing Systems, pp. 4790-4799; Carr, S., Jansen, N., Wimmer, R., Serban, A. C., Becker, B., Topcu, U., (2019) Counterexample-guided strategy improvement for pomdps using recurrent neural networks, , arXiv preprint arXiv:1903.08428; Dahleh, M. A., Pearson, J. B., l1-optimal feedback controllers for mimo discrete-Time systems (1987) IEEE Transactions on Automatic Control, 32 (4), pp. 314-322; Dean, S., Mania, H., Matni, N., Recht, B., Tu, S., (2017) On the sample complexity of the linear quadratic regulator, , arXiv preprint arXiv:1710.01688; Dvijotham, K., Stanforth, R., Gowal, S., Mann, T., Kohli, P., A dual approach to scalable verification of deep networks (2018) UAI; Ehlers, R., Formal verification of piece-wise linear feedforward neural networks (2017) International Symposium on Automated Technology for Verification and Analysis, pp. 269-286. , Springer; Gehr, T., Mirman, M., Drachsler-Cohen, D., Tsankov, P., Chaudhuri, S., Vechev, M., Ai2: Safety and robustness certification of neural networks with abstract interpretation (2018) IEEE Symposium on Security and Privacy (SP), pp. 948-963. , 00; Hill, A., Raffin, A., Ernestus, M., Gleave, A., Traore, R., Dhariwal, P., Hesse, C., Wu, Y., (2018) Stable baselines, , https://github.com/hill-A/stable-baselines; Huang, S., Papernot, N., Goodfellow, I., Duan, Y., Abbeel, P., (2017) Adversarial attacks on neural network policies, , arXiv preprint arXiv:1702.02284; Ivanov, R., Weimer, J., Alur, R., Pappas, G. J., Lee, I., Verisig: verifying safety properties of hybrid systems with neural network controllers (2019) Proceedings of the 22nd ACM International Conference on Hybrid Systems: Computation and Control, pp. 169-178. , ACM; Jia, R., Liang, P., Adversarial examples for evaluating reading comprehension systems (2017) Empirical Methods in Natural Language Processing (EMNLP), , Outstanding paper award; Jin, M., Lavaei, J., Control-Theoretic analysis of smoothness for stability-certified reinforcement learning (2018) 2018 IEEE Conference on Decision and Control (CDC), pp. 6840-6847. , IEEE, a; Jin, M., Lavaei, J., (2018) Stability-certified reinforcement learning: A control-Theoretic perspective, , arXiv preprint arXiv:1810.11505, b; Katz, G., Barrett, C., Dill, D. L., Julian, K., Kochenderfer, M. J., Reluplex: An efficient SMT solver for verifying deep neural networks (2017) International Conference on Computer Aided Verification, pp. 97-117. , Springer; Khammash, M., Pearson, J., Performance robustness of discrete-Time systems with structured uncertainty (1991) IEEE Transactions on Automatic Control, 36 (4), pp. 398-412; Kiumarsi, B., Vamvoudakis, K. G., Modares, H., Lewis, F. L., Optimal and autonomous control using reinforcement learning: A survey (2017) IEEE transactions on neural networks and learning systems, 29 (6), pp. 2042-2062; Kolter, J. Z., Wong, E., Provable defenses against adversarial examples via the convex outer adversarial polytope (2018) ICML; Oppenheim, A. V., Willsky, A. S., Nawab, S. H., (1996) Signals & systems, , Prentice-Hall, Inc; Packard, A., Doyle, J., The complex structured singular value (1993) Automatica, 29 (1), pp. 71-109; Recht, B., A tour of reinforcement learning: The view from continuous control (2019) Annual Review of Control, Robotics, and Autonomous Systems, 2, pp. 253-279; Richards, S. M., Berkenkamp, F., Krause, A., (2018) The lyapunov neural network: Adaptive stability certification for safe learning of dynamic systems, , arXiv preprint arXiv:1808.00924; Royo, V. R., Calandra, R., Stipanovic, D. M., Tomlin, C., (2019) Fast neural network verification via shadow prices, , arXiv preprint arXiv:1902.07247; Ruan, W., Wu, M., Sun, Y., Huang, X., Kroening, D., Kwiatkowska, M., (2018) Global robustness evaluation of deep neural networks with provable guarantees for the l_0 norm, , arXiv preprint arXiv:1804.05805; Schulman, J., Wolski, F., Dhariwal, P., Radford, A., Klimov, O., (2017) Proximal policy optimization algorithms, , arXiv preprint arXiv:1707.06347; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing properties of neural networks, , arXiv preprint arXiv:1312.6199; Weng, T.-W., Zhang, H., Chen, H., Song, Z., Hsieh, C.-J., Boning, D., Dhillon, I. S., Daniel, L., Towards fast computation of certified robustness for relu networks (2018) ICML; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., Adversarial examples for semantic segmentation and object detection (2017) ICCV; Zhang, H., Weng, T.-W., Chen, P.-Y., Hsieh, C.-J., Daniel, L., Efficient neural network robustness certification with general activation functions (2018) NIPS, , dec; Zhang, T., Kahn, G., Levine, S., Abbeel, P., Learning deep control policies for autonomous aerial vehicles with mpc-guided policy search (2016) 2016 IEEE international conference on robotics and automation (ICRA), pp. 528-535. , IEEE; Zhou, K., Doyle, J. C., Glover, K., (1996) Robust and optimal control, 40. , Prentice hall New Jersey","Wang, Y.S.; Argo AiUnited States; 电子邮件: yswang@argo.ai",Daume H.Singh A.,,International Machine Learning Society (IMLS),"37th International Conference on Machine Learning, ICML 2020",13 July 2020 through 18 July 2020,,168147,,9.78E+12,,,English,"Int. Conf. Machin. Learn., ICML",Conference Paper,Final,,Scopus,2-s2.0-85105259982
"Geiping J., Bauermeister H., Dröge H., Moeller M.",57201420593;57219689713;57219687382;56496461000;,Inverting gradients - How easy is it to break privacy in federated learning?,2020,Advances in Neural Information Processing Systems,2020-December,,,,,,19,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103750657&partnerID=40&md5=2dccdaaee368280fe63246fd126a7ee4,"Dep. of Electrical Engineering and Computer Science, University of Siegen, Germany","Geiping, J., Dep. of Electrical Engineering and Computer Science, University of Siegen, Germany; Bauermeister, H., Dep. of Electrical Engineering and Computer Science, University of Siegen, Germany; Dröge, H., Dep. of Electrical Engineering and Computer Science, University of Siegen, Germany; Moeller, M., Dep. of Electrical Engineering and Computer Science, University of Siegen, Germany","The idea of federated learning is to collaboratively train a neural network on a server. Each user receives the current weights of the network and in turns sends parameter updates (gradients) based on local data. This protocol has been designed not only to train neural networks data-efficiently, but also to provide privacy benefits for users, as their input data remains on device and only parameter gradients are shared. But how secure is sharing parameter gradients? Previous attacks have provided a false sense of security, by succeeding only in contrived settings - even for a single image. However, by exploiting a magnitude-invariant loss along with optimization strategies based on adversarial attacks, we show that is is actually possible to faithfully reconstruct images at high resolution from the knowledge of their parameter gradients, and demonstrate that such a break of privacy is possible even for trained deep networks. We analyze the effects of architecture as well as parameters on the difficulty of reconstructing an input image and prove that any input to a fully connected layer can be reconstructed analytically independent of the remaining architecture. Finally we discuss settings encountered in practice and show that even aggregating gradients over several iterations or several images does not guarantee the user’s privacy in federated learning applications. © 2020 Neural information processing systems foundation. All rights reserved.",,Image reconstruction; Network architecture; Privacy by design; High resolution; Input datas; Input image; Local data; Optimization strategy; Sense of security; Single images; Neural networks,,,,,"Athalye, Anish, Carlini, Nicholas, Wagner, David, (2018) Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples, , arXiv:1802.00420 [cs], February; Benning, Martin, Burger, Martin, Modern regularization methods for inverse problems (2018) Acta Numerica, 27, pp. 1-111. , May; Bonawitz, Keith, Eichner, Hubert, Grieskamp, Wolfgang, Huba, Dzmitry, Ingerman, Alex, Ivanov, Vladimir, Kiddon, Chloe, Roselander, Jason, (2019) Towards Federated Learning at Scale: System Design, , arXiv:1902.01046 [cs, stat], March; Candes, E. J., Romberg, J., Tao, T., Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency information (2006) IEEE Transactions on Information Theory, 52 (2), pp. 489-509. , February; Charpiat, Guillaume, Girard, Nicolas, Felardos, Loris, Tarabalka, Yuliya, Input Similarity from the Neural Network Perspective (2019) Advances in Neural Information Processing Systems, 32, pp. 5342-5351. , Curran Associates, Inc; Chilimbi, Trishul, Suzue, Yutaka, Apacible, Johnson, Kalyanaraman, Karthik, Project Adam: Building an Efficient and Scalable Deep Learning Training System (2014) 11th {USENIX} Symposium on Operating Systems Design and Implementation ({OSDI} 14), pp. 571-582; Dosovitskiy, Alexey, Brox, Thomas, Generating Images with Perceptual Similarity Metrics based on Deep Networks (2016) Advances in Neural Information Processing Systems, 29, pp. 658-666. , Curran Associates, Inc; Dosovitskiy, Alexey, Brox, Thomas, Inverting Visual Representations With Convolutional Networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4829-4837; Fredrikson, Matt, Jha, Somesh, Ristenpart, Thomas, Model Inversion Attacks that Exploit Confidence Information and Basic Countermeasures (2015) Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security, CCS’15, pp. 1322-1333. , Denver, Colorado, USA, October Association for Computing Machinery; Ganju, Karan, Wang, Qi, Yang, Wei, Gunter, Carl A., Borisov, Nikita, Property Inference Attacks on Fully Connected Neural Networks using Permutation Invariant Representations (2018) Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, pp. 619-633. , Toronto Canada, January ACM; Jacobsen, Jörn-Henrik, Smeulders, Arnold, Oyallon, Edouard, (2018) I-RevNet: Deep Invertible Networks, , arXiv:1802.07088 [cs, stat], February; Jayaraman, Bargav, Evans, David, (2019) Evaluating Differentially Private Machine Learning in Practice, , arXiv:1902.08874 [cs, stat], August; Jochems, Arthur, Deist, Timo M., Naqa, Issam El, Kessler, Marc, Mayo, Chuck, Reeves, Jackson, Jolly, Shruti, Dekker, Andre, Developing and Validating a Survival Prediction Model for NSCLC Patients Through Distributed Learning Across 3 Countries (2017) International Journal of Radiation Oncology*Biology*Physics, 99 (2), pp. 344-352. , October; Jochems, Arthur, Deist, Timo M., van Soest, Johan, Eble, Michael, Bulens, Paul, Coucke, Philippe, Dries, Wim, Dekker, Andre, Distributed learning: Developing a predictive model based on data from multiple hospitals without data leaving the hospital – A real life proof of concept (2016) Radiotherapy and Oncology, 121 (3), pp. 459-467. , December; Kingma, Diederik P., Ba, Jimmy, Adam: A Method for Stochastic Optimization (2015) International Conference on Learning Representations (ICLR), , San Diego, May; Koh, Pang Wei, Liang, Percy, Understanding Black-box Predictions via Influence Functions (2017) International Conference on Machine Learning, pp. 1885-1894. , July; Konecný, Jakub, McMahan, Brendan, Ramage, Daniel, (2015) Federated Optimization:Distributed Optimization Beyond the Datacenter, , arXiv:1511.03575 [cs, math], November; Liu, Dong C., Nocedal, Jorge, On the limited memory BFGS method for large scale optimization (1989) Mathematical Programming, 45 (1-3), pp. 503-528. , August; Madry, Aleksander, Makelov, Aleksandar, Schmidt, Ludwig, Tsipras, Dimitris, Vladu, Adrian, (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , arXiv:1706.06083 [cs, stat], June; Mahendran, Aravindh, Vedaldi, Andrea, Visualizing Deep Convolutional Neural Networks Using Natural Pre-images (2016) International Journal of Computer Vision, 120 (3), pp. 233-255. , December; Brendan McMahan, H., Moore, Eider, Ramage, Daniel, Hampson, Seth, Agüera, Blaise, Arcas, y, (2017) Communication-Efficient Learning of Deep Networks from Decentralized Data, , arXiv:1602.05629 [cs], February; Brendan McMahan, H., Ramage, Daniel, Talwar, Kunal, Zhang, Li, (2018) Learning Differentially Private Recurrent Language Models, , arXiv:1710.06963 [cs], February; Melis, Luca, Song, Congzheng, Cristofaro, Emiliano De, Shmatikov, Vitaly, Exploiting Unintended Feature Leakage in Collaborative Learning (2019) 2019 IEEE Symposium on Security and Privacy (SP), pp. 691-706. , May; Phong, Le Trieu, Aono, Yoshinori, Hayashi, Takuya, Wang, Lihua, Moriai, Shiho, Privacy-Preserving Deep Learning: Revisited and Enhanced (2017) Applications and Techniques in Information Security, Communications in Computer and Information Science, pp. 100-110. , Singapore, Springer; Phong, Le Trieu, Aono, Yoshinori, Hayashi, Takuya, Wang, Lihua, Moriai, Shiho, (2017) Privacy-Preserving Deep Learning via Additively Homomorphic Encryption, , Technical Report 715; Reddi, Sashank, Charles, Zachary, Zaheer, Manzil, Garrett, Zachary, Rush, Keith, Konecný, Jakub, Kumar, Sanjiv, Brendan McMahan, H., (2020) Adaptive Federated Optimization, , arXiv:2003.00295 [cs, math, stat], February; Rudin, Leonid I., Osher, Stanley, Fatemi, Emad, Nonlinear total variation based noise removal algorithms (1992) Physica D: Nonlinear Phenomena, 60 (1), pp. 259-268. , November; Shokri, Reza, Shmatikov, Vitaly, Privacy-Preserving Deep Learning (2015) Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security - CCS’15, pp. 1310-1321. , Denver, Colorado, USA, ACM Press; Szegedy, Christian, Zaremba, Wojciech, Sutskever, Ilya, Bruna, Joan, Erhan, Dumitru, Goodfellow, Ian, Fergus, Rob, (2013) Intriguing properties of neural networks, , arXiv:1312.6199 [Cs], December; Veale, Michael, Binns, Reuben, Edwards, Lilian, Algorithms that remember: Model inversion attacks and data protection law (2018) Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences, 376 (2133), p. 20180083. , November; Wang, Zhibo, Song, Mengkai, Zhang, Zhifei, Song, Yang, Wang, Qian, Qi, Hairong, (2018) Beyond Inferring Class Representatives: User-Level Privacy Leakage From Federated Learning, , arXiv:1812.00535 [cs], December; Yang, Qiang, Liu, Yang, Chen, Tianjian, Tong, Yongxin, (2019) Federated Machine Learning: Concept and Applications, , arXiv:1902.04885 [cs], February; Zhang, Yuheng, Jia, Ruoxi, Pei, Hengzhi, Wang, Wenxiao, Li, Bo, Song, Dawn, (2019) The Secret Revealer: Generative Model-Inversion Attacks Against Deep Neural Networks, , arXiv:1911.07135 [cs, stat], November; Zhao, Bo, Mopuri, Konda Reddy, Bilen, Hakan, iDLG: Improved Deep Leakage from Gradients, , arXiv:2001.02610 [cs, stat], January 2020; Zhu, Ligeng, Liu, Zhijian, Han, Song, Deep Leakage from Gradients (2019) Advances in Neural Information Processing Systems, 32, pp. 14774-14784. , Curran Associates, Inc","Geiping, J.; Dep. of Electrical Engineering and Computer Science, Germany; 电子邮件: jonas.geiping@uni-siegen.de
Bauermeister, H.; Dep. of Electrical Engineering and Computer Science, Germany; 电子邮件: hartmut.bauermeister@uni-siegen.de
Dröge, H.; Dep. of Electrical Engineering and Computer Science, Germany; 电子邮件: hannah.droege@uni-siegen.de",,Apple;et al.;Microsoft;PDT Partners;Sony;Tenstorrent,Neural information processing systems foundation,"34th Conference on Neural Information Processing Systems, NeurIPS 2020",6 December 2020 through 12 December 2020,,169463,10495258,,,,English,Adv. neural inf. proces. syst.,Conference Paper,Final,,Scopus,2-s2.0-85103750657
"Tramer F., Behrmann J., Carlini N., Papernot N., Jacobsen J.H.",56878876400;57201698451;57194977162;56732917800;56799939300;,Fundamental Tradeoffs between Invariance and Sensitivity to Adversarial Perturbations,2020,"37th International Conference on Machine Learning, ICML 2020",PartF168147-13,,,9503,9513,,4,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101673181&partnerID=40&md5=e9941b2e8e7c7ff54f08799a95f040c0,"Stanford University, United States; University of Bremen, Germany; Google Brain, United States; Vector Institute and University of Toronto, Canada","Tramer, F., Stanford University, United States; Behrmann, J., University of Bremen, Germany; Carlini, N., Google Brain, United States; Papernot, N., Google Brain, United States; Jacobsen, J.H., Vector Institute and University of Toronto, Canada","Adversarial examples are malicious inputs crafted to induce misclassification. Commonly studied sensitivity-based adversarial examples introduce semantically-small changes to an input that result in a different model prediction. This paper studies a complementary failure mode, invariance-based adversarial examples, that introduce minimal semantic changes that modify an input s true label yet preserve the model s prediction. We demonstrate fundamental tradeoffs between these two types of adversarial examples. We show that defenses against sensitivity-based attacks actively harm a model s accuracy on invariance-based attacks, and that new approaches are needed to resist both attack types. In particular, we break state-of-The-Art adversarially-Trained and certifiably-robust models by generating small perturbations that the models are (provably) robust to, yet that change an input s class according to human labelers. Finally, we formally show that the existence of excessively invariant classifiers arises from the presence of overly-robust predictive features in standard datasets. © 2020 by the Authors.",,Classification (of information); Machine learning; Semantics; Misclassifications; Model prediction; New approaches; Robust models; Small perturbations; State of the art; Commerce,,,,,"Bafna, M., Murtagh, J., Vyas, N., Thwarting adversarial examples: An ?0-robust sparse fourier transform (2018) Advances in Neural Information Processing Systems, pp. 10096-10106; Biggio, B., Corona, I., Maiorca, D., Nelson, B., rndié, N., Laskov, P., Giacinto, G., Roli, F, Evasion attacks against machine learning at test time (2013) Joint European conference on machine learning and knowledge discovery in databases, pp. 387-402. , Springer; Co, K. T., Mufloz-GonzAlez, L., de Maupeou, S., Lupu, E. C., (2018) Procedural noise adversarial examples for black-box attacks on deep convolutional networks, , arXiv preprint arXiv]8]O.00470; Engstrom, L., Ilyas, A., Santurkar, S., Tsipras, D., Tran, B., Madry, A., (2019) Adversarial robustness as a prior for learned representations; Engstrom, L., Tran, B., Tsipras, D., Schmidt, L., Madry, A., Exploring the landscape of spatial robustness (2019) International Conference on Machine Learning, pp. 1802-1811; Gilmer, J., Adams, R. P., Goodfellow, I., Andersen, D., Dahi, G. E., (2018) Motivating the rules of the game for adversarial example research, , arXiv preprint arXiv]807. 06732; Goodfellow, I., Papernot, N., Is attacking machine learning easier than defending it? (2017), 15, p. 2017. , Blog post on Feb; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations; Goodfellow, I. J., Shlens, J., Szegedy, C., (2014) Explaining and harnessing adversarial examples, , arXiv preprint arXiv:1412.6572; Ilyas, A., Jalal, A., Asteri, E., Daskalakis, C., Dimakis, A. G., (2017) The robust manifold defense: Adversarial training using generative models, , arXiv preprint arXiv:1712.09196; Ilyas, A., Santurkar, S., Tsipras, D., Engstrom, L., Tran, B., Madry, A., Adversarial examples are not bugs, they are features (2019) Advances in Neural Information Processing Systems, pp. 125-136; Jacobsen, J.-H., Behrmann, J., Zemel, R., Bethge, M., Excessive invariance causes adversarial vulnerability (2019) International Conference on Learning Representations; Jo, J., Bengio, Y., (2017) Measuring the tendency of cnns to learn surface statistical regularities, , arXiv preprint arXiv:1711.11561; Kang, D., Sun, Y., Hendrycks, D., Brown, T., Steinhardt, J., (2019) Testing robustness against unforeseen adversaries, , arXiv preprint arXiv:1908.08016; Kaushik, D., Hovy, E., Lipton, Z. C., (2019) Learning the difference that makes a difference with counterfactuallyaugmented data, , arXiv preprint arXiv:1909.12434; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2017) International Conference on Learning Representations; Mirza, M., Osindero, S., (2014) Conditional generative adversarial nets, , arXivpreprint arXiv:1411.1 784; Panda, P., Chakraborty, I., Roy, K., Discretization based solutions for secure machine learning against adversarial attacks (2019) IEEE Access, 7, pp. 70157-70168; Raghunathan, A., Steinhardt, J., Liang, P., Certified defenses against adversarial examples (2018) International Conference on Learning Representations; Sabour, S., Cao, Y., Faghri, F., Fleet, D. J., Adversarial manipulation of deep representations (2016) International Conference on Learning Representations; Samangouei, P., Kabkab, M., Chellappa, R., (2018) Defensegan: Protecting classifiers against adversarial attacks using generative models, , arXiv preprint arXiv:1805.06605; Schott, L., Rauber, J., Bethge, M., Brendel, W., Towards the first adversarially robust neural network model on MNIST (2019) International Conference on Learning Representations; Shaeiri, A., Nobahari, R., Rohban, M. H., (2020) Towards deep learning models resistant to large perturbations, , arXiv preprint arXiv:2003.1 33 70; Sharif, M., Bauer, L., Reiter, M. K., On the suitability of lp-norms for creating and preventing adversarial examples (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, pp. 1605-1613; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing properties of neural networks, , arXivpreprint arXiv:1312.6199; Tramèr, F., Boneh, D., Adversarial training and robustness for multiple perturbations (2019) Advances in Neural Information Processing Systems, pp. 5858-5868; Tramèr, F., Dupré, P., Rusak, G., Pellegrino, G., Boneh, D., Adversarial: Perceptual ad blocking meets adversarial machine learning (2019) Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security, , 2005?202 1; Tsipras, D., Santurkar, S., Engstrom, L., Turner, A., Madry, A., Robustness may be at odds with accuracy (2019) International Conference on Learning Representations; Wong, E., Kolter, Z., Provable defenses against adversarial examples via the convex outer adversarial polytope (2018) Proceedings of the 35th International Conference on Machine Learning; Yin, D., Lopes, R. G., Shlens, J., Cubuk, E. D., Gilmer, J., (2019) A fourier perspective on model robustness in computer vision, , arXiv preprint arXiv:1906.08988; Zhang, H., Chen, H., Xiao, C., Li, B., Boning, D., Hsieh, C.-J., (2019) Towards stable and efficient training of verifiably robust neural networks, , arXiv preprint arXiv]906.063]6","Tramer, F.; Stanford UniversityUnited States; 电子邮件: tramer@cs.stanford.edu",Daume H.Singh A.,,International Machine Learning Society (IMLS),"37th International Conference on Machine Learning, ICML 2020",13 July 2020 through 18 July 2020,,168147,,9.78E+12,,,English,"Int. Conf. Machin. Learn., ICML",Conference Paper,Final,,Scopus,2-s2.0-85101673181
"Morawiecki P., Spurek P., Smieja M., Tabor J.",23985570800;54906233900;55199316800;7007067124;,Fast and stable interval bounds propagation for training verifiably robust models,2020,"ESANN 2020 - Proceedings, 28th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning",,,,55,60,,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099000135&partnerID=40&md5=658dc9cbb7aea98a37d04988912299b5,"Institute of Computer Science, Polish Academy of Sciences, Poland; Institute of Computer Science and Computational Mathematics, Jagiellonian University, Poland","Morawiecki, P., Institute of Computer Science, Polish Academy of Sciences, Poland; Spurek, P., Institute of Computer Science and Computational Mathematics, Jagiellonian University, Poland; Smieja, M., Institute of Computer Science and Computational Mathematics, Jagiellonian University, Poland; Tabor, J., Institute of Computer Science and Computational Mathematics, Jagiellonian University, Poland","We present an efficient technique to train classification networks which are verifiably robust against norm-bounded adversarial attacks. This framework is built upon interval bounds propagation (IBP), which applies the interval arithmetic to bound the activations at each layer and keeps the prediction invariant to the input perturbation. To speed up and stabilize training of IBP, we supply its cost function with an additional term, which encourages the model to keep the interval bounds at hidden layers small. Experimental results demonstrate that the training of our model is faster, more stable and less sensitive to the exact specification of the training process than original IBP. © ESANN 2020 - Proceedings, 28th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning.",,Backpropagation; Cost functions; Intelligent computing; Learning systems; Classification networks; Hidden layers; Input perturbation; Interval arithmetic; Interval bounds; Robust models; Speed up; Training process; Neural networks,,,,,"Szegedy, Christian, Zaremba, Wojciech, Sutskever, Ilya, Bruna, Joan, Erhan, Dumitru, Goodfellow, Ian, Fergus, Rob, (2013) Intriguing properties of neural networks, , arXiv preprint arXiv:1312.6199; Tramèr, Florian, Kurakin, Alexey, Papernot, Nicolas, Goodfellow, Ian, Boneh, Dan, McDaniel, Patrick, (2017) Ensemble adversarial training: Attacks and defenses, , arXiv preprint arXiv:1705.07204; Yuan, Xiaoyong, He, Pan, Zhu, Qile, Li, Xiaolin, Adversarial examples: Attacks and defenses for deep learning (2019) IEEE transactions on neural networks and learning systems; Singh, Gagandeep, Gehr, Timon, Püschel, Markus, Vechev, Martin, An abstract domain for certifying neural networks (2019) Proceedings of the ACM on Programming Languages, 3, p. 41. , (POPL); Gowal, Sven, Dvijotham, Krishnamurthy, Stanforth, Robert, Bunel, Rudy, Qin, Chongli, Uesato, Jonathan, Mann, Timothy, Kohli, Pushmeet, (2018) On the effectiveness of interval bound propagation for training verifiably robust models, , arXiv preprint arXiv:1810.12715","Morawiecki, P.; Institute of Computer Science, Poland; 电子邮件: pawel.morawiecki@gmail.com",,,ESANN (i6doc.com),"28th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2020",2 October 2020 through 4 October 2020,,166125,,9.78E+12,,,English,"ESANN - Proc., Euro. Symp. Artif. Neural Networks, Comput. Intell. Mach. Learn.",Conference Paper,Final,,Scopus,2-s2.0-85099000135
"Sun J., Cao X., Liang H., Huang W., Chen Z., Li Z.",57219228248;57189660642;57220928721;57203556518;57219684996;55707052900;,New interpretations of normalization methods in deep learning,2020,AAAI 2020 - 34th AAAI Conference on Artificial Intelligence,,,,5875,5882,,4,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098397004&partnerID=40&md5=bfb7fccaf25bf38d672fb60f85a48ee4,"Huawei Noah's Ark Lab; Xi'an Jiaotong University, China","Sun, J., Huawei Noah's Ark Lab; Cao, X., Xi'an Jiaotong University, China; Liang, H., Huawei Noah's Ark Lab; Huang, W., Huawei Noah's Ark Lab; Chen, Z., Huawei Noah's Ark Lab; Li, Z., Huawei Noah's Ark Lab","In recent years, a variety of normalization methods have been proposed to help training neural networks, such as batch normalization (BN), layer normalization (LN), weight normalization (WN), group normalization (GN), etc. However, some necessary tools to analyze all these normalization methods are lacking. In this paper, we first propose a lemma to define some necessary tools. Then, we use these tools to make a deep analysis on popular normalization methods and obtain the following conclusions: 1) Most of the normalization methods can be interpreted in a unified framework, namely normalizing pre-activations or weights onto a sphere; 2) Since most of the existing normalization methods are scaling invariant, we can conduct optimization on a sphere with scaling symmetry removed, which can help to stabilize the training of network; 3) We prove that training with these normalization methods can make the norm of weights increase, which could cause adversarial vulnerability as it amplifies the attack. Finally, a series of experiments are conducted to verify these claims. © 2020, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,Multilayer neural networks; Network security; Normalization methods; Scaling symmetries; Unified framework; Deep learning,,,,,"Arnol'd, V. I., (2013) Mathematical methods of classical mechanics, 60. , Springer Science & Business Media; Arora, S., Li, Z., Lyu, K., (2018) Theoretical analysis of auto rate-tuning by batch normalization, , arXiv preprint arXiv:1812.03981; Ba, J. L., Kiros, J. R., Hinton, G. E., (2016) Layer normalization, , arXiv preprint arXiv:1607.06450; Bjorck, N., Gomes, C. P., Selman, B., Weinberger, K. Q., Understanding batch normalization (2018) Advances in Neural Information Processing Systems, pp. 7694-7705; Cho, M., Lee, J., Riemannian approach to batch normalization (2017) Advances in Neural Information Processing Systems, pp. 5225-5235; Galloway, A., Golubeva, A., Tanay, T., Moussa, M., Taylor, G. W., (2019) Batch normalization is a cause of adversarial vulnerability, , arXiv preprint arXiv:1905.02161; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770-778; Hoffer, E., Banner, R., Golan, I., Soudry, D., Norm matters: efficient and accurate normalization schemes in deep networks (2018) Advances in Neural Information Processing Systems, pp. 2160-2170; Huang, L., Liu, X., Liu, Y., Lang, B., Tao, D., Centered weight normalization in accelerating training of deep neural networks (2017) Proceedings of the IEEE International Conference on Computer Vision, pp. 2803-2811; Ioffe, S., Szegedy, C., (2015) Batch normalization: Accelerating deep network training by reducing internal covariate shift, , arXiv preprint arXiv:1502.03167; Kohler, J., Daneshmand, H., Lucchi, A., Hofmann, T., Zhou, M., Neymeyr, K., Exponential convergence rates for batch normalization: The power of length-direction decoupling in non-convex optimization (2019) The 22nd International Conference on Artificial Intelligence and Statistics, pp. 806-815; Liu, Z., Li, J., Shen, Z., Huang, G., Yan, S., Zhang, C., Learning efficient convolutional networks through network slimming (2017) Proceedings of the IEEE International Conference on Computer Vision, pp. 2736-2744; Luo, P., Wang, X., Shao, W., Peng, Z., (2019) Towards understanding regularization in batch normalization; Masters, D., Luschi, C., (2018) Revisiting small batch training for deep neural networks, , arXiv preprint arXiv:1804.07612; Meng, Q., Zheng, S., Zhang, H., Chen, W., Ma, Z.-M., Liu, T.-Y., G-sgd: Optimizing relu neural networks in its positively scale-invariant space (2019) ICLR 2019; Mishkin, D., Matas, J., (2015) All you need is a good init, , arXiv preprint arXiv:1511.06422; Miyato, T., Kataoka, T., Koyama, M., Yoshida, Y., (2018) Spectral normalization for generative adversarial networks; Morcos, A. S., Barrett, D. G., Rabinowitz, N. C., Botvinick, M., (2018) On the importance of single directions for generalization; Park, D. S., Sohl-Dickstein, J., Le, Q. V., Smith, S. L., (2019) The effect of network width on stochastic gradient descent and generalization: an empirical study, , arXiv preprint arXiv:1905.03776; Qiao, S., Wang, H., Liu, C., Shen, W., Yuille, A., (2019) Weight standardization, , arXiv preprint arXiv:1903.10520; Salimans, T., Kingma, D. P., Weight normalization: A simple reparameterization to accelerate training of deep neural networks (2016) Advances in Neural Information Processing Systems, pp. 901-909; Santurkar, S., Tsipras, D., Ilyas, A., Madry, A., How does batch normalization help optimization? (2018) Advances in Neural Information Processing Systems, pp. 2483-2493; Ulyanov, D., Vedaldi, A., Lempitsky, V., (2016) Instance normalization: The missing ingredient for fast stylization, , arXiv preprint arXiv:1607.08022; Wu, Y., He, K., Group normalization (2018) Proceedings of the European Conference on Computer Vision (ECCV), pp. 3-19; Yang, G., Pennington, J., Rao, V., Sohl-Dickstein, J., Schoenholz, S. S., (2019) A mean field theory of batch normalization, , arXiv preprint arXiv:1902.08129; Zhang, G., Wang, C., Xu, B., Grosse, R., (2018) Three mechanisms of weight decay regularization, , arXiv preprint arXiv:1810.12281",,,Association for the Advancement of Artificial Intelligence,AAAI press,"34th AAAI Conference on Artificial Intelligence, AAAI 2020",7 February 2020 through 12 February 2020,,166426,,9.78E+12,,,English,AAAI - AAAI Conf. Artif. Intell.,Conference Paper,Final,,Scopus,2-s2.0-85098397004
"Wang H., Dinkel H., Wang S., Qian Y., Yu K.",57211634201;57140223100;57201042533;35103128400;7403385716;,Dual-adversarial domain adaptation for generalized replay attack detection,2020,"Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH",2020-October,,,1086,1090,,3,10.21437/Interspeech.2020-1255,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098201244&doi=10.21437%2fInterspeech.2020-1255&partnerID=40&md5=20a717dd3ccd3db332b828441f6f1e3a,"MoE Key Lab of Artificial Intelligence SpeechLab, Department of Computer Science and Engineering AI Institute, Shanghai Jiao Tong University, Shanghai, China","Wang, H., MoE Key Lab of Artificial Intelligence SpeechLab, Department of Computer Science and Engineering AI Institute, Shanghai Jiao Tong University, Shanghai, China; Dinkel, H., MoE Key Lab of Artificial Intelligence SpeechLab, Department of Computer Science and Engineering AI Institute, Shanghai Jiao Tong University, Shanghai, China; Wang, S., MoE Key Lab of Artificial Intelligence SpeechLab, Department of Computer Science and Engineering AI Institute, Shanghai Jiao Tong University, Shanghai, China; Qian, Y., MoE Key Lab of Artificial Intelligence SpeechLab, Department of Computer Science and Engineering AI Institute, Shanghai Jiao Tong University, Shanghai, China; Yu, K., MoE Key Lab of Artificial Intelligence SpeechLab, Department of Computer Science and Engineering AI Institute, Shanghai Jiao Tong University, Shanghai, China","Despite tremendous progress in speaker verification recently, replay spoofing attacks are still a major threat to these systems. Focusing on dataset-specific scenarios, anti-spoofing systems have achieved promising in-domain performance at the cost of poor generalization towards unseen out-of-domain datasets. This is treated as a domain mismatch problem with a domain adversarial training (DAT) framework, which has previously been applied to enhance generalization. However, since only one domain discriminator is adopted, DAT suffers from the false alignment of cross-domain spoofed and genuine pairs, thus failing to acquire a strong spoofing-discriminative capability. In this work, we propose the dual-adversarial domain adaptation (DADA) framework to enable fine-grained alignment of spoofed and genuine data separately by using two domain discriminators, which effectively alleviates the above problem and further improves spoofing detection performance. Experiments on the ASVspoof 2017 V.2 dataset and the physical access portion of BTAS 2016 dataset demonstrate that the proposed DADA framework significantly outperforms the baseline model and DAT framework in cross-domain evaluation scenarios. It is shown that the newly proposed DADA architecture is more robust and effective for generalized replay attack detection. Copyright © 2020 ISCA",Domain invariant; Dual-adversarial domain adaptation; Replay spoofing attack detection; Speaker verification,Speech communication; Speech recognition; Anti-spoofing; Baseline models; Cross-domain evaluations; Detection performance; Domain adaptation; Mismatch problems; Speaker verification; Spoofing attacks; Alignment,,,,,"Wu, Z., Evans, N., Kinnunen, T., Yamagishi, J., Alegre, F., Li, H., Spoofing and countermeasures for speaker verification: A survey (2015) speech communication, 66, pp. 130-153; Qian, Y., Chen, N., Dinkel, H., Wu, Z., Deep feature engineering for noise robust spoofing detection (2017) IEEE/ACM Transactions on Audio, Speech, and Language Processing, 25 (10), pp. 1942-1955; Alegre, F., Janicki, A., Evans, N., Re-assessing the threat of replay spoofing attacks against automatic speaker verification (2014) 2014 International Conference of the Biometrics Special Interest Group (BIOSIG), pp. 1-6. , IEEE; Yoon, S., Yu, H., Multiple points input for convolutional neural networks in replay attack detection (2020) ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 6444-6448; Qian, Y., Chen, N., Yu, K., Deep features for automatic spoofing detection (2016) Speech Communication, 85, pp. 43-52; Korshunov, P., Marcel, S., Cross-database evaluation of audio-based spoofing detection systems (2016) Interspeech, , CONF; Paul, D., Sahidullah, M., Saha, G., Generalization of spoofing countermeasures: A case study with asvspoof 2015 and btas 2016 corpora (2017) 2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 2047-2051. , IEEE; Dinkel, H., Qian, Y., Yu, K., Investigating raw wave deep neural networks for end-to-end speaker spoofing detection (2018) IEEE/ACM Transactions on Audio, Speech, and Language Processing, 26 (11), pp. 2002-2014. , Nov; Das, R. K., Yang, J., Li, H., Assessing the scope of generalized countermeasures for anti-spoofing (2020) ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 6589-6593; Wang, H., Dinkel, H., Wang, S., Qian, Y., Yu, K., Cross-domain replay spoofing attack detection using domain adversarial training (2019) Proc. Interspeech 2019, pp. 2938-2942; Pei, Z., Cao, Z., Long, M., Wang, J., Multi-adversarial domain adaptation (2018) Thirty-Second AAAI Conference on Artificial Intelligence; Wang, S., Yang, Y., Wang, T., Qian, Y., Yu, K., Knowledge distillation for small foot-print deep speaker embedding (2019) ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 6021-6025. , IEEE; Yang, Y., Wang, H., Dinkel, H., Chen, Z., Wang, S., Qian, Y., Yu, K., The sjtu robust anti-spoofing system for the asvspoof 2019 challenge (2019) Proc. Interspeech 2019, pp. 1038-1042; Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette, F., Marchand, M., Lempitsky, V., Domain-adversarial training of neural networks (2016) The Journal of Machine Learning Research, 17 (1), pp. 2096-2030; Lavrentyeva, G., Novoselov, S., Volkova, M., Matveev, Y., De Marsico, M., Phonespoof: A new dataset for spoofing attack detection in telephone channel (2019) ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 2572-2576. , IEEE; Delgado, H., Todisco, M., Sahidullah, M., Evans, N., Kinnunen, T., Lee, K., Yamagishi, J., Asvspoof 2017 version 2.0: meta-data analysis and baseline enhancements (2018) Odyssey 2018 The Speaker and Language Recognition Workshop; Korshunov, P., Marcel, S., Muckenhirn, H., Gonçalves, A. R., Mello, A. S., Violato, R. V., Simões, F. O., Stuchi, J. A., Overview of btas 2016 speaker antispoofing competition (2016) 2016 IEEE 8th international conference on biometrics theory, applications and systems (BTAS), pp. 1-6. , IEEE; Kinnunen, T., Sahidullah, M., Falcone, M., Costantini, L., Hautamäki, R. G., Thomsen, D., Sarkar, A., Lee, K. A., Reddots replayed: A new replay spoofing attack corpus for text-dependent speaker verification research (2017) 2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 5395-5399; Ergünay, S. K., Khoury, E., Lazaridis, A., Marcel, S., On the vulnerability of speaker verification to realistic voice spoofing (2015) 2015 IEEE 7th International Conference on Biometrics Theory, Applications and Systems (BTAS), pp. 1-6. , IEEE; Glorot, X., Bengio, Y., Understanding the difficulty of training deep feedforward neural networks (2010) Proceedings of the thirteenth international conference on artificial intelligence and statistics, pp. 249-256; Lavrentyeva, G., Novoselov, S., Malykh, E., Kozlov, A., Kudashev, O., Shchemelinin, V., Audio replay attack detection with deep learning frameworks (2017) Interspeech, pp. 82-86; Lavrentyeva, G., Novoselov, S., Tseren, A., Volkova, M., Gorlanov, A., Kozlov, A., (2019) Stc antispoofing systems for the asvspoof2019 challenge, , arXiv preprint arXiv:1904.05576; Cheng, X., Xu, M., Zheng, T. F., Replay detection using cqt-based modified group delay feature and resnewt network in asvspoof 2019 (2019) 2019 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC), pp. 540-545. , IEEE; Lai, C.-I., Chen, N., Villalba, J., Dehak, N., (2019) Assert: Anti-spoofing with squeeze-excitation and residual networks, , arXiv preprint arXiv:1904.01120; Cai, W., Wu, H., Cai, D., Li, M., (2019) The dku replay detection system for the asvspoof 2019 challenge: On data augmentation, feature representation, classification, and fusion, , arXiv preprint arXiv:1907.02663; Maaten, L. v. d., Hinton, G., Visualizing data using t-sne (2008) Journal of machine learning research, 9 (Nov), pp. 2579-2605","Qian, Y.; MoE Key Lab of Artificial Intelligence SpeechLab, China; 电子邮件: yanminqian@sjtu.edu.cn
Yu, K.; MoE Key Lab of Artificial Intelligence SpeechLab, China; 电子邮件: kai.yu@sjtu.edu.cn",,Alibaba Group;Amazon Alexa;Apple;et al.;Intel;Magic Data,International Speech Communication Association,"21st Annual Conference of the International Speech Communication Association, INTERSPEECH 2020",25 October 2020 through 29 October 2020,,165507,2308457X,,,,English,"Proc. Annu. Conf. Int. Speech. Commun. Assoc., INTERSPEECH",Conference Paper,Final,,Scopus,2-s2.0-85098201244
"Liu W., Li Z.",36166704100;57220041665;,Enhancing Adversarial Examples with Flip-Invariance and Brightness-Invariance,2020,Communications in Computer and Information Science,1268 CCIS,,,469,481,,1,10.1007/978-981-15-9129-7_32,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096529760&doi=10.1007%2f978-981-15-9129-7_32&partnerID=40&md5=f9c825b9bc1b353281618ed9cc265d35,"College of Computer Science and Engineering, Chongqing University of Technology, Chongqing, 400054, China","Liu, W., College of Computer Science and Engineering, Chongqing University of Technology, Chongqing, 400054, China; Li, Z., College of Computer Science and Engineering, Chongqing University of Technology, Chongqing, 400054, China","Despite of achieving remarkable success in computer vision tasks, convolutional neural networks still face the threat of adversarial examples, crafted by adding small human-invisible perturbations on clean inputs. Usually, most of existing black-box adversarial attacks show extremely low transferability while encountering powerful defense models. In this paper, based on the observed invariant property of convolutional neural networks (i.e., the models could maintain accuracy to transformed images), we propose two new methods to improve the transferability which are called as the flip-invariant attack method (FIM) and the brightness-invariant attack method (BIM), respectively. Both the novel approaches derive multiple different logit outputs by inputting the transformed copies of the original image into the white-box model. Simultaneously, the ensemble of these outputs is attacked to avoid overfitting the white-box model and generating more transferable adversarial examples. Moreover, the newly-proposed FIM and BIM methods can be naturally combined with other gradient-based methods. Extensive experiments on the ImageNet dataset prove that our methods achieve higher attack success rate and higher transferability than previous gradient-based attack methods. © 2020, Springer Nature Singapore Pte Ltd.",Adversarial attacks; Adversarial examples; Convolutional neural networks; Cybersecurity; Transferability,Convolution; Convolutional neural networks; Luminance; Attack methods; Black boxes; Gradient based; Gradient-based method; Invariant properties; Original images; Overfitting; White-box models; Image enhancement,,,,,"Szegedy, C., Intriguing properties of neural networks (2014) Proceedings of 2Nd International Conference on Learning Representations (ICLR 2014); Girshick, R., Fast R-CNN (2015) Proceedings of 2015 IEEE International Conference on Computer Vision (ICCV), pp. 1440-1448; He, K., Zhang, X., Ren, S., Sun, J., Identity mappings in deep residual networks (2016) ECCV 2016. LNCS, 9908, pp. 630-645. , https://doi.org/10.1007/978-3-319-46493-038, Leibe, B., Matas, J., Sebe, N., Welling, M. (eds.) , Springer, Cham; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2017) Commun. ACM, 60 (6), pp. 84-90; Long, J., Shelhamer, E., Darrell, T., Fully convolutional networks for semantic segmentation (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3431-3440; Ren, S., He, K., Girshick, R., Sun, J., Faster R-CNN: Towards real-time object detection with region proposal networks (2017) IEEE Trans. Pattern Anal. Mach. Intell., 39 (6), pp. 1137-1149; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) Proceedings of 3Rd International Conference on Learning Representations, , ICLR 2015; Arnab, A., Miksik, O., Torr, P.H., On the robustness of semantic segmentation models to adversarial attacks (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 888-897; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) Proceedings of 3Rd International Conference on Learning Representations (ICLR 2015); Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) Proceedings of 5Th International Conference on Learning Representations (ICLR 2017); Moosavi-Dezfooli, S.M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1765-1773; Liu, W., Zhong, S., Web malware spread modelling and optimal control strategies (2017) Sci. Rep, 7; Liu, W., Zhong, S., Modeling and analyzing the dynamic spreading of epidemic malware by a network eigenvalue method (2018) Appl. Math. Model., 63, pp. 491-507; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2017) Proceedings of 5Th International Conference on Learning Representations (ICLR 2017); Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Proceedings of the IEEE Symposium on Security and Privacy, pp. 39-57; Dong, Y., Boosting adversarial attacks with momentum (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 9185-9193; Xie, C., Improving transferability of adversarial examples with input diversity (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2730-2739; Dong, Y., Pang, T., Su, H., Zhu, J., Evading defenses to transferable adversarial examples by translation-invariant attacks (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4312-4321; Russakovsky, O., Imagenet large scale visual recognition challenge (2015) Int. J. Comput. Vision, 115 (3), pp. 211-252; Tramer, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2018) Proceedings of 6Th International Conference on Learning Representations, , ICLR 2018; Guo, C., Rana, M., Cisse, M., van Der Maaten, L., Countering adversarial images using input transformations (2018) Proceedings of 6Th International Conference on Learning Representations, , ICLR 2018; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., Mitigating adversarial effects through randomization (2018) Proceedings of 6Th International Conference on Learning Representations (ICLR 2018); Liu, Z., Feature distillation: DNN-oriented jpeg compression against adversarial examples (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 860-868; Liao, F., Liang, M., Dong, Y., Pang, T., Hu, X., Zhu, J., Defense against adversarial attacks using high-level representation guided denoiser (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1778-1787; Jia, X., Wei, X., Cao, X., Foroosh, H., Comdefend: An efficient image compression model to defend adversarial examples (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 6084-6092; Cohen, J.M., Rosenfeld, E., Kolter, J.Z., Certified adversarial robustness via randomized smoothing (2019) Proceedings of 7Th International Conference on Learning Representations (ICLR 2019); Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) Proceedings of 6Th International Conference on Learning Representations (ICLR 2018); Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A., Inception-v4, inception-ResNet and the impact of residual connections on learning (2017) Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence, pp. 4278-4284","Liu, W.; College of Computer Science and Engineering, China; 电子邮件: wpliu@cqut.edu.cn",Yu S.Mueller P.Qian J.,,Springer Science and Business Media Deutschland GmbH,"1st International Conference on Security and Privacy in Digital Economy, SPDE 2020",30 October 2020 through 1 November 2020,,250659,18650929,9.79E+12,,,English,Commun. Comput. Info. Sci.,Conference Paper,Final,,Scopus,2-s2.0-85096529760
"Naseer M., Khan S., Hayat M., Khan F.S., Porikli F.",57204565968;56415451600;55613268900;36100204000;6603528219;,A Self-supervised Approach for Adversarial Robustness,2020,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,,,9156294,259,268,,15,10.1109/CVPR42600.2020.00034,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094862396&doi=10.1109%2fCVPR42600.2020.00034&partnerID=40&md5=527f0f2e0944a399add006d185805920,"Australian National University, Australia; Inception Institute of Artificial Intelligence, United Arab Emirates; Data61-CSIRO, Australia; Cvl, Link¨oping University, Sweden","Naseer, M., Australian National University, Australia, Inception Institute of Artificial Intelligence, United Arab Emirates, Data61-CSIRO, Australia; Khan, S., Inception Institute of Artificial Intelligence, United Arab Emirates; Hayat, M., Inception Institute of Artificial Intelligence, United Arab Emirates; Khan, F.S., Inception Institute of Artificial Intelligence, United Arab Emirates, Cvl, Link¨oping University, Sweden; Porikli, F., Australian National University, Australia","Adversarial examples can cause catastrophic mistakes in Deep Neural Network (DNNs) based vision systems e.g., for classification, segmentation and object detection. The vulnerability of DNNs against such attacks can prove a major roadblock towards their real-world deployment. Transferability of adversarial examples demand generalizable defenses that can provide cross-task protection. Adversarial training that enhances robustness by modifying target model's parameters lacks such generalizability. On the other hand, different input processing based defenses fall short in the face of continuously evolving attacks. In this paper, we take the first step to combine the benefits of both approaches and propose a self-supervised adversarial training mechanism in the input space. By design, our defense is a generalizable approach and provides significant robustness against the\textbf{unseen} adversarial attacks (\eg by reducing the success rate of translation-invariant\textbf{ensemble} attack from 82.6\% to 31.9\% in comparison to previous state-of-the-art). It can be deployed as a plug-and-play solution to protect a variety of vision systems, as we demonstrate for the case of classification, segmentation and detection. © 2020 IEEE.",,Deep neural networks; Input space; Plug-and-play solutions; Real world deployment; State of the art; Target model; Translation invariants; Vision systems; Object detection,,,,,"Arjovsky, M., Chintala, S., Bottou, L., (2017) Wasserstein Gan, , arXiv preprint, 3; Athalye, A., Carlini, N., Wagner, D.A., Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples (2018) International Conference on Machine Learning (ICML), , 2,7; Athalye, A., Engstrom, L., Ilyas, A., Kwok, K., Synthesizing robust adversarial examples (2017) International Conference on Machine Learning (ICML), , 2; Badrinarayanan, V., Kendall, A., Cipolla, R., Segnet: A deep convolutional encoder-decoder architecture for image segmentation (2017) Ieee Transactions on Pattern Analysis and Machine Intelligence, 39, pp. 2481-2495. , 7; Brostow, G.J., Fauqueur, J., Cipolla, R., Semantic object classes in video: A high-definition ground truth database (2009) Pattern Recognition Letters, 30 (2), pp. 88-97. , 7,8; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 Ieee Symposium on Security and Privacy (SP), pp. 39-57. , IEEE, 3, 7; NeurIPS Challenge, , https://www.kaggle.com/c/nips-2017-defense-against-adversarial-attack/data, Kaggle 2017, 4; Cohen, J.M., Rosenfeld, E., Kolter, J.Z., (2019) Certified Adversarial Robustness Via Randomized Smoothing, , arXiv preprint, 6; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2018) The Ieee Conference on Computer Vision and Pattern Recognition (CVPR), , June, 2, 3, 4, 7, 8; Dong, Y., Pang, T., Su, H., Zhu, J., Evading defenses to transferable adversarial examples by translation-invariant attacks (2019) Proceedings of the Ieee Computer Society Conference on Computer Vision and Pattern Recognition, , 2, 5, 6, 7,8; Engstrom, L., Ilyas, A., Santurkar, S., Tsipras, D., Tran, B., Madry, A., (2019) Adversarial Robustness As a Prior for Learned Representations, , 7; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations (ICRL), , 2, 3, 7,8; Goodfellow, I.J., Shlens, J., Szegedy, C., Adversarial examples in the physical world (2017) International Conference on Learning Representations (ICRL), , 2, 3, 4, 7, 8; Guo, C., Rana, M., Cissé, M., Maaten Der, L.Van, Countering adversarial images using input transformations (2017) International Conference on Learning Representations (ICRL), , 1,2; Guo, C., Rana, M., Cisse, M., Maaten Der, L.Van, Countering adversarial images using input transformations (2018) International Conference on Learning Representations, , 6; He, K., Gkioxari, G., Dollár, P., Girshick, R.B., Mask r-cnn (2017) 2017 Ieee International Conference on Computer Vision (ICCV), pp. 2980-2988. , 6, 7, 8; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the Ieee Conference on Computer Vision and Pattern Recognition, pp. 770-778. , 1; He, K., Zhang, X., Ren, S., Sun, J., Identity mappings in deep residual networks (2016) European Conference on Computer Vision, pp. 630-645. , Springer, 5, 7; Iandola, F.N., Moskewicz, M.W., Ashraf, K., Han, S., Dally, W.J., Keutzer, K., (2017) Squeezenet: Alexnet-level Accuracy with 50x Fewer Parameters and ¡1mb Model Size, , ArXiv, abs/1602.07360, 5; Jolicoeur-Martineau, A., (2018) The Relativistic Discriminator: A Key Element Missing from Standard Gan, , arXiv preprint, 4; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Commun. Acm, 60, pp. 84-90. , 5; Kupyn, O., Budzan, V., Mykhailych, M., Mishkin, D., Matas, J., Deblurgan: Blind motion deblurring using conditional adversarial networks (2018) The Ieee Conference on Computer Vision and Pattern Recognition (CVPR), , June, 5; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Machine Learning at Scale, , arXiv preprint, 1,5; Ledig, C., Theis, L., Huszár, F., Caballero, J., Cunningham, A., Acosta, A., Aitken, A., Wang, Z., Photorealistic single image super-resolution using a generative adversarial network (2017) Proceedings of the Ieee Conference on Computer Vision and Pattern Recognition, pp. 4681-4690. , 5, 7; Liao, F., Liang, M., Dong, Y., Pang, T., Hu, X., Zhu, J., Defense against adversarial attacks using high-level representation guided denoiser (2018) The Ieee Conference on Computer Vision and Pattern Recognition (CVPR), , June, 6; Liao, F., Liang, M., Dong, Y., Pang, T., Zhu, J., Hu, X., Defense against adversarial attacks using high-level representation guided denoiser (2017) 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 1778-1787. , 2; Lin, T.-Y., Goyal, P., Girshick, R., He, K., Dollár, P., Focal loss for dense object detection (2018) Ieee Transactions on Pattern Analysis and Machine Intelligence, , 7,8; Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Dollár, P., Lawrence Zitnick, C., Microsoft coco: Common objects in context (2014) European Conference on Computer Vision, pp. 740-755. , Springer, 8; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learn-ing models resistant to adversarial attacks (2018) International Conference on Learning Representations, , 1; Mopuri, K.R., Garg, U., Babu, R.V., Fast feature fool: A data independent approach to universal adversarial perturbations (2017) Proceedings of the British Machine Vision Conference (BMVC), , 8; Mustafa, A., Khan, S.H., Hayat, M., Shen, J.-B., Shao, L., (2019) Image Super-Resolution As A Defense against Adversarial Attacks, , arXiv preprint, 2,6; Naseer, M., Khan, S.H., Khan, H., Shahbaz Khan, F., Porikli, F., Cross-domain trans-ferability of adversarial perturbations (2019) Advances in Neural Information Processing Systems, , 2, 4, 5, 6, 8; Ronneberger, O., Fischer, P., Brox, T., U-net: Convolutional networks for biomedical image segmentation (2015) International Conference on Medical Image Computing and Computer-assisted Intervention, pp. 234-241. , Springer, 7; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Fei-Fei, L., ImageNet Large Scale Visual Recognition Challenge (2015) International Journal of Computer Vision (IJCV), 115 (3), pp. 211-252. , 1, 2,5; Shafahi, A., Najibi, M., Ghiasi, A., Xu, Z., Dickerson, J., Studer, C., Davis, L.S., Goldstein, T., (2019) Adversarial Training for Free!, , arXiv preprint, 1; Shen, S., Jin, G., Gao, K., Zhang, Y., (2017) Ape-Gan: Adversarial Perturbation Elimination with Gan, , arXiv preprint, 2, 6; Simonyan, K., Zisserman, A., (2014) Very Deep Convo-Lutional Networks for Large-Scale Image Recognition, , 5; Su, D., Zhang, H., Chen, H., Yi, J., Chen, P.-Y., Gao, Y., Is robustness the cost of accuracy?-a comprehensive study on the robustness of 18 deep image classification models (2018) Computer Vision-ECCV 2018, pp. 644-661. , In Vittorio Ferrari, Martial Hebert, Cristian Sminchisescu, and Yair Weiss, editors, Cham, Springer International Publishing. 3; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., Inception-v4, inception-resnet and the impact of residual connections on learning (2017) Aaai, 4, p. 12. , 5, 7; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the Ieee Conference on Computer Vision and Pattern Recognition, pp. 2818-2826. , 5; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations (ICRL), , 2; Thomas, A., Elibol, O., (2017) Defense against Adversarial Attacks-3Rd Place, , https://github.com/anlthms/nips-2017/blob/master/poster/defense.pdf, 2,6; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2018) International Conference on Learning Representations (ICRL), , 2, 5, 6, 7, 8; Wang, X., Chan, K.C.K., Yu, K., Dong, C., Loy, C.C., Edvr: Video restoration with enhanced deformable convolutional networks (2019) The Ieee Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, , June, 5; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., (2017) Mitigating Adversarial Effects through Randomization, , arXiv preprint, 1,6; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., Mitigating adversarial effects through randomization (2018) International Conference on Learning Representations, , 2; Xie, C., Zhang, Z., Wang, J., Zhou, Y., Ren, Z., Yuille, A., (2018) Improving Transferability of Adversarial Examples with Input Diversity, , arXiv preprint, 2, 3, 5, 7, 8; Xu, B., Wang, N., Chen, T., Li, M., (2015) Empirical Evaluation of Rectified Activations in Convolutional Network, , arXiv preprint, 5; Zantedeschi, V., Nicolae, M.-I., Rawat, A., (2017) Efficient Defenses against Adversarial Attacks, , ArXiv, abs/1707.06728, 6; Zhang, H., Wang, J., (2019) Defense against Adversarial Attacks Using Feature Scattering-Based Adversarial Training, , arXiv preprint, 1; Zhang, R., Isola, P., Efros, A.A., Shecht-Man, E., Wang, O., The unreasonable effectiveness of deep features as a perceptual metric (2018) 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 586-595. , 5; Zhou, W., Hou, X., Chen, Y., Tang, M., Huang, X.-A., Gan, X., Yang, Y., Transferable adversarial perturbations (2018) The European Conference on Computer Vision (ECCV), 3 (7), p. 8. , September",,,,IEEE Computer Society,"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2020",14 June 2020 through 19 June 2020,,162261,10636919,,PIVRE,,English,Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85094862396
"Yang J., Xu R., Li R., Qi X., Shen X., Li G., Lin L.",57215779658;57220778186;57214784313;57189658166;56119201200;56163693300;15061363400;,An adversarial perturbation oriented domain adaptation approach for semantic segmentation,2020,AAAI 2020 - 34th AAAI Conference on Artificial Intelligence,,,,12613,12620,,9,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093465731&partnerID=40&md5=5cc667310e85fce95e9f747ff130a0ba,"School of Data and Computer Science, Sun Yat-sen University, China; Tencent YouTu Lab; University of Oxford; DarkMatter AI Research","Yang, J., School of Data and Computer Science, Sun Yat-sen University, China, Tencent YouTu Lab; Xu, R., School of Data and Computer Science, Sun Yat-sen University, China; Li, R., Tencent YouTu Lab; Qi, X., University of Oxford; Shen, X., Tencent YouTu Lab; Li, G., School of Data and Computer Science, Sun Yat-sen University, China; Lin, L., School of Data and Computer Science, Sun Yat-sen University, China, DarkMatter AI Research","We focus on Unsupervised Domain Adaptation (UDA) for the task of semantic segmentation. Recently, adversarial alignment has been widely adopted to match the marginal distribution of feature representations across two domains globally. However, this strategy fails in adapting the representations of the tail classes or small objects for semantic segmentation since the alignment objective is dominated by head categories or large objects. In contrast to adversarial alignment, we propose to explicitly train a domain-invariant classifier by generating and defensing against pointwise feature space adversarial perturbations. Specifically, we firstly perturb the intermediate feature maps with several attack objectives (i.e., discriminator and classifier) on each individual position for both domains, and then the classifier is trained to be invariant to the perturbations. By perturbing each position individually, our model treats each location evenly regardless of the category or object size and thus circumvents the aforementioned issue. Moreover, the domain gap in feature space is reduced by extrapolating source and target perturbed features towards each other with attack on the domain discriminator. Our approach achieves the state-of-the-art performance on two challenging domain adaptation tasks for semantic segmentation: GTA5 → Cityscapes and SYNTHIA → Cityscapes. Copyright 2020, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,Alignment; Classifiers; Semantics; Domain adaptation; Feature representation; Feature space; Marginal distribution; Oriented domains; Semantic segmentation; Small objects; State-of-the-art performance; Artificial intelligence,,,,,"Berman, M., Rannen Triki, A., Blaschko, M. B., The lovász-softmax loss: A tractable surrogate for the optimization of the intersection-over-union measure in neural networks (2018) CVPR, pp. 4413-4421; Bottou, L., Large-scale machine learning with stochastic gradient descent (2010) Proceedings of COMPSTAT’2010, pp. 177-186; Chen, L.-C., Papandreou, G., Kokkinos, I., Murphy, K., Yuille, A. L., Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs (2017) IEEE T-PAMI, 40 (4), pp. 834-848; Chen, Y.-H., Chen, W.-Y., Chen, Y.-T., Tsai, B.-C., Frank Wang, Y.-C., Sun, M., No more discrimination: Cross city adaptation of road scene segmenters (2017) ICCV, pp. 1992-2001; Chen, Y., Li, W., Van Gool, L., Road: Reality oriented adaptation for semantic segmentation of urban scenes (2018) CVPR, pp. 7892-7901; Cordts, M., Omran, M., Ramos, S., Rehfeld, T., Enzweiler, M., Benenson, R., Franke, U., Schiele, B., The cityscapes dataset for semantic urban scene understanding (2016) CVPR; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2018) CVPR, pp. 9185-9193; Ganin, Y., Lempitsky, V., Unsupervised domain adaptation by backpropagation (2015) ICML, pp. 1180-1189; Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette, F., Marchand, M., Lempitsky, V., Domain-adversarial training of neural networks (2016) JMLR, 17 (1), pp. 2096-2030; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) NeuralIPS, pp. 2672-2680; Goodfellow, I. J., Shlens, J., Szegedy, C., (2014) Explaining and harnessing adversarial examples, , arXiv preprint arXiv:1412.6572; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) CVPR, pp. 770-778; Hoffman, J., Wang, D., Yu, F., Darrell, T., (2016) Fcns in the wild: Pixel-level adversarial and constraint-based adaptation, , arXiv preprint arXiv:1612.02649; Hoffman, J., Tzeng, E., Park, T., Zhu, J.-Y., Isola, P., Saenko, K., Efros, A., Darrell, T., Cycada: Cycle-consistent adversarial domain adaptation (2018) ICML; Kingma, D. P., Ba, J., (2014) Adam: A method for stochastic optimization, , arXiv preprint arXiv:1412.6980; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial examples in the physical world, , arXiv preprint arXiv:1607.02533; Liu, H., Long, M., Wang, J., Jordan, M., Transferable adversarial training: A general approach to adapting deep classifiers (2019) ICML, pp. 4013-4022; Long, M., Cao, Y., Wang, J., Jordan, M., Learning transferable features with deep adaptation networks (2015) ICML, pp. 97-105; Long, M., Zhu, H., Wang, J., Jordan, M. I., Deep transfer learning with joint adaptation networks (2017) ICML, pp. 2208-2217; Long, M., Cao, Y., Cao, Z., Wang, J., Jordan, M. I., Transferable representation learning with deep adaptation networks (2018) IEEE T-PAMI; Long, J., Shelhamer, E., Darrell, T., Fully convolutional networks for semantic segmentation (2015) CVPR, pp. 3431-3440; Luo, Y., Zheng, L., Guan, T., Yu, J., Yang, Y., Taking a closer look at domain shift: Category-level adversaries for semantics consistent domain adaptation (2019) CVPR, pp. 2507-2516; Radford, A., Metz, L., Chintala, S., (2015) Unsupervised representation learning with deep convolutional generative adversarial networks, , arXiv preprint arXiv:1511.06434; Richter, S. R., Vineet, V., Roth, S., Koltun, V., Playing for data: Ground truth from computer games (2016) ECCV, pp. 102-118; Ros, G., Sellart, L., Materzynska, J., Vazquez, D., Lopez, A. M., The synthia dataset: A large collection of synthetic images for semantic segmentation of urban scenes (2016) CVPR, pp. 3234-3243; Saito, K., Ushiku, Y., Harada, T., Asymmetric tri-training for unsupervised domain adaptation (2017) ICML, pp. 2988-2997; Simonyan, K., Zisserman, A., (2014) Very deep convolutional networks for large-scale image recognition, , arXiv preprint arXiv:1409.1556; Springenberg, J. T., (2015) Unsupervised and semi-supervised learning with categorical generative adversarial networks, , arXiv preprint arXiv:1511.06390; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing properties of neural networks, , arXiv preprint arXiv:1312.6199; Tsai, Y.-H., Hung, W.-C., Schulter, S., Sohn, K., Yang, M.-H., Chandraker, M., Learning to adapt structured output space for semantic segmentation (2018) CVPR, pp. 7472-7481; Volpi, R., Namkoong, H., Sener, O., Duchi, J. C., Murino, V., Savarese, S., Generalizing to unseen domains via adversarial data augmentation (2018) NeuralIPS, pp. 5334-5344; Vu, T.-H., Jain, H., Bucher, M., Cord, M., Pérez, P., Advent: Adversarial entropy minimization for domain adaptation in semantic segmentation (2019) CVPR, pp. 2517-2526; Wu, Y., Winston, E., Kaushik, D., Lipton, Z., Domain adaptation with asymmetrically-relaxed distribution alignment (2019) ICML, pp. 6872-6881; Xu, R., Li, G., Yang, J., Lin, L., Larger norm more transferable: An adaptive feature norm approach for unsupervised domain adaptation (2019) ICCV; Zhang, Y., Qiu, Z., Yao, T., Liu, D., Mei, T., Fully convolutional adaptation networks for semantic segmentation (2018) CVPR, pp. 6810-6818; Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J., Pyramid scene parsing network (2017) CVPR, pp. 2881-2890; Zhu, J.-Y., Park, T., Isola, P., Efros, A. A., Unpaired image-to-image translation using cycle-consistent adversarial networks (2017) ICCV, pp. 2223-2232; Zou, Y., Yu, Z., Vijaya Kumar, B., Wang, J., Unsupervised domain adaptation for semantic segmentation via class-balanced self-training (2018) ECCV, pp. 289-305","Li, G.; School of Data and Computer Science, China; 电子邮件: liguanbin@mail.sysu.edu.cn",,Association for the Advancement of Artificial Intelligence,AAAI press,"34th AAAI Conference on Artificial Intelligence, AAAI 2020",7 February 2020 through 12 February 2020,,166426,,9.78E+12,,,English,AAAI - AAAI Conf. Artif. Intell.,Conference Paper,Final,,Scopus,2-s2.0-85093465731
"Sun J., Cao Y., Chen Q.A., Morley Mao Z.",57204729809;57200512662;56379253400;57202743717;,Towards robust LiDAR-based perception in autonomous driving: General black-box adversarial sensor attack and countermeasures,2020,Proceedings of the 29th USENIX Security Symposium,,,,877,894,,23,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091956673&partnerID=40&md5=d2c5942e1a7d98b8faa74b1761e19f25,"University of Michigan, United States; UC Irvine, United States","Sun, J., University of Michigan, United States; Cao, Y., University of Michigan, United States; Chen, Q.A., UC Irvine, United States; Morley Mao, Z., University of Michigan, United States","Perception plays a pivotal role in autonomous driving systems, which utilizes onboard sensors like cameras and LiDARs (Light Detection and Ranging) to assess surroundings. Recent studies have demonstrated that LiDAR-based perception is vulnerable to spoofing attacks, in which adversaries spoof a fake vehicle in front of a victim self-driving car by strategically transmitting laser signals to the victim's LiDAR sensor. However, existing attacks suffer from effectiveness and generality limitations. In this work, we perform the first study to explore the general vulnerability of current LiDAR-based perception architectures and discover that the ignored occlusion patterns in LiDAR point clouds make self-driving cars vulnerable to spoofing attacks. We construct the first black-box spoofing attack based on our identified vulnerability, which universally achieves around 80% mean success rates on all target models. We perform the first defense study, proposing CARLO to mitigate LiDAR spoofing attacks. CARLO detects spoofed data by treating ignored occlusion patterns as invariant physical features, which reduces the mean attack success rate to 5.5%. Meanwhile, we take the first step towards exploring a general architecture for robust LiDAR-based perception, and propose SVF that embeds the neglected physical features into end-to-end learning. SVF further reduces the mean attack success rate to around 2.3%. © 2020 by The USENIX Association. All Rights Reserved.",,Autonomous vehicles; Lithium compounds; Autonomous driving; Defense studies; General architectures; LIDAR (light detection and ranging); Lidar point clouds; On-board sensors; Physical features; Spoofing attacks; Optical radar,,,,,"Baidu debuts robotaxi ride hailing service in China, using self-driving electric taxis, , https://www.marketwatch.com/story/baidudebuts-robotaxi-ride-hailing-service-in-china-using-self-driving-electric-taxis-2019-09-26; UPS joins race for future of delivery services by investing in self-driving trucks, , https://abcnews.go.com/Business/upsjoins-race-future-delivery-services-investing-driving/story?id=65014414; https://www.businessinsider.com/waymo-one-driverless-car-service-launches-in-phoenixarizona-2018-12, Waymo has launched its commercial self-driving service in Phoenix and it's called 'Waymo One; (2017) GM Advances Self-Driving Vehicle Deployment With Acquisition of LIDAR Developer, , https://media.gm.com/media/us/en/gm/news.detail.html/content/Pages/news/us/en/2017/oct/1009-lidar1.html; (2019) Introducing Laser Bear Honeycomb by Waymo, , https://waymo.com/lidar/; (2020), https://www.autoware.ai/, Autoware.AI; Apollo, Baidu, (2020), http://apollo.auto; Devil's whisper: A general approach for physical adversarial attacks against commercial black-box speech recognition devices 29th USENIX Security Symposium (USENIX Security 20), , Boston, MA, Aug. 2020. USENIX Association; (2020) KITTI Vision Benchmark: 3D Object Detection, , http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=3d; Plug-n-pwned: Comprehensive vulnerability analysis of obd-ii dongles as a new over-the-air attack surface in automotive iot 29th USENIX Security Symposium (USENIX Security 20), , Boston, MA, Aug. 2020. USENIX Association; (2020), https://www.tek.com/signal-generator/afg2021-software-0, Replay attack; Stealthy tracking of autonomous vehicles with cache side channels 29th USENIX Security Symposium (USENIX Security 20), , Boston, MA, Aug. 2020. USENIX Association; Athalye, A., Carlini, N., Wagner, D., (2018) Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples, , arXiv preprint arXiv:1802.00420; Avatefipour, O., Al-Sumaiti, A. S., El-Sherbeeny, A. M., Awwad, E. M., Elmeligy, M. A., Mohamed, M. A., Malik, H., An intelligent secured framework for cyberattack detection in electric vehicles' can bus using machine learning (2019) IEEE Access, 7, pp. 127580-127592; Biasutti, P., Lepetit, V., Aujol, J.-F., Brédif, M., Bugeau, A., Lu-net: An efficient network for 3d lidar point cloud semantic segmentation based on end-to-end-learned 3d features and u-net (2019) Proceedings of the IEEE International Conference on Computer Vision Workshops, pp. 0-0; Bresenham, J., A linear algorithm for incremental digital display of circular arcs (1977) Communications of the ACM, 20 (2), pp. 100-106; Cao, Y., Xiao, C., Cyr, B., Zhou, Y., Park, W., Rampazzi, S., Chen, Q. A., Mao, Z. M., Adversarial sensor attack on lidar-based perception in autonomous driving (2019) Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security, pp. 2267-2281. , ACM; Cao, Y., Xiao, C., Yang, D., Fang, J., Yang, R., Liu, M., Li, B., (2019) Adversarial objects against lidar-based autonomous driving systems, , arXiv preprint arXiv:1907.05418; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 3-14; Chaman, A., Wang, J., Sun, J., Hassanieh, H., Roy Choudhury, R., Ghostbuster: Detecting the presence of hidden eavesdroppers (2018) Proceedings of the 24th Annual International Conference on Mobile Computing and Networking, pp. 337-351; Checkoway, S., McCoy, D., Kantor, B., Anderson, D., Shacham, H., Savage, S., Koscher, K., Kohno, T., Comprehensive Experimental Analyses of Automotive Attack Surfaces (2011) Proceedings of the 20th USENIX Conference on Security, SEC'11; Chen, Q. A., Yin, Y., Feng, Y., Mao, Z. M., Liu, H. X. L., Exposing Congestion Attack on Emerging Connected Vehicle based Traffic Signal Control (2018) Proceedings of the 25th Annual Network and Distributed System Security Symposium, NDSS'18; Chen, X., Kundu, K., Zhu, Y., Berneshawi, A. G., Ma, H., Fidler, S., Urtasun, R., 3d object proposals for accurate object class detection (2015) Advances in Neural Information Processing Systems, pp. 424-432; Chen, X., Ma, H., Wan, J., Li, B., Xia, T., Multi-view 3d object detection network for autonomous driving (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1907-1915; Chen, Y., Liu, S., Shen, X., Jia, J., Fast point r-cnn (2019) Proceedings of the IEEE International Conference on Computer Vision, pp. 9775-9784; Cho, K.-T., Shin, K. G., Error handling of in-vehicle networks makes them vulnerable (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, CCS'16; Everingham, M., Van Gool, L., Williams, C. K. I., Winn, J., Zisserman, A., The pascal visual object classes (voc) challenge (2010) International Journal of Computer Vision, 88 (2), pp. 303-338. , June; Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Xiao, C., Prakash, A., Song, D., Robust physical-world attacks on deep learning visual classification (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1625-1634; Feng, Y., Huang, S., Chen, Q. A., Liu, H. X., Mao, Z. M., Vulnerability of Traffic Control System Under Cyber-Attacks Using Falsified Data (2018) Transportation Research Board 2018 Annual Meeting (TRB); Gaddam, A., Prakash, G., Aissi, S., (2015) Mechanism for secure in-vehicle payment transaction, , Feb. 26 US Patent App. 14/466,405; Geiger, A., Lenz, P., Stiller, C., Urtasun, R., Vision meets robotics: The kitti dataset (2013) International Journal of Robotics Research (IJRR); (2018) VLP-16 User Manual, , L. Inc; Kim, T., Ghosh, J., (2019) On single source robustness in deep fusion models, , arXiv preprint arXiv:1906.04691; Koscher, K., Czeskis, A., Roesner, F., Patel, S., Kohno, T., Checkoway, S., McCoy, D., Savage, S., Experimental Security Analysis of a Modern Automobile (2010) Proceedings of the 2010 IEEE Symposium on Security and Privacy, SP'10; Ku, J., Mozifian, M., Lee, J., Harakeh, A., Waslander, S. L., Joint 3d proposal generation and object detection from view aggregation (2018) 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 1-8. , IEEE; Lang, A. H., Vora, S., Caesar, H., Zhou, L., Yang, J., Beijbom, O., Pointpillars: Fast encoders for object detection from point clouds (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 12697-12705; Lehner, J., Mitterecker, A., Adler, T., Hofmarcher, M., Nessler, B., Hochreiter, S., (2019) Patch refinement-localized 3d object detection, , arXiv preprint arXiv:1910.04093; Li, B., Zhang, T., Xia, T., (2016) Vehicle detection from 3d lidar using fully convolutional network, , arXiv preprint arXiv:1608.07916; Li, Y., Sun, J., Huang, W., Tian, X., Detecting anomaly in large-scale network using mobile crowdsourcing (2019) IEEE INFOCOM 2019-IEEE Conference on Computer Communications, pp. 2179-2187. , IEEE; Liang, M., Yang, B., Wang, S., Urtasun, R., Deep continuous fusion for multi-sensor 3d object detection (2018) Proceedings of the European Conference on Computer Vision (ECCV), pp. 641-656; Liu, D., Yu, R., Su, H., Extending adversarial attacks and defenses to deep 3d point cloud classifiers (2019) 2019 IEEE International Conference on Image Processing (ICIP), pp. 2279-2283. , IEEE; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards deep learning models resistant to adversarial attacks, , arXiv preprint arXiv:1706.06083; Meyer, G. P., Laddha, A., Kee, E., Vallespi-Gonzalez, C., Wellington, C. K., Lasernet: An efficient probabilistic 3d object detector for autonomous driving (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 12677-12686; Nassi, B., Nassi, D., Ben-Netanel, R., Mirsky, Y., Drokin, O., Elovici, Y., (2020) Phantom of the adas: Phantom attacks on driver-assistance systems; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z. B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia conference on computer and communications security, pp. 506-519; Park, Y., Son, Y., Shin, H., Kim, D., Kim, Y., This ain't your dose: Sensor spoofing attack on medical infusion pump (2016) 10th USENIX Workshop on Offensive Technologies (WOOT 16), , Austin, TX, Aug. USENIX Association; Patsakis, C., Dellios, K., Bouroche, M., Towards a distributed secure in-vehicle communication architecture for modern vehicles (2014) Computers & security, 40, pp. 60-74; Petit, J., Stottelaar, B., Feiri, M., Kargl, F., Remote attacks on automated vehicles sensors: Experiments on camera and lidar (2015) Black Hat Europe, 11, p. 2015; Qi, C. R., Su, H., Mo, K., Guibas, L. J., Pointnet: Deep learning on point sets for 3d classification and segmentation (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 652-660; Rao, A., Sangwan, A., Kherani, A. A., Varghese, A., Bellur, B., Shorey, R., Secure v2v communication with certificate revocations (2007) 2007 Mobile Networking for Vehicular Environments, pp. 127-132. , IEEE; Ren, S., He, K., Girshick, R., Sun, J., Faster r-cnn: Towards real-time object detection with region proposal networks (2015) Advances in neural information processing systems, pp. 91-99; Ronneberger, O., Fischer, P., Brox, T., U-net: Convolutional networks for biomedical image segmentation (2015) International Conference on Medical image computing and computer-assisted intervention, pp. 234-241. , Springer; Shi, S., Wang, X., Li, H., Pointrcnn: 3d object proposal generation and detection from point cloud (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-779; Shi, S., Wang, Z., Wang, X., Li, H., (2019) Part-a2 net: 3d part-aware and aggregation neural network for object detection from point cloud, , arXiv preprint arXiv:1907.03670; Shin, H., Kim, D., Kwon, Y., Kim, Y., Illusion and dazzle: Adversarial optical channel exploits against lidars for automotive applications (2017) International Conference on Cryptographic Hardware and Embedded Systems, pp. 445-467. , Springer; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) International Conference on Learning Representations; Tsai, T., Yang, K., Ho, T.-Y., Jin, Y., Robust adversarial objects against deep learning models; Wang, B., An, J., Cao, J., (2019) Voxel-fpn: multi-scale voxel feature aggregation in 3d object detection from point clouds, , arXiv preprint arXiv:1907.05286; Wang, Y., Shi, T., Yun, P., Tai, L., Liu, M., (2018) Pointseg: Real-time semantic segmentation based on 3d lidar point cloud, , arXiv preprint arXiv:1807.06288; Wen, Y., Lin, J., Chen, K., Jia, K., (2019) Geometry-aware generation of adversarial and cooperative point clouds, , arXiv preprint arXiv:1912.11171; Wong, W., Huang, S., Feng, Y., Chen, Q. A., Mao, Z. M., Liu, H. X., Trajectory-Based Hierarchical Defense Model to Detect Cyber-Attacks on Transportation Infrastructure (2019) Transportation Research Board 2019 Annual Meeting (TRB); Woo, S., Jo, H. J., Kim, I. S., Lee, D. H., A practical security architecture for in-vehicle can-fd (2016) IEEE Transactions on Intelligent Transportation Systems, 17 (8), pp. 2248-2261; Wu, B., Wan, A., Yue, X., Keutzer, K., Squeezeseg: Convolutional neural nets with recurrent crf for real-time road-object segmentation from 3d lidar point cloud (2018) 2018 IEEE International Conference on Robotics and Automation (ICRA), pp. 1887-1893. , IEEE; Xiang, C., Qi, C. R., Li, B., Generating 3d adversarial point clouds (2019) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , June; Xiao, C., Yang, D., Li, B., Deng, J., Liu, M., Meshadv: Adversarial meshes for visual recognition (2019) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , June; Xu, W., Evans, D., Qi, Y., (2017) Feature squeezing: Detecting adversarial examples in deep neural networks, , arXiv preprint arXiv:1704.01155; Yan, Y., Mao, Y., Li, B., Second: Sparsely embedded convolutional detection (2018) Sensors, 18 (10), p. 3337; Yang, B., Luo, W., Urtasun, R., Pixor: Real-time 3d object detection from point clouds (2018) Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, pp. 7652-7660; Yang, J., Zhang, Q., Fang, R., Ni, B., Liu, J., Tian, Q., (2019) Adversarial attack and defense on point sets, , arXiv preprint arXiv:1902.10899; Yang, Y., Zhang, G., Katabi, D., Xu, Z., ME-Net: Towards effective adversarial robustness with matrix estimation (2019) Proceedings of the 36th International Conference on Machine Learning (ICML); Yang, Z., Sun, Y., Liu, S., Shen, X., Jia, J., Std: Sparse-to-dense 3d object detector for point cloud (2019) Proceedings of the IEEE International Conference on Computer Vision, pp. 1951-1960; Zhou, Y., Sun, P., Zhang, Y., Anguelov, D., Gao, J., Ouyang, T., Guo, J., Vasudevan, V., (2019) End-to-end multi-view fusion for 3d object detection in lidar point clouds, , arXiv preprint arXiv:1910.06528; Zhou, Y., Tuzel, O., Voxelnet: End-to-end learning for point cloud based 3d object detection (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4490-4499",,,ByteDance;et al.;Facebook;Microsoft;Salesforce;USENIX Association,USENIX Association,29th USENIX Security Symposium,12 August 2020 through 14 August 2020,,162471,,9.78E+12,,,English,Proc. USENIX Secur. Symp.,Conference Paper,Final,,Scopus,2-s2.0-85091956673
"Xu L., Zeng X., Huang Z., Li W., Zhang H.",57210788847;54920639100;57193565509;36067507500;57210801226;,Low-dose chest X-ray image super-resolution using generative adversarial nets with spectral normalization,2020,Biomedical Signal Processing and Control,55,,101600,,,,13,10.1016/j.bspc.2019.101600,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071427447&doi=10.1016%2fj.bspc.2019.101600&partnerID=40&md5=6a484e49fe7b0069e2ce1fa04ce66199,"Chongqing Key Laboratory of Image Cognition, College of Computer Science and Technology, Chongqing University of Posts and Telecommunications, Chongqing, 400065, China; School of Medical Information and Engineering, Southwest Medical University, Luzhou, 646000, China","Xu, L., Chongqing Key Laboratory of Image Cognition, College of Computer Science and Technology, Chongqing University of Posts and Telecommunications, Chongqing, 400065, China; Zeng, X., Chongqing Key Laboratory of Image Cognition, College of Computer Science and Technology, Chongqing University of Posts and Telecommunications, Chongqing, 400065, China; Huang, Z., School of Medical Information and Engineering, Southwest Medical University, Luzhou, 646000, China; Li, W., Chongqing Key Laboratory of Image Cognition, College of Computer Science and Technology, Chongqing University of Posts and Telecommunications, Chongqing, 400065, China; Zhang, H., Chongqing Key Laboratory of Image Cognition, College of Computer Science and Technology, Chongqing University of Posts and Telecommunications, Chongqing, 400065, China","Chest X-ray (CXR) imaging is one of the most widely-used and cost-effective technology for chest screening and diagnosis of Pulmonary diseases. An always concerned improvement about CXR is to reduce X-ray radiation while achieving ultra-high quality imaging with fine structural details since CXR involves ionizing radiation and tolerance of different populations. In this paper, we present a supervised generative adversarial nets approach to accurately recover high-resolution (HR) CXR images from low-resolution (LR) counterparts while keep pathological invariance. Specifically, the auxiliary label information is introduced to constrain the feature generation to attack the potential risk of pathological variance. Then, spectral normalization is designed to control the performance of discriminative network with the guarantee of theoretical demonstration in controlling Lipschitz bound of discriminator. Results from quantitative and qualitative evaluations demonstrate that our method delivers more authentic improvement for CXR super-resolution (SR) compared to recent state-of-the-art methods. The proposed method has outperformed average 13.0%, 12.2% in FSIM and 13.7%, 12.5% in MSIM on two datasets, respectively. Besides, the index of generative performance GAN-train and GAN-test have achieved average increment 9.3% and 10.5% on CXR2 dataset. Subjective evaluation on SR CXR has outperformed average score 0.425 and 0.525 in terms of pathological invariance and acceptability, respectively. © 2019",Auxiliary information; Generative adversarial nets; Pathological invariance; Spectral normalization,Cost effectiveness; Diagnosis; Optical resolving power; Statistical tests; Auxiliary information; Cost-effective technology; Discriminative networks; Feature generation; Generative adversarial nets; Qualitative evaluations; Spectral normalization; Subjective evaluations; X rays; Article; artificial neural network; cost effectiveness analysis; generative adversarial network; human; image processing; image quality; nuclear magnetic resonance imaging; priority journal; radiation dose; thorax radiography,,,,,"Shi, W., Caballero, J., Huszár, F., Totz, J., Aitken, A., Bishop, R., Rueckert, D., Wang, Z., Real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network (2016) IEEE Conference on Computer Vision and Pattern Recognition, pp. 1874-1883; Lai, W., Deep Laplacian pyramid networks for fast and accurate super-resolution (2017) IEEE European Conference on Computer Vision, pp. 5835-5843; Ledig, C., Theis, L., Huszar, F., Caballero, J., Aitken, A., Tejani, A., Totz, J., Shi, W., Photo-realistic single image super-resolution using a generative adversarial network (2017) IEEE Conference on Computer Vision and Pattern Recognition, pp. 105-123; Nasrollahi, K., Moeslund, T., Super-resolution: a comprehensive survey (2014) Mach. Vision Appl., 25 (6), pp. 1423-1468; Yang, C., Ma, C., Yang, M., Single-image super-resolution: a benchmark (2014) IEEE European Conference on Computer Vision, pp. 372-386; Greenspan, H., Super-resolution in medical imaging (2009) Comput. J., 52 (1), pp. 43-63; Fattal, R., Image upsampling via imposed edge statistics (2007) ACM Trans. Graphics, 26 (3), p. 95; Jian, S., Xu, Z., Shum, H., Image super-resolution using gradient profile prior (2008) IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-8; KwangIn, K., Younghee, K., Single-image super-resolution using sparse regression and natural image prior (2010) IEEE Trans. Pattern Anal. Mach. Intell., 32 (6), pp. 1127-1133; Jia, Y., He, Z., Gholipour, A., Warfield, S., Single anisotropic 3-D MR image upsampling via overcomplete dictionary trained from in-plane high resolution slices (2016) IEEE J. Biomed. Health Inform., 20 (6), pp. 1552-1561; Yang, F., Zhu, Y., Luo, J., Robini, M., Liu, J., Croisille, P., A comparative study of different level interpolations for improving spatial resolution in diffusion tensor imaging (2014) IEEE J. Biomed. Health Inform., 18 (4), pp. 1317-1327; Chang, H., Yeung, D.Y., Xiong, Y., Super-resolution through neighbor embedding (2004) IEEE Conference on Computer Vision and Pattern Recognition, pp. 275-282; Li, H., Qi, H., Zaretzki, R., Beta process joint dictionary learning for coupled feature spaces with application to single image super-resolution (2013) IEEE European Conference on Computer Vision, pp. 345-352; Yang, J., Zhe, L., Cohen, S., Fast image super-resolution based on in-place example regression (2013) IEEE Conference on Computer Vision and Pattern Recognition, pp. 1059-1066; He, H., WanChi, S., Single image super-resolution using gaussian process regression (2011) IEEE Conference on Computer Vision and Pattern Recognition, pp. 449-456; Shen, H., Zhang, L., Huang, B., Li, P., A map approach for joint motion estimation, segmentation, and super resolution (2007) IEEE Trans. Image Process., 16 (2), pp. 479-490; Liu, W., Li, S., Multi-morphology image super-resolution via sparse representation (2013) Neurocomputing, 120 (10), pp. 645-654; Yang, J., Wang, Z., Zhe, L., Shu, X., Huang, T., Bilevel sparse coding for coupled feature spaces (2012) IEEE Conference on Computer Vision and Pattern Recognition, pp. 2360-2367; Yang, S., Wang, M., Chen, Y., Sun, Y., Single-image super-resolution reconstruction via learned geometric dictionaries and clustered sparse coding (2012) IEEE Trans. Image Process., 21 (9), pp. 4016-4028; Chao, D., Chen, C., Tang, X., Accelerating the super-resolution convolutional neural network (2016) Proceeding of the European Conference on Computer Vision, pp. 391-407; Chaudhari, A., Fang, Z., Kogan, F., Wood, J., Stevens, K., Gibbons, E., Lee, J., Hargreaves, B., Super-resolution musculoskeletal MRI using deep learning (2018) Magn. Resonance Med., 80 (5), pp. 2139-2154; Park, J., Hwang, D., Kim, K., Kang, S., Kim, Y., Lee, J., Computed tomography super-resolution using deep convolutional neural network (2018) Phys. Med. Biol., pp. 3944-3948; Zhang, K., Tao, D., Gao, X., Li, X., Li, J., Coarse-to-fine learning for single-image super-resolution (2017) IEEE Trans. Neural Netw. Learn. Syst., 28 (5), pp. 1109-1122; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Bing, X., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) International Conference on Neural Information Processing Systems, pp. 2672-2680; Chen, Y., Feng, S., Christodoulou, A.G., Zhou, Z., Li, D., Efficient and Accurate MRI Super-Resolution Using a Generative Adversarial Network and 3D Multi-Level Densely Connected Network (2018); You, C., Li, G., Zhang, Y., Zhang, X., Shan, H., Ju, S., Zhao, Z., Vannier, M.W., CT Super-Resolution GAN Constrained by the Identical, Residual, and Cycle Learning Ensemble (GAN-CIRCLE) (2018); Arjovsky, M., Chintala, S., Bottou, L., Wasserstein GAN (2017) International Conference on Machine Learning, pp. 214-223; Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., Courville, A., Improved training of wasserstein GANs (2017) International Conference on Neural Information Processing Systems, pp. 294-303; Wang, Z., Simoncelli, E., Bovik, A., Multiscale structural similarity for image quality assessment (2003) IEEE Asilomar Conference on Signals, Systems and Computers, pp. 1398-1402; Lin, Z., Lei, Z., Xuanqin, M., David, Z., FSIM: a feature similarity index for image quality assessment (2011) IEEE Trans. Image Process., 20 (8), pp. 2378-2386; Yoshida, Y., Miyato, T., Spectral norm regularization for improving the generalizability of deep learning (2018) International Conference on Neural Information Processing Systems, pp. 1539-1542; Odena, A., Olah, C., Shlens, J., Conditional image synthesis with auxiliary classifier GANs (2016) International Conference on Machine Learning, pp. 2642-2651; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) International Conference on Learning Representations, pp. 1-14; Atarsaikhan, G., Iwana, B.K., Uchida, S., Contained Neural Style Transfer for Decorated Logo Generation (2018); Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., Klambauer, G., Hochreiter, S., GANs trained by a two time-scale update rule converge to a nash equilibrium (2017) International Conference on Neural Information Processing Systems, pp. 2672-2680; Kermany, D., Goldbaum, M., Cai, W., Valentim, C.C., Liang, H., Baxter, S., Mckeown, A., Yan, F., Identifying medical diagnoses and treatable diseases by image-based deep learning (2018) Cell, 172 (5), pp. 1122-1131; Wang, X., Peng, Y., Le, L., Lu, Z., Bagheri, M., Summers, R., Chestx-ray8: hospital-scale chest X-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases (2017) IEEE Conference on Computer Vision and Pattern Recognition, pp. 3462-3471; Diederik, K., Jimmy, B., Adam: a method for stochastic optimization (2015) International Conference on Learning Representations, pp. 165-179; Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., Xi, C., Improved Techniques for Training GANs (2016); Karras, T., Aila, T., Laine, S., Lehtinen, J., Progressive growing of GANs for improved quality, stability, and variation (2017) International Conference on Learning Representations, pp. 1-26; Shmelkov, K., Schmid, C., Alahari, K., How good is my GAN? (2018) IEEE Conference on Computer Vision and Pattern Recognition, pp. 3654-3668; Gao, H., Zhuang, L., Weinberger, K.Q., Densely Connected Convolutional Networks (2017), pp. 2261-2269; Yuan, Y., Siyuan, L., Jiawei, Z., Yongbing, Z., Chao, D., Liang, L., Unsupervised image super-resolution using cycle-in-cycle generative adversarial networks (2018) IEEE Conference on Computer Vision and Pattern Recognition, pp. 814-822; Michaeli, T., Irani, M., Nonparametric blind super-resolution (2013) IEEE International Conference on Computer Vision, pp. 945-952; Zhu, J.Y., Park, T., Isola, P., Efros, A.A., Unpaired image-to-image translation using cycle-consistent adversarial networks (2017) IEEE International Conference on Computer Vision, pp. 2242-2251","Zeng, X.; Chongqing Key Laboratory of Image Cognition, China; 电子邮件: zengxh@cqupt.edu.cn",,,Elsevier Ltd,,,,,17468094,,,,English,Biomed. Signal Process. Control,Article,Final,,Scopus,2-s2.0-85071427447
"Jin X., Haddad W.M., Jiang Z.-P., Kanellopoulos A., Vamvoudakis K.G.",55541046800;35461378700;7404279463;57204669545;24726183300;,An adaptive learning and control architecture for mitigating sensor and actuator attacks in connected autonomous vehicle platoons,2019,International Journal of Adaptive Control and Signal Processing,33,12,,1788,1802,,6,10.1002/acs.3032,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068058467&doi=10.1002%2facs.3032&partnerID=40&md5=defc1938a79321b450a2597ead785df5,"School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA, Georgia; Control and Networks Lab, Department of Electrical and Computer Engineering, Tandon School of Engineering, New York University, Brooklyn, NY, United States","Jin, X., School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA, Georgia; Haddad, W.M., School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA, Georgia; Jiang, Z.-P., Control and Networks Lab, Department of Electrical and Computer Engineering, Tandon School of Engineering, New York University, Brooklyn, NY, United States; Kanellopoulos, A., School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA, Georgia; Vamvoudakis, K.G., School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA, Georgia","In this paper, we develop an adaptive control algorithm for addressing security for a class of networked vehicles that comprise a formation of (Formula presented.) human-driven vehicles sharing kinematic data and an autonomous vehicle in the aft of the vehicle formation receiving data from the preceding vehicles through wireless vehicle-to-vehicle communication devices. Specifically, we develop an adaptive controller for mitigating time-invariant state-dependent adversarial sensor and actuator attacks while guaranteeing uniform ultimate boundedness of the closed-loop networked system. Furthermore, an adaptive learning framework is presented for identifying the state space model parameters based on input-output data. This learning technique utilizes previously stored data as well as current data to identify the system parameters using a relaxed persistence of excitation condition. The effectiveness of the proposed approach is demonstrated by an illustrative numerical example involving a platoon of connected vehicles. © 2019 John Wiley & Sons, Ltd.",adaptive control; adaptive learning; connected vehicle formations; relaxed excitation conditions; sensor and actuator attacks; uniform boundedness,Actuators; Adaptive control systems; Autonomous vehicles; Networked control systems; State space methods; Adaptive Control; Adaptive learning; Boundedness; Excitation conditions; Sensor and actuators; Vehicle formations; Vehicle to vehicle communications,,,,,"Levine, W.S., Athans, M., On the optimal error regulation of a string of moving vehicles (1966) IEEE Trans Autom Control, 11 (3), pp. 355-361; Chu, K.C., Decentralized control of high-speed vehicular strings (1974) Transportation Science, 8 (4), pp. 361-384; Raza, H., Ioannou, P., Vehicle following control design for automated highway systems (1996) IEEE Control Syst Mag, 16 (6), pp. 43-60; Stankovic, S.S., Stanojevic, M.J., Siljak, D.D., Decentralized overlapping control of a platoon of vehicles (2000) IEEE Trans Control Syst Technol, 8 (5), pp. 816-832; Morbidi, F., Colaneri, P., Stanger, T., (2013) Decentralized optimal control of a car platoon with guaranteed string stability, , In Proceedings of the European Control Conference;, Zürich, Switzerland; Antsaklis, P., Goals and challenges in cyber-physical systems research (2014) IEEE Trans Autom Control, 59 (12), pp. 3117-3119; Yucelen, T., Haddad, W.M., Feron, E., Adaptive control architectures for mitigating sensor attacks in cyber-physical systems (2016) Cyber-Phys Syst, 2 (2), pp. 24-52; Arabi, E., Yucelen, T., Haddad, W.M., Mitigating the effects of sensor uncertainties in networked multiagent systems (2017) ASME J Dyn Syst Meas Control, 139 (4), pp. 1-11; Jin, X., Haddad, W.M., Yucelen, T., An adaptive control architecture for mitigating sensor and actuator attacks in cyber-physical systems (2017) IEEE Trans Autom Control, 62 (11), pp. 6058-6064; Jin, X., Haddad, W.M., Hayakawa, T., An adaptive control architecture for cyber-physical system security in the face of sensor and actuator attacks and exogenous stochastic disturbances (2018) Cyber-Phys Syst, 4 (1), pp. 39-56; Massoumnia, M.-A., Verghese, G.C., Willsky, A.S., Failure detection and identification (1989) IEEE Trans Autom Control, 34 (3), pp. 316-321; Blanke, M., Kinnaert, M., Lunze, J., Staroswiecki, M., Schröder, J., (2006) Diagnosis and Fault-Tolerant Control, , Vol 2., Berlin, Germany, Springer; Hwang, I., Kim, S., Kim, Y., Seah, C.E., A survey of fault detection, isolation, and reconfiguration methods (2010) IEEE Trans Control Syst Technol, 18 (3), pp. 636-653; Pasqualetti, F., Dorfler, F., Bullo, F., Attack detection and identification in cyber-physical systems (2013) IEEE Trans Autom Control, 58 (11), pp. 2715-2729; Fawzi, H., Tabuada, P., Diggavi, S., Secure estimation and control for cyber-physical systems under adversarial attacks (2012) IEEE Trans Autom Control, 59 (6), pp. 1454-1467; Weimer, J., Bezzo, N., Pajic, M., Pappas, G.J., Sokolsky, O., Lee, I., Resilient parameter-invariant control with application to vehicle cruise control (2013) Control of Cyber-Physical Systems, pp. 197-216. , Berlin, Germany, Springer; Schenato, L., Sinopoli, B., Franceschetti, M., Poolla, K., Sastry, S.S., Foundations of control and estimation over lossy networks (2007) Proc IEEE, 95 (1), pp. 163-187; Gupta, A., Langbort, C., Basar, T., (2010) Optimal control in the presence of an intelligent jammer with limited actions, , Paper presented at 49th IEEE Conference on Decision and Control (CDC);, Atlanta, GA; Sou, K.C., Sandberg, H., Johansson, K.H., On the exact solution to a smart grid cyber-security analysis problem (2013) IEEE Trans Smart Grid, 4 (2), pp. 856-865; Kosut, O., Jia, L., Thomas, R.J., Tong, L., Malicious data attacks on the smart grid (2011) IEEE Trans Smart Grid, 2 (4), pp. 645-658; Kim, T.T., Poor, H.V., Strategic protection against data injection attacks on power grids (2011) IEEE Trans Smart Grid, 2 (2), pp. 326-333; Chowdhary, G., Johnson, E., (2010) Concurrent learning for convergence in adaptive control without persistency of excitation, , Paper presented at 49th IEEE Conference on Decision and Control (CDC);, Atlanta, GA; Adam, S., Busoniu, L., Babuska, R., Experience replay for real-time reinforcement learning control (2012) IEEE Trans Syst Man Cybern Part C Appl Rev, 42 (2), pp. 201-212; Ioannou, P.A., Sun, J., (1996) Robust Adaptive Control, , Upper Saddle River, NJ, Prentice Hall; Jin, X., Haddad, W.M., Jiang, Z.-P., Vamvoudakis, K.G., (2018) Adaptive control for mitigating sensor and actuator attacks in connected autonomous vehicle platoons, , Paper presented at IEEE Conference on Decision and Control (CDC);, Miami Beach, FL; Jin, I.G., Orosz, G., Dynamics of connected vehicle systems with delayed acceleration feedback (2014) Trans Res C Emerg Technol, 46, pp. 46-64; Gao, W., Jiang, Z.P., Ozbay, K., Data-driven adaptive optimal control of connected vehicles (2017) IEEE Trans Intell Trans Syst, 18 (5), pp. 1122-1133; Teixeira, A., Shames, I., Sandberg, H., Johansson, K.H., A secure control framework for resource-limited adversaries (2015) Automatica, 51, pp. 135-148; Lucia, W., Sinopoli, B., Franze, G., (2016) A set-theoretic approach for secure and resilient control of cyber-physical systems subject to false data injection attacks, , Paper presented at Science of Security for Cyber-Physical Systems Workshop (SOSCYPS);, Vienna, Austria; Manandhar, K., Cao, X., Hu, F., Liu, Y., Detection of faults and attacks including false data injection attack in smart grid using Kalman filter (2014) IEEE Trans Control Netw Syst, 1 (4), pp. 370-379; Haddad, W.M., Chellaboina, V., (2008) Nonlinear Dynamical Systems and Control: A Lyapunov-Based Approach, , Princeton, NJ, Princeton University Press; Lavretsky, E., Wise, K., (2012) Robust and Adaptive Control With Aerospace Applications, , London, UK, Springer; Polycarpou, M.M., Ioannou, P.A., A robust adaptive nonlinear control design (1996) Automatica, 32 (3), pp. 423-427; Yucelen, T., Haddad, W.M., Low-frequency learning and fast adaptation in model reference adaptive control (2013) IEEE Trans Autom Control, 58 (2), pp. 1080-1085; Lewis, F.L., Jagannathan, S., Yesildirak, A., (1999) Neural Network Control of Robot Manipulators and Nonlinear Systems, , London, UK, Taylor & Francis; Boutayeb, H., Darouach, M., Recursive identification method for MISO Wiener-Hammerstein model (1995) IEEE Trans Autom Control, 40 (2), pp. 287-291; Modares, H., Lewis, F.L., Naghibi-Sistani, M.-B., Adaptive optimal control of unknown constrained-input systems using policy iteration and neural networks (2013) IEEE Trans Neural Netw Learn Syst, 24 (10), pp. 1513-1525; Vamvoudakis, K.G., Miranda, M.F., Hespanha, J.P., Asymptotically stable adaptive–optimal control algorithm with saturating actuators and relaxed persistence of excitation (2016) IEEE Trans Neural Netw Learn Syst, 27 (11), pp. 2386-2398; Johnson, M., Bhasin, S., Dixon, W.E., (2011) Nonlinear two-player zero-sum game approximate solution using a policy iteration algorithm, , Paper presented at 50th IEEE Conference on Decision and Control and European Control Conference;, Orlando, FL","Haddad, W.M.; School of Aerospace Engineering, Georgia; 电子邮件: wm.haddad@aerospace.gatech.edu",,,John Wiley and Sons Ltd,,,,,8906327,,IACPE,,English,Int J Adapt Control Signal Process,Article,Final,"All Open Access, Bronze",Scopus,2-s2.0-85068058467
"Kim E., Shah P., Yarnall J., Kenyon G.T.",56729479000;57211268279;57211272741;7102602432;,A neuromorphic sparse coding defense to adversarial images,2019,ACM International Conference Proceeding Series,,,a12,,,,6,10.1145/3354265.3354277,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073228943&doi=10.1145%2f3354265.3354277&partnerID=40&md5=617189ab59ecc82c3d6600e844c59664,"Villanova University, Villanova, PA, United States; Los Alamos National Laboratory, Los Alamos, NM, United States","Kim, E., Villanova University, Villanova, PA, United States; Shah, P., Villanova University, Villanova, PA, United States; Yarnall, J., Villanova University, Villanova, PA, United States; Kenyon, G.T., Los Alamos National Laboratory, Los Alamos, NM, United States","Adversarial images are a class of images that have been slightly altered by very specific noise to change the way a deep learning neural network classifies the image. In many cases, this particular noise is imperceptible to the human vision system and thus presents a vulnerability of significant concern to the machine learning and artificial intelligence community. Research towards mitigating this type of attack has taken many forms, one of which is to filter or post process the image before classifying the image with a deep neural network. Techniques such as smoothing, filtering, and compression have been used with varying levels of success. In our work, we explored the use of a neuromorphic software and hardware approach as a protection against adversarial image attack. The algorithm governing our neuromorphic approach is based upon sparse coding. Our sparse coding approach is solved using a dynamic system of equations that models biological low level vision. Our quantitative and qualitative results show that a sparse coding reconstruction is remarkably invariant to changes in sparsity and reconstruction error with respect to classification accuracy. Furthermore, our approach is able to maintain low reconstruction errors without sacrificing classification performance. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Adversarial image attack; Neuromorphic computing; Sparse coding,Deep learning; Deep neural networks; Image classification; Neural networks; Classification accuracy; Classification performance; Dynamic system of equations; Image attacks; Learning neural networks; Neuromorphic computing; Software and hardwares; Sparse coding; Image coding,,,,,"Baddeley, R., Visual-perception-an efficient code in V1 (1996) Nature, 381 (6583), pp. 560-561. , 1996; Baum, E.B., Moody, J., Wilczek, F., Internal representations for associative memory (1988) Biological Cybernetics, 59 (4-5), pp. 217-228. , 1988; Davies, M., Srinivasa, N., Lin, T.-H., Chinya, G., Cao, Y., Choday, S.H., Dimou, G., Jain, S., Loihi: A neuromorphic manycore processor with on-chip learning (2018) IEEE Micro, 38 (1), pp. 82-99. , 2018; Dziugaite, G.K., Ghahramani, Z., Roy, D.M., (2016) A Study of the Effect of Jpg Compression on Adversarial Images, , arXiv preprint 2016; Efron, B., Hastie, T., Johnstone, I., Tibshirani, R., Least angle regression (2004) The Annals of Statistics, 32 (2), pp. 407-499. , 2004; Foldiak, P., Sparse coding in the primate cortex (2003) The Handbook of Brain Theory and Neural Networks, , 2003; Glorot, X., Bordes, A., Bengio, Y., Deep sparse rectifier neural networks (2011) Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics, pp. 315-323; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint 2014; Guo, C., Rana, M., Cisse, M., Van Der Maaten, L., (2017) Countering Adversarial Images Using Input Transformations, , arXiv preprint 2017; He, K., Zhang, X., Ren, S., Sun, J., Delving deep into rectifiers: Surpassing human-level performance on imagenet classification (2015) Proceedings of the IEEE International Conference on Computer Vision, pp. 1026-1034; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 770-778; Huang, G., Liu, Z., Van Der Maaten, L., Weinberger, K.Q., Densely connected convolutional networks (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4700-4708; Jo, J., Bengio, Y., (2017) Measuring the Tendency of CNNs to Learn Surface Statistical Regularities, , arXiv preprint 2017; Kim, E., Hannan, D., Kenyon, G., Deep sparse coding for invariant multimodal halle berry neurons (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , 2018; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324. , 1998; Marzi, Z., Gopalakrishnan, S., Madhow, U., Pedarsani, R., (2018) Sparsity-Based Defense against Adversarial Attacks on Linear Classifiers, , arXiv preprint 2018; Mitro, J., Bridge, D., Prestwich, S., (2018) Denoising Dictionary Learning against Adversarial Perturbations, , arXiv preprint 2018; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Olshausen, B.A., Field, D.J., Sparse coding with an overcomplete basis set: A strategy employed by V1? (1997) Vision Research, 37 (23), pp. 3311-3325. , 1997; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387; Rozell, C., Johnson, D., Baraniuk, R., Olshausen, B., Locally competitive algorithms for sparse approximation (2007) IEEE International Conference on Image Processing, 4, pp. 4-169; Schultz, P.F., Paiton, D.M., Lu, W., Kenyon, G.T., (2014) Replicating Kernels with a Short Stride Allows Sparse Reconstructions with Fewer Independent Kernels, , arXiv preprint 2014; Springer, J.M., Strauss, C.S., Thresher, A.M., Kim, E., Kenyon, G.T., (2018) Classifiers Based on Deep Sparse Coding Architectures Are Robust to Deep Learning Transferable Examples, , arXiv preprint 2018; Su, J., Vargas, D.V., Kouichi, S., (2017) One Pixel Attack for Fooling Deep Neural Networks, , arXiv preprint 2017; Su, J., Vargas, D.V., Sakurai, K., One pixel attack for fooling deep neural networks (2019) IEEE Transactions on Evolutionary Computation, , 2019; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint 2013; Tang, P.T.P., Lin, T.-H., Davies, M., (2017) Sparse Coding by Spiking Neural Networks: Convergence Theory and Computational Results, , arXiv preprint 2017; Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses, , arXiv preprint 2017; Weyand, T., Kostrikov, I., Philbin, J., Planet-photo geolocation with convolutional neural networks (2016) European Conference on Computer Vision, pp. 37-55. , Springer; Xu, W., Evans, D., Qi, Y., (2017) Feature Squeezing Mitigates and Detects Carlini/Wagner Adversarial Examples, , arXiv preprint 2017",,,Department of Energy;Intel;KNOWM,Association for Computing Machinery,"2019 International Conference on Neuromorphic Systems, ICONS 2019",23 July 2019 through 25 July 2019,,151857,,9.78E+12,,,English,ACM Int. Conf. Proc. Ser.,Conference Paper,Final,,Scopus,2-s2.0-85073228943
"Dong Y., Pang T., Su H., Zhu J.",57191433539;57204799576;37017428500;56734692500;,Evading defenses to transferable adversarial examples by translation-invariant attacks,2019,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,2019-June,,8953425,4307,4316,,89,10.1109/CVPR.2019.00444,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078733079&doi=10.1109%2fCVPR.2019.00444&partnerID=40&md5=7b5dae6b666eafa3cae7f9e99e9d479a,"Dept. of Comp. Sci. and Tech., BNRist Center, State Key Lab for Intell. Tech. and Sys., Institute for AI, THBI Lab, Tsinghua University, Beijing, 100084, China","Dong, Y., Dept. of Comp. Sci. and Tech., BNRist Center, State Key Lab for Intell. Tech. and Sys., Institute for AI, THBI Lab, Tsinghua University, Beijing, 100084, China; Pang, T., Dept. of Comp. Sci. and Tech., BNRist Center, State Key Lab for Intell. Tech. and Sys., Institute for AI, THBI Lab, Tsinghua University, Beijing, 100084, China; Su, H., Dept. of Comp. Sci. and Tech., BNRist Center, State Key Lab for Intell. Tech. and Sys., Institute for AI, THBI Lab, Tsinghua University, Beijing, 100084, China; Zhu, J., Dept. of Comp. Sci. and Tech., BNRist Center, State Key Lab for Intell. Tech. and Sys., Institute for AI, THBI Lab, Tsinghua University, Beijing, 100084, China","Deep neural networks are vulnerable to adversarial examples, which can mislead classifiers by adding imperceptible perturbations. An intriguing property of adversarial examples is their good transferability, making black-box attacks feasible in real-world applications. Due to the threat of adversarial attacks, many methods have been proposed to improve the robustness. Several state-of-the-art defenses are shown to be robust against transferable adversarial examples. In this paper, we propose a translation-invariant attack method to generate more transferable adversarial examples against the defense models. By optimizing a perturbation over an ensemble of translated images, the generated adversarial example is less sensitive to the white-box model being attacked and has better transferability. To improve the efficiency of attacks, we further show that our method can be implemented by convolving the gradient at the untranslated image with a pre-defined kernel. Our method is generally applicable to any gradient-based attack method. Extensive experiments on the ImageNet dataset validate the effectiveness of the proposed method. Our best attack fools eight state-of-the-art defenses at an 82% success rate on average based only on the transferability, demonstrating the insecurity of the current defense techniques. © 2019 IEEE.",Categorization; Deep Learning; Recognition: Detection; Retrieval,Computer vision; Deep learning; Deep neural networks; Network security; Attack methods; Categorization; Defense techniques; Gradient based; Retrieval; State of the art; Translation invariants; White-box models; Image enhancement,,,,,"Athalye, A., Carlini, N., Wagner, D., Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples (2018) ICML; Athalye, A., Engstrom, L., Ilyas, A., Kwok, K., Synthesizing robust adversarial examples (2018) ICML; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 387-402; Brendel, W., Rauber, J., Bethge, M., Decision-based adversarial attacks: Reliable attacks against black-box machine learning models (2018) ICLR; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy; Chen, P.Y., Zhang, H., Sharma, Y., Yi, J., Jui Hsieh, C., Zoo: Zeroth order optimization based blackbox attacks to deep neural networks without training substitute models (2017) ACM Workshop on Artificial Intelligence and Security (AISec, pp. 15-26; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2018) CVPR; Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Xiao, C., Prakash, A., Song, D., Robust physical-world attacks on deep learning visual classification (2018) CVPR; Goodfellow, I., Lee, H., Le, Q.V., Saxe, A., Ng, A.Y., Measuring invariances in deep networks (2009) NIPS; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR; Guo, C., Rana, M., Cisse, M., Van Der Maaten, L., Countering adversarial images using input transformations (2018) ICLR; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) CVPR; He, K., Zhang, X., Ren, S., Sun, J., Identity mappings in deep residual networks (2016) ECCV; Kauderer-Abrams, E., (2017) Quantifying Translation-invariance in Convolutional Neural Networks, , arXiv preprint arXiv: 1801.01450; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint arXiv: 1607.02533; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2017) ICLR; LeCun, Y., Bengio, Y., Convolutional networks for images, speech, and time series (1995) Handbook of Brain Theory and Neural Networks; Liao, F., Liang, M., Dong, Y., Pang, T., Hu, X., Zhu, J., Defense against adversarial attacks using high-level representation guided denoiser (2018) CVPR; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and blackbox attacks (2017) ICLR; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) ICLR; Hendrik Metzen, J., Genewein, T., Fischer, V., Bischoff, B., On detecting adversarial perturbations (2017) ICLR; Mohsen Moosavi-Dezfooli, S., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) CVPR; Pang, T., Du, C., Dong, Y., Zhu, J., Towards robust detection of adversarial examples (2018) NeurIPS; Pang, T., Du, C., Zhu, J., Max-mahalanobis linear discriminant analysis networks (2018) ICML; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security; Raghunathan, A., Steinhardt, J., Liang, P., Certified defenses against adversarial examples (2018) ICLR; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Bernstein, M., Imagenet large scale visual recognition challenge (2015) International Journal of Computer Vision, 115 (3), pp. 211-252; Samangouei, P., Kabkab, M., Chellappa, R., Defense-gan: Protecting classifiers against adversarial attacks using generative models (2018) ICLR; Song, Y., Kim, T., Nowozin, S., Ermon, S., Kushman, N., Pixeldefend: Leveraging generative models to understand and defend against adversarial examples (2018) ICLR; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., Inception-v4, inception-resnet and the impact of residual connections on learning (2017) AAAI; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) CVPR; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) ICLR; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2018) ICLR; Tsipras, D., Santurkar, S., Engstrom, L., Turner, A., Madry, A., (2018) Robustness May Be at Odds with Accuracy, , arXiv preprint arXiv: 1805. 12152; Wong, E., Zico Kolter, J., Provable defenses against adversarial examples via the convex outer adversarial polytope (2018) ICML; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., Mitigating adversarial effects through randomization (2018) ICLR; Xie, C., Zhang, Z., Wang, J., Zhou, Y., Ren, Z., Yuille, A., (2018) Improving Transferability of Adversarial Examples with Input Diversity, , arXiv preprint arXiv: 1803.06978; Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., Torralba, A., Learning deep features for discriminative localization (2016) CVPR","Zhu, J.; Dept. of Comp. Sci. and Tech., China; 电子邮件: dcszj@mail.tsinghua.edu.cn",,,IEEE Computer Society,"32nd IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2019",16 June 2019 through 20 June 2019,,156730,10636919,9.78E+12,PIVRE,,English,Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85078733079
"Jaiswal A., Xia S., Masi I., Abdalmageed W.",56717277600;57215525571;36470557100;55953857600;,RoPAD: Robust Presentation Attack Detection through Unsupervised Adversarial Invariance,2019,"2019 International Conference on Biometrics, ICB 2019",,,8987276,,,,7,10.1109/ICB45273.2019.8987276,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074689049&doi=10.1109%2fICB45273.2019.8987276&partnerID=40&md5=693e2543db63a9ea84998912f8faf846,"USC Information Sciences Institute, Marina del Rey, CA, United States","Jaiswal, A., USC Information Sciences Institute, Marina del Rey, CA, United States; Xia, S., USC Information Sciences Institute, Marina del Rey, CA, United States; Masi, I., USC Information Sciences Institute, Marina del Rey, CA, United States; Abdalmageed, W., USC Information Sciences Institute, Marina del Rey, CA, United States","For enterprise, personal and societal applications, there is now an increasing demand for automated authentication of identity from images using computer vision. However, current authentication technologies are still vulnerable to presentation attacks. We present RoPAD, an end-to-end deep learning model for presentation attack detection that employs unsupervised adversarial invariance to ignore visual distractors in images for increased robustness and reduced overfitting. Experiments show that the proposed framework exhibits state-of-the-art performance on presentation attack detection on several benchmark datasets. © 2019 IEEE.",,Authentication; Benchmarking; Biometrics; Attack detection; Authentication technology; Benchmark datasets; End to end; Learning models; Overfitting; State-of-the-art performance; Visual distractors; Deep learning,,,,,"Atoum, Y., Liu, Y., Jourabloo, A., Liu, X., Face antispoofing using patch and depth-based cnns (2017) Biometrics (IJCB), 2017 IEEE International Joint Conference on, pp. 319-328. , IEEE; Boulkenafet, Z., Komulainen, J., Hadid, A., Face antispoofing based on color texture analysis (2015) Image Processing (ICIP), 2015 IEEE International Conference on, pp. 2636-2640. , IEEE; Boulkenafet, Z., Komulainen, J., Hadid, A., Face antispoofing using speeded-up robust features and fisher vector encoding (2017) IEEE Signal Processing Letters, 24 (2), pp. 141-145; Chingovska, I., Anjos, A., Marcel, S., On the effectiveness of local binary patterns in face anti-spoofing (2012) Proceedings of the 11th International Conference of the Biometrics Special Interes Group, , number EPFL-CONF-192369; Clevert, D., Unterthiner, T., Hochreiter, S., Fast and accurate deep network learning by exponential linear units (elus) (2015) CoRR, , abs/1511.07289; Costa-Pazo, A., Bhattacharjee, S., Vazquez-Fernandez, E., Marcel, S., The replay-mobile face presentation-Attack database (2016) Biometrics Special Interest Group (BIOSIG), 2016 International Conference of the, pp. 1-7. , IEEE; Erdogmus, N., Marcel, S., Spoofing in 2d face recognition with 3d masks and anti-spoofing with kinect (2014) IEEE Sixth International Conference on Biometrics: Theory, Applications and Systems, pp. 1-6; Gan, J., Li, S., Zhai, Y., Liu, C., 3d convolutional neural network based on face anti-spoofing (2017) Multimedia and Image Processing (ICMIP), 2017 2nd International Conference on, pp. 1-5. , IEEE; Gragnaniello, D., Poggi, G., Sansone, C., Verdoliva, L., An investigation of local descriptors for biometric spoofing detection (2015) IEEE Transactions on Information Forensics and Security, 10, pp. 849-863; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , June; (2016) Information Technology Biometric Presentation Attack Detection Part 1: Framework, , https://www.iso.org/obp/ui/iso, ISO/IEC JTC 1/SC 37-Biometrics. Standard, International Organization for Standardization; Jaiswal, A., Wu, Y., Abd-Almageed, W., Natarajan, P., Unsupervised adversarial invariance (2018) Advances in Neural Information Processing Systems, 31, pp. 5097-5107. , Curran Associates, Inc; Jourabloo, A., Liu, Y., Liu, X., (2018) Face De-spoofing: Anti-spoofing Via Noise Modeling., , arXiv preprint arXiv:1807.09968,1(2):3; Liu, Y., Jourabloo, A., Liu, X., Learning deep models for face anti-spoofing: Binary or auxiliary supervision (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 389-398; Määttä, J., Hadid, A., Pietikäinen, M., Face spoofing detection from single images using micro-Texture analysis (2011) Biometrics (IJCB), 2011 International Joint Conference on, pp. 1-7. , IEEE; Nogueira, R.F., De Alencar Lotufo, R., Machado, R.C., Fingerprint liveness detection using convolutional neural networks (2016) IEEE Trans. Information Forensics and Security, 11 (6), pp. 1206-1213; Peng, F., Qin, L., Long, M., Face presentation attack detection using guided scale texture (2017) Multimedia Tools and Applications, pp. 1-27; Peng, F., Qin, L., Long, M., Ccolbp: Chromatic cooccurrence of local binary pattern for face presentation attack detection (2018) 2018 27th International Conference on Computer Communication and Networks (ICCCN, pp. 1-9. , IEEE; Phan, Q.-T., Dang-Nguyen, D.-T., Boato, G., De Natale, F.G., Face spoofing detection using ldp-Top (2016) Image Processing (ICIP), 2016 IEEE International Conference on, pp. 404-408. , IEEE; Raghavendra, R., Raja, K.B., Busch, C., Presentation attack detection for face recognition using light field camera (2015) IEEE Transactions on Image Processing, 24 (3), pp. 1060-1075; Ramachandra, R., Busch, C., Presentation attack detection methods for face recognition systems: A comprehensive survey (2017) ACM Computing Surveys (CSUR), 50 (1), p. 8; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2014) CoRR, , abs/1409.1556; Wen, D., Han, H., Jain, A.K., Face spoof detection with image distortion analysis (2015) IEEE Transactions on Information Forensics and Security, 10 (4), pp. 746-761; Yang, J., Lei, Z., Li, S.Z., (2014) Learn Convolutional Neural Network for Face Anti-spoofing., , arXiv preprint arXiv:1408.5601",,,,Institute of Electrical and Electronics Engineers Inc.,"2019 International Conference on Biometrics, ICB 2019",4 June 2019 through 7 June 2019,,157624,,9.78E+12,,,English,"Int. Conf. Biom., ICB",Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85074689049
"Huang Y., Xu M., Wang W., Wang H., Jiang T., Zhang Q.",57207982877;57210292254;57020942200;57218524265;56492041300;56670485000;,Towards Motion Invariant Authentication for On-Body IoT Devices,2019,IEEE International Conference on Communications,2019-May,,8761982,,,,5,10.1109/ICC.2019.8761982,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070186004&doi=10.1109%2fICC.2019.8761982&partnerID=40&md5=b9183cbc8fb832769060274b7494a200,"School of Electronic Information and Communications, Huazhong University of Science and Technology, China; Computer Science and Artificial Intelligence Lab, Massachusetts, Institute of Technology, United States; Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong","Huang, Y., School of Electronic Information and Communications, Huazhong University of Science and Technology, China; Xu, M., School of Electronic Information and Communications, Huazhong University of Science and Technology, China; Wang, W., School of Electronic Information and Communications, Huazhong University of Science and Technology, China; Wang, H., Computer Science and Artificial Intelligence Lab, Massachusetts, Institute of Technology, United States; Jiang, T., School of Electronic Information and Communications, Huazhong University of Science and Technology, China; Zhang, Q., Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong","As the rapid proliferation of on-body Internet of Things (IoT) devices, their security vulnerabilities have raised serious privacy and safety issues. Traditional efforts to secure these devices against impersonation attacks mainly rely on either dedicated sensors or specified user motions, impeding their wide-scale adoption. This paper transcends these limitations with a general security solution by leveraging ubiquitous wireless chips available in IoT devices. Particularly, representative time and frequency features are first extracted from received signal strengths (RSSs) to characterize radio propagation profiles. Then, an adversarial multi-player network is developed to recognize underlying radio propagation patterns and facilitate on-body device authentication. We prove that at equilibrium, our adversarial model can extract all information about propagation patterns and eliminate any irrelevant information caused by motion variances. We build a prototype of our system using universal software radio peripheral (USRP) devices and conduct extensive experiments with both static and dynamic body motions in typical indoor and outdoor environments. The experimental results show that our system achieves an average authentication accuracy of 90.4%, with a high area under the receiver operating characteristic curve (AUROC) of 0.958 and better generalization performance in comparison with the conventional non-adversarial-based approach. © 2019 IEEE.",,Authentication; Radio waves; Software radio; Wave propagation; Device authentications; Generalization performance; Internet of Things (IOT); Received signal strength; Receiver operating characteristic curves; Security vulnerabilities; Time and frequencies; Universal software radio peripherals (USRP); Internet of things,,,,,"Uckelmann, D., Harrison, M., Michahelles, F., An architectural approach towards the future internet of things (2011) Springer Architecting the Internet of Things, pp. 1-24; Mainetti, L., Mighali, V., Patrono, L., An iot-based user-centric ecosystem for heterogeneous smart home environments (2015) Proc. IEEE ICC, pp. 704-709; Gollakota, S., They can hear your heartbeats: Non-invasive security for implantable medical devices (2011) Proc. ACM SIGCOMM, 41 (4), pp. 2-13; Shi, L., Bana: Body area network authentication exploiting channel characteristics (2013) IEEE J. Sel. Areas Commun., 31 (9), pp. 1803-1816; Revadigar, G., Accelerometer and fuzzy vault-based secure group key generation and sharing protocol for smart wearables (2017) IEEE Trans. Inf. Forensics Security, 12 (10), pp. 2467-2482; Xu, W., Gait-key: A gait-based shared secret key generation protocol for wearable devices (2017) ACM Trans. Sensor Networks, 13 (1), p. 6; Cornelius, C., A wearable system that knows who wears it (2014) Proc. ACM MobiSys, pp. 55-67; Vu, T., Distinguishing users with capacitive touch communication (2012) Proc. ACM MobiCom, pp. 197-208; Di Franco, F., On-body to on-body channel characterization (2011) IEEE Sensors J., pp. 908-911; Ryckaert, J., Channel model for wireless communication around human body (2004) IET Electronics Letters, 40 (9), pp. 543-544; Ganin, Y., Domain-adversarial training of neural networks (2016) MIT press Journal of Machine Learning Research, 17 (1), pp. 2030-2096; Zhao, M., Learning sleep stages from radio signals: A conditional adversarial architecture (2017) Proc. ACM ICML, pp. 4100-4109; Shinohara, Y., Adversarial multi-task learning of deep neural networks for robust speech recognition (2016) Interspeech, pp. 2369-2372; Goodfellow, I., (2016) Deep Learning, 1. , MIT press; Mobilenetv2: The next generation of on-device computer vision networks (2018) Google Research, , https://ai.googleblog.com/2018/04/mobilenetv2-next-generation-of-on.html, April 3; Xiong, Y., Quek, F., Hand motion gesture frequency properties and multimodal discourse analysis (2006) Springer International Journal of Computer Vision, 69 (3), pp. 353-371; Xu, W., Walkie-talkie: Motion-assisted automatic key generation for secure on-body device communication (2016) Proc. ACM/IEEE IPSN, pp. 1-12; Ren, Y., Smartphone based user verification leveraging gait recognition for mobile healthcare systems (2013) Proc. IEEE SECON, pp. 149-157; Das, A., Borisov, N., Caesar, M., Do you hear what i hear?: Fingerprinting smart devices through embedded acoustic components (2014) Proc. ACM CCS, pp. 441-452; Wang, W., Securing on-body iot devices by exploiting creeping wave propagation (2018) IEEE J. Sel. Areas Commun., 36 (4), pp. 696-703",,,,Institute of Electrical and Electronics Engineers Inc.,"2019 IEEE International Conference on Communications, ICC 2019",20 May 2019 through 24 May 2019,,149930,15503607,9.78E+12,,,English,IEEE Int Conf Commun,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85070186004
"Tang Z., Kuijper M., Chong M.S., Mareels I., Leckie C.",57220907881;7003535680;54912439800;7004369521;7003524629;,Linear system security—Detection and correction of adversarial sensor attacks in the noise-free case,2019,Automatica,101,,,53,59,,14,10.1016/j.automatica.2018.11.048,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058171038&doi=10.1016%2fj.automatica.2018.11.048&partnerID=40&md5=8e837b8f98c78b7e6f5d64ef795fcd38,"Department of Electrical and Electronic Engineering, The University of Melbourne, Australia; Department of Automatic Control, KTH Royal Institute of Technology, Sweden; School of Computing and Information Systems, The University of Melbourne, Australia","Tang, Z., Department of Electrical and Electronic Engineering, The University of Melbourne, Australia; Kuijper, M., Department of Electrical and Electronic Engineering, The University of Melbourne, Australia; Chong, M.S., Department of Automatic Control, KTH Royal Institute of Technology, Sweden; Mareels, I., Department of Electrical and Electronic Engineering, The University of Melbourne, Australia; Leckie, C., School of Computing and Information Systems, The University of Melbourne, Australia","We address the problem of attack detection and attack correction for multi-output discrete-time linear time-invariant dynamical systems under sensor attack. More specifically, we focus on the situation where adversarial attack signals are added to some of the system's output signals. Algorithms for sensor attack detection and correction are presented using the notion of ‘security index’ which characterizes the system's vulnerability against such attacks. The results are illustrated by examples involving multiple sensors. © 2018 Elsevier Ltd",Attack correction; Attack detection; Error control coding; Linear time-invariant systems; Security; Sensor attacks,Dynamical systems; Invariance; Linear control systems; Time varying control systems; Attack detection; Error control coding; Linear time invariant systems; Linear-time invariant dynamical systems; Multiple sensors; Noise free case; Security; Security indices; Linear systems,,,,,"Chen, Y., Kar, S., Moura, J., (2015), pp. 1752-1756. , M. F. Cyber-physical systems: dynamic sensor attacks and strong observability. In Proc. 40th international conference on acoustics, speech and signal processing; Chen, J., Patton, R.J., Robust model-based fault diagnosis for dynamic systems (1999), Kluwer; Chong, M.S., Kuijper, M., (2016), pp. 5906-5911. , Characterising the vulnerability of linear control systems under sensor attacks using a system’ s security index. Proc. IEEE 55th conference on decision and control December, 2016; Chong, M.S., Kuijper, M., (2016), pp. 373-376. , Vulnerability of linear systems against sensor attacks–a system's security index. In Proc. 22nd international symposium on mathematical theory of networks and systems; Chong, M.S., Wakaiki, M., Hespanha, J.P., , pp. 2439-2444. , Observability of linear systems under adversarial attacks. In Proc. 2015 American control conference; Chow, E.Y., Willsky, A.S., Analytical redundancy and the design of robust failure detection systems (1984) IEEE Transactions on Automatic Control, 27, pp. 603-614; Colonius, F., Helmke, U., Prätzel-Wolters, D., Wirth, F., System and control: Foundations and applications (2001), Springer; Ding, S.X., Model-based fault diagnosis techniques (2008), Springer; Fawzi, H., Tabuada, P., Diggavi, S.N., Secure estimation and control for cyber-physical systems under adversarial attacks (2014) IEEE Transactions of Automatic Control, 59 (6), pp. 1454-1467; Frisk, E., Nyberg, M., (1999), pp. 4161-4166. , Using minimal polynomial bases for fault diagnosis. In Proc. European control conference; Fuhrmann, P.A., Helmke, U., The mathematics of networks of linear systems (2015), Springer; Hajshirmohamadi, S., Davoodi, M., Meskin, N., Sheikholeslam, F., Event-triggered fault detection and isolation for discrete-time linear systems (2016) IET Control Theory & Applications, 10, pp. 526-533; Hendrickx, J.M., Johansson, K.H., Jungers, R.M., Sandberg, H., Sou, K.C., Efficient computations of a security index for false data attacks in power networks (2014) IEEE Transactions on Automatic Control, 59 (12), pp. 3194-3208; Hinrichsen, D., Prätzel-Wolters, D., Generalized Hermite matrices and complete invariants of stict system equivalence (1983) SlAM Journal on Control and Optimization, 21, pp. 289-306; Kuijper, M., First-order representations of linear systems (1994), Birkhäuser Boston, USA; Lee, C., Shim, H., Eun, Y., (2015), pp. 1872-1877. , Secure and robust state estimation under sensor attacks, measurement noises, and process disturbances: observer-based combinatorial approach. In Proc. 2015 European control conference; Manandhar, K., Cao, X., Detection of faults and attacks including false data injection attack in smart grid using kalman filter (2014) IEEE Transactions on Control of Network Systems, 1, pp. 370-379; Pajic, M., Tabuada, P., Lee, I., (2015), pp. 5827-5832. , Attack-resilient state estimation in the presence of noise. In Proc. 54th IEEE conference on decision and control; Pasqualetti, F., Dörfler, F., Bullo, F., Attack detection and identification in cyber-physical systems (2013) IEEE Transactions on Automatic Control, 58 (11), pp. 2715-2729; Polderman, J.W., Willems, J.C., (1997), Introduction to mathematical systems theory: a behavioral approach, Vol. 26. Springer; Proakis, J.G., Salehi, M., Digital communications (2008), McGraw Hill; Reed, I.S., Solomon, G., Polynomial codes over certain finite fields (1960) SIAM Journal on Applied Mathematics, 8, pp. 300-304; Sandberg, H., Teixeira, A., (2016), pp. 1-6. , M. H. From control system security indices to attack identifiability. In Proc. 2016 science of security for cyber-physical systems workshop; Sandberg, H., Teixeira, A., Johansson, K., (2010), pp. 1-6. , On security indices for state estimators in power networks. In Proceedings of first workshop on secure control systems; Shoukry, Y., Chong, M., Wakaiki, M., Nuzzo, P., Sangiovanni-Vincentelli, A.L., Seshia, S.A., Hespanha, J.P., Tabuada, P., (2016), pp. 1-10. , SMT-based observer design for cyber-physical systems under sensor attacks. In Proc. 2016 ACM/IEEE 7th international conference on cyber-physical systems; Shoukry, Y., Tabuada, P., Event-triggered state observers for sparse sensor noise/attacks (2016) IEEE Transactions of Automatic Control, 61 (8), pp. 2079-2091; Stallings, W., Cryptography and network security (2011), Prentice Hall; Teixeira, A., Shames, I., Sandberg, H., Johansson, K.H., A secure control framework for resource-limited adversaries (2015) Automatica, 51, pp. 135-148; Teixeira, A., Sou, K.C., H. Sandberg, K.H.J., Secure control systems: A quantitative risk management approach (2015) IEEE Control System Magazine, 35, pp. 24-45; Warner, J.S., Johnston, R.G., A simple demonstration that the global positioning system is vulnerable to spoofing (2002) Journal of Security Administration, pp. 19-27; Willems, J., (1993), pp. 3664-3668. , C. LQ-control: a behavioral approach. In Proc. 32nd IEEE conference on decision and control; Zhang, Y., Qiu, Q., Yang, F., Han, Q.L., Vlacic, L., Liul, J., , pp. 170-175. , Set-membership filtering approach for fault detection of systems with unknown-but-bounded noises. In Proc. 5th Australian control conference","Tang, Z.; Department of Electrical and Electronic Engineering, Australia; 电子邮件: zhanghant@student.unimelb.edu.au",,,Elsevier Ltd,,,,,51098,,ATCAA,,English,Automatica,Article,Final,,Scopus,2-s2.0-85058171038
"Jin X., Haddad W.M., Jiang Z.-P., Vamvoudakis K.G.",55541046800;35461378700;7404279463;24726183300;,Adaptive Control for Mitigating Sensor and Actuator Attacks in Connected Autonomous Vehicle Platoons,2019,Proceedings of the IEEE Conference on Decision and Control,2018-December,,8619560,2810,2815,,3,10.1109/CDC.2018.8619560,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062188938&doi=10.1109%2fCDC.2018.8619560&partnerID=40&md5=c1511bfe0f806a89a47fe6b041f312b3,"School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA  0332-0150, United States; Department of Electrical and Computer Engineering, Tandon School of Engineering, New York University, Control and Networks Lab, Brooklyn, NY  11201, United States","Jin, X., School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA  0332-0150, United States; Haddad, W.M., School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA  0332-0150, United States; Jiang, Z.-P., Department of Electrical and Computer Engineering, Tandon School of Engineering, New York University, Control and Networks Lab, Brooklyn, NY  11201, United States; Vamvoudakis, K.G., School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA  0332-0150, United States","In this paper, we develop an adaptive control algorithm for addressing security for a class of networked vehicles that comprise n human-driven vehicles sharing kinematic data and an autonomous vehicle in the aft of the vehicle formation receiving data from the preceding vehicles by wireless vehicle-to-vehicle communication devices. Specifically, we develop an adaptive controller for mitigating time-invariant, state-dependent adversarial sensor and actuator attacks while guaranteeing uniform ultimate boundedness of the closed-loop networked system. The effectiveness of the proposed approach is demonstrated by an illustrative numerical example involving a platoon of connected vehicles. © 2018 IEEE.",,Actuators; Adaptive control systems; Autonomous vehicles; Networked control systems; Adaptive Control; Adaptive control algorithms; Adaptive controllers; Networked systems; Networked vehicles; Sensor and actuators; Uniform ultimate boundedness; Vehicle formations; Vehicle to vehicle communications,,,,,"Levine, W.S., Athans, M., On the optimal error regulation of a string of moving vehicles (1966) IEEE Transactions on Automatic Control, 11 (3), pp. 355-361; Chu, K.C., Decentralized control of high-speed vehicular strings (1974) Transportaion Science, 8 (4), pp. 361-384; Raza, H., Ioannou, P., Vehicle following control design for automated highway systems (1996) IEEE Control Systems Magazine, 16 (6), pp. 43-60; Stankovic, S.S., Stanojevic, M.J., Siljak, D.D., Decentralized overlapping control of a platoon of vehicles (2000) IEEE Transactions on Control Systems Technology, 8 (5), pp. 816-832; Morbidi, F., Colaneri, P., Stanger, T., Decentralized optimal control of a car platoon with guaranteed string stability (2013) Proceedings of the 2013 European Control Conference, pp. 3494-3499; Antsaklis, P., Goals and challenges in cyber-physical systems research (2014) IEEE Transactions on Automatic Control, 59 (12), pp. 3117-3119; Yucelen, T., Haddad, W.M., Feron, E., Adaptive control architectures for mitigating sensor attacks in cyber-physical systems (2016) Cyber-Physical Systems, 2 (2), pp. 24-52; Arabi, E., Yucelen, T., Haddad, W.M., Mitigating the effects of sensor uncertainties in networked multiagent systems (2017) ASME Journal of Dynamic Systems, Measurement, and Control, 139 (4), pp. 1-11; Jin, X., Haddad, W.M., Yucelen, T., An adaptive control architecture for mitigating sensor and actuator attacks in cyber-physical systems (2017) IEEE Transactions on Automatic Control, 62 (11), pp. 6058-6064; Jin, X., Haddad, W.M., Hayakawa, T., An adaptive control architecture for cyber-physical system security in the face of sensor and actuator attacks and stochastic distrubances (2017) IEEE Conference on Decision and Control, pp. 1380-1385; Massoumnia, M.-A., Verghese, G.C., Willsky, A.S., Failure detection and identification (1989) IEEE Transactions on Automatic Control, 34 (3), pp. 316-321; Blanke, M., Schröder, J., (2006) Diagnosis and Fault-Tolerant Control, 691. , Springer; Hwang, I., Kim, S., Kim, Y., Seah, C.E., A survey of fault detection, isolation, and reconfiguration methods (2010) IEEE Transactions on Control Systems Technology, 18 (3), pp. 636-653; Pasqualetti, F., Dorfler, F., Bullo, F., Attack detection and identification in cyber-physical systems (2013) IEEE Transactions on Automatic Control, 58 (11), pp. 2715-2729; Fawzi, H., Tabuada, P., Diggavi, S., Secure estimation and control for cyber-physical systems under adversarial attacks (2012) IEEE Transactions on Automatic Control, 59 (6), pp. 1454-1467; Weimer, J., Bezzo, N., Pajic, M., Pappas, G.J., Sokolsky, O., Lee, I., Resilient parameter-invariant control with application to vehicle cruise control (2013) Control of Cyber-Physical Systems, pp. 197-216. , Springer; Schenato, L., Sinopoli, B., Franceschetti, M., Poolla, K., Sastry, S.S., Foundations of control and estimation over lossy networks (2007) Proceedings of the IEEE, 95 (1), pp. 163-187; Gupta, A., Langbort, C., Basar, T., Optimal control in the presence of an intelligent jammer with limited actions (2010) IEEE Conference on Decision and Control, pp. 1096-1101; Sou, K.C., Sandberg, H., Johansson, K.H., On the exact solution to a smart grid cyber-security analysis problem (2013) IEEE Transactions on Smart Grid, 4 (2), pp. 856-865; Kosut, O., Jia, L., Thomas, R.J., Tong, L., Malicious data attacks on the smart grid (2011) IEEE Transactions on Smart Grid, 2 (4), pp. 645-658; Kim, T.T., Poor, H.V., Strategic protection against data injection attacks on power grids (2011) IEEE Transactions on Smart Grid, 2 (2), pp. 326-333; Gao, W., Jiang, Z.P., Ozbay, K., Data-driven adaptive optimal control of connected vehicles (2017) IEEE Transactions on Intelligent Transportation Systems, 18 (5), pp. 1122-1133; Haddad, W.M., Chellaboina, V., (2008) Nonlinear Dynamical Systems and Control: A Lyapunov-Based Approach, , Princeton, NJ: Princeton Univ. Press; Lavretsky, E., Wise, K., (2012) Robust and Adaptive Control with Aerospace Applications, , Springer; Polycarpou, M.M., Ioannou, P.A., A robust adaptive nonlinear control design (1996) Automatica, 32 (3), pp. 423-427; Yucelen, T., Haddad, W.M., Low-frequency learning and fast adaptation in model reference adaptive control (2013) IEEE Trans. Autom. Contr., 58 (2), pp. 1080-1085",,,et al.;MathWorks;Mitsubishi Electric Research Laboratories (MERL);Skydio;Society for Industrial and Applied Mathematics (SIAM);United Technologies Research Center (UTRC),Institute of Electrical and Electronics Engineers Inc.,"57th IEEE Conference on Decision and Control, CDC 2018",17 December 2018 through 19 December 2018,,144492,7431546,9.78E+12,PCDCD,,English,Proc IEEE Conf Decis Control,Conference Paper,Final,,Scopus,2-s2.0-85062188938
"Uesato J., Alayrac J.-B., Huang P.-S., Stanforth R., Fawzi A., Kohli P.",57202451204;57191077348;47061231500;57205283528;55413093600;14035707300;,Are labels required for improving adversarial robustness?,2019,Advances in Neural Information Processing Systems,32,,,,,,24,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090178362&partnerID=40&md5=520d2c20847ca686ebf98d7d4020ea00,DeepMind,"Uesato, J., DeepMind; Alayrac, J.-B., DeepMind; Huang, P.-S., DeepMind; Stanforth, R., DeepMind; Fawzi, A., DeepMind; Kohli, P., DeepMind","Recent work has uncovered the interesting (and somewhat surprising) finding that training models to be invariant to adversarial perturbations requires substantially larger datasets than those required for standard classification. This result is a key hurdle in the deployment of robust machine learning models in many real world applications where labeled data is expensive. Our main insight is that unlabeled data can be a competitive alternative to labeled data for training adversarially robust models. Theoretically, we show that in a simple statistical setting, the sample complexity for learning an adversarially robust model from unlabeled data matches the fully supervised case up to constant factors. On standard datasets like CIFAR-10, a simple Unsupervised Adversarial Training (UAT) approach using unlabeled data improves robust accuracy by 21.7% over using 4K supervised examples alone, and captures over 95% of the improvement from the same number of labeled examples. Finally, we report an improvement of 4% over the previous state-of-the-art on CIFAR-10 against the strongest known attack by using additional unlabeled data from the uncurated 80 Million Tiny Images dataset. This demonstrates that our finding extends as well to the more realistic case where unlabeled data is also uncurated, therefore opening a new avenue for improving adversarial training. © 2019 Neural information processing systems foundation. All rights reserved.",,Image enhancement; Labeled data; Constant factors; Machine learning models; Robust modeling; Robust models; Sample complexity; State of the art; Training model; Unlabeled data; Learning systems,,,,,"Athalye, A., Carlini, N., Wagner, D., (2018) Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples, , arXiv preprint arXiv:1802.00420, 2, 3, 9, 16; Attias, I., Kontorovich, A., Mansour, Y., Improved generalization bounds for robust learning (2018) ALT, p. 2; Bachman, P., Alsharif, O., Precup, D., Learning with pseudo-ensembles (2014) NeurIPS, p. 3; Berthelot, D., Carlini, N., Goodfellow, I., Papernot, N., Oliver, A., Raffel, C., (2019) MixMatch: A Holistic Approach to Semi-Supervised Learning, , arXiv:1905.02249, 3; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndic, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 387-402. , Springer, 2; Blum, A., Mitchell, T., Combining labeled and unlabeled data with co-training (1998) Proceedings of the Eleventh Annual Conference on Computational Learning Theory, pp. 92-100. , ACM, 3; Bojarski, M., Testa, D. D., Dworakowski, D., Firner, B., Flepp, B., Goyal, P., Jackel, L. D., Zieba, K., (2016) End to end learning for self-driving cars, p. 1. , CoRR, abs/1604.07316; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 3-14. , ACM, 2; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) In Security and Privacy (SP), 2017 IEEE Symposium on, pp. 39-57. , IEEE, 14; Carmon, Y., Raghunathan, A., Schmidt, L., Liang, P., Duchi, J. C., Unlabeled Data Improves Adversarial Robustness (2019) In NeurIPS, 1 (2), p. 3; Chapelle, O., Scholkopf, B., Zien, A., Semi-Supervised Learning (2009) MITPress, 3; Chen, D.-D., Wang, W., Gao, W., Zhou, Z.-H., Tri-net for semi-supervised deep learning (2018) IJCAI, p. 3; Covington, P., Adams, J., Sargin, E., Deep neural networks for Youtube recommendations (2016) Proceedings of the 10th ACM Conference on Recommender Systems, pp. 191-198. , ACM, 1; De Fauw, J., Ledsam, J. R., Romera-Paredes, B., Nikolov, S., Tomasev, N., Blackwell, S., Askham, H., Visentin, D., Clinically applicable deep learning for diagnosis and referral in retinal disease (2018) Nature Medicine, 24 (9), p. 1342. , 1; Douze, M., Jégou, H., Sandhawalia, H., Amsaleg, L., Schmid, C., Evaluation of gist descriptors for web-scale image search (2009) In Proceedings of the ACM International Conference on Image and Video Retrieval, 8, p. 15. , page 19, ACM; Finlayson, S. G., Bowers, J. D., Ito, J., Zittrain, J. L., Beam, A. L., Kohane, I. S., Adversarial attacks on medical machine learning (2019) Science, p. 9; Goodfellow, I. J., Shlens, J., Szegedy, C., (2014) Explaining and harnessing adversarial examples, 1 (2). , arXiv preprint arXiv:1412.6572, 8; Gowal, S., Dvijotham, K., Stanforth, R., Bunel, R., Qin, C., Uesato, J., Arandjelovic, R., Kohli, P., (2018) On the effectiveness of interval bound propagation for training verifiably robust models, , arXiv preprint arXiv:1810.12715, 5; Gowal, S., Uesato, J., Qin, C., Huang, P.-S., Mann, T., Kohli, P., (2019) An alternative surrogate loss for PGD-based adversarial testing, 5, p. 15; Gu, S., Rigazio, L., (2014) Towards deep neural network architectures robust to adversarial examples, , arXiv preprint arXiv:1412.5068, 2; Hendrycks, D., Lee, K., Mazeika, M., Using pre-training can improve model robustness and uncertainty (2019) ICML, 2 (8), p. 9; Huang, P.-S., He, X., Gao, J., Deng, L., Acero, A., Heck, L., Learning deep structured semantic models for web search using clickthrough data (2013) Proceedings of the 22nd ACM international conference on Information & Knowledge Management, pp. 2333-2338. , ACM, 1; Khim, J., Loh, P.-L., (2018) Adversarial risk bounds for binary classification via function transformation, , arXiv preprint arXiv:1810.09519, 2; Kingma, D. P., Ba, J., (2014) Adam: A method for stochastic optimization, p. 14. , arXiv preprint arXiv:1412.6980; Krizhevsky, A., Hinton, G., Learning multiple layers of features from tiny images (2009) Technical report, 7, p. 15; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial Machine Learning at Scale (2017) ICLR, 2, p. 4. , 5, 8, 14; Laine, S., Aila, T., Temporal ensembling for semi-supervised learnings (2017) ICLR, p. 3; Laurent, B., Massart, P., Adaptive estimation of a quadratic functional by model selection (2000) Annals of Statistics, pp. 1302-1338. , 17; Liu, Y., Chen, X., Liu, C., Song, D., (2016) Delving into transferable adversarial examples and black-box attacks, p. 14. , arXiv preprint arXiv:1611.02770; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards Deep Learning Models Resistant to Adversarial Attacks (2018) ICLR, 1. , 2, 3, 4, 5, 8, 9, 12, 14; Miller, G. A., Wordnet: a lexical database for english (1995) Communications of the ACM, 38 (11), pp. 39-41. , 15","Uesato, J.; DeepMind电子邮件: juesato@google.com",,Citadel;Doc.AI;et al.;Lambda;Lyft;Microsoft Research,Neural information processing systems foundation,"33rd Annual Conference on Neural Information Processing Systems, NeurIPS 2019",8 December 2019 through 14 December 2019,,161263,10495258,,,,English,Adv. neural inf. proces. syst.,Conference Paper,Final,,Scopus,2-s2.0-85090178362
"Naseer M., Khan S., Khan M.H., Khan F.S., Porikli F.",57204565968;56415451600;57215775432;36100204000;6603528219;,Cross-domain transferability of adversarial perturbations,2019,Advances in Neural Information Processing Systems,32,,,,,,17,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090172930&partnerID=40&md5=37e0825bd073ab494e3f393c6629f468,"Australian National University, Canberra, Australia; Inception Institute of Artificial Intelligence, Abu Dhabi, United Arab Emirates; CVL, Department of Electrical Engineering, Linköping University, Sweden","Naseer, M., Australian National University, Canberra, Australia, Inception Institute of Artificial Intelligence, Abu Dhabi, United Arab Emirates; Khan, S., Australian National University, Canberra, Australia, Inception Institute of Artificial Intelligence, Abu Dhabi, United Arab Emirates; Khan, M.H., Inception Institute of Artificial Intelligence, Abu Dhabi, United Arab Emirates; Khan, F.S., Inception Institute of Artificial Intelligence, Abu Dhabi, United Arab Emirates, CVL, Department of Electrical Engineering, Linköping University, Sweden; Porikli, F., Australian National University, Canberra, Australia","Adversarial examples reveal the blind spots of deep neural networks (DNNs) and represent a major concern for security-critical applications. The transferability of adversarial examples makes real-world attacks possible in black-box settings, where the attacker is forbidden to access the internal parameters of the model. The underlying assumption in most adversary generation methods, whether learning an instance-specific or an instance-agnostic perturbation, is the direct or indirect reliance on the original domain-specific data distribution. In this work, for the first time, we demonstrate the existence of domain-invariant adversaries, thereby showing common adversarial space among different datasets and models. To this end, we propose a framework capable of launching highly transferable attacks that crafts adversarial patterns to mislead networks trained on entirely different domains. For instance, an adversarial function learned on Paintings, Cartoons or Medical images can successfully perturb ImageNet samples to fool the classifier, with success rates as high as ~99% (`8 = 10). The core of our proposed adversarial function is a generative network that is trained using a relativistic supervisory signal that enables domain-invariant perturbations. Our approach sets the new state-of-the-art for fooling rates, both under the white-box and black-box scenarios. Furthermore, despite being an instance-agnostic perturbation function, our attack outperforms the conventionally much stronger instance-specific attack methods. © 2019 Neural information processing systems foundation. All rights reserved.",,Medical imaging; Data distribution; Different domains; Generation method; Internal parameters; Perturbation functions; Real-world attack; Security critical applications; State of the art; Deep neural networks,,,,,"Papernot, Nicolas, McDaniel, Patrick, Goodfellow, Ian, (2016) Transferability in machine learning: from phenomena to black-box attacks using adversarial samples, , arXiv preprint arXiv:1605.07277; Liu, Yanpei, Chen, Xinyun, Liu, Chang, Song, Dawn, Delving into transferable adversarial examples and black-box attacks (2017) Proceedings of 5th International Conference on Learning Representations; Tramèr, Florian, Papernot, Nicolas, Goodfellow, Ian, Boneh, Dan, McDaniel, Patrick, (2017) The space of transferable adversarial examples, , arXiv preprint arXiv:1704.03453; Fawzi, Alhussein, Fawzi, Omar, Frossard, Pascal, (2015) Analysis of classifiers' robustness to adversarial perturbations, , arXiv preprint arXiv:1502.02590; Fawzi, Alhussein, Dezfooli, Seyed-Mohsen Moosavi, Frossard, Pascal, Robustness of classifiers: from adversarial to random noise (2016) Advances in Neural Information Processing Systems, pp. 1632-1640; Goodfellow, Ian J, Shlens, Jonathon, Szegedy, Christian, (2014) Explaining and harnessing adversarial examples, , arXiv preprint arXiv:1412.6572; Kurakin, Alexey, Goodfellow, Ian, Bengio, Samy, (2016) Adversarial machine learning at scale, , arXiv preprint arXiv:1611.01236; Dezfooli, Seyed-Mohsen Moosavi, Fawzi, Alhussein, Frossard, Pascal, Deepfool: a simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2574-2582; Nguyen, Anh, Yosinski, Jason, Clune, Jeff, Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 427-436; Dong, Yinpeng, Pang, Tianyu, Su, Hang, Zhu, Jun, Evading defenses to transferable adversarial examples by translation-invariant attacks (2019) Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition; Li, Yingwei, Bai, Song, Xie, Cihang, Liao, Zhenyu, Shen, Xiaohui, Yuille, Alan L, (2019) Regional homogeneity: Towards learning transferable universal adversarial perturbations against defenses, , arXiv preprint arXiv:1904.00979; Dezfooli, Seyed-Mohsen Moosavi, Fawzi, Alhussein, Fawzi, Omar, Frossard, Pascal, Universal adversarial perturbations (2017) 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 86-94; Mopuri, Konda Reddy, Garg, Utsav, Venkatesh Babu, R, Fast feature fool: A data independent approach to universal adversarial perturbations (2017) Proceedings of the British Machine Vision Conference (BMVC); Mopuri, Konda Reddy, Uppala, Phani Krishna, Venkatesh Babu, R., Ask, acquire, and attack: Data-free uap generation using class impressions (2018) ECCV; Baluja, Shumeet, Fischer, Ian, (2017) Adversarial transformation networks: Learning to generate adversarial examples, , arXiv preprint arXiv:1703.09387; Poursaeed, Omid, Katsman, Isay, Gao, Bicheng, Belongie, Serge J., Generative adversarial perturbations (2018) 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 4422-4431; Szegedy, Christian, Zaremba, Wojciech, Sutskever, Ilya, Bruna, Joan, Erhan, Dumitru, Goodfellow, Ian, Fergus, Rob, Intriguing properties of neural networks (2014) International Conference on Learning Representations (ICRL); Xie, Cihang, Zhang, Zhishuai, Wang, Jianyu, Zhou, Yuyin, Ren, Zhou, Yuille, Alan Loddon, (2018) Improving transferability of adversarial examples with input diversity, , CoRR, abs/1803.06978; Song, Yang, Shu, Rui, Kushman, Nate, Ermon, Stefano, Constructing unrestricted adversarial examples with generative models (2018) Advances in Neural Information Processing Systems, pp. 8312-8323; Xiao, Chaowei, Li, Bo, Zhu, Jun-Yan, He, Warren, Liu, Mingyan, Song, Dawn, Generating adversarial examples with adversarial networks (2018) Proceedings of the 27th International Joint Conference on Artificial Intelligence, pp. 3905-3911. , AAAI Press; Jolicoeur-Martineau, Alexia, (2018) The relativistic discriminator: a key element missing from standard gan, , arXiv preprint arXiv:1807.00734; Johnson, Justin, Alahi, Alexandre, Fei-Fei, Li, Perceptual losses for real-time style transfer and super-resolution (2016) ECCV; Kingma, Diederik P, Ba, Jimmy, (2014) Adam: A method for stochastic optimization, , arXiv preprint arXiv:1412.6980; Simonyan, Karen, Zisserman, Andrew, (2014) Very deep convolutional networks for large-scale image recognition, , arXiv preprint arXiv:1409.1556; Szegedy, Christian, Vanhoucke, Vincent, Ioffe, Sergey, Shlens, Jon, Wojna, Zbigniew, Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2818-2826; He, Kaiming, Zhang, Xiangyu, Ren, Shaoqing, Sun, Jian, Deep residual learning for image recognition (2016) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770-778; Huang, Gao, Liu, Zhuang, Weinberger, Kilian Q., Densely connected convolutional networks (2017) 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2261-2269; Rajpurkar, Pranav, Irvin, Jeremy, Zhu, Kaylie, Yang, Brandon, Mehta, Hershel, Duan, Tony, Ding, Daisy, Ng, Andrew Y., Chexnet: Radiologist-level pneumonia detection on chest x-rays with deep learning (2017), CoRR, abs/1711.05225; (2017), https://www.kaggle.com/c/painter-by-numbers/data.Kaggle, Painter b; Bircanoglu, Cenk, (2017), https://www.kaggle.com/cenkbircanoglu/comic-books-classification.Kaggle; (2017), https://www.kaggle.com/c/nips-2017-defense-against-adversarial-attack/data.Kaggle, NeurIPS; Selvaraju, Ramprasaath R., Cogswell, Michael, Das, Abhishek, Vedantam, Ramakrishna, Parikh, Devi, Batra, Dhruv, Grad-cam: Visual explanations from deep networks via gradient-based localization (2017) 2017 IEEE International Conference on Computer Vision (ICCV), pp. 618-626; Geirhos, Robert, Rubisch, Patricia, Michaelis, Claudio, Bethge, Matthias, Wichmann, Felix A., Brendel, Wieland, Imagenet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness (2019) International Conference on Learning Representations; Tramèr, Florian, Kurakin, Alexey, Papernot, Nicolas, Boneh, Dan, McDaniel, Patrick, Ensemble adversarial training: Attacks and defenses (2018) International Conference on Learning Representations (ICRL); Szegedy, Christian, Ioffe, Sergey, Vanhoucke, Vincent, Alemi, Alexander A, Inception-v4, inceptionresnet and the impact of residual connections on learning (2017) AAAI, 4, p. 12; He, Kaiming, Zhang, Xiangyu, Ren, Shaoqing, Sun, Jian, Identity mappings in deep residual networks (2016) European conference on computer vision, pp. 630-645. , Springer",,,Citadel;Doc.AI;et al.;Lambda;Lyft;Microsoft Research,Neural information processing systems foundation,"33rd Annual Conference on Neural Information Processing Systems, NeurIPS 2019",8 December 2019 through 14 December 2019,,161263,10495258,,,,English,Adv. neural inf. proces. syst.,Conference Paper,Final,,Scopus,2-s2.0-85090172930
"Song C., Wang L., He K., Hopcroft J.E.",57210639361;55721280000;57204773777;6701837666;,Improving the generalization of adversarial training with domain adaptation,2019,"7th International Conference on Learning Representations, ICLR 2019",,,,,,,25,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083953819&partnerID=40&md5=09c0f4d10bf81b1cbf0fe51dfd00fcb9,"Department of Computer Science, Huazhong University of Science and Technology, Wuhan, 430074, China; Department of Machine Intelligence, Peking University, China; Department of Computer Science, Cornell University, Ithaca, NY  14850, United States","Song, C., Department of Computer Science, Huazhong University of Science and Technology, Wuhan, 430074, China; Wang, L., Department of Machine Intelligence, Peking University, China; He, K., Department of Computer Science, Huazhong University of Science and Technology, Wuhan, 430074, China; Hopcroft, J.E., Department of Computer Science, Cornell University, Ithaca, NY  14850, United States","By injecting adversarial examples into training data, adversarial training is promising for improving the robustness of deep learning models. However, most existing adversarial training approaches are based on a specific type of adversarial attack. It may not provide sufficiently representative samples from the adversarial domain, leading to a weak generalization ability on adversarial examples from other attacks. Moreover, during the adversarial training, adversarial perturbations on inputs are usually crafted by fast single-step adversaries so as to scale to large datasets. This work is mainly focused on the adversarial training yet efficient FGSM adversary. In this scenario, it is difficult to train a model with great generalization due to the lack of representative adversarial samples, aka the samples are unable to accurately reflect the adversarial domain. To alleviate this problem, we propose a novel Adversarial Training with Domain Adaptation (ATDA) method. Our intuition is to regard the adversarial training on FGSM adversary as a domain adaption task with limited number of target domain samples. The main idea is to learn a representation that is semantically meaningful and domain invariant on the clean domain as well as the adversarial domain. Empirical evaluations on Fashion-MNIST, SVHN, CIFAR-10 and CIFAR-100 demonstrate that ATDA can greatly improve the generalization of adversarial training and the smoothness of the learned models, and outperforms state-of-the-art methods on standard benchmark datasets. To show the transfer ability of our method, we also extend ATDA to the adversarial training on iterative attacks such as PGD-Adversial Training (PAT) and the defense performance is improved considerably. © 7th International Conference on Learning Representations, ICLR 2019. All Rights Reserved.",,Iterative methods; Large dataset; Benchmark datasets; Domain adaptation; Domain adaptions; Empirical evaluations; Generalization ability; Learning models; Representative sample; State-of-the-art methods; Deep learning,,,,,"Arpit, D., Jastrzebski, S.K., Ballas, N., Krueger, D., Bengio, E., Kanwal, M.-D.S., Maharaj, T., Lacoste-Julien, S., A closer look at memorization in deep networks (2017) Proceedings of the 34th International Conference on Machine Learning, ICML 2017, pp. 233-242. , Sydney, NSW, Australia, 6-11 August 2017; Borgwardt, K.M., Gretton, A., Rasch, M.J., Kriegel, H.-P., Schölkopf, B., Smola, A.J., Integrating structured biological data by kernel maximum mean discrepancy (2006) Bioinformatics, 22 (14), pp. e49-e57; Clevert, D.-A., Unterthiner, T., Hochreiter, S., (2015) Fast and Accurate Deep Network Learning by Exponential Linear Units (Elus), , arXiv preprint; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2018) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , June; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images, , Technical report, Citeseer; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Machine Learning at Scale, , arXiv preprint; Liao, F., Liang, M., Dong, Y., Pang, T., Zhu, J., Hu, X., Defense against adversarial attacks using high-level representation guided denoiser (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1778-1787; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) International Conference on Learning Representations(ICLR); Van Der Maaten, L., Hinton, G., Visualizing data using t-sne (2008) Journal of Machine Learning Research, 9, pp. 2579-2605. , Nov; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) International Conference on Learning Representations(ICLR); Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., Ng, A.Y., Reading digits in natural images with unsupervised feature learning (2011) NIPS Workshop on Deep Learning and Unsupervised Feature Learning, p. 5. , 2011; Nøkland, A., (2015) Improving Back-Propagation by Adding an Adversarial Gradient, , arXiv preprint; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Li, F.-F., Imagenet large scale visual recognition challenge (2015) International Journal of Computer Vision, 115 (3), pp. 211-252; Sun, B., Saenko, K., Deep coral: Correlation alignment for deep domain adaptation (2016) European Conference on Computer Vision, pp. 443-450; Szegedy, C., Inc, G., Zaremba, W., Sutskever, I., Inc, G., Bruna, J., Erhan, D., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations(ICLR); Tabacof, P., Valle, E., Exploring the space of adversarial images (2016) 2016 International Joint Conference on Neural Networks (IJCNN), pp. 426-433; Torralba, A., Efros, A.A., Unbiased look at dataset bias (2011) Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on, pp. 1521-1528; Tramèr, F., Papernot, N., Goodfellow, I.J., Boneh, D., McDaniel, P.D., (2017) The Space of Transferable Adversarial Examples, , arXiv preprint; Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2018) International Conference on Learning Representations; Wen, Y., Zhang, K., Li, Z., Qiao, Y., A discriminative feature learning approach for deep face recognition (2016) European Conference on Computer Vision, pp. 499-515; Wong, E., Zico Kolter, J., Provable defenses against adversarial examples via the convex outer adversarial polytope (2018) Proceedings of the 35th International Conference on Machine Learning, ICML 2018, pp. 5283-5292. , Stockholmsmässan, Stockholm, Sweden, July 10-15, 2018; Wu, Y., He, K., (2018) Group Normalization, , arXiv preprint; Xiao, H., Rasul, K., Vollgraf, R., (2017) Fashion-Mnist: A Novel Image Dataset for Benchmarking Machine Learning Algorithms, , arXiv preprint","He, K.; Department of Computer Science, China; 电子邮件: brooklet60@hust.edu.cn",,,"International Conference on Learning Representations, ICLR","7th International Conference on Learning Representations, ICLR 2019",6 May 2019 through 9 May 2019,,149936,,,,,English,"Int. Conf. Learn. Represent., ICLR",Conference Paper,Final,,Scopus,2-s2.0-85083953819
"Jacobsen J.-H., Behrmann J., Zemel R., Bethge M.",56799939300;57201698451;7004912699;57210225326;,Excessive invariance causes adversarial vulnerability,2019,"7th International Conference on Learning Representations, ICLR 2019",,,,,,,23,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083952960&partnerID=40&md5=ea622324dfbc01a687d1de12fb8bfbd3,"Vector Institute and University of Toronto, Canada; University of Bremen, Center for Industrial Mathematics, Germany; University of Tübingen, Germany","Jacobsen, J.-H., Vector Institute and University of Toronto, Canada; Behrmann, J., Vector Institute and University of Toronto, Canada, University of Bremen, Center for Industrial Mathematics, Germany; Zemel, R., Vector Institute and University of Toronto, Canada; Bethge, M., University of Tübingen, Germany","Despite their impressive performance, deep neural networks exhibit striking failures on out-of-distribution inputs. One core idea of adversarial example research is to reveal neural network errors under such distribution shifts. We decompose these errors into two complementary sources: sensitivity and invariance. We show deep networks are not only too sensitive to task-irrelevant changes of their input, as is well-known from -adversarial examples, but are also too invariant to a wide range of task-relevant changes, thus making vast regions in input space vulnerable to adversarial attacks. We show such excessive invariance occurs across various tasks and architecture types. On MNIST and ImageNet one can manipulate the class-specific content of almost any image without changing the hidden activations. We identify an insufficiency of the standard cross-entropy loss as a reason for these failures. Further, we extend this objective based on an information-theoretic analysis so it encourages the model to consider all task-dependent features in its decision. This provides the first approach tailored explicitly to overcome excessive invariance and resulting vulnerabilities. © 7th International Conference on Learning Representations, ICLR 2019. All Rights Reserved.",,Information theory; Cross entropy; Information-theoretic analysis; Input space; Task relevant; Deep neural networks,,,,,"Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Isard, M., TensorFlow: A system for large-scale machine learning (2016) OSDI, 16, pp. 265-283; Achille, A., Soatto, S., Emergence of invariance and disentanglement in deep representations (2018) Journal of Machine Learning Research, 18; Alemi, A.A., Fischer, I., Dillon, J.V., Murphy, K., Deep variational information bottleneck (2017) International Conference on Lerning Representations; Alemi, A.A., Poole, B., Fischer, I., Dillon, J.V., Saurous, R.A., Murphy, K., An information-theoretic analysis of deep latent-variable models (2018) Proceedings of the 35th International Conference on Machine Learning; Ardizzone, L., Kruse, J., Rother, C., Kthe, U., Analyzing inverse problems with invertible neural networks (2019) International Conference on Learning Representations; Barber, D., Agakov, F., The im algorithm: A variational approach to information maximization (2003) Advances in Neural Information Processing Systemss; Behrmann, J., Dittmer, S., Fernsel, P., Maaß, P., (2018) Analysis of Invariance and Robustness Via Invertibility of Relu-Networks, , arXiv preprint; Behrmann, J., Duvenaud, D., Jacobsen, J.-H., (2018) Invertible Residual Networks, , arXiv preprint; Belghazi, M.I., Baratin, A., Rajeshwar, S., Ozair, S., Bengio, Y., Hjelm, D., Courville, A., Mutual information neural estimation (2018) Proceedings of the 35th International Conference on Machine Learning; Brendel, W., Rauber, J., Kurakin, A., Papernot, N., Veliqi, B., Salathé, M., Mohanty, S.P., Bethge, M., (2018) Adversarial Vision Challenge, , arXiv preprint; Brown, T.B., Carlini, N., Zhang, C., Olsson, C., Christiano, P., Goodfellow, I., (2018) Unrestricted Adversarial Examples, , arXiv preprint; Bubeck, S., Price, E., Razenshteyn, I., (2018) Adversarial Examples from Computational Constraints, , arXiv preprint; Chen, X., Duan, Y., Houthooft, R., Schulman, J., Sutskever, I., Abbeel, P., Infogan: Interpretable representation learning by information maximizing generative adversarial nets (2016) Advances in Neural Information Processing Systems; Cimpoi, M., Maji, S., Kokkinos, I., Mohamed, S., Vedaldi, A., Describing textures in the wild (2014) Proceedings of the IEEE Conf. On Computer Vision and Pattern Recognition (CVPR); Cover, T.M., Thomas, J.A., (2006) Elements of Information Theory (Wiley, , Series in Telecommunications and Signal Processing). Wiley-Interscience, New York, NY, USA, ISBN; Dinh, L., Sohl-Dickstein, J., Bengio, S., Density estimation using real nvp (2017) International Conference on Learning Representations; Fawzi, A., Fawzi, H., Fawzi, O., Adversarial vulnerability for any classifier (2018) Advances in Neural Information Processing Systems, 31; Gatys, L.A., Ecker, A.S., Bethge, M., Texture and art with deep neural networks (2017) Current Opinion in Neurobiology, 46, pp. 178-186; Ghassami, A., Kiyavash, N., (2017) Interaction Information for Causal Inference: The Case of Directed Triangle, , arXiv preprint; Gilmer, J., Adams, R.P., Goodfellow, I., Andersen, D., Dahl, G.E., (2018) Motivating the Rules of the Game for Adversarial Example Research, , arXiv preprint; Gilmer, J., Metz, L., Faghri, F., Schoenholz, S.S., Raghu, M., Watten-Berg, M., Goodfellow, I., (2018) Adversarial Spheres, , arXiv preprint; Gomez, A.N., Ren, M., Urtasun, R., Grosse, R.B., The reversible residual network: Backpropagation without storing activations (2017) Advances in Neural Information Processing Systems; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, pp. 2672-2680; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations; Grathwohl, W., Chen, R.T.Q., Bettencourt, J., Duvenaud, D., Scalable reversible generative models with free-form continuous dynamics (2019) International Conference on Learning Representations; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Hjelm, D., Fedorov, A., Lavoie-Marchildon, S., Grewal, K., Bachman, P., Trischler, A., Bengio, Y., Learning deep representations by mutual information estimation and maximization (2019) International Conference on Learning Representations; Hyvärinen, A., Hoyer, P., Emergence of phase-and shift-invariant features by decomposition of natural images into independent feature subspaces (2000) Neural Computation, 12 (7), pp. 1705-1720; Jacobsen, J.-H., Smeulders, A.W.M., Oyallon, E., I-revnet: Deep invertible networks (2018) International Conference on Learning Representations; Jo, J., Bengio, Y., (2017) Measuring the Tendency of Cnns to Learn Surface Statistical Regularities, , arXiv preprint; Kingma, D.P., Ba, J., (2014) Adam: A Method for Stochastic Optimization, , arXiv preprint; Kingma, D.P., Dhariwal, P., Glow: Generative flow with invertible 1x1 convolutions (2018) Advances in Neural Information Processing Systems, 31; Kraskov, A., Stögbauer, H., Grassberger, P., Estimating mutual information (2004) Physical Review E, 69; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), pp. 436-444; Louizos, C., Swersky, K., Li, Y., Welling, M., Zemel, R.S., (2015) The Variational Fair Autoencoder, , arXiv preprint; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2017) International Conference on Learning Representations; Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., Lin, Z., Lerer, A., (2017) Automatic Differentiation in Pytorch; Pereyra, G., Tucker, G., Chorowski, J., Kaiser, L., Hinton, G.E., Regularizing neural networks by penalizing confident output distributions (2017) International Conference on Lerning Representations (Workshop); Raghunathan, A., Steinhardt, J., Liang, P., Certified defenses against adversarial examples (2018) International Conference on Learning Representations; Sabour, S., Cao, Y., Faghri, F., Fleet, D.J., Adversarial manipulation of deep representations (2016) International Conference on Learning Representations; Schmidhuber, J., (1991) Learning Factorial Codes by Predictability Minimization, , Technical report, Dept. of Comp. Sci., University of Colorado at Boulder; Schmidt, L., Santurkar, S., Tsipras, D., Talwar, K., Madry, A., Adver-sarially robust generalization requires more data (2018) Advances in Neural Information Processing Systems, 31; Shwartz-Ziv, R., Tishby, N., (2017) Opening the Black Box of Deep Neural Networks Via Information, , arXiv preprint; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-Scale Image Recognition, , arXiv preprint; Song, Y., Shu, R., Kushman, N., Ermon, S., Constructing unrestricted adversarial examples with generative models (2018) Advances in Neural Information Processing Systems, 31; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint; Tishby, N., Zaslavsky, N., Deep learning and the information bottleneck principle (2015) Information Theory Workshop (ITW), 2015 IEEE, pp. 1-5; Tsipras, D., Santurkar, S., Engstrom, L., Turner, A., Madry, A., Robustness may be at odds with accuracy (2019) International Conference on Learning Representations",,,,"International Conference on Learning Representations, ICLR","7th International Conference on Learning Representations, ICLR 2019",6 May 2019 through 9 May 2019,,149936,,,,,English,"Int. Conf. Learn. Represent., ICLR",Conference Paper,Final,,Scopus,2-s2.0-85083952960
"Wong E., Schmidt F.R., Zico Kolter J.",57155743900;56954458900;36873773800;,Wasserstein adversarial examples via projected sinkhorn iterations,2019,"36th International Conference on Machine Learning, ICML 2019",2019-June,,,11812,11825,,12,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078235960&partnerID=40&md5=4a1f047084491c4519661b4142f778a8,"Machine Learning Department, Carnegie Mellon University, Pittsburgh, PA, United States; Bosch Center for Artificial Intelligence, Renningen, Germany; Computer Science Department, Carnegie Mellon University, Pittsburgh, PA, United States; Bosch Center for Artificial Intelligence, Pittsburgh, PA, United States","Wong, E., Machine Learning Department, Carnegie Mellon University, Pittsburgh, PA, United States; Schmidt, F.R., Bosch Center for Artificial Intelligence, Renningen, Germany; Zico Kolter, J., Computer Science Department, Carnegie Mellon University, Pittsburgh, PA, United States, Bosch Center for Artificial Intelligence, Pittsburgh, PA, United States","A rapidly growing area of work has studied the existence of adversarial examples, datapoints which have been perturbed to fool a classifier, but the vast majority of these works have focused primarily on threat models defined by lv norm-bounded perturbations. In this paper, we propose a new threat model for adversarial attacks based on the Wasserstein distance in image space. In the image classification setting, such distances measure the cost of moving pixel mass, which can naturally represent ""standard"" image manipulations such as scaling, rotation, translation, and distortion (and can potentially be applied to other settings as well). To generate Wasserstein adversarial examples, we develop a procedure for approximate projection onto the Wasserstein ball, based upon a modified version of the Sinkhorn iteration. The resulting algorithm can successfully attack image classification models, bringing traditional CIFAR10 models down to 3% accuracy within a Wasserstein ball with radius 0.1 (i.e., moving 10% of the image mass 1 pixel), and we demonstrate that PGD-based adversarial training can improve this adversarial accuracy to 76%. In total, this work opens up a new direction of study in adversarial robustness, more formally considering convex metrics that accurately capture the invariances that we typically believe should exist in classifiers, and code for all experiments in the paper is available at https://gi thub.com/locuslab/projected-sinkhorn. Copyright © 2019 ASME",,Image enhancement; Iterative methods; Machine learning; Pixels; Approximate projection; Classification models; Convex metrics; Image manipulation; Norm-bounded perturbation; Threat modeling; Threat models; Wasserstein distance; Image classification,,,,,"Altschuler, J., Weed, J., Rigollet, P., Near-linear time approximation algorithms for optimal transport via sinkhorn iteration (2017) Advances in Neural Information Processing Systems, pp. 1964-1974; Athalye, A., Carlini, N., Wagner, D., Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples (2018) Proceedings of the 35th International Conference on Machine Learning, ICML 2018, , https://arxiv.org/abs/1802.00420, July; Athalye, A., Engstrom, L., Ilyas, A., Kwok, K., Synthesizing robust adversarial examples (2018) Proceedings of the 35th International Conference on Machine Learning, Volume 80 of Proceedings of Machine Learning Research, pp. 284-293. , http://proceedings.mlr.press/v80/athalyel8b.html, Dy, J. and Krause, A. eds, Stockholmsmssan, Stockholm Sweden, 10-15 Jul PMLR. URL; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium on, pp. 39-57; Chizat, L., Pcyrc, G., Schmitzer, B., Vialard, F.-X., (2016) Scaling Algorithms for Unbalanced Transport Problems, , arXiv preprint 2016; Croce, F., Andriushchenko, M., Hein, M., Provable robustness of relu networks via maximization of linear regions (2018) CoRR, , http://arxiv.org/abs/1810.07481, abs/1810.07481; Cuturi, M., Sinkhorn distances: Lightspeed computation of optimal transport (2013) Advances in Neural Information Processing Systems, 26, pp. 2292-2300. , http://papers.nips.ee/paper/4927-sinkhorn-distances-lightspeed-computation-of-optimal-transport.pdf, Burges, C. J. C, Bottou, L., Welling, M., Ghahramani, Z., and Weinberger, K. Q. eds, Curran Associates, Inc; Dvijotham, K., Stanforth, R., Gowal, S., Mann, T., Kohli, P., A dual approach to scalable verification of deep networks (2018) Proceedings of the Thirty-Fourth Conference Annual Conference on Uncertainty in Artificial Intelligence (UAI-18), pp. 162-171. , Corvallis, Oregon, AUAI Press; Engstrom, L., Tran, B., Tsipras, D., Schmidt, L., Madry, A., (2017) A Rotation and a Translation Suffice: Fooling Enns with Simple Transformations, , arXiv preprint; Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Xiao, C., Prakash, A., Song, D., Robust physical-world attacks on deep learning visual classification (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1625-1634; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations, , http://arxiv.org/abs/1412.6572; Gowal, S., Dvijotham, K., Stanforth, R., Bunel, R., Qin, C., Uesato, J., Arandjelovic, R., Kohli, P., On the effectiveness of interval bound propagation for training verifiably robust models (2018) CoRR, , http://arxiv.org/abs/1810.12715, abs/1810.12715; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Jordan, R., Kinderlehrer, D., Otto, F., The variational formulation of the fokker-planck equation (1998) SIAM Journal on Mathematical Analysis, 29 (1), pp. 1-17; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2017) ICLR Workshop, , https://arxiv.org/abs/1607.02533; Lu, J., Sibai, H., Fabry, E., Forsyth, D., (2017) No Need to Worry about Adversarial Examples in Object Detection in Autonomous Vehicles, , arXiv preprint; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=rJzIBfZAb; Mirman, M., Gehr, T., Vechev, M., Differentiable abstract interpretation for provably robust neural networks (2018) International Conference on Machine Learning (ICML), , https://www.icml.cc/Conferences/2018/Schedule?showEvent=2477; Papcrnot, N., McDanicl, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Security and Privacy (SP), 2016 IEEE Symposium on, pp. 582-597; Peleg, S., Werman, M., Rom, H., A unified approach to the change of resolution: Space and gray-level (1989) IEEE Transactions on Pattern Analysis and Machine Intelligence, 11 (7), pp. 739-742; Peyre, G., Entropic approximation of wasserstein gradient flows (2015) SIAM Journal on Imaging Sciences, 8 (4), pp. 2323-2351; Raghunathan, A., Steinhardt, J., Liang, P.S., Semidefinite relaxations for certifying robustness to adversarial examples (2018) Advances in Neural Information Processing Systems, 31, pp. 10900-10910. , http://papers.nips.cc/paper/8285-semidefinite-relaxations-for-certifying-robustness-to-adversarial-examples.pdf, Bengio, S., Wallach, H., Larochelle, H., Grauman, K., Cesa-Bianchi, N., and Garnett, R. eds, Curran Associates, Inc; Rubncr, Y., Tomasi, C., Guibas, L.J., The earth mover's distance as a metric for image retrieval (2000) International Journal of Computer Vision, 40 (2), pp. 99-121; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., (2017) Adversarial Generative Nets: Neural Network Attacks on State-of-The-Art Face Recognition, , arXiv preprint; Sinha, A., Namkoong, H., Duchi, J., (2018) Certifying Some Distributional Robustness with Principled Adversarial Training; Snow, M., (2016) Monge's Optimal Transport Distance for Image Classification, , arXiv preprint; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations, , http://arxiv.org/abs/1312.6199; Tjeng, V., Xiao, K.Y., Tedrake, R., Evaluating robustness of neural networks with mixed integer programming (2019) International Conference on Learning Representations, , https://openreview.net/forum?id=HyGIdiRqtm; Wong, E., Kolter, Z., Provable defenses against adversarial examples via the convex outer adversarial polytope (2018) International Conference on Machine Learning, pp. 5283-5292; Wong, E., Schmidt, E., Metzen, J.H., Kolter, J.Z., Scaling provable adversarial defenses (2018) Advances in Neural Information Processing Systems, 31, pp. 8410-8419. , http://papers.nips.ee/paper/8060-scaling-provable-adversarial-defenses.pdf, Bengio, S., Wallach, H., Larochelle, H., Grauman, K., Cesa-Bianchi, N., and Garnett, R. eds, Curran Associates, Inc; Xiao, C., Zhu, J.-Y., Li, B., He, W., Liu, M., Song, D., (2018) Spatially Transformed Adversarial Examples, , arXiv preprintarXiv; Xiao, K.Y., Tjeng, V., Shafiullah, N.M.M., Madry, A., Training for faster adversarial robustness verification via inducing reLU stability (2019) International Conference on Learning Representations, , https://openreview.net/forum?id=BJfIVjAcKm","Wong, E.; Machine Learning Department, United States; 电子邮件: ericwong@cs.cmu.edu",,,International Machine Learning Society (IMLS),"36th International Conference on Machine Learning, ICML 2019",9 June 2019 through 15 June 2019,,156104,,9.78E+12,,,English,"Int. Conf. Mach. Learn., ICML",Conference Paper,Final,,Scopus,2-s2.0-85078235960
[无可用作者姓名],[无可用的作者 ID],"15th International Conference on Information Systems Security, ICISS 2019",2019,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),11952 LNCS,,,,,344,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076928484&partnerID=40&md5=ec7225cb6139c792c80ad21a9b160b23,,,The proceedings contain 18 papers. The special focus in this conference is on Information Systems Security. The topics include: Cloud Data Sharing and Device-Loss Recovery with Hardware-Bound Keys; item-Based Privacy-Preserving Recommender System with Offline Users and Reduced Trust Requirements; wip: Degree Evaluation of Grain-v1; a Novel k-Anonymization Approach to Prevent Insider Attack in Collaborative Social Network Data Publishing; wiP: Security Enhanced Size Invariant Visual Cryptography with Perfect Reconstruction of White Pixels; a New High Capacity and Reversible Data Hiding Technique for Images; Anti-forensics of a NAD-JPEG Detection Scheme Using Estimation of DC Coefficients; differential Attack Graph-Based Approach for Assessing Change in the Network Attack Surface; wiP: Criminal Smart Contract for Private Key Theft in End to End Encrypted Applications; Trustworthy Isolation of DMA Enabled Devices; Toward Implementing Spatio-Temporal RBAC Extensions; VisMAP: Visual Mining of Attribute-Based Access Control Policies; policy Reconciliation and Migration in Attribute Based Access Control; wiP: Generative Adversarial Network for Oversampling Data in Credit Card Fraud Detection; an Introduction to the CellTree Paradigm (Invited Paper); Secure Information Flow Analysis Using the PRISM Model Checker.,,,,,,,,,Garg D.Kumar N.V.Shyamasundar R.K.,,Springer,"15th International Conference on Information Systems Security, ICISS 2019",16 December 2019 through 20 December 2019,,235029,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Review,Final,,Scopus,2-s2.0-85076928484
"Yu F., Qin Z., Liu C., Zhao L., Wang Y., Chen X.",57203734488;57201128558;56393438200;56355436400;36555062200;54398338300;,Interpreting and evaluating neural network robustness,2019,IJCAI International Joint Conference on Artificial Intelligence,2019-August,,,4199,4205,,8,10.24963/ijcai.2019/583,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074954059&doi=10.24963%2fijcai.2019%2f583&partnerID=40&md5=333aab164a24f8dda2828a0bbb2e12f5,"George Mason University, United States; University of Maryland, Baltimore County, United States; Northeastern University, United States","Yu, F., George Mason University, United States; Qin, Z., George Mason University, United States; Liu, C., University of Maryland, Baltimore County, United States; Zhao, L., George Mason University, United States; Wang, Y., Northeastern University, United States; Chen, X., George Mason University, United States","Recently, adversarial deception becomes one of the most considerable threats to deep neural networks. However, compared to extensive research in new designs of various adversarial attacks and defenses, the neural networks' intrinsic robustness property is still lack of thorough investigation. This work aims to qualitatively interpret the adversarial attack and defense mechanism through loss visualization, and establish a quantitative metric to evaluate the neural network model's intrinsic robustness. The proposed robustness metric identifies the upper bound of a model's prediction divergence in the given domain and thus indicates whether the model can maintain a stable prediction. With extensive experiments, our metric demonstrates several advantages over conventional adversarial testing accuracy based robustness estimation: (1) it provides a uniformed evaluation to models with different structures and parameter scales; (2) it over-performs conventional accuracy based robustness estimation and provides a more reliable evaluation that is invariant to different test settings; (3) it can be fast generated without considerable testing cost. © 2019 International Joint Conferences on Artificial Intelligence. All rights reserved.",,,,,,,"Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP), pp. 39-57; Dinh, L., Pascanu, R., Bengio, S., Bengio, Y., Sharp minima can generalize for deep nets (2017) International Conference on Machine Learning, pp. 1019-1028; Goodfellow, I.J., Vinyals, O., Saxe, A.M., Qualitatively characterizing neural network optimization problems (2015) International Conference on Learning Representations (ICLR); Hinton, G., Deng, L., Yu, D., Dahl, G., Mohamed, A.-R., Jaitly, N., Senior, A., Kingsbury, B., Deep neural networks for acoustic modeling in speech recognition (2012) IEEE Signal Processing Magazine, 29; Huval, B., Wang, T., Tan-Don, S., Kiske, J., Song, W., Pazhayampallil, J., Andriluka, M., Cheng-Yue, R., (2015) An Empirical Evaluation of Deep Learning on Highway Driving, , arXiv preprint; Goodfellow, C.S.I.J., Shlens, J., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint; Kannan, H., Kurakin, A., Goodfellow, I., (2018) Adversarial Logit Pairing, , arXiv preprint; Keskar, N.S., Mudigere, D., Nocedal, J., Smelyanskiy, M., Tak Peter Tang, P., On large-batch training for deep learning: Generalization gap and sharp minima (2017) International Conference on Learning Representations (ICLR); Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint; Liu, Q., Liu, T., Liu, Z., Wang, Y., Jin, Y., Wen, W., Security analysis and enhancement of model compressed deep learning systems under adversarial attacks (2018) Proceedings of the 23rd Asia and South Pacific Design Automation Conference, pp. 721-726. , IEEE Press; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2018) Towards Deep Learning Models Resistant to Adversarial Attacks; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) 2016 IEEE Symposium on Security and Privacy (SP), pp. 582-597; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519; Ross, A.S., Doshi-Velez, F., Improving the adversarial robustness and interpretability of deep neural networks by regularizing their input gradients (2018) AAAI; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826; Xie, C., Wu, Y., Van Der Maaten, L., Yuille, A., He, K., (2018) Feature Denoising for Improving Adversarial Robustness, , arXiv preprint",,Kraus S.,Baidu;et al.;Huawei;International Joint Conferences on Artifical Intelligence (IJCAI);Sony;Xiao-i,International Joint Conferences on Artificial Intelligence,"28th International Joint Conference on Artificial Intelligence, IJCAI 2019",10 August 2019 through 16 August 2019,,153611,10450823,9.78E+12,,,English,IJCAI Int. Joint Conf. Artif. Intell.,Conference Paper,Final,"All Open Access, Bronze, Green",Scopus,2-s2.0-85074954059
Jha S.,23476883200;,"Trust, Resilience and Interpretability of AI Models",2019,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),11652 LNCS,,,3,25,,1,10.1007/978-3-030-28423-7_1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070676741&doi=10.1007%2f978-3-030-28423-7_1&partnerID=40&md5=3b79b0d470199969191dfa34c3cce5e7,"Computer Science Laboratory, SRI International, Menlo Park, United States","Jha, S., Computer Science Laboratory, SRI International, Menlo Park, United States","In this tutorial, we present our recent work on building trusted, resilient and interpretable AI models by combining symbolic methods developed for automated reasoning with connectionist learning methods that use deep neural networks. The increasing adoption of artificial intelligence and machine learning in systems, including safety-critical systems, has created a pressing need for developing scalable techniques that can be used to establish trust over their safe behavior, resilience to adversarial attacks, and interpretability to enable human audits. This tutorial is comprised of three components: review of techniques for verification of neural networks, methods for using geometric invariants to defend against adversarial attacks, and techniques for extracting logical symbolic rules by reverse engineering machine learning models. These techniques form the core of TRINITY: Trusted, Resilient and Interpretable AI framework being developed at SRI. In this tutorial, we identify the key challenges in building the TRINITY framework, and report recent results on each of these three fronts. © 2019, Springer Nature Switzerland AG.",,Deep neural networks; Machine components; Machine learning; Reverse engineering; Safety engineering; Automated reasoning; Engineering machines; Geometric invariant; Interpretability; Learning methods; Safety critical systems; Symbolic methods; Three component; Verification,,,,,"Abouzied, A., Angluin, D., Papadimitriou, C., Hellerstein, J.M., Silberschatz, A., Learning and verifying quantified boolean queries by example (2013) ACM Symposium on Principles of Database Systems, pp. 49-60. , pp., ACM; Angluin, D., Computational learning theory: Survey and selected bibliography (1992) ACM Symposium on Theory of Computing, pp. 351-369. , pp., ACM; Angluin, D., Kharitonov, M., When won’t membership queries help? (1991) ACM Symposium on Theory of Computing, pp. 444-454. , pp., ACM; Athalye, A., Carlini, N., Wagner, D., (2018) Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples, , arXiv preprint arXiv; Bengio, Y., Mesnil, G., Dauphin, Y., Rifai, S., Better mixing via deep representations (2013) International Conference on Machine Learning, pp. 552-560. , pp; Bittner, B., Bozzano, M., Cimatti, A., Gario, M., Griggio, A., Towards pareto-optimal parameter synthesis for monotonie cost functions (2014) FMCAD, pp. 23-30. , pp., October; Boigelot, B., Godefroid, P., Automatic synthesis of specifications from the dynamic observation of reactive programs (1997) TACAS 1997. LNCS, 1217, pp. 321-333. , https://doi.org/10.1007/BFb0035397, Brinksma, E. (ed.), pp., Springer, Heidelberg; Botinčan, M., Babić, D., Sigma*: Symbolic learning of input-output specifications (2013) POPL, pp. 443-456. , https://doi.org/10.1145/2429069.2429123, pp; Carlini, N., Wagner, D., (2016) Towards Evaluating the Robustness of Neural Networks, , arXiv preprint arXiv; Cook, B., Kroening, D., Rümmer, P., Wintersteiger, C.M., Ranking function synthesis for bit-vector relations (2013) FMSD, 43 (1), pp. 93-120. , https://doi.org/10.1007/s10703-013-0186-4; Dutta, S., Jha, S., Sankaranarayanan, S., Tiwari, A., Learning and verification of feedback control systems using feedforward neural networks (2018) Ifac-Papersonline, 51 (16), pp. 151-156; Dutta, S., Jha, S., Sankaranarayanan, S., Tiwari, A., Output range analysis for deep feedforward neural networks (2018) NFM 2018. LNCS, 10811, pp. 121-138. , https://doi.org/10.1007/978-3-319-77935-5_9, Dutle, A., Muñoz, C., Narkawicz, A. (eds.); Ehrenfeucht, A., Haussler, D., Kearns, M., Valiant, L., A general lower bound on the number of examples needed for learning (1989) Inf. Comput., 82 (3), pp. 247-261. , https://doi.org/10.1016/0890-5401(89)90002-3; Elizalde, F., Sucar, E., Noguez, J., Reyes, A., Generating explanations based on Markov decision processes (2009) MICAI 2009. LNCS, 5845, pp. 51-62. , https://doi.org/10.1007/978-3-642-05258-3_5, Aguirre, A.H., Borja, R.M., Garciá, C.A.R.(eds.), pp., Springer, Heidelberg; Feng, C., Muggleton, S., Towards inductive generalisation in higher order logic (2014) 9Th International Workshop on Machine Learning, pp. 154-162. , pp; Gardner, J.R., (2015) Deep Manifold Traversal: Changing Labels with Convolutional Features, , arXiv preprint arXiv; Godefroid, P., Taly, A., Automated synthesis of symbolic instruction encodings from I/O samples (2012) SIGPLAN Not, 47 (6), pp. 441-452. , https://doi.org/10.1145/2345156.2254116; Goldsmith, J., Sloan, R.H., Szörényi, B., Turán, G., Theory revision with queries: Horn, read-once, and parity formulas (2004) Artif. Intell., 156 (2), pp. 139-176; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint arXiv; Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., (2017) On the (Statistical) Detection of Adversarial Examples, , arXiv preprint arXiv; Gurfinkel, A., Belov, A., Marques-Silva, J., Synthesizing safe bit-precise invariants (2014) TACAS 2014. LNCS, 8413, pp. 93-108. , https://doi.org/10.1007/978-3-642-54862-8_7, Ábrahám, E., Havelund, K.(eds.), pp., Springer, Heidelberg; Harbers, M., Meyer, J.J., van den Bosch, K., Explaining simulations through self explaining agents (2010) J. Artif. Soc. Soc. Simul., , http://EconPapers.repec.org/RePEc:jas:jasssj:2009-25-1; Hellerstein, L., Servedio, R.A., On PAC learning algorithms for rich boolean function classes (2007) Theoret. Comput. Sci., 384 (1), pp. 66-76; Hinton, G., Vinyals, O., Dean, J., (2015) Distilling the Knowledge in a Neural Network, , arXiv preprint arXiv; Jha, S., Gulwani, S., Seshia, S.A., Tiwari, A., Oracle-guided component-based program synthesis (2010) ICSE, pp. 215-224; Jha, S., Jang, U., Jha, S., Jalaian, B., Detecting adversarial examples using data manifolds (2018) 2018 IEEE Military Communications Conference (MILCOM), MIL-COM 2018, pp. 547-552; Jha, S., Raman, V., Pinto, A., Sahai, T., Francis, M., On learning sparse boolean formulae for explaining AI decisions (2017) NFM 2017. LNCS, 10227, pp. 99-114. , https://doi.org/10.1007/978-3-319-57288-8_7, Barrett, C., Davies, M., Kahsai, T. (eds.); Jha, S., Sahai, T., Raman, V., Pinto, A., Francis, M., Explaining AI decisions using efficient methods for learning sparse boolean formulae (2018) J. Autom. Reason., pp. 1-21; Jha, S., Seshia, S.A., A theory of formal synthesis via inductive learning (2016) Acta Informatica, 54, pp. 693-726. , Special Issue on Synthesis; Jones, M.C., Marron, J.S., Sheather, S.J., A brief survey of bandwidth selection for density estimation (1996) J. Am. Stat. Assoc., 91 (433), pp. 401-407; Kannan, H., Kurakin, A., Goodfellow, I., (2018) Adversarial Logit Pairing, , arXiv preprint arXiv; Katz, G., Barrett, C., Dill, D.L., Julian, K., Kochenderfer, M.J., Reluplex: An efficient SMT solver for verifying deep neural networks (2017) CAV 2017. LNCS, 10426, pp. 97-117. , https://doi.org/10.1007/978-3-319-63387-9_5, Majumdar, R., Kunčak, V.(eds.), pp., Springer, Cham; Kearns, M., Li, M., Valiant, L., Learning boolean formulas (1994) J. ACM, 41 (6), pp. 1298-1328; Kearns, M., Valiant, L., Cryptographic limitations on learning boolean formulae and finite automata (1994) J. ACM (JACM), 41 (1), pp. 67-95; Kos, J., Fischer, I., Song, D., (2017) Adversarial Examples for Generative Models, , arXiv preprint arXiv; Krizhevsky, A., Nair, V., Hinton, G., (2014) The CIFAR-10 Dataset, , http://www.cs.toronto.edu/kriz/cifar.html; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint arXiv; Lavalle, S.M., (2006) Planning Algorithms, , Cambridge University Press, Cambridge; Lecun, Y., (1998) The MNIST Database of Handwritten Digits, , http://yann.lecun.com/exdb/mnist; Lee, J., Moray, N., Trust, control strategies and allocation of function in human-machine systems (1992) Ergonomics, 35 (10), pp. 1243-1270; van der Maaten, L., Hinton, G., Visualizing data using t-SNE (2008) J. Mach. Learn. Res, 9 (Nov), pp. 2579-2605; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , arXiv preprint arXiv; Mansour, Y., Learning boolean functions via the Fourier transform (1994) Theoretical Advances in Neural Computation and Learning, pp. 391-424. , https://doi.org/10.1007/978-1-4615-2696-4_11, Roychowd-hury, V., Siu, K.Y., Orlitsky, A.(eds.), pp., Springer, Boston; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., (2017) On Detecting Adversarial Perturbations, , arXiv preprint arXiv; Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P., DeepFool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582. , pp; Papernot, N., (2016) Cleverhans V2.0.0: An Adversarial Machine Learning Library, , arXiv preprint arXiv; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519. , pp., ACM; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) 2016 IEEE European Symposium on Security and Privacy (EuroS&P), pp. 372-387; Papernot, N., McDaniel, P., Swami, A., Harang, R., Crafting adversarial input sequences for recurrent neural networks (2016) 2016 IEEE Military Communications Conference, MILCOM 2016, pp. 49-54; Pitt, L., Valiant, L.G., Computational limitations on learning from examples (1988) J. ACM (JACM), 35 (4), pp. 965-984; Raman, V., Lignos, C., Finucane, C., Lee, K.C.T., Marcus, M.P., Kress-Gazit, H., Sorry Dave, I’m afraid I can’t do that: Explaining unachievable robot tasks using natural language (2013) Robotics: Science and Systems; Reynolds, A., Deters, M., Kuncak, V., Tinelli, C., Barrett, C., Counterexample-guided quantifier instantiation for synthesis in SMT (2015) CAV 2015. LNCS, 9207, pp. 198-216. , https://doi.org/10.1007/978-3-319-21668-3_12, Kroening, D., Păsăreanu, C.S.(eds.), pp., Springer, Cham; Sankaranarayanan, S., Automatic invariant generation for hybrid systems using ideal fixed points (2010) HSCC, pp. 221-230. , https://doi.org/10.1145/1755952.1755984, pp; Roweis, S.T., Saul, L.K., Nonlinear dimensionality reduction by locally linear embedding (2000) Science, 290 (5500), pp. 2323-2326; Sankaranarayanan, S., Miller, C., Raghunathan, R., Ravanbakhsh, H., Fainekos, G., A model-based approach to synthesizing insulin infusion pump usage parameters for diabetic patients (2012) Annual Allerton Conference on Communication, Control, and Computing, pp. 1610-1617. , https://doi.org/10.1109/Allerton.2012.6483413, pp., October; Sankaranarayanan, S., Automatic invariant generation for hybrid systems using ideal fixed points (2010) HSCC, pp. 221-230. , https://doi.org/10.1145/1755952.1755984, pp; Sankaranarayanan, S., Sipma, H.B., Manna, Z., Constructing invariants for hybrid systems (2008) FMSD, 32 (1), pp. 25-55. , https://doi.org/10.1007/s10703-007-0046-1; Saul, L.K., Roweis, S.T., Think globally, fit locally: Unsupervised learning of low dimensional manifolds (2003) J. Mach. Learn. Res, 4 (Jun), pp. 119-155; Shaham, U., Yamada, Y., Negahban, S., (2015) Understanding Adversarial Training: Increasing Local Stability of Neural Nets through Robust Optimization, , arXiv preprint arXiv; Štrumbelj, E., Kononenko, I., Explaining prediction models and individual predictions with feature contributions (2014) KIS, 41 (3), pp. 647-665. , https://doi.org/10.1007/s10115-013-0679-x; Szegedy, C., (2013) Intriguing Properties of Neural Networks, , arXiv preprint arXiv; Tenenbaum, J.B., de Silva, V., Langford, J.C., A global geometric framework for nonlinear dimensionality reduction (2000) Science, 290 (5500), pp. 2319-2323; Urban, C., Gurfinkel, A., Kahsai, T., Synthesizing ranking functions from bits and pieces (2016) TACAS 2016. LNCS, 9636, pp. 54-70. , https://doi.org/10.1007/978-3-662-49674-9_4, Chechik, M., Raskin, J.-F.(eds.), pp., Springer, Heidelberg; Yuan, C., Lim, H., Lu, T.C., Most relevant explanation in Bayesian networks (2011) J. Artif. Intell. Res. (JAIR), 42, pp. 309-352","Jha, S.; Computer Science Laboratory, United States; 电子邮件: susmit.jha@sri.com",Zamani M.Zufferey D.,,Springer Verlag,"12th International Workshop on Numerical Software Verification, NSV 2019",13 July 2019 through 14 July 2019,,229449,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,,Scopus,2-s2.0-85070676741
"Khorshidpour Z., Tahmoresnezhad J., Hashemi S., Hamzeh A.",36668707900;57003652000;14038956200;13405284800;,Domain invariant feature extraction against evasion attack,2018,International Journal of Machine Learning and Cybernetics,9,12,,2093,2104,,1,10.1007/s13042-017-0692-6,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056591445&doi=10.1007%2fs13042-017-0692-6&partnerID=40&md5=119b1211e15c9bc48422d5980840684b,"Department of Computer Science Engineering and Information Technology, School of Electrical and Computer Engineering, Shiraz University, Shiraz, Iran","Khorshidpour, Z., Department of Computer Science Engineering and Information Technology, School of Electrical and Computer Engineering, Shiraz University, Shiraz, Iran; Tahmoresnezhad, J., Department of Computer Science Engineering and Information Technology, School of Electrical and Computer Engineering, Shiraz University, Shiraz, Iran; Hashemi, S., Department of Computer Science Engineering and Information Technology, School of Electrical and Computer Engineering, Shiraz University, Shiraz, Iran; Hamzeh, A., Department of Computer Science Engineering and Information Technology, School of Electrical and Computer Engineering, Shiraz University, Shiraz, Iran","In the security application, an attacker might violate the data stationary assumption that is a common assumption in the most machine learning techniques. This problem named as the domain shift problem arises when training (source) and test (target) data follow different distributions. The inherent adversarial nature of the security applications considerably effects on the robustness of a learning system. For that, a classifier designer needs to evaluate the robustness of a learning system under potential attacks during the design phase. The previous studies investigate the effect of reduced feature vector on the security evaluation of a learning classifier. They demonstrate that traditional feature selection techniques lead to even worsen performance. Therefore, an adversary-aware feature selection algorithm is proposed to improve the robustness of the learning systems. However, prior studies in domain adaptation techniques which are fundamental in addressing domain shift problem demonstrate that original space may not be directly suitable for refining this distribution mismatch, because some features may have been distorted by the domain shift. In this paper, we propose domain invariant feature extraction model based on domain adaptation technique in order to address domain shift problem caused by an adversary. We conduct an experiment that graphically shows the effect of a successful attack on the MNIST handwritten digits classification task. After that, we design synthetic datasets to investigate the effect of reduced feature vector on the performance of a learning system under attack. Moreover, our proposed feature extraction model significantly outperforms the adversarial-aware feature selection and traditional feature selection models on the application of spam filtering. © 2017, Springer-Verlag Berlin Heidelberg.",Adversarial environment; Domain adaptation; Domain shift; Evasion attack; Spam filtering,Character recognition; Extraction; Learning systems; Adversarial environments; Domain adaptation; Domain shift; Evasion attack; Spam filtering; Feature extraction,,,,,"Barreno, M., Nelson, B., Joseph, A.D., Tygar, J., The security of machine learning (2010) Mach Learn, 81 (2), pp. 121-148; Barreno, M., Nelson, B., Sears, R., Joseph, A.D., Tygar, J.D., Can machine learning be secure? (2006) Proceedings of the 2006 ACM Symposium on Information, Computer and Communications Security, pp. 16-25. , ACM; Basu, T., Murthy, C., A supervised term selection technique for effective text categorization (2016) Int J Mach Learn Cybern, 7 (5), pp. 877-892; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndić, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Machine Learning and Knowledge Discovery in Databases. Springer, pp. 387-402; Biggio, B., Fumera, G., Roli, F., Security evaluation of pattern classifiers under attack (2014) Knowl Data Eng IEEE Trans, 26 (4), pp. 984-996; Blitzer, J., McDonald, R., Pereira, F., Domain adaptation with structural correspondence learning (2006) Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pp. 120-128. , Association for Computational Linguistics; Brückner, M., Kanzow, C., Scheffer, T., Static prediction games for adversarial learning problems (2012) J Mach Learn Res, 13 (1), pp. 2617-2654; Brückner, M., Scheffer, T., Stackelberg games for adversarial prediction problems (2011) Proceedings of the 17Th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 547-555. , ACM; Byrd, R.H., Lu, P., Nocedal, J., Zhu, C., A limited memory algorithm for bound constrained optimization (1995) SIAM J Sci Comput, 16 (5), pp. 1190-1208; Cao, J., Chen, T., Fan, J., Landmark recognition with compact bow histogram and ensemble ELM (2016) Multimed Tools Appl, 75 (5), pp. 2839-2857; Chen, J., Guo, M., Wang, X., Liu, B., A comprehensive review and comparison of different computational methods for protein remote homology detection (2016) Briefings in Bioinformatics, 19 (2), pp. 231-244; Frustratingly easy domain adaptation (2007) Proceedings of the 45Th Annual Meeting of the Association of Computational Linguistics, pp. 256-263. , Prague, Czech Republic; Dekel, O., Shamir, O., Xiao, L., Learning to classify with missing and corrupted features (2010) Mach Learn, 81 (2), pp. 149-178; Duan, L., Tsang, I.W., Xu, D., Maybank, S.J., Domain transfer svm for video concept detection (2009) IEEE Conference on Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE, pp. 1375-1381; Gopalan, R., Li, R., Chellappa, R., Unsupervised adaptation across domain shifts by generating intermediate data representations (2014) Pattern Ana Mach Intell IEEE Trans, 36 (11), pp. 2288-2302; Huang, J., Gretton, A., Borgwardt, K.M., Schölkopf, B., Smola, A.J., Correcting sample selection bias by unlabeled data (2006) Advances in Neural Information Processing Systems, pp. 601-608; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I., Tygar, J., Adversarial machine learning (2011) Proceedings of the 4Th ACM Workshop on Security and Artificial Intelligence, pp. 43-58. , ACM; Jorgensen, Z., Zhou, Y., Inge, M., A multiple instance learning strategy for combating good word attacks on spam filters (2008) J Mach Learn Res, 9, pp. 1115-1146; Kołcz, A., Teo, C.H., Feature weighting for improved classifier robustness (2009) CEAS09: Sixth Conference on Email and Anti-Spam; Li, B., Vorobeychik, Y., Feature cross-substitution in adversarial classification (2014) Advances in Neural Information Processing Systems, pp. 2087-2095; Liu, B., Wang, S., Dong, Q., Li, S., Liu, X., Identification of DNA-binding proteins by combining auto-cross covariance transformation and ensemble learning (2016) IEEE Trans Nanobiosci, 15 (4), pp. 328-334; Long, M., Wang, J., Ding, G., Sun, J., Yu, P., Transfer feature learning with joint distribution adaptation (2013) In: Proceedings of the IEEE International Conference on Computer Vision, pp. 2200-2207; Long, M., Wang, J., Ding, G., Sun, J., Yu, P., Transfer joint matching for unsupervised domain adaptation (2014) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1410-1417; Lowd, D., Meek, C., Adversarial learning (2005) Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining. ACM, pp. 641-647; Macdonald, C., Ounis, I., Soboroff, I., Overview of the TREC 2007 blog track (2007) TREC, 7, pp. 31-43. , Citeseer; Nelson, B., Barreno, M., Chi, F.J., Joseph, A.D., Rubinstein, B.I., Saini, U., Sutton, C., Xia, K., Misleading learners: Co-opting your spam filter (2009) Machine Learning in Cyber Trust, pp. 17-51. , Springer; Hearst, M.A., Support vector machines (1998) IEEE Intell Syst App, 13 (4), pp. 18-28; Pan, S.J., Ni, X., Sun, J.-T., Yang, Q., Chen, Z., Cross-domain sentiment classification via spectral feature alignment (2010) In: Proceedings of the 19Th International Conference on World Wide Web, pp. 751-760. , ACM; Pan, S.J., Tsang, I.W., Kwok, J.T., Yang, Q., Domain adaptation via transfer component analysis (2011) Neural Netw IEEE Trans, 22 (2), pp. 199-210; Saenko, K., Kulis, B., Fritz, M., Darrell, T., Adapting visual category models to new domains (2010) Computer vision—ECCV 2010, pp. 213-226. , Springer; Shah, A.R., Oehmen, C.S., Webb-Robertson, B.-J., Svm-hustlean iterative semi-supervised machine learning approach for pairwise protein remote homology detection (2008) Bioinformatics, 24 (6), pp. 783-790; Uguroglu, S., Carbonell, J., Feature selection for transfer learning (2011) Machine Learning and Knowledge Discovery in Databases. Springer, pp. 430-442; Wang, F., Liu, W., Chawla, S., On sparse feature attacks in adversarial learning (2014) 2014 IEEE International Conference on Data Mining (ICDM). IEEE, pp. 1013-1018; Xiao, H., Biggio, B., Brown, G., Fumera, G., Eckert, C., Roli, F., Is feature selection secure against training data poisoning? (2015) Proceedings of the 32Nd International Conference on Machine Learning (ICML-15), pp. 1689-1698; Zhang, F., Adversarial feature selection against evasion attacks (2016) IEEE Trans Cybern, 46 (3), pp. 766-777; Zhu, C., Byrd, R.H., Lu, P., Nocedal, J., Algorithm 778: L-bfgs-b: Fortran subroutines for large-scale bound-constrained optimization (1997) ACM Trans Math Softw (TOMS), 23 (4), pp. 550-560","Hashemi, S.; Department of Computer Science Engineering and Information Technology, Iran; 电子邮件: s_hashemi@shirazu.ac.ir",,,Springer Verlag,,,,,18688071,,,,English,Intl. J. Mach. Learn. Cybern.,Article,Final,,Scopus,2-s2.0-85056591445
"Showkatbakhsh M., Shoukry Y., Chen R.H., Diggavi S., Tabuada P.",55640653000;35776891900;7406313050;7003736362;6603754297;,An SMT-based approach to secure state estimation under sensor and actuator attacks,2018,"2017 IEEE 56th Annual Conference on Decision and Control, CDC 2017",2018-January,,,157,162,,4,10.1109/CDC.2017.8263659,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046261293&doi=10.1109%2fCDC.2017.8263659&partnerID=40&md5=f5ad0a93c39b57e00d097e52f49bd1c5,"UCLA Electrical Engineering Department, Los Angeles, CA, United States; NG Next, Redondo Beach, CA, United States; Department of Electrical and Computer Engineering, University of Maryland, College Park, MD, United States","Showkatbakhsh, M., UCLA Electrical Engineering Department, Los Angeles, CA, United States; Shoukry, Y., Department of Electrical and Computer Engineering, University of Maryland, College Park, MD, United States; Chen, R.H., NG Next, Redondo Beach, CA, United States; Diggavi, S., UCLA Electrical Engineering Department, Los Angeles, CA, United States; Tabuada, P., UCLA Electrical Engineering Department, Los Angeles, CA, United States","This paper addresses the problem of state estimation of a linear time-invariant system when some of the sensors or/and actuators are under adversarial attack. In our set-up, the adversarial agent attacks a sensor (actuator) by manipulating its measurement (input), and we impose no constraint on how the measurements (inputs) are corrupted. We introduce the notion of 'sparse strong observability' to characterize systems for which the state estimation is possible, given bounds on the number of attacked sensors and actuators. Furthermore, we develop a secure state estimator based on Satisfiability Modulo Theory (SMT) solvers. © 2017 IEEE.",,Actuators; Invariance; Linear systems; Time varying control systems; Adversarial agent; Linear time invariant systems; Satisfiability modulo Theories; Sensor and actuators; Sensors and actuators; State Estimators; Strong observabilities; State estimation,,,,,"Langner, R., Stuxnet: Dissecting a cyberwarfare weapon (2011) IEEE Security & Privacy, 9 (3), pp. 49-51; Greenberg, A., (2015) Hackers Remotely Kill a Jeep on the Highway, with Me in It, , http://www.wired.com/2015/07/hackers-remotelykill-jeep-highway, [online]; Kelion, L., (2016) Nissan Leaf Electric Cars Hack Vulnerability Disclosed, , http://www.bbc.com/news/technology-35642749, [online]; Ćardenas, A.A., Amin, S., Sastry, S., Research challenges for the security of control systems (2008) HotSec; Sundaram, S., Pajic, M., Hadjicostis, C.N., Mangharam, R., Pappas, G.J., The wireless control network: Monitoring for malicious behavior (2010) 49th IEEE Conference on Decision and Control (CDC), pp. 5979-5984; Amin, S., Schwartz, G.A., Hussain, A., In quest of benchmarking security risks to cyber-physical systems (2013) IEEE Network, 27 (1), pp. 19-24; Mo, Y., Kim, T.H.-J., Brancik, K., Dickinson, D., Lee, H., Perrig, A., Sinopoli, B., Cyber-physical security of a smart grid infrastructure (2012) Proceedings of the IEEE, 100 (1), pp. 195-209; Zhu, M., Martinez, S., On the performance analysis of resilient networked control systems under replay attacks (2014) IEEE Transactions on Automatic Control, 59 (3), pp. 804-808; Persis, C.D., Tesi, P., Input-to-state stabilizing control under denial-of-service (2015) IEEE Transactions on Automatic Control, 60 (11), pp. 2930-2944; Senejohnny, D., Tesi, P., Persis, C.D., (2016) A Jamming-resilient Algorithm for Self-triggered Network Coordination, , arXiv preprint arXiv:1603.02563; Gupta, A., Langbort, C., Basar, T., Optimal control in the presence of an intelligent jammer with limited actions (2010) 49th IEEE Conference on Decision and Control (CDC), pp. 1096-1101; Mo, Y., Sinopoli, B., Secure control against replay attacks (2009) 47th Annual Allerton Conference on Communication, Control, and Computing, pp. 911-918. , IEEE; Smith, R.S., Covert misappropriation of networked control systems: Presenting a feedback structure (2015) Control Systems Magazine, 35 (1), pp. 82-92. , IEEE; Mo, Y., Garone, E., Casavola, A., Sinopoli, B., False data injection attacks against state estimation in wireless sensor networks (2010) N 49th IEEE Conference on Decision and Control (CDC), pp. 5967-5972; Fawzi, H., Tabuada, P., Diggavi, S., Secure estimation and control for cyber-physical systems under adversarial attacks (2014) IEEE Transactions on Automatic Control, 59 (6), pp. 1454-1467; Shoukry, Y., Tabuada, P., Event-triggered state observers for sparse sensor noise/attacks (2016) IEEE Transactions on Automatic Control, 61 (8), pp. 2079-2091; Chong, M.S., Wakaiki, M., Hespanha, J.P., Observability of linear systems under adversarial attacks (2015) American Control Conference (ACC), pp. 2439-2444; Nakahira, Y., Mo, Y., Dynamic state estimation in the presence of compromised sensory data (2015) 54th Annual Conference on Decision and Control (CDC), pp. 5808-5813. , IEEE; Mishra, S., Shoukry, Y., Karamchandani, N., Diggavi, S., Tabuada, P., Secure state estimation: Optimal guarantees against sensor attacks in the presence of noise (2017) IEEE Transactions on Control of Network Systems, 4 (1), pp. 49-59; Shoukry, Y., Nuzzo, P., Puggelli, A., Sangiovanni-Vincentelli, A.L., Seshia, S.A., Tabuada, P., Secure state estimation for cyber physical systems under sensor attacks: A satisfiability modulo theory approach (2017) IEEE Transactions on Automatic Control, , To be appeared on; Yong, S.Z., Foo, M.Q., Frazzoli, E., Robust and resilient estimation for cyber-physical systems under adversarial attacks (2016) American Control Conference (ACC), pp. 308-315. , IEEE; Pajic, M., Weimer, J., Bezzo, N., Tabuada, P., Sokolsky, O., Lee, I., Pappas, G.J., Robustness of attack-resilient state estimators (2014) ICCPS'14: ACM/IEEE 5th International Conference on Cyber- Physical Systems (With CPS Week 2014), pp. 163-174; Tiwari, A., Dutertre, B., Jovanovíc, D., Candia, T.D., Lincoln, P.D., Rushby, J., Sadigh, D., Seshia, S., Safety envelope for security (2014) ACM Proceedings of the 3rd International Conference on High Confidence Networked Systems, pp. 85-94; Showkatbakhsh, M., Tabuada, P., Diggavi, S., System identification in the presence of adversarial outputs (2016) Decision and Control (CDC), IEEE 55th Conference on, pp. 7177-7182. , IEEE; Showkatbakhsh, M., Tabuada, P., Diggavi, S., Secure system identification (2016) 54th Annual Allerton Conference on Communication, Control, and Computing, pp. 1137-1141. , IEEE; Blanke, M., Kinnaert, M., Lunze, J., Staroswiecki, M., Schröder, J., (2006) Diagnosis and Fault-tolerant Control, 691. , Springer; Jones, H.L., (1973) Failure Detection in Linear Systems, , PhD thesis, Massachusetts Institute of Technology; Harirchi, F., Ozay, N., (2016) Guaranteed Model-based Fault Detection in Cyber-physical Systems: A Model Invalidation Approach, , arXiv preprint arXiv:1609.05921; Pasqualetti, F., Dorfler, F., Bullo, F., Attack detection and identification in cyber-physical systems (2013) IEEE Transactions on Automatic Control, 58 (11), pp. 2715-2729; Sandberg, H., Teixeira, A.M., From control system security indices to attack identifiability (2016) Science of Security for Cyber-Physical Systems Workshop (SOSCYPS), pp. 1-6. , IEEE; Showkatbakhsh, M., Shoukry, Y., Chen, R.H., Diggavi, S., Tabuada, P., An SMT-based Approach to Secure State Estimation under Sensor and Actuator Attacks, , http://www.cyphylab.ee.ucla.edu/Home/publications, Technical Report UCLA-CyPhyLab-2017-02, 2017. Electronically; Yoshikawa, T., Bhattacharyya, S., Partial uniqueness: Observability and input identifiability (1975) IEEE Transactions on Automatic Control, 20 (5), pp. 713-714; Barrett, C.W., Sebastiani, R., Seshia, S.A., Tinelli, C., Satisfiability modulo theories (2009) Handbook of Satisfiability, 185, pp. 825-885; Berre, D.L., Parrain, A., The sat4j library, release 2.2, system description (2010) Journal on Satisfiability, Boolean Modeling and Computation, 7, pp. 59-64",,,ANCA Motion;City of Melbourne;Mathworks;The University of Melbourne;The University of Newcastle;United Technologies Research Center (UTRC),Institute of Electrical and Electronics Engineers Inc.,"56th IEEE Annual Conference on Decision and Control, CDC 2017",12 December 2017 through 15 December 2017,,133780,,9.78E+12,,,English,"IEEE Annu. Conf. Decis. Control, CDC",Conference Paper,Final,,Scopus,2-s2.0-85046261293
"Jin X., Haddad W.M., Hayakawa T.",55541046800;35461378700;7402974582;,An adaptive control architecture for cyber-physical system security in the face of sensor and actuator attacks and exogenous stochastic disturbances,2018,"2017 IEEE 56th Annual Conference on Decision and Control, CDC 2017",2018-January,,,1380,1385,,4,10.1109/CDC.2017.8263847,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046120898&doi=10.1109%2fCDC.2017.8263847&partnerID=40&md5=277bb71a4a212032e0d17c2924accd90,"School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA  30332-0150, United States; Department of Mechanical and Environmental Informatics, Tokyo Institute of Technology, Tokyo, 152-8552, Japan","Jin, X., School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA  30332-0150, United States; Haddad, W.M., School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA  30332-0150, United States; Hayakawa, T., Department of Mechanical and Environmental Informatics, Tokyo Institute of Technology, Tokyo, 152-8552, Japan","In this paper, we propose a novel adaptive control architecture for addressing security and safety in cyber-physical systems subject to exogenous disturbances. Specifically, we develop an adaptive controller for time-invariant, state-dependent adversarial sensor and actuator attacks in the face of stochastic exogenous disturbances. We show that the proposed controller guarantees uniform ultimate boundedness of the closed-loop dynamical system in a mean-square sense. We further discuss the practicality of the proposed approach and provide a numerical example involving the lateral directional dynamics of an aircraft to illustrate the efficacy of the proposed adaptive control architecture. © 2017 IEEE.",,Actuators; Controllers; Cyber Physical System; Dynamical systems; Embedded systems; Stochastic systems; Adaptive control architecture; Adaptive controllers; Cyber-physical system securities; Directional dynamics; Exogenous disturbances; Sensor and actuators; Stochastic disturbances; Uniform ultimate boundedness; Adaptive control systems,,,,,"Antsaklis, P., Goals and challenges in cyber-physical systems research (2014) IEEE Transactions On Automatic Control, 59 (12), pp. 3117-3119; Massoumnia, M.-A., Verghese, G.C., Willsky, A.S., Failure detection and identification (1989) IEEE Transactions On Automatic Control, 34 (3), pp. 316-321; Blanke, M., Schroder, J., (2006) Diagnosis and Fault-Tolerant Control, 691. , Springer; Hwang, I., Kim, S., Kim, Y., Seah, C.E., A survey of fault detection, isolation, and reconfiguration methods (2010) IEEE Transactions On Control Systems Technology, 18 (3), pp. 636-653; Yucelen, T., Haddad, W.M., Feron, E.M., Adaptive control architectures for mitigating sensor attacks in cyber-physical systems (2016) Cyber-Physical Systems, 2 (2), pp. 24-52; Jin, X., Haddad, W.M., Yucelen, T., An adaptive control architecture for mitigating sensor and actuator attacks in cyber-physical systems IEEE Transactions On Automatic Control, , to appear; Khasminskii, R.Z., (2012) Stochastic Stability of Differential Equations, , Berlin Heidelberg: Springer; Arnold, L., (1974) Stochastic Differential Equations: Theory and Applications, , USA: A Wiley-Interscience Publication; Ksendal, B., (1995) Stochastic Differential Equations: An Introduction with Applications, , Verlag Berlin, Heidelberg: Springer; Wu, Z.J., Xie, X.J., Shi, P., Xia, Y.Q., Backstepping controller design for a class of stochastic nonlinear systems with Markovian switching (2009) Automatica, 45, pp. 101-127; Wang, H.Q., Chen, B., Lin, C., Adaptive neural tracking control for a class of stochastic nonlinear systems (2014) International Journal of Robust and Nonlinear Control, 24 (7), pp. 1262-1280; Zhao, X., Shi, P., Zheng, X., Zhang, L., Adaptive tracking control for switched stochastic nonlinear systems with unknown actuator deadzone (2015) Automatica, 60, pp. 193-200; Hua, D., Kristic, M., Williams, R., Stabilization of stochastic nonlinear systems driven by noise of unknown covariance (2001) IEEE Transactions On Automatic Control, 48, pp. 1237-1253; Arapostathis, A., Borkar, V.S., Ghosh, M.K., (2012) Ergodic Control of Diffusion Processes, , Cambridge U.K.: Cambridge University Press; Haddad, W.M., Chellaboina, V., (2008) Nonlinear Dynamical Systems and Control: A Lyapunov-Based Approach, , Princeton University Press; Polycarpou, M.M., Ioannou, P.A., A robust adaptive nonlinear control design (1996) Automatica, 32 (3), pp. 423-427; Liu, M., Zhang, L., Shi, P., Karimi, H.R., Robust control of stochastic systems against bounded disturbances with application to flight control (2014) IEEE Transactions On Industrial Electronics, 61 (3), pp. 1504-1515; Fravolini, M.L., Yucelen, T., Campa, G., Set theoretic performance verification of low-frequency learning adaptive controllers (2015) International Journal of Adaptive Control and Signal Processing, 29 (10), pp. 1243-1258",,,ANCA Motion;City of Melbourne;Mathworks;The University of Melbourne;The University of Newcastle;United Technologies Research Center (UTRC),Institute of Electrical and Electronics Engineers Inc.,"56th IEEE Annual Conference on Decision and Control, CDC 2017",12 December 2017 through 15 December 2017,,133780,,9.78E+12,,,English,"IEEE Annu. Conf. Decis. Control, CDC",Conference Paper,Final,,Scopus,2-s2.0-85046120898
"Jin X., Haddad W.M., Hayakawa T.",55541046800;35461378700;7402974582;,An adaptive control architecture for cyber-physical system security in the face of sensor and actuator attacks and exogenous stochastic disturbances,2018,Cyber-Physical Systems,4,1,,39,56,,11,10.1080/23335777.2018.1484818,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053425305&doi=10.1080%2f23335777.2018.1484818&partnerID=40&md5=e674251f3f053501937ab379696a2a03,"School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA, United States; Department of Mechanical and Environmental Informatics, Tokyo Institute of Technology, Tokyo, Japan","Jin, X., School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA, United States; Haddad, W.M., School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA, United States; Hayakawa, T., Department of Mechanical and Environmental Informatics, Tokyo Institute of Technology, Tokyo, Japan","In this paper, we propose a novel adaptive control architecture for addressing security and safety in cyber-physical systems subject to exogenous disturbances. Specifically, we develop an adaptive controller for time-invariant, state-dependent adversarial sensor and actuator attacks in the face of stochastic exogenous disturbances modelled as Markov processes. We show that the proposed controller guarantees uniform ultimate boundedness of the closed-loop dynamical system in a mean-square sense. We further discuss the practicality of the proposed approach and provide a numerical example involving the lateral directional dynamics of an aircraft to illustrate the efficacy of the proposed adaptive control architecture. © 2018, © 2018 Taylor & FrancisInforma UK Limited, trading as Taylor & Francis Group.",cyber-physical systems; Markov processes; Sensor and actuator attacks; adaptive control; stochastic disturbances; uniform boundedness in probability,Actuators; Computer architecture; Controllers; Cyber Physical System; Dynamical systems; Embedded systems; Markov processes; Stochastic systems; Adaptive Control; Adaptive control architecture; Adaptive controllers; Boundedness; Cyber-physical system securities; Exogenous disturbances; Stochastic disturbances; Uniform ultimate boundedness; Adaptive control systems,,,,,"Antsaklis, P., Goals and challenges in cyber-physical systems research (2014) IEEE Trans Autom Control, 59 (12), pp. 3117-3119; Teixeira, A., Shames, I., Sandberg, H., A secure control framework for resource-limited adversaries (2015) Automatica, 51, pp. 135-148; Khaitan, S.K., McCalley, J.D., Design techniques and applications of cyberphysical systems: a survey (2015) IEEE Syst J, 9 (2), pp. 350-365; Massoumnia, M.A., Verghese, G.C., Willsky, A.S., Failure detection and identification (1989) IEEE Trans Autom Control, 34 (3), pp. 316-321; Blanke, M., Schröder, J., (2006) Diagnosis and fault-tolerant control, 691. , Berlin, Germany: Springer; Hwang, I., Kim, S., Kim, Y., A survey of fault detection, isolation, and reconfiguration methods (2010) IEEE Trans Control Syst Technol, 18 (3), pp. 636-653; Schenato, L., Sinopoli, B., Franceschetti, M., Foundations of control and estimation over lossy networks (2007) Proc IEEE, 95 (1), pp. 163-187; Gupta, A., Langbort, C., Basar, T., Optimal control in the presence of an intelligent jammer with limited actions (2010) IEEE Conference on Decision and Control, Atlanta, GA, pp. 1096-1101. , In:,.\pagination{\break} p; Pasqualetti, F., Dorfler, F., Bullo, F., Attack detection and identification in cyber-physical systems (2013) IEEE Trans Autom Control, 58 (11), pp. 2715-2729; Fawzi, H., Tabuada, P., Diggavi, S., Secure estimation and control for cyber-physical systems under adversarial attacks (2014) IEEE Trans Autom Control, 59 (6), pp. 1454-1467; Weimer, J., Bezzo, N., Pajic, M., Resilient parameter-invariant control with application to vehicle cruise control (2013) Control of cyber-physical systems, pp. 197-216. , Heidelberg, Germany: Springer,. In:,. p; Sou, K.C., Sandberg, H., Johansson, K.H., On the exact solution to a smart grid cyber-security analysis problem (2013) IEEE Trans Smart Grid, 4 (2), pp. 856-865; Kosut, O., Jia, L., Thomas, R.J., Malicious data attacks on the smart grid (2011) IEEE Trans Smart Grid, 2 (4), pp. 645-658; Kim, T.T., Poor, H.V., Strategic protection against data injection attacks on power grids (2011) IEEE Trans Smart Grid, 2 (2), pp. 326-333; Vamvoudakis, K.G., Hespanha, J.P., Sinopoli, B., Detection in adversarial environments (2014) IEEE Trans Autom Control, 59 (12), pp. 3209-3223; Garcia, H.E., Lin, W.C., Meerkov, S.M., Resilient monitoring systems: architecture, design, and application to boiler/turbine plant (2014) IEEE Trans Cybern, 44 (11), pp. 2010-2023; Weerakkody, S., Sinopoli, B., Kar, S., Information flow for security in control systems (2016) IEEE Conference on Decision and Control, Las Vegas, NV, pp. 5065-5072. , In:,. p; Lucia, W., Sinopoli, B., Franze, G., A set-theoretic approach for secure and resilient control of cyber-physical systems subject to false data injection attacks (2016) Science of Security for Cyber-Physical Systems Workshop, Vienna, Austria, pp. 1-5. , In:,. p; Li, Y., Chen, T., Stochastic detector against linear deception attacks on remote state estimation (2016) IEEE Conference on Decision and Control, Las Vegas, NV, pp. 6291-6296. , In:,. p; Li, Y., Shi, L., Chen, T., Detection against linear deception attacks on multi-sensor remote state estimation (2018) IEEE Trans Control Netw Syst, , Forthcoming; Yucelen, T., Haddad, W.M., Feron, E.M., Adaptive control architectures for mitigating sensor attacks in cyber-physical systems (2016) Cyber Phys Syst, 2 (2), pp. 24-52; Jin, X., Haddad, W.M., Yucelen, T., An adaptive control architecture for mitigating sensor and actuator attacks in cyber-physical systems (2017) IEEE Trans Autom Control, 62 (11), pp. 6058-6064; Manandhar, K., Cao, X., Hu, F., Detection of faults and attacks including false data injection attack in smart grid using kalman filter (2014) IEEE Trans Control Netw Syst, 1 (4), pp. 370-379; Paridari, K., Mady, A.E.D., La Porta, S., Cyber-physical-security framework for building energy management system (2016) 2016 ACM/IEEE 7th International Conference on Cyber-Physical Systems (ICCPS), Vienna, Austria, pp. 1-9. , In:,. p; Ding, D., Wang, Z., Ho, D.W., Observer-based event-triggering consensus control for multiagent systems with lossy sensors and cyber-attacks (2017) IEEE Trans Cybern, 47 (8), pp. 1936-1947; Arabi, E., Yucelen, T., Haddad, W.M., Mitigating the effects of sensor uncertainties in networked multiagent systems (2017) ASME J Dyn Syst Meas Control, 139 (4), pp. 1-11; Jin, X., Haddad, W.M., Hayakawa, T., An adaptive control architecture for cyber-physical system security in the face of sensor and actuator attacks and stochastic distrubances (2017) Proceedings of IEEE Conference on Decision and Control, pp. 1380-1385. , Melbourne, Australia:. In:,. p; Kushner, H.J., (1967) Stochastic stability and control, , New York (NY): Academic Press; Khasminskii, R.Z., (2012) Stochastic stability of differential equations, , Berlin: Springer; Kushner, H.J., (1971) Introduction to stochastic control, , New York (NY): Holt, Rinehart and Winston, Inc; Arnold, L., (1974) Stochastic differential equations: theory and applications, , New York (NY): A Wiley-Interscience Publication; Sharov, V., Stability and stabilization of stochastic systems vis-a-vis some of the variables (1978) Avtomat Telemekh, 11, pp. 63-71. , Russian; Øksendal, B., (1995) Stochastic differential equations: an introduction with applications, , Verlag Berlin, Heidelberg: Springer; Wang, H.Q., Chen, B., Lin, C., Adaptive neural tracking control for a class of stochastic nonlinear systems (2014) Int J Robust Nonlinear Control, 24 (7), pp. 1262-1280; Zhao, X., Shi, P., Zheng, X., Adaptive tracking control for switched stochastic nonlinear systems with unknown actuator dead-zone (2015) Automatica, 60, pp. 193-200; Hua, D., Kristić, M., Williams, R., Stabilization of stochastic nonlinear systems driven by noise of unknown covariance (2001) IEEE Trans Autom Control, 48, pp. 1237-1253; Arapostathis, A., Borkar, V.S., Ghosh, M.K., (2012) Ergodic control of diffusion processes, , Cambridge: Cambridge University Press; Haddad, W.M., Chellaboina, V., (2008) Nonlinear dynamical systems and control: a Lyapunov-based approach, , Princeton, NJ: Princeton University Press; Lavretsky, E., Wise, K., (2012) Robust and adaptive control with aerospace applications, , London: Springer; Polycarpou, M.M., Ioannou, P.A., A robust adaptive nonlinear control design (1996) Automatica, 32 (3), pp. 423-427; Yucelen, T., Haddad, W.M., Low-frequency learning and fast adaptation in model reference adaptive control (2013) IEEE Trans Autom Control, 58 (2), pp. 1080-1085; Liu, M., Zhang, L., Shi, P., Robust control of stochastic systems against bounded disturbances with application to flight control (2014) IEEE Trans Indus Electron, 61 (3), pp. 1504-1515; Fravolini, M.L., Yucelen, T., Campa, G., Set theoretic performance verification of low-frequency learning adaptive controllers (2015) Int J Adapt Control Signal Process, 29 (10), pp. 1243-1258","Haddad, W.M.; School of Aerospace Engineering, United States; 电子邮件: wm.haddad@aerospace.gatech.edu",,,Taylor and Francis Ltd.,,,,,23335785,,,,English,Cyber Phy. Sys.,Article,Final,,Scopus,2-s2.0-85053425305
"Hinton G., Sabour S., Frosst N.",7006699573;57202058686;57201639852;,Matrix capsules with EM routing,2018,"6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings",,,,,,,392,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083952562&partnerID=40&md5=4dac4eeb2b5015f699847cc0b789eefe,"Google Brain, Toronto, Canada","Hinton, G., Google Brain, Toronto, Canada; Sabour, S., Google Brain, Toronto, Canada; Frosst, N., Google Brain, Toronto, Canada","A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagat-ing through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network. © Learning Representations, ICLR 2018 - Conference Track Proceedings.All right reserved.",,Image segmentation; Iterative methods; Maximum principle; Neural networks; Convolutional neural network; Expectation-maximization algorithms; State of the art; Test errors; Transformation matrices; Viewpoint invariant; White box; Linear transformations,,,,,"Brendel, W., Bethge, M., (2017) Comment on” Biologically Inspired Protection of Deep Networks from Adversarial Attacks, , arXiv preprint; Ciresan, D., Meier, U., Schmidhuber, J., Multi-column deep neural networks for image classification (2012) Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, pp. 3642-3649; Cireşan, D.C., Meier, U., Masci, J., Gambardella, L.M., Schmidhuber, J., (2011) High-Performance Neural Networks for Visual Object Classification, , arXiv preprint; Cohen, T., Welling, M., Group equivariant convolutional networks (2016) International Conference on Machine Learning, pp. 2990-2999; Dai, J., Qi, H., Xiong, Y., Li, Y., Zhang, G., Hu, H., Wei, Y., (2017) Deformable Convolutional Networks, , arXiv preprint; De Brabandere, B., Jia, X., Tuytelaars, T., Van Gool, L., Dynamic filter networks (2016) Neural Information Processing Systems (NIPS); Dieleman, S., De Fauw, J., Kavukcuoglu, K., Exploiting cyclic symmetry in convolutional neural networks (2016) Proceedings of the 33rd International Conference on International Conference on Machine Learning - Volume 48, ICML’16, pp. 1889-1898. , http://dl.acm.org/citation.cfm?id=3045390.3045590, JMLR.org; Fasel, B., Gatica-Perez, D., Rotation-invariant neoperceptron (2006) Pattern Recognition, 2006. ICPR 2006. 18th International Conference on, 3, pp. 336-339; Gens, R., Domingos, P.M., Deep symmetry networks (2014) Advances in Neural Information Processing Systems, pp. 2537-2545; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint; Gregor, K., Danihelka, I., Graves, A., Rezende, D., Wierstra, D., Draw: A recurrent neural network for image generation (2015) International Conference on Machine Learning, pp. 1462-1471; Guermeur, Y., Monfrini, E., A quadratic loss multi-class SVM for which a radius–margin bound applies (2011) Informatica, 22 (1), pp. 73-96; Hinton, G.E., Krizhevsky, A., Wang, S.D., Transforming auto-encoders (2011) International Conference on Artificial Neural Networks, pp. 44-51. , Springer; Jaderberg, M., Simonyan, K., Zisserman, A., Kavukcuoglu, K., Spatial transformer networks (2015) Advances in Neural Information Processing Systems, pp. 2017-2025; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint; Laptev, D., Savinov, N., Buhmann, J.M., Pollefeys, M., Ti-pooling: Transformation-invariant pooling for feature learning in convolutional neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 289-297; LeCun, Y., Boser, B.E., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W.E., Jackel, L.D., Handwritten digit recognition with a back-propagation network (1990) Advances in Neural Information Processing Systems, pp. 396-404; LeCun, Y., Huang, F.J., Bottou, L., Learning methods for generic object recognition with invariance to pose and lighting (2004) Computer Vision and Pattern Recognition, 2004. CVPR 2004. Proceedings of the 2004 IEEE Computer Society Conference on, 2, pp. II–104; Lenc, K., Vedaldi, A., Learning covariant feature detectors (2016) Computer Vision–ECCV 2016 Workshops, pp. 100-117. , Springer; Oyallon, E., Mallat, S., Deep roto-translation scattering for object classification (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2865-2873; Sabour, S., Fross, N., Hinton, G.E., Dynamic routing between capsules (2017) Neural Information Processing Systems (NIPS); Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, L., Polosukhin, I., Attention is all you need (2017) Neural Information Processing Systems (NIPS); Worrall, D.E., Garbin, S.J., Turmukhambetov, D., Brostow, G.J., Harmonic networks: Deep translation and rotation equivariance (2017) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , July",,,,"International Conference on Learning Representations, ICLR","6th International Conference on Learning Representations, ICLR 2018",30 April 2018 through 3 May 2018,,149806,,,,,English,"Int. Conf. Learn. Represent., ICLR - Conf. Track Proc.",Conference Paper,Final,,Scopus,2-s2.0-85083952562
"Tang Z., Kuijper M., Chong M., Mareels I., Leckie C.",57220907881;7003535680;54912439800;7004369521;7003524629;,Sensor attack correction for linear systems with known inputs,2018,IFAC-PapersOnLine,51,23,,206,211,,2,10.1016/j.ifacol.2018.12.036,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058467946&doi=10.1016%2fj.ifacol.2018.12.036&partnerID=40&md5=7aa0259fb602c0f4c813fd1002d12a09,"School of Electrical and Electronic Engineering, University of Melbourne, Australia; Department of Automatic Control, KTH Royal Institute of Technology, Sweden; IBM Research Australia, Australia; School of Computing and Information Systems, University of Melbourne, Australia","Tang, Z., School of Electrical and Electronic Engineering, University of Melbourne, Australia; Kuijper, M., School of Electrical and Electronic Engineering, University of Melbourne, Australia; Chong, M., Department of Automatic Control, KTH Royal Institute of Technology, Sweden; Mareels, I., IBM Research Australia, Australia; Leckie, C., School of Computing and Information Systems, University of Melbourne, Australia","We address the problem of attack detection and attack correction for multi-input multi-output discrete-time linear time-invariant systems under sensor attacks. More specifically, we consider the situation that a system with known input is corrupted by additive adversarial attack signals on some of the system's outputs. In this paper, we use system representation in a behavioural approach, which allows for natural and compact statements regarding linear system security. We extend our earlier results for systems with zero inputs to systems with non-zero inputs. We assume that these non-zero inputs are known. © 2018",error correction; Linear systems; system security,Error correction; Invariance; MIMO systems; Time varying control systems; Attack detection; Behavioural approach; Discrete-time linear time-invariant systems; Multi input multi output; System representation; System security; Linear systems,,,,,"Chen, Y., Kar, S., Moura, J., (2015), Cyber-physical systems: dynamic sensor attacks and strong observability. In Proc. of the 40th International Conference on Acoustics, Speech and Signal Processing (ICASSP), 1752–1756. Brisbane, Australia; Chong, M., Kuijper, M., Characterising the vulnerability of linear control systems under sensor attacks using a system’ s security index (2016) In Proc. of the 55th Conference on Decision and Control (CDC) December, 2016, pp. 5906-5911. , Las Vegas, USA; Chong, M., Kuijper, M., (2016), Vulnerability of linear systems against sensor attacks–a system's security index. In Proc. of 22nd International Symposium on Mathematical Theory of Networks and Systems(MTNS), 373–376. Minneapolis, USA; Chong, M., Wakaiki, M., Hespanha, J., (2015), Observability of linear systems under adversarial attacks. In Proc. of the 2015 American Control Conference (ACC), 2439–2444. Chicago, USA; Chow, E.Y., Willsky, A.S., Analytical redundancy and the design of robust failure detection systems (1984) IEEE Trans. Automat. Contr., 27, pp. 603-614; Fawzi, H., Tabuada, P., Diggavi, S., Secure estimation and control for cyber-physical systems under adversarial attacks (2014) IEEE Transactions of Automatic Control, 59 (6), pp. 1454-1467; Frisk, E., Nyberg, M., (1999), Using minimal polynomial bases for fault diagnosis. In Proc. of European Control Conference, 4161–4166. Karlsruhe, Germany; Hajshirmohamadi, S., Davoodi, M., Meskin, N., Sheik-holeslam, F., Event-triggered fault detection and isolation for discrete-time linear systems (2016) IET Control Theory and Applications, 10, pp. 526-533; Manandhar, K., Cao, X., Detection of faults and attacks including false data injection attack in smart grid using Kalman filter (2014) IEEE Transactions on Control of Network Systems, 1, pp. 370-379; Pajic, M., Tabuada, P., Lee, I., Pappas, G., (2015), Attack-resilient state estimation in the presence of noise. In Proc. of the 54th Conference on Decision and Control (CDC), 5827–5832. Osaka, Japan; Pasqualetti, F., Dörfler, F., Bullo, F., Attack detection and identification in cyber-physical systems (2013) IEEE Transactions on Automatic Control, 58 (99), pp. 2715-2729; Polderman, J., Willems, J., (1997) Introduction to mathematical systems theory: a behavioral approach, volume 26 of Texts in Applied Mathematics, , Springer New York NY, USA; Proakis, J., Salehi, M., (2008) Digital Communications 5th edition, , McGraw Hill New York, USA; Sandberg, H., Teixeira, A., (2016), From control system security indices to attack identifiability. In Proc. of 2016 Science of Security for Cyber-Physical Systems Workshop (SOSCYPS), 1–6. Vienna, Austria; Sandberg, H., Teixeira, A., Johansson, K., (2010), On security indices for state estimators in power networks. In Proc. of First Workshop on Secure Control Systems, CPSWEEK, 1–6. Stockholm, Sweden; Shoukry, Y., Chong, M., Wakaiki, M., Nuzzo, P., Sangiovanni-Vincentelli, A., Seshia, S., Hespanha, J., Tabuada, P., (2016), SMT-based observer design for cyber-physical systems under sensor attacks. In 7th ACM/IEEE International Conference on Cyber-Physical Systems, ICCPS, 29:1–29:10. Vienna, Austria; Shoukry, Y., Tabuada, P., Event-triggered state observers for sparse sensor noise/attacks (2016) IEEE Transactions of Automatic Control, 61 (8), pp. 2079-2091; Tang, Z., Kuijper, M., Chong, M., Mareels, I., Leckie, C., (2017), Linear system security–detection and correction of adversarial attacks in the noise-free case. Available at submitted to Automatica; Tang, Z., Kuijper, M., Chong, M., Mareels, I., Leckie, C., Attack correction for noise-free linear systems subject to sensor attacks (2018) In Proc. of the 23rd International Symposium on Mathematical Theory of Networks and Systems, MTNS, Hong Kong, China, pp. 18-21; Teixeira, A., Shames, I., Sandberg, H., Johansson, K., A secure control framework for resource-limited adversaries (2015) Automatica, 51, pp. 135-148; Teixeira, A., Sou, K.C., Sandberg, H., K.H.J., Secure control systems: A quantitave risk management approach (2015) IEEE Control System, 35, pp. 24-45; Warner, J.S., Johnstib, R.G., A simple demonstration that the global positioning system is vulnerable to spoofing (2002) In Journal of Security Administration, pp. 19-27; Yang, T., Murguia, C., Kuijper, M., Nešić, D., (2018), A robust circle-criterion observer-based estimator for discrete-time nonlinear systems in the presence of sensor attacks and measurement noise. Available at, accepted 57th IEEE Conference on Decision and Control (CDC); Zhang, Y., Qiu, Q., Yang, F., Han, Q.L., Vlacic, L., Liul, J., (2015), Set-membership filtering approach for fault detection of systems with unknown-but-bounded noises. In Proc. of the 5th Australian Control Conference (AUCC), 170–175. Gold Coast, Australia",,,,Elsevier B.V.,,,,,24058963,,,,English,IFAC-PapersOnLine,Conference Paper,Final,"All Open Access, Bronze",Scopus,2-s2.0-85058467946
"Jin X., Haddad W.M., Yucelen T.",55541046800;35461378700;23570112600;,An Adaptive Control Architecture for Mitigating Sensor and Actuator Attacks in Cyber-Physical Systems,2017,IEEE Transactions on Automatic Control,62,11,7814246,6058,6064,,141,10.1109/TAC.2017.2652127,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027850990&doi=10.1109%2fTAC.2017.2652127&partnerID=40&md5=d852eabb71e655f0611dfa1f5a96d0a7,"School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA  30332, United States; Department of Mechanical Engineering, University of South Florida, Tampa, FL  33620, United States","Jin, X., School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA  30332, United States; Haddad, W.M., School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA  30332, United States; Yucelen, T., Department of Mechanical Engineering, University of South Florida, Tampa, FL  33620, United States","Recent technological advances in communications and computation have spurred a broad interest in control law architectures involving the monitoring, coordination, integration, and operation of sensing, computing, and communication components that tightly interact with the physical processes that they control. These systems are known as cyber-physical systems and due to their use of open computation and communication platform architectures, controlled cyber-physical systems are vulnerable to adversarial attacks. In this technical note, we propose a novel adaptive control architecture for addressing security and safety in cyber-physical systems. Specifically, we develop an adaptive controller that guarantees uniform ultimate boundedness of the closed-loop dynamical system in the face of adversarial sensor and actuator attacks that are time-varying and partial asymptotic stability when the sensor and actuator attacks are time-invariant. Finally, we provide a numerical example to illustrate the efficacy of the proposed adaptive control architecture. © 2012 IEEE.",Actuator attacks; adaptive control; cyber-physical systems; partial asymptotic stability; sensor attacks; uniform ultimate boundedness,Actuators; Asymptotic stability; Cyber Physical System; Dynamical systems; Embedded systems; System stability; Adaptive Control; Adaptive control architecture; Adaptive controllers; Communication components; Communication platforms; Sensor and actuators; Technological advances; Uniform ultimate boundedness; Adaptive control systems,,,,,"Antsaklis, P., Goals, challenges in cyber-physical systems research (2014) IEEE Trans. Autom. Control, 59 (12), pp. 3117-3119; Massoumnia, M.-A., Verghese, G.C., Willsky, A.S., Failure detection, identification (1989) IEEE Trans. Autom. Control, 34 (3), pp. 316-321; Blanke, M., Schröder, J., (2006) Diagnosis, Fault-Tolerant Control, 691. , New York: Springer; Hwang, I., Kim, S., Kim, Y., Seah, C.E., A survey of fault detection, isolation, reconfiguration methods (2010) IEEE Trans. Control Syst. Technol., 18 (3), pp. 636-653; Schenato, L., Sinopoli, B., Franceschetti, M., Poolla, K., Sastry, S.S., Foundations of control, estimation over lossy networks (2007) Proc. IEEE, 95 (1), pp. 163-187; Gupta, A., Langbort, C., Basar, T., Optimal control in the presence of an intelligent jammer with limited actions (2010) Proc. IEEE Conf. Decision, Control, pp. 1096-1101; Pasqualetti, F., Dörfler, F., Bullo, F., (2012) Attack Detection, Identification in Cyber-physical Systems-Part I: Models, Fundamental Limitations, , arXiv preprint arXiv: 1202.6144; Pasqualetti, F., Dörfler, F., Bullo, F., (2012) Attack Detection, Identification in Cyber-physical Systems-Part II: Centralized, Distributed Monitor Design, , arXiv preprint arXiv: 1202.6049; Pasqualetti, F., Dorfler, F., Bullo, F., Attack detection, identification in cyber-physical systems (2013) IEEE Trans. Autom. Control, 58 (11), pp. 2715-2729; Fawzi, H., Tabuada, P., Diggavi, S., Secure estimation, control for cyber-physical systems under adversarial attacks (2012) IEEE Trans. Autom. Control, 59 (6), pp. 1454-1467; Weimer, J., Bezzo, N., Pajic, M., Pappas, G.J., Sokolsky, O., Lee, I., Resilient parameter-invariant control with application to vehicle cruise control (2013) Control OfCyber-Physical Systems, pp. 197-216. , NewYork: Springer; Sou, K.C., Sandberg, H., Johansson, K.H., On the exact solution to a smart grid cyber-security analysis problem (2013) IEEE Trans. Smart Grid, 4 (2), pp. 856-865; Kosut, O., Jia, L., Thomas, R.J., Tong, L., Malicious data attacks on the smart grid (2011) IEEE Trans. Smart Grid, 2 (4), pp. 645-658; Kim, T.T., Poor, H.V., Strategic protection against data injection attacks on power grids (2011) IEEE Trans. Smart Grid, 2 (2), pp. 326-333; Vamvoudakis, K.G., Hespanha, J.P., Sinopoli, B., Mo, Y., Detection in adversarial environments (2014) IEEE Trans. Autom. Control, 59 (12), pp. 3209-3223; Bezzo, N., Weimer, J., Pajic, M., Sokolsky, O., Pappas, G.J., Lee, I., Attack resilient state estimation for autonomous robotic systems (2014) Proc. IEEE/RSJ Int. Conf. Intelligent Robots, Systems, pp. 3692-3698; Park, J., Ivanov, R., Weimer, J., Pajic, M., Lee, I., Sensor attack detection in the presence of transient faults (2015) Proc. ACM/IEEE 6th Int. Conf. Cyber-Physical Systems, pp. 1-10; Pajic, M., Tabuada, P., Lee, I., Pappas, G.J., Attack-resilient state estimation in the presence of noise (2015) Proc. 54th IEEE Conf. Decision, Control, pp. 5827-5832; Mitchell, R., Chen, R., Effect of intrusion detection, response on reliability of cyber physical systems (2013) IEEE Trans. Reliability, 62 (1), pp. 199-210; Teixeira, A., Shames, I., Sandberg, H., Johansson, K.H., A secure control framework for resource-limited adversaries (2015) Automatica, 51, pp. 135-148; Fawzi, H., Tabuada, P., Diggavi, S., Secure estimation, control for cyber-physical systems under adversarial attacks (2012) IEEE Trans. Autom. Control, 59 (6), pp. 1454-1467; Haddad, W.M., Chellaboina, V., (2008) Nonlinear Dynamical Systems Control: A Lyapunov-Based Approach, , Princeton NJ: Princeton University Press; Pomet, J.-B., Praly, L., Adaptive nonlinear regulation: Estimation from the Lyapunov equation (1992) IEEE Trans. Autom. Control, 37 (6), pp. 729-740; Lavretsky, E., Wise, K., (2012) Robust, Adaptive Control with Aerospace Applications, , New York: Springer; Polycarpou, M.M., Ioannou, P.A., A robust adaptive nonlinear control design (1996) Automatica, 32 (3), pp. 423-427; Haddad, W.M., Chellaboina, V., Nersesov, S.G., (2006) Impulsive Hybrid Dynamical Systems: Stability Dissipativity Control, , Princeton NJ: Princeton University Press; Fravolini, M.L., Yucelen, T., Campa, G., Set theoretic performance verification of low-frequency learning adaptive controllers (2015) Int. J. Adapt. Control, Signal Process., 29 (10), pp. 1243-1258",,,,Institute of Electrical and Electronics Engineers Inc.,,,,,189286,,IETAA,,English,IEEE Trans Autom Control,Article,Final,,Scopus,2-s2.0-85027850990
"Showkatbakhsh M., Tabuada P., Diggavi S.",55640653000;6603754297;7003736362;,Secure system identification,2017,"54th Annual Allerton Conference on Communication, Control, and Computing, Allerton 2016",,,7852363,1137,1141,,2,10.1109/ALLERTON.2016.7852363,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015235233&doi=10.1109%2fALLERTON.2016.7852363&partnerID=40&md5=0e3f31f8cca32301d00e4eecf2086d2b,"UCLA Electrical Engineering Department, University of California at Los AngelesCA  90095-1594, United States","Showkatbakhsh, M., UCLA Electrical Engineering Department, University of California at Los AngelesCA  90095-1594, United States; Tabuada, P., UCLA Electrical Engineering Department, University of California at Los AngelesCA  90095-1594, United States; Diggavi, S., UCLA Electrical Engineering Department, University of California at Los AngelesCA  90095-1594, United States","This work is concerned with the identification of linear time-invariant systems in the presence of an adversarial agent that attacks sensor measurements. The attacker is omniscient and we impose no restrictions (statistical or otherwise) on how the adversary alters the sensor measurements. We work in a noisy scenario where, in addition to the attacks, the sensor measurements are also affected by additive noise. Given a bound on the number of attacked sensors, and under a certain observability condition, we show that we can still construct a model that is useful for stabilization. Furthermore, we show that this model is closely related to the original system. © 2016 IEEE.",,Invariance; Linear systems; Time varying control systems; Adversarial agent; Linear time invariant systems; Original systems; Secure system; Sensor measurements; Additive noise,,,,,"Langner, R., Stuxnet: Dissecting a cyberwarfare weapon (2011) IEEE Security & Privacy, 9 (3), pp. 49-51; Greenberg, A., (2015) Hackers Remotely Kill A Jeep on the Highway, with Me in It, , http://www.wired.com/2015/07/hackers-remotelykill-jeep-highway; Kelion, L., (2016) Nissan Leaf Electric Cars Hack Vulnerability Disclosed, , http://www.bbc.com/news/technology-35642749; Cárdenas, A.A., Amin, S., Sastry, S., Research challenges for the security of control systems (2008) HotSec; Sundaram, S., Pajic, M., Hadjicostis, C.N., Mangharam, R., Pappas, G.J., The wireless control network: Monitoring for malicious behavior (2010) 49th IEEE Conference on Decision and Control (CDC), pp. 5979-5984; Amin, S., Schwartz, G.A., Hussain, A., In quest of benchmarking security risks to cyber-physical systems (2013) IEEE Network, 27 (1), pp. 19-24; Mo, Y., Kim, T.H.-J., Brancik, K., Dickinson, D., Lee, H., Perrig, A., Sinopoli, B., Cyber-physical security of a smart grid infrastructure (2012) Proceedings of the IEEE, 100 (1), pp. 195-209; Zhu, M., Martinez, S., On the performance analysis of resilient networked control systems under replay attacks (2014) IEEE Transactions on Automatic Control, 59 (3), pp. 804-808; De Persis, C., Tesi, P., Input-to-state stabilizing control under denial-of-service (2015) IEEE Transactions on Automatic Control, 60 (11), pp. 2930-2944; Senejohnny, D., Tesi, P., De Persis, C., (2016) A Jamming-resilient Algorithm for Self-triggered Network Coordination, , arXiv preprint arXiv: 1603. 02563; Gupta, A., Langbort, C., Basar, T., Optimal control in the presence of an intelligent jammer with limited actions (2010) 49th IEEE Conference on Decision and Control (CDC), pp. 1096-1101; Smith, R.S., Covert misappropriation of networked control systems: Presenting a feedback structure (2015) Control Systems Magazine, IEEE, 35 (1), pp. 82-92; Mo, Y., Garone, E., Casavola, A., Sinopoli, B., False data injection attacks against state estimation in wireless sensor networks (2010) 49th IEEE Conference on Decision and Control (CDC), pp. 5967-5972; Fawzi, H., Tabuada, P., Diggavi, S., Secure estimation and control for cyber-physical systems under adversarial attacks (2014) IEEE Transactions on Automatic Control, 59 (6), pp. 1454-1467; Teixeira, A., Sou, K.C., Sandberg, H., Johansson, K.H., Secure control systems: A quantitative risk management approach (2015) IEEE Control Systems Magazine, 35 (1), pp. 24-45; Chong, M.S., Wakaiki, M., Hespanha, J.P., Observability of linear systems under adversarial attacks (2015) American Control Conference (ACC), pp. 2439-2444; Shoukry, Y., Chong, M., Wakiaki, M., De Nuzzo, P., Sangiovanni-Vincentelli, A.D., Seshia, S., Hespanha, J.P., Tabuada, P., SMT-based observer design for cyber physical systems under sensor attacks (2015) American Control Conference (ACC), pp. 2439-2444; Pajic, M., Weimer, J., Bezzo, N., Tabuada, P., Sokolsky, O., Lee, I., Pappas, G.J., Robustness of attack-resilient state estimators (2014) ICCPS'14: ACM/IEEE 5th International Conference on Cyber-Physical Systems (With CPS Week 2014), pp. 163-174; Mo, Y., Sinopoli, B., Secure estimation in the presence of integrity attacks (2015) Automatic Control, IEEE Transactions on, 60 (4), pp. 1145-1151; Shoukry, Y., Tabuada, P., Event-triggered state observers for sparse sensor noise/attacks (2013) IEEE Transactions on Automatic Control; Mo, Y., Hespanha, J.P., Sinopoli, B., Resilient detection in the presence of integrity attacks (2014) IEEE Transactions on Signal Processing, 62 (1), pp. 31-43; Pasqualetti, F., Dorfler, F., Bullo, F., Attack detection and identification in cyber-physical systems (2013) IEEE Transactions on Automatic Control, 58 (11), pp. 2715-2729; Yong, S., Zhu, M., Frazzoli, E., Resilient state estimation against switching attacks on stochastic cyber-physical systems (2015) IEEE International Conference on Decision and Control (CDC); Mishra, S., Shoukry, Y., Karamchandani, N., Diggavi, S., Tabuada, P., Secure state estimation: Optimal guarantees against sensor attacks in the presence of noise (2015) IEEE International Symposium on Information Theory (ISIT), pp. 2929-2933; Tiwari, A., Dutertre, B., Jovanovíc, D., De Candia, T., Lincoln, P.D., Rushby, J., Sadigh, D., Seshia, S., Safety envelope for security (2014) ACM Proceedings of the 3rd International Conference on High Confidence Networked Systems, pp. 85-94; Showkatbakhsh, M., Tabuada, P., Diggavi, S., System identification in the presence of adversarial outputs (2016) IEEE 55th Annual Conference on Decision and Control (CDC); Antsaklis, P.J., Michel, A.N., (2006) Linear Systems, , Springer Science & Business Media; Markovsky, I., Willems, J.C., Van Huffel, S., De Moor, B., (2006) Exact and Approximate Modeling of Linear Systems: A Behavioral Approach, 11. , SIAM; Van Overschee, P., De Moor, B., (2012) Subspace Identification for Linear Systems: Theory-Implementation-Applications, , Springer Science & Business Media; Ljung, L., (1987) System Identification: Theory for the User, , Englewood Cliffs; Howes, N.R., (2012) Modern Analysis and Topology, , Springer Science & Business Media",,,Coordinated Science Laboratory;Department of Electrical and Computer Engineering of the University of Illinois at Urbana-Champaign,Institute of Electrical and Electronics Engineers Inc.,"54th Annual Allerton Conference on Communication, Control, and Computing, Allerton 2016",27 September 2016 through 30 September 2016,,126437,,9.78E+12,,,English,"Annu. Allerton Conf. Commun., Control, Comput., Allerton",Conference Paper,Final,,Scopus,2-s2.0-85015235233
"Showkatbakhsh M., Tabuada P., Diggavi S.",55640653000;6603754297;7003736362;,System identification in the presence of adversarial outputs,2016,"2016 IEEE 55th Conference on Decision and Control, CDC 2016",,,7799376,7177,7182,,6,10.1109/CDC.2016.7799376,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010832459&doi=10.1109%2fCDC.2016.7799376&partnerID=40&md5=d53fe62337c133b77cd0fcfa4b861188,"UCLA Electrical Engineering Department, University of California, Los Angeles, CA  90095-1594, United States","Showkatbakhsh, M., UCLA Electrical Engineering Department, University of California, Los Angeles, CA  90095-1594, United States; Tabuada, P., UCLA Electrical Engineering Department, University of California, Los Angeles, CA  90095-1594, United States; Diggavi, S., UCLA Electrical Engineering Department, University of California, Los Angeles, CA  90095-1594, United States","We consider the problem of system identification of linear time invariant systems when some of the sensor measurements are changed by a malicious adversary. We treat adversaries as omniscient and impose no restrictions (statistical or otherwise) on how they can alter the measurements of the sensors under attack. Given a bound on the number of attacked sensors, and under a certain observability condition, we show that we can construct models that are useful for certain control purposes, e.g., stabilization. We also provide a precise characterization of the equivalence relation that identifies which models cannot be distinguished in the presence of attacks. © 2016 IEEE.",,,,,,,"Greenberg, A., (2015) Hackers Remotely Kill A Jeep on the Highway, with Me in It, , http//www.wired.com/2015/07/hackers-remotelykill-jeep-highway; Langner, R., Stuxnet: Dissecting a cyberwarfare weapon (2011) IEEE Security & Privacy, 9 (3), pp. 49-51; Cárdenas, A.A., Amin, S., Sastry, S., Research challenges for the security of control systems (2008) HotSec; Sundaram, S., Pajic, M., Hadjicostis, C.N., Mangharam, R., Pappas, G.J., The wireless control network: Monitoring for malicious behavior (2010) 49th IEEE Conference on Decision and Control (CDC), pp. 5979-5984; Amin, S., Schwartz, G.A., Hussain, A., Quest of benchmarking security risks to cyber-physical systems (2013) IEEE Network, 27 (1), pp. 19-24; Mo, Y., Kim, T.H.-J., Brancik, K., Dickinson, D., Lee, H., Perrig, A., Sinopoli, B., Cyber-physical security of a smart grid infrastructure (2012) Proceedings of the IEEE, 100 (1), pp. 195-209; Fawzi, H., Tabuada, P., Diggavi, S., Secure estimation and control for cyber-physical systems under adversarial attacks (2014) IEEE Transactions on Automatic Control, 59 (6), pp. 1454-1467; Mo, Y., Garone, E., Casavola, A., Sinopoli, B., False data injection attacks against state estimation in wireless sensor networks (2010) 49th IEEE Conference on Decision and Control (CDC), pp. 5967-5972; Teixeira, A., Sou, K.C., Sandberg, H., Johansson, K.H., Secure control systems: A quantitative risk management approach (2015) IEEE Control Systems Magazine, 35 (1), pp. 24-45; Mo, Y., Hespanha, J.P., Sinopoli, B., Resilient detection in the presence of integrity attacks (2014) IEEE Transactions on Signal Processing, 62 (1), pp. 31-43; Pasqualetti, F., Dorfler, F., Bullo, F., Attack detection and identification in cyber-physical systems (2013) IEEE Transactions on Automatic Control, 58 (11), pp. 2715-2729; Antsaklis, P.J., Michel, A.N., Linear systems (2006) Springer Science & Business Media; Showkatbakhsh, M., Tabuada, P., Diggavi, S., System identification in the presence of adversarial outputs Technical Report UCLA-CyPhyLab-2016-01, 2016. Electronically, , http//www.cyphylab.ee.ucla.edu/Home/publications; Zhu, M., Martinez, S., On the performance analysis of resilient networked control systems under replay attacks (2014) IEEE Transactions on Automatic Control, 59 (3), pp. 804-808; De Persis, C., Tesi, P., Input-to-state stabilizing control under denial-of-service (2015) IEEE Transactions on Automatic Control, 60 (11), pp. 2930-2944; Senejohnny, D., Tesi, P., De Persis, C., (2016) A Jamming-resilient Algorithm for Self-triggered Network Coordination, , arXiv preprint arXiv:1603.02563; Gupta, A., Langbort, C., Basar, T., Optimal control in the presence of an intelligent jammer with limited actions (2010) 49th IEEE Conference on Decision and Control (CDC), pp. 1096-1101; Smith, R.S., Covert misappropriation of networked control systems: Presenting a feedback structure (2015) Control Systems Magazine, IEEE, 35 (1), pp. 82-92; Chong, M.S., Wakaiki, M., Hespanha, J.P., Observability of linear systems under adversarial attacks (2015) American Control Conference (ACC), pp. 2439-2444; Shoukry, Y., Chong, M., Wakiaki, M., De Nuzzo, P., Sangiovanni-Vincentelli, A.D., Seshia, S., Hespanha, J.P., Tabuada, P., SMT-based observer design for cyber physical systems under sensor attacks (2015) American Control Conference (ACC), pp. 2439-2444; Pajic, M., Weimer, J., Bezzo, N., Tabuada, P., Sokolsky, O., Lee, I., Pappas, G.J., Robustness of attack-resilient state estimators (2014) ICCPS'14: ACM/IEEE 5th International Conference on Cyber-Physical Systems (With CPS Week 2014), pp. 163-174; Mo, Y., Sinopoli, B., Secure estimation in the presence of integrity attacks (2015) Automatic Control, IEEE Transactions on, 60 (4), pp. 1145-1151; Shoukry, Y., Tabuada, P., Event-triggered state observers for sparse sensor noise/attacks (2013) IEEE Transactions on Automatic Control; Yong, S., Zhu, M., Frazzoli, E., Resilient state estimation against switching attacks on stochastic cyber-physical systems (2015) IEEE International Conference on Decision and Control (CDC); Mishra, S., Shoukry, Y., Karamchandani, N., Diggavi, S., Tabuada, P., Secure state estimation: Optimal guarantees against sensor attacks in the presence of noise (2015) IEEE International Symposium on Information Theory (ISIT), pp. 2929-2933; Shoukry, Y., Nuzzo, P., Bezzo, N., Sangiovanni-Vincentelli, A.L., Seshia, S.A., Tabuada, P., Secure state reconstruction in differentially flat systems under sensor attacks using satisfiability modulo theory solving (2015) IEEE 54th Annual Conference on Decision and Control (CDC), pp. 3804-3809; Tiwari, A., Dutertre, B., Jovanovíc, D., De Candia, T., Lincoln, P.D., Rushby, J., Sadigh, D., Seshia, S., Safety envelope for security (2014) ACM Proceedings of the 3rd International Conference on High Confidence Networked Systems, pp. 85-94; Willems, J.C., Polderman, J.W., Introduction to mathematical systems theory: A behavioral approach (2013) Springer Science & Business Media, 26; Markovsky, I., Willems, J.C., Van Huffel, S., De Moor, B., Exact and approximate modeling of linear systems: A behavioral approach (2006) SIAM, 11",,,,Institute of Electrical and Electronics Engineers Inc.,"55th IEEE Conference on Decision and Control, CDC 2016",12 December 2016 through 14 December 2016,,125650,,9.78E+12,,,English,"IEEE Conf. Decis. Control, CDC 2016",Conference Paper,Final,,Scopus,2-s2.0-85010832459
"Mitra A., Sundaram S.",56080788000;15926451900;,Secure distributed observers for a class of linear time invariant systems in the presence of Byzantine adversaries,2016,"2016 IEEE 55th Conference on Decision and Control, CDC 2016",,,7798671,2709,2714,,32,10.1109/CDC.2016.7798671,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010818622&doi=10.1109%2fCDC.2016.7798671&partnerID=40&md5=a414bdcb3af1848ba566208f256da839,"School of Electrical and Computer Engineering, Purdue University, United States","Mitra, A., School of Electrical and Computer Engineering, Purdue University, United States; Sundaram, S., School of Electrical and Computer Engineering, Purdue University, United States","We study the problem of distributed state estimation of a linear time-invariant system by a network of nodes, some of which are subject to adversarial attacks. We develop a secure distributed estimation strategy subject to an f-locally bounded Byzantine adversary model, where a compromised node can arbitrarily deviate from the rules of any prescribed algorithm. Under such a threat model, we provide sufficient conditions guaranteeing the success of our estimation strategy. Our method relies on the construction of a subgraph, which we call a Mode Estimation Directed Acyclic Graph (MEDAG), for each unstable and marginally stable eigenvalue of the plant. We provide a distributed algorithm for constructing a MEDAG and characterize graph topologies for which the construction algorithm is guaranteed to succeed. Our approach provides fundamental insights into the relationship between the dynamics of the system, the measurement structure of the nodes, and the underlying graph topology. © 2016 IEEE.",,,,,,,"Olfati-Saber, R., Distributed Kalman filter with embedded consensus filters (2005) Proc. of the 44th IEEE Conference on Decision and Control and European Control Conference, pp. 8179-8184; Olfati-Saber, R., Distributed Kalman filtering for sensor networks (2007) Proc. of the 46th IEEE Conference on Decision and Control, pp. 5492-5498; Khan, U.A., Jadbabaie, A., On the stability and optimality of distributed Kalman filters with finite-time data fusion (2011) Proc. of the American Control Conference, pp. 3405-3410; Khan, U., Kar, S., Jadbabaie, A., Moura, J.M., On connectivity, observability, and stability in distributed estimation (2010) Proc. of the 49th IEEE Conference on Decision and Control, pp. 6639-6644; Park, S., Martins, N.C., Necessary and sufficient conditions for the stabilizability of a class of LTI distributed observers (2012) Proc. of the 47th IEEE Conference on Decision and Control, pp. 7431-7436; Park, S., Martins, N.C., Design of distributed LTI observers for state omniscience IEEE Transactions on Automatic Control, , to appear; Mitra, A., Sundaram, S., (2016) Distributed Observers for LTI Systems, , arXiv preprint arXiv: 1608. 01429; Zhang, H., Sundaram, S., Robustness of information diffusion algorithms to locally bounded adversaries (2012) Proc. of the American Control Conference, pp. 5855-5861; LeBlanc, H.J., Zhang, H., Koutsoukos, X., Sundaram, S., Resilient asymptotic consensus in robust networks (2013) IEEE Journal on Selected Areas in Communications, 31 (4), pp. 766-781; Vaidya, N.H., Tseng, L., Liang, G., Iterative approximate byzantine consensus in arbitrary directed graphs (2012) Proc. of the 2012 ACM Symposium on Principles of Distributed Computing. ACM, pp. 365-374; Tseng, L., Vaidya, N., Bhandari, V., (2012) Broadcast Using Certified Propagation Algorithm in Presence of Byzantine Faults, , arXiv preprint arXiv: 1209. 4620; Sundaram, S., Gharesifard, B., Consensus-based distributed optimization with malicious nodes (2015) Proc. of the 53rd Annual Allerton Conference on Communication, Control, and Computing (Allerton), pp. 244-249; Su, L., Vaidya, N., (2015) Byzantine Multi-agent Optimization: Part i, , arXiv preprint arXiv: 1506. 04681; Shames, I., Teixeira, A.M., Sandberg, H., Johansson, K.H., Distributed fault detection for interconnected second-order systems (2011) Automatica, 47 (12), pp. 2757-2764; Matei, I., Baras, J.S., Srinivasan, V., Trust-based multi-agent filtering for increased smart grid security (2012) Proc. of the 20th Mediterranean Conference on Control & Automation, pp. 716-721; Jiang, T., Matei, I., Baras, J., A trust based distributed Kalman filtering approach for mode estimation in power systems (2010) Proc. of the First Workshop on Secure Control Systems; Khan, U., Stankovic, A.M., Secure distributed estimation in cyberphysical systems (2013) Proc. of the IEEE International Conference on Acoustics, Speech and Signal Processing, pp. 5209-5213; Dolev, D., Lynch, N.A., Pinter, S.S., Stark, E.W., Weihl, W.E., Reaching approximate agreement in the presence of faults (1986) Journal of the ACM (JACM), 33 (3), pp. 499-516; Koo, C.-Y., Broadcast in radio networks tolerating byzantine adversarial behavior (2004) Proc. of the Twenty-Third Annual ACM Symposium on Principles of Distributed Domputing. ACM, pp. 275-282; Pelc, A., Peleg, D., Broadcasting with locally bounded byzantine faults (2005) Information Processing Letters, 93 (3), pp. 109-115; Chen, C.-T., (1995) Linear System Theory and Design, , Oxford University Press, Inc",,,,Institute of Electrical and Electronics Engineers Inc.,"55th IEEE Conference on Decision and Control, CDC 2016",12 December 2016 through 14 December 2016,,125650,,9.78E+12,,,English,"IEEE Conf. Decis. Control, CDC 2016",Conference Paper,Final,,Scopus,2-s2.0-85010818622
"Hu Q., Chang Y.H., Tomlin C.J.",56704101800;51461119200;7005284849;,Secure estimation for unmanned aerial vehicles against adversarial cyber attacks,2016,"30th Congress of the International Council of the Aeronautical Sciences, ICAS 2016",,,,,,,6,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013683719&partnerID=40&md5=1ee07b4b3d7208482ded9a3acfbe2e89,"Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, CA  94720, United States; Department of Biomedical Engineering, Oregon Health and Science UniversityOR  97239, United States","Hu, Q., Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, CA  94720, United States; Chang, Y.H., Department of Biomedical Engineering, Oregon Health and Science UniversityOR  97239, United States; Tomlin, C.J., Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, CA  94720, United States","In the coming years, usage of Unmanned Aerial Vehicles (UAVs) is expected to grow tremendously. Maintaining security of UAVs under cyber attacks is an important yet challenging task, as these attacks are often erratic and difficult to predict. Secure estimation problems study how to estimate the states of a dynamical system from a set of noisy and maliciously corrupted sensor measurements. The fewer assumptions that an estimator makes about the attacker, the larger the set of attacks it can protect the system against. In this paper, we focus on sensor attacks on UAVs and attempt to design a secure estimator for linear time-invariant systems based on as few assumptions about the attackers as possible. We propose a computationally efficient estimator that protects the system against arbitrary and unbounded attacks, where the set of attacked sensors can also change over time. In addition, we propose to combine our secure estimator with a Kalman Filter for improved practical performance and demonstrate its effectiveness through simulations of two scenarios where an UAV is under adversarial cyber attack.",Cyber attacks; Error correction; Secure estimation; UAV,Crime; Dynamical systems; Error correction; Invariance; Linear systems; Network security; Time varying control systems; Unmanned aerial vehicles (UAV); Computationally efficient; Cyber-attacks; Estimation problem; Linear time invariant systems; Sensor measurements; Computer crime,,,,,"Press Release - DOT and FAA Propose New Rules for Small Unmanned Aircraft Systems, , http://www.faa.gov/news/pressreleases/newsstory.cfm/?newsId=18295, accessed: 2015-02-15; Google Project Wing, , http://www.theatlantic.com/technology/archive/2014/08/inside-googles-secret-drone-delivery-program/379306/?singlepage=true, accessed: 2014-08-28; Amazon Prime Air, , http://www.amazon.com/b?node=8037720011; Ascending Technologies, , http://www.asctec.de/en/drone-uav/uav-uas-drone-powerline-infrastructure-inspection/; UAS: The Future of Precision Agriculture, , http://www.croplife.com/equipment/precision-ag/uas-the-future-of-precision-agriculture/; Pasqualetti, F., Dorfler, F., Bullo, F., Cyber-physical attacks in power networks: Models, fundamental limitations and monitor design (2011) 50th IEEE Conference on Decision and Control and European Control Conference, pp. 2195-2201. , December; Manandhar, K., Cao, X., Hu, F., Liu, Y., Combating false data injection attacks in smart grid using Kalman filter (2014) International Conference on Computing, pp. 16-20. , Networking and Communications February; Roy, S., Ellis, C., Shiva, S., Dasgupta, D., Shandilya, V., Wu, Q., A survey of game theory as applied to network security (2010) 43rd Hawaii International Conference on System Sciences; Gupta, A., Langbort, C., Basar, T., Optimal control in the presence of an intelligent jammer with limited actions (2010) 49th IEEE Conference on Decision and Control, pp. 1096-1101. , December; Manshaei, M.H., Zhu, Q., Alpcan, T., Basar, T., Hubaux, J.-P., Game theory meets network security and privacy (2013) ACM Computing Surveys, 45 (3). , June; Gueye, A., Marbukh, V., Walrand, J.C., Towards a metric for communication network vulnerability to attacks: A game theoretic approach (2012) 3rd International ICST Conference on Game Theory for Networks, , May; Fei, M., Pajic, M., Pappas, G.J., Stochastic game approach for replay attack detection (2013) 52nd IEEE Conference on Decision and Control, pp. 1854-1859. , December; Fawzi, H., Tabuada, P., Diggavi, S., Secure estimation and control for cyber-physical systems under adversarial attacks (2014) Automatic Control, IEEE Transactions On, 59 (6), pp. 1454-1467. , June; Candes, E., Tao, T., Decoding by linear programming (2005) Information Theory, IEEE Transactions On, 51 (12 P), pp. 4203-4215. , Dec; Hayden, D., Chang, Y.H., Goncalves, J., Tomlin, C., Sparse network identifiability via compressed sensing (2016) Automatica, 52; Chang, Y.H., Hu, Q., Tomlin, C., (2015) Secure Estimation Based Kalman Filter for Cyber-Physical Systems Against Adversarial Attacks, , arXiv:1512.03853v2; Kwon, C., Liu, W., Hwang, I., Security analysis for cyber-physical systems against stealthy deception attacks (2013) American Control Conference; Bouffard, P., (2012) On-board Model Predictive Control of a Quadrotor Helicopter: Design, Implementation, and Experiments, , http://www.eecs.berkeley.edu/Pubs/TechRpts/2012/EECS-2012-241.html, University of California Berkeley Technical Report UCB/EECS-2012-241, December",,,,International Council of the Aeronautical Sciences,"30th Congress of the International Council of the Aeronautical Sciences, ICAS 2016",25 September 2016 through 30 September 2016,,126186,,9.78E+12,,,English,"Congr. Int. Counc. Aeronaut. Sci., ICAS",Conference Paper,Final,,Scopus,2-s2.0-85013683719
"Chen C., Jia L., Xu H., Luo C., Zhou W., Loo B.T.",57196286029;35558803200;56209123400;56208763000;55475947600;8700326800;,A program logic for verifying secure routing protocols,2015,Logical Methods in Computer Science,11,4,,,,,2,10.2168/LMCS-11(4:19)2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957928265&doi=10.2168%2fLMCS-11%284%3a19%292015&partnerID=40&md5=ba53c33ece9650f28edce428f4bfe5d9,"University of Pennsylvania, United States; Carnegie Mellon University, United States; Georgetown University, United States","Chen, C., University of Pennsylvania, United States; Jia, L., Carnegie Mellon University, United States; Xu, H., University of Pennsylvania, United States; Luo, C., University of Pennsylvania, United States; Zhou, W., Georgetown University, United States; Loo, B.T.","The Internet, as it stands today, is highly vulnerable to attacks. However, little has been done to understand and verify the formal security guarantees of proposed secure inter-domain routing protocols, such as Secure BGP (S-BGP). In this paper, we develop a sound program logic for SANDLog—a declarative specification language for secure routing protocols—for verifying properties of these protocols. We prove invariant properties of SANDLog programs that run in an adversarial environment. As a step towards automated verification, we implement a verification condition generator (VCGen) to automatically extract proof obligations. VCGen is integrated into a compiler for SANDLog that can generate executable protocol implementations; and thus, both verification and empirical evaluation of secure routing protocols can be carried out in this unified framework. To validate our framework, we encoded several proposed secure routing mechanisms in SANDLog, verified variants of path authenticity properties by manually discharging the generated verification conditions in Coq, and generated executable code based on SANDLog specification and ran the code in simulation. © 2015 Logical Methods in Computer Science.",Declarative networking; Program logic; Routing protocols,Formal logic; Reconfigurable hardware; Routing protocols; Specification languages; Specifications; Theorem proving; Adversarial environments; Automated verification; Declarative networkings; Program logic; Protocol implementation; Secure inter-domain routing; Secure routing protocols; Verification condition; Computer circuits,,,,,"http://www.nsnam.org/; Arnaud, M., Cortier, V., Delaune, S., Modeling and verifying ad hoc routing protocols (2010) Proceedings of CSF; Arnaud, M., Cortier, V., Delaune, S., Deciding security for protocols with recursive tests (2011) Proceedings of CADE; Bau, J., Mitchell, J., A security evaluation of DNSSEC with NSEC3 (2010) Proceedings of NDSS; Bhargavan, K., Obradovic, D., Gunter, C.A., Formal verification of standards for distance vector routing protocols (2002) J. ACM, 49 (4); Blanchet, B., Automatic verification of correspondences for security protocols (2009) J. Comput. Secur, 17 (4); Blanchet, B., Smyth, B., Proverif 1.86: Automatic Cryptographic Protocol Verifier, User Manual and Tutorial, , http://www.proverif.ens.fr/manual.pdf; Chen, C., Jia, L., Loo, B.T., Zhou, W., Reduction-based security analysis of internet routing protocols (2012) Wripe; Chen, C., Jia, L., Xu, H., Luo, C., Zhou, W., Loo, B.T., (2014) A Program Logic for Verifying Secure Routing Protocols; How Pakistan Knocked Youtube Offline, , http://news.cnet.com/8301-10784_3-9878655-7.html; Cortier, V., Degrieck, J., Delaune, S., Analysing routing protocols: Four nodes topologies are sufficient (2012) Proceedings of POST; Datta, A., Derek, A., Mitchell, J.C., Roy, A., Protocol Composition Logic (PCL) (2007) Electronic Notes in Theoretical Computer Science, 172, pp. 311-358; Engler, D., Musuvathi, M., Model-checking large network protocol implementations (2004) Proceedings of NSDI; Escobar, S., Meadows, C., Meseguer, J., A rewriting-based inference system for the NRL protocol analyzer: Grammar generation (2005) Proceedings of FMSE; Garg, D., Franklin, J., Kaynar, D., Datta, A., Compositional system security with interface-confined adversaries (2010) ENTCS, 265, pp. 49-71; Goodloe, A., Gunter, C.A., Stehr, M.O., Formal prototyping in early stages of protocol design (2005) Proceedings of ACM WITS; He, C., Sundararajan, M., Datta, A., Derek, A., Mitchell, J.C., A modular correctness proof of IEEE 802.11i and TLS (2005) Proceedings of CCS; Kamp, H.W., (1968) Tense Logic and the Theory of Linear Order, , Phd thesis, Computer Science Department, University of California at Los Angeles, USA; Kent, S., Lynn, C., Mikkelson, J., Seo, K., Secure border gateway protocol (S-BGP) (2000) IEEE Journal on Selected Areas in Communications, 18, pp. 103-116; Loo, B.T., Condie, T., Garofalakis, M., Gay, D.E., Hellerstein, J.M., Maniatis, P., Ramakrishnan, R., Stoica, I., Declarative Networking: Language, Execution and Optimization (2006) SIGMOD; Loo, B.T., Condie, T., Garofalakis, M., Gay, D.E., Hellerstein, J.M., Maniatis, P., Ramakrishnan, R., Stoica, I., Declarative networking (2009) Communications of the ACM; Loo, B.T., Hellerstein, J.M., Stoica, I., Ramakrishnan, R., Declarative Routing: Extensible Routing with Declarative Queries (2005) SIGCOMM; Naous, J., Walfish, M., Nicolosi, A., Mazieres, D., Miller, M., Seehra, A., Verifying and enforcing network paths with ICING (2011) Proceedings of Conext; Nigam, V., Jia, L., Loo, B.T., Scedrov, A., Maintaining distributed logic programs incrementally (2011) Proceedings of PPDP; (2010), http://www.uscc.gov/annual_report/2010/annual_report_full_10.pdf; Paulson, L.C., Mechanized proofs for a recursive authentication protocol (1997) Proceedings of CSFW; A Declarative Toolkit for Rapid Network Simulation and Experimentation, , http://netdb.cis.upenn.edu/rapidnet/; Rivest, R.L., Shamir, A., Adleman, L.M., A method for obtaining digital signatures and public-key cryptosystems (Reprint) (1983) Commun. ACM, 26 (1), pp. 96-99. , http://doi.acm.org/10.1145/357980.358017; Roy, A., Datta, A., Derek, A., Mitchell, J.C., Jean-Pierre, S., Secrecy analysis in protocol composition logic (2007) Proceedings of ESORICS; http://www.ir.bbn.com/sbgp/; Wan, T., Kranakis, E., Oorschot, P.C., Pretty secure BGP (PsBGP) (2005) Proceedings of 12Th NDSS; White, R., Securing bgp through secure origin BGP (SoBGP) (2003) The Internet Protocol Journal, 6 (3), pp. 15-22; Zhang, X., Hsiao, H.C., Hasker, G., Chan, H., Perrig, A., Ersen, D.G., Scion: Scalability, control, and isolation on next-generation networks (2011) Proceedings of Oakland S&P",,,,Logical Methods in Computer Science,,,,,18605974,,,,English,Log. Methods Comp. Sci.,Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-84957928265
"Neville S.W., Elgamal M., Nikdel Z.",35894525300;57130461700;55327116800;,Robust adversarial learning and invariant measures,2015,"IEEE Pacific RIM Conference on Communications, Computers, and Signal Processing - Proceedings",2015-November,,7334893,529,535,,,10.1109/PACRIM.2015.7334893,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958755028&doi=10.1109%2fPACRIM.2015.7334893&partnerID=40&md5=5607d7f1b568e942bc31cce1725a22c0,"Department of Electrical and Computer Engineering, University of Victoria, STN CSC, P.O. Box 3055, Victoria, BC  V8W 3P6, Canada","Neville, S.W., Department of Electrical and Computer Engineering, University of Victoria, STN CSC, P.O. Box 3055, Victoria, BC  V8W 3P6, Canada; Elgamal, M., Department of Electrical and Computer Engineering, University of Victoria, STN CSC, P.O. Box 3055, Victoria, BC  V8W 3P6, Canada; Nikdel, Z., Department of Electrical and Computer Engineering, University of Victoria, STN CSC, P.O. Box 3055, Victoria, BC  V8W 3P6, Canada","A number of open cyber-security challenges are arising due to the rapidly evolving scale, complexity, and heterogeneity of modern IT systems and networks. The ease with which copious volumes of operational data can be collected from such systems has produced a strong interest in the use of machine learning (ML) for cyber-security, provided that ML can itself be made sufficiently immune to attack. Adversarial learning (AL) is the domain focusing on such issues and an arising AL theme is the need to ensure that ML solutions make use of robust input measurement features (i.e., the data sets used for ML training must themselves be robust against adversarial influences). This observation leads to further open questions, including: ""What formally denotes sufficient robustness?"", ""Must robust features necessarily exist for all IT systems?"", ""Do robust features necessarily provide complete coverage of the attack space?"", etc. This work shows that these (and other) open AL questions can be usefully re-cast in terms of the classical dynamical system's problem of needing to focus analyses on a system's invariant measures. This re-casting is useful as a large body of mature dynamical systems theory exists concerning invariant measures which can then be applied to cyber-security. To our knowledge this the first work to identify and highlight this potentially useful cross-domain linkage. © 2015 IEEE.",,Aluminum; Artificial intelligence; Complex networks; Dynamical systems; Learning systems; Adversarial learning; Attack spaces; Complete coverages; Cross-domain; Cyber security; Input measurements; Invariant measure; Operational data; Signal processing,,,,,"Gubbi, J., Buyya, R., Marusic, S., Palaniswami, M., Internet of things (iot): A vision, architectural elements, and future directions (2013) Future Generation Computer Systems, 29 (7), pp. 1645-1660; Khurana, H., Hadley, M., Lu, N., Frincke, D.A., Smart-grid security issues (2010) IEEE Security & Privacy, (1), pp. 81-85; Kearns, M., Li, M., Learning in the presence of malicious errors (1993) SIAM Journal on Computing, 22 (4), pp. 807-837; Lowd, D., Meek, C., Adversarial learning (2005) Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining, pp. 641-647. , ACM; Barreno, M., Nelson, B., Joseph, A.D., Tygar, J., The security of machine learning (2010) Machine Learning, 81 (2), pp. 121-148; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I., Tygar, J., Adversarial machine learning (2011) Proceedings of the 4th ACM Workshop on Security and Artificial Intelligence, pp. 43-58. , ACM; Biggio, B., Fumera, G., Roli, F., Security evaluation of patternclassifiers under attack (2014) Knowledge and Data Engineering, IEEE Transactions on, 26 (4), pp. 984-996; Rubinstein, B.I., Nelson, B., Huang, L., Joseph, A.D., Lau, S.-H., Rao, S., Taft, N., Tygar, J., Antidote: Understanding and defending against poisoning of anomaly detectors (2009) Proceedings of the 9th ACM SIGCOMM Conference on Internet Measurement Conference, pp. 1-14. , ACM; Peebles, P.Z., Read, J., Read, P., (2001) Probability, Random Variables, and Random Signal Principles, 3. , McGraw-Hill New York; Fawcett, T., Provost, F.J., Combining data mining and machine learning for effective user profiling (1996) KDD, pp. 8-13; Ngai, E., Hu, Y., Wong, Y., Chen, Y., Sun, X., The application of data mining techniques in financial fraud detection: A classification framework and an academic review of literature (2011) Decision Support Systems, 50 (3), pp. 559-569; Sahami, M., Dumais, S., Heckerman, D., Horvitz, E., A bayesian approach to filtering junk e-mail (1998) Learning for Text Categorization: Papers from the 1998 Workshop, 62, pp. 98-105; Blanzieri, E., Bryl, A., A survey of learning-based techniques of email spam filtering (2008) Artificial Intelligence Review, pp. 63-92; Androutsopoulos, I., Koutsias, J., Chandrinos, K.V., Paliouras, G., Spyropoulos, C.D., (2000) An Evaluation of Naive Bayesian Anti-spam Filtering, , arXiv preprint cs/0006013; Sommer, R., Paxson, V., Outside the closed world: On using machine learning for network intrusion detection (2010) Security and Privacy (SP), 2010 IEEE Symposium on, pp. 305-316. , IEEE; Fette, I., Sadeh, N., Tomasic, A., Learning to detect phishing emails (2007) Proceedings of the 16th International Conference on World Wide Web, pp. 649-656. , ACM; Dua, S., Du, X., (2011) Data Mining and Machine Learning in Cybersecurity, , CRC press; Lowd, D., Meek, C., Good word attacks on statistical spam filters (2005) CEAS; Fogla, P., Sharif, M.I., Perdisci, R., Kolesnikov, O.M., Lee, W., Polymorphic blending attacks (2006) USENIX Security; Newsome, J., Karp, B., Song, D., Paragraph: Thwarting signature learning by training maliciously (2006) Recent Advances in Intrusion Detection, pp. 81-105. , Springer; Barreno, M., Bartlett, P.L., Chi, F.J., Joseph, A.D., Nelson, B., Rubinstein, B.I., Saini, U., Tygar, J.D., Open problems in the security of learning (2008) Proceedings of the 1st ACM Workshop on Workshop on AISec, pp. 19-26. , ACM; Hampel, F.R., Ronchetti, E.M., Rousseeuw, P.J., Stahel, W.A., (2011) Robust Statistics: The Approach Based on Influence Functions, 114. , John Wiley & Sons; Huber, P.J., (2011) Robust Statistics, , Springer; Christian, S.F., Lebiere, C., The cascade-correlation learning architecture (1990) Advances in Neural Information Processing Systems, 2. , Citeseer; Gray, R.M., Gray, R., (1988) Probability, Random Processes, and Ergodic Properties, , Springer; Walters, P., (2000) An Introduction to Ergodic Theory, 79. , Springer Science & Business Media; De Almeida, A.M.O., (1990) Hamiltonian Systems: Chaos and Quantization, , Cambridge University Press; Lubotzky, A., (2010) Discrete Groups, Expanding Graphs and Invariant Measures, , Springer Science & Business Media; Meyn, S.P., Tweedie, R., Stability of markovian processes i: Criteria for discrete-time chains (1992) Advances in Applied Probability, pp. 542-574; Da Prato, G., Zabczyk, J., (1996) Ergodicity for Infinite Dimensional Systems, 229. , Cambridge University Press",,,,Institute of Electrical and Electronics Engineers Inc.,"IEEE Pacific Rim Conference on Communications, Computers and Signal Processing, PACRIM 2015",24 August 2015 through 26 August 2015,,118373,,9.78E+12,,,English,IEEE Pac RIM Conf Commun Comput Signal Process Proc,Conference Paper,Final,,Scopus,2-s2.0-84958755028
"Chen C., Jia L., Xu H., Luo C., Zhou W., Loo B.T.",57196286029;35558803200;56209123400;56208763000;55475947600;8700326800;,A program logic for verifying secure routing protocols,2014,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),8461 LNCS,,,117,132,,2,10.1007/978-3-662-43613-4_8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902602241&doi=10.1007%2f978-3-662-43613-4_8&partnerID=40&md5=c7ad63c2828c0d2a2bc737ed290f88c4,"University of Pennsylvania, Philadelphia, PA, United States; Carnegie Mellon University, Pittsburgh, PA, United States; Georgetown University, Washington, United States","Chen, C., University of Pennsylvania, Philadelphia, PA, United States; Jia, L., Carnegie Mellon University, Pittsburgh, PA, United States; Xu, H., University of Pennsylvania, Philadelphia, PA, United States; Luo, C., University of Pennsylvania, Philadelphia, PA, United States; Zhou, W., Georgetown University, Washington, United States; Loo, B.T., University of Pennsylvania, Philadelphia, PA, United States","The Internet, as it stands today, is highly vulnerable to attacks. However, little has been done to understand and verify the formal security guarantees of proposed secure inter-domain routing protocols, such as Secure BGP (S-BGP). In this paper, we develop a sound program logic for SANDLog-a declarative specification language for secure routing protocols-for verifying properties of these protocols. We prove invariant properties of SANDLog programs that run in an adversarial environment. As a step towards automated verification, we implement a verification condition generator (VCGen) to automatically extract proof obligations. VCGen is integrated into a compiler for SANDLog that can generate executable protocol implementations; and thus, both verification and empirical evaluation of secure routing protocols can be carried out in this unified framework. To validate our framework, we (1) encoded several proposed secure routing mechanisms in SANDLog, (2) verified variants of path authenticity properties by manually discharging the generated verification conditions in Coq, and (3) generated executable code based on SANDLog specification and ran the code in simulation. © 2014 IFIP International Federation for Information Processing.",,Formal logic; Specification languages; Theorem proving; Adversarial environments; Automated verification; Empirical evaluations; Invariant properties; Protocol implementation; Secure inter-domain routing; Secure routing protocols; Verification condition; Routing protocols,,,,,"ns 3 Project: Network Simulator 3, , http://www.nsnam.org/; Arnaud, M., Cortier, V., Delaune, S., Modeling and verifying ad hoc routing protocols Proceedings of CSF (2010); Arnaud, M., Cortier, V., Delaune, S., Deciding security for protocols with recursive tests (2011) LNCS, 6803, pp. 49-63. , Bjørner, N., Sofronie-Stokkermans, V. (eds.) CADE 2011. Springer, Heidelberg; Bau, J., Mitchell, J., A security evaluation of DNSSEC with NSEC3 Proceedings of NDSS (2010); Bhargavan, K., Obradovic, D., Gunter, C.A., Formal verification of standards for distance vector routing protocols (2002) J. ACM, 49 (4); Blanchet, B., Automatic verification of correspondences for security protocols (2009) J. Comput. Secur., 17 (4). , December; Blanchet, B., Smyth, B., Proverif 1.86: Automatic Cryptographic Protocol Verifier, User Manual and Tutorial, , http://www.proverif.ens.fr/manual.pdf; Chen, C., Jia, L., Loo, B.T., Zhou, W., Reduction-based security analysis of internet routing protocols (2012) WRiPE; Chen, C., Jia, L., Xu, H., Luo, C., Zhou, W., Loo, B.T., (2014) A Program Logic for Verifying Secure Routing Protocols, , http://netdb.cis.upenn.edu/forte2014, Tech. rep., CIS Dept. University of Pennsylvania February; How Pakistan Knocked Youtube Offline, , http://news.cnet.com/8301-10784_3-9878655-7.html, CNET; Cortier, V., Degrieck, J., Delaune, S., Analysing routing protocols: Four nodes topologies are sufficient (2012) LNCS, 7215, pp. 30-50. , Degano, P., Guttman, J.D. (eds.) POST. Springer, Heidelberg; Datta, A., Derek, A., Mitchell, J.C., Roy, A., Protocol Composition Logic (PCL) (2007) Electronic Notes in Theoretical Computer Science, 172, pp. 311-358; Engler, D., Musuvathi, M., Model-checking large network protocol implementations Proceedings of NSDI (2004); Escobar, S., Meadows, C., Meseguer, J., A rewriting-based inference system for the NRL protocol analyzer: Grammar generation Proceedings of FMSE (2005); Garg, D., Franklin, J., Kaynar, D., Datta, A., Compositional system security with interface-confined adversaries (2010) ENTCS, 265, pp. 49-71; Goodloe, A., Gunter, C.A., Stehr, M.O., Formal prototyping in early stages of protocol design Proceedings of ACM WITS (2005); He, C., Sundararajan, M., Datta, A., Derek, A., Mitchell, J.C., A modular correctness proof of IEEE 802.11i and TLS Proceedings of CCS (2005); Kamp, H.W., (1968) Tense Logic and the Theory of Linear Order, , Phd thesis, Computer Science Department, University of California at Los Angeles, USA; Kent, S., Lynn, C., Mikkelson, J., Seo, K., Secure border gateway protocol (SBGP) (2000) IEEE Journal on Selected Areas in Communications, 18, pp. 103-116; Loo, B.T., Condie, T., Garofalakis, M., Gay, D.E., Hellerstein, J.M., Maniatis, P., Ramakrishnan, R., Stoica, I., Declarative Networking: Language, Execution and Optimization (2006) SIGMOD; Loo, B.T., Condie, T., Garofalakis, M., Gay, D.E., Hellerstein, J.M., Maniatis, P., Ramakrishnan, R., Stoica, I., Declarative networking (2009) Communications of the ACM; Naous, J., Walfish, M., Nicolosi, A., Mazieres, D., Miller, M., Seehra, A., Verifying and enforcing network paths with ICING Proceedings of CoNEXT (2011); Nigam, V., Jia, L., Loo, B.T., Scedrov, A., Maintaining distributed logic programs incrementally Proceedings of PPDP (2011); (2010) One Hundred Eleventh Congress: 2010 Report to Congress of the U.S.-china Economic and Security Review Commission, , http://www.uscc.gov/annual_report/2010/annual_report_full_10.pdf; Paulson, L.C., Mechanized proofs for a recursive authentication protocol Proceedings of CSFW (1997); A Declarative Toolkit for Rapid Network Simulation and Experimentation, , http://netdb.cis.upenn.edu/rapidnet/, RapidNet; Roy, A., Datta, A., Derek, A., Mitchell, J.C., Seifert, J.-P., Secrecy analysis in protocol composition logic (2007) LNCS, 4435, pp. 197-213. , Okada, M., Satoh, I. (eds.) ASIAN 2006. Springer, Heidelberg; Wan, T., Kranakis, E., Oorschot, P.C., Pretty secure BGP (psBGP) Proceedings of NDSS (2005); Wang, A., Basu, P., Loo, B.T., Sokolsky, O., Declarative network verification (2008) LNCS, 5418, pp. 61-75. , Gill, A., Swift, T. (eds.) PADL 2009. Springer, Heidelberg; White, R., Securing bgp through secure origin BGP (soBGP) (2003) The Internet Protocol Journal, 6 (3), pp. 15-22; Zhang, X., Hsiao, H.C., Hasker, G., Chan, H., Perrig, A., Andersen, D.G., Scion: Scalability, control, and isolation on next-generation networks Proceedings of IEEE S&P (2011)",,,International Federation for Information Processing (IFIP),Springer Verlag,"34th IFIPWG6.1 International Conference on Formal Techniques for Distributed Objects, Components, and Systems, FORTE 2014 - Held as Part of the 9th International Federated Conference on Distributed Computing Techniques, DisCoTec 2014",3 June 2014 through 5 June 2014,Berlin,105567,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,"All Open Access, Bronze, Green",Scopus,2-s2.0-84902602241
