Authors,Author(s) ID,Title,Year,Source title,Volume,Issue,Art. No.,Page start,Page end,Page count,Cited by,DOI,Link,Affiliations,Authors with affiliations,Abstract,Author Keywords,Index Keywords,Molecular Sequence Numbers,Chemicals/CAS,Tradenames,Manufacturers,References,Correspondence Address,Editors,Sponsors,Publisher,Conference name,Conference date,Conference location,Conference code,ISSN,ISBN,CODEN,PubMed ID,Language of Original Document,Abbreviated Source Title,Document Type,Publication Stage,Open Access,Source,EID
"Zhang X., Zheng X., Mao W.",57192912049;57192908413;7201436830;,Adversarial Perturbation Defense on Deep Neural Networks,2022,ACM Computing Surveys,54,8,159,,,,,10.1145/3465397,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116697245&doi=10.1145%2f3465397&partnerID=40&md5=c0d922be81f0da460ba2e763617fa304,"School of Artificial Intelligence, University of Chinese Academy of Sciences; The State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China","Zhang, X., School of Artificial Intelligence, University of Chinese Academy of Sciences, The State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Zheng, X., School of Artificial Intelligence, University of Chinese Academy of Sciences, The State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Mao, W., School of Artificial Intelligence, University of Chinese Academy of Sciences, The State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China","Deep neural networks (DNNs) have been verified to be easily attacked by well-designed adversarial perturbations. Image objects with small perturbations that are imperceptible to human eyes can induce DNN-based image class classifiers towards making erroneous predictions with high probability. Adversarial perturbations can also fool real-world machine learning systems and transfer between different architectures and datasets. Recently, defense methods against adversarial perturbations have become a hot topic and attracted much attention. A large number of works have been put forward to defend against adversarial perturbations, enhancing DNN robustness against potential attacks, or interpreting the origin of adversarial perturbations. In this article, we provide a comprehensive survey on classical and state-of-the-art defense methods by illuminating their main concepts, in-depth algorithms, and fundamental hypotheses regarding the origin of adversarial perturbations. In addition, we further discuss potential directions of this domain for future researchers. © 2021 Association for Computing Machinery.",Adversarial perturbation defense; deep neural networks; origin; security,Network security; Adversarial perturbation defense; High probability; Human eye; Image objects; Machine learning systems; Network-based; Origin; Real-world; Security; Small perturbations; Deep neural networks,,,,,"Deng, L., Yu, D., Deep learning: Methods and applications (2014) Foundations and Trends in Signal Processing, 7 (3-4), pp. 197-387. , 2014; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , https://arXiv:1312.6199, Retrieved June 25, 2021; Yuan, X., He, P., Zhu, Q., Li, X., Adversarial examples: Attacks and defenses for deep learning (2019) IEEE Transactions on Neural Networks and Learning Systems, 30 (9), pp. 2805-2824. , 2019; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Blackbox Attacks Using Adversarial Samples, , https://arXiv:1605.07277.s, Retrieved June 25, 2021; Liu, Y., Chen, X., Liu, C., Song, D., (2016) Delving into Transferable Adversarial Examples and Black-box Attacks, , https://arXiv:1611.02770, Retrieved June 25, 2021; Meng, D., Chen, H., Magnet: A two-pronged defense against adversarial examples (2017) Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security. ACM, Dallas, TX USA, pp. 135-147; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts, , https://arXiv:1703.00410, Retrieved June 25, 2021; Goodfellow, I., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , https://arXiv:1412.6572, Retrieved June 25, 2021; Miyato, T., Maeda, S.-I., Koyama, M., Ishii, S., Virtual adversarial training: A regularization method for supervised and semi-supervised learning (2018) IEEE Transactions on Pattern Analysis and Machine Intelligence, 41 (8), pp. 1979-1993. , 2018; Schmidt, L., Santurkar, S., Tsipras, D., Talwar, K., Madry, A., Adversarially robust generalization requiresmore data (2018) Advances in Neural Information Processing Systems. MIT Press, Palais des Congres de Montreal, Montreal Canada, pp. 5019-5031; Tanay, T., Griffin, L., (2016) A Boundary Tilting Perspective on the Phenomenon of Adversarial Examples, , https://arXiv:1608.07690, Retrieved June 25, 2021; Cisse, M., Bojanowski, P., Grave, E., Dauphin, Y., Usunier, N., Parseval networks: Improving robustness to adversarial examples (2017) Proceedings of the 34th International Conference on Machine Learning. ACM, Sydney, NSW Australia, pp. 854-863; Gopinath, D., Katz, G., Pasareanu, C.S., Barrett, C., (2017) Deepsafe: A Data-driven Approach for Checking Adversarial Robustness in Neural Networks, , https://arXiv:1710.00486, Retrieved June 25, 2021; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) 2016 IEEE Symposium on Security and Privacy (SP'16). IEEE, San Jose, CA USA, pp. 582-597; Samangouei, P., Kabkab, M., Chellappa, R., (2018) Defense-gan: Protecting Classifiers against Adversarial Attacks Using Generative Models, , https://arXiv:1805.06605, Retrieved June 25, 2021; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , https://arXiv:1706.06083, Retrieved June 25, 2021; Bubeck, S., Price, E., Razenshteyn, I., (2018) Adversarial Examples from Computational Constraints, , https://arXiv:1805.10204; Ilyas, A., Santurkar, S., Tsipras, D., Engstrom, L., Tran, B., Madry, A., (2019) Adversarial Examples Are Not Bugs, They Are Features, , https://arXiv:1905.02175, Retrieved June 25, 2021; Akhtar, N., Mian, A., Threat of adversarial attacks on deep learning in computer vision: A survey (2018) IEEE Access, 6, pp. 14410-14430. , 2018; Ozdag, M., Adversarial attacks and defenses against deep neural networks: A survey (2018) Procedia Computer Science, 140, pp. 152-161. , 2018; Miller, D.J., Xiang, Z., Kesidis, G., (2019) Adversarial Learning in Statistical Classification: A Comprehensive Review of Defenses against Attacks, , https://arXiv:1904.06292, Retrieved June 25, 2021; Hinton, G.E., Osindero, S., The, Y.-W., A fast learning algorithm for deep belief nets (2006) Neural Computation, 18 (7), pp. 1527-1554. , 2006; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), pp. 436-444. , 2015; Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Xiao, C., Prakash, A., Song, D., (2017) Robust Physical-world Attacks on Deep Learning Models, , https://arXiv:1707.08945, Retrieved June 25, 2021; Nakkiran, P., (2019) Adversarial Robustnessmay Be at Odds with Simplicity, , https://arXiv:1901.00532, Retrieved June 25, 2021; Chen, K., Zhu, H., Yan, L., Wang, J., A survey on adversarial examples in deep learning (2020) Journal on Big Data, 2 (2), pp. 71-84. , 2020; Kannan, H., Kurakin, A., Goodfellow, I., (2018) Adversarial Logit Pairing, , https://arXiv:1803.06373, Retrieved June 25, 2021; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Machine Learning at Scale, , https://arXiv:1611.01236, Retrieved June 25, 2021; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582. , IEEE, New York, NY USA; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) 2016 IEEE European Symposium on Security and Privacy (EuroS&P'16). IEEE, Saarbrucken, Saarland Germany, pp. 372-387; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP'17), pp. 39-57. , IEEE, SAN Jose, CA USA; Athalye, A., Carlini, N., Wagner, D., Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples (2018) Proceedings of the 35th International Conference on Machine Learning. ACM, Stockholm, Sweden, pp. 274-283; Zhao, P., Liu, S., Wang, Y., Lin, X., An ADMM-based universal framework for adversarial attacks on deep neural networks (2018) Proceedings of the 26th ACM International Conference on Multimedia, pp. 1065-1073. , ACM, San Servolo Island, Venice Italy; Xu, K., Liu, S., Zhao, P., Chen, P.-Y., Zhang, H., Fan, Q., Erdogmus, D., Lin, X., Structured adversarial attack: Towards general implementation and better interpretability (2018) OpenReview.net, Millennium Hall, Addis Ababa Ethiopia, , https://arXiv:1808.01664, Retrieved June 25, 2021; Wang, B., Zou, F., Liu, X., New algorithm to generate the adversarial example of image (2020) Optik, 207, p. 164477. , https://doi.org/10.1016/j.ijleo.2020.164477.%3c/bib, April 2020; Cheng, M., Singh, S., Chen, P.-Y., Liu, S., Hsieh, C., Sign-opt: A query-efficient hard-label adversarial attack (2020) International Conference on Learning Representations, , https://openreview.net/forum.id=SklTQCNtvS, Retrieved June 25, 2021; Ilyas, A., Engstrom, L., Athalye, A., Lin, J., (2018) Black-box Adversarial Attackswith Limited Queries and Information, , https://arXiv:1804.08598, Retrieved June 25, 2021; Cheng, S., Dong, Y., Pang, T., Su, H., Zhu, J., Improving black-box adversarial attacks with a transfer-based prior (2019) Advances in Neural Information Processing Systems, pp. 10934-10944. , MIT Press, Vancouver, B.C Canada; Carlini, N., Athalye, A., Papernot, N., Brendel, W., Rauber, J., Tsipras, D., Goodfellow, I., Kurakin, A., (2019) On Evaluating Adversarial Robustness, , https://arXiv:1902.06705, Retrieved June 25, 2021; Zhang, H., Yu, Y., Jiao, J., Xing, E.P., Ghaoui, L.E., Jordan, M.I., (2019) Theoretically Principled Trade-off between Robustness and Accuracy, , https://arXiv:1901.08573, Retrieved June 25, 2021; Zhao, P., Chen, P.-Y., Wang, S., Lin, X., Towards query-efficient black-box adversary with zeroth-order natural gradient descent (2020) Proceedings of the AAAI Conference on Artificial Intelligence, pp. 6909-6916. , AAAI, New York, NY USA; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 15-26. , ACM, Dallas, TX USA; Ilyas, A., Engstrom, L., Madry, A., (2018) Prior Convictions: Black-box Adversarial Attacks with Bandits and Priors, , https://arXiv:1807.07978, Retrieved June 25, 2021; Narodytska, N., Kasiviswanathan, S.P., (2016) Simple Black-box Adversarial Perturbations for Deep Networks, , https://arXiv:1612.06299, Retrieved June 25, 2021; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM Asia Conference on Computer and Communications Security, pp. 506-519. , ACM, New York, NY USA; Tramer, F., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2017) The Space of Transferable Adversarial Examples, , https://arXiv:1704.03453, Retrieved June 25, 2021; Luo, Y., Boix, X., Roig, G., Poggio, T., Zhao, Q., (2015) Foveation-based Mechanisms Alleviate Adversarial Examples, , https://arXiv:1511.06292, Retrieved June 25, 2021; Fawzi, A., Fawzi, O., Frossard, P., Analysis of classifiers' robustness to adversarial perturbations (2018) Machine Learning, 107 (3), pp. 481-508. , 2018; Gilmer, J., Metz, L., Faghri, F., Schoenholz, S.S., Raghu, M., Wattenberg, M., Goodfellow, I., The relationship between high-dimensional geometry and adversarial examples (2018) Retrieved June 25, 2021, , https://arXiv:1801.02774; Shafahi, A., Huang, W.R., Studer, C., Feizi, S., Goldstein, T., (2018) Are Adversarial Examples Inevitable, , https://arXiv:1809.02104, Retrieved June 25, 2021; Fawzi, A., Fawzi, H., Fawzi, O., Adversarial vulnerability for any classifier (2018) Advances in Neural Information Processing Systems, pp. 1186-1195. , MIT Press, Vancouver, B.C Canada; Mahloujifar, S., Diochnos, D.I., Mahmoody, M., The curse of concentration in robust learning: Evasion and poisoning attacks from concentration of measure (2019) Proceedings of the AAAI Conference on Artificial Intelligence, pp. 4536-4543. , AAAI, Hawaii, HI USA; Fawzi, A., Moosavi-Dezfooli, S.M., Frossard, P., (2016) Robustness of Classifiers: From Adversarial to Random Noise, , https://arXiv:1608.08967, Retrieved June 25, 2021; Franceschi, J.Y., Fawzi, A., Fawzi, O., Robustness of classifiers to uniform lp and Gaussian noise (2018) Proceedings of the 21st International Conference on Artificial Intelligence and Statistics. AAAI, Beijing, China, pp. 1280-1288; Ford, N., Gilmer, J., Carlini, N., Cubuk, D., (2019) Adversarial Examples Are A Natural Consequence of Test Error in Noise, , https://arXiv:1901.10513, Retrieved June 25, 2021; Dong, Y., Su, H., Zhu, J., Bao, F., (2017) Towards Interpretable Deep Neural Networks by Leveraging Adversarial Examples, , https://arXiv:1708.05493, Retrieved June 25, 2021; Kim, B., Seo, J., Jeon, T., (2019) Bridging Adversarial Robustness and Gradient Interpretability, , https://arXiv:1903.11626, Retrieved June 25, 2021; Hendrycks, D., Lee, D.K., Mazeika, M., Using pre-training can improve model robustness and uncertainty (2019) Proceedings of the 36th International Conference on Machine Learning, 97, pp. 2712-2721. , ACM, Long Beach, CA USA; Carmon, Y., Raghunathan, A., Schmidt, L., Liang, P., Duchi, J.C., (2019) Unlabeled Data Improves Adversarial Robustness, , https://arXiv:1905.13736, Retrieved June 25, 2021; Stanforth, R., Fawzi, A., Kohli, P., (2019) Are Labels Required for Improving Adversarial Robustness, , https://arXiv:1905.13725, Retrieved June 25, 2021; Mao, C., Gupta, A., Nitin, V., Ray, B., Song, S., Yang, J., Vondrick, C., Multitask learning strengthens adversarial robustness (2020) Proceedings of the European Conference on Computer Vision. IEEE, Edinburgh, UK, pp. 158-174; Li, B., Chen, C., Wang, W., Carin, L., Certified adversarial robustness with additive noise (2019) Advances in Neural Information Processing Systems, pp. 9459-9469. , MIT Press, Vancouver, B.C Canada; Su, D., Zhang, H., Chen, H., Yi, J., Chen, P.-Y., Gao, Y., Is robustness the cost of accuracy-A comprehensive study on the robustness of 18 deep image classification models (2018) Proceedings of the European Conference on Computer Vision (ECCV'18), pp. 631-648. , IEEE, Munich, Free State of Bavaria Germany; Koh, P.W., Liang, P., Understanding black-box predictions via influence functions (2017) Proceedings of the 34th International Conference on Machine Learning, 70, pp. 1885-1894. , ACM, Sydney, NSW Australia; Gong, Z., Wang, W., Ku, W.-S., (2017) Adversarial and Clean Data Are Not Twins, , https://arXiv:1704.04960, Retrieved June 25, 2021; Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., (2017) On the (Statistical) Detection of Adversarial Examples, , https://arXiv:1702.06280, Retrieved June 25, 2021; Li, X., Li, F., Adversarial examples detection in deep networks with convolutional filter statistics (2017) Proceedings of the IEEE International Conference on Computer Vision, pp. 5764-5772; Lu, J., Issaranon, T., Forsyth, D., Safetynet: Detecting and rejecting adversarial examples robustly (2017) Proceedings of the IEEE International Conference on Computer Vision. IEEE, Venice, Italy, pp. 446-454; Hendrycks, D., Gimpel, K., (2016) Early Methods for Detecting Adversarial Images, , https://arXiv:1608.00530, Retrieved June 25, 2021; Bhagoji, A.N., Cullina, D., Sitawarin, C., Mittal, P., Enhancing robustness of machine learning systems via data transformations (2018) 52nd Annual Conference on Information Sciences and Systems (CISS'18), pp. 1-5. , IEEE, Princeton, NJ USA; Xu, W., Evans, D., Qi, Y., Feature squeezing: Detecting adversarial examples in deep neural networks (2017) Retrieved June 25, 2021, , https://arXiv:1704.01155; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 3-14. , ACM, Dallas, TX USA; Lee, K., Lee, K., Lee, H., Shin, J., A simple unified framework for detecting out-of-distribution samples and adversarial attacks (2018) Advances in Neural Information Processing Systems, pp. 7167-7177. , MIT Press, Vancouver, B.C Canada; Ma, X., Li, B., Wang, Y., Erfani, S.M., Wijewickrema, S., Schoenebeck, G., Song, D., Bailey, J., (2018) Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality, , https://arXiv:1801.02613, Retrieved June 25, 2021; Wang, J., Dong, G., Sun, J., Wang, X., Zhang, P., Adversarial sample detection for deep neural network through model mutation testing (2019) Proceedings of the 41st International Conference on Software Engineering, pp. 1245-1256. , IEEE, Montreal, QC Canada; Ma, S., Liu, Y., Tao, G., Lee, W.-C., Zhang, X., NIC: Detecting adversarial samples with neural network invariant checking (2019) Proceedings of the 26th Network and Distributed Systems Security, , https://openreview.net/forumid=D54VV3ic4L, OpenReview.net, San Diego, CA USA; Dziugaite, G.K., Ghahramani, Z., Roy, D.M., (2016) A Study of the Effect of JPG Compression on Adversarial Images, , https://arXiv:1608.00853, Retrieved June 25, 2021; Guo, C., Rana, M., Cisse, M., Maaten Der, L.Van, (2017) Countering Adversarial Images Using Input Transformations, , https://arXiv:1711.00117, Retrieved June 25, 2021; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., (2017) Mitigating Adversarial Effects through Randomization, , https://arXiv:1711.01991, Retrieved June 25, 2021; Prakash, A., Moran, N., Garber, S., DiLillo, A., Storer, J., Deflecting adversarial attacks with pixel deflection (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 8571-8580. , IEEE, Salt Lake City, UT USA; Kou, C., Lee, H.K., Chang, E.-C., Ng, T.K., Enhancing transformation-based defenses against adversarial attacks with a distribution classifier (2020) International Conference on Learning Representations, pp. 8571-8580. , OpenReview.net, Millennium Hall, Addis Ababa Ethiopia; Gu, S., Rigazio, L., (2014) Towards Deep Neural Network Architectures Robust to Adversarial Examples, , https://arXiv:1412.5068, Retrieved June 25, 2021; Song, Y., Kim, T., Nowozin, S., Ermon, S., Kushman, N., (2017) Pixeldefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples, , https://arXiv:1710.10766, Retrieved June 25, 2021; Liao, F., Liang, M., Dong, Y., Pang, T., Hu, X., Zhu, J., Defense against adversarial attacks using high-level representation guided denoiser (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1778-1787. , IEEE, Salt Lake City, UT USA; Xie, C., Wu, Y., Maaten, L.V.D., Yuille, A.L., He, K., Feature denoising for improving adversarial robustness (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 501-509. , IEEE, Long Beach, CA USA; Cao, X., Gong, N.Z., Mitigating evasion attacks to deep neural networks via region-based classification (2018) Proceedings of the 33rd Annual Computer Security Applications Conference (ACSAC'18), pp. 278-287. , ACM, San Juan, PR USA; Zantedeschi, V., Nicolae, M.I., Rawat, A., Efficient defenses against adversarial attacks (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 39-49. , ACM, Dallas, TX USA; Pang, T., Du, C., Dong, Y., Zhu, J., Towards robust detection of adversarial examples (2018) Advances in Neural Information Processing Systems, pp. 4584-4594. , Montreal, A.B Canada; Buckman, J., Roy, A., Raffel, C., Goodfellow, I., Thermometer encoding: One hot way to resist adversarial examples (2018) 6th International Conference on Learning Representations, , https://openreview.net/forumid=S18Su-CW, OpenReview.net, Vancouver, B.C Canada. Retrieved June 25, 2021; Mustafa, A., Khan, S.H., Hayat, M., Goecke, R., Shen, J., Shao, L., Deeply supervised discriminative learning for adversarial defense (2020) IEEE Transactions on Pattern Analysis and Machine Intelligence. IEEE, p. 1; Liu, X., Cheng, M., Zhang, H., Hsieh, C.-J., Towards robust neural networks via random self-ensemble (2018) 15th Proceedings of the European Conference on Computer Vision (ECCV'18), pp. 369-385. , IEEE, Munich, Free State of Bavaria Germany; Dhillon, G.S., Azizzadenesheli, K., Lipton, Z.C., Bernstein, J., Kossaifi, J., Khanna, A., Anandkumar, A., (2018) Stochastic Activation Pruning for Robust Adversarial Defense, , https://arXiv:1803.01442, Retrieved June 25, 2021; Wang, S., Wang, X., Zhao, P., Wen, W., Kaeli, D., Chin, P., Lin, X., Defensive dropout for hardening deep neural networks under adversarial attacks (2018) Proceedings of the International Conference on Computer-Aided Design, 71, pp. 1-8. , ACM, San Diego, CA USA; Wang, X., Wang, S., Chen, P.-Y., Wang, Y., Chin, S., Protecting neural networks with hierarchical random switching: Towards better robustness-accuracy trade-off for stochastic defenses (2019) 28th International Joint Conference on Artificial Intelligence (IJCAI'19), pp. 6013-6019. , Morgan Kaufmann, Macao, China; Bui, A., Le, T., Zhao, H., Montague, P., DeVel, O., Abraham, T., Phung, D., Improving adversarial robustness by enforcing local and global compactness (2020) Proceedings of the European Conference on Computer Vision. ECCV, Edinburgh, UK, pp. 209-223; Huang, R., Xu, B., Schuurmans, D., Szepesvari, C., (2016) Learning with A Strong Adversary, , https://arXiv:1511.03034, Retrieved June 25, 2021; Shaham, U., Yamada, Y., Negahban, S., Understanding adversarial training: Increasing local stability of supervised models through robust optimization (2018) Neurocomputing, 307, pp. 195-204. , 2018; Tramer, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses, , https://arXiv:1705.07204, Retrieved June 25, 2021; Cheng, M., Lei, Q., Chen, P.-Y., Dhillon, I., Hsieh, C., (2020) CAT: Customized Adversarial Training for Improved Robustness, , https://arXiv:2002.06789, Retrieved June 25, 2021; Wang, Y., Zou, D., Yi, J., Bailey, J., Ma, X., Gu, Q., Improving adversarial robustness requires revisiting misclassified examples (2020) International Conference on Learning Representations, , https://openreview.net/forumid=rklOg6EFwS, OpenReview.net, Millennium Hall, Addis Ababa Ethiopia. Retrieved June 25, 2021; Shafahi, A., Najibi, M., Xu, Z., Dickerson, J.P., Davis, L.S., Goldstein, T., Universal adversarial training (2020) Proceedings of the AAAI Conference on Artificial Intelligence, 34 (4), pp. 5636-5643. , 2020; Miyato, T., Maeda, S.-I., Koyama, M., Nakae, K., Ishii, S., (2015) Distributional Smoothing with Virtual Adversarial Training, , https://arXiv:1507.00677, Retrieved June 25, 2021; Ilyas, A., Jalal, A., Asteri, E., Daskalakis, C., Dimakis, A.G., (2017) The Robust Manifold Defense: Adversarial Training Using Generative Models, , https://arXiv:1712.09196, Retrieved June 25, 2021; Zhang, H., Wang, J., Defense against adversarial attacks using feature scattering-based adversarial training (2019) Advances in Neural Information Processing Systems, pp. 1829-1839. , MIT Press, Vancouver, B.C Canada; Sinha, A., Namkoong, H., Duchi, J., Certifiable distributional robustness with principled adversarial training (2017) International Conference on Learning Representations, , https://openreview.net/forumid=Hk6kPgZA, OpenReview.net, Vancouver, B.C Canada; Wong, E., Kolter, J.Z., (2017) Provable Defenses against Adversarial Examples Via the Convex Outer Adversarial Polytope, , https://arXiv:1711.00851, Retrieved June 25, 2021; Raghunathan, A., Steinhardt, J., Liang, P., (2018) Certified Defenses against Adversarial Examples, , https://arXiv:1801.09344, Retrieved June 25, 2021; Weng, T.W., Zhang, H., Chen, P.Y., Yi, J., Daniel, L., (2018) Evaluating the Robustness of Neural Networks: An Extreme Value Theory Approach, , https://arXiv:1801.10578, Retrieved June 25, 2021; Weng, T.-W., Zhang, H., Chen, H., Song, Z., Hsieh, C.-J., Boning, D., Dhillon, I.S., Daniel, L., (2018) Towards Fast Computation of Certified Robustness for ReLU Networks, , https://arXiv:1804.09699, Retrieved June 25, 2021; Zhang, H., Weng, T.-W., Chen, P.-Y., (2018) Efficient Neural Network Robustness Certificationwith General Activation Functions, , https://arXiv:1811.00866, Retrieved June 25, 2021; Wong, E., Schmidt, F., Metzen, J.H., Kolter, J.Z., Scaling provable adversarial defenses (2018) Advances in Neural Information Processing Systems, pp. 8410-8419. , MIT Press, Montreal, A.B Canada; Lecuyer, M., Atlidakis, V., Geambasu, R., Hsu, D., Jana, S., (2018) Certified Robustness to Adversarial Examples with Differential Privacy, , https://arXiv:1802.03471.2018, Retrieved June 25, 2021; Cohen, J.M., Rosenfeld, E., Kolter, J.Z., (2019) Certified Adversarial Robustness Via Randomized Smoothing, , https://arXiv:1902.02918, Retrieved June 25, 2021; Zhai, R., Dan, C., He, D., Zhang, H., Gong, B., Ravikumar, P., Hsieh, C.-J., Wang, L., MACER: Attack-free and scalable robust training via maximizing certified radius (2020) International Conference on Learning Representations. OpenReview.net, Millennium Hall, Addis Ababa Ethiopia, , https://openreview.net/forumid=rJx1Na4Fwr, Retrieved June 25, 2021; Croce, F., Hein, M., Provable robustness against all adversarial lp-perturbations for p-1 (2020) International Conference on Learning Representations, , https://openreview.net/forumid=rklk-ySYPB, OpenReview.net, Millennium Hall, Addis Ababa Ethiopia. Retrieved June 25, 2021; Ross, A.S., Doshi-Velez, F., Improving the adversarial robustness and interpretability of deep neural networks by regularizing their input gradients (2018) 32nd AAAI Conference on Artificial Intelligence. AAAI, , https://ojs.aaai.org/index.php/AAAI/article/view/11504, New Orleans, LA USA. Retrieved June 25, 2021; Hein, M., Andriushchenko, M., Formal guarantees on the robustness of a classifier against adversarial manipulation (2017) Advances in Neural Information Processing Systems, pp. 2263-2273. , MIT Press, Los Angeles, CA USA; Tsuzuku, Y., Sato, I., Sugiyama, M., Lipschitz-margin training: Scalable certification of perturbation invariance for deep neural networks (2018) Advances in Neural Information Processing Systems, pp. 6542-6551. , MIT Press, Montreal, A.B Canada; Bhagoji, A.N., Cullina, D., Mittal, P., (2017) Dimensionality Reduction As A Defense against Evasion Attacks on Machine Learning Classifiers, , https://arXiv:1704.02654, Retrieved June 25, 2021; Liu, X., Cheng, M., Zhang, H., Hsieh, C.-J., Towards robust neural networks via random self-ensemble (2018) Proceedings of the European Conference on Computer Vision (ECCV'18), pp. 369-385. , IEEE, Munich, Free State of Bavaria Germany; Ye, S., Xu, K., Liu, S., Cheng, H., Lambrechts, J.-H., Zhang, H., Zhou, A., Lin, X., Adversarial robustness vs (2019) Model Compression, or Both in Proceedings of the IEEE/CVF International Conference on Computer Vision. IEEE, Seoul, South Korea, pp. 111-120; Wang, J., Zhang, H., Bilateral adversarial training: Towards fast training of more robust models against adversarial attacks (2019) Proceedings of the IEEE International Conference on Computer Vision. IEEE, Seoul, South Korea, pp. 6629-6638; Katz, G., Barrett, C., Dill, D.L., Julian, K., Kochenderfer, M.J., Reluplex: An efficient SMT solver for verifying deep neural networks (2017) International Conference on Computer Aided Verification. Springer, Heidelberg, BW Germany, pp. 97-117; Sharma, Y., Chen, P., (2018) Attacking the Madry Defense Model with L1-based Adversarial Examples, , https://arXiv:1710.10733, Retrieved June 25, 2021; Kang, D., Sun, Y., Brown, T., Hendrycks, D., Steinhardt, J., (2019) Transfer of Adversarial Robustness between Perturbation Types, , https://arXiv:1905.01034, Retrieved June 25, 2021; Li, B., Chen, C., Wang, W., Carin, L., (2018) Second-order Adversarial Attack and Certifiable Robustness, , https://arXiv:1809.03113, Retrieved June 25, 2021; Zheng, H., Zhang, Z., Gu, J., Lee, H., Prakash, A., Efficient adversarial training with transferable adversarial examples (2020) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. IEEE, Seattle, WA USA, pp. 1181-1190; Huang, X., Kwiatkowska, M., Wang, S., Wu, M., Safety verification of deep neural networks (2017) International Conference on Computer Aided Verification. Springer, Heidelberg, BW Germany, pp. 3-29; Tjeng, V., Xiao, K., Tedrake, R., (2017) Evaluating Robustness of Neural Networks with Mixed Integer Programming, , https://arXiv:1711.07356, Retrieved June 25, 2021; Zhou, J., Liang, C., Chen, J., Manifold projection for adversarial defense on face recognition (2020) European Conference on Computer Vision. Springer, Glasgow, UK, pp. 288-305; Zhou, H., Chen, K., Zhang, W., Fang, H., Zhou, W., Yu, N., DUP-net: Denoiser and upsampler network for 3d adversarial point clouds defense (2019) Proceedings of the IEEE/CVF International Conference on Computer Vision. IEEE, Seoul, South Korea, pp. 1961-1970; Jia, X., Wei, X., Cao, X., (2019) Identifying and Resisting Adversarial Videos Using Temporal Consistency, , https://arXiv:1909.04837, Retrieved June 25, 2021; Xu, X., Zhao, H., Jia, J., (2020) Dynamic Divide-and-conquer Adversarial Training for Robust Semantic Segmentation, , https://arXiv:2003.06555, Retrieved June 25, 2021; Li, H., Li, G., Yu, Y., ROSA: Robust salient object detection against adversarial attacks (2019) IEEE Transactions on Cybernetics, 50 (11), pp. 4835-4847. , 2019; Bai, S., Li, Y., Zhou, Y., Li, Q., Torr, P., (2019) Adversarial Metric Attack and Defense for Person Re-identification, , https://arXiv:1901.10650, Retrieved June 25, 2021; Li, D., Li, Q., Adversarial deep ensemble: Evasion attacks and defenses for malware detection (2020) IEEE Transactions on Information Forensics and Security, 15, pp. 3886-3900; Kwon, H., Yoon, H., Park, K.-W., POSTER: Detecting audio adversarial example through audio modification (2019) Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security, pp. 2521-2523. , ACM, London, UK; He, X., He, Z., Du, X., Chua, T.-S., Adversarial personalized ranking for recommendation (2018) 41st International ACM SIGIR Conference on Research & Development in Information Retrieval, pp. 355-364. , ACM, Ann Arbor, MI USA; Li, X., Pan, D., Zhu, D., (2020) Defending against Adversarial Attacks on Medical Imaging AI System, Classification or Detection, , https://arXiv:2006.13555, Retrieved June 25, 2021; Cheng, Y., Jiang, L., Macherey, W., (2019) Robust Neural Machine Translation with Doubly Adversarial Inputs, , https://arXiv:1906.02443, Retrieved June 25, 2021; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., (2017) On Detecting Adversarial Perturbations, , https://arXiv:1702.04267, Retrieved June 25, 2021","Zheng, X.; School of Artificial Intelligence, 电子邮件: xiaolong.zheng@ia.ac.cn",,,Association for Computing Machinery,,,,,3600300,,ACSUE,,English,ACM Comput Surv,Review,Final,"All Open Access, Bronze",Scopus,2-s2.0-85116697245
"Ludvigsen K.R., Nagaraja S.",57219787288;23398029100;,Dissecting liabilities in adversarial surgical robot failures: A national (Danish) and EU law perspective,2022,Computer Law and Security Review,44,,105656,,,,,10.1016/j.clsr.2022.105656,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125144444&doi=10.1016%2fj.clsr.2022.105656&partnerID=40&md5=6298269246fd0107bb4b622da98b37f7,"Department of Computer and Information Sciences, University of Strathclyde, United Kingdom","Ludvigsen, K.R., Department of Computer and Information Sciences, University of Strathclyde, United Kingdom; Nagaraja, S., Department of Computer and Information Sciences, University of Strathclyde, United Kingdom","Over the last decade, surgical robots have risen in prominence and usage. They are not merely tools, but have also become advanced instruments with network connectivity. Connectivity is necessary to accept software updates, accept instructions, and transfer sensory data, but it also exposes the robot to cyberattacks, which can damage the patient or the surgeon. These injuries are normally caused by safety failures, as seen in accidents with industrial robots, but cyberattacks are caused by security failures instead. We create a taxonomy for both types of failures in this paper specifically for surgical robots. These robots are increasingly sold and used in the European Union (EU), hence it is natural to consider how surgical robots are viewed and treated by EU law. Specifically, which rights regulators and manufacturers have under it, and which legal remedies and actions a patient or manufacturer would have in a single national legal system in the union, if injuries were to occur from a security failure caused by an adversary that cannot be unambiguously identified (attribution of cyberattacks is often hard). Given that the Medical Device Regulation (MDR) has only recently entered into force, we also offer some general considerations of the regulation. We find that the selected (Danish) national legal system can adequately deal with attacks on surgical robots, because it can on one hand efficiently compensate the patient, and at the same time protect the patient by not shying away from dealing with the problem concretely. This is because of its flexibility; secondly, a remarkable absence of distinction between safety vs security causes of failure and focusing instead on the detrimental effects, thus benefiting the patient; and third, liability can be removed from the manufacturer by withdrawing its status as party, if the patient chooses a separate public law measure to recover damages. Furthermore, we find that current EU law does consider both security and safety aspects of surgical robots, without it mentioning it through literal wording, but it also adds substantial liabilities and responsibilities to the manufacturers of surgical robots, gives the patient special rights and confers immense powers on the regulators, which can end up affecting any future lawsuits. © 2022 Kaspar Rosager Ludvigsen",Civil litigation; Cyberphysical systems; Cybersecurity; Danish law; EU law; Healthcare law; Product liability; Surgical robots,Accidents; Cybersecurity; Industrial robots; Manufacture; Product liability; Robotic surgery; Surgical equipment; Civil litigation; Cyber security; Cyber-attacks; Cyber-physical systems; Danish law; European Union Law; Healthcare law; Legal system; Network connectivity; Security failure; Accident prevention,,,,,"Alemzadeh, H., Chen, D., Li, X., Kesavadas, T., Kalbarczyk, Z.T., Iyer, R.K., Targeted attacks on teleoperated surgical robots: dynamic model-based detection and mitigation (2016) Proceedings of the 46th annual IEEE/IFIP international conference on dependable systems and networks, DSN 2016, pp. 395-406; Alemzadeh, H., Raman, J., Leveson, N., Kalbarczyk, Z., Iyer, R.K., Adverse events in robotic surgery: a retrospective study of 14 years of FDA data (2016) PLoS ONE, 11 (4), pp. 1-20; Andersen, M.B., Lookofsky, J., Lærebog i obligationsret (2010), 1. , 4th Karnov Group; Aslam, T., Krsul, I., Spafford, E.H., Use of a taxonomy of security faults (1996) Proceedings of the 19th national information systems security conference, pp. 551-560; Beglinger, C., A broken theory: the malfunction theory of strict products liability and the need for a new doctrine in the field of surgical robotics (2019) Minn Law Rev, 104 (2), pp. 1041-1094; Bergeles, C., Yang, G.Z., From passive tool holders to microsurgeons: safer, smaller, smarter surgical robots (2014) IEEE Trans Biomed Eng, 61 (5), pp. 1565-1576; Biasin, E., Kamenjasevic, E., Cybersecurity of medical devices: regulatory challenges in the EU (2020) The future of medical device regulation: innovation and protection; Bonaci, T., Herron, J., Yusuf, T., Yan, J., Kohno, T., Chizeck, H.J., To make a robot secure: an experimental analysis of cyber security threats against teleoperated surgical robots (2015), pp. 1-11; et al. Cardenas, A.A., Challenges for securing cyber physical systems (2009) Comput Audit Update, 2009 (3), pp. 3-6; Dhanani, N.H., Olavarria, O.A., Bernardi, K., Lyons, N.B., Holihan, J.L., Loor, M., Haynes, A.B., Liang, M.K., The evidence behind robot-assisted abdominopelvic surgery (2021) Ann Intern Med, 174 (8), pp. 1100-1117; von Eyben, B., Isager, H., Lærebog i erstatningsret (2013), 7th Jurist- og økonomforbundets Forlag; Falliere, N., Murchu, L.O., Chien, E., W32. Stuxnet dossier (2011) Symantec Secur Response, 14 (February), pp. 1-69; Fosch-Villaronga, E., Millard, C., Cloud robotics law and regulation: challenges in the governance of complex and dynamic cyberphysical ecosystems (2019) Robot Auton Syst, 119, pp. 77-91; Gomard, B., Godsk Pedersen, H.V., Ørgaard, A., Almindelig kontraktsret (2015), 4th Jurist- og økonomforbundets Forlag; Gómez-González, E., Gomez, E., Márquez-Rivas, J., Guerrero-Claro, M., Fernández-Lizaranzu, I., Relimpio-López, M.I., Dorado, M.E., Izquierdo-Ayuso, G., (2020), Capitán-Morales L. Artificial intelligence in medicine and healthcare: a review and classification of current and near-future applications and their ethical and social Impact;; Hockstein, N.G., Gourin, C.G., Faust, R.A., Terris, D.J., A history of robots: from science fiction to surgical robotics (2007) J Robot Surg, 1 (2), pp. 113-118; Holder, C., Khurana, V., Harrison, F., Jacobs, L., Robotics and law: key legal and regulatory implications of the robotics age (Part I of II) (2016) Comput Law Secur Rev, 32 (3), pp. 383-402; Kobara, K., Cyber physical security for industrial control systems and IoT (2016) IEICE Trans Inf Syst, E99D (4), pp. 787-795; Koops, B.J., Should ICT regulation be technology-neutral? (2006); Landwehr, C.E., Bull, A.R., McDermott, J.P., Choi, W.S., A taxonomy of computer program security flaws (1994) ACM Comput Surv (CSUR), 26 (3), pp. 211-254; Leenes, R., Palmerini, E., Koops, B.J., Bertolini, A., Salvini, P., Lucivero, F., Regulatory challenges of robotics: some guidelines for addressing legal and ethical issues (2017) Law Innov Technol, 9 (1), pp. 1-44; Ludvigsen, K., Nagaraja, S., Daly, A., When is software a medical device? Understanding and determining the ǣintentionǥ and requirements for software as a medical device in european union law (2021) Eur J Risk Regul, pp. 1-16; Nicol, D.M., Mallapura, V., Modeling and analysis of stepping stone attacks (2014) Proceedings of the 2014 winter simulation conference, pp. 3036-3047; Niemeyer, G., Preusche, C., Hirzinger, G., Telerobotics (2008) Springer handbook of robotics, pp. 741-757; NSF, Cyber-physical systems (2014) Technical Report, , National Science Foundation; Ohm, P., The argument against technology-neutral surveillance laws (2010) Tex Law Rev; Papp, D., Ma, Z., Buttyan, L., Embedded systems security: threats, vulnerabilities, and attack taxonomy (2015) Proceedings of the 13th annual conference on privacy, security and trust, PST 2015, pp. 145-152; Quarta, D., Pogliani, M., Polino, M., Maggi, F., Zanchettin, A.M., Zanero, S., An experimental security analysis of an industrial robot controller (2017) Proceedings of the IEEE symposium on security and privacy, pp. 268-285; Reed, C., Taking sides on technology neutrality (2007) SCRIPT-ed; Rizvi, S., Kurtz, A., Pfeffer, J., Rizvi, M., Securing the Internet of Things (IoT): a security taxonomy for IoT (2018) Proceedings of the 17th IEEE international conference on trust, security and privacy in computing and communications and 12th IEEE international conference on big data science and engineering, Trustcom/BigDataSE 2018, pp. 163-168; Tomsett, R., Widdicombe, A., Xing, T., Chakraborty, S., Julier, S., Gurram, P., Rao, R., Srivastava M. Why the failure? How adversarial examples can provide insights for interpretable machine learning. Proceedings of the 21st international conference on information fusion, FUSION 20182018;:838–845. 10.23919/ICIF.2018.8455710; Vasic, M., Billard, A., Safety Issues in Human-Robot Interactions (2013) Proceedings of the IEEE international conference on robotics and automation; Zeng, X., Liu, C., Wang, Y.S., Qiu, W., Xie, L., Tai, Y.W., Tang, C.K., Yuille, A.L., Adversarial attacks beyond the image space (2019) Proceedings of the IEEE computer society conference on computer vision and pattern recognition, 2019-June, pp. 4297-4306","Ludvigsen, K.R.; Department of Computer and Information Sciences, United Kingdom; 电子邮件: kaspar.rosager-ludvigsen@strath.ac.uk",,,Elsevier Ltd,,,,,2673649,,CLSRE,,English,Comput Law Secur. Rev.,Article,Final,,Scopus,2-s2.0-85125144444
"Minagi A., Hirano H., Takemoto K.",57221334568;57209291559;57444035700;,Natural Images Allow Universal Adversarial Attacks on Medical Image Classification Using Deep Neural Networks with Transfer Learning,2022,Journal of Imaging,8,2,38,,,,,10.3390/jimaging8020038,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124215538&doi=10.3390%2fjimaging8020038&partnerID=40&md5=eb8501b7843ba32523ec28a5f2ff8048,"Department of Bioscience and Bioinformatics, Kyushu Institute of Technology, Fukuoka, Iizuka, 820-8502, Japan","Minagi, A., Department of Bioscience and Bioinformatics, Kyushu Institute of Technology, Fukuoka, Iizuka, 820-8502, Japan; Hirano, H., Department of Bioscience and Bioinformatics, Kyushu Institute of Technology, Fukuoka, Iizuka, 820-8502, Japan; Takemoto, K., Department of Bioscience and Bioinformatics, Kyushu Institute of Technology, Fukuoka, Iizuka, 820-8502, Japan","Transfer learning from natural images is used in deep neural networks (DNNs) for medical image classification to achieve a computer-aided clinical diagnosis. Although the adversarial vulnerability of DNNs hinders practical applications owing to the high stakes of diagnosis, adversarial attacks are expected to be limited because training datasets (medical images), which are often required for adversarial attacks, are generally unavailable in terms of security and privacy preser-vation. Nevertheless, in this study, we demonstrated that adversarial attacks are also possible using natural images for medical DNN models with transfer learning, even if such medical images are unavailable; in particular, we showed that universal adversarial perturbations (UAPs) can also be generated from natural images. UAPs from natural images are useful for both non-targeted and targeted attacks. The performance of UAPs from natural images was significantly higher than that of random controls. The use of transfer learning causes a security hole, which decreases the reliabil-ity and safety of computer-based disease diagnosis. Model training from random initialization re-duced the performance of UAPs from natural images; however, it did not completely avoid vulnerability to UAPs. The vulnerability of UAPs to natural images is expected to become a significant security threat. © 2022 by the authors. Li-censee MDPI, Basel, Switzerland.",Adversarial attacks; Deep neural networks; Medical imaging; Security and privacy; Transfer learning,,,,,,"Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Bernstein, M., ImageNet large scale visual recognition challenge (2015) Int. J. Comput. Vis, 115, pp. 211-252. , https://doi.org/10.1007/s11263-015-0816-y; Litjens, G., Kooi, T., Bejnordi, B.E., Setio, A.A.A., Ciompi, F., Ghafoorian, M., van der Laak, J.A.W.M., Sánchez, C.I., A survey on deep learning in medical image analysis (2017) Med. Image Anal, 42, pp. 60-88. , https://doi.org/10.1016/j.media.2017.07.005; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2818-2826. , Las Vegas, NV, USA, 27–30 June IEEE: New York, NY, USA, 2016; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 770-778. , Las Vegas, NV, USA, 27–30 June IEEE: New York, NY, USA, 2016; Esteva, A., Kuprel, B., Novoa, R.A., Ko, J., Swetter, S.M., Blau, H.M., Thrun, S., Dermatologist-level classification of skin cancer with deep neural networks (2017) Nature, 542, pp. 115-118. , https://doi.org/10.1038/nature21056; Kermany, D.S., Goldbaum, M., Cai, W., Valentim, C.C.S., Liang, H., Baxter, S.L., McKeown, A., Yan, F., Identifying medical diagnoses and treatable diseases by image-based deep learning (2018) Cell, 172, pp. 1122-1131. , https://doi.org/10.1016/j.cell.2018.02.010, e9; Liu, X., Faes, L., Kale, A.U., Wagner, S.K., Fu, D.J., Bruynseels, A., Mahendiran, T., Kern, C., A comparison of deep learning performance against health-care professionals in detecting diseases from medical imaging: A systematic review and meta-analysis (2019) Lancet Digit. Heal, 1, pp. e271-e297. , https://doi.org/10.1016/S2589-7500(19)30123-2; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and harnessing adversarial examples, , arXiv arXiv:1412.6572; Yuan, X., He, P., Zhu, Q., Li, X., Adversarial examples: Attacks and defenses for deep learning (2019) IEEE Trans. Neural Networks Learn. Syst, 30, pp. 2805-2824. , https://doi.org/10.1109/TNNLS.2018.2886017; Ortiz-Jimenez, G., Modas, A., Moosavi-Dezfooli, S.-M., Frossard, P., (2020) Optimism in the face of adversity: Understanding and improving deep learning through adversarial robustness, , arXiv arXiv:2010.09624; Kaissis, G.A., Makowski, M.R., Rückert, D., Braren, R.F., Secure, privacy-preserving and federated machine learning in medical imaging (2020) Nat. Mach. Intell, 2, pp. 305-311. , https://doi.org/10.1038/s42256-020-0186-1; Finlayson, S.G., Bowers, J.D., Ito, J., Zittrain, J.L., Beam, A.L., Kohane, I.S., Adversarial attacks on medical machine learning (2019) Science, 363, pp. 1287-1289. , https://doi.org/10.1126/science.aaw4399; Matyasko, A., Chau, L.-P., Improved network robustness with adversary critic (2018) Proceedings of the 32nd International Conference on Neural Information Processing Systems, pp. 10601-10610. , Montreal, QC, Canada, 4 December 2018; Asgari Taghanaki, S., Das, A., Hamarneh, G., Vulnerability analysis of chest X-ray image classification against adversarial attacks (2018) Understanding and Interpreting Machine Learning in Medical Image Computing Applications, 11038, pp. 87-94. , LNCS; Springer International Publishing: Berlin/Heidelberg, Germany, ISBN 9783030026271; Hirano, H., Minagi, A., Takemoto, K., Universal adversarial attacks on deep neural networks for medical image classification (2021) BMC Med. Imaging, 21, p. 9. , https://doi.org/10.1186/s12880-020-00530-y; Moosavi-Dezfooli, S.M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 86-94. , https://doi.org/10.1109/CVPR.2017.17, Honolulu, HI, USA, 21–26 July; Hirano, H., Takemoto, K., Simple iterative method for generating targeted universal adversarial perturbations (2020) Algorithms, 13, p. 268. , https://doi.org/10.3390/a13110268; Raghu, M., Zhang, C., Kleinberg, J., Bengio, S., Transfusion: Understanding transfer learning for medical imaging (2019) Advances in Neural Information Processing Systems 32, pp. 3347-3357. , Wallach, H., Larochelle, H., Beygelzimer, A., Alché-Buc, F., Fox, E., Garnett, R., Eds.; Curran Associates, Inc.: Red Hook, NY, USA; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) Proceedings of the 3rd International Conference on Learning Representations, ICLR—2015 Conference Track Proceedings, , San Diego, CA, USA, 7–9 May; Nicolae, M.-I., Sinn, M., Tran, M.N., Buesser, B., Rawat, A., Wistuba, M., Zantedeschi, V., Ludwig, H., (2018) Adversarial Robustness Toolbox v1.0.0, , arXiv arXiv:1807.01069; Linardatos, P., Papastefanopoulos, V., Kotsiantis, S., Explainable AI: A Review of Machine Learning Interpretability Methods (2020) Entropy, 23, p. 18. , https://doi.org/10.3390/e23010018; Amann, J., Blasimme, A., Vayena, E., Frey, D., Madai, V.I., Explainability for artificial intelligence in healthcare: A multidisciplinary perspective (2020) BMC Med. Inform. Decis. Mak, 20, p. 310. , https://doi.org/10.1186/s12911-020-01332-6; Selvaraju, R.R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., Batra, D., Grad-CAM: Visual explanations from deep networks via gradient-based localization (2020) Int. J. Comput. Vis, 128, pp. 336-359. , https://doi.org/10.1007/s11263-019-01228-7; Wang, L., Lin, Z.Q., Wong, A., COVID-Net: A tailored deep convolutional neural network design for detection of COVID-19 cases from chest X-ray images (2020) Sci. Rep, 10, p. 19549. , https://doi.org/10.1038/s41598-020-76550-z; Chang, K., Balachandar, N., Lam, C., Yi, D., Brown, J., Beers, A., Rosen, B., Kalpathy-Cramer, J., Distributed deep learning networks among institutions for medical imaging (2018) J. Am. Med. Informatics Assoc, 25, pp. 945-954. , https://doi.org/10.1093/jamia/ocy017; Bortsova, G., González-Gonzalo, C., Wetstein, S.C., Dubost, F., Katramados, I., Hogeweg, L., Liefers, B., Veta, M., Adversarial attack vulnerability of medical image analysis systems: Unexplored factors (2021) Med. Image Anal, 73, p. 102141. , https://doi.org/10.1016/j.media.2021.102141; Chen, J., Su, M., Shen, S., Xiong, H., Zheng, H., POBA-GA: Perturbation optimized black-box adversarial attacks via genetic algorithm (2019) Comput. Secur, 85, pp. 89-106. , https://doi.org/10.1016/j.cose.2019.04.014; Guo, C., Gardner, J.R., You, Y., Wilson, A.G., Weinberger, K.Q., Simple black-box adversarial attacks (2019) Proceedings of the 36th International Conference on Machine Learning, pp. 2484-2493. , Long Beach, CA, USA, 9–15 June; Co, K.T., Muñoz-González, L., de Maupeou, S., Lupu, E.C., Procedural noise adversarial examples for black-box attacks on deep convolutional networks (2019) Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security, pp. 275-289. , London, UK, 11–15 November ACM: New York, NY, USA, 2019; Marchisio, A., Nanfa, G., Khalid, F., Hanif, M.A., Martina, M., Shafique, M., Is Spiking Secure? A comparative study on the security vulnerabilities of spiking and deep neural networks (2020) Proceedings of the 2020 International Joint Conference on Neural Networks (IJCNN), pp. 1-8. , Glasgow, UK, 19–24 July; Tsuzuku, Y., Sato, I., On the structural sensitivity of deep convolutional networks to the directions of Fourier basis functions (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2019, pp. 51-60. , Long Beach, CA, USA, 16–20 June Computer Vision Foundation/IEEE: New York, NY, USA, 2019; Alzubaidi, L., Al-Amidie, M., Al-Asadi, A., Humaidi, A.J., Al-Shamma, O., Fadhel, M.A., Zhang, J., Duan, Y., Novel Transfer Learning Approach for Medical Imaging with Limited Labeled Data (2021) Cancers, 13, p. 1590. , https://doi.org/10.3390/cancers13071590; Azizi, S., Mustafa, B., Ryan, F., Beaver, Z., Freyberg, J., Deaton, J., Loh, A., Chen, T., Big self-supervised models advance medical image classification (2021) Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pp. 3478-3488. , New York, NY, USA, 24–26 August; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) Proceedings of the International Conference on Learning Representations, , Vancouver, BC, Canada, 30 April–3 May; Zhang, H., Yu, Y., Jiao, J., Xing, E., Ghaoui, L. El, Jordan, M., Theoretically Principled Trade-Off Between Robustness and Accuracy (2019) Proceedings of the 36th International Conference on Machine Learning, 97, pp. 7472-7482. , Long Beach, CA, USA, 9–15 June Chaudhuri, K., Salakhutdinov, R., Eds.; PMLR: Long Beach, CA, USA, 2019; Xiao, C., Zhong, P., Zheng, C., Enhancing adversarial defense by k-winners-take-all (2020) Proceedings of the 8th International Conference Learning Represent, , Vienna, Austria, 4–8 May; Song, C., He, K., Wang, L., Hopcroft, J.E., Improving the generalization of adversarial training with domain adaptation (2019) Proceedings of the 7th International Conference Learning Represent, , ICLR, New Orleans, LA, USA, 6–9 May; Hwang, U., Park, J., Jang, H., Yoon, S., Cho, N.I., PuVAE: A variational autoencoder to purify adversarial examples (2019) IEEE Access, 7, pp. 126582-126593. , https://doi.org/10.1109/ACCESS.2019.2939352; Croce, F., Hein, M., Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks (2020) Proceedings of the 37th International Conference Machine Learning, , Long Beach, CA, USA, 3–7 May; Carlini, N., Wagner, D., Adversarial examples are not easily detected (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security—AISec ’17, pp. 3-14. , Dallas, TX, USA, 3 November ACM Press: New York, NY, USA, 2017; Aldahdooh, A., Hamidouche, W., Fezza, S.A., Déforges, O., Adversarial example detection for DNN models: A review and experimental comparison (2022) Artif. Intell. Rev, 55, pp. 1-60. , https://doi.org/10.1007/s10462-021-10125-w; Ma, X., Niu, Y., Gu, L., Wang, Y., Zhao, Y., Bailey, J., Lu, F., Understanding adversarial attacks on deep learning based medical image analysis systems (2021) Pattern Recognit, 110, p. 107332. , https://doi.org/10.1016/j.patcog.2020.107332; Subramanya, A., Pillai, V., Pirsiavash, H., Fooling network interpretation in image classification (2019) Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), , Seoul, Korea, 27 October–2 November; Goldblum, M., Fowl, L., Goldstein, T., Adversarially robust few-shot learning: A meta-learning approach (2020) Advances in Neural Information Processing Systems, 33, pp. 17886-17895. , Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M.F., Lin, H., Eds.; Curran Associates, Inc.: Red Hook, NY, USA","Takemoto, K.; Department of Bioscience and Bioinformatics, Fukuoka, Japan; 电子邮件: takemoto@bio.kyutech.ac.jp",,,MDPI,,,,,2313433X,,,,English,J. Imaging,Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85124215538
"Wang F., Chai G., Li Q., Wang C.",55740544400;57222272134;35324722300;13003976700;,An Efficient Deep Unsupervised Domain Adaptation for Unknown Malware Detection,2022,Symmetry,14,2,296,,,,,10.3390/sym14020296,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124075534&doi=10.3390%2fsym14020296&partnerID=40&md5=cf2e6fde1693a3d67c181b1757cf755e,"Key Laboratory of Network and Information Security of Hebei Province, College of Computer & Cyber Security, Hebei Normal University, Shijiazhuang, 050024, China","Wang, F., Key Laboratory of Network and Information Security of Hebei Province, College of Computer & Cyber Security, Hebei Normal University, Shijiazhuang, 050024, China; Chai, G., Key Laboratory of Network and Information Security of Hebei Province, College of Computer & Cyber Security, Hebei Normal University, Shijiazhuang, 050024, China; Li, Q., Key Laboratory of Network and Information Security of Hebei Province, College of Computer & Cyber Security, Hebei Normal University, Shijiazhuang, 050024, China; Wang, C., Key Laboratory of Network and Information Security of Hebei Province, College of Computer & Cyber Security, Hebei Normal University, Shijiazhuang, 050024, China","As an innovative way of communicating information, the Internet has become an indis-pensable part of our lives. However, it also facilitates a more widespread attack of malware. With the assistance of modern cryptanalysis, emerging malware having symmetric properties, such as encryption and decryption, pack and unpack, presents new challenges to effective malware detec-tion. Currently, numerous malware detection approaches are based on supervised learning. The biggest challenge is that the existing systems rely on a large amount of labeled data, which is usually difficult to gain. Moreover, since the newly emerging malware has a different data distribution from the original training samples, the detection performance of these systems will degrade along with the emergence of new malware. To solve these problems, we propose an Unsupervised Domain Adaptation (UDA)-based malware detection method by jointly aligning the distribution of known and unknown malware. Firstly, the distribution divergence between the source and target domain is minimized with the help of symmetric adversarial learning to learn shared feature representa-tions. Secondly, to further obtain semantic information of unlabeled target domain data, this paper reduces the class-level distribution divergence by aligning the class center of labeled source and pseudo-labeled target domain data. Finally, we mainly use a residual network with a self-attention mechanism to extract more accurate feature information. A series of experiments are performed on two public datasets. Experimental results illustrate that the proposed approach outperforms the existing detection methods with an accuracy of 95.63% and 95.04% in detecting unknown malware on two datasets, respectively. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",Malware detection; Self-attention module; Transfer learning; Unsupervised domain adaptation,,,,,,"https://www.av-test.org/en/statistics/malware/, (accessed on 1 January 2022); Jung, B.H., Bae, S.I., Choi, C., Im, E.G., Packer identification method based on byte sequences (2020) Concurr. Comput. Pract. Exp, 32, p. e5082; Yuan, Z., Lu, Y., Xue, Y., Droiddetector: Android malware characterization and detection using deep learning (2016) Tsinghua Sci. Technol, 21, pp. 114-123; Shijo, P.V., Salim, A., Integrated static and dynamic analysis for malware detection (2015) Procedia Comput. Sci, 46, pp. 804-881; Imran, M., Afzal, M.T., Qadir, M.A., Using hidden markov model for dynamic malware analysis: First impressions (2015) Proceedings of the 12th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD), pp. 816-821. , Zhangjiajie, China, 15–17 August; Damodaran, A., Di Troia, F., Visaggio, C.A., Austin, C.A., Stamp, M., A comparison of static, dynamic, and hybrid analysis for malware detection (2017) J. Comput. Virol. Hacking Tech, 13, pp. 1-12; Vasan, D., Alazab, M., Wassan, S., Naeem, H., Safaei, B., Zheng, Q., IMCFN: Image-based malware classification using fine-tuned convolutional neural network architecture (2020) Comput. Netw, 171, pp. 107-138; Rafique, M.F., Ali, M., Qureshi, A.S., Khan, A., Mirza, A.M., (2019) Malware Classification using Deep Learning based Feature Extraction and Wrapper based Feature Selection Technique, , arXiv arXiv:1910.10958; Vasan, D., Alazab, M., Wassan, S., Naeem, H., Safaei, B., Zheng, Q., Image-based malware classification using ensemble of CNN architectures (IMCEC) (2020) Comput. Secur, 92, p. 101748; Catak, F.O., Ahmed, J., Sahinbas, K., Khand, Z.H., Data augmentation-based malware detection using convolutional neural networks (2021) PeerJ Comput. Sci, 7, p. e346; Arora, A., Peddoju, S.K., Chouhan, V., Chaudhary, A., Hybrid Android malware detection by combining supervised and unsupervised learning (2018) Proceedings of the 24th Annual International Conference on Mobile Computing and Networking, pp. 798-800. , New York, NY, USA, 15 October; Wilson, G., Cook, D.J., A survey of unsupervised deep domain adaptation (2020) ACM Trans. Intell. Syst. Technol, 11, pp. 1-46; Nataraj, L., Yegneswaran, V., Porras, P., A comparative assessment of malware classification using binary texture analysis and dynamic analysis (2011) Proceedings of the ACM Conference on Computer and Communications Security, pp. 21-30. , New York, NY, USA, 21 October; Naeem, H., Guo, B., Naeem, R.M., A light-weight malware static visual analysis for IoT infrastructure (2018) Proceedings of the 2018 International Conference on Artificial Intelligence and Big Data (ICAIBD), pp. 240-244. , Chengdu China, 26–28 May; Yan, J., Qi, Y., Rao, Q., Detecting malware with an ensemble method based on deep neural network (2018) Secur. Commun. Netw, 2018, p. 7247095; Alom, M.Z., Taha, T.M., Network intrusion detection for cyber security using unsupervised deep learning approaches (2017) Proceedings of the 2017 IEEE National Aerospace and Electronics Conference (NAECON), pp. 63-69. , Dayton, OH, USA, 27–30 June; Pitolli, G., Laurenza, G., Aniello, L., Querzoni, L., Baldoni, R., MalFamAware: Automatic family identification and malware classification through online clustering (2021) Int. J. Inf. Secur, 20, pp. 371-386; Moti, Z., Hashemi, S., Namavar, A., Discovering future malware variants by generating new malware samples using generative adversarial network (2019) Proceedings of the 9th International Conference on Computer and Knowledge Engineering (ICCKE), pp. 319-324. , Mashhad, Iran, 24–25 October; Sun, Q., Liu, Y., Chua, T.S., Schiele, B., Meta-transfer learning for few-shot learning (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 403-412. , Long Beach, CA, USA, 16–20 June; Pathak, Y., Shukla, P.K., Tiwari, A., Stalin, S., Singh, S., Deep transfer learning-based classification model for COVID-19 disease (2020) IRBM, , https://doi.org/10.1016/j.irbm.2020.05.003, online ahead of print; Wang, J., Chen, Y., Feng, W., Yu, H., Huang, M., Yang, Q., Transfer learning with dynamic distribution adaptation (2020) ACM Trans. Intell. Syst. Technol. (TIST), 11, pp. 1-25; Neyshabur, B., Sedghi, H., Zhang, C., (2020) What is being transferred in transfer learning?, , arXiv arXiv:2008.11687; Celik, Y., Talo, M., Yildirim, O., Karabatak, M., Acharya, U.R., Automated invasive ductal carcinoma detection based using deep transfer learning with whole-slide images (2020) Pattern Recognit. Lett, 33, pp. 232-239; Rezende, E., Ruppert, G., Carvalho, T., Theophilo, A., Ramos, F., Geus, P., Malicious software classification using VGG16 deep neural network’s bottleneck features (2018) Adv. Intell. Syst. Comput, 738, pp. 51-59; Cui, B., Chen, X., Lu, Y., Semantic segmentation of remote sensing images using transfer learning and deep convolutional neural network with dense connection (2020) IEEE Access, 8, pp. 116744-116755; Sorocky, M.J., Zhou, S., Schoellig, A.P., Experience selection using dynamics similarity for efficient multi-source transfer learning between robots (2020) Proceedings of the 2020 IEEE International Conference on Robotics and Automation (ICRA), pp. 2739-2745. , Paris, France, 31 May–31 August; Bartos, K., Sofka, M., Franc, V., Optimized invariant representation of network traffic for detecting unseen malware variants (2016) Proceedings of the 25th USENIX Security Symposium, pp. 807-822. , USENIX, Austin, TX, USA, 10–12 August; Li, H., Chen, Z., Spolaor, R., Dart: Detecting unseen malware variants using adaptation regularization transfer learning (2019) Proceedings of the ICC 2019—2019 IEEE International Conference on Communications (ICC), pp. 1-6. , Shanghai, China, 1 May; Rong, C., Gou, G., Cui, M., Xiong, G., Li, Z., Guo, L., TransNet: Unseen malware variants detection using deep transfer learning (2020) Lect. Notes Inst. Comput. Sci, 336, pp. 84-101; Zhang, H., Goodfellow, I., Metaxas, D., Odena, A., (2019) Self-attention generative adversarial networks, , arXiv arXiv:1805.08318v2; Zhu, Y., Zhuang, F., Wang, J., Chen, J., Shi, Z., Wu, W., He, Q., Multi-representation adaptation network for cross-domain image classification (2019) Neural Netw, 119, pp. 214-221; Zhuang, F., Cheng, X., Luo, P., Pan, S.J., He, Q., Supervised representation learning: Transfer learning with deep autoencoders (2015) Proceedings of the Twenty-Fourth International Joint Conference on Artificial Intelligence, pp. 4119-4125. , Palo Alto, CA, USA, 27 June; Sun, B., Feng, J., Saenko, K., Return of frustratingly easy domain adaptation (2016) Proceedings of the Thirtieth Conference on Artificial Intelligence, pp. 2058-2065. , Phoenix, AZ, USA, 2 March; Courty, N., Flamary, R., Tuia, D., Rakotomamonjy, A., Optimal transport for domain adaptation (2017) IEEE Trans. Pattern Anal. Mach. Intell, 39, pp. 1853-1865; Tzeng, E., Hoffman, J., Saenko, K., Darrell, T., Adversarial discriminative domain adaptation (2017) Proceedings of the Conference on Computer Vision and Pattern Recognition, pp. 2962-2971. , Honolulu, HI, USA, 21–26 July; Weston, J., Ratle, F., Mobahi, H., Collobert, R., Deep learning via semi-supervised embedding (2012) Neural Networks: Tricks of the Trade 2012, 7700, pp. 639-655. , Montavon, G., Orr, G.B., Eds.; Springer Press: Berlin/Heidelberg, Germany; Wen, Y., Zhang, K., Li, Z., Qiao, Y., A discriminative feature learning approach for deep face recognition (2016) Computer Vision— ECCV 2016, 9911, pp. 499-515. , Leibe, B., Matas, J., Eds.; Springer: Cham, Switzerland; Ficco, M., Detecting IoT malware by Markov chain behavioral models (2019) Proceedings of the 2019 IEEE International Conference on Cloud Engineering (IC2E), pp. 229-234. , Prague, Czech Republic, 24–27 June; Moustafa, N., Slay, J., Creech, G., Novel geometric area analysis technique for anomaly detection using trapezoidal area estima-tion on large-scale networks (2017) IEEE Trans. Big Data, 5, pp. 481-494; Zhao, Y., Cui, W., Geng, S., Bo, B., Feng, Y., Zhang, W., A malware detection method of code texture visualization based on an improved faster RCNN combining transfer learning (2020) IEEE Access, 8, pp. 166630-166641","Li, Q.; Key Laboratory of Network and Information Security of Hebei Province, China; 电子邮件: qingruli@hebtu.edu.cn
Wang, C.; Key Laboratory of Network and Information Security of Hebei Province, China; 电子邮件: wangcg@hebtu.edu.cn",,,MDPI,,,,,20738994,,,,English,Symmetry,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85124075534
"Yu M., Sun S.",57218624915;8892785100;,FE-DaST: Fast and effective data-free substitute training for black-box adversarial attacks,2022,Computers and Security,113,,102555,,,,,10.1016/j.cose.2021.102555,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119977045&doi=10.1016%2fj.cose.2021.102555&partnerID=40&md5=5adc5e67cacc143251c83f0f043dacc7,"School of Computer Science and Technology, East China Normal University, 3663 North Zhongshan Road, Shanghai, 200062, China","Yu, M., School of Computer Science and Technology, East China Normal University, 3663 North Zhongshan Road, Shanghai, 200062, China; Sun, S., School of Computer Science and Technology, East China Normal University, 3663 North Zhongshan Road, Shanghai, 200062, China","Deep learning models have shown their advantages in computer vision, e.g., image classification, whereas they are well-known to be susceptible to imperceptible perturbations of input images which are called adversarial attacks. Recently proposed data-free substitute training (DaST), an adversarial framework based on a multi-branch generator where each branch generated images of the corresponding class to balance synthetic images, trained surrogate models without the requirement of any real image for transfer-based black-box adversarial attacks. However, this multi-branch framework was too redundant to converge quickly and was limited to datasets of a few categories. In this paper, we propose a simpler adversarial framework based on a single-branch generator to train substitute models fast and effectively, named FE-DaST. More specifically, we adopt a single-branch deep convolutional generator with an information entropy loss to stimulate the generation of balanced images, promote the similarity between substitute models and target models, and further enhance the strength of the transfer-based attack. Despite its simplicity, experimental results demonstrate the superiority of our proposed FE-DaST over DaST in terms of computational loads, similarities between surrogate models and target models, and attack success rates of transferable adversarial examples on MNIST and CIFAR-10 datasets. For CIFAR-100 and Tiny-ImageNet datasets where DaST is not available, our FE-DaST also achieves competitive attack success rates compared with pre-trained models which are trained with realistic training images. Furthermore, the attack performance of FE-DaST outperforms other state-of-the-art substitute training methods on the four datasets. © 2021 Elsevier Ltd",Adversarial framework; Black-box adversarial attacks; Data-free substitute training; Image classification; Information entropy,Classification (of information); Convolutional neural networks; Deep learning; Image enhancement; Adversarial framework; Black boxes; Black-box adversarial attack; Data-free substitute training; Images classification; Information entropy; Input image; Learning models; Surrogate modeling; Target model; Image classification,,,,,"Athalye, A., Carlini, N., Wagner, D., Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples (2018) Proceedings of the International Conference on Machine Learning, pp. 274-283; Bhagoji, A.N., He, W., Li, B., Song, D., Practical black-box attacks on deep neural networks using efficient query mechanisms (2018) Proceedings of the European Conference on Computer Vision, pp. 158-174; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndić, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Proceedings of the Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 387-402; Brendel, W., Rauber, J., Bethge, M., Decision-based adversarial attacks: reliable attacks against black-box machine learning models (2018) Proceedings of the International Conference on Learning Representations; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Proceedings of the IEEE Symposium on Security and Privacy, pp. 39-57; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) Proceedings of the ACM Workshop on Artificial Intelligence and Security, pp. 15-26; Duan, Y., Zhou, X., Zou, J., Qiu, J., Zhang, J., Pan, Z., Mask-guided noise restriction adversarial attacks for image classification (2021) Computers & Security, 100, p. 102111; Goodfellow, I.J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial networks (2014) arXiv preprint arXiv:1406.2661; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) Proceedings of the International Conference on Learning Representations; Hashemi, M., Cusack, G., Keller, E., Stochastic substitute training: A gray-box approach to craft adversarial examples against gradient obfuscation defenses (2018) Proceedings of the ACM Workshop on Artificial Intelligence and Security, pp. 25-36; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the Conference on Computer Vision and Pattern Recognition, pp. 770-778; Ilyas, A., Engstrom, L., Athalye, A., Lin, J., Black-box adversarial attacks with limited queries and information (2018) Proceedings of the International Conference on Machine Learning, pp. 2137-2146; Jandial, S., Mangla, P., Varshney, S., Balasubramanian, V., AdvGAN++: Harnessing latent layers for adversary generation (2019) Proceedings of the International Conference on Computer Vision Workshops, pp. 0-3; Krizhevsky, A., Hinton, G., Learning multiple layers of features from tiny images (2009) Technique Report; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2017) Proceedings of the International Conference on Learning Representations; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324; Lee, K., Lee, K., Lee, H., Shin, J., A simple unified framework for detecting out-of-distribution samples and adversarial attacks (2018) Advances in Neural Information Processing Systems, pp. 7167-7177; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2016) Proceedings of the International Conference on Learning Representations; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) Proceedings of the International Conference on Learning Representations; Meng, D., Chen, H., Magnet: a two-pronged defense against adversarial examples (2017) Proceedings of the Conference on Computer and Communications Security, pp. 135-147; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: a simple and accurate method to fool deep neural networks (2016) Proceedings of the Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Narodytska, N., Kasiviswanathan, S.P., Simple black-box adversarial perturbations for deep networks (2016) arXiv preprint arXiv:1612.06299; Orekondy, T., Schiele, B., Fritz, M., Knockoff nets: Stealing functionality of black-box models (2019) Proceedings of the Conference on Computer Vision and Pattern Recognition, pp. 4954-4963; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the ACM on Asia Conference on Computer and Communications Security, pp. 506-519; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Proceedings of the IEEE Symposium on Security and Privacy, pp. 582-597; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Bernstein, M., Imagenet large scale visual recognition challenge (2015) Int J Comput Vis, 115 (3), pp. 211-252; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) Proceedings of the International Conference on Learning Representations; Singh, M., Sinha, A., Kumari, N., Machiraju, H., Krishnamurthy, B., Balasubramanian, V.N., Harnessing the vulnerability of latent layers in adversarially trained models (2019) Proceedings of the International Joint Conference on Artificial Intelligence, pp. 2779-2785; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) Proceedings of the International Conference on Learning Represenations; Tramer, F., Boneh, D., Adversarial training and robustness for multiple perturbations (2019) Advances in Neural Information Processing Systems, pp. 5866-5876; Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2018) Proceedings of the International Conference on Learning Representations; Tu, C.-C., Ting, P., Chen, P.-Y., Liu, S., Zhang, H., Yi, J., Hsieh, C.-J., Cheng, S.-M., Autozoom: Autoencoder-based zeroth order optimization method for attacking black-box neural networks (2019) Proceedings of the AAAI Conference on Artificial Intelligence, pp. 742-749; Wang, W., Yin, B., Yao, T., Zhang, L., Fu, Y., Ding, S., Li, J., Xue, X., Delving into data: Effectively substitute training for black-box attack (2021) Proceedings of the Conference on Computer Vision and Pattern Recognition, pp. 4761-4770; Xiao, C., Li, B., Zhu, J.-Y., He, W., Liu, M., Song, D., Generating adversarial examples with adversarial networks (2018) Proceedings of the International Joint Conference on Artificial Intelligence, pp. 3905-3911; Zhou, M., Wu, J., Liu, Y., Liu, S., Zhu, C., DaST: Data-free substitute training for adversarial attacks (2020) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 234-243","Sun, S.; School of Computer Science and Technology, 3663 North Zhongshan Road, China; 电子邮件: slsun@cs.ecnu.edu.cn",,,Elsevier Ltd,,,,,1674048,,CPSED,,English,Comput Secur,Article,Final,,Scopus,2-s2.0-85119977045
[无可用作者姓名],[无可用的作者 ID],"11th International Advanced Computing Conference, IACC 2021",2022,Communications in Computer and Information Science,1528 CCIS,,,,,685,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125263476&partnerID=40&md5=a7607759fb37a72d55a08b42213f001c,,,"The proceedings contain 51 papers. The special focus in this conference is on Advanced Computing. The topics include: An Analysis of the Psychological Implications of COVID-19 Pandemic on Undergraduate Students and Efforts on Mitigation; network-Based Identification of Module Biomarker Associated with Hepatocellular Carcinoma; identifying Hub Nodes and Sub-networks from Cattle Rumen Microbiome Multilayer Networks; machine Learning-Based Psychology: A Study to Understand Cognitive Decision-Making; predicting Stock Market Prices Using Sentiment Analysis of News Articles; Sentimental Analysis on Multi-domain Sentiment Dataset Using SVM and Naive Bayes Algorithm; artificial Intelligence in Online Stores’ Processes; early Warning Indicators for Financial Crisis During Covid-19; facial Recognition Based Attendance Monitoring System; Covid Alert System: A Smart Security System to Alert Violations of Covid Protocol Using OpenCV; transfer Learning Using Variational Quantum Circuit; gait Learning Using Reinforcement Learning; data Science in the Business Environment: Architecture, Process and Tools; a Logarithmic Distance-Based Multi-Objective Genetic Programming Approach for Classification of Imbalanced Data; multiview Classification with Missing-Views Through Adversarial Representation and Inductive Transfer Learning; Deep Reinforcement Learning Based Throughput Maximization Scheme for D2D Users Underlaying NOMA-Enabled Cellular Network; An Intrusion Detection System for Blackhole Attack Detection and Isolation in RPL Based IoT Using ANN; evaluating the Efficacy of Different Neural Network Deep Reinforcement Algorithms in Complex Search-and-Retrieve Virtual Simulations; post-hoc Explainable Reinforcement Learning Using Probabilistic Graphical Models; ghostbusters: How the Absence of Class Pairs in Multi-Class Multi-Label Datasets Impacts Classifier Accuracy; Corona Virus Detection Using EfficientNet from CT Scans; reLearner: A Reinforcement Learning-Based Self Driving Car Model Using Gym Environment; automating Paid Parking System Using IoT Technology.",,,,,,,,,Garg D.Jagannathan S.Gupta A.Garg L.Gupta S.,,Springer Science and Business Media Deutschland GmbH,"11th International Advanced Computing Conference, IACC 2021",18 December 2021 through 19 December 2021,,272079,18650929,9.78E+12,,,English,Commun. Comput. Info. Sci.,Conference Review,Final,,Scopus,2-s2.0-85125263476
"Durbha K.S., Amuru S.",57465361300;55606466400;,AutoML Models for Wireless Signals Classification and their effectiveness against Adversarial Attacks,2022,"2022 14th International Conference on COMmunication Systems and NETworkS, COMSNETS 2022",,,,265,269,,,10.1109/COMSNETS53615.2022.9668448,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125180155&doi=10.1109%2fCOMSNETS53615.2022.9668448&partnerID=40&md5=e64a7232709d0639b0bd8e2633a3d1d6,"Indian Institute of Technology, Department of Electrical Engineering, Hyderabad, India","Durbha, K.S., Indian Institute of Technology, Department of Electrical Engineering, Hyderabad, India; Amuru, S., Indian Institute of Technology, Department of Electrical Engineering, Hyderabad, India","In this paper, we study and compare the performance of AutoML models with state-of-the-art models on wireless signal classification and their vulnerability and transferability towards transfer-based white-box and black-box attacks. We designed models of four architectures using AutoML, namely Deep Residual Network (ResNet), Convolutional Long Short-Term Deep Neural Network (CLDNN), Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN). Using AutoML techniques for model generation helps to reduce time spent on designing, training and tuning hyper-parameters of deep learning models. Using numerical results, we show that AutoML models are a viable and solid candidate approach for the classification of wireless signals. In addition, we show the vulnerability of AutoML models towards adversarial attacks when compared to state-of-the-art models. © 2022 IEEE.",Adversarial ML; AutoML; Classification; CLDNN; CNN; Deep Learning; Modulation; ResNet; RNN,Convolution; Convolutional neural networks; Recurrent neural networks; Adversarial ML; ART model; Automl; Convolutional long short-term deep neural network; Convolutional neural network; Deep learning; Residual network; Signal classification; State of the art; Wireless signals; Deep neural networks,,,,,"Warrier, A.N., Amuru, S., How to choose a neural network architecture.-a modulation classification example (2020) Proc. IEEE 5G World Forum, pp. 413-417; Shea, T.J.O., Corgan, J., Clancy, T.C., Convolutional Radio Modulation Recognition Networks; Ramjee, S., Fast Deep Learning for Automatic Modulation Classification; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and Harnessing Adversarial Examples; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP), pp. 39-57; Demontis, A., (2019) Why Do Adversarial Attacks Transfer. Explaining Transferability of Evasion and Poisoning Attacks; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-Box Attacks Using Adversarial Samples; Jin, H., Song, Q., Hu, X., (2019) Auto-Keras: An Efficient Neural Architecture Search System; Usama, M., Qadir, J., Fuqaha, A.A., Black-box Adversarial ML Attack on Modulation Classification; https://autokeras.com/; Jolly, A., Khorramshahi, P., Saeed, T., Improvements to Modulation Classification Techniques Using Deep Learning, , http://noiselab.ucsd.edu/ECE228-2020/projects/Report/76Report.pdf, Noiselab, University of California, San Diego; Shea, T.J.O., West, N., Radio machine learning dataset generation with gnu radio Proc. GNU Radio Conference, 1; Papernot, N., Technical Report on the CleverHans v2. 1. 0 Adversarial Examples Library",,,,Institute of Electrical and Electronics Engineers Inc.,"14th International Conference on COMmunication Systems and NETworkS, COMSNETS 2022",4 January 2022 through 8 January 2022,,176397,,9.78E+12,,,English,"Int. Conf. COMmun. Syst. NETworkS, COMSNETS",Conference Paper,Final,,Scopus,2-s2.0-85125180155
"Xia H., Shao S., Hu C., Zhang R., Qiu T., Xiao F.",37012925800;57219311694;55224734400;57209642532;34971882000;57406614100;,Robust Clustering Model Based on Attention Mechanism and Graph Convolutional Network,2022,IEEE Transactions on Knowledge and Data Engineering,,,,,,,,10.1109/TKDE.2022.3150300,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124714482&doi=10.1109%2fTKDE.2022.3150300&partnerID=40&md5=6093f2a11c11cc82868ce1bd705f82ca,"College of Computer Science and Technology, Ocean University of China, 12591 Qingdao, Shandong, China, 266100; College of Computer Science and Technology, Qingdao University, 12593 Qingdao, Shandong, China; School of Big Data &amp;Software Engineering, Chongqing University, 47913 Chongqing, Chongqing, China, 400000; College of Computer Science and Technology, Ocean University of China, 12591 Qingdao, Shandong, China; School of Computer Science and Technology, Tianjin University, 12605 Tianjin, Tianjin, China; School of Computer, Nanjing University of Posts and Telecommunications, 12577 Nanjing, Jiangsu, China","Xia, H., College of Computer Science and Technology, Ocean University of China, 12591 Qingdao, Shandong, China, 266100; Shao, S., College of Computer Science and Technology, Qingdao University, 12593 Qingdao, Shandong, China; Hu, C., School of Big Data &amp;Software Engineering, Chongqing University, 47913 Chongqing, Chongqing, China, 400000; Zhang, R., College of Computer Science and Technology, Ocean University of China, 12591 Qingdao, Shandong, China; Qiu, T., School of Computer Science and Technology, Tianjin University, 12605 Tianjin, Tianjin, China; Xiao, F., School of Computer, Nanjing University of Posts and Telecommunications, 12577 Nanjing, Jiangsu, China","GCN-based clustering schemes cannot interactively fuse feature information of nodes and topological structure information of graphs, leading to insufficient accuracy of clustering results. Moreover, the deep clustering model based on graph structure is vulnerable to the attack of adversarial samples leading to the reduced robustness of the model. To solve the above two problems, this paper proposes a robust clustering model based on attention mechanism and graph convolutional network (GCN), named AG-cluster. This model firstly uses graph attention network (GAT) and GCN to learn the feature information of nodes and the topological structure information of graphs, respectively. Then the representation results of the above two learning modules are interactively fused by the interlayer transfer operator. Finally, the model is trained end-to-end using a self-supervised training module to optimize the clustering results. In particular, an efficient graph purification defense mechanism (GPDM) is designed to resist adversarial attacks on graph data to improve the robustness of the model. Experimental results show that AG-cluster outperforms the other four benchmark methods, specifically, AG-cluster improves 7.6% in Accuracy and 11.5% in NMI compared to the best benchmark method. Besides, the new model still exhibits higher robustness and stronger migration ability under multiple attacks. IEEE",adversarial attack; deep clustering; defense; robustness,Cluster analysis; Clustering algorithms; Convolution; Graph theory; Adversarial attack; Attention mechanisms; Clusterings; Convolutional networks; Deep clustering; Feature information; Model-based OPC; Robust clustering models; Robustness; Topological structure; Network security,,,,,,,,,IEEE Computer Society,,,,,10414347,,ITKEE,,English,IEEE Trans Knowl Data Eng,Article,Article in Press,,Scopus,2-s2.0-85124714482
"Du T., Ji S., Wang B., He S., Li J., Li B., Wei T., Jia Y., Beyah R., Wang T.",57195491788;36918358000;57221064147;57447222000;57208691588;57199786691;57446970600;57219508246;6506392493;57383675800;,DetectS ec: Evaluating the robustness of object detection models to adversarial attacks,2022,International Journal of Intelligent Systems,,,,,,,,10.1002/int.22851,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124389749&doi=10.1002%2fint.22851&partnerID=40&md5=5386cf9d6a72c3a628ae4f3bd8815a2a,"Institute of Computer Science and Technology, Zhejiang University, Hangzhou, China; Department of Information Science, Binjiang Institute of Zhejiang University, Hangzhou, China; Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana-Champaign, IL, United States; Department of Foundational Security, Ant Group, Hangzhou, China; Department of Security and Privacy Technology, ByteDance AI Lab, Palo Alto, CA, United States; Institute of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, United States; Department of Information Sciences and Technology, The Pennsylvania State University, State College, PA, United States","Du, T., Institute of Computer Science and Technology, Zhejiang University, Hangzhou, China; Ji, S., Institute of Computer Science and Technology, Zhejiang University, Hangzhou, China, Department of Information Science, Binjiang Institute of Zhejiang University, Hangzhou, China; Wang, B., Institute of Computer Science and Technology, Zhejiang University, Hangzhou, China; He, S., Institute of Computer Science and Technology, Zhejiang University, Hangzhou, China; Li, J., Institute of Computer Science and Technology, Zhejiang University, Hangzhou, China; Li, B., Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana-Champaign, IL, United States; Wei, T., Department of Foundational Security, Ant Group, Hangzhou, China; Jia, Y., Department of Security and Privacy Technology, ByteDance AI Lab, Palo Alto, CA, United States; Beyah, R., Institute of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, United States; Wang, T., Department of Information Sciences and Technology, The Pennsylvania State University, State College, PA, United States","Despite their tremendous success in various machine learning tasks, deep neural networks (DNNs) are inherently vulnerable to adversarial examples, which are maliciously crafted inputs to cause DNNs to misbehave. Intensive research has been conducted on this phenomenon in simple tasks (e.g., image classification). However, little is known about this adversarial vulnerability for object detection, a much more complicated task, which often requires specialized DNNs and multiple additional components. In this paper, we present DetectSec, a uniform platform for robustness analysis of object detection models. Currently, DetectSec implements 13 representative adversarial attacks with 7 utility metrics and 13 defenses on 18 standard object detection models. Leveraging DetectSec, we conduct the first rigorous evaluation of adversarial attacks on the state-of-the-art object detection models. We analyze the impact of the factors including DNN architecture and capacity on the model robustness. We show that many conclusions about adversarial attacks and defenses in image classification tasks do not transfer to object detection tasks, for example, the targeted attack is stronger than the untargeted attack for two-stage detectors. Our findings will aid future efforts in understanding and defending against adversarial attacks in complicated tasks. In addition, we compare the robustness of different detection models and discuss their relative strengths and weaknesses. The platform DetectSec will be open source as a unique facility for further research on adversarial attacks and defenses in object detection tasks. © 2022 Wiley Periodicals LLC",adversarial attack; deep learning; neural network; object detection; robustness evaluation,Deep neural networks; Image classification; Object detection; Adversarial attack; Deep learning; Images classification; Intensive research; Neural-networks; Rigorous evaluation; Robustness analysis; Robustness evaluation; Simple++; State of the art; Object recognition,,,,,"Karpathy, A., Fei-Fei, L., (2015), pp. 3128-3137. , Deep visual-semantic alignments for generating image descriptions; Girshick, R., (2015), pp. 1440-1448. , Fast R-CNN; Ren, S., He, K., Girshick, R., Sun, J., (2015), Faster R-CNN towards real-time object detection with region proposal networks; Szegedy, C., (2014), Intriguing properties of neural networks; Goodfellow, I.J., Shlens, J., Szegedy, C., (2015), Explaining and harnessing adversarial examples; Zhao, P., Liu, S., Wang, Y., Lin, X., (2018), pp. 1065-1073. , An admm-based universal framework for adversarial attacks on deep neural networks; Yang, E., Liu, T., Deng, C., Tao, D., Adversarial examples for hamming space search (2020) IEEE Trans Cybernet, 50 (4), pp. 1473-1484; Zhang, F., Chan, P.P., Biggio, B., Yeung, D.S., Roli, F., Adversarial feature selection against evasion attacks (2015) IEEE Trans Cybernet, 46 (3), pp. 766-777; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., (2016), pp. 1528-1540. , Accessorize to a crime real and stealthy attacks on state-of-the-art face recognition., ACM; Janai, J., Güney, F., Behl, A., Geiger, A., (2017), Computer vision for autonomous vehicles problems, datasets and state-of-the-art. arXiv preprint; Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P., (2016), pp. 2574-2582. , Deepfool a simple and accurate method to fool deep neural networks; Carlini, N., Wagner, D., (2017), pp. 39-57. , Towards evaluating the robustness of neural networks., IEEE; Ling, X., Ji, S., Zou, J., (2019), DEEPSEC a uniform platform for security analysis of deep learning model; Yao, J., Fidler, S., Urtasun, R., (2012), pp. 702-709. , Describing the scene as a whole Joint object detection, scene classification and semantic segmentation., IEEE; Liu, L., Ouyang, W., Wang, X., (2018), Deep learning for generic object detection a survey. arXiv preprint; Liu, W., Anguelov, D., Erhan, D., (2016), pp. 21-37. , SSD single shot multibox detector; Li, Z., Zhou, F., (2017), FSSD Feature fusion single shot multibox detector. arXiv preprint; Girshick, R., Donahue, J., Darrell, T., Malik, J., (2014), pp. 580-587. , Rich feature hierarchies for accurate object detection and semantic segmentation; Eykholt, K., Evtimov, I., Fernandes, E., (2018), Robust physical-world attacks on deep learning visual classification; Xu, J., Du, Q., Adversarial attacks on text classification models using layer-wise relevance propagation (2020) Int J Intell Syst, 35 (9), pp. 1397-1415; Zhang, L., Wang, X., Lu, K., Peng, S., Wang, X., An efficient framework for generating robust adversarial examples (2020) Int J Intell Syst, 35 (9), pp. 1433-1449; Chen, J., Zheng, H., Xiong, H., FineFool: a novel DNN object contour attack on image recognition based on the attention perturbation adversarial technique (2021) Comput Security, 104; Chen, J., Zheng, H., Su, M., Du, T., Lin, C.T., Ji, S., (2019), pp. 173-198. , Invisible poisoning highly stealthy targeted poisoning attack; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2017) ICLR Workshop; Dong, Y., Liao, F., Pang, T., (2018), Boosting adversarial attacks with momentum; Athalye, A., Carlini, N., Wagner, D., (2018), Obfuscated gradients give a false sense of security circumventing defenses to adversarial examples. arXiv preprint; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., (2017), pp. 506-519. , Practical black-box attacks against machine learning., ACM; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., (2016), pp. 582-597. , Distillation as a defense to adversarial perturbations against deep neural networks., IEEE; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017), Towards deep learning models resistant to adversarial attacks. arXiv preprint; Li, J., Du, T., Ji, S., (2020), pp. 1381-1398. , Textshield Robust text classification based on multimodal embedding and neural machine translation; Du, T., Ji, S., Shen, L., (2021), pp. 516-534. , Cert-RNN Towards certifying the robustness of recurrent neural networks; Li, J., Du, T., Liu, X., Zhang, R., Xue, H., Ji, S., Enhancing model robustness by incorporating adversarial knowledge into semantic representation (2021) IEEE, pp. 7708-7712; Carlini, N., Wagner, D., (2017), pp. 3-14. , Adversarial examples are not easily detected bypassing ten detection methods., ACM; Gu, S., Rigazio, L., (2014), Towards deep neural network architectures robust to adversarial examples. arXiv preprint; Li, J., Ji, S., Du, T., Li, B., Wang, T., (2019), TextBugger generating adversarial text against real-world applications. In; Du, T., Ji, S., Li, J., Gu, Q., Wang, T., Beyah, R., (2019), SirenAttack generating adversarial audio for end-to-end acoustic systems. arXiv preprint; Li, S., Neupane, A., Paul, S., (2019), Adversarial perturbations against real-time video classification systems; Xie, C., Wang, J., Zhang, Z., (2017), Adversarial examples for semantic segmentation and object detection; Chen, S.T., Cornelius, C., Martin, J., ShapeShifter: robust physical adversarial attack on faster R-CNN object detector (2018) ECML-PKDD; Szegedy, C., Vanhoucke, V., Ioffe, S., (2016), pp. 2818-2826. , Rethinking the inception architecture for computer vision. In; Howard, A.G., Zhu, M., Chen, B., (2017), Mobilenets efficient convolutional neural networks for mobile vision applications. arXiv preprint; Pengchong, J., Vivek, R., Xiangxin, Z., (2018), Pooling pyramid network for object detection. arXiv preprint; Lin, T.Y., Goyal, P., Girshick, R., Focal loss for dense object detection (2018) TPAMI; Jonathan, H., Vivek, R., (2019), https://ai.googleblog.com/2018/07/accelerated-training-and-inference-with.html, Accelerated training and inference with the tensorflow object detection API; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2017) ICLR; Chen, P.Y., Sharma, Y., Zhang, H., (2018), EAD elastic-net attacks to deep neural networks via adversarial examples; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., On detecting adversarial perturbations (2017) ICLR; Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., (2017), On the (statistical) detection of adversarial examples. arXiv preprint; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017), Detecting adversarial samples from artifacts; Katz, G., Barrett, C., Dill, D.L., Julian, K., Kochenderfer, M.J., (2017), pp. 97-117. , Reluplex An efficient SMT solver for verifying deep neural networks; Bunel, R., Turkaslan, I., Torr, P.H., Kohli, P., Kumar, M.P., (2017), Piecewise linear neural network verification a comparative study. arXiv preprint; Guo, C., Rana, M., Cisse, M., Van Der Maaten, L., Countering adversarial images using input transformations (2018) ICLR; Xu, W., Evans, D., Qi, Y., Feature squeezing: Detecting adversarial examples in deep neural networks (2018) NDSS; Osadchy, M., Hernandez-Castro, J., Gibson, S., Dunkelman, O., Pérez-Cabo, D., No bot expects the DeepCAPTCHA! Introducing immutable adversarial examples with applications to CAPTCHA (2016) IACR Cryptology ePrint Archive, 2016, p. 336; Zhang, D., Zhang, T., Lu, Y., Zhu, Z., Dong, B., (2019), pp. 227-238. , You only propagate once Accelerating adversarial training via maximal principle; Zhang, H., Wang, J., (2019), pp. 421-430. , Towards adversarially robust object detection; Buades, A., Coll, B., Morel, J.M., (2005), 2, pp. 60-65. , A non-local algorithm for image denoising., IEEE; Mihcak, M.K., Kozintsev, I., Ramchandran, K., (1999), 6, pp. 3253-3256. , Spatially adaptive statistical modeling of wavelet image coefficients and its application to denoising; Dziugaite, G.K., Ghahramani, Z., Roy, D.M., (2016), A study of the effect of jpg compression on adversarial images. arXiv preprint; Wang, Z., Bovik, A.C., Sheikh, H.R., Simoncelli, E.P., Image quality assessment: from error visibility to structural similarity (2004) IEEE Trans Image Process, 13 (4), pp. 600-612; Wang, Z., Simoncelli, E.P., Bovik, A.C., (2003), 2, pp. 1398-1402. , Multiscale structural similarity for image quality assessment. Vol; Everingham, M., Van Gool, L., Williams, C.K., The pascal visual object classes (voc) challenge (2010) IJCV, 88 (2), pp. 303-338; Lin, T.Y., Maire, M., Belongie, S., (2014), pp. 740-755. , Microsoft coco common objects in context., Springer; Cubuk, E.D., Zoph, B., Schoenholz, S.S., Le, Q.V., (2017), Intriguing properties of adversarial examples; Huang, J., Rathod, V., Sun, C., (2017), Speed/accuracy trade-offs for modern convolutional object detectors; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) ICLR; Papernot, N., McDaniel, P., Goodfellow, I., (2016), Transferability in machine learning from phenomena to black-box attacks using adversarial samples. arXiv preprint; Xie, C., Wang, J., Zhang, Z., Mitigating adversarial effects through randomization (2018) ICLR; Athalye, A., Sutskever, I., (2017), Synthesizing robust adversarial examples. arXiv preprint; Tsipras, D., Santurkar, S., Engstrom, L., Turner, A., Madry, A., (2019), Robustness may be at odds with accuracy","Ji, S.; Institute of Computer Science and Technology, China; 电子邮件: sji@zju.edu.cn",,,John Wiley and Sons Ltd,,,,,8848173,,IJISE,,English,Int J Intell Syst,Article,Article in Press,,Scopus,2-s2.0-85124389749
"Wu B., Wang S., Yuan X., Wang C., Rudolph C., Yang X.",57219585598;57192102600;56377984000;57222484380;57441282600;57219589059;,Defeating Misclassification Attacks Against Transfer Learning,2022,IEEE Transactions on Dependable and Secure Computing,,,,,,,,10.1109/TDSC.2022.3144988,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124092159&doi=10.1109%2fTDSC.2022.3144988&partnerID=40&md5=534d9e5d193eb32df38efd9751964a48,"IT, Monash University, 2541 Clayton, Victoria, Australia, (e-mail: bang.wu@monash.edu); IT, Monash University Faculty of Information Technology, 224480 Clayton, Victoria, Australia, (e-mail: shuo.wang@csiro.au); Information Technology, Monash University, Melbourne, Victoria, Australia, (e-mail: xyuancs@gmail.com); Computer Science, City University of Hong Kong, Hong Kong, Hong Kong, Hong Kong, (e-mail: congwang@cityu.edu.hk); Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria, Australia, (e-mail: Carsten.Rudolph@monash.edu); IT, Monash University, 2541 Clayton, Victoria, Australia, (e-mail: wayne.yang@monash.edu)","Wu, B., IT, Monash University, 2541 Clayton, Victoria, Australia, (e-mail: bang.wu@monash.edu); Wang, S., IT, Monash University Faculty of Information Technology, 224480 Clayton, Victoria, Australia, (e-mail: shuo.wang@csiro.au); Yuan, X., Information Technology, Monash University, Melbourne, Victoria, Australia, (e-mail: xyuancs@gmail.com); Wang, C., Computer Science, City University of Hong Kong, Hong Kong, Hong Kong, Hong Kong, (e-mail: congwang@cityu.edu.hk); Rudolph, C., Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria, Australia, (e-mail: Carsten.Rudolph@monash.edu); Yang, X., IT, Monash University, 2541 Clayton, Victoria, Australia, (e-mail: wayne.yang@monash.edu)","Transfer learning is prevalent as a technique to efficiently generate new models (Student models) based on the knowledge transferred from a pre-trained model (Teacher model). However, Teacher models are often publicly available for sharing and reuse, which inevitably introduces vulnerability to trigger severe attacks against transfer learning systems. In this paper, we take a first step towards mitigating one of the most advanced misclassification attacks in transfer learning. We design a distilled \emph{differentiator} via activation-based network pruning to enervate the attack transferability while retaining accuracy. We adopt an ensemble structure from variant differentiators to improve the defence robustness. To avoid the bloated ensemble size during inference, we propose two-phase defence, in which inference from the Student model is firstly performed to narrow down the candidate differentiators to be assembled, and later only a small, fixed number of them can be chosen to validate clean or reject adversarial inputs effectively. Our comprehensive evaluations on both large and small image recognition tasks confirm that the Student models with our defence of only 5 differentiators immune over 90\% the adversarial inputs with accuracy loss less than 10\%. Our comparison also demonstrates that our design outperforms prior problematic defences. IEEE",Computational modeling; Data models; Deep neural network; Defence against adversarial examples; Mathematical models; Perturbation methods; Pre-trained model; Task analysis; Training; Transfer learning; Transfer learning,Deep neural networks; Image recognition; Job analysis; Perturbation techniques; Students; Teaching; Computational modelling; Defense against adversarial example; Differentiators; Misclassifications; Perturbation method; Pre-trained model; Student Modeling; Task analysis; Transfer learning; Personnel training,,,,,,,,,Institute of Electrical and Electronics Engineers Inc.,,,,,15455971,,,,English,IEEE Trans. Dependable Secure Comput.,Article,Article in Press,"All Open Access, Green",Scopus,2-s2.0-85124092159
"Sun Y., Ochiai H.",57212474153;57381425100;,Homogeneous Learning: Self-Attention Decentralized Deep Learning,2022,IEEE Access,10,,,7695,7703,,,10.1109/ACCESS.2022.3142899,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123297637&doi=10.1109%2fACCESS.2022.3142899&partnerID=40&md5=a2a2de7c3f7548627bc811beb745bc4c,"University of Tokyo, Graduate School of Information Science and Technology, Tokyo, 1138654, Japan; RIKEN AIP, Tokyo, 1030027, Japan","Sun, Y., University of Tokyo, Graduate School of Information Science and Technology, Tokyo, 1138654, Japan, RIKEN AIP, Tokyo, 1030027, Japan; Ochiai, H., University of Tokyo, Graduate School of Information Science and Technology, Tokyo, 1138654, Japan","Federated learning (FL) has been facilitating privacy-preserving deep learning in many walks of life such as medical image classification, network intrusion detection, and so forth. Whereas it necessitates a central parameter server for model aggregation, which brings about delayed model communication and vulnerability to adversarial attacks. A fully decentralized architecture like Swarm Learning allows peer-to-peer communication among distributed nodes, without the central server. One of the most challenging issues in decentralized deep learning is that data owned by each node are usually non-independent and identically distributed (non-IID), causing time-consuming convergence of model training. To this end, we propose a decentralized learning model called Homogeneous Learning (HL) for tackling non-IID data with a self-attention mechanism. In HL, training performs on each round's selected node, and the trained model of a node is sent to the next selected node at the end of each round. Notably, for the selection, the self-attention mechanism leverages reinforcement learning to observe a node's inner state and its surrounding environment's state, and find out which node should be selected to optimize the training. We evaluate our method with various scenarios for two different image classification tasks. The result suggests that HL can achieve a better performance compared with standalone learning and greatly reduce both the total training rounds by 50.8% and the communication cost by 74.6% for decentralized learning with non-IID data. This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/",Computational modeling; Computer architecture; Data models; Peer-to-peer computing; Servers; Task analysis; Training,Computer architecture; Deep neural networks; Distributed computer systems; Image classification; Network architecture; Network layers; Peer to peer networks; Privacy-preserving techniques; Reinforcement learning; Supervised learning; Attention mechanisms; Collective intelligences; Computational modelling; Decentralised; Decentralized learning; Distributed data; Knowledge transfer; Multi-layer neural networks; Peer-to-peer computing; Task analysis; Knowledge management,,,,,"General Data Protection Regulation. Accessed: Sep. 22, 2021; Konecný, J., McMahan, H.B., Yu, X.F., Richtarik, P., Suresh, A.T., Bacon, D., Federated learning: Strategies for improving communication efficiency (2016) Proc. NIPS Workshop Private Multi-Party Mach. Learn.; Priya, P.M.S., Pham, Q.-V., Dev, K., Maddikunta, P.K.R., Gadekallu, T.R., Huynh-The, T., (2021) Fusion of Federated Learning and Industrial Internet of Things: A Survey; Gao, Y., Liu, L., Hu, B., Lei, T., Ma, H., Federated region-learning for environment sensing in edge computing system (2020) IEEE Trans. Netw. Sci. Eng., 7 (4), pp. 2192-2204. , Oct; Liu, Y., Huang, A., Luo, Y., Huang, H., Liu, Y., Chen, Y., Feng, L., Yang, Q., Fedvision: An online visual object detection platform powered by federated learning (2020) Proc. AAAI Conf. Artif. Intell., 34 (8), pp. 13172-13179. , Apr; Pokhrel, S.R., Choi, J., Federated learning with blockchain for autonomous vehicles: Analysis and design challenges (2020) IEEE Trans. Com-mun., 68 (8), pp. 4734-4746. , Aug; Liu, B., Wang, L., Liu, M., Lifelong federated reinforcement learning: A learning architecture for navigation in cloud robotic systems (2019) IEEE Robot. Autom. Lett., 4 (4), pp. 4555-4562. , Oct; Sun, Y., Esaki, H., Ochiai, H., Adaptive intrusion detection in the networking of large-scale LANs with segmented federated learning (2021) IEEE Open J. Commun. Soc., 2, pp. 102-112; Rahman, S.A., Tout, H., Talhi, C., Mourad, A., Internet of Things intrusion detection: Centralized, on-device, or federated learning? (2020) IEEE Netw., 34 (6), pp. 310-317. , Nov; Brendan McMahan, H., Ramage, D., Talwar, K., Zhang, L., Learning differentially private recurrent language models (2018) Proc. ICLR; Cao, D., Chang, S., Lin, Z., Liu, G., Sun, D., Understanding distributed poisoning attack in federated learning (2019) Proc. IEEE 25th Int. Conf. Parallel Distrib. Syst. (ICPADS), pp. 233-239. , Dec; Nguyen, T., Rieger, P., Miettinen, M., Sadeghi, A., Poisoning attacks on federated learning-based IOT intrusion detection system (2020) Proc. Workshop Decentralized IoT Syst. Secur. (DISS), pp. 1-7; Duan, M., Liu, D., Chen, X., Liu, R., Tan, Y., Self-balancing federated learning with global imbalanced data in mobile systems (2021) IEEE Trans. Parallel Distrib. Syst., 32 (1), pp. 59-71. , Jul; Warnat-Herresthal, S., Schultze, H., Shastry, K.L., Manamohan, S., Mukherjee, S., Garg, V., Sarveswara, R., Ktena, S., Swarm learning for decentralized and confidential clinical machine learning (2021) Nature, 594 (7862), pp. 265-270; Li, Y., Chen, C., Liu, N., Huang, H., Zheng, Z., Yan, Q., A blockchain-based decentralized federated learning framework with committee consensus (2021) IEEE Netw., 35 (1), pp. 234-241. , Jan; Lu, Y., Huang, X., Dai, Y., Maharjan, S., Zhang, Y., Blockchain and federated learning for privacy-preserved data sharing in industrial IoT (2020) IEEE Trans. Ind. Informat., 16 (6), pp. 4177-4186. , Jun; Mowla, N., Tran, N.H., Doh, I., Chae, K., Federated learning-based cognitive detection of jamming attack in flying ad-hoc network (2020) IEEE Access, 8, pp. 4338-4350; Sener, O., Savarese, S., (2018) Active Learning for Convolutional Neural Networks: A Core-set Approach; Wang, H., Kaplan, Z., Niu, D., Li, B., Optimizing federated learning on non-IID data with reinforcement learning (2020) Proc. IEEE Conf. Comput. Commun. (INFOCOM), pp. 1698-1707. , Jul; Zhao, Y., Li, M., Lai, L., Suda, N., Civin, D., Chandra, V., Federated learning with non-IID data (2018) CoRR, pp. 1-13. , abs/1806.00582, Jun; Jeong, E., Oh, S., Kim, H., Park, J., Bennis, M., Kim, S.-L., Communication-efficient on-device machine learning: Federated distillation and augmentation under non-IID private data (2018) CoRR, pp. 1-6. , abs/1811.11479, Nov; He, C., Annavaram, M., Avestimehr, S., Group knowledge transfer: Federated learning of large CNNs at the edge (2020) Proc. NeurIPS; Singh, A., Vepakomma, P., Gupta, O., Raskar, R., Detailed comparison of communication efficiency of split learning and federated learning (2019) CoRR, pp. 1-5. , abs/1909.09145 Sep; Lecun, Y., Cortes, C., Burges, C., (2010) MNIST Handwritten Digit Database. ATT Labs, , http://yann.lecun.com/exdb/mnist, Feb; Xiao, H., Rasul, K., Vollgraf, R., Fashion-MNIST: A novel image dataset for benchmarking machine learning algorithms (2017) CoRR, pp. 1-6. , Aug abs/1708.07747","Sun, Y.; University of Tokyo, Japan; 电子邮件: ywsun@g.ecc.u-tokyo.ac.jp",,,Institute of Electrical and Electronics Engineers Inc.,,,,,21693536,,,,English,IEEE Access,Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85123297637
"Mahmood K., Nguyen P.H., Nguyen L.M., Nguyen T., Van Dijk M.",55586392400;57222210769;57190262358;56659739300;7102854233;,Besting the Black-Box: Barrier Zones for Adversarial Example Defense,2022,IEEE Access,10,,,1451,1474,,,10.1109/ACCESS.2021.3138966,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122331903&doi=10.1109%2fACCESS.2021.3138966&partnerID=40&md5=f5e2b6ffde751cf8c987b31a77ee4dda,"Department of Electrical and Computer Engineering, University of Connecticut, Storrs, CT  06269, United States; EBay Inc., San Jose, CA  95125, United States; IBM Research, Thomas J. Watson Research Center, Yorktown Heights, NY  10562, United States; Amazon Inc., Seattle, WA  98109, United States; CWI Amsterdam, Amsterdam, 1098, Netherlands","Mahmood, K., Department of Electrical and Computer Engineering, University of Connecticut, Storrs, CT  06269, United States; Nguyen, P.H., EBay Inc., San Jose, CA  95125, United States; Nguyen, L.M., IBM Research, Thomas J. Watson Research Center, Yorktown Heights, NY  10562, United States; Nguyen, T., Amazon Inc., Seattle, WA  98109, United States; Van Dijk, M., CWI Amsterdam, Amsterdam, 1098, Netherlands","Adversarial machine learning defenses have primarily been focused on mitigating static, white-box attacks. However, it remains an open question whether such defenses are robust under an adaptive black-box adversary. In this paper, we specifically focus on the black-box threat model and make the following contributions: First we develop an enhanced adaptive black-box attack which is experimentally shown to be ≥ 30 % more effective than the original adaptive black-box attack proposed by Papernot et al. For our second contribution, we test 10 recent defenses using our new attack and propose our own black-box defense (barrier zones). We show that our defense based on barrier zones offers significant improvements in security over state-of-the-art defenses. This improvement includes greater than 85% robust accuracy against black-box boundary attacks, transfer attacks and our new adaptive black-box attack, for the datasets we study. For completeness, we verify our claims through extensive experimentation with 10 other defenses using three adversarial models (14 different black-box attacks) on two datasets (CIFAR-10 and Fashion-MNIST). © 2013 IEEE.",adversarial defense; adversarial examples; Adversarial machine learning; black-box attack; deep learning; security,Deep learning; Adversarial defense; Adversarial example; Adversarial machine learning; Black boxes; Black-box attack; Deep learning; License; Robustness; Security; Network security,,,,,"Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classi-fication with deep convolutional neural networks (2012) Proc. Nips, pp. 1097-1105. , F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger, Eds; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) Proc. Iclr, pp. 1-14; Girshick, R., Fast R-CNN (2015) Proc. Ieee Int. Conf. Comput. Vis. (ICCV), pp. 1440-1448. , Dec; Ren, S., He, K., Girshick, R.B., Sun, J., Faster R-CNN: Towards realtime object detection with region proposal networks (2015) Proc. Nips, pp. 91-99; Shelhamer, E., Long, J., Darrell, T., Fully convolutional networks for semantic segmentation (2017) Ieee Trans. Pattern Anal. Mach. Intell., 39 (4), pp. 640-651. , Apr; Wang, J., Zhang, Z., Xie, C., Zhou, Y., Premachandran, V., Zhu, J., Xie, L., Yuille, A., (2017) Visual Concepts and Compositional Voting; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R., Intriguing properties of neural networks (2013) CoRR, , http://arxiv.org/abs/1312.6199, abs/1312.6199, [Online]; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2014) CoRR, , http://arxiv.org/abs/1412.6572, abs/1412.6572, [Online]; Tramer, F., Carlini, N., Brendel, W., Madry, A., (2020) On Adaptive Attacks to Adversarial Example Defenses; Athalye, A., Carlini, N., Wagner, D.A., Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples (2018) Proc. Icml, pp. 274-283; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) Proc. AISec@CCS, pp. 3-14; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Proc. Ieee Symp. Secur. Privacy (SP), pp. 582-597. , May; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial machine learning at scale (2016) CoRR, , http://arxiv.org/abs/1611.01236, abs/1611.01236, [Online]; Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2018) Proc. Int. Conf. Learn. Represent.; Cao, X., Gong, N.Z., Mitigating evasion attacks to deep neural networks via region-based classification (2017) Proc. 33rd Annu. Comput. Secur. Appl. Conf., pp. 278-287; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., On detecting adversarial perturbations (2017) CoRR, , http://arxiv.org/abs/1702.04267, abs/1702.04267, [Online]; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., Mitigating adversarial effects through randomization (2018) Proc. Iclr, pp. 1-16; Meng, D., Chen, H., MagNet: A two-pronged defense against adversarial examples (2017) Proc. Acm Sigsac Conf. Comput. Commun. Secur., pp. 135-147. , Oct; Guo, C., Rana, M., Cisse, M., Maaten Der, L.Van, Countering adversarial images using input transformations (2018) Proc. Int. Conf. Learn. Represent.; Srisakaokul, S., Zhang, Y., Zhong, Z., Yang, W., Xie, T., Li, B., (2018) MULDEF: Multi-model-based Defense Against Adversarial Examples for Neural Networks; Raff, E., Sylvester, J., Forsyth, S., McLean, M., Barrage of random transforms for adversarially robust defense (2019) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 6528-6537. , Jun; Roth, K., Kilcher, Y., Hofmann, T., (2019) The Odds Are Odd: A Statistical Test for Detecting Adversarial Examples; Pang, T., Xu, K., Du, C., Chen, N., Zhu, J., Improving adversarial robustness via promoting ensemble diversity (2019) Proc. Icml, pp. 4970-4979; Chen, J., Jordan, M.I., Wainwright, M.J., HopSkipJumpAttack: A query-efficient decision-based attack (2020) Proc. Ieee Symp. Secur. Privacy (SP), pp. 1277-1294. , May; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proc. ACMAsia Conf. Comput. Commun. Secur., pp. 506-519. , Apr; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) Proc. Int. Conf. Learn. Represent. (ICLR), pp. 1-28; Yuan, X., He, P., Zhu, Q., Li, X., Adversarial examples: Attacks and defenses for deep learning (2019) Ieee Trans. Neural Netw. Learn. Syst., 30 (9), pp. 2805-2824; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) Proc. Int. Conf. Learn. Represent. (ICLR), pp. 1-11; Carlini, N., Athalye, A., Papernot, N., Brendel, W., Rauber, J., Tsipras, D., Goodfellow, I., Kurakin, A., (2019) On Evaluating Adversarial Robustness; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R., Intriguing properties of neural networks (2014) Proc. Iclr, pp. 1-10; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) Proc. Iclr, pp. 1-24; Chen, J., Gu, Q., (2020) RayS: A Ray Searching Method for Hard-label Adversarial Attack; Brendel, W., Rauber, J., Bethge, M., (2017) Decision-based Adversarial Attacks: Reliable Attacks Against Black-box Machine Learning Models; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., ZOO: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) Proc. 10th Acm Workshop Artif. Intell. Secur., pp. 15-26. , Nov; Guo, C., Gardner, J.R., You, Y., Wilson, A.G., Weinberger, K.Q., (2019) Simple Black-box Adversarial Attacks; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2017) Proc. Int. Conf. Learn. Represent. (ICLR) Workshop, pp. 1-14; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2018) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 9185-9193. , Jun; Chen, P.-Y., Sharma, Y., Zhang, H., Yi, J., Hsieh, C.-J., EAD: Elastic-net attacks to deep neural networks via adversarial examples (2018) Proc. 32nd Aaai Conf. Artif. Intell., pp. 1-8; Mahmood, K., Gurevin, D., Van Dijk, M., Ha Nguyen, P., (2020) Beware the Black-box: On the Robustness of Recent Defenses to Adversarial Examples; Tsipras, D., Santurkar, S., Engstrom, L., Turner, A., Madry, A., Robustness may be at odds with accuracy (2019) Proc. Int. Conf. Learn. Represent., pp. 1-24. , https://openreview.net/forum?id=SyxAb30cY7, [Online]; Zhang, H., Yu, Y., Jiao, J., Xing, E., El Ghaoui, L., Jordan, M., Theoretically principled trade-off between robustness and accuracy (2019) Proc. Int. Conf. Mach. Learn., pp. 7472-7482; Xiao, H., Rasul, K., Vollgraf, R., (2017) Fashion-MNIST: A Novel Image Dataset for Benchmarking Machine Learning Algorithms; Krizhevsky, A., Nair, V., Hinton, G., (2019) CIFAR-10 (Canadian Institute for Advanced Research). Accessed: Apr. 15, , http://www.cs.toronto.edu/~kriz/cifar.html, [Online]; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. Ieee Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 770-778. , Jun; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition; Carlini, N., Wagner, D., (2017) Magnet and 'Efficient Defenses Against Adversarial Attacks' Are Not Robust to Adversarial Examples; Kingma, D.P., Ba, J., (2014) Adam: A Method for Stochastic Optimization; Kolesnikov, A., Beyer, L., Zhai, X., Puigcerver, J., Yung, J., Gelly, S., Houlsby, N., Big transfer (BiT): General visual representation learning (2020) Proc. Eur. Conf. Comput. Vis., in Lecture Notes in Computer Science, pp. 491-507","Mahmood, K.; Department of Electrical and Computer Engineering, United States; 电子邮件: kaleel.mahmood@uconn.edu",,,Institute of Electrical and Electronics Engineers Inc.,,,,,21693536,,,,English,IEEE Access,Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85122331903
"Mahmood K., Mahmood R., Rathbun E., Van Dijk M.",55586392400;57223764114;57305347100;7102854233;,Back in Black: A Comparative Evaluation of Recent State-Of-The-Art Black-Box Attacks,2022,IEEE Access,10,,,998,1019,,,10.1109/ACCESS.2021.3138338,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122100382&doi=10.1109%2fACCESS.2021.3138338&partnerID=40&md5=af8aecaa4633cf8ea20ed4f648557640,"Department of Computer Science and Engineering, University of Connecticut, Storrs, CT  06268, United States; CWI Amsterdam, Amsterdam, 1098 XG, Netherlands","Mahmood, K., Department of Computer Science and Engineering, University of Connecticut, Storrs, CT  06268, United States; Mahmood, R., Department of Computer Science and Engineering, University of Connecticut, Storrs, CT  06268, United States; Rathbun, E., Department of Computer Science and Engineering, University of Connecticut, Storrs, CT  06268, United States; Van Dijk, M., CWI Amsterdam, Amsterdam, 1098 XG, Netherlands","The field of adversarial machine learning has experienced a near exponential growth in the amount of papers being produced since 2018. This massive information output has yet to be properly processed and categorized. In this paper, we seek to help alleviate this problem by systematizing the recent advances in adversarial machine learning black-box attacks since 2019. Our survey summarizes and categorizes 20 recent black-box attacks. We also present a new analysis for understanding the attack success rate with respect to the adversarial model used in each paper. Overall, our paper surveys a wide body of literature to highlight recent attack developments and organizes them into four attack categories: score based attacks, decision based attacks, transfer attacks and non-traditional attacks. Further, we provide a new mathematical framework to show exactly how attack results can fairly be compared. © 2013 IEEE.",adversarial defense; adversarial examples; Adversarial machine learning; black-box attack; deep learning; security,Surveys; Adversarial defense; Adversarial example; Adversarial machine learning; Black boxes; Black-box attack; Comparative evaluations; Deep learning; Recent state; Security; State of the art; Deep learning,,,,,"LeCun, Y., Boser, B., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W., Jackel, L.D., Backpropagation applied to handwritten zip code recognition (1989) Neural Comput., 1 (4), pp. 541-551; He, K., Gkioxari, G., Dollár, P., Girshick, R., Mask R-CNN (2017) Proc. Ieee Int. Conf. Comput. Vis. (ICCV), , Oct; Redmon, J., Divvala, S., Girshick, R., Farhadi, A., You only look once: Unified, real-Time object detection (2016) Proc. Ieee Conf. Comput. Vis. Pattern Recognit. (CVPR), , Jun; Kolesnikov, A., Beyer, L., Zhai, X., Puigcerver, J., Yung, J., Gelly, S., Houlsby, N., Big transfer (BiT): General visual representation learning (2020) Proc. Eur. Conf. Comput. Vis. (Lecture Notes in Computer Science), pp. 491-507; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proc. ACMAsia Conf. Comput. Commun. Secur., pp. 506-519. , Apr; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., ZOO: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) Proc. 10th Acm Workshop Artif. Intell. Secur., pp. 15-26; Brendel, W., Rauber, J., Bethge, M., Decision-based adversarial attacks: Reliable attacks against black-box machine learning models (2018) Proc. Int. Conf. Learn. Represent.; Zhou, M., Wu, J., Liu, Y., Liu, S., Zhu, C., DaST: Data-free substitute training for adversarial attacks (2020) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 231-240. , Jun; Chen, J., Jordan, M.I., Wainwright, M.J., HopSkipJumpAttack: A query-efficient decision-based attack (2020) Proc. Ieee Symp. Secur. Privacy (SP), pp. 1277-1294. , May; Bhambri, S., Muku, S., Tulasi, A., Balaji Buduru, A., (2019) A Survey of Black-box Adversarial Attacks on Computer Vision Models; Maho, T., Furon, T., Le Merrer, E., SurFree:Afast surrogate-free blackbox attack (2021) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 10430-10439. , Jun; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks; Biggio, B., Roli, F., Wild patterns: Ten years after the rise of adversarial machine learning (2018) Pattern Recognit., 84, pp. 317-331. , Dec; Hsieh, Y.-L., Cheng, M., Juan, D.-C., Wei, W., Hsu, W.-L., Hsieh, C.-J., On the robustness of self-Attentive models (2019) Proc. 57th Annu. Meeting Assoc. Comput. Linguistics, pp. 1520-1529; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) Proc. Int. Conf. Learn. Represent.; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Proc. Ieee Symp. Secur. Privacy (SP), pp. 39-57. , May; Chen, P.-Y., Sharma, Y., Zhang, H., Yi, J., Hsieh, C.-J., EAD: Elastic-net attacks to deep neural networks via adversarial examples (2018) Proc. 32nd Aaai Conf. Artif. Intell.; Croce, F., Hein, M., Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks (2020) Proc. Int. Conf. Mach. Learn., pp. 2206-2216; Athalye, A., Carlini, N., Wagner, D., Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples (2018) Proc. 35th Int. Conf. Mach. Learn. (Proceedings of Machine Learning Research), 80, pp. 274-283. , J. Dy and A. Krause, Eds., Jul; Mahmood, K., Ha Nguyen, P., Nguyen, L.M., Nguyen, T., Van Dijk, M., (2019) BUZz: BUffer Zones for Defending Adversarial Examples in Image Classification; Li, M., Deng, C., Li, T., Yan, J., Gao, X., Huang, H., Towards transferable targeted attack (2020) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 641-649. , Jun; Du, J., Zhang, H., Zhou, J.T., Yang, Y., Feng, J., Query-efficient meta attack to deep neural networks (2020) Proc. Int. Conf. Learn. Represent., , https://openreview.net/forum?id=Skxd6gSYDS, [Online]; Cheng, S., Dong, Y., Pang, T., Su, H., Zhu, J., Improving black-box adversarial attacks with a transfer-based prior (2019) Proc. 33rd Int. Conf. Neural Inf. Process. Syst., pp. 10934-10944; Zhao, P., Liu, S., Chen, P.-Y., Hoang, N., Xu, K., Kailkhura, B., Lin, X., On the design of black-box adversarial examples by leveraging gradientfree optimization and operator splitting method (2019) Proc. IEEE/CVF Int. Conf. Comput. Vis. (ICCV), pp. 121-130. , Oct; Huang, Z., Zhang, T., Black-box adversarial attack with transferable model-based embedding (2019) Proc. Int. Conf. Learn. Represent.; Andriushchenko, M., Croce, F., Flammarion, N., Hein, M., Square attack: A query-efficient black-box adversarial attack via random search (2020) Proc. Eur. Conf. Comput. Vis., pp. 484-501. , Springer; Zhao, P., Chen, P.-Y., Wang, S., Lin, X., Towards query-efficient blackbox adversary with zeroth-order natural gradient descent (2020) Proc. Aaai Conf. Artif. Intell., 34 (4), pp. 6909-6916; Li, J., Ji, R., Liu, H., Liu, J., Zhong, B., Deng, C., Tian, Q., Projection & probability-driven black-box attack (2020) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., pp. 362-371. , Jun; Liu, Y., Moosavi-Dezfooli, S.-M., Frossard, P., A geometry-inspired decision-based attack (2019) Proc. IEEE/CVF Int. Conf. Comput. Vis. (ICCV), pp. 4889-4897. , Oct; Rahmati, A., Moosavi-Dezfooli, S.-M., Frossard, P., Dai, H., GeoDA: A geometric framework for black-box adversarial attacks (2020) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 8446-8455. , Jun; Li, H., Xu, X., Zhang, X., Yang, S., Li, B., QEBA: Query-efficient boundary-based blackbox attack (2020) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 1218-1227. , Jun; Chen, J., Gu, Q., RayS: A ray searching method for hard-label adversarial attack (2020) Proc. 26th Acm Sigkdd Int. Conf. Knowl. Discovery Data Mining, pp. 1739-1747. , Aug; Li, H., Li, L., Xu, X., Zhang, X., Yang, S., Li, B., Nonlinear projection based gradient estimation for query efficient blackbox attacks (2021) Proc. 24th Int. Conf. Artif. Intell. Statist. (Proceedings of Machine Learning Research), 130, pp. 3142-3150. , http://proceedings.mlr.press/v130/li21f.html, A. Banerjee and K. Fukumizu, Eds. Apr., [Online]; Croce, F., Hein, M., Sparse and imperceivable adversarial attacks (2019) Proc. IEEE/CVF Int. Conf. Comput. Vis. (ICCV), pp. 4724-4732. , Oct; Yang, C., Kortylewski, A., Xie, C., Cao, Y., Yuille, A., Patchattack: A black-box texture-based attack with reinforcement learning (2020) Proc. Eur. Conf. Comput. Vis., pp. 681-698. , Springer; Shahin Shamsabadi, A., Sanchez-Matilla, R., Cavallaro, A., Color-Fool: Semantic adversarial colorization (2020) Proc. IEEE/CVF Conf. Com-put. Vis. Pattern Recognit. (CVPR), pp. 1148-1157. , Los Alamitos, CA, USA, Jun; Machado, G.R., Silva, E., Goldschmidt, R.R., Adversarial machine learning in image classification: A survey toward the defender's perspective (2021) Acm Comput. Surv., 55 (1), pp. 1-38; Aldahdooh, A., Hamidouche, W., Fezza, S.A., Deforges, O., (2021) Adversarial Example Detection for Dnn Models: A Review; Abolghasemi, V., Ferdowsi, S., Makkiabadi, B., Sanei, S., On optimization of the measurement matrix for compressive sensing (2010) Proc. 18th Eur. Signal Process. Conf., pp. 427-431. , Aug; Ravelomanantsoa, A., Rabah, H., Rouane, A., Compressed sensing: A simple deterministic measurement matrix and a fast recovery algorithm (2015) Ieee Trans. Instrum. Meas., 64 (12), pp. 3405-3413. , Dec; Nesterov, Y., Spokoiny, V., Random gradient-free minimization of convex functions (2017) Found. Comput. Math., 17 (2), pp. 527-566. , Apr; Ilyas, A., Engstrom, L., Athalye, A., Lin, J., Black-box adversarial attacks with limited queries and information (2018) Proc. Icml, pp. 2137-2146; Fawzi, A., Moosavi-Dezfooli, S.-M., Frossard, P., Robustness of classi fiers: From adversarial to random noise (2016) Proc. Nips, pp. 1632-1640. , Red Hook, NY, USA: Curran Associates; Mahmood, K., Gurevin, D., Van Dijk, M., Ha Nguyen, P., (2020) Beware the Black-box: On the Robustness of Recent Defenses to Adversarial Examples; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2018) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., pp. 9185-9193. , Jun; Hoffer, E., Ailon, N., Deep metric learning using triplet network (2015) Proc. Simbad, pp. 84-92; Selvaraju, R.R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., Batra, D., Grad-CAM: Visual explanations from deep networks via gradient-based localization (2017) Proc. Ieee Int. Conf. Comput. Vis. (ICCV), pp. 618-626. , Oct; Gatys, L.A., Ecker, A.S., Bethge, M., Image style transfer using convolutional neural networks (2016) Proc. Ieee Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 2414-2423. , Jun; Gatys, L., Ecker, A.S., Bethge, M., Texture synthesis using convolutional neural networks (2015) Proc. Adv. Neural Inf. Process. Syst., 28, pp. 262-270; Ruderman, D.L., Cronin, T.W., Chiao, C.-C., Statistics of cone responses to natural images: Implications for visual coding (1998) J. Opt. Soc. Amer. A, Opt. Image Sci., 15 (8), pp. 2036-2045. , http://josaa.osa.org/abstract.cfm?URI=josaa-15-8-2036, [Online]; Zhang, R., Isola, P., Efros, A.A., Colorful image colorization (2016) Proc. Eccv, pp. 649-666; Lecun, Y., (2021) The Mnist Database of Handwritten Digits, , http://yann.lecun.com/exdb/mnist/andhttps://ci.nii.ac.jp/naid/10027939599/en, Accessed: Jan. 8, [Online]; Krizhevsky, A., Nair, V., Hinton, G., (2021) CIFAR-10 (Canadian Institute for Advanced Research)., , http://www.cs.toronto.edu/~kriz/cifar.html, Accessed: Apr. 15, [Online]; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., ImageNet: A large-scale hierarchical image database (2009) Proc. Ieee Conf. Comput. Vis. Pattern Recognit., pp. 248-255. , Jun; Cheng, S., Dong, Y., Pang, T., Su, H., Zhu, J., (2019) Improving Black-box Adversarial Attacks with a Transfer-based Prior; Li, H., Li, L., Xu, X., Zhang, X., Yang, S., Li, B., Nonlinear projection based gradient estimation for query efficient blackbox attacks (2021) Proc. Int. Conf. Artif. Intell. Statist., pp. 3142-3150","Mahmood, K.; Department of Computer Science and Engineering, United States; 电子邮件: kaleel.mahmood@uconn.edu",,,Institute of Electrical and Electronics Engineers Inc.,,,,,21693536,,,,English,IEEE Access,Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85122100382
"Ahmad M., Cheema U., Abdullah M., Moon S., Han D.",57210116830;57193442051;26650323000;8584419100;56152561800;,Generating synthetic disguised faces with cycle-consistency loss and an automated filtering algorithm,2022,Mathematics,10,1,4,,,,,10.3390/math10010004,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121573420&doi=10.3390%2fmath10010004&partnerID=40&md5=a0be64c4d63b50a2e2a17bccf43d954b,"Department of Computer Engineering, Sejong University, Seoul, 05006, South Korea","Ahmad, M., Department of Computer Engineering, Sejong University, Seoul, 05006, South Korea; Cheema, U., Department of Computer Engineering, Sejong University, Seoul, 05006, South Korea; Abdullah, M., Department of Computer Engineering, Sejong University, Seoul, 05006, South Korea; Moon, S., Department of Computer Engineering, Sejong University, Seoul, 05006, South Korea; Han, D., Department of Computer Engineering, Sejong University, Seoul, 05006, South Korea","Applications for facial recognition have eased the process of personal identification. How-ever, there are increasing concerns about the performance of these systems against the challenges of presentation attacks, spoofing, and disguises. One of the reasons for the lack of a robustness of facial recognition algorithms in these challenges is the limited amount of suitable training data. This lack of training data can be addressed by creating a database with the subjects having several dis-guises, but this is an expensive process. Another approach is to use generative adversarial networks to synthesize facial images with the required disguise add-ons. In this paper, we present a synthetic disguised face database for the training and evaluation of robust facial recognition algorithms. Fur-thermore, we present a methodology for generating synthetic facial images for the desired disguise add-ons. Cycle-consistency loss is used to generate facial images with disguises, e.g., fake beards, makeup, and glasses, from normal face images. Additionally, an automated filtering scheme is presented for automated data filtering from the synthesized faces. Finally, facial recognition experi-ments are performed on the proposed synthetic data to show the efficacy of the proposed methodology and the presented database. Training on the proposed database achieves an improvement in the rank-1 recognition rate (68.3%), over a model trained on the original nondisguised face images. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",CycleGAN; Data augmentation; Disguised face; Generative adversarial networks; Sejong Face Database; Style transfer; Synthetic database; Synthetic disguised face database; Synthetic faces,,,,,,"Singh, R., Vatsa, M., Bhatt, H.S., Bharadwaj, S., Noore, A., Nooreyezdan, S.S., Plastic Surgery: A New Dimension to Face Recog-nition (2010) IEEE Trans. Inf. Forensics Secur, 5, pp. 441-448. , https://doi.org/10.1109/TIFS.2010.2054083; Phillips, P.J., Flynn, P.J., Bowyer, K.W., Bruegge, R.W.V., Grother, P.J., Quinn, G.W., Pruitt, M., Distinguishing Identical Twins by Face Recognition (2011) Proceedings of the 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG), pp. 185-192. , Santa Barbara, CA, USA, 21–25 March; Adjabi, I., Ouahabi, A., Benzaoui, A., Jacques, S., Multi-block Color-binarized Statistical Images for Single-sam-Ple Face Recog-nition (2021) Sensors, 21, p. 728. , https://doi.org/10.3390/s21030728; Bhatt, H.S., Bharadwaj, S., Singh, R., Vatsa, M., On Matching Sketches with Digital Face Images (2010) Proceedings of the IEEE 4th International Conference on Biometrics: Theory, Applications and Systems (BTAS), , Washington, DC, USA, 27–29 September; Klare, B., Li, Z., Jain, A.K., Matching Forensic Sketches to Mug Shot Photos (2010) IEEE Trans. Pattern Anal. Mach. Intell, 33, pp. 639-646. , https://doi.org/10.1109/TPAMI.2010.180; Chen, X., Flynn, P.J., Bowyer, K.W., IR and Visible Light Face Recognition (2005) Comput. Vis. Image Underst, 99, pp. 332-358. , https://doi.org/10.1016/j.cviu.2005.03.001; Klare, B., Jain, A.K., HeTerogeneous Face Recognition: Matching NIR to Visible Light Images (2010) Proceedings of the International Conference on Pattern Recognition, , Istanbul, Turkey, 23–26 August; Singh, R., Vatsa, M., Noore, A., Hierarchical Fusion of Multi-Spectral Face Images for Improved Recognition Performance (2008) Inf. Fusion, 9, pp. 200-210. , https://doi.org/10.1016/j.inffus.2006.06.002; Adjabi, I., Ouahabi, A., Benzaoui, A., Taleb-Ahmed, A., Past, Present, and Future of Face Recognition: A Review (2020) Electronics, 9, p. 1188; Taskiran, M., Kahraman, N., Erdem, C.E., Face Recognition: Past, Present and Future (a Review) (2020) Digit. Signal Process, 106, p. 102809; Ramanathan, N., Chellappa, R., Roy Chowdhury, A.K., Facial Similarity across Age, Disguise, Illumination and Pose (2004) Proceedings of the International Conference on Image Processing (ICIP), 3. , Singapore, 24–27 October; Singh, R., Vatsa, M., Noore, A., Face Recognition with Disguise and Single Gallery Images (2009) Image Vis. Comput, 27, pp. 245-257. , https://doi.org/10.1016/j.imavis.2007.06.010; Cheema, U., Moon, S., Sejong Face Database: A Multi-Modal Disguise Face Database (2021) Comput. Vis. Image Underst, pp. 208-209. , https://doi.org/10.1016/J.CVIU.2021.103218, 103218; Noyes, E., Parde, C.J., Colón, Y.I., Hill, M.Q., Castillo, C.D., Jenkins, R., O’Toole, A.J., Seeing through Disguise: Getting to Know You with a Deep Convolutional Neural Network (2021) Cognition, 211, p. 104611. , https://doi.org/10.1016/J.COGNI-TION.2021.104611; Dhamecha, T.I., Nigam, A., Singh, R., Vatsa, M., Disguise Detection and Face Recognition in Visible and Thermal Spectrums (2013) Proceedings of the 2013 International Conference on Biometrics (ICB), , Madrid, Spain, 4–7 June; Min, R., Kose, N., Dugelay, J.L., KinectfaceDB: A Kinect Database for Face Recognition (2014) IEEE Trans. Syst. Man Cybern. Syst, 44, pp. 1534-1548. , https://doi.org/10.1109/TSMC.2014.2331215; Dhamecha, T.I., Singh, R., Vatsa, M., Kumar, A., Recognizing Disguised Faces: Human and Machine Evaluation (2014) PLoS ONE, 9, p. e99212. , https://doi.org/10.1371/JOURNAL.PONE.0099212; Zhang, S., Liu, A., Wan, J., Liang, Y., Guo, G., Escalera, S., Escalante, H.J., Li, S.Z., CASIA-SURF: A Large-Scale Multi-Modal Benchmark for Face Anti-Spoofing (2020) IEEE Trans. Biom. Behav. Identity Sci, 2, pp. 182-193. , https://doi.org/10.1109/tbiom.2020.2973001; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative Adversarial Networks (2020) Commun. ACM, 63, pp. 139-144. , https://doi.org/10.1145/3422622; Khaldi, Y., Benzaoui, A., Region of Interest Synthesis Using Image-to-Image Translation for Ear Recognition (2020) Proceedings of the 2020 4th International Conference on Advanced Aspects of Software Engineering (ICAASE), , Constantine, Algeria, 28–30 November; Khan, A., Jin, W., Haider, A., Rahman, M., Wang, D., Adversarial Gaussian Denoiser for Multiple-Level Image Denoising (2021) Sensors, 21, p. 2998. , https://doi.org/10.3390/s21092998; Khaldi, Y., Benzaoui, A., A New Framework for Grayscale Ear Images Recognition Using Generative Adversarial Networks under Unconstrained Conditions (2020) Evol. Syst, 12, pp. 923-934. , https://doi.org/10.1007/s12530-020-09346-1; Zhu, J.-Y., Park, T., Isola, P., Efros, A.A., Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks (2017) Proceedings of the IEEE International Conference on Computer Vision, pp. 2242-2251. , Venice, Italy, 22–29 October; Steiner, H., Kolb, A., Jung, N., Reliable Face Anti-Spoofing Using Multispectral SWIR Imaging (2016) Proceedings of the 2016 International Conference on Biometrics (ICB), , https://doi.org/10.1109/ICB.2016.7550052, Halmstad, Sweden, 13–16 June; Steiner, H., Sporrer, S., Kolb, A., Jung, N., Design of an Active Multispectral SWIR Camera System for Skin Detection and Face Verification (2016) J. Sens, 2016, p. 9682453. , https://doi.org/10.1155/2016/9682453; Raghavendra, R., Vetrekar, N., Raja, K.B., Gad, R.S., Busch, C., Detecting Disguise Attacks on Multi-Spectral Face Recognition Through Spectral Signatures (2018) Proceedings of the International Conference on Pattern Recognition, pp. 3371-3377. , https://doi.org/10.1109/ICPR.2018.8545076, Beijing, China, 20–24 August; Weyrauch, B., Heisele, B., Huang, J., Blanz, V., Component-Based Face Recognition with 3D Morphable Models (2004) Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, , https://doi.org/10.1109/CVPR.2004.315, Washington, DC, USA, 27 June–2 July; Paysan, P., Knothe, R., Amberg, B., Romdhani, S., Vetter, T., A 3D Face Model for Pose and Illumination Invariant Face Recog-nition (2009) Proceedings of the 6th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS), pp. 296-301. , https://doi.org/10.1109/AVSS.2009.58, Genova, Italy, 2–4 September; Dantcheva, A., Chen, C., Ross, A., Can Facial Cosmetics Affect the Matching Accuracy of Face Recognition Systems? (2012) Proceedings of the 2012 IEEE 5th International Conference on Biometrics: Theory, Applications and Systems (BTAS), pp. 391-398. , https://doi.org/10.1109/BTAS.2012.6374605, Arlington, VA, USA, 23–27 September; Phillips, P.J., Flynn, P.J., Scruggs, T., Bowyer, K.W., Chang, J., Hoffman, K., Marques, J., Worek, W., Overview of the Face Recognition Grand Challenge (2005) Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR), pp. 947-954. , https://doi.org/10.1109/CVPR.2005.268, San Diego, CA, USA, 20–25 June; Afifi, M., Abdelhamed, A., AFIF4: Deep Gender Classification Based on AdaBoost-Based Fusion of Isolated Facial Features and Foggy Faces (2019) J. Vis. Commun. Image Represent, 62, pp. 77-86. , https://doi.org/10.1016/J.JVCIR.2019.05.001; Isola, P., Zhu, J.Y., Zhou, T., Efros, A.A., Image-to-Image Translation with Conditional Adversarial Networks (2017) Proceedings of the 30th IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , Honolulu, HI, USA, 21–26 July; Ahmad, M., Abdullah, M., Moon, H., Yoo, S.J., Han, D., Image Classification Based on Automatic Neural Architecture Search Using Binary Crow Search Algorithm (2020) IEEE Access, 8, pp. 189891-189912. , https://doi.org/10.1109/ACCESS.2020.3031599; Subramanya, A., Pillai, V., Pirsiavash, H., Fooling Network Interpretation in Image Classification (2019) Proceedings of the IEEE International Conference on Computer Vision, , Seoul, Korea, 27 October–2 November; Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., Hochreiter, S., GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium (2017) Proceedings of the Advances in Neural Information Processing Systems, , Long Beach, CA, USA, 4–9 December; Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., Chen, X., Improved Techniques for Training GANs (2016) Proceedings of the Advances in Neural Information Processing Systems, , Barcelona, Spain, 5–10 December; Binkowski, M., Sutherland, D.J., Arbel, M., Gretton, A., Demystifying MMD GANs (2018) Proceedings of the 6th International Conference on Learning Representations (ICLR), , Vancouver, BC, Canada, 30 April–3 May; Kingma, D.P., Ba, J.L., Adam: A Method for Stochastic Optimization (2015) Proceedings of the 3rd International Conference on Learning Representations (ICLR), , San Diego, CA, USA, 7–9 May","Han, D.; Department of Computer Engineering, South Korea; 电子邮件: dihan@sejong.ac.kr",,,MDPI,,,,,22277390,,,,English,Mathematics,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85121573420
"Gupta D., Pal B.",57223692519;57197069959;,Vulnerability Analysis and Robust Training with Additive Noise for FGSM Attack on Transfer Learning-Based Brain Tumor Detection from MRI,2022,Lecture Notes on Data Engineering and Communications Technologies,95,,,103,114,,,10.1007/978-981-16-6636-0_9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120888941&doi=10.1007%2f978-981-16-6636-0_9&partnerID=40&md5=6ce405ce9dd5aeb178b15f79427e2a3e,"Rajshahi University of Engineering & Technology, Rajshahi, Bangladesh","Gupta, D., Rajshahi University of Engineering & Technology, Rajshahi, Bangladesh; Pal, B., Rajshahi University of Engineering & Technology, Rajshahi, Bangladesh","Deep learning-based high-precision computerized brain tumor diagnosis helps to obtain significant clinical features for proper treatment. Research also revealed that medical deep learning systems are easily compromised by several small imperceptible perturbation strategies and resultant adversarial attacks. Medical deep learning systems for brain MRI-based tumor classification has been unexplored for susceptibility to adversarial attack except some abstract description of the vulnerability. In this research, the vulnerability of a highly accurate pretrained deep learning model has been studied in presence of adversarial samples. The potential risk associated with this model has been illustrated in terms of performance drop for misclassification, correct classification, and visual perceptibility. It is found that a very small perturbation variation of 0.0001–0.0007 can cause the performance to drop from 97 to 82%. Finally, a Gaussian additive noise-based robustness improvement strategy has been presented to overcome the drop of correct classification probability criteria. The results has been validated with publicly available dataset. These findings can be useful to raise safety concerns and design more robust medical deep learning systems. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Adversarial attack; Brain tumor; Deep learning; FGSM; Robustness,Additive noise; Additives; Deep learning; Diagnosis; Drops; Magnetic resonance imaging; Medical imaging; Tumors; Adversarial attack; Brain tumors; Deep learning; FGSM; Performance; Robust trainings; Robustness; Transfer learning; Tumour detection; Vulnerability analysis; Brain,,,,,"Afshar, P., Mohammadi, A., Plataniotis, K.N., Brain tumor type classification via capsule networks. In: 2018 25th IEEE international conference on image processing (ICIP) (2018) IEEE, pp. 3129-3133. , pp; Cheng, G., Ji, H., Adversarial perturbation on MRI modalities in brain tumor segmentation (2020) IEEE Access, 8, pp. 206009-206015; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples. Arxiv, 1412, p. 6572; Havaei, M., Davy, A., Warde-Farley, D., Biard, A., Courville, A., Bengio, Y., Pal, C., Larochelle, H., Brain tumor segmentation with deep neural networks (2016) Cornell University Library. Arxiv, 3540 (2016), p. 1505; Kingma, D.P., (2014) Ba J (2014) Adam: A Method for Stochastic Optimization. Arxiv, 1412, p. 6980; Kotia, J., Kotwal, A., Bharti, R., Risk susceptibility of brain tumor classification to adversarial attacks (2019) International Conference on man–machine Interactions, pp. 181-187. , Springer, pp; Li, B., Chen, C., Wang, W., Carin, L., Certified adversarial robustness with additive noise (2019) Advances in Neural Information Processing Systems, 32. , https://proceedings.neurips.cc/paper/2019/file/335cd1b90bfa4ee70b39d08a4ae0cf2d-Paper.pdf, Wallach H, Larochelle H, Beygelzimer A, d’Alché-Buc F, Fox E, Garnett R, vol, Curran Associates, Inc; Li, Y., Zhang, H., Bermudez, C., Chen, Y., Landman, B.A., Vorobeychik, Y., Anatomical context protects deep learning from adversarial perturbations in medical imaging (2020) Neurocomputing, 379, pp. 370-378. , https://www.sciencedirect.com/science/article/pii/S0925231219315279; Ma, X., Niu, Y., Gu, L., Wang, Y., Zhao, Y., Bailey, J., Lu, F., Understanding adversarial attacks on deep learning based medical image analysis systems (2021) Pattern Recogn, 110; Noreen, N., Palaniappan, S., Qayyum, A., Ahmad, I., Imran, M., Shoaib, M., A deep learning model based on concatenation approach for the diagnosis of brain tumor (2020) IEEE Access, 8; Pereira, S., Pinto, A., Alves, V., Silva, C.A., Brain tumor segmentation using convolutional neural networks in MRI images (2016) IEEE Trans Med Imaging, 35 (5), pp. 1240-1251; Rathi, V.P., Palani, S., (2012) Brain Tumor MRI Image Classification with Feature Selection and Extraction Using Linear Discriminant Analysis. Arxiv, 1208, p. 2128; Sartaj, N., Chakrabarty, S.K., (2020) Brain Tumor Classification (MRI), , https://www.kaggle.com/sartajbhuvaji/brain-tumor-classification-mri/activity; Saxena, P., Maheshwari, A., Maheshwari, S., Predictive modeling of brain tumor: A deep learning approach (2019) Innovations in Computational Intelligence and Computer Vision, pp. 275-285. , Springer, pp; Seetha, J., Raja, S.S., Brain tumor classification using convolutional neural networks (2018) Biomed Pharmacol J, 11 (3), p. 1457; Stupp, R., Roila, F., Malignant glioma: ESMO clinical recommendations for diagnosis, treatment and follow-up (2009) Ann Oncol, 20, pp. 126-128. , Suppl. 4; Wang, S., Nepal, S., Rudolph, C., Grobler, M., (2020) Chen S, , Chen T, Backdoor attacks against transfer learning with pre-trained deep learning models. IEEE Trans Services Comput; Yuan, X., He, P., Zhu, Q., Li, X., Adversarial examples: Attacks and defenses for deep learning (2019) IEEE Trans Neural Netw Learn Syst, 30 (9), pp. 2805-2824","Pal, B.; Rajshahi University of Engineering & TechnologyBangladesh; 电子邮件: biprodip.cse@gmail.com",,,Springer Science and Business Media Deutschland GmbH,,,,,23674512,,,,English,Lecture. Notes. Data Eng. Commun. Tech.,Book Chapter,Final,,Scopus,2-s2.0-85120888941
"Zhang X., Wang J., Zhu S.",57192504236;57346877800;57347039100;,Dual Generative Adversarial Networks Based Unknown Encryption Ransomware Attack Detection,2022,IEEE Access,10,,,900,913,,,10.1109/ACCESS.2021.3128024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119457876&doi=10.1109%2fACCESS.2021.3128024&partnerID=40&md5=1821faf4f2f3e63a47c452e0b870f6d6,"East China University of Science and Technology, College of Information Science and Engineering, Shanghai, 200237, China","Zhang, X., East China University of Science and Technology, College of Information Science and Engineering, Shanghai, 200237, China; Wang, J., East China University of Science and Technology, College of Information Science and Engineering, Shanghai, 200237, China; Zhu, S., East China University of Science and Technology, College of Information Science and Engineering, Shanghai, 200237, China","Aiming at unknown or variant ransomware attack encrypted with SSL (Secure Sockets Layer)/ TLS (Transport Layer Security) protocol, a detection framework named TGAN-IDS (Transferred Generating Adversarial Network-Intrusion Detection System) based on dual generative adversarial networks is presented in this paper. In this framework, DCGAN (Deep Convolutional Generative Adversarial Network) is adopted to train a generator which has good performance to generate adversarial sample, and is transferred to the generator of TGAN. A pre-training model named PreD is built based on CNN (Convolutional Neural Network), which has good performance to do binary classification, and is transferred to the discriminator of TGAN. The generator and discriminator of TGAN play games in training process until the discriminator has a strong ability to detection unknown attack, and then it is output as an anomaly detector. In order to suppress the deterioration of normal sample detection ability during adversarial training of TGAN, a reconstruction loss function is introduced into the target function of TGAN. Experiments on a mixed dataset which is constructed by CICIDS2017 and other ransomware datasets show comparing with other deep learning network, such as AlexNet, ResNet and DenseNet etc., TGAN-IDS performs well in the indicators of detection accuracy, recall or F1-score etc. Also experiments on KDD99, SWaT and WADI datasets show that TGAN-IDS is suitable for other unencrypted unknown network attack detection. © 2021 IEEE Access. All rights reserved.",Anomaly detection; Generative adversarial networks; Generators; Intrusion detection; Protocols; Ransomware; Training,Convolution; Cryptography; Deep learning; Generative adversarial networks; Intrusion detection; Network security; Neural networks; Adversarial networks; Anomaly detection; Attack detection; Encrypted traffic; GAN; Network intrusion detection systems; Network-based; Performance; Secure sockets layers; Transfer learning; Malware,,,,,"Khalife, J., Hajjar, A., Diaz-Verdejo, J., A multilevel taxonomy and requirements for an optimal traffic-classification model (2014) Int. J. Netw. Manage., 24 (2), pp. 101-120. , Mar; Sherry, J., Lan, C., Popa, R.A., Ratnasamy, S., BlindBox: Deep packet inspection over encrypted traffic (2015) Proc. ACM Conf. Special Interest Group Data Commun., pp. 213-226. , Aug; Chen, L., Gao, S., Liu, B., Lu, Z., Jiang, Z., THS-IDPC: A three-stage hierarchical sampling method based on improved density peaks clustering algorithm for encrypted malicious traffic detection (2020) J. Supercomput., 76 (9), pp. 7489-7518. , Sep; Aceto, G., Ciuonzo, D., Montieri, A., Pescape, A., Mobile encrypted traffic classification using deep learning (2018) Proc. Netw. Traffic Meas. Anal. Conf. (TMA), pp. 1-8. , Jun; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Generative adversarial nets (2014) Proc. Adv. Neural Inf. Process. Syst., pp. 2672-2680; Lee, H., Han, S., Lee, J., (2017) Generative Adversarial Trainer: Defense to Adversarial Perturbations with GAN; Labonne, M., Olivereau, A., Polve, B., Zeghlache, D., Unsupervised protocol-based intrusion detection for real-world networks (2020) Proc. Int. Conf. Comput., Netw. Commun. (ICNC), pp. 299-303. , Feb; Roopak, M., Tian, G.Y., Chambers, J., Deep learning models for cyber security in IoT networks (2019) Proc. IEEE 9th Annu. Com-put. Commun. Workshop Conf. (CCWC), pp. 452-457. , Jan; Hindy, H., Atkinson, R., Tachtatzis, C., Colin, J.-N., Bayne, E., Bellekens, X., Utilising deep learning techniques for effective zero-day attack detection (2020) Electronics, 9 (10), p. 1684. , Oct; Salem, M., Taheri, S., Yuan, J.S., Anomaly generation using generative adversarial networks in host-based intrusion detection (2018) Proc. 9th IEEE Annu. Ubiquitous Comput., Electron. Mobile Commun. Conf. (UEMCON), pp. 683-687. , Nov; Yang, Y., Zheng, K., Wu, B., Yang, Y., Wang, X., Network intrusion detection based on supervised adversarial variational auto-encoder with regularization (2020) IEEE Access, 8, pp. 42169-42184; Li, D., Kotani, D., Okabe, Y., Improving attack detection performance in NIDS using GAN (2020) Proc. IEEE 44th Annu. Comput., Softw., Appl. Conf. (COMPSAC), pp. 817-825. , Jul; Huang, S., Lei, K., IGAN-IDS: An imbalanced generative adversarial network towards intrusion detection system in ad-hoc networks (2020) Ad Hoc Netw., 105. , Aug; Xiao, C., Li, B., Zhu, J.-Y., He, W., Liu, M., Song, D., Generating adversarial examples with adversarial networks (2018) Proc. 27th Int. Joint Conf. Artif. Intell., pp. 3905-3911. , Jul; Wang, Z., Wang, P., Zhou, X., Li, S., Zhang, M., FLOWGAN: Unbalanced network encrypted traffic identification method based on GAN (2019) Proc. IEEE Int. Conf. Parallel Distrib. Process. with Appl., Big Data Cloud Comput., Sustain. Comput. Commun., Social Comput. Netw. (ISPA/BDCloud/SocialCom/SustainCom), pp. 3905-3911. , Dec; Zhang, X., Zhou, Y., Pei, S., Zhuge, J., Chen, J., Adversarial examples detection for XSS attacks based on generative adversarial networks (2020) IEEE Access, 8, pp. 10989-10996; Zenati, H., Romain, M., Foo, C.-S., Lecouat, B., Chandrasekhar, V., Adversarially learned anomaly detection (2018) Proc. IEEE Int. Conf. Data Mining (ICDM), pp. 727-736. , Nov; Li, D., Chen, D., Jin, B., Shi, L., Goh, J., Ng, S.-K., MAD-GAN: Multivariate anomaly detection for time series data with generative adversarial networks (2019) Proc. Int. Conf. Artif. Neural Netw., pp. 703-716; De Araujo-Filho, P.F., Kaddoum, G., Campelo, D.R., Santos, A.G., Macedo, D., Zanchettin, C., Intrusion detection for cyber-physical systems using generative adversarial networks in fog environment (2021) IEEE Internet Things J., 8 (8), pp. 6247-6256. , Apr; Almashhadani, A.O., Kaiiali, M., Sezer, S., O'Kane, P., A multiclassi fier network-based crypto ransomware detection system: A case study of Locky ransomware (2019) IEEE Access, 7, pp. 47053-47067; Cabaj, K., Gregorczyk, M., Mazurczyk, W., Software-defined networking-based crypto ransomware detection using HTTP traffic characteristics (2018) Comput. Electr. Eng., 66, pp. 353-368. , Feb; Modi, J., Traore, I., Ghaleb, A., Ganame, K., Ahmed, S., Detecting ransomware in encrypted web traffic (2019) Proc. 12th Int. Symp. Found. Pract. Secur., (FPS), pp. 345-353; Radford, A., Metz, L., Chintala, S., Unsupervised representation learning with deep convolutional generative adversarial networks (2016) Proc. ICLR, pp. 97-108; Yamauchi, H., Nakao, A., Oguchi, M., Yamamoto, S., Yamaguchi, S., A study on service identification based on server name indication analysis (2019) Proc. 7th Int. Symp. Comput. Netw. Workshops (CANDARW), pp. 470-474. , Nov; Li, Y., Xiao, N., Ouyang, W., Improved generative adversarial networks with reconstruction loss (2019) Neurocomputing, 323, pp. 363-372. , Jan; http://www.malware-traffic-analysis.net; https://packettotal.com; https://app.any.run; Heusel, M., Ramsauer, H., Unterthiner, T., GANs trained by a two timescale update rule converge to a local nash equilibrium (2017) Proc. 31st Int. Conf. Neural Inf. Process. Syst., pp. 6629-6640; http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html; https://itrust.sutd.edu.sg/","Zhang, X.; East China University of Science and Technology, China; 电子邮件: zxq@ecust.edu.cn",,,Institute of Electrical and Electronics Engineers Inc.,,,,,21693536,,,,English,IEEE Access,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85119457876
"Xie P., Shi S., Yang S., Qiao K., Liang N., Wang L., Chen J., Hu G., Yan B.",57225707574;57224929858;57216501846;57188641013;57203978839;57225973684;57256011400;57382557700;35188444100;,Improving the Transferability of Adversarial Examples With a Noise Data Enhancement Framework and Random Erasing,2021,Frontiers in Neurorobotics,15,,784053,,,,,10.3389/fnbot.2021.784053,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121635140&doi=10.3389%2ffnbot.2021.784053&partnerID=40&md5=450b2c3accf1fd15610ef7e415d968e5,"Henan Key Laboratory of Imaging and Intelligent Processing, PLA Strategy Support Force Information Engineering University, Zhengzhou, China","Xie, P., Henan Key Laboratory of Imaging and Intelligent Processing, PLA Strategy Support Force Information Engineering University, Zhengzhou, China; Shi, S., Henan Key Laboratory of Imaging and Intelligent Processing, PLA Strategy Support Force Information Engineering University, Zhengzhou, China; Yang, S., Henan Key Laboratory of Imaging and Intelligent Processing, PLA Strategy Support Force Information Engineering University, Zhengzhou, China; Qiao, K., Henan Key Laboratory of Imaging and Intelligent Processing, PLA Strategy Support Force Information Engineering University, Zhengzhou, China; Liang, N., Henan Key Laboratory of Imaging and Intelligent Processing, PLA Strategy Support Force Information Engineering University, Zhengzhou, China; Wang, L., Henan Key Laboratory of Imaging and Intelligent Processing, PLA Strategy Support Force Information Engineering University, Zhengzhou, China; Chen, J., Henan Key Laboratory of Imaging and Intelligent Processing, PLA Strategy Support Force Information Engineering University, Zhengzhou, China; Hu, G., Henan Key Laboratory of Imaging and Intelligent Processing, PLA Strategy Support Force Information Engineering University, Zhengzhou, China; Yan, B., Henan Key Laboratory of Imaging and Intelligent Processing, PLA Strategy Support Force Information Engineering University, Zhengzhou, China","Deep neural networks (DNNs) are proven vulnerable to attack against adversarial examples. Black-box transfer attacks pose a massive threat to AI applications without accessing target models. At present, the most effective black-box attack methods mainly adopt data enhancement methods, such as input transformation. Previous data enhancement frameworks only work on input transformations that satisfy accuracy or loss invariance. However, it does not work for other transformations that do not meet the above conditions, such as the transformation which will lose information. To solve this problem, we propose a new noise data enhancement framework (NDEF), which only transforms adversarial perturbation to avoid the above issues effectively. In addition, we introduce random erasing under this framework to prevent the over-fitting of adversarial examples. Experimental results show that the black-box attack success rate of our method Random Erasing Iterative Fast Gradient Sign Method (REI-FGSM) is 4.2% higher than DI-FGSM in six models on average and 6.6% higher than DI-FGSM in three defense models. REI-FGSM can combine with other methods to achieve excellent performance. The attack performance of SI-FGSM can be improved by 22.9% on average when combined with REI-FGSM. Besides, our combined version with DI-TI-MI-FGSM, i.e., DI-TI-MI-REI-FGSM can achieve an average attack success rate of 97.0% against three ensemble adversarial training models, which is greater than the current gradient iterative attack method. We also introduce Gaussian blur to prove the compatibility of our framework. Copyright © 2021 Xie, Shi, Yang, Qiao, Liang, Wang, Chen, Hu and Yan.",adversarial examples; black-box attack; data enhancement; transfer-based attack; transferability,Iterative methods; Metadata; Adversarial example; Attack methods; Black boxes; Black-box attack; Data enhancement; Enhancement framework; Input transformation; Noise data; Transfer-based attack; Transferability; Deep neural networks; article; noise,,,,,"Behzadan, V., Munir, A., Vulnerability of deep reinforcement learning to policy induction attacks (2017) International Conference on Machine Learning and Data Mining in Pattern Recognition, pp. 262-275. , Cham, Springer; Bochkovskiy, A., Wang, C.-Y., Liao, H.Y.M., Yolov4: Optimal speed and accuracy of object detection (2020) arXiv [Preprint] arXiv:2004.10934, , 34300543; Bojarski, M., Del Testa, D., Dworakowski, D., Firner, B., Flepp, B., Goyal, P., End to end learning for self-driving cars (2016) arXiv [Preprint] arXiv:1604.07316, , 30325645; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) arXiv [Preprint] arXiv: 1608.04644, , 27295638; Carlini, N., Wagner, D., Audio adversarial examples: Targeted attacks on speech-to-text (2018) 2018 IEEE Security and Privacy Workshops (SPW), pp. 1-7. , San Francisco, CA, IEEE; Dai, H., Li, H., Tian, T., Huang, X., Wang, L., Zhu, J., Adversarial attack on graph structured data (2018) International Conference on Machine Learning, pp. 1115-1124. , Stockholm, PMLR; Deng, J., Guo, J., Xue, N., Zafeiriou, S., Arcface: Additive angular margin loss for deep face recognition (2019) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 4690-4699. , Long Beach, CA, IEEE, 34106845; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Boosting adversarial attacks with momentum (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 9185-9193. , Salt Lake City, UT, IEEE; Dong, Y., Pang, T., Su, H., Zhu, J., Evading defenses to transferable adversarial examples by translation-invariant attacks (2019) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 4312-4321. , IEEE; Fischer, M., Baader, M., Vechev, M., Certified defense to image transformations via randomized smoothing (2020) arXiv [Preprint] arXiv:2002.12463; Gao, L., Cheng, Y., Zhang, Q., Xu, X., Song, J., Feature space targeted attacks by statistic alignment (2021) Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, pp. 671-677. , Montreal, Canada. International Joint Conferences on Artificial Intelligence Organization; Gao, L., Zhang, Q., Song, J., Liu, X., Shen, H.T., Patch-wise attack for fooling deep neural network (2020) European Conference on Computer Vision, pp. 307-322. , Cham, Springer; Gedraite, E.S., Hadad, M., Investigation on the effect of a gaussian blur in image filtering and segmentation (2011) In Proceedings ELMAR-2011, pp. 393-396. , IEEE, pages; Gehring, J., Auli, M., Grangier, D., Yarats, D., Dauphin, Y.N., Convolutional sequence to sequence learning (2017) International Conference on Machine Learning, pp. 1243-1252. , PMLR; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) arXiv [Preprint] arXiv: 1412.6572; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778. , Las Vegas, NV, IEEE, 32166560; Inkawhich, N., Liang, K.J., Carin, L., Chen, Y., Transferable perturbations of deep feature distributions (2020) arXiv [preprint]; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2016) arXiv [preprint]; Li, Y., Bai, S., Zhou, Y., Xie, C., Zhang, Z., Yuille, A., Learning transferable adversarial examples via ghost networks (2020) Proceedings of the AAAI Conference on Artificial Intelligence, Vol, 34, pp. 11458-11465. , in; Lin, J., Song, C., He, K., Wang, L., Hopcroft, J.E., Nesterov accelerated gradient and scale invariance for adversarial attacks (2019) arXiv [Preprint] arXiv:1908.06281; Liu, W., Li, Z., Enhancing adversarial examples with flip-invariance and brightness-invariance (2020) International Conference on Security and Privacy in Digital Economy, pp. 469-481. , Quzhou, Springer; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) arXiv[Preprint] arXiv: 1611.02770; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2019) arXiv [Preprint] arXiv: 1706.06083; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: a simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582. , Las Vegas, NV, IEEE; Papernot, N., McDaniel, P., Goodfellow, I., Transferability in machine learning: from phenomena to black-box attacks using adversarial samples (2016) arXiv [Preprint] arXiv:1605.07277; Raghunathan, A., Steinhardt, J., Liang, P., Certified defenses against adversarial examples (2018) arXiv [Preprint] arXiv:1801.09344; Redmon, J., Farhadi, A., Yolov3: An incremental improvement (2018) arXiv arXiv [Preprint] arXiv:1801.09344; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A., Inception-v4, inception-resnet and the impact of residual connections on learning (2017) Proceedings of the AAAI Conference on Artificial Intelligence, Vo, p. 31. , in; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826. , Las Vegas, NV, IEEE; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Intriguing properties of neural networks (2013) arXiv [Preprint] arXiv:1312.6199; Tramér, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., Ensemble adversarial training: attacks and defenses (2017) arXiv [Preprint] arXiv:1705.07204; Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Attention is all you need (2017) In Advances in neural information processing systems, pages, pp. 5998-6008; Wang, X., He, K., Enhancing the transferability of adversarial attacks through variance tuning (2021) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 1924-1933. , IEEE; Wang, X., He, X., Wang, J., He, K., Admix: enhancing the transferability of adversarial attacks (2021) arXiv [Preprint] arXiv: 2102.00436, , a, 27295638; Wang, Z., Guo, H., Zhang, Z., Liu, W., Qin, Z., Ren, K., Feature importance-aware transferable adversarial attacks (2021) arXiv [Preprint] arXiv: 2107.14185, , b; Wu, D., Wang, Y., Xia, S.-T., Bailey, J., Ma, X., Skip connections matter: on the transferability of adversarial examples generated with resnets (2020) arXiv [Preprint] arXiv: 2002.05990, , a; Wu, L., Zhu, Z., Tai, C., Understanding and enhancing the transferability of adversarial examples (2018) arXiv [Preprint] arXiv:1802.09707, , others; Wu, W., Su, Y., Chen, X., Zhao, S., King, I., Lyu, M.R., Boosting the transferability of adversarial samples via attention (2020) 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1158-1167. , b, Seattle, WA, IEEE; Wu, W., Su, Y., Lyu, M.R., King, I., Improving the transferability of adversarial samples with adversarial transformations (2021) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 9024-9033. , in; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., Mitigating adversarial effects through randomization (2017) arXiv [Preprint] arXiv:1711.01991; Xie, C., Zhang, Z., Zhou, Y., Bai, S., Wang, J., Ren, Z., Improving transferability of adversarial examples with input diversity (2019) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 2730-2739. , in; Xie, P., Wang, L., Qin, R., Qiao, K., Shi, S., Hu, G., Improving the transferability of adversarial examples with new iteration framework and input dropout (2021) arXiv [Preprint] arXiv:2106.01617; Zhong, Z., Zheng, L., Kang, G., Li, S., Yang, Y., Random erasing data augmentation (2020) Proc. AAAI Conf. Artif. Intell, 34, pp. 13001-13008; Zou, J., Pan, Z., Qiu, J., Liu, X., Rui, T., Li, W., Improving the transferability of adversarial examples with resized-diverse-inputs, diversity-ensemble and region fitting (2020) Computer Vision – ECCV 2020, 12367, pp. 563-579. , Vedaldi A., Bischof H., Brox T., Frahm J.-M., (eds), Cham, Springer International Publishing,., eds","Yan, B.; Henan Key Laboratory of Imaging and Intelligent Processing, China; 电子邮件: ybspace@hotmail.com",,,Frontiers Media S.A.,,,,,16625218,,,,English,Front. Neurorobotics,Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85121635140
"Hu H., Pang J.",57198978159;23390311500;,Stealing Machine Learning Models: Attacks and Countermeasures for Generative Adversarial Networks,2021,ACM International Conference Proceeding Series,,,,1,16,,,10.1145/3485832.3485838,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121606290&doi=10.1145%2f3485832.3485838&partnerID=40&md5=d96a054b32bbab2999ba1cf4fe18a10d,"SnT, University of Luxembourg, Esch-sur-Alzette, Luxembourg; FSTM, SnT, University of Luxembourg, Esch-sur-Alzette, Luxembourg","Hu, H., SnT, University of Luxembourg, Esch-sur-Alzette, Luxembourg; Pang, J., FSTM, SnT, University of Luxembourg, Esch-sur-Alzette, Luxembourg","Model extraction attacks aim to duplicate a machine learning model through query access to a target model. Early studies mainly focus on discriminative models. Despite the success, model extraction attacks against generative models are less well explored. In this paper, we systematically study the feasibility of model extraction attacks against generative adversarial networks (GANs). Specifically, we first define fidelity and accuracy on model extraction attacks against GANs. Then we study model extraction attacks against GANs from the perspective of fidelity extraction and accuracy extraction, according to the adversary's goals and background knowledge. We further conduct a case study where the adversary can transfer knowledge of the extracted model which steals a state-of-the-art GAN trained with more than 3 million images to new domains to broaden the scope of applications of model extraction attacks. Finally, we propose effective defense techniques to safeguard GANs, considering a trade-off between the utility and security of GAN models. © 2021 Copyright held by the owner/author(s).",Generative adversarial networks; Model extraction; Perturbation-based defenses; Transfer learning,Economic and social effects; Extraction; Network security; Background knowledge; Case-studies; Discriminative models; Generative model; Machine learning models; Model extraction; Perturbation-based defense; Success models; Target model; Transfer learning; Generative adversarial networks,,,,,"Abadi, M., Chu, A., Goodfellow, I., McMahan, H.B., Mironov, I., Talwar, K., Zhang, L., Deep Learning with Differential Privacy (2016) ProceedingsofACMSIGSACConferenceonComputerandCommunicationsSecurity (CCS), pp. 308-318; Agustsson, E., Sage, A., Timofte, R., van Gool, L., Optimal Transport Maps for Distribution Preserving Operations on Latent Spaces of Generative Models (2019) Proceedings of International Conference on Learning Representations (ICLR); Azadi, S., Olsson, C., Darrell, T., Goodfellow, I., Odena, A., Discriminator Rejection Sampling (2019) Proceedings of International Conference on Learning Representations (ICLR); Bahri, Y., Kadmon, J., Pennington, J., Schoenholz, S.S., Sohl-Dickstein, J., Ganguli, S., Statistical Mechanics of Deep Learning (2020) Annual Review of Condensed Matter Physics, 11 (1), pp. 501-528. , 2020; Bau, D., Zhu, J.-Y., Wulff, J., Peebles, W., Strobelt, H., Zhou, B., Torralba, A., Seeing What a Gan Cannot Generate (2019) Proceedings of IEEE International Conference on Computer Vision (ICCV), pp. 4502-4511; Brock, A., Donahue, J., Simonyan, K., Large Scale GaN Training for High Fidelity Natural Image Synthesis (2019) Proceedings of International Conference on Learning Representations (ICLR); Brown, T.B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Askell, A., (2020) Language Models Are Few-Shot Learners, , arXiv preprint; Cao, X., Jia, J., Gong, N.Z., IPGuard: Protecting Intellectual Property of Deep Neural Networks via Fingerprinting the Classification Boundary (2021) Proceedings of ACM Asia Conference on Computer and Communications Security (ASIA CCS), pp. 14-25; Carlini, N., Jagielski, M., Mironov, I., Cryptanalytic Extraction of Neural Network Models (2020) Proceedings of Annual International Cryptology Conference (CRYPTO), , Springer; Carlini, N., Tramer, F., Wallace, E., Jagielski, M., Herbert-Voss, A., Lee, K., Roberts, A., Erlingsson, U., Extracting Training Data from Large Language Models (2021) Proceedings of USENIX Security Symposium (USENIX Security), pp. 2633-2650. , USENIX Association; Carlini, N., Wagner, D., Towards Evaluating the Robustness of Neural Networks (2017) Proceedings of IEEE Symposium on Security and Privacy (S&P), pp. 39-57; Chandrasekaran, V., Chaudhuri, K., Giacomelli, I., Jha, S., Yan, S., Exploring Connections between Active Learning and Model Extraction (2020) Proceedings of USENIX Security Symposium (USENIX Security), , USENIX Association; Chen, D., Yu, N., Zhang, Y., Fritz, M., Gan-leaks: A Taxonomy of Membership Inference Attacks against Generative Models (2020) Proceedings of ACM SIGSAC Conference on Computer and Communications Security (CCS), pp. 343-362; Chen, K., Guo, S., Zhang, T., Xie, X., Liu, Y., Stealing Deep Reinforcement Learning Models for Fun and Profit (2021) Proceedings of ACM Asia Conference on Computer and Communications Security (ASIA CCS), pp. 307-319; Devlin, J., Chang, M.-W., Lee, K., Toutanova, K., (2018) BERT: Pre-Training of Deep Bidirectional Transformers for Language Understanding, , arXiv preprint 2018; Ding, X., Wang, Z.J., Welch, W.J., Subsampling Generative Adversarial Networks: Density Ratio Estimation in Feature Space with Softplus Loss (2020) IEEE Transactions on Signal Processing, 68 (2020), pp. 1910-1922; (2020) Simplejpeg 1.4.0, , https://gitlab.com/jfolz/simplejpeg; Ganju, K., Wang, Q., Yang, W., Gunter, C.A., Borisov, N., Property Inference Attacks on fully connected neural networks using permutation invariant representations (2018) Proceedings of ACM SIGSAC Conference on Computer and Communications Security (CCS), pp. 619-633; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative Adversarial Nets (2014) Proceedings of Annual Conference on Neural Information Processing Systems (NeurIPS), pp. 2672-2680. , Curran Associates, Inc; Hayes, J., Melis, L., Danezis, G., de Cristofaro, E., Logan: Membership Inference Attacks against Generative Models (2019) Proceedings on Privacy Enhancing Technologies, 2019, pp. 133-152. , Sciendo; He, K., Zhang, X., Ren, S., Sun, J., Deep Residual Learning for Image Recognition (2016) Proceedings of IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 770-778; He, Y., Meng, G., Chen, K., Hu, X., He, J., (2019) Towards Privacy and Security of Deep Learning Systems: A Survey, , arXiv preprint 2019; Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., Hochreiter, S., Gans Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium (2017) Proceedings of Annual Conference on Neural Information Processing Systems (NeurIPS), pp. 6626-6637. , Curran Associates, Inc; Hilprecht, B., Härterich, M., Bernau, D., Monte Carlo and Reconstruction Membership Inference Attacks against Generative Models (2019) Proceedings on Privacy Enhancing Technologies, 2019, pp. 232-249. , Sciendo; Huang, X., Belongie, S., Arbitrary Style Transfer in Real-Time with Adaptive Instance Normalization (2017) Proceedings of IEEE International Conference on Computer Vision (ICCV), pp. 1501-1510; Huang, X., Li, Y., Poursaeed, O., Hopcroft, J., Belongie, S., Stacked Generative Adversarial Networks (2017) Proceedings of IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 5077-5086; Jagielski, M., Carlini, N., Berthelot, D., Kurakin, A., Papernot, N., High Accuracy and High Fidelity Extraction of Neural Networks (2020) Proceedings of USENIX Security Symposium (USENIX Security), , USENIX Association; Ji, S., Li, W., Gong, N.Z., Mittal, P., Beyah, R.A., On Your Social Network De-Anonymizablity: Quantification and Large Scale Evaluation with Seed Knowledge (2015) Proceedings of Network and Distributed Systems Security Symposium (NDSS), , Internet Society; Jia, H., Choquette-Choo, C.A., Chandrasekaran, V., Papernot, N., Entangled Watermarks as a Defense against Model Extraction (2021) Proceedings of USENIX Security Symposium (USENIX Security), pp. 1937-1954. , USENIX Association; Juuti, M., Szyller, S., Marchal, S., Asokan, N., Prada: Protecting against DNN Model Stealing Attacks (2019) Proceedings of IEEE European Symposium on Security and Privacy (Euro S&P), pp. 512-527; Karras, T., Aila, T., Laine, S., Lehtinen, J., Progressive Growing of GANs for Improved Quality, Stability, and Variation (2018) Proceedings of International Conference on Learning Representations (ICLR); Karras, T., Laine, S., Aila, T., A Style-Based Generator Architecture for Generative Adversarial Networks (2019) Proceedings of IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4401-4410; Karras, T., Laine, S., Aittala, M., Hellsten, J., Lehtinen, J., Aila, T., Analyzing and Improving the Image Quality of Stylegan (2020) Proceedings of IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 8110-8119; Krishna, K., Tomar, G.S., Parikh, A.P., Papernot, N., Iyyer, M., Thieves on Sesame Street! Model Extraction of BERT-based APIs (2020) Proceedings of International Conference on Learning Representations (ICLR); Lee, J., Yoon, W., Kim, S., Kim, D., Kim, S., So, C.H., Kang, J., Biobert: A Pre-Trained Biomedical Language Representation Model for Biomedical Text Mining (2020) Bioinformatics, 36 (4), pp. 1234-1240. , 2020; Lee, T., Edwards, B., Molloy, I., Su, D., Defending against Model Stealing Attacks using Deceptive Perturbations (2019) Proceedings of IEEE Security and Privacy Workshops, pp. 43-49; Li, C., Wand, M., Precomputed Real-Time Texture Synthesis with Markovian Generative Adversarial Networks (2016) Proceedings of European Conference on Computer Vision (ECCV), pp. 702-716. , Springer; Li, H., Wenger, E., Zhao, B.Y., Zheng, H., (2019) Piracy Resistant Watermarks for Deep Neural Networks, , arXiv preprint 2019; Lin, C.H., Chang, C.-C., Chen, Y.-S., Juan, D.-C., Wei, W., Chen, H.-T., Coco-GaN: Generation by Parts via Conditional Coordinating (2019) Proceedings of IEEE International Conference on Computer Vision (ICCV), pp. 4512-4521; Liu, M.-Y., Huang, X., Mallya, A., Karras, T., Aila, T., Lehtinen, J., Kautz, J., Few-Shot Unsupervised Image-to-Image Translation (2019) Proceedings of IEEE International Conference on Computer Vision (ICCV), pp. 10551-10560; Liu, Z., Luo, P., Wang, X., Tang, X., Deep Learning Face Attributes in the Wild (2015) Proceedings of IEEE International Conference on Computer Vision (ICCV), pp. 3730-3738; Lowd, D., Meek, C., Adversarial Learning (2005) Proceedings of ACM SIGKDD International Conference on Knowledge Discovery in Data Mining (KDD), pp. 641-647; Lučić, M., Tschannen, M., Ritter, M., Zhai, X., Bachem, O., Gelly, S., High-Fidelity Image Generation with Fewer Labels (2019) Proceedings of International Conference on Machine Learning (ICML), pp. 4183-4192; Mahajan, D., Girshick, R., Ramanathan, V., He, K., Paluri, M., Li, Y., Bharambe, A., van der Maaten, L., Exploring the Limits of Weakly Supervised Pretraining (2018) Proceedings of European Conference on Computer Vision (ECCV), pp. 181-196. , Springer; Milli, S., Schmidt, L., Dragan, A.D., Hardt, M., Model Reconstruction from Model Explanations (2019) Proceedings of Conference on Fairness, Accountability, and Transparency, pp. 1-9; Mittal, A., Soundararajan, R., Bovik, A.C., Making a “Completely Blind” Image Quality Analyzer (2012) IEEE Signal Processing Letters, 20 (3), pp. 209-212. , 2012; Miyato, T., Kataoka, T., Koyama, M., Yoshida, Y., Spectral Normalization for Generative Adversarial Networks (2018) Proceedings of International Conference on Learning Representations (ICLR); Odena, A., Olah, C., Shlens, J., Conditional Image Synthesis with Auxiliary Classifier GANs (2017) Proceedings of International Conference on Machine Learning (ICML), pp. 2642-2651; Orekondy, T., Schiele, B., Fritz, M., Knockoff Nets: Stealing Functionality of Black-Box Models (2019) Proceedings of IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4954-4963; Pal, S., Gupta, Y., Shukla, A., Kanade, A., Shevade, S., Ganapathy, V., Activethief: Model Extraction Using Active Learning and Unannotated Public Data (2020) Proceedings of AAAI Conference on Artificial Intelligence (AAAI), 34, pp. 865-872; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical Black-Box Attacks against Machine Learning (2017) Proceedings of ACM on Asia Conference on Computer and Communications Security (ASIA CCS), pp. 506-519; Park, T., Liu, M.-Y., Wang, T.-C., Zhu, J.-Y., Semantic Image Synthesis with Spatially-Adaptive Normalization (2019) Proceedings of IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2337-2346; Radford, A., Metz, L., Chintala, S., Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks (2016) Proceedings of International Conference on Learning Representations (ICLR); Richardson, E., Weiss, Y., On Gans and Gmms (2018) Proceedings of Advances in Neural Information Processing Systems (NeurIPS), 31, pp. 5847-5858. , Curran Associates, Inc; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Fei-Fei, L., ImageNet Large Scale Visual Recognition Challenge (2015) International Journal of Computer Vision, 115 (3), pp. 211-252. , 2015; Salem, A., Zhang, Y., Humbert, M., Berrang, P., Fritz, M., Backes, M., ML-Leaks: Model and Data Independent Membership Inference Attacks and Defenses on Machine Learning Models (2019) Proceedings of Network and Distributed Systems Security Symposium (NDSS), , Internet Society; Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., Chen, X., Improved Techniques for Training GANs (2016) Proceedings of Annual Conference on Neural Information Processing Systems (NeurIPS), pp. 2234-2242. , Curran Associates, Inc; Shen, Y., Gu, J., Tang, X., Zhou, B., Interpreting the Latent Space of Gans for Semantic Face Editing (2020) Proceedings of IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 9243-9252; Shokri, R., Strobel, M., Zick, Y., (2019) Privacy Risks of Explaining Machine Learning Models, , arXiv preprint 2019; Shokri, R., Stronati, M., Song, C., Shmatikov, V., Membership Inference Attacks against Machine Learning Models (2017) Proceedings of IEEE Symposium on Security and Privacy (S&P), pp. 3-18; Takemura, T., Yanai, N., Fujiwara, T., (2020) Model Extraction Attacks against Recurrent Neural Networks, , arXiv preprint 2020; Tierney, L., Markov Chains for Exploring Posterior Distributions (1994) The Annals of Statistics, pp. 1701-1728. , 1994; Touvron, H., Vedaldi, A., Douze, M., Jégou, H., Fixing the train-test resolution discrepancy (2019) Proceedings of Annual Conference on Neural Information Processing Systems (NeurIPS), pp. 8250-8260. , Curran Associates, Inc; Tramèr, F., Zhang, F., Juels, A., Reiter, M.K., Ristenpart, T., Stealing machine learning models via prediction APIs (2016) Proceedings of USENIX Security Symposium (USENIX Security), pp. 601-618. , USENIX Association; Turner, R., Hung, J., Frank, E., Saatchi, Y., Yosinski, J., Metropolis-hastings generative adversarial networks (2019) Proceedings of International Conference on Machine Learning (ICML), pp. 6345-6353; van der Walt, S., Schönberger, J.L., Nunez-Iglesias, J., Boulogne, F., Warner, J.D., Yager, N., Gouillart, E., Yu, T., The scikit-image contributors, Scikit-image: Image processing in Python (2014) PeerJ, 2 (6). , 2014; Venkatanath, N., Praneeth, D., Bh, M.C., Channappayya, S.S., Medasani, S.S., Blind image quality evaluation using perception based features (2015) 2015 Twenty First National Conference on Communications, pp. 1-6; Wang, B., Gong, N.Z., Stealing hyperparameters in machine learning (2018) Proceedings of IEEE Symposium on Security and Privacy (S&P), pp. 36-52; Xian, W., Sangkloy, P., Agrawal, V., Raj, A., Lu, J., Fang, C., Yu, F., Hays, J., Texturegan: Controlling deep image synthesis with texture patches (2018) Proceedings of IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 8456-8465; Xudong, P., Mi, Z., Shouling, J., Min, Y., Privacy risks of general-purpose language models (2020) Proceedings of IEEE Symposium on Security and Privacy (S&P), pp. 1471-1488; Yu, F., Seff, A., Zhang, Y., Song, S., Funkhouser, T., Xiao, J., (2015) LSUN: Construction of a Large-Scale Image Dataset Using Deep Learning with Humans in the Loop, , arXiv preprint 2015; Zhang, H., Xu, T., Li, H., Zhang, S., Wang, X., Huang, X., Metaxas, D.N., Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks (2017) Proceedings of IEEE International Conference on Computer Vision (ICCV), pp. 5907-5915; Zhu, J.-Y., Krähenbühl, P., Shechtman, E., Efros, A.A., Generative visual manipulation on the natural image manifold (2016) Proceedings of European Conference on Computer Vision (ECCV), pp. 597-613. , Springer",,,Applied Computer Security Associates (ACSA),Association for Computing Machinery,"37th Annual Computer Security Applications Conference, ACSAC 2021",6 December 2021 through 10 December 2021,,175315,,9.78E+12,,,English,ACM Int. Conf. Proc. Ser.,Conference Paper,Final,"All Open Access, Bronze",Scopus,2-s2.0-85121606290
"Marrone S., Sansone C.",57203106891;7004587033;,On the transferability of adversarial perturbation attacks against fingerprint based authentication systems,2021,Pattern Recognition Letters,152,,,253,259,,,10.1016/j.patrec.2021.10.015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118510545&doi=10.1016%2fj.patrec.2021.10.015&partnerID=40&md5=a7c6a8c18a7b9c39cf04626148ea0556,"DIETI - University of Naples Federico II, Via Claudio 21, Napoli, 80125, Italy","Marrone, S., DIETI - University of Naples Federico II, Via Claudio 21, Napoli, 80125, Italy; Sansone, C., DIETI - University of Naples Federico II, Via Claudio 21, Napoli, 80125, Italy","The growing availability of cheap and reliable fingerprint acquisition scanners is resulting in an increasing spread of Fingerprint-based Authentication Systems (FAS) in consumer electronics. This has giving rise to a new wave in research on both smarter spoofing attacks, aimed to bypass a FAS by using a counterfeit fingerprint, and on more effective Liveness Detectors (LD), aimed to discern authentic (live) fingerprints from fake ones. As in many other computer vision tasks, deep Convolutional Neural Networks (CNN) demonstrated to be very effective also for fingerprint liveness detection. However, we showed that it is possible to adapt adversarial perturbation approaches to mislead CNN-based LD. In this paper, we want to make a step further toward the design of a black-box attack by investigating whether it is possible to transfer a perturbation across different CNN liveness detectors in the case of a target LD very different from the one used to compute the perturbations. To this aim, we designed an attack scenario where a shadow LD (i.e. an adaptation of the substitute technique for the liveness detection application) is used to generate an adversarial fingerprint in a white-box setting before submitting it to the real target LD, invoked in a total back-box manner. Finally, we analysed the impact that such attack has on the authentication system, also analysing if and to what extent the scanner and the spoofing material combinations affect the success of the attack. © 2021 Elsevier B.V.",,Authentication; Convolution; Convolutional neural networks; Deep neural networks; Palmprint recognition; Attacks scenarios; Authentication systems; Black boxes; Convolutional neural network; Fingerprint acquisition; Fingerprint liveness detection; Liveness; Network-based; Perturbation approach; Spoofing attacks; Scanning,,,,,"Akhtar, Z., Micheloni, C., Foresti, G.L., Biometric liveness detection: challenges and research opportunities (2015) IEEE Secur. Privacy, 13 (5), pp. 63-72; Ghiani, L., Yambay, D.A., Mura, V., Marcialis, G.L., Roli, F., Schuckers, S.A., Review of the fingerprint liveness detection (LivDet) competition series: 2009 to 2015 (2017) Image Vis. Comput., 58, pp. 110-128; Chugh, T., Cao, K., Jain, A.K., Fingerprint spoof buster: use of minutiae-centered patches (2018) IEEE Trans. Inf. Forensics Secur., 13 (9), pp. 2190-2202; Marrone, S., Sansone, C., Adversarial perturbations against fingerprint based authentication systems (2019) IEEE International Conference on Biometrics (ICB), pp. 1-6; Papernot, N., McDaniel, P., Goodfellow, I., (2016), Transferability in machine learning: from phenomena to black-box attacks using adversarial samples; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013), Intriguing properties of neural networks; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014), Explaining and harnessing adversarial examples; Kurakin, A., Goodfellow, I., Bengio, S., (2016), Adversarial examples in the physical world; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., DeepFool: a simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Dong, Y., Liao, F., Pang, T., Su, H., Hu, X., Li, J., Zhu, J., (2017), Boosting adversarial attacks with momentum. arxiv preprint; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP), pp. 39-57. , IEEE; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) 2016 IEEE European Symposium on Security and Privacy (EuroS&P), pp. 372-387. , IEEE; Su, J., Vargas, D.V., Kouichi, S., (2017), One pixel attack for fooling deep neural networks; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017), Towards deep learning models resistant to adversarial attacks; Milton, M.A.A., (2018), Evaluation of momentum diverse input iterative fast gradient sign method (M-DI2-FGSM) based attack method on MCS 2018 adversarial attacks on black box face recognition system; Xie, C., Zhang, Z., Zhou, Y., Bai, S., Wang, J., Ren, Z., Yuille, A.L., Improving transferability of adversarial examples with input diversity (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2730-2739; Li, M., Deng, C., Li, T., Yan, J., Gao, X., Huang, H., Towards transferable targeted attack (2020) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 641-649; Al-Ajlan, A., Survey on fingerprint liveness detection (2013) 2013 International Workshop on Biometrics and Forensics (IWBF), pp. 1-5. , IEEE; Marcialis, G.L., Roli, F., Liveness detection competition 2009 (2009) Biom. Technol. Today, 17 (3), pp. 7-9; Mura, V., Ghiani, L., Marcialis, G.L., Roli, F., Yambay, D.A., Schuckers, S.A., Livdet 2015 fingerprint liveness detection competition 2015 (2015) 2015 IEEE 7th International Conference on Biometrics Theory, Applications and Systems (BTAS), pp. 1-6. , IEEE; Gragnaniello, D., Poggi, G., Sansone, C., Verdoliva, L., Local contrast phase descriptor for fingerprint liveness detection (2015) Pattern Recognit., 48 (4), pp. 1050-1058; Simonyan, K., Zisserman, A., (2014), Very deep convolutional networks for large-scale image recognition; Nogueira, R.F., de Alencar Lotufo, R., Machado, R.C., Fingerprint liveness detection using convolutional neural networks (2016) IEEE Trans. Inf. Forensics Secur., 11 (6), pp. 1206-1213; Raghavendra, R., Venkatesh, S., Raja, K.B., Busch, C., Transferable deep convolutional neural network features for fingervein presentation attack detection (2017) 2017 5th International Workshop on Biometrics and Forensics (IWBF), pp. 1-5. , IEEE; Hoffman, S., Sharma, R., Ross, A., Convolutional neural networks for iris presentation attack detection: toward cross-dataset and cross-sensor generalization (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, pp. 1620-1628; Ghiani, L., Marcialis, G.L., Roli, F., Fingerprint liveness detection by local phase quantization (2012) Pattern Recognition (ICPR), 2012 21st International Conference on, pp. 537-540. , IEEE; Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H., (2017), Mobilenets: efficient convolutional neural networks for mobile vision applications; Joshua, A., Paul, K., Junbin, G., Fingerprint matching using a hybrid shape and orientation descriptor (2011) State of the art in Biometrics, ISBN, pp. 953-978; Evans, N., Handbook of Biometric Anti-Spoofing: Presentation Attack Detection (2019), Springer","Marrone, S.; DIETI - University of Naples Federico II, Via Claudio 21, Italy; 电子邮件: stefano.marrone@unina.it",,,Elsevier B.V.,,,,,1678655,,,,English,Pattern Recogn. Lett.,Article,Final,,Scopus,2-s2.0-85118510545
"Kanwal S., Shah J.H., Khan M.A., Nisa M., Kadry S., Sharif M., Yasmin M., Maheswari M.",57216956017;55337133500;57200036013;57218281569;55906598300;26422599200;55243255400;57214525631;,Person re-identification using adversarial haze attack and defense: A deep learning framework,2021,Computers and Electrical Engineering,96,,107542,,,,1,10.1016/j.compeleceng.2021.107542,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117403420&doi=10.1016%2fj.compeleceng.2021.107542&partnerID=40&md5=73b3219df5945b999bd1dfad9e9da113,"Department of Computer Science, COMSATS University Islamabad, Wah CampusWah Cantonment, Pakistan; Department of Computer Science, HITEC University Taxila, Taxila, Pakistan; Faculty of Mathematics, Beirut Arab University, Beirut, Lebanon; Department of Computer Science and Engineering, Sathyabama Institute of Science and Technology, Chennai, Tamil Nadu  600119, India","Kanwal, S., Department of Computer Science, COMSATS University Islamabad, Wah CampusWah Cantonment, Pakistan; Shah, J.H., Department of Computer Science, COMSATS University Islamabad, Wah CampusWah Cantonment, Pakistan; Khan, M.A., Department of Computer Science, HITEC University Taxila, Taxila, Pakistan; Nisa, M., Department of Computer Science, COMSATS University Islamabad, Wah CampusWah Cantonment, Pakistan; Kadry, S., Faculty of Mathematics, Beirut Arab University, Beirut, Lebanon; Sharif, M., Department of Computer Science, COMSATS University Islamabad, Wah CampusWah Cantonment, Pakistan; Yasmin, M., Department of Computer Science, COMSATS University Islamabad, Wah CampusWah Cantonment, Pakistan; Maheswari, M., Department of Computer Science and Engineering, Sathyabama Institute of Science and Technology, Chennai, Tamil Nadu  600119, India","In this paper, the adversarial haze attack problem is addressed using the dark channel prior (DCP) de-hazing method. The adversarial attack affects rank-1 accuracy, where searching a target image against each test image is a specific search problem. To resolve this kind of problem, a feature fusion model is proposed to fuse handcrafted features and a pre-trained network model to obtain robust and discriminative features. The proposed model learns global features using transfer learning architecture whereas local features are obtained using the conventional method. Three pre-trained CNN models (AlexNet, ResNet, and Inception-v3) are used for feature extraction via transfer learning. The experiments are performed on publicly available datasets, achieving 68.6% accuracy in rank-1 with VIPER dataset and 79.6% accuracy with CHUK03 dataset. The proposed model enhances rank-1 accuracy of person re-identification when comparing with other state-of-the-art methods. © 2021 Elsevier Ltd",Adversarial haze attack; Dark channel prior (DCP) algorithm; Deep learning; Feature fusion; Handcrafted model; Person re-identification; Transfer learning,Adversarial haze attack; Dark channel prior algorithm; Dark channel priors; Deep learning; Features fusions; Handcrafted model; Learning frameworks; Person re identifications; Target images; Transfer learning; Deep learning,,,,,"Biggio, B., Roli, F., Wild patterns: ten years after the rise of adversarial machine learning (2018) Pattern Recognit, 84, pp. 317-331; Arshad, H., Khan, M.A., Sharif, M.I., Yasmin, M., Tavares, J.M.R., Zhang, Y.D., A multilevel paradigm for deep convolutional neural network features selection with an application to human gait recognition (2020) Expert Syst, p. e12541; Khan, M.A., Zhang, Y.D., Khan, S.A., Attique, M., Rehman, A., Seo, S., A resource conscious human action recognition framework using 26-layered deep convolutional neural network (2020) Multimedia tools and applications, pp. 1-23; Khan, M.A., Javed, K., Khan, S.A., Saba, T., Habib, U., Khan, J.A., Human action recognition using fusion of multiview and deep features: an application to video surveillance (2020) Multimedia tools and applications, pp. 1-27; Gong, W., Yan, B., Lin, C., Flow-guided feature enhancement network for video-based person re-identification (2020) Neurocomputing, 383, pp. 295-302; Liu, Z., Lu, H., Ruan, X., Yang, M.H., Person reidentification by joint local distance metric and feature transformation (2019) IEEE Trans Neural Netw Learn Syst, 30, pp. 2999-3009; Khan, M.A., Sharif, M., Akram, T., Raza, M., Saba, T., Rehman, A., Hand-crafted and deep convolutional neural network features fusion and selection strategy: an application to intelligent human action recognition (2020) Appl Soft Comput, 87; Sharif, A., Khan, M.A., Javed, K., Gulfam, H., Iqbal, T., Saba, T., Intelligent human action recognition: a framework of optimal features selection based on euclidean distance and strong correlation (2019) J Control Eng Appl Inform, 21, pp. 3-11; Rashid, M., Khan, M.A., Alhaisoni, M., Wang, S.H., Naqvi, S.R., Rehman, A., A sustainable deep learning framework for object recognition using multi-layers deep features fusion and selection (2020) Sustainability, 12, p. 5037; Khan, M.A., Haider, I., Nazir, M., Armghan, A., Lodhi, H.M.J., Khan, J.A., Traditional features based automated system for human activities recognition (2020) Proceedings of the 2nd international conference on computer and information sciences (ICCIS), pp. 1-6; Song, S., Chen, Y., Cheung, N.M., Kuo, C.C.J., (2018), ""Defense against adversarial attacks with saak transform,"" arXiv preprint arXiv:1808.01785; Wang, H., Wang, G., Li, Y., Zhang, D., Lin, L., Transferable, controllable, and inconspicuous adversarial attacks on person re-identification with deep mis-ranking (2020) Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 342-351; He, K., Sun, J., Tang, X., Single image haze removal using dark channel prior (2010) IEEE Trans Pattern Anal Mach Intell, 33, pp. 2341-2353; Nnolim, U.A., Partial differential equation-based hazy image contrast enhancement (2018) Comput Electr Eng, 72, pp. 670-681; Ding, S., Lin, L., Wang, G., Chao, H., Deep feature learning with relative distance comparison for person re-identification (2015) Pattern Recognit, 48, pp. 2993-3003; Zheng, Z., Zheng, L., Yang, Y., Pedestrian alignment network for large-scale person re-identification (2018) IEEE Trans Circuits Syst Video Technol, 29, pp. 3037-3045; Chen, Y.C., Zhu, X., Zheng, W.S., Lai, J.H., Person re-identification by camera correlation aware feature augmentation (2017) IEEE Trans Pattern Anal Mach Intell, 40, pp. 392-408; Wang, X., Zhao, C., Miao, D., Wei, Z., Zhang, R., Ye, T., Fusion of multiple channel features for person re-identification (2016) Neurocomputing, 213, pp. 125-136; Wu, S., Chen, Y.C., Li, X., Wu, A.C., You, J.J., Zheng, W.S., An enhanced deep feature representation for person re-identification (2016) Proceedings of the IEEE winter conference on applications of computer vision (WACV), pp. 1-8; Yao, H., Zhang, S., Hong, R., Zhang, Y., Xu, C., Tian, Q., Deep representation learning with part loss for person re-identification (2019) IEEE Trans Image Process, 28, pp. 2860-2871; Li, S., Yu, H., Hu, R., Attributes-aided part detection and refinement for person re-identification (2020) Pattern Recognit, 97; Zhou, B., Duan, X.M., Wei, W., Ye, D.J., Woźniak, M., Damaševičius, R., An adaptive local descriptor embedding Zernike moments for image matching (2019) IEEE Access, 7, pp. 183971-183984; Chen, J., Su, M., Shen, S., Xiong, H., Zheng, H., POBA-GA: perturbation optimized black-box adversarial attacks via genetic algorithm (2019) Comput Secur, 85, pp. 89-106; Feng, Q., Wei, Y., Yi, Y., Hao, Q., Dai, J., Local ternary cross structure pattern: a color LBP feature extraction with applications in CBIR (2019) Appl Sci, 9, p. 2211; Gray, D., Brennan, S., Tao, H., Evaluating appearance models for recognition, reacquisition, and tracking (2007) Proceedings of the IEEE international workshop on performance evaluation for tracking and surveillance (PETS), pp. 1-7; Li, W., Zhao, R., Xiao, T., Wang, X., Deepreid: deep filter pairing neural network for person re-identification (2014) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 152-159; Wu, L., Wang, Y., Gao, J., Li, X., Deep adaptive feature embedding with local sample distributions for person re-identification (2018) Pattern Recognit, 73, pp. 275-288; Zheng, L., Huang, Y., Lu, H., Yang, Y., Pose-invariant embedding for deep person re-identification (2019) IEEE Trans Image Process, 28, pp. 4500-4509; Li, W., Zhu, X., Gong, S., Harmonious attention network for person re-identification (2018) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2285-2294; Zhang, H., Xie, Z., Lin, H.C., Li, S., Power capacity optimization in a photovoltaics-based microgrid using the improved artificial bee colony algorithm (2020) Appl Sci, 10, p. 2990","Khan, M.A.; Department of Computer Science, Pakistan; 电子邮件: attique@ciitwah.edu.pk",,,Elsevier Ltd,,,,,457906,,CPEEB,,English,Comput Electr Eng,Article,Final,,Scopus,2-s2.0-85117403420
"Chhabra A., Mohapatra P.",57194457704;24725118000;,Moving Target Defense against Adversarial Machine Learning,2021,"MTD 2021 - Proceedings of the 8th ACM Workshop on Moving Target Defense, co-located with CCS 2021",,,,29,30,,,10.1145/3474370.3485662,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121443617&doi=10.1145%2f3474370.3485662&partnerID=40&md5=de288c0a0d5d02de2a19efa0f1ddf8a4,"University of California, Davis, Davis, United States","Chhabra, A., University of California, Davis, Davis, United States; Mohapatra, P., University of California, Davis, Davis, United States","As Machine Learning (ML) models are increasingly employed in a number of applications across a multitude of fields, the threat of adversarial attacks against ML models is also increasing. Adversarial samples crafted via specialized attack algorithms have been shown to significantly decrease the performance of ML models. Furthermore, it has also been found that adversarial samples generated for a particular model can transfer across other models, and decrease accuracy and other performance metrics for a model they were not originally crafted for. In recent research, many different defense approaches have been proposed for making ML models robust, ranging from adversarial input re-training to defensive distillation, among others. While these approaches operate at the model-level, we propose an alternate approach to defending ML models against adversarial attacks, using Moving Target Defense (MTD). We formulate the problem and provide preliminary results to showcase the validity of the proposed approach. © 2021 Owner/Author.",adversarial attacks; adversarial machine learning; moving target defense; reinforcement learning,Distillation; Reinforcement learning; Adversarial attack; Adversarial machine learning; Alternate approaches; Machine learning models; Machine-learning; Moving target defense; Performance; Performance metrices; Recent researches; Network security,,,,,"Carlini, Nicholas, Katz, Guy, Barrett, Clark, Dill, David L, (2017) Provably minimally-distorted adversarial examples, , arXiv preprint arXiv:1709.10207 (2017); Papernot, Nicolas, McDaniel, Patrick, Goodfellow, Ian, (2016) Transferability in machine learning: from phenomena to black-box attacks using adversarial samples, , arXiv preprint arXiv:1605.07277 (2016); Papernot, Nicolas, McDaniel, Patrick, Wu, Xi, Jha, Somesh, Swami, Ananthram, Distillation as a defense to adversarial perturbations against deep neural networks (2016) 2016 IEEE symposium on security and privacy (SP), pp. 582-597. , IEEE; Roy, Abhishek, Chhabra, Anshuman, Kamhoua, Charles A, Mohapatra, Prasant, A moving target defense against adversarial machine learning (2019) Proceedings of the 4th ACM/IEEE Symposium on Edge Computing, pp. 383-388; Schulman, John, Wolski, Filip, Dhariwal, Prafulla, Radford, Alec, Klimov, Oleg, (2017) Proximal policy optimization algorithms, , arXiv preprint arXiv:1707.06347 (2017); Sutton, Richard S, Barto, Andrew G, (2018) Reinforcement learning: An introduction, , MIT press",,,ACM SIGSAC,"Association for Computing Machinery, Inc","8th ACM Workshop on Moving Target Defense, MTD 2021, co-located with CCS 2021",15-Nov-21,,174213,,9.78E+12,,,English,"MTD - Proc. ACM Workshop Mov. Target Def., co-located CCS",Conference Paper,Final,,Scopus,2-s2.0-85121443617
[无可用作者姓名],[无可用的作者 ID],"AISec 2021 - Proceedings of the 14th ACM Workshop on Artificial Intelligence and Security, co-located with CCS 2021",2021,"AISec 2021 - Proceedings of the 14th ACM Workshop on Artificial Intelligence and Security, co-located with CCS 2021",,,,,,215,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120894855&partnerID=40&md5=80f13b2fe35d762558170976034d6848,,,The proceedings contain 17 papers. The topics discussed include: Unicode evil: evading NLP systems using visual similarities of text characters; adversarial transfer attacks with unknown data and class overlap; SEAT: similarity encoder by adversarial training for detecting model extraction attack queries; network anomaly detection using transfer learning based on auto-encoders loss normalization; a framework for cluster and classifier evaluation in the absence of reference labels; patch-based defenses against web fingerprinting attacks; investigating labelless drift adaptation for malware detection; spying through virtual backgrounds of video calls; and explaining graph neural networks for vulnerability discovery.,,,,,,,,,,ACM SIGSAC,"Association for Computing Machinery, Inc","14th ACM Workshop on Artificial Intelligence and Security, AISec 2021, co-located with CCS 2021",15-Nov-21,,174212,,9.78E+12,,,English,"AISec - Proc. ACM Workshop Artif. Intell. Secur., co-located CCS",Conference Review,Final,,Scopus,2-s2.0-85120894855
"Richards L.E., Nguyen A., Capps R., Forsyth S., Matuszek C., Raff E.",57221150854;56835058900;57289170100;57212022609;10239806100;57191162116;,Adversarial Transfer Attacks with Unknown Data and Class Overlap,2021,"AISec 2021 - Proceedings of the 14th ACM Workshop on Artificial Intelligence and Security, co-located with CCS 2021",,,,13,24,,,10.1145/3474369.3486862,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120861525&doi=10.1145%2f3474369.3486862&partnerID=40&md5=383e3e4e07ebd496a56507f2b9695496,"Booz Allen Hamilton and University of Maryland, Baltimore County, Baltimore, MD, United States; Booz Allen Hamilton, Washinton, DC, United States; NVIDIA, Washinton, DC, United States","Richards, L.E., Booz Allen Hamilton and University of Maryland, Baltimore County, Baltimore, MD, United States; Nguyen, A., Booz Allen Hamilton and University of Maryland, Baltimore County, Baltimore, MD, United States; Capps, R., Booz Allen Hamilton, Washinton, DC, United States; Forsyth, S., NVIDIA, Washinton, DC, United States; Matuszek, C., Booz Allen Hamilton and University of Maryland, Baltimore County, Baltimore, MD, United States; Raff, E., Booz Allen Hamilton and University of Maryland, Baltimore County, Baltimore, MD, United States","The ability to transfer adversarial attacks from one model (the surrogate) to another model (the victim) has been an issue of concern within the machine learning (ML) community. The ability to successfully evade unseen models represents an uncomfortable level of ease toward implementing attacks. In this work we note that as studied, current transfer attack research has an unrealistic advantage for the attacker: The attacker has the exact same training data as the victim. We present the first study of transferring adversarial attacks focusing on the data available to attacker and victim under imperfect settings without querying the victim, where there is some variable level of overlap in the exact data used or in the classes learned by each model. This threat model is relevant to applications in medicine, malware, and others. Under this new threat model attack success rate is not correlated with data or class overlap in the way one would expect, and varies with dataset. This makes it difficult for attacker and defender to reason about each other and contributes to the broader study of model robustness and security. We remedy this by developing a masked version of Projected Gradient Descent that simulates class disparity, which enables the attacker to reliably estimate a lower-bound on their attack's success. © 2021 ACM.",adversarial machine learning; machine learning; machine learning security,,,,,,"Anderson, Hyrum S., Roth, Phil, (2018) EMBER: An Open Dataset for Training Static PE Malware Machine Learning Models, , ArXiv e-prints; Arslan, Bilgehan, Ulker, Mehtap, Sagiroglu, Seref, Machine Learning Methods Used in Evaluations of Secure Biometric System Components (2017) 2017 16th IEEE International Conference on Machine Learning and Applications (ICMLA), pp. 448-453. , IEEE, 12; Ashraf, Ahmed Bilal, Lucey, Simon, Cohn, Jeffrey F., Chen, Tsuhan, Ambadar, Zara, Prkachin, Kenneth M., Solomon, Patricia E., The painful face ? Pain expression recognition using active appearance models (2009) Image and Vision Computing, 27 (12), pp. 1788-1796. , 11; Athalye, Anish, Carlini, Nicholas, Wagner, David, Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples (2018) International Conference on Machine Learning (ICML); Athalye, Anish, Engstrom, Logan, Ilyas, Andrew, Kwok, Kevin, (2017) Synthesizing Robust Adversarial Examples, , ArXiv e-prints; Biggio, Battista, Fumera, Giorgio, Roli, Fabio, Security evaluation of pattern classifiers under attack (2014) IEEE Transactions on Knowledge and Data Engineering, 26 (4), pp. 984-996; Biggio, Battista, Roli, Fabio, Wild patterns: Ten years after the rise of adversarial machine learning (2018) Pattern Recognition, 84, pp. 317-331. , 12; Broome, Sofia, Gleerup, Karina Bech, Andersen, Pia Haubro, Kjellstrom, Hedvig, Dynamics Are Important for the Recognition of Equine Pain in Video (2019) 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 12659-12668. , IEEE, 6; Carlini, Nicholas, Wagner, David, Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, AISec ?17, pp. 3-14. , New York, NY, USA, ACM; Chang, Wei-Cheng, Yu, Hsiang-Fu, Zhong, Kai, Yang, Yiming, Dhillon, Inderjit S, Taming Pretrained Transformers for Extreme Multi-Label Text Classification (2020) Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, KDD ?20, pp. 3163-3171. , page New York, NY, USA, Association for Computing Machinery; Cheng, Shuyu, Dong, Yinpeng, Pang, Tianyu, Su, Hang, Zhu, Jun, (2019) Improving black-box adversarial attacks with a transfer-based prior, , arXiv preprint arXiv:1906.06919; Demontis, Ambra, Melis, Marco, Pintor, Maura, Jagielski, Matthew, Biggio, Battista, Oprea, Alina, Nita-Rotaru, Cristina, Roli, Fabio, (2018) Why Do Adversarial Attacks Transfer? Explaining Transferability of Evasion and Poisoning Attacks, pp. 26-28. , ArXiv e-prints, pages; Demontis, Ambra, Melis, Marco, Pintor, Maura, Jagielski, Matthew, Biggio, Battista, Oprea, Alina, Nita-Rotaru, Cristina, Roli, Fabio, Why Do Adversarial Attacks Transfer? Explaining Transferability of Evasion and Poisoning Attacks (2019) 28th USENIX Security Symposium (USENIX Security 19), pp. 321-338. , Santa Clara, CA, 8 {USENIX Association; Dong, Yinpeng, Liao, Fangzhou, Pang, Tianyu, Su, Hang, Zhu, Jun, Hu, Xiaolin, Li, Jianguo, Boosting adversarial attacks with momentum (2018) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 9185-9193; Dong, Y, Pang, T, Su, H, Zhu, J, Evading Defenses to Transferable Adversarial Examples by Translation-Invariant Attacks (2019) 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4307-4316. , 6; Dong, Yinpeng, Pang, Tianyu, Su, Hang, Zhu, Jun, Evading defenses to transferable adversarial examples by translation-invariant attacks (2019) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 4312-4321; Egele, Manuel, Scholte, T, Kirda, E, Barbara, Santa, A Survey On Automated Dynamic Malware Analysis Evasion and Counter-Evasion (2017) Proceedings of Reversing and Offensive-oriented Trends Symposium; Finlayson, Samuel G, Kohane, Isaac S, Beam, Andrew L, (2018) Adversarial Attacks Against Medical Deep Learning Systems; Hammal, Zakia, Cohn, Jeffrey F., Automatic detection of pain intensity (2012) Proceedings of the 14th ACM international conference on Multimodal interaction - ICMI ?12, p. 47. , page New York, New York, USA, ACM Press; He, Kaiming, Zhang, Xiangyu, Ren, Shaoqing, Sun, Jian, Deep Residual Learning for Image Recognition (2015) IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Jain, Himanshu, Balasubramanian, Venkatesh, Chunduri, Bhanu, Varma, Manik, Slice: Scalable Linear Extreme Classifiers Trained on 100 Million Labels for Related Searches (2019) Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining, WSDM ?19, pp. 528-536. , page New York, NY, USA, Association for Computing Machinery; Kariyappa, Sanjay, Qureshi, Moinuddin K., (2019) Improving Adversarial Robustness of Ensembles with Diversity Training, , arXiv; Kingma, Diederik P, Ba, Jimmy Lei, Adam: A Method for Stochastic Optimization (2015) International Conference On Learning Representations; Kolosnjaji, Bojan, Demontis, Ambra, Biggio, Battista, Maiorca, Davide, Giacinto, Giorgio, Eckert, Claudia, Roli, Fabio, Adversarial malware binaries: Evading deep learning for malware detection in executables (2018) European Signal Processing Conference, pp. 533-537. , 2018-Septe; Kurakin, Alexey, Goodfellow, Ian, Bengio, Samy, Adversarial Machine Learning at Scale (2017) International Conference on Learning Representations (ICLR); Lucey, Patrick, Cohn, Jeffrey, Lucey, Simon, Matthews, Iain, Sridharan, Sridha, Prkachin, Kenneth M., Automatically detecting pain using facial actions (2009) 2009 3rd International Conference on Affective Computing and Intelligent Interaction and Workshops, pp. 1-8. , IEEE, 9; Madry, Aleksander, Makelov, Aleksandar, Schmidt, Ludwig, Tsipras, Dimitris, Vladu, Adrian, Towards Deep Learning Models Resistant to Adversarial Attacks (2018) International Conference on Learning Representations (ICLR); Martinez, Daniel Lopez, Rudovic, Ognjen, Picard, Rosalind, Personalized Automatic Estimation of Self-Reported Pain Intensity from Facial Expressions (2017) 2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), pp. 2318-2327. , IEEE, 7; Nguyen, Andre T, Raff, Edward, Adversarial Attacks, Regression, and Numerical Stability Regularization (2018) AAAI 2019 Workshop on Engineering Dependable and Secure Machine Learning Systems; Papernot, Nicolas, McDaniel, Patrick, Goodfellow, Ian, (2016) Transferability in Machine Learning: from Phenomena to Black-Box Attacks using Adversarial Samples, , arXiv; Papernot, Nicolas, McDaniel, Patrick, Goodfellow, Ian, Jha, Somesh, Berkay Celik, Z, Swami, Ananthram, Practical Black-Box Attacks against Machine Learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, ASIA CCS ?17, pp. 506-519. , page New York, NY, USA, Association for Computing Machinery; Raff, Edward, Lantzy, Shannon, Maier, Ezekiel J, Dr. AI, Where Did You Get Your Degree? In Fernando Koch, Andrew Koster, David Ria?o, Sara Montagna, Michael Schumacher, Annette ten Teije, Christian Guttmann, Manfred Reichert, Isabelle Bichindaritz, Pau Herrero, Richard Lenz, Beatriz L?pez, Cindy Marling, Clare Martin, Stefania Montani, and Nirmalie Wiratunga, editors (2019) Artificial Intelligence in Health, pp. 76-83. , Cham, Springer International Publishing; Raff, Edward, Nicholas, Charles, A Survey of Machine Learning Methods and Challenges for Windows Malware Classification (2020) NeurIPS 2020 Workshop: ML Retrospectives, Surveys & Meta-Analyses (ML-RSA); Salman, Hadi, Ilyas, Andrew, Engstrom, Logan, Kapoor, Ashish, Madry, Aleksander, (2020) Do Adversarially Robust ImageNet Models Transfer Better?, , arXiv; Sebasti, Marcos, Rivera, Richard, Kotzias, Platon, Caballero, Juan, AVclass: A Tool for Massive Malware Labeling (2016) Research in Attacks, Intrusions, and Defenses: 19th International Symposium, RAID 2016, pp. 230-253. , and, Fabian Monrose, Marc Dacier, Gregory Blanc, and Joaquin Garcia-Alfaro, editors, pages Springer International Publishing, Paris, France; Sebasti, Silvia, Caballero, Juan, AVClass2: Massive Malware Tag Extraction from AV Labels (2020) ACSAC, , n and; Seideman, Jeremy D., Khan, Bilal, Vargas, Antonio Cesar, Identifying malware genera using the Jensen-Shannon distance between system call traces (2014) 2014 9th International Conference on Malicious and Unwanted Software: The Americas (MALWARE), pp. 1-7. , IEEE, 10; Shan, Shawn, Wenger, Emily, Zhang, Jiayun, Li, Huiying, Zheng, Haitao, Zhao, Ben Y., (2020) Fawkes: Protecting Privacy against Unauthorized Deep Learning Models; Srivastava, Nitish, Hinton, Geoffrey, Krizhevsky, Alex, Sutskever, Ilya, Salakhutdinov, Ruslan, Dropout : A Simple Way to Prevent Neural Networks from Overfitting (2014) The Journal of Machine Learning Research, 15 (1), pp. 1929-1958; Srndic, Nedim, Laskov, Pavel, Practical Evasion of a Learning-Based Classifier: A Case Study (2014) Proceedings of the 2014 IEEE Symposium on Security and Privacy, SP ?14, pp. 197-211. , page USA, IEEE Computer Society; Suciu, Octavian, Marginean, Radu, Kaya, Yigitcan, Daume, Hal, Dumitras, Tudor, When Does Machine Learning FAIL? Generalized Transferability for Evasion and Poisoning Attacks (2018) 27th USENIX Security Symposium (USENIX Security 18), pp. 1299-1316. , Baltimore, MD, 8 {USENIX Association; Tram, Florian, Papernot, Nicolas, Goodfellow, Ian, Boneh, Dan, Mc- Daniel, Patrick, (2017) The Space of Transferable Adversarial Examples, pp. 1-15. , and, arXiv, pages; Treede, Rolf-Detlef, The International Association for the Study of Pain definition of pain: as valid in 2018 as in 1979, but in need of regularly updated footnotes (2018) Pain reports, 3 (2), pp. e643-e643. , 3; Wong, Eric, Rice, Leslie, Zico Kolter, J., Fast is better than free: Revisiting adversarial training (2020) International Conference on Learning Representations (ICLR); Xie, C, Zhang, Z, Zhou, Y, Bai, S, Wang, J, Ren, Z, Yuille, A L, Improving Transferability of Adversarial Examples With Input Diversity (2019) 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2725-2734. , 6; Zhou, Wen, Hou, Xin, Chen, Yongjun, Tang, Mengyun, Huang, Xiangqi, Gan, Xiang, Yang, Yong, Transferable Adversarial Perturbations (2018) ECCV, pp. 471-486. , Vittorio Ferrari, Martial Hebert, Cristian Sminchisescu, and Yair Weiss, editors, pages Cham, Springer International Publishing",,,ACM SIGSAC,"Association for Computing Machinery, Inc","14th ACM Workshop on Artificial Intelligence and Security, AISec 2021, co-located with CCS 2021",15-Nov-21,,174212,,9.78E+12,,,English,"AISec - Proc. ACM Workshop Artif. Intell. Secur., co-located CCS",Conference Paper,Final,"All Open Access, Bronze, Green",Scopus,2-s2.0-85120861525
"Zhang Y., Yang J., Li X., Liu H., Shao K.",57196201561;57223825387;57314845900;56125442700;57226882823;,Textual adversarial attacking with limited queries,2021,Electronics (Switzerland),10,21,2671,,,,,10.3390/electronics10212671,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118184814&doi=10.3390%2felectronics10212671&partnerID=40&md5=8901ac175552db3ec99be063bea8d829,"Institute of Electronic Countermeasure, National University of Defense Technology, Hefei, 230037, China","Zhang, Y., Institute of Electronic Countermeasure, National University of Defense Technology, Hefei, 230037, China; Yang, J., Institute of Electronic Countermeasure, National University of Defense Technology, Hefei, 230037, China; Li, X., Institute of Electronic Countermeasure, National University of Defense Technology, Hefei, 230037, China; Liu, H., Institute of Electronic Countermeasure, National University of Defense Technology, Hefei, 230037, China; Shao, K., Institute of Electronic Countermeasure, National University of Defense Technology, Hefei, 230037, China","Recent studies have shown that natural language processing (NLP) models are vulnerable to adversarial examples, which are maliciously designed by adding small perturbations to benign inputs that are imperceptible to the human eye, leading to false predictions by the target model. Compared to character-and sentence-level textual adversarial attacks, word-level attack can generate higher-quality adversarial examples, especially in a black-box setting. However, existing attack methods usually require a huge number of queries to successfully deceive the target model, which is costly in a real adversarial scenario. Hence, finding appropriate models is difficult. Therefore, we propose a novel attack method, the main idea of which is to fully utilize the adversarial examples generated by the local model and transfer part of the attack to the local model to complete ahead of time, thereby reducing costs related to attacking the target model. Extensive experiments conducted on three public benchmarks show that our attack method can not only improve the success rate but also reduce the cost, while outperforming the baselines by a significant margin. Copyright: © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",Adversarial attack; Black box; Machine learning; Natural language processing (NLP),,,,,,"Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R., Intriguing properties of neural networks Proceedings of the 2nd International Conference on Learning Representations, ICLR 2014, , Banff, AB, Canada, 14–16 April 2014; Bengio, Y., LeCun, Y., Eds.; Conference Track Proceedings; Thys, S., Ranst, W.V., Goedemé, T., Fooling automated surveillance cameras: Adversarial patches to attack person detection Proceedings of the 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), pp. 49-55. , Long Beach, CA, USA, 16–17 June 2019; [CrossRef]; Papernot, N., McDaniel, P.D., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings Proceedings of the IEEE European Symposium on Security and Privacy, EuroS&P 2016, pp. 372-387. , Saarbrücken, Germany, 21–24 March 2016; [CrossRef]; Li, J., Ji, S., Du, T., Li, B., Wang, T., TextBugger: Generating adversarial text against real-world applications Proceedings of the 2019 Network and Distributed System Security Symposium, , San Diego, California, USA, 24–27 February 2019. [CrossRef]; Yu, F., Wang, L., Fang, X., Zhang, Y., The defense of adversarial example with conditional generative adversarial networks (2020) Secur. Commun. Netw, 2020. , 3932584:1–3932584:12, [CrossRef]; Jiang, L., Qiao, K., Qin, R., Wang, L., Yu, W., Chen, J., Bu, H., Yan, B., Cycle-Consistent Adversarial GAN: The integration of adversarial attack and defense (2020) Secur. Commun. Netw, 2020. , 3608173:1–3608173:9, [CrossRef]; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, , Abu Dhabi, United Arab Emirates, 2–6 April; Ebrahimi, J., Rao, A., Lowd, D., Dou, D., HotFlip: White-box adversarial examples for text classification Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018, 2, pp. 31-36. , Melbourne, Australia, 15–20 July 2018; Gurevych, I., Miyao, Y., Eds.; Short Papers, [CrossRef]; Iyyer, M., Wieting, J., Gimpel, K., Zettlemoyer, L., Adversarial example generation with syntactically controlled paraphrase networks (2018) Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2018, 1, pp. 1875-1885. , New Orleans, LA, USA, 1–6 June Walker, M.A., Ji, H., Stent, A., Eds.; (Long, Papers), [CrossRef]; Wang, W., Wang, R., Wang, L., Wang, Z., Ye, A., Towards a robust deep neural network against adversarial texts: A survey (2021) IEEE Trans. Knowl. Data Eng, 1. , [CrossRef]; Zang, Y., Qi, F., Yang, C., Liu, Z., Zhang, M., Liu, Q., Sun, M., Word-level textual adversarial attacking as combinatorial optimization Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, , Online, 5–10 July 2020; Devlin, J., Chang, M., Lee, K., Toutanova, K., BERT: Pre-training of deep bidirectional transformers for language understanding Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, 1, pp. 4171-4186. , Minneapolis, MN, USA, 2–7 June 2019; Burstein, J., Doran, C., Solorio, T., Eds.; (Long and Short, Papers), [CrossRef]; Jin, D., Jin, Z., Zhou, J.T., Szolovits, P., Is BERT really robust? A strong baseline for natural language attack on text classification and entailment Proceedings of the Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2020, pp. 8018-8025. , New York, NY, USA, 7–12 February 2020; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) Proceedings of the 5th International Conference on Learning Representations, ICLR 2017, , Toulon, France, 24–26 April; Li, P., Yi, J., Zhang, L., Query-Efficient Black-Box Attack by Active Learning Proceedings of the IEEE International Conference on Data Mining, ICDM 2018, pp. 1200-1205. , Singapore, 17–20 November 2018; [CrossRef]; Papernot, N., McDaniel, P.D., Goodfellow, I.J., (2016) Transferability in machine learning: From phenomena to black-box attacks using adversarial samples, , arXiv arXiv:1605.07277; Gil, Y., Chai, Y., Gorodissky, O., Berant, J., White-to-Black: Efficient distillation of black-box adversarial attacks Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, 1, pp. 1373-1379. , Minneapolis, MN, USA, 2–7 June 2019; Burstein, J., Doran, C., Solorio, T., Eds.; (Long and Short, Papers), [CrossRef]; Goodfellow, I.J., Shlens, J., Szegedy, C., (2015) Explaining and Harnessing Adversarial Examples, , arXiv arXiv:1412.6572; Moosavi-Dezfooli, S., Fawzi, A., Frossard, P., DeepFool: A simple and accurate method to fool deep neural networks Proceedings of the 2016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2016, pp. 2574-2582. , Las Vegas, NV, USA, 27–30 June 2016; [CrossRef]; Jia, R., Liang, P., (2017) Adversarial examples for evaluating reading comprehension systems, , arXiv arXiv:1707.07328; Zhao, Z., Dua, D., Singh, S., (2018) Generating natural adversarial examples, , arXiv arXiv:1710.11342; Eger, S., Sahin, G.G., Rücklé, A., Lee, J., Schulz, C., Mesgar, M., Swarnkar, K., Gurevych, I., Text processing like humans do: Visually attacking and shielding NLP systems (2019) Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, 1, pp. 1634-1647. , Minneapolis, MN, USA, 2–7 June (Long and Short Papers); Belinkov, Y., Bisk, Y., Synthetic and natural noise both break neural machine translation (2018) Proceedings of the 6th International Conference on Learning Representations, ICLR 2018, , Vancouver, BC, Canada, 30 April–3 May; Gao, J., Lanchantin, J., Soffa, M.L., Qi, Y., Black-Box generation of adversarial text sequences to evade deep learning classifiers Proceedings of the 2018 IEEE Security and Privacy Workshops, SP Workshops 2018, pp. 50-56. , San Francisco, CA, USA, 24 May 2018; [CrossRef]; Pruthi, D., Dhingra, B., Lipton, Z.C., Combating adversarial misspellings with robust word recognition Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019, 1, pp. 5582-5591. , Florence, Italy, 28 July–2 August 2019; Korhonen, A., Traum, D.R., Màrquez, L., Eds.; Long, Papers, [CrossRef]; Sato, M., Suzuki, J., Shindo, H., Matsumoto, Y., (2018) Interpretable adversarial perturbation in input embedding space for text, , arXiv arXiv:1805.02917; Zhang, H., Zhou, H., Miao, N., Li, L., (2020) Generating fluent adversarial examples for natural languages, , arXiv arXiv:2007.06174; Samanta, S., Mehta, S., (2017) Towards crafting text adversarial samples, , arXiv arXiv:1710.11342; Ren, S., Deng, Y., He, K., Che, W., Generating natural language adversarial examples through probability weighted word saliency (2019) Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pp. 1085-1097. , Florence, Italy, 28 July–2 August; Alzantot, M., Sharma, Y., Elgohary, A., Ho, B.J., Srivastava, M.B., Chang, K.W., (2018) Generating natural language adversarial examples, , arXiv arXiv:1804.07998; Glockner, M., Shwartz, V., Goldberg, Y., (2018) Breaking NLI systems with sentences that require simple lexical inferences, , arXiv arXiv:1805.02266; Papernot, N., Mcdaniel, P., Swami, A., Harang, R.E., Crafting adversarial input sequences for recurrent neural networks Proceedings of the MILCOM 2016-2016 IEEE Military Communications Conference, pp. 49-54. , Baltimore, MD, USA, 1–3 November 2016; Liang, B., Li, H., Su, M., Bian, P., Li, X., Shi, W., Deep text classification can be fooled Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence, , Stockholm, Sweden, 13–19 July 2018. [CrossRef]; Maas, A.L., Daly, R.E., Pham, P.T., Huang, D., Ng, A.Y., Potts, C., Learning word vectors for sentiment analysis (2011) Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pp. 142-150. , Stroudsburg, PA, USA, 19–24 June Association for Computational Linguistics, HLT ’11: Seattle, WA, USA; Socher, R., Perelygin, A., Wu, J., Chuang, J., Manning, C.D., Ng, A., Potts, C., Recursive deep models for semantic compositionality over a sentiment treebank (2013) Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pp. 1631-1642. , Seattle, WA, USA, 18–21 October Association for Computational Linguistics: Seattle, WA, USA, 2013; Bowman, S.R., Angeli, G., Potts, C., Manning, C.D., (2015) A large annotated corpus for learning natural language inference, , arXiv arXiv:1508.05326; Conneau, A., Kiela, D., Schwenk, H., Barrault, L., Bordes, A., (2017) Supervised learning of universal sentence representations from natural language inference data, , arXiv arXiv:1705.02364","Yang, J.; Institute of Electronic Countermeasure, China; 电子邮件: yangjunan@ustc.edu.cn",,,MDPI,,,,,20799292,,,,English,Electronics (Switzerland),Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85118184814
"Zhao X., Zhang J., Huang X.",57193750353;57276924200;57226088998;,APF: An Adversarial Privacy-preserving Filter to Protect Portrait Information,2021,MM 2021 - Proceedings of the 29th ACM International Conference on Multimedia,,,,2813,2815,,,10.1145/3474085.3478568,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119342269&doi=10.1145%2f3474085.3478568&partnerID=40&md5=615af246a889741d9f737db0d1247c08,"School of Computer and Information Technology, Beijing Key Lab of Traffic Data Analysis and Mining, Beijing Jiaotong University, Beijing, China","Zhao, X., School of Computer and Information Technology, Beijing Key Lab of Traffic Data Analysis and Mining, Beijing Jiaotong University, Beijing, China; Zhang, J., School of Computer and Information Technology, Beijing Key Lab of Traffic Data Analysis and Mining, Beijing Jiaotong University, Beijing, China; Huang, X., School of Computer and Information Technology, Beijing Key Lab of Traffic Data Analysis and Mining, Beijing Jiaotong University, Beijing, China","While widely adopted in practical applications, face recognition has been disputed on the malicious use of face images and potential privacy issues. Online photo sharing services accidentally act as the main approach for the malicious crawlers to exploit face recognition to access portrait privacy. In this demo, we propose an adversarial privacy-preserving filter, which can preserve face image from malicious face recognition algorithms. This filter is generated by an end-cloud collaborated adversarial attack framework consisting of three modules: (1) Image-specific gradient generation module, to extract image-specific gradient in the user end; (2) Adversarial gradient transfer module, to fine-tune the image-specific gradient in the server; and (3) Universal adversarial perturbation enhancement module, to append image-independent perturbation to derive the final adversarial perturbation. A short video about our system is available at https://github.com/Anonymity-for-submission/3247. © 2021 Owner/Author.",adversarial examples; face recognition; privacy-preserving,Image enhancement; Privacy-preserving techniques; Adversarial example; Face images; Face recognition algorithms; Online Photo Sharing; Privacy issue; Privacy preserving; Face recognition,,,,,"Chen, S., Liu, Y., Gao, X., Han, Z., Mobilefacenets: Efficient cnns for accurate real-Time face verification on mobile devices (2018) Proceedings of Chinese Conference on Biometric Recognition., pp. 428-438. , Springer; Deng, J., Guo, J., Xue, N., Zafeiriou, S., Arcface: Additive angular margin loss for deep face recognition (2019) Proceedings of the Ieee Conference on Computer Vision and Pattern Recognition., pp. 4690-4699; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples., , 2014; Guo, Y., Zhang, L., Hu, Y., He, X., Gao, J., Msceleb-1m: A dataset and benchmark for large-scale face recognition (2016) Proceedings of the European Conference on Computer Vision., pp. 87-102. , Springer; Moosavi-Dezfooli, S., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) Proceedings of the Ieee Conference on Computer Vision and Pattern Recognition., pp. 1765-1773; (2019) Airport and Payment Facial Recognition Systems Fooled by Masks and Photos, Raising Security Concerns., , https://fortune.com/2019/12/12/airport-bank-facial-recognition-systems-fooled/, EFF JOHN ROBERTS., 2019; Ronneberger, O., Fischer, P., Brox, T., U-net: Convolutional networks for biomedical image segmentation (2015) Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention., pp. 234-241. , Springer; Zhang, J., Sang, J., Zhao, X., Huang, X., Sun, Y., Hu, Y., Adversarial privacy-preserving filter (2020) Proceedings of the 28th Acm International Conference on Multimedia., pp. 1423-1431",,,ACM SIGMM,"Association for Computing Machinery, Inc","29th ACM International Conference on Multimedia, MM 2021",20 October 2021 through 24 October 2021,,173350,,9.78E+12,,,English,MM - Proc. ACM Int. Conf. Multimed.,Conference Paper,Final,,Scopus,2-s2.0-85119342269
"Nguyen D.M., Nguyen A.T., Tran H.M., Le N.T., Quan T.T.",57343403000;57213904801;57343259800;57343403100;23398146600;,Physical Transferable Attack against Black-box Face Recognition Systems,2021,"2021 International Conference on Multimedia Analysis and Pattern Recognition, MAPR 2021 - Proceedings",,,,,,,,10.1109/MAPR53640.2021.9585256,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119279983&doi=10.1109%2fMAPR53640.2021.9585256&partnerID=40&md5=5d59b2e8b808dd962d9e006d8b0cbf3f,"Ho Chi Minh City University of Technology, Faculty of Computer Science and Engineering, Viet Nam National University Ho Chi Minh City, Viet Nam","Nguyen, D.M., Ho Chi Minh City University of Technology, Faculty of Computer Science and Engineering, Viet Nam National University Ho Chi Minh City, Viet Nam; Nguyen, A.T., Ho Chi Minh City University of Technology, Faculty of Computer Science and Engineering, Viet Nam National University Ho Chi Minh City, Viet Nam; Tran, H.M., Ho Chi Minh City University of Technology, Faculty of Computer Science and Engineering, Viet Nam National University Ho Chi Minh City, Viet Nam; Le, N.T., Ho Chi Minh City University of Technology, Faculty of Computer Science and Engineering, Viet Nam National University Ho Chi Minh City, Viet Nam; Quan, T.T., Ho Chi Minh City University of Technology, Faculty of Computer Science and Engineering, Viet Nam National University Ho Chi Minh City, Viet Nam","Recent studies have shown that machine learning models in general and deep neural networks like CNN, in particular, are vulnerable to adversarial attacks. Specifically, in terms of face recognition, one can easily deceive deep learning networks by adding a visually imperceptible adversarial perturbation to the input images. However, most of these works assume the ideal scenario where the attackers have perfect information about the victim model and the attack is performed in the digital domain, which is not a realistic assumption. As a result, these methods often poorly (or even impossible to) transfer to the real world. To address this issue, we propose a novel physical transferable attack method on deep face recognition systems that can work in real-world settings without any knowledge about the victim model. Our experiments on various state-of-the-art models with various architectures and training losses show non-trivial attack success rates. With the observed results, we believe that our method can enable further studies on improving adversarial robustness as well as security of deep face recognition systems. © 2021 IEEE.",Adversarial Machine Learning; Deep Learning; Face Recognition,Computer vision; Deep neural networks; Adversarial machine learning; Black boxes; Deep learning; Face recognition systems; Input image; Learning network; Machine learning models; Machine-learning; Network likes; Perfect informations; Face recognition,,,,,"Taigman, Y., Yang, M., Ranzato, M., Wolf, L., Deepface: Closing the gap to human-level performance in face verification (2014) 2014 IEEE Conference on Computer Vision and Pattern Recognition, pp. 1701-1708; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2014) Intriguing Properties of Neural Networks; Goodfellow, I.J., Shlens, J., Szegedy, C., (2015) Explaining and Harnessing Adversarial Examples; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, Ser. CCS '16. Association for Computing Machinery, pp. 1528-1540; Dong, Y., Su, H., Wu, B., Li, Z., Liu, W., Zhang, T., Zhu, J., Efficient decision-based black-box adversarial attacks on face recognition (2019) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), , June; Agarwal, S., Fan, W., Farid, H., A diverse large-scale dataset for evaluating rebroadcast attacks (2018) 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), p. 19972001; Athalye, A., Engstrom, L., Ilyas, A., Kwok, K., Synthesizing robust adversarial examples Proceedings of the 35th International Conference on Machine Learning, Ser. Proceedings of Machine Learning Research, J. Dy and A. Krause, Eds., 80, pp. 284-293. , PMLR, 10-15 Jul 2018; Huang, G.B., Ramesh, M., Berg, T., Learned-Miller, E., Labeled faces in the wild: A database for studying face recognition in unconstrained environments (2007) University of Massachusetts, , Amherst, Tech. Rep. 07-49, October; Wang, J., Liu, Y., Hu, Y., Shi, H., Mei, T., Facex-zoo: A pytorh toolbox for face recognition (2021) ArXiv, , preprint arXiv:2101.04407; Schmidt, L., Santurkar, S., Tsipras, D., Talwar, K., Madry, A., Adversarially robust generalization requires more data (2018) Proceedings of the 32nd International Conference on Neural Information Processing Systems, Ser. NIPS'18. Red Hook, NY, USA: Curran Associates Inc., pp. 5019-5031; Ilyas, A., Santurkar, S., Tsipras, D., Engstrom, L., Tran, B., Madry, A., Adversarial examples are not bugs, they are features (2019) Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada, pp. 125-136; Sun, Y., Wang, X., Tang, X., Deep learning face representation from predicting 10,000 classes (2014) 2014 IEEE Conference on Computer Vision and Pattern Recognition, pp. 1891-1898; Guo, C., Gardner, J.R., You, Y., Wilson, A.G., Weinberger, K.Q., Simple black-box adversarial attacks (2019); Nezami, O.M., Chaturvedi, A., Dras, M., Garain, U., Pick-objectattack: Type-specific adversarial attack for object detection (2020); Kurakin, A., Brain, G., Openai, I.J.G., Bengio, S., Adversarial examples in the physical world (2017) Tech. Rep.; Shi, Y., Wang, S., Han, Y., Curls whey: Boosting black-box adversarial attacks (2019); Wu, D., Wang, Y., Xia, S.-T., Bailey, J., Ma, X., Skip connections matter: On the transferability of adversarial examples generated with resnets (2020); Jan, S., Messou, J., Lin, Y.-C., Huang, J.-B., Wang, G., Connecting the digital and physical world: Improving the robustness of adversarial attacks (2019) Proceedings of the AAAI Conference on Artificial Intelligence, 33, pp. 962-969. , 07; Yuan, X., He, P., Zhu, Q., Li, X., Adversarial examples: Attacks and defenses for deep learning (2018); Komkov, S., Petiushko, A., Advhat: Real-world adversarial attack on arcface face id system (2019); Huang, G.B., Ramesh, M., Berg, T., Learned-Miller, E., Labeled faces in the wild: A database for studying face recognition in unconstrained environments (2007) University of Massachusetts, , Amherst, Tech. Rep. 07-49, October; Deng, J., Guo, J., Xue, N., Zafeiriou, S., (2019) Arcface: Additive Angular Margin Loss for Deep Face Recognition; Zhang, K., Zhang, Z., Li, Z., Qiao, Y., Joint face detection and alignment using multitask cascaded convolutional networks (2016) IEEE Signal Processing Letters, 23 (10), pp. 1499-1503. , http://dx.doi.org/10.1109/LSP.2016.2603342, Oct; Guo, Y., Zhang, L., Hu, Y., He, X., Gao, J., Ms-celeb-1m: A dataset and benchmark for large-scale face recognition (2016) ECCV; Chen, S., Liu, Y., Gao, X., Han, Z., Mobilefacenets: Efficient cnns for accurate real-time face verification on mobile devices (2018); He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2015); Hu, J., Shen, L., Albanie, S., Sun, G., Wu, E., Squeeze-and-excitation networks (2019); Wang, J., Sun, K., Cheng, T., Jiang, B., Deng, C., Zhao, Y., Liu, D., Xiao, B., Deep high-resolution representation learning for visual recognition (2020); Tan, M., Le, Q.V., Efficientnet: Rethinking model scaling for convolutional neural networks (2020); Hu, Y., Wu, X., He, R., Tf-nas: Rethinking three search freedoms of latency-constrained differentiable neural architecture search (2020); Han, K., Wang, Y., Tian, Q., Guo, J., Xu, C., Xu, C., Ghostnet: More features from cheap operations (2020); Wang, F., Jiang, M., Qian, C., Yang, S., Li, C., Zhang, H., Wang, X., Tang, X., Residual attention network for image classification (2017); Zhang, H., Wu, C., Zhang, Z., Zhu, Y., Lin, H., Zhang, Z., Sun, Y., Smola, A., Resnest: Split-attention networks (2020); Wang, X., Zhang, S., Wang, S., Fu, T., Shi, H., Mei, T., Mis-classified vector guided softmax loss for face recognition (2019); Wang, F., Cheng, J., Liu, W., Liu, H., Additive margin softmax for face verification (2018) IEEE Signal Processing Letters, 25 (7), pp. 926-930. , http://dx.doi.org/10.1109/LSP.2018.2822810, Jul; Liu, H., Zhu, X., Lei, Z., Li, S.Z., Adaptiveface: Adaptive margin and sampling for face recognition (2019) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), , June; Zhang, X., Zhao, R., Qiao, Y., Wang, X., Li, H., Adacos: Adaptively scaling cosine logits for effectively learning deep face representations (2019); Huang, Y., Wang, Y., Tai, Y., Liu, X., Shen, P., Li, S., Li, J., Huang, F., Curricularface: Adaptive curriculum learning loss for deep face recognition (2020); Sun, Y., Cheng, C., Zhang, Y., Zhang, C., Zheng, L., Wang, Z., Wei, Y., Circle loss: A unified perspective of pair similarity optimization (2020); Zeng, D., Shi, H., Du, H., Wang, J., Lei, Z., Mei, T., Npcface: Negativepositive collaborative training for large-scale face recognition (2021); Meng, Q., Zhao, S., Huang, Z., Zhou, F., Magface: A universal representation for face recognition and quality assessment (2021)",,,,Institute of Electrical and Electronics Engineers Inc.,"4th International Conference on Multimedia Analysis and Pattern Recognition, MAPR 2021",15 October 2021 through 16 October 2021,,173321,,9.78E+12,,,English,"Int. Conf. Multimed. Anal. Pattern Recognit., MAPR - Proc.",Conference Paper,Final,,Scopus,2-s2.0-85119279983
"Pawlicki M., Choraś R.S.",57204352435;6602567934;,Preprocessing pipelines including block-matching convolutional neural network for image denoising to robustify deep reidentification against evasion attacks,2021,Entropy,23,10,1304,,,,1,10.3390/e23101304,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116795449&doi=10.3390%2fe23101304&partnerID=40&md5=102fc7f48ff628d8907b05b187758e78,"ITTI Sp. z o.o., Poznań, 61-612, Poland; Institute of Telecommunications and Computer Science, Bydgoszcz University of Science and Technology, Bydgoszcz, 85-796, Poland","Pawlicki, M., ITTI Sp. z o.o., Poznań, 61-612, Poland; Choraś, R.S., Institute of Telecommunications and Computer Science, Bydgoszcz University of Science and Technology, Bydgoszcz, 85-796, Poland","Artificial neural networks have become the go-to solution for computer vision tasks, including problems of the security domain. One such example comes in the form of reidentification, where deep learning can be part of the surveillance pipeline. The use case necessitates considering an adversarial setting—and neural networks have been shown to be vulnerable to a range of attacks. In this paper, the preprocessing defences against adversarial attacks are evaluated, including blockmatching convolutional neural network for image denoising used as an adversarial defence. The benefit of using preprocessing defences comes from the fact that it does not require the effort of retraining the classifier, which, in computer vision problems, is a computationally heavy task. The defences are tested in a real-life-like scenario of using a pre-trained, widely available neural network architecture adapted to a specific task with the use of transfer learning. Multiple preprocessing pipelines are tested and the results are promising. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",Adversarial attacks; Adversarial defences; Computer vision; Deep learning,,,,,,"Fazal, M.I., Patel, M.E., Tye, J., Gupta, Y., The past, present and future role of artificial intelligence in imaging (2018) Eur. J. Radiol, 105, pp. 246-250; Ho-Phuoc, T., (2018) CIFAR10 to compare visual recognition performance between deep neural networks and humans, , arXiv arXiv:1811.07270; Huang, G., Liu, Z., Van Der Maaten, L., Weinberger, K.Q., Densely Connected Convolutional Networks Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2261-2269. , Honolulu, HI, USA, 21–26 July 2017; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521, pp. 436-444; Wang, G., Yuan, Y., Chen, X., Li, J., Zhou, X., Learning discriminative features with multiple granularities for person reidentification Proceedings of the 26th ACM international conference on Multimedia, pp. 274-282. , Seoul, Korea, 22–26 October 2018; Luo, H., Gu, Y., Liao, X., Lai, S., Jiang, W., Bag of tricks and a strong baseline for deep person re-identification Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, pp. 1487-1495. , Long Beach, CA, USA, 16–17 June 2019; Ye, M., Shen, J., Lin, G., Xiang, T., Shao, L., Hoi, S.C., Deep Learning for Person Re-identification: A Survey and Outlook (2021) IEEE Trans. Pattern Anal. Mach. Intell, p. 1; Choraś, M., Pawlicki, M., Puchalski, D., Kozik, R., Machine learning–the results are not the only thing that matters! what about security, explainability and fairness? (2020) International Conference on Computational Science, pp. 615-628. , Springer: Cham, Switzerland; Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., (2017) On the (Statistical) Detection of Adversarial Examples, , arXiv arXiv:1702.06280; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a Defense to Adversarial Perturbations Against Deep Neural Networks (2016) Proceedings of the 2016 IEEE Symposium on Security and Privacy (SP), , San Jose, CA, USA, 22–26 May; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The Limitations of Deep Learning in Adversarial Settings (2016) Proceedings of the 2016 IEEE European Symposium on Security and Privacy (EuroS&P), , Saarbruecken, Germany, 21–24 March; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519. , Abu Dhabi, United Arab Emirates, 2–6 April 2017; Srinivas, S., Sarvadevabhatla, R.K., Mopuri, K.R., Prabhu, N., Kruthiventi, S.S., Babu, R.V., An Introduction to Deep Convolutional Neural Nets for Computer Vision (2017) Deep Learning for Medical Image Analysis, pp. 25-52. , Elsevier: Cambridge, MA, USA; Anwar, A., (2019) Difference between AlexNet, VGGNet, ResNet, and Inception, , https://towardsdatascience.com/the-w3h-of-alexnet-vggnet-resnet-and-inception-7baaaecccc96, (accessed on 10 February 2021); Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., (2014) Going Deeper with Convolutions, , arXiv arXiv:1409.4842; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778. , Las Vegas, NV, USA, 27–30 June 2016; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2017) Commun. ACM, 60, pp. 84-90; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-Scale Image Recognition, , arXiv arXiv:1409.1556; Thompson, N.C., Greenewald, K., Lee, K., Manso, G.F., (2020) The Computational Limits of Deep Learning, , arXiv arXiv:2007.05558; Kaya, A., Keceli, A.S., Catal, C., Yalic, H.Y., Temucin, H., Tekinerdogan, B., Analysis of transfer learning for deep neural network based plant classification models (2019) Comput. Electron. Agric, 158, pp. 20-29; Wang, B., Yao, Y., Viswanath, B., Zheng, H., Zhao, B.Y., With great training comes great vulnerability: Practical attacks against transfer learning Proceedings of the 27th {USENIX} Security Symposium ({USENIX} Security 18), pp. 1281-1297. , Baltimore, MD, USA, 15–17 August 2018; Davchev, T., Korres, T., Fotiadis, S., Antonopoulos, N., Ramamoorthy, S., (2019) An empirical evaluation of adversarial robustness under transfer learning, , arXiv arXiv:1905.02675; Akhtar, N., Mian, A., Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey (2018) IEEE Access, 6, pp. 14410-14430; Choraś, M., Pawlicki, M., Kozik, R., The feasibility of deep learning use for adversarial model extraction in the cybersecurity domain (2019) International Conference on Intelligent Data Engineering and Automated Learning, pp. 353-360. , Springer: Cham, Switzerland; Chakraborty, A., Alam, M., Dey, V., Chattopadhyay, A., Mukhopadhyay, D., (2018) Adversarial Attacks and Defences: A Survey, , arXiv arXiv:1810.00069; Pawlicki, M., Choraś, M., Kozik, R., Defending network intrusion detection systems against adversarial evasion attacks (2020) Future Gener. Comput. Syst, 110, pp. 148-154; Pitropakis, N., Panaousis, E., Giannetsos, T., Anastasiadis, E., Loukas, G., A taxonomy and survey of attacks against machine learning (2019) Comput. Sci. Rev, 34, p. 100199; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing properties of neural networks, , arXiv arXiv:1312.6199; Kurakin, A., Goodfellow, I., Bengio, S., Dong, Y., Liao, F., Liang, M., Pang, T., Xie, C., Adversarial Attacks and Defences Competition (2018) The NIPS ’17 Competition: Building Intelligent Systems, pp. 195-231. , Escalera, S., Weimer, M., Eds.; Springer International Publishing: Cham, Switzerland; Liu, Z., Luo, P., Wang, X., Tang, X., (2014) Deep Learning Face Attributes in the Wild, , arXiv arXiv:1411.7766; Liu, Z., Luo, P., Wang, X., Tang, X., (2016) Large-scale CelebFaces Attributes (CelebA) Dataset, , https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html, (accessed on 10 February 2021); Chakraborty, A., Alam, M., Dey, V., Chattopadhyay, A., Mukhopadhyay, D., A survey on adversarial attacks and defences (2021) CAAI Trans. Intell. Technol, 6, pp. 25-45; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 3-14. , Dallas, TX, USA, 3 November; Uesato, J., O’donoghue, B., Kohli, P., Oord, A., Adversarial risk and the dangers of evaluating against weak attacks (2018) Proceedings of the International Conference on Machine Learning, pp. 5025-5034. , PMLR, Stockholm, Sweden, 10–15 July 2018; Shafahi, A., Huang, W.R., Studer, C., Feizi, S., Goldstein, T., (2018) Are adversarial examples inevitable?, , arXiv arXiv:1809.02104; Athalye, A., Carlini, N., Wagner, D., Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples (2018) Proceedings of Machine Learning Research, Proceedings of the 35th International Conference on Machine Learning, PMLR 2018, 80, pp. 274-283. , Stockholm, Sweden, 10-15.07.2018; Dy, J., Krause, A., Eds.; JMLR: Cambridge, MA, USA; Carlini, N., Wagner, D., Towards Evaluating the Robustness of Neural Networks Proceedings of the 2017 IEEE Symposium on Security and Privacy (SP), pp. 39-57. , San Jose, CA, USA, 22–26 May 2017; Carlini, N., Athalye, A., Papernot, N., Brendel, W., Rauber, J., Tsipras, D., Goodfellow, I., Kurakin, A., (2019) On evaluating adversarial robustness, , arXiv arXiv:1902.06705; de Mello, F.L., A survey on machine learning adversarial attacks (2020) J. Inf. Secur. Cryptogr. (Enigm.), 7, pp. 1-7; Yuan, X., He, P., Zhu, Q., Li, X., Adversarial Examples: Attacks and Defenses for Deep Learning (2019) IEEE Trans. Neural Netw. Learn. Syst, 30, pp. 2805-2824; Sadeghi, K., Banerjee, A., Gupta, S.K., A system-driven taxonomy of attacks and defenses in adversarial machine learning (2020) IEEE Trans. Emerg. Top. Comput. Intell, 4, pp. 450-467; Wiyatno, R.R., Xu, A., Dia, O., de Berker, A., (2019) Adversarial examples in modern machine learning: A review, , arXiv arXiv:1911.05268; Serban, A., Poll, E., Visser, J., Adversarial examples on object recognition: A comprehensive survey (2020) ACM Comput. Surv. (CSUR), 53, pp. 1-38; Xu, H., Ma, Y., Liu, H.C., Deb, D., Liu, H., Tang, J.L., Jain, A.K., Adversarial attacks and defenses in images, graphs and text: A review (2020) Int. J. Autom. Comput, 17, pp. 151-178; Parkhi, O.M., Vedaldi, A., Zisserman, A., Deep Face Recognition (2015) Procedings of the British Machine Vision Conference 2015, , Swansea, UK, 7–10 September British Machine Vision Association: Durham, UK, 2015; 41.1–41.12; (2017) ResNet-50 Pre-trained Model for Keras, , https://www.kaggle.com/keras/resnet50, ResNet-50. (accessed on 10 February 2021); Du, J., High-Precision Portrait Classification Based on MTCNN and Its Application on Similarity Judgement (2020) J. Phys. Conf. Ser, 1518, p. 12066; Xiang, J., Zhu, G., Joint Face Detection and Facial Expression Recognition with MTCNN Proceedings of the 2017 4th International Conference on Information Science and Control Engineering (ICISCE), pp. 424-427. , Changsha, China, 21–23 July 2017; Zhang, K., Zhang, Z., Li, Z., Qiao, Y., Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks (2016) IEEE Signal Process. Lett, 23, pp. 1499-1503; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , arXiv arXiv:1706.06083; Qiu, S., Liu, Q., Zhou, S., Wu, C., Review of Artificial Intelligence Adversarial Attack and Defense Technologies (2019) Appl. Sci, 9, p. 909; Bai, T., Luo, J., Zhao, J., Wen, B., Wang, Q., (2021) Recent Advances in Adversarial Training for Adversarial Robustness, , arXiv arXiv:2102.01356; Dziugaite, G.K., Ghahramani, Z., Roy, D.M., (2016) A study of the effect of JPG compression on adversarial images, , arXiv arXiv:1608.00853; Das, N., Shanbhogue, M., Chen, S.T., Hohman, F., Chen, L., Kounavis, M.E., Chau, D.H., (2017) Keeping the Bad Guys Out: Protecting and Vaccinating Deep Learning with JPEG Compression, , arXiv arXiv:1705.02900; Zantedeschi, V., Nicolae, M.I., Rawat, A., (2017) Efficient Defenses Against Adversarial Attacks, , arXiv arXiv:1707.06728; Xu, W., Evans, D., Qi, Y., (2017) Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks, , arXiv arXiv:1704.01155; Guo, C., Rana, M., Cisse, M., van der Maaten, L., (2017) Countering Adversarial Images using Input Transformations, , arXiv arXiv:1711.00117; Ahn, B., Kim, Y., Park, G., Cho, N.I., Block-Matching Convolutional Neural Network (BMCNN): Improving CNN-Based Denoising by Block-Matched Inputs Proceedings of the 2018 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC), pp. 516-525. , Honolulu, HI, USA, 12–15 November 2018; Creswell, A., Bharath, A.A., (2017) Denoising Adversarial Autoencoders, , arXiv arXiv:1703.01220; Xu, J., Zhang, L., Zuo, W., Zhang, D., Feng, X., Patch Group Based Nonlocal Self-Similarity Prior Learning for Image Denoising Proceedings of the 2015 IEEE International Conference on Computer Vision (ICCV), pp. 244-252. , Santiago, Chile, 1–13 December 2015; Zhang, K., Zuo, W., Chen, Y., Meng, D., Zhang, L., Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising (2016) IEEE Trans. Image Process, 26, pp. 3142-3155; Salazar, A., Vergara, L., Safont, G., Generative Adversarial Networks and Markov Random Fields for oversampling very small training sets (2021) Expert Syst. Appl, 163, p. 113819","Pawlicki, M.; ITTI Sp. z o.o.Poland; 电子邮件: mpawlicki@itti.com.pl",,,MDPI,,,,,10994300,,,,English,Entropy,Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85116795449
"Zheng J., Cao Y., Wang H.",57208581991;55470280700;14055082900;,Resisting membership inference attacks through knowledge distillation,2021,Neurocomputing,452,,,114,126,,,10.1016/j.neucom.2021.04.082,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105881073&doi=10.1016%2fj.neucom.2021.04.082&partnerID=40&md5=5d4562dbfffdfdeaedf27c17f9dd0688,"Key Laboratory of High Confidence Software Technologies (MOE), Department of Computer Science and Technology, Peking University, Beijing, 100871, China; School of Computer Science and Cyber Engineering, Guangzhou University, Guangzhou, 510006, China","Zheng, J., Key Laboratory of High Confidence Software Technologies (MOE), Department of Computer Science and Technology, Peking University, Beijing, 100871, China; Cao, Y., Key Laboratory of High Confidence Software Technologies (MOE), Department of Computer Science and Technology, Peking University, Beijing, 100871, China; Wang, H., Key Laboratory of High Confidence Software Technologies (MOE), Department of Computer Science and Technology, Peking University, Beijing, 100871, China, School of Computer Science and Cyber Engineering, Guangzhou University, Guangzhou, 510006, China","Recently, membership inference attacks (MIAs) against machine learning models have been proposed. Using MIAs, adversaries can inference whether a data record is in the training set of the target model. Defense methods which use differential privacy mechanisms or adversarial training cannot handle the trade-off between privacy and utility well. Other methods based on knowledge transfer to improve model utility need public unlabeled data in the same distribution as private data, and this requirement may not be satisfied in some scenarios. To handle the trade-off between privacy and utility better, we propose two algorithms of deep learning, i.e., complementary knowledge distillation (CKD) and pseudo complementary knowledge distillation (PCKD). In CKD, the transfer data of knowledge distillation all come from the private training set, but their soft targets are generated from the teacher model which is trained using their complementary set. With similar idea, we propose PCKD which reduces the training set of each teacher model and uses model averaging to generate soft targets of transfer data. Because smaller training set leads to less utility, PCKD utilizes pre-training to improve the utility of teacher models. Experimental results on widely used datasets show that CKD and PCKD can both averagely decrease attack accuracy by nearly 25% with negligible utility loss. The training time of PCKD is nearly 40% lower than that of CKD. Compared with existing defense methods such as DMP, adversarial regularization, dropout, and DP-SGD, CKD and PCKD have great advantages on handling the trade-off between privacy and utility. © 2021 Elsevier B.V.",Deep learning; Knowledge distillation; Membership inference attacks; Membership privacy; Privacy,Data privacy; Deep learning; Distillation; Economic and social effects; Knowledge management; Network security; Deep learning; Inference attacks; Knowledge distillation; Membership inference attack; Membership privacy; Privacy; Soft targets; Teacher models; Trade off; Training sets; Personnel training; algorithm; article; averaging; deep learning; distillation; human; privacy; teacher,,,,,"Liu, X., Xia, Y., Yang, W., Yang, F., Secure and efficient querying over personal health records in cloud computing (2018) Neurocomputing, 274, pp. 99-105; Jitta, A., Klami, A., Partially hidden markov models for privacy-preserving modeling of indoor trajectories (2017) Neurocomputing, 266, pp. 196-205; Taigman, Y., Yang, M., Ranzato, M., Wolf, L., Deepface: closing the gap to human-level performance in face verification (2014) IEEE Conference on Computer Vision and Pattern Recognition, 2014, pp. 1701-1708; Shokri, R., Stronati, M., Song, C., Shmatikov, V., Membership inference attacks against machine learning models IEEE Symposium on Security and Privacy (2017) IEEE, 2017, pp. 3-18; Salem, A., Zhang, Y., Humbert, M., Fritz, M., Backes, M., ML-leaks: model and data independent membership inference attacks and defenses on machine learning models (2019) Network and Distributed System Security Symposium; Truex, S., Liu, L., Gursoy, M.E., Yu, L., Wei, W., Demystifying membership inference attacks in machine learning as a service, IEEE Transactions on Servives Computing (2019in press); Nasr, M., Shokri, R., Houmansadr, A., Comprehensive privacy analysis of deep learning: passive and active white-box inference attacks against centralized and federated learning (2019) IEEE Symposium on Security and Privacy, 2019, pp. 739-753; Hayes, J., Melis, L., Danezis, G., De Cristofaro, E., LOGAN, Membership inference attacks against generative models (2019) Proceedings on Privacy Enhancing Technologies, pp. 133-152; Long, Y., Bindschaedler, V., Wang, L., Bu, D., Wang, X., Tang, H., Gunter, C.A., Chen, K., (2018), Understanding membership inferences on well-generalized learning models, arXiv preprint arXiv:1802.04889; Yeom, S., Giacomelli, I., Fredrikson, M., Jha, S., Privacy risk in machine learning: analyzing the connection to overfitting, IEEE 31st Computer Security Foundations Symposium (2018) IEEE, 2018, pp. 268-282; Sablayrolles, A., Douze, M., Schmid, C., Ollivier, Y., Jegou, H., White-box vs black-box: Bayes optimal strategies for membership inference (2019) Proceedings of the 36th International Conference on Machine Learning, pp. 5558-5567; Abadi, M., Chu, A., Goodfellow, I., McMahan, H.B., Mironov, I., Talwar, K., Zhang, L., Deep learning with differential privacy (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 308-318; Chaudhuri, K., Monteleoni, C., Sarwate, A.D., Differentially private empirical risk minimization (2011) Journal of Machine Learning Research, 12, pp. 1069-1109; Zhang, J., Zhang, Z., Xiao, X., Yang, Y., Winslett, M., Functional mechanism: regression analysis under differential privacy (2012), 5, pp. 1364-1375. , Proceedings of the VLDB Endowment; Liu, X., Li, Q., Li, T., Private classification with limited labeled data (2017) Knowledge-Based Systems, 133, pp. 197-207; Papernot, N., Abadi, M., Erlingsson, Ú., Goodfellow, I.J., Talwar, K., Semi-supervised knowledge transfer for deep learning from private training data (2017) 5th International Conference on Learning Representations; Boulemtafes, A., Derhab, A., Challal, Y., A review of privacy-preserving techniques for deep learning (2020) Neurocomputing, 384, pp. 21-45; Dwork, C., (2006), pp. 1-12. , Differential privacy, in: Proceedings of the 33rd International Conference on Automata, Languages and Programming - Volume Part II; Dwork, C., Roth, A., The algorithmic foundations of differential privacy (2014) Foundations and Trends in Theoretical Computer Science, 9 (3-4), pp. 211-407; Shejwalkar, V., Houmansadr, A., (2019), Reconciling utility and membership privacy via knowledge distillation, arXiv preprint arXiv:1906.06589; Jayaraman, B., Evans, D., Evaluating differentially private machine learning in practice (2019), pp. 1895-1912. , 28th USENIX Security Symposium (USENIX Security 19); Nasr, M., Shokri, R., Houmansadr, A., Machine learning with membership privacy using adversarial regularization (2018) Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, pp. 634-646; Wang, C., Liu, G., Huang, H., Feng, W., Peng, K., Wang, L., Miasec: enabling data indistinguishability against membership inference attacks in mlaas (2020) IEEE Transactions on Sustainable Computing, 5, pp. 365-376; Hinton, G., Vinyals, O., Dean, J., (2015), Distilling the knowledge in a neural network, arXiv preprint arXiv:1503.02531; Furlanello, T., Lipton, Z.C., Tschannen, M., Itti, L., Anandkumar, A., Born-again neural networks (2018) Proceedings of the 35th International Conference on Machine Learning, pp. 1602-1611; Tarvainen, A., Valpola, H., Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results (2017), pp. 1195-1204. , Proceedings of the 31st International Conference on Neural Information Processing Systems, Curran Associates Inc; Pan, S.J., Yang, Q., A survey on transfer learning (2010) IEEE Transactions on Knowledge and Data Engineering, 22 (10), pp. 1345-1359; Krizhevsky, A., Hinton, G., Learning multiple layers of features from tiny images (2009), Master's thesis Department of Computer Science, University of Toronto; Ioffe, S., Szegedy, C., Batch normalization: accelerating deep network training by reducing internal covariate shift (2015) Proceedings of the 32nd International Conference on Machine Learning, pp. 448-456; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Huang, G., Liu, Z., Van Der Maaten, L., Weinberger, K.Q., Densely connected convolutional networks (2017) IEEE Conference on Computer Vision and Pattern Recognition, 2017, pp. 2261-2269; Kingma, D., Ba, J., Adam, A Method for Stochastic Optimization (2015) 3rd International Conference on Learning Representations; Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., Dropout: a simple way to prevent neural networks from overfitting (2014) Journal of Machine Learning Research, 15, pp. 1929-1958; Li, X., Chen, S., Hu, X., Yang, J., Understanding the disharmony between dropout and batch normalization by variance shift (2019) IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019, pp. 2677-2685","Cao, Y.; Key Laboratory of High Confidence Software Technologies (MOE), China; 电子邮件: caoyz@pku.edu.cn",,,Elsevier B.V.,,,,,9252312,,NRCGE,,English,Neurocomputing,Article,Final,,Scopus,2-s2.0-85105881073
"Kalnoor G., Gowrishankar S.",57191221919;57209596975;,IoT-based smart environment using intelligent intrusion detection system,2021,Soft Computing,25,17,,11573,11588,,,10.1007/s00500-021-06028-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110858217&doi=10.1007%2fs00500-021-06028-1&partnerID=40&md5=2e9827586567a2f866eb94e0c9c1d4d8,"BMS College of Engineering, Bangalore, India","Kalnoor, G., BMS College of Engineering, Bangalore, India; Gowrishankar, S., BMS College of Engineering, Bangalore, India","One of the most basic characteristic features of every smart device in a network based on the Internet of Things (IoT) is to gather a larger set of data that has been created and then transfer the gathered data to the destination/receiver server through the internet. Thus, IoT-based networks are most vulnerable to simple or complex attacks that need to be identified in the early stage of data transmission for saving the network from these malicious attacks. The chief goal of the proposed work is to design and form the intelligent intrusion detection system (I-IDS) using the machine learning models such that the attacks can be identified in the IoT network. The model is built considering the normal and malicious attacks on the data that are generated in IoT smart environment. To simulate such a model, a testbed is built where a wireless router, a DHT11 sensor, and a node MCU are being used during the design phase. An attacker or adversarial system is built to perform poisoning and sniffing attacks using a laptop system. The node captures the sensor values and transmits the data to the ThinkSpeak platform, during the normal phase via the wireless gateway, and in the attack phase, the malicious attacker interprets the data, modifies it while transmitting from node to the ThinkSpeak server. Thus, the attack called Man-In-The-Middle (MITM) is performed and classified as abnormal data. Various machine learning algorithms are performed on the data, and finally, the results obtained using a probabilistic model called as Markov model have a high performance evaluated based on the I-IDS IoT network. The results obtained during the experimental analysis show that the Markov model has obtained a 100% detection rate and 19% of false alarm rate (FAR) with high precision and low error rate. The algorithms such as naïve Bayes classifier, support vector machine (SVM), decision tree, and Adaboost are considered in comparison with the Markov model. The optimal solution is obtained concerning other evaluation metrics like sensitivity, F1, and true-positive rate (TPR). Therefore, the integrated network of IoT-WSN with its performance metrics is tabulated to show the potentials of securing a network system. Additionally, the proposed work gives a high level of security for IoT smart environment as compared with the other machine learning algorithms using the novel technique of intelligent IDS. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",Cloud computing; Computing; Fog computing; Internet of Things (IoT); Intrusion detection; Security; Wireless sensor network (WSN),Adaptive boosting; Computer crime; Data communication systems; Decision trees; Gateways (computer networks); Intrusion detection; Learning systems; Markov processes; Network security; Routers; Support vector machines; Basic characteristics; Experimental analysis; Intelligent Intrusion detection systems; Internet of thing (IOT); Machine learning models; Man in the middles (MITM); Probabilistic modeling; True positive rates; Internet of things,,,,,"Alaparthy, V.T., Morgera, S.D., A multi_level intrusion detection system for wireless sensor networks based on immune theory (2018) IEEE Access, 6, pp. 47364-47373; Ammar, M., Russello, G., Crispo, B., Internet of Things: a survey on the security of IoT frameworks (2018) J Inf Secure Appl, 38, pp. 8-27; Arshad, J., Azad, M.A., Abdeltaif, M.M., Salah, K., An intrusion detection framework for energy-constrained IoT devices (2020) Mech Syst Signal Process, 136, p. 106436; Breitenbacher, D., Homoliak, I., Aung, Y.L., Tippenhauer, N.O., Elovici, Y., HADES-IoT: A practical host-based anomaly detection system for IoT devices (2019) Proc. ACM Asia Conf. Comput. Commun. Secur., Auckland, New Zealand, P.; Chaabouni, N., Mosbah, M., Zemmari, A., Sauvignac, C., Faruki, P., Network intrusion detection for IoT security based on learning techniques (2019) IEEE Commun. Surv. Tutor., 21, pp. 2671-2701; Challa, S., Wazid, M., Das, A.K., Kumar, N., Reddy, A.G., Yoon, E.-J., Yoo, K.-Y., Secure signature-based authenticated key establishment scheme for future IoT applications (2017) IEEE Access, 5, pp. 3028-3043; Challa, S., Wazid, M., Das, A.K., Khan, M.K., Authentication protocols for implantable medical devices: taxonomy, analysis, and future directions (2018) IEEE Consum Electron Mag, 7 (1), pp. 57-65; (2019) Top 20 Best Internet of Things Projects (IoT Projects) that you can make right now., , https://www.ubuntupit.com/best-internet-of-things%20projects-%20iot-projects-that-you-can-make-right-now, Accessed: Oct. 2019. [Online]. Available; Das, A.K., Zeadally, S., He, D., Taxonomy and analysis of security protocols for the Internet of Things (2018) Future Gener Comput Syst, 89, pp. 110-125; Diechmann, J., Heineke, K., Reinbacher, T., Wee, D., The Internet of Things: How to capture the value of IoT (2015) Technical Report, pp. 1-124. , https://www.mckinsey.com/featured-insights/internet-of-things/our-insights/the-internet-of-things-how-to-capture-the-value-of-iot#, Available online:, (Accessed on 13 July 2020); Elrawy, M.F., Awad, A.I., Hamed, H.F.A., Intrusion detection systems for IoT-based smart environments: a survey (2018) J Cloud Comput, 7 (1), p. 21; Fan, X., Susan, F., Long, W., Li, S., (2017) Security analysis of Zigbee, , https://courses.csail.mit.edu/6.857/2017/project/17.pdf, Available online:, (accessed on 13 July 2020); Faria, E.R., Gonçalves, I.J.C.R., de Carvalho, A.C.P.L.F., Gama, J., Novelty detection in data streams (2016) Artif Intell Rev, 45 (2), pp. 235-269; Fremantle P (2015) A reference architecture for the Internet of Things. WSO2 White Paper. 2015. Available online: https://docs.huihoo.com/wso2/wso2-whitepaper-a-reference-architecture-for-the-internet-of-things.pdf (accessed on 13 July 2020); Jan, S.U., Ahmed, S., Shakhov, V., Koo, I., Toward a lightweight intrusion detection system for the Internet of Things (2019) IEEE Access, 7, pp. 42450-42471; Kiwanuka, F.N., Akhtar, I.A., Improving event monitoring in IoT network using an integrated blockchain-distributed pattern recognition scheme (2019) Blockchain and Applications: International Congress, 1010. , Springer; Košt’Ál, K., Helebrandt, P., Belluš, M., Ries, M., Kotuliak, I., Management and Monitoring of IoT Devices Using Blockchain (2019) Sensors, 19, p. 856; Lawal, M.A., Shaikh, R.A., Hassan, S.R., Security analysis of network anomalies mitigation schemes in IoT networks (2020) IEEE Access, 8, pp. 43355-43374; Li, W., Tug, S., Meng, W., Wang, Y., Designing collaborative block chained signature-based intrusion detection in IoT environments (2019) Future Gener Comput Syst, 96, p. 481489; Moustafa, N., Choo, K.K.R., Radwan, I., Camtepe, S., Outlier dirichlet mixture mechanism: adversarial statistical learning for anomaly detection in the fog (2019) IEEE Trans Inf Forensics Secur, 14, pp. 1975-1987; Mudgerikar, A., Sharma, P., Bertino, E., E-spion: A system-level intrusion detection system for IoT devices (2019) Proc. ACM Asia Conf. Comput. Commun. Secur., Auckland, New Zealand, P.; Nesterenko, N., Bou-Harb, E., Crichigno, J., Kaddoum, G., Ghani, N., Demystifying IoT security: an exhaustive survey on IoT vulnerabilities and a first empirical look on internet-scale IoT exploitations (2019) IEEE Commun Surv Tutor, 21, pp. 2702-2733; Pajouh, H.H., Javidan, R., Khayami, R., Dehghantanha, A., Choo, K.-K.-R., A two-layer dimension reduction and two-tier classification model for anomaly-based intrusion detection in IoT backbone networks (2019) IEEE Trans Emerg Topics Comput, 7 (2), p. 314323; Raoof, A., Matrawy, A., Lung, C.-H., Routing attacks and mitigation methods for RPLbased Internet of Things (2019) IEEE Commun Surv Tuts, 21 (2), pp. 1582-1606; Selvakumar, K., Karuppiah, M., Sairamesh, L., Islam, S.H., Hassan, M.M., Fortino, G., Choo, K.-K.-R., Intelligent temporal classification and fuzzy rough set-based feature selection algorithm for intrusion detection system in WSNs (2019) Inf Sci, 497, pp. 77-90; Sharma, V., You, I., Yim, K., Chen, I.-R., Cho, J.-H., BRIoT: behavior rule specification_based misbehavior detection for IoT_embedded cyber_physical systems (2019) IEEE Access, 7, pp. 118556-118580; Sivasakthiselvan, S., Nagarajan, V., Energy-efficient data gathering by using optimum pattern recognition with relocalization in mobile wireless sensor networks (2017) J ICT Stand, 5 (2), pp. 129-148; Sun, T., Yu, W., A formal verification framework for security issues of blockchain smart contracts (2020) Electronics, 9, p. 255; Sun, Z., Xu, Y., Liang, G., Zhou, Z., An intrusion-detection model for wireless sensor networks with an improved V_detector algorithm (2018) IEEE Sensors J, 18 (5), pp. 1971-1984; Wazid, M., Design and analysis of intrusion detection protocols for hierarchical wireless sensor networks. Ph.D. dissertation, Centre Secure., Theory Algorithmic Res., Int. Inst. Inf (2017) Technol., , Hyderabad, India; Wazid, M., (2017) Design and analysis of intrusion detection protocols for hierarchical wireless sensor networks, , . Ph.D. dissertation, Center Secur., Theory Algorithmic Res., Int. Inst. Inf. Technol., Hyderabad, India; Wazid, M., Das, A.K., A secure group_based blackhole node detection scheme for hierarchical wireless sensor networks (2017) Wirel Pers Commun, 94 (3), pp. 1165-1191; Wazid, M., Bagga, P., Das, A.K., Shetty, S., Rodrigues, J.J.P.C., Park, Y., AKM_IoV: authenticated key management protocol in fog computing-based internet of vehicles deployment (2019) IEEE Internet Things J, 6 (5), pp. 8804-8817; Wazid, M., Reshma Dsouza, P., Das, A.K., Bhat, V., Rodrigues, J.J.P.C., RAD_EI: a routing attack detection scheme for edge-based internet of things environment (2019) Int J Commun Syst, 32 (15); Wheelus, C., Zhu, X., IoT network security: threats, risks, and a data-driven defense framework (2020) IoT, 1 (2), pp. 259-285","Kalnoor, G.; BMS College of EngineeringIndia; 电子邮件: kalnoor.gauri@gmail.com",,,Springer Science and Business Media Deutschland GmbH,,,,,14327643,,,,English,Soft Comput.,Article,Final,,Scopus,2-s2.0-85110858217
"Jan M.A., Khan F., Mastorakis S., Adil M., Akbar A., Stergiou N.",55843090400;57188879276;56879181900;57215830410;57195515723;7004254944;,LightIoT: Lightweight and secure communication for energy-efficient IoT in health informatics,2021,IEEE Transactions on Green Communications and Networking,5,3,9422780,1202,1211,,5,10.1109/TGCN.2021.3077318,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105881035&doi=10.1109%2fTGCN.2021.3077318&partnerID=40&md5=e04b2c656dd92db263ac35b885a5e24d,"Department of Computer Science, Abdul Wali Khan University Mardan, Mardan, 23200, Pakistan; Department of Computer Science, University of Nebraska at Omaha, Omaha, NE  68182, United States; Department of Computer Science, Virtual University of Pakistan, Lahore, 54000, Pakistan; Department of Biomechanics, University of Nebraska at Omaha, Omaha, NE  68182, United States","Jan, M.A., Department of Computer Science, Abdul Wali Khan University Mardan, Mardan, 23200, Pakistan; Khan, F., Department of Computer Science, Abdul Wali Khan University Mardan, Mardan, 23200, Pakistan; Mastorakis, S., Department of Computer Science, University of Nebraska at Omaha, Omaha, NE  68182, United States; Adil, M., Department of Computer Science, Virtual University of Pakistan, Lahore, 54000, Pakistan; Akbar, A., Department of Computer Science, Abdul Wali Khan University Mardan, Mardan, 23200, Pakistan; Stergiou, N., Department of Biomechanics, University of Nebraska at Omaha, Omaha, NE  68182, United States","Internet of Things (IoT) is considered as a key enabler of health informatics. IoT-enabled devices are used for in-hospital and in-home patient monitoring to collect and transfer biomedical data pertaining to blood pressure, electrocardiography (ECG), blood sugar levels, body temperature, etc. Among these devices, wearables have found their presence in a wide range of healthcare applications. These devices generate data in real-time and transmit them to nearby gateways and remote servers for processing and visualization. The data transmitted by these devices are vulnerable to a range of adversarial threats, and as such, privacy and integrity need to be preserved. In this paper, we present LightIoT, a lightweight and secure communication approach for data exchanged among the devices of a healthcare infrastructure. LightIoT operates in three phases: initialization, pairing, and authentication. These phases ensure the reliable transmission of data by establishing secure sessions among the communicating entities (wearables, gateways and a remote server). Statistical results exhibit that our scheme is lightweight, robust, and resilient against a wide range of adversarial attacks and incurs much lower computational and communication overhead for the transmitted data in the presence of existing approaches. © 2017 IEEE.",authentication; energy-efficient IoT; Health informatics; lightweight communication; wearables,Blood; Blood pressure; Data transfer; Data visualization; Electrocardiography; Electronic data interchange; Energy efficiency; Gateways (computer networks); Health care; Medical informatics; Patient monitoring; Secure communication; Wearable technology; Blood sugar levels; Body temperature; Communication overheads; Energy efficient; Health care application; Healthcare infrastructure; Internet of Things (IOT); Reliable transmission; Internet of things,,,,,"Jan, M.A., A lightweight mutual authentication and privacypreservation scheme for intelligent wearable devices in industrial-CPS (2020) IEEE Trans. Ind. Informat., , early access, Dec. 10; Rehman, M.A.U., Ullah, R., Kim, B.-S., Nour, B., Mastorakis, S., CCIC-WSN: An architecture for single channel cluster-based information-centric wireless sensor networks (2021) IEEE Internet Things J., 8 (95), pp. 7661-7675. , May; Jan, M.A., Security and blockchain convergence with Internet of Multimedia Things: Current trends, research challenges and future directions (2021) J. Netw. Comput. Appl., 175. , Feb; Mastorakis, S., Mtibaa, A., Lee, J., Misra, S., ICedge: When edge computing meets information-centric networking (2020) IEEE Internet Things J., 7 (5), pp. 4203-4217. , May; Al-Turjman, F., Alturjman, S., Context-sensitive access in Industrial Internet of Things (IIOT) healthcare applications (2018) IEEE Trans. Ind. Informat., 14 (6), pp. 2736-2744. , Jun; Jan, M.A., An AI-enabled lightweight data fusion and load optimization approach for Internet of Things (2021) Future Gener. Comput. Syst., 122, pp. 40-51. , Sep; Fitbit, W., (2019) Find A Fit for Everybody, , https://www.fitbit.com/whyfitbit, Accessed: Aug. 27; Bader, F., Jagtap, S., (2019) Internet of Things Linked Wearable Devices for Managing Food Safety in the Healthcare Sector, , Cambridge, MA, USA: Academic Press; Banerjee, S., Hemphill, T., Longstreet, P., Wearable devices and healthcare: Data sharing and privacy (2018) Inf. Soc., 34 (1), pp. 49-57; Mastorakis, S., Zhong, X., Huang, P.-C., Tourani, R., DLWIOT: Deep learning-based watermarking for authorized iot onboarding (2021) Proc. IEEE 18th Annu. Consum. Commun. Netw. Conf. (CCNC), pp. 1-7; Zhang, K., Ni, J., Yang, K., Liang, X., Ren, J., Shen, X.S., Security and privacy in smart city applications: Challenges and solutions (2017) IEEE Commun. Mag., 55 (1), pp. 122-129. , Jan; Jan, M.A., Khan, F., Alam, M., Usman, M., A payload-based mutual authentication scheme for Internet of Things (2019) Future Gener. Comput. Syst., 92, pp. 1028-1039. , Mar; He, D., Zeadally, S., Kumar, N., Lee, J.-H., Anonymous authentication for wireless body area networks with provable security (2017) IEEE Syst. J., 11 (4), pp. 2590-2601. , Dec; Yao, W., A secured and efficient communication scheme for decentralized cognitive radio-based Internet of Vehicles (2019) IEEE Access, 7, pp. 160889-160900; Khan, F., Jan, M.A., Rehman, A.U., Mastorakis, S., Alazab, M., Watters, P., A secured and intelligent communication scheme for IIOTenabled pervasive edge computing (2021) IEEE Trans. Ind. Informat., 17 (7), pp. 5128-5137. , Jul; Mastorakis, S., Li, T., Zhang, L., DAPES: Named Data for Off-The-Grid File Sharing with Peer-to-Peer Interactions (2020) Proc. 40th IEEE Int. Conf. Distrib. Comput. Syst. (ICDCS), pp. 710-720; Wong, K.H., Zheng, Y., Cao, J., Wang, S., A dynamic user authentication scheme for wireless sensor networks (2006) Proc. IEEE Int. Conf. Sensor Netw. Ubiquitous Trustworthy Comput. (SUTC), 1, pp. 244-251; Liu, J., Zhang, Z., Chen, X., Kwak, K.S., Certificateless remote anonymous authentication schemes for wirelessbody area networks (2014) IEEE Trans. Parallel Distrib. Syst., 25 (2), pp. 332-342. , Feb; Das, A.K., Wazid, M., Kumar, N., Khan, M.K., Choo, K.-K.R., Park, Y., Design of secure and lightweight authentication protocol for wearable devices environment (2018) IEEE J. Biomed. Health Inform., 22 (4), pp. 1310-1322. , Jul; Diez, F.P., Touceda, D.S., Camara, J.M.S., Zeadally, S., Toward self-authenticable wearable devices (2015) IEEE Wireless Commun., 22 (1), pp. 36-43. , Feb; Wu, F., Li, X., Xu, L., Kumari, S., Karuppiah, M., Shen, J., A lightweight and privacy-preserving mutual authentication scheme for wearable devices assisted by cloud server (2017) Comput. Elect. Eng., 63, pp. 168-181. , Oct; Chang, C.-C., Le, H.-D., A provably secure, efficient, and flexible authentication scheme for ad hoc wireless sensor networks (2016) IEEE Trans. Wireless Commun., 15 (1), pp. 357-366. , Jan; Das, A.K., Kumari, S., Odelu, V., Li, X., Wu, F., Huang, X., Provably secure user authentication and key agreement scheme for wireless sensor networks (2016) Secur. Commun. Netw., 9 (16), pp. 3670-3687; He, J., Yang, Z., Zhang, J., Liu, W., Liu, C., On the security of a provably secure, efficient, and flexible authentication scheme for ad hoc wireless sensor networks (2018) Int. J. Distrib. Sensor Netw., 14 (1), pp. 1-11; Aghili, S.F., Mala, H., Kaliyar, P., Conti, M., SecLAP: Secure and lightweight RFID authentication protocol for medical IoT (2019) Future Gener. Comput. Syst., 101, pp. 621-634. , Dec; Turkanović, M., Brumen, B., Hölbl, M., A novel user authentication and key agreement scheme for heterogeneous ad hoc wireless sensor networks, based on the Internet of Things notion (2014) Ad Hoc Netw., 20, pp. 96-112. , Sep; Amin, R., Biswas, G., A secure light weight scheme for user authentication and key agreement in multi-gateway based wireless sensor networks (2016) Ad Hoc Netw., 36, pp. 58-80. , Jan; Amin, R., Islam, S.H., Biswas, G., Khan, M.K., Kumar, N., A robust and anonymous patient monitoring system using wireless medical sensor networks (2018) Future Gener. Comput. Syst., 80, pp. 483-495. , Mar; Jiang, Q., Ma, J., Yang, C., Ma, X., Shen, J., Chaudhry, S.A., Efficient end-to-end authentication protocol for wearable health monitoring systems (2017) Comput. Elect. Eng., 63, pp. 182-195. , Oct; Ali, R., Pal, A.K., Kumari, S., Karuppiah, M., Conti, M., A secure user authentication and key-agreement scheme using wireless sensor networks for agriculture monitoring (2018) Future Gener. Comput. Syst., 84, pp. 200-215. , Jul; Li, X., Niu, J., Bhuiyan, M.Z.A., Wu, F., Karuppiah, M., Kumari, S., A robust ECC-based provable secure authentication protocol with privacy preserving for industrial Internet of Things (2018) IEEE Trans. Ind. Electron., 14 (8), pp. 3599-3609. , Aug; Wu, F., A lightweight and robust two-factor authentication scheme for personalized healthcare systems using wireless medical sensor networks (2018) Future Gener. Comput. Syst., 82, pp. 727-737. , May; Mastorakis, S., (2019) Peer-to-peer Data Sharing in Named Data Networking, , Ph.D. dissertation, UCLA, Oakland, CA, USA; Yang, G., Jan, M.A., Menon, V.G., Shynu, P., Aimal, M.M., Alshehri, M.D., A centralized cluster-based hierarchical approach for green communication in a smart healthcare system (2020) IEEE Access, 8, pp. 101464-101475; Abbasi, M., Rezaei, H., Menon, V.G., Qi, L., Khosravi, M.R., Enhancing the performance of flow classification in SDN-based intelligent vehicular networks (2020) IEEE Trans. Intell. Transp. Syst., , early access, Aug. 13; Zhang, H., Babar, M., Tariq, M.U., Jan, M.A., Menon, V.G., Li, X., SafeCity: Toward safe and secured data management design for iotenabled smart city planning (2020) IEEE Access, 8, pp. 145256-145267; Li, T., Kong, Z., Mastorakis, S., Zhang, L., Distributed dataset synchronization in disruptive networks (2019) Proc. IEEE 16th Int. Conf. Mobile Ad Hoc Sensor Syst. (MASS), pp. 428-437; Abbasi, M., Najafi, A., Rafiee, M., Khosravi, M.R., Menon, V.G., Muhammad, G., Efficient flow processing in 5g-envisioned SDN-based Internet of Vehicles using GPUS (2020) IEEE Trans. Intell. Transp. Syst., , early access, Dec. 7; Li, X., Ibrahim, M.H., Kumari, S., Sangaiah, A.K., Gupta, V., Choo, K.-K.R., Anonymous mutual authentication and key agreement scheme for wearable sensors in wireless body area networks (2017) Comput. Netw., 129, pp. 429-443. , Dec; Jan, M.A., Usman, M., He, X., Rehman, A.U., SAMS: A seamless and authorized multimedia streaming framework for WMSN-based IoMT (2019) IEEE Internet Things J., 6 (2), pp. 1576-1583. , Apr; Gope, P., Hwang, T., A realistic lightweight anonymous authentication protocol for securing real-time application data access in wireless sensor networks (2016) IEEE Trans. Ind. Electron., 63 (11), pp. 7124-7132. , Nov","Khan, F.; Department of Computer Science, Pakistan; 电子邮件: fazlullah@awkum.edu.pk
Mastorakis, S.; Department of Computer Science, United States; 电子邮件: smastorakis@unomaha.edu",,,Institute of Electrical and Electronics Engineers Inc.,,,,,24732400,,,,English,IEEE Trans. Green Commun. Networking,Article,Final,"All Open Access, Green",Scopus,2-s2.0-85105881035
"Ding K., Liu X., Niu W., Hu T., Wang Y., Zhang X.",57217391606;57192919250;56417209400;57207918876;57204077526;55715736700;,A low-query black-box adversarial attack based on transferability,2021,Knowledge-Based Systems,226,,107102,,,,1,10.1016/j.knosys.2021.107102,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107012591&doi=10.1016%2fj.knosys.2021.107102&partnerID=40&md5=e334c5993cbc97380bdef0d1274817bd,"Institute for Cyber Security, School of Computer Science and Engineering, University of Electronic Science and Technology of China, China; Institute of Computer Application, China Academy of Engineering Physics, China; Cyberspace Security Research Center, Peng Cheng Laboratory, China","Ding, K., Institute for Cyber Security, School of Computer Science and Engineering, University of Electronic Science and Technology of China, China; Liu, X., Institute of Computer Application, China Academy of Engineering Physics, China; Niu, W., Institute for Cyber Security, School of Computer Science and Engineering, University of Electronic Science and Technology of China, China; Hu, T., Institute for Cyber Security, School of Computer Science and Engineering, University of Electronic Science and Technology of China, China, Institute of Computer Application, China Academy of Engineering Physics, China; Wang, Y., Institute for Cyber Security, School of Computer Science and Engineering, University of Electronic Science and Technology of China, China; Zhang, X., Institute for Cyber Security, School of Computer Science and Engineering, University of Electronic Science and Technology of China, China, Cyberspace Security Research Center, Peng Cheng Laboratory, China","Artificial intelligence systems suffer from black-box adversarial attacks recently. To prevent this kind of attack, a large amount of researches that reveal the nature of this attack has emerged. However, the query count, success rate, and distortion in the existing works cannot fully satisfy the practical purposes. In this paper, we propose a low-query black-box adversarial attack based on transferability by combining the optimization-based method and the transfer-based method. Our approach aims to improve the black-box attack with a lower number of queries, higher success rate, and lower distortion. In addition, we make full use of surrogate models and optimize the objective function to further improve the performance of our algorithm. We verified our method on MNIST (Lecun and Bottou, 1998) [1], CIFAR-10 (Krizhevsky et al., 2009) [2], and ImageNet (Deng et al. 2009) [3], respectively. Experimental results demonstrate that our method can implement a black-box attack with more than 98.5% success rate and achieve specific distortion with less than 5% queries comparing with other state-of-the-art methods. © 2021 Elsevier B.V.",Adversarial sample; Black-box attack; Neural network; Transferability,Software engineering; Adversarial sample; Artificial intelligence systems; Black boxes; Black-box attack; Large amounts; Low-distortion; Neural-networks; Optimization based methods; Rate distortions; Transferability; Neural networks,,,,,"Lecun, Y., Bottou, L., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324; Krizhevsky, A., Hinton, G., Learning Multiple Layers of Features from Tiny Images (2009), Citeseer; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., Imagenet: A large-scale hierarchical image database (2009) 2009 IEEE Conference on Computer Vision and Pattern Recognition, pp. 248-255. , Ieee; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2014); He, K., Zhang, X., Ren, S., Jian, S., Deep residual learning for image recognition (2016), IEEE Conference on Computer Vision & Pattern Recognition; Yurtsever, E., Lambert, J., Carballo, A., Takeda, K., A survey of autonomous driving: Common practices and emerging technologies (2020) IEEE Access, 8, pp. 58443-58469; Huang, Y., Chen, Y., Autonomous driving with deep learning: A survey of state-of-art technologies (2020), arXiv preprint; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput., 9 (8), pp. 1735-1780; Collobert, R., Weston, J., A unified architecture for natural language processing: Deep neural networks with multitask learning (2008), pp. 160-167. , Proceedings of the 25th International Conference on Machine Learning; Bahdanau, D., Cho, K., Bengio, Y., Neural machine translation by jointly learning to align and translate (2014), arXiv preprint; Silver, D., Huang, A., Maddison, C.J., Guez, A., Sifre, L., Van Den Driessche, G., Schrittwieser, J., Lanctot, M., Mastering the game of go with deep neural networks and tree search (2016) Nature, 529 (7587), pp. 484-489; Berner, C., Brockman, G., Chan, B., Cheung, V., Dębiak, P., Dennison, C., Farhi, D., Hesse, C., Dota 2 with large scale deep reinforcement learning (2019), arXiv preprint; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016), pp. 2818-2826. , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2013), arXiv preprint; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2014), arXiv preprint; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) 2016 IEEE European Symposium on Security and Privacy (EuroS&P), pp. 372-387. , IEEE; Liu, X., Hu, T., Ding, K., Bai, Y., Niu, W., Lu, J., A black-box attack on neural networks based on swarm evolutionary algorithm (2020) Australasian Conference on Information Security and Privacy, pp. 268-284. , Springer; Selvaraju, R.R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., Batra, D., Grad-cam: Visual explanations from deep networks via gradient-based localization (2017), pp. 618-626. , Proceedings of the IEEE International Conference on Computer Vision; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016), pp. 1528-1540. , Proceedings of the 2016 Acm Sigsac Conference on Computer and Communications Security; Liu, X., Wan, K., Ding, Y., Zhang, X., Zhu, Q., Weighted-sampling audio adversarial example attack (2020) AAAI, pp. 4908-4915; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) 2016 IEEE Symposium on Security and Privacy (SP), pp. 582-597. , IEEE; Yu, Y., Yu, P., Li, W., Auxblocks: Defense adversarial examples via auxiliary blocks (2019) 2019 International Joint Conference on Neural Networks (IJCNN), pp. 1-8. , IEEE; Gopinath, D., Katz, G., Pasareanu, C.S., Barrett, C., Deepsafe: A data-driven approach for checking adversarial robustness in neural networks (2017), arXiv preprint; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2017), arXiv preprint; Kannan, H., Kurakin, A., Goodfellow, I., Adversarial logit pairing (2018), arXiv preprint; Liao, F., Liang, M., Dong, Y., Pang, T., Hu, X., Zhu, J., Defense against adversarial attacks using high-level representation guided denoiser (2018), pp. 1778-1787. , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Jia, X., Wei, X., Cao, X., Foroosh, H., Comdefend: An efficient image compression model to defend adversarial examples (2019), pp. 6084-6092. , Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition; Frosst, N., Sabour, S., Hinton, G., Darccc: Detecting adversaries by reconstruction from class conditional capsules (2018), arXiv preprint; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: a simple and accurate method to fool deep neural networks (2016), pp. 2574-2582. , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 Ieee Symposium on Security and Privacy (Sp), pp. 39-57. , IEEE; Chaturvedi, I., Ong, Y.-S., Arumugam, R.V., Deep transfer learning for classification of time-delayed Gaussian networks (2015) Signal Process., 110, pp. 250-262; Weiss, K., Khoshgoftaar, T.M., Wang, D., A survey of transfer learning (2016) J. Big data, 3 (1), pp. 1-40; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2016), arXiv preprint; Shi, Y., Wang, S., Han, Y., (2019), pp. 6519-6527. , Curls & whey: Boosting black-box adversarial attacks, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017), pp. 15-26. , Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security; Tu, C.-C., Ting, P., Chen, P.-Y., Liu, S., Zhang, H., Yi, J., Hsieh, C.-J., Cheng, S.-M., Autozoom: Autoencoder-based zeroth order optimization method for attacking black-box neural networks (2019), 33, pp. 742-749. , Proceedings of the AAAI Conference on Artificial Intelligence; Ilyas, A., Engstrom, L., Athalye, A., Lin, J., Black-box adversarial attacks with limited queries and information (2018), arXiv preprint; Brendel, W., Rauber, J., Bethge, M., Decision-based adversarial attacks: Reliable attacks against black-box machine learning models (2017), arXiv preprint; Chen, J., Jordan, M.I., Wainwright, M.J., Hopskipjumpattack: A query-efficient decision-based attack (2020) 2020 IEEE Symposium on Security and Privacy (SP), pp. 1277-1294. , IEEE; Brunner, T., Diehl, F., Le, M.T., Knoll, A., Guessing smart: Biased sampling for efficient black-box adversarial attacks (2019), pp. 4958-4966. , Proceedings of the IEEE International Conference on Computer Vision; Cheng, S., Dong, Y., Pang, T., Su, H., Zhu, J., Improving black-box adversarial attacks with a transfer-based prior (2019) Advances in Neural Information Processing Systems, pp. 10934-10944; Suya, F., Chi, J., Evans, D., Tian, Y., Hybrid batch attacks: Finding black-box adversarial examples with limited queries (2020) 29th {USENIX} Security Symposium ({USENIX} Security 20), pp. 1327-1344; Kingma, D.P., Ba, J., Adam: A method for stochastic optimization (2014), arXiv preprint; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A., Inception-v4, inception-resnet and the impact of residual connections on learning (2017), 31. , Proceedings of the AAAI Conference on Artificial Intelligence; Zoph, B., Vasudevan, V., Shlens, J., Le, Q.V., Learning transferable architectures for scalable image recognition (2018), pp. 8697-8710. , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Chollet, F., Xception: Deep learning with depthwise separable convolutions (2017), pp. 1251-1258. , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Huang, G., Liu, Z., Van Der Maaten, L., Weinberger, K.Q., (2017), pp. 4700-4708. , Densely connected convolutional networks, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., Chen, L.-C., Mobilenetv2: Inverted residuals and linear bottlenecks (2018), pp. 4510-4520. , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition","Zhang, X.; Institute for Cyber Security, China; 电子邮件: johnsonzxs@uestc.edu.cn",,,Elsevier B.V.,,,,,9507051,,KNSYE,,English,Knowl Based Syst,Article,Final,,Scopus,2-s2.0-85107012591
"Löwe M., Villareale J., Freed E., Sladek A., Zhu J., Risi S.",57203490987;57211159962;57194283372;57219796958;43261949300;35240753900;,Dealing with Adversarial Player Strategies in the Neural Network Game iNNk through Ensemble Learning,2021,ACM International Conference Proceeding Series,,,,,,,,10.1145/3472538.3472540,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118258527&doi=10.1145%2f3472538.3472540&partnerID=40&md5=79e204bc9ca4f2fc9da65d1e52742d08,"It University of Copenhagen, Copenhagen, Denmark; Drexel University, Philadelphia, PA, United States","Löwe, M., It University of Copenhagen, Copenhagen, Denmark; Villareale, J., Drexel University, Philadelphia, PA, United States; Freed, E., Drexel University, Philadelphia, PA, United States; Sladek, A., Drexel University, Philadelphia, PA, United States; Zhu, J., Drexel University, Philadelphia, PA, United States; Risi, S., It University of Copenhagen, Copenhagen, Denmark","Applying neural network (NN) methods in games can lead to various new and exciting game dynamics not previously possible. However, they also lead to new challenges such as the lack of large, clean datasets, varying player skill levels, and changing gameplay strategies. In this paper, we focus on the adversarial player strategy aspect in the game iNNk, in which players try to communicate secret code words through drawings with the goal of not being deciphered by a NN. Some strategies exploit weaknesses in the NN that consistently trick it into making incorrect classifications, leading to unbalanced gameplay. We present a method that combines transfer learning and ensemble methods to obtain a data-efficient adaptation to these strategies. This combination significantly outperforms the baseline NN across all adversarial player strategies despite only being trained on a limited set of adversarial examples. We expect the methods developed in this paper to be useful for the rapidly growing field of NN-based games, which will require new approaches to deal with unforeseen player creativity. © 2021 ACM.",adversarial attacks; ensemble methods; games; neural networks; transfer learning,Interactive computer graphics; Learning systems; Adversarial attack; Ensemble learning; Ensemble methods; Game; Gameplay; Network game; Neural network method; Neural-networks; Skill levels; Transfer learning; Large dataset,,,,,"Abbasi, M., Gagné, C., (2017) Robustness to Adversarial Examples through An Ensemble of Specialists; Alcorn, M.A., Li, Q., Gong, Z., Wang, C., Mai, L., Ku, W., Nguyen, A., Strike (with) a pose: Neural networks are easily fooled by strange poses of familiar objects (2019) 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4840-4849. , https://doi.org/10.1109/CVPR.2019.00498; Awiszus, M., Schubert, F., Rosenhahn, B., Toad-gan: Coherent style level generation from a single example (2020) Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment, 16 (1), pp. 10-16. , https://ojs.aaai.org/index.php/AIIDE/article/view/7401, Oct 2020; Benz, P., Zhang, C., So Kweon, I., (2020) Batch Normalization Increases Adversarial Vulnerability: Disentangling Usefulness and Robustness of Model Features; Blitzer, J., Dredze, M., Pereira, F., Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification (2007) Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pp. 440-447; Breiman, L., Bagging predictors (1996) Machine Learning, 24 (2), pp. 123-140; Brock, A., Donahue, J., Simonyan, K., Large scale gan training for high fidelity natural image synthesis (2019) 7th International Conference on Learning Representations, ICLR 2019, , https://openreview.net/forumid=B1xsqj09Fm, New Orleans, LA, USA, May 6-9, 2019. OpenReview. net; Brown, T.B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Amodei, D., (2020) Language Models Are Few-Shot Learners; Cimolino, G., Lee, S., Petraroia, Q., Nicholas Graham, T.C., Oui, chef: Supervised learning for novel gameplay with believable ai (2019) Extended Abstracts of the Annual Symposium on Computer-Human Interaction in Play Companion Extended Abstracts, pp. 241-246; Wang, D., Deng, L., Ni, J., Gao, J., Zhu, H., Han, Z., Recognition pest by image-based transfer learning (2019) Journal of the Science of Food and Agriculture, 99 (10), pp. 4524-4531. , https://onlinelibrary.wiley.com/doi/pdf/10.1002/jsfa.9689, https: //doi. org/10. 1002/jsfa. 9689 arXiv; Dietterich, T.G., Ensemble methods in machine learning (2000) International Workshop on Multiple Classifier Systems, pp. 1-15. , Springer; Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Xiao, C., Prakash, A., Song, D., Robust physical-world attacks on deep learning visual classification (2018) 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 1625-1634. , https://doi.org/10.1109/CVPR.2018.00175; Fontaine, M.C., Liu, R., Khalifa, A., Modi, J., Togelius, J., Hoover, A.K., Nikolaidis, S., Illuminating mario scenes in the latent space of a generative adversarial network (2021) Proceedings of the AAAI Conference on Artificial Intelligence, 35 (7), pp. 5922-5930. , https://ojs.aaai.org/index.php/AAAI/article/view/16740, May 2021; Freund, Y., Schapire, R.E., Experiments with a new boosting algorithm (1996) Proceedings of the Thirteenth International Conference on International Conference on Machine Learning (Bari, Italy) (ICML'96)., pp. 148-156. , Morgan Kaufmann Publishers Inc., San Francisco, CA, USA; Galloway, A., Golubeva, A., Tanay, T., Moussa, M., Taylor, G.W., (2019) Batch Normalization is A Cause of Adversarial Vulnerability; Gao, Y., Mosalam, K.M., Deep transfer learning for image-based structural damage recognition (2018) Computer-Aided Civil and Infrastructure Engineering, 33 (9), pp. 748-768. , https://onlinelibrary.wiley.com/doi/pdf/10.1111/mice.12363, https: //doi. org/10. 1111/mice. 12363 arXiv; Gitlin, J.M., (2020) War Stories: How Forza Learned to Love Neural Nets to Train AI Drivers, , https://arstechnica.com/gaming/2020/09/war-stories-howforza-learned-to-love-neural-nets-to-train-ai-drivers/; Glorot, X., Bengio, Y., Understanding the difficulty of training deep feedforward neural networks (2010) Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics (Proceedings of Machine Learning Research, pp. 249-256. , http://proceedings.mlr.press/v9/glorot10a.html, 9, Yee Whye Teh and Mike Titterington (Eds.). JMLR Workshop and Conference Proceedings, Chia Laguna Resort, Sardinia, Italy; Goodfellow, I., Bengio, Y., Courville, A., Bengio, Y., (2016) Deep Learning, 1. , MIT press Cambridge; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, 27, pp. 2672-2680. , https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf, Z. Ghahramani, M. Welling, C. Cortes, N. Lawrence, and K. Q. Weinberger (Eds.). Curran Associates, Inc; Goodfellow, I.J., Shlens, J., Szegedy, C., (2015) Explaining and Harnessing Adversarial Examples, , CoRR abs/1412. 6572; (2016) Quick, Draw Online, , https://quickdraw.withgoogle.com, Google; Grand, S., Cliff, D., Malhotra, A., Creatures: Artificial life autonomous software agents for home entertainment (1997) Proceedings of the First International Conference on Autonomous Agents, pp. 22-29; Guo, C., Rana, M., Cissé, M., Van Der Maaten, L., Countering adversarial images using input transformations (2018) 6th International Conference on Learning Representations, ICLR 2018, , https://openreview.net/forumid=SyJ7ClWCb, Vancouver, BC, Canada, April 30-May 3, 2018, Conference Track Proceedings. OpenReview. net; Kai Hansen, L., Salamon, P., Neural network ensembles (1990) IEEE Transactions on Pattern Analysis and Machine Intelligence, 12 (10), pp. 993-1001; Hastings, E.J., Guha, R.K., Stanley, K.O., Evolving content in the galactic arms race video game (2009) 2009 IEEE Symposium on Computational Intelligence and Games. IEEE, pp. 241-248; Hinton, G., Vinyals, O., Dean, J., Distilling the knowledge in a neural network (2015) NIPS Deep Learning and Representation LearningWorkshop, , http://arxiv.org/abs/1503.02531; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9, pp. 1735-1780. , https://doi.org/10.1162/neco.1997.9.8.1735, 12 1997; Huang, J.-T., Li, J., Yu, D., Deng, L., Gong, Y., Cross-language knowledge transfer using multilingual deep neural network with shared hidden layers (2013) 2013 IEEE International Conference on Acoustics, Speech and Signal Processing. IEEE, pp. 7304-7308; Ilyas, A., Engstrom, L., Athalye, A., Lin, J., (2018) Black-box Adversarial Attacks with Limited Queries and Information; Ioffe, S., Szegedy, C., Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015) International Conference on Machine Learning. PMLR, pp. 448-456; Ioffe, S., Szegedy, C., Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015) Proceedings of the 32nd International Conference on Machine Learning (Proceedings of Machine Learning Research, 37, pp. 448-456. , http://proceedings.mlr.press/v37/ioffe15.html, Francis Bach and David Blei (Eds.). PMLR, Lille, France; Kingma, D., Ba, J., Adam: A method for stochastic optimization (2014) International Conference on Learning Representations, , 12 2014; Kurakin, A., Goodfellow, I., Bengio, S., (2017) Adversarial Machine Learning at Scale; Lyu, C., Huang, K., Liang, H.-N., A unified gradient regularization family for adversarial examples (2015) Proceedings of the 2015 IEEE International Conference on Data Mining (ICDM) (ICDM '15)., pp. 301-309. , https://doi.org/10.1109/ICDM.2015.84, IEEE Computer Society, USA; Millington, I., Funge, J., (2009) Artificial Intelligence for Games, , CRC Press; Morgulis, N., Kreines, A., Mendelowitz, S., Weisglass, Y., (2019) Fooling A Real Car with Adversarial Traffic Signs; Mozafari, M., Farahbakhsh, R., Crespi, N., A bert-based transfer learning approach for hate speech detection in online social media (2020) Complex Networks and Their Applications VIII, pp. 928-940. , Hocine Cherifi, Sabrina Gaito, José Fernendo Mendes, Esteban Moro, and Luis Mateus Rocha (Eds.). Springer International Publishing, Cham; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 427-436. , https://doi.org/10.1109/CVPR.2015.7298640; Opitz, D., Maclin, R., Popular ensemble methods: An empirical study (1999) Journal of Artificial Intelligence Research, 11, pp. 169-198; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) 2016 IEEE Symposium on Security and Privacy (SP), pp. 582-597. , https://doi.org/10.1109/SP.2016.41; Parmanto, B., Munro, P.W., Doyle, H.R., Improving committee diagnosis with resampling techniques (1996) Advances in Neural Information Processing Systems, pp. 882-888; Prechelt, L., Early stopping-but when (1998) Neural Networks: Tricks of the Trade, pp. 55-69. , Springer; Radford, A., Metz, L., Chintala, S., Unsupervised representation learning with deep convolutional generative adversarial networks (2016) 4th International Conference on Learning Representations, ICLR 2016, , http://arxiv.org/abs/1511.06434, San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings, Yoshua Bengio and Yann LeCun (Eds.); Ramer, U., An iterative procedure for the polygonal approximation of plane curves (1972) Computer Graphics and Image Processing, 1 (3), pp. 244-256. , https://doi.org/10.1016/S0146-664X(72)80017-0; Risi, S., Lehman, J., D'Ambrosio, D.B., Hall, R., Stanley, K.O., Petalz: Search-based procedural content generation for the casual gamer (2015) IEEE Transactions on Computational Intelligence and AI in Games, 8 (3), pp. 244-255; Ross, A., Doshi-Velez, F., Improving the adversarial robustness and interpretability of deep neural networks by regularizing their input gradients (2018) Proceedings of the AAAI Conference on Artificial Intelligence, 32. , New Orleans, Louisiana, USA; Shin, H., Roth, H.R., Gao, M., Lu, L., Xu, Z., Nogues, I., Yao, J., Summers, R.M., Deep convolutional neural networks for computer-aided detection: Cnn architectures, dataset characteristics and transfer learning (2016) IEEE Transactions on Medical Imaging, 35 (5), pp. 1285-1298. , https://doi.org/10.1109/TMI.2016.2528162; Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., Dropout: A simple way to prevent neural networks from overfitting (2014) The Journal of Machine Learning Research, 15 (1), pp. 1929-1958; Su, J., Vasconcellos Vargas, D., Sakurai, K., One pixel attack for fooling deep neural networks (2019) IEEE Transactions on Evolutionary Computation, 23 (5), pp. 828-841. , https://doi.org/10.1109/tevc.2019.2890858, Oct 2019; Tan, C., Sun, F., Kong, T., Zhang, W., Yang, C., Liu, C., A survey on deep transfer learning (2018) International Conference on Artificial Neural Networks, pp. 270-279. , Springer; AI Dungeon: Dragon Model Upgrade, , https://aidungeon.medium.com/ai-dungeon-dragon-model-upgrade-7e8ea579abfe, Latitude Team. [n. d. ]; (2019) Recurrent Neural Networks for Drawing Classification, , https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/recurrent_quickdraw.md, Tensorflow; Thakkar, S., Cao, C., Wang, L., Jong Choi, T., Togelius, J., Autoencoder and evolutionary algorithm for level generation in lode runner (2019) 2019 IEEE Conference on Games (CoG), pp. 1-4. , https://doi.org/10.1109/CIG.2019.8848076; (2016) CS231n Convolutional Neural Networks for Visual Recognition: Transfer Learning, , http://cs231n.stanford.edu, Stanford University; Villareale, J., Acosta-Ruiz, A.V., Adam Arcaro, S., Fox, T., Freed, E., Gray, R.C., Löwe, M., Zhu, J., (2020) INNk: A Multi-Player Game to Deceive A Neural Network, pp. 33-37. , https://doi.org/10.1145/3383668.3419858, Association for Computing Machinery, New York, NY, USA; Volz, V., Schrum, J., Liu, J., Lucas, S.M., Smith, A., Risi, S., Evolving mario levels in the latent space of a deep convolutional generative adversarial network (2018) Proceedings of the Genetic and Evolutionary Computation Conference, pp. 221-228. , https://doi.org/10.1145/3205455.3205517, (Kyoto, Japan) (GECCO '18). Association for Computing Machinery, New York, NY, USA; Walton, N., (2019) AI Dungeon, , https://aidungeon.io/, Website; Warr, K., (2019) Strengthening Deep Neural Networks: Making AI Less Susceptible to Adversarial Trickery, , (1 ed.). O'Reilly Media, Inc. 246 pages; Wolpert, D.H., Stacked generalization (1992) Neural Networks, 5 (2), pp. 241-259; Yosinski, J., Clune, J., Bengio, Y., Lipson, H., Howtransferable are features in deep neural networks (2014) Advances in Neural Information Processing Systems, 27, pp. 3320-3328. , https://proceedings.neurips.cc/paper/2014/file/375c71349b295fbe2dcdca9206f20a06-Paper.pdf, Z. Ghahramani, M. Welling, C. Cortes, N. Lawrence, and K. Q. Weinberger (Eds.). Curran Associates, Inc; Yu, J., Lin, Z., Yang, J., Shen, X., Lu, X., Huang, T.S., Generative image inpainting with contextual attention (2018) 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 5505-5514. , https://doi.org/10.1109/CVPR.2018.00577; Zhao, W., Research on the deep learning of the small sample data based on transfer learning (2017) AIP Conference Proceedings, 1864 (1), p. 020018. , https://aip.scitation.org/doi/pdf/10.1063/1.4992835, https: //doi. org/10. 1063/1. 4992835 arXiv; Zhou, Z.-H., (2012) Ensemble Methods: Foundations and Algorithms, , CRC press; Zhu, J., Villareale, J., Javvaji, N., Risi, S., Löwe, M., Weigelt, R., Harteveld, C., Player-ai interaction: What neural network games reveal about ai as play (2021) Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, pp. 1-17",,Fowler A.Pirker J.Canossa A.A.Arya A.A.Harteveld C.,Microsoft;Zynga,Association for Computing Machinery,"16th International Conference on the Foundations of Digital Games, FDG 2021",2 August 2021 through 6 August 2021,,172903,,9.78E+12,,,English,ACM Int. Conf. Proc. Ser.,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85118258527
"Alvarez E., Alvarez R., Cazorla M.",57214014506;57285836300;6601915223;,Studying the Transferability of Non-Targeted Adversarial Attacks,2021,Proceedings of the International Joint Conference on Neural Networks,2021-July,,,,,,,10.1109/IJCNN52387.2021.9534138,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116459391&doi=10.1109%2fIJCNN52387.2021.9534138&partnerID=40&md5=dae159821b0d29b7afbc73fcd1f25149,"University of Alicante, Dept. Computer Science and A.I, Alicante, Spain","Alvarez, E., University of Alicante, Dept. Computer Science and A.I, Alicante, Spain; Alvarez, R., University of Alicante, Dept. Computer Science and A.I, Alicante, Spain; Cazorla, M., University of Alicante, Dept. Computer Science and A.I, Alicante, Spain","There is no doubt that the use of machine learning is increasing every day. Its applications include self-driving cars, malware detection, recommendation systems and many other fields. Although the broad scope of this technology highlights the importance of its reliability, it has been shown that machine learning models can be vulnerable to adversarial attacks. In this paper, we study a property of these attacks called transferability across different architectures and models, measuring how these attacks transfer based on a specific number of parameters among three adversarial attacks: Fast Gradient Sign Method, Projected Gradient Descent and HopSkipJumpAttack. © 2021 IEEE.",Adversarial Attacks; Convolutional Neural Networks; Deep Learning,Convolutional neural networks; Deep neural networks; Malware; Adversarial attack; Architectures and models; Convolutional neural network; Deep learning; ITS applications; Machine learning models; Malware detection; Non-targeted; Projected gradient; Property; Gradient methods,,,,,"Hinton, G.E., Deng, L., Yu, D., Dahl, G.E., Rahman Mohamed, A., Jaitly, N., Senior, A., Kingsbury, B., Edeep neural networks for acoustic modeling in speech recognition: The shared views of four research groups (2012) IEEE Signal Process; Collobert, R., Weston, J., A unified architecture for natural language processing: Deep neural networks with task learning (2008) Proceedings of the 25th International Conference on Machine Learning. ACM; Yuan, Z., Lu, Y., Wang, Z., Xue, Y., Droid-sec: Deep learning in android malware detection (2014) ACM; LeCun, Y., Boser, B., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W., Jackel, L.D., Backpropagation applied to handwritten zip code recognition (1989) Neural Computation; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition; Szegedy, C., Liu, W., Ji, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., (2014) Going Deeper with Convolutions; He, K., Zhang, X., Ren, S., Sun, J., (2015) Deep Residual Learning for Image Recognition; Tan, M., Le, Q.V., (2019) Efficientnet: Rethinking Model Scaling for Convolutional Neural Networks; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., (2013) Intriguing Properties of Neural Networks; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks; Chen, J., Jordan, M.I., Wainwright, M.J., (2019) Hopskipjumpattack: A Query-efficient Decision-based Attack; Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P., (2015) Deepfool: A Simple and Accurate Method to Fool Deep Neural Networks; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., (2015) The Limitations of Deep Learning in Adversarial Settings; Carlini, D.W.N., (2016) Towards Evaluating the Robustness of Neural Network; Su, J., Vargas, D.V., Kouichi, S., (2017) One Pixel Attack for Fooling Deep Neural Networks; Guo, C., Gardner, J., You, Y., Wilson, A., Weinberger, K., (2019) Simple Black-box Adversarial Attacks; Andriushchenko, M., Croce, F., Flammarion, N., Hein, M., (2019) Square Attack: A Query-efficient Black-box Adversarial Attack Via Random Search; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) CCS '16: Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Fei-Fei, L., (2014) Imagenet Large Scale Visual Recognition Challenge; Liu, Y., Chen, X., Liu, C., Song, D., (2016) Delving into Transferable Adversarial Examples and Black Box Attacks; Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., Chen, L., Mobilenetv2: Inverted residuals and linear bottlenecks (2018) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Huang, G., Liu, Z., Maaten Der Van, L., Weinberger, K.Q., (2016) Densely Connected Convolutional Networks; Nicolae, M., Sinn, M., Tran, M., Buesser, B., Rawat, A., Wistuba, M., Zantedeschi, V., Edwards, B., (2018) Adversarial Robustness Toolbox v1. 0. 0; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World; Kurakin, A., Goodfellow, I., Bengio, S., Dong, Y., Liao, F., Liang, M., Pang, T., Abe, M., (2018) Adversarial Attacks and Defences Competition; Brendel, W., Rauber, J., Bethge, M., (2017) Decision-based Adversarial Attacks: Reliable Attacks against Black-box Machine Learning Models",,,IEEE Computational Intelligence Society;International Neural Network Society,Institute of Electrical and Electronics Engineers Inc.,"2021 International Joint Conference on Neural Networks, IJCNN 2021",18 July 2021 through 22 July 2021,,171891,,9.78E+12,85OFA,,English,Proc Int Jt Conf Neural Networks,Conference Paper,Final,,Scopus,2-s2.0-85116459391
"Bernhard R., Moellic P.-A., Dutertre J.-M.",57215361510;55886039600;36558983300;,Luring Transferable Adversarial Perturbations for Deep Neural Networks,2021,Proceedings of the International Joint Conference on Neural Networks,2021-July,,,,,,,10.1109/IJCNN52387.2021.9534397,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116431681&doi=10.1109%2fIJCNN52387.2021.9534397&partnerID=40&md5=71d03cabb799ca097a4e5ddc9cbf59d0,"Cea, Leti, Mines Saint-Etienne, Cea Tech, Sas, Centre Cmp, Gardanne, F-13541, France; Mines Saint-Etienne, Cea Tech, Sas, Centre Cmp, Gardanne, France","Bernhard, R., Cea, Leti, Mines Saint-Etienne, Cea Tech, Sas, Centre Cmp, Gardanne, F-13541, France; Moellic, P.-A., Cea, Leti, Mines Saint-Etienne, Cea Tech, Sas, Centre Cmp, Gardanne, F-13541, France; Dutertre, J.-M., Mines Saint-Etienne, Cea Tech, Sas, Centre Cmp, Gardanne, France","The growing interest for adversarial examples, i.e. maliciously modified examples which fool a classifier, has resulted in many defenses intended to detect them, render them inoffensive or make the model more robust against them. In this paper, we pave the way towards a new approach to improve the robustness of a model against black-box transfer attacks. A removable additional neural network is included in the target model, and is designed to induce the luring effect, which tricks the adversary into choosing false directions to fool the target model. Training the additional model is achieved thanks to a loss function acting on the logits sequence order. Our deception-based method only needs to have access to the predictions of the target model and does not require a labeled data set. We explain the luring effect thanks to the notion of robust and non-robust useful features and perform experiments on MNIST, SVHN and CIFAR10 to characterize and evaluate this phenomenon. Additionally, we scale the luring effect to ImageNet, experiment practical use of it and discuss its complementarity with other defense schemes. © 2021 IEEE.",adversarial examples; black-box transfer attacks; deep neural networks,Computer vision; Network security; Adversarial example; Black boxes; Black-box transfer attack; Data set; Labeled data; Loss functions; Neural-networks; New approaches; Practical use; Target model; Deep neural networks,,,,,"Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations; Schmidt, L., Santurkar, S., Tsipras, D., Talwar, K., Madry, A., Adversarially robust generalization requires more data (2018) Advances in Neural Information Processing Systems, pp. 5014-5026; Ford, N., Gilmer, J., Cubuk, E.D., Adversarial examples are a natural consequence of test error in noise (2019) Proceedings of the 36th International Conference on Machine Learning, ICML, pp. 2280-2289; Ilyas, A., Santurkar, S., Tsipras, D., Engstrom, L., Tran, B., Madry, A., Adversarial examples are not bugs, they are features (2019) Advances in Neural Information Processing Systems, pp. 125-136; Shafahi, A., Huang, W.R., Studer, C., Feizi, S., Goldstein, T., Are adversarial examples inevitable (2019) International Conference on Learning Representations; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) International Conference on Learning Representations; Zhang, H., Yu, Y., Jiao, J., Xing, E.P., Ghaoui, L.E., Jordan, M.I., Theoretically principled trade-off between robustness and accuracy (2019) Proceedings of the 36th International Conference on Machine Learning, ICML 2019; Cohen, J.M., Rosenfeld, E., Kolter, J.Z., Certified adversarial robustness via randomized smoothing (2019) Proceedings of the 36th International Conference on Machine Learning, ICML 2019, pp. 1310-1320; Hendrycks, D., Lee, K., Mazeika, M., Using pre-training can improve model robustness and uncertainty (2019) Proceedings of the 36th International Conference on Machine Learning, ICML 2019; Carmon, Y., Raghunathan, A., Schmidt, L., Liang, P., Duchi, J.C., Unlabeled data improves adversarial robustness (2019) Advances in Neural Information Processing Systems; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security. ACM, pp. 506-519; Meng, D., Chen, H., Magnet: A two-pronged defense against adversarial examples (2017) Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security. ACM, pp. 135-147; Hwang, U., Park, J., Jang, H., Yoon, S., Cho, N.I., Puvae: A variational autoencoder to purify adversarial examples (2019) IEEE Access, 7, pp. 126582-126593; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations., , Wiley Online Library; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP). IEEE, pp. 39-57; Chen, P.-Y., Sharma, Y., Zhang, H., Yi, J., Hsieh, C.-J., Ead: Elasticnet attacks to deep neural networks via adversarial examples (2018) The Thirty-Second AAAI Conference on Artificial Intelligence; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2018) 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, , Jun; Wang, S., Chen, Y., Abdou, A., Jana, S., Enhancing gradient-based attacks with symbolic intervals (2019) Proceedings of the 36th International Conference on Machine Learning, ICML 2019; Uesato, J., O'Donoghue, B., Oord A, V.D., Kohli, P., Adversarial risk and the dangers of evaluating against weak attacks (2018) Proceedings of the 35th International Conference on Machine Learning, ICML 2018, pp. 5025-5034; Guo, C., Gardner, J.R., You, Y., Wilson, A.G., Weinberger, K.Q., Simple black-box adversarial attacks (2019) Proceedings of the 36th International Conference on Machine Learning, ICML 2019; Su, J., Vargas, D.V., Sakurai, K., One pixel attack for fooling deep neural networks (2019) IEEE Transactions on Evolutionary Computation; Brendel, W., Rauber, J., Bethge, M., Decision-based adversarial attacks: Reliable attacks against black-box machine learning models (2018) International Conference on Learning Representations; Ilyas, A., Engstrom, L., Athalye, A., Lin, J., Black-box adversarial attacks with limited queries and information (2018) Proceedings of the 35th International Conference on Machine Learning, ICML 2018; Chen, J., Jordan, M.I., Wainwright, M.J., Hopskipjumpattack: A query-efficient decision-based attack (2020) 2020 IEEE Symposium on Security and Privacy (SP); Chen, S., Carlini, N., Wagner, D., (2019) Stateful Detection of Black-box Adversarial Attacks; Li, H., Shan, S., Wenger, E., Zhang, J., Zheng, H., Zhao, B.Y., (2020) Blacklight: Defending Black-box Adversarial Attacks on Deep Neural Networks; Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proceedings of the IEEE, 86 (11), pp. 2278-2324; Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., Ng, A.Y., Reading digits in natural images with unsupervised feature learning (2011) NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011; Krizhevsky, A., (2009) Learning Multiple Layers of Features from Tiny Images, , University of Toronto, Tech. Rep; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) International Conference on Learning Representations; Moon, S., An, G., Song, H.O., Parsimonious black-box adversarial attacks via efficient combinatorial optimization (2019) Proceedings of the 36th International Conference on Machine Learning, pp. 4636-4645; Xie, C., Zhang, Z., Wang, J., Zhou, Y., Ren, Z., Yuille, A.L., Improving transferability of adversarial examples with input diversity (2018) 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition; Dong, Y., Pang, T., Su, H., Zhu, J., Evading defenses to transferable adversarial examples by translation-invariant attacks (2019) 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition; Athalye, A., Carlini, N., Wagner, D., Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples (2018) Proceedings of the 35th International Conference on Machine Learning, ICML 2018; Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., Chen, L.-C., Mobilenetv2: Inverted residuals and linear bottlenecks (2018) 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition; Shan, S., Wenger, E., Wang, B., Li, B., Zheng, H., Zhao, B.Y., Using honeypots to catch adversarial attacks on neural networks (2019) Proceedings of ACM Conference on Computer and Communications Security (CCS)",,,IEEE Computational Intelligence Society;International Neural Network Society,Institute of Electrical and Electronics Engineers Inc.,"2021 International Joint Conference on Neural Networks, IJCNN 2021",18 July 2021 through 22 July 2021,,171891,,9.78E+12,85OFA,,English,Proc Int Jt Conf Neural Networks,Conference Paper,Final,,Scopus,2-s2.0-85116431681
"Chen M., Lu J., Wang Y., Qin J., Wang W.",57226898177;57222559358;57204780329;42262710100;57202602788;,DAIR: A Query-Efficient Decision-based Attack on Image Retrieval Systems,2021,SIGIR 2021 - Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval,,,3462887,1064,1073,,1,10.1145/3404835.3462887,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111695579&doi=10.1145%2f3404835.3462887&partnerID=40&md5=7053fe6a6c105754b03d41063054c8b8,"University of New South Wales, Sydney, Australia; Dongguan University of Technology, Dongguan, China; Shenzhen Institute of Computing Sciences, Shenzhen University, Shenzhen, China","Chen, M., University of New South Wales, Sydney, Australia; Lu, J., University of New South Wales, Sydney, Australia; Wang, Y., Dongguan University of Technology, Dongguan, China; Qin, J., Shenzhen Institute of Computing Sciences, Shenzhen University, Shenzhen, China; Wang, W., University of New South Wales, Sydney, Australia","There is an increasing interest in studying adversarial attacks on image retrieval systems. However, most of the existing attack methods are based on the white-box setting, where the attackers have access to all the model and database details, which is a strong assumption for practical attacks. The generic transfer-based attack also requires substantial resources yet the effect was shown to be unreliable. In this paper, we make the first attempt in proposing a query-efficient decision-based attack framework for the image retrieval (DAIR) to completely subvert the top-K retrieval results with human imperceptible perturbations. We propose an optimization-based method with a smoothed utility function to overcome the challenging discrete nature of the problem. To further improve the query efficiency, we propose a novel sampling method that can achieve the transferability between the surrogate and the target model efficiently. Our comprehensive experimental evaluation on the benchmark datasets shows that our DAIR method outperforms significantly the state-of-the-art decision-based methods. We also demonstrate that real image retrieval engines (Bing Visual Search and Face++ engines) can be attacked successfully with only several hundreds of queries. © 2021 Owner/Author.",adversarial attack in deep learning; content-based image retrieval; decision-based attack in deep learning,Engines; Image retrieval; Query processing; Benchmark datasets; Experimental evaluation; Image retrieval systems; Optimization based methods; Query efficiency; Sampling method; State of the art; Utility functions; Search engines,,,,,"Babenko, A., Lempitsky, V.S., Aggregating local deep features for image retrieval (2015) ICCV. IEEE Computer Society, pp. 1269-1277; Brendel, W., Rauber, J., Bethge, M., Decision-based adversarial attacks: Reliable attacks against black-box machine learning models (2018) ICLR (Poster), , OpenReview. net; Brunner, T., Diehl, F., Truong-Le, M., Knoll, A.C., Guessing smart: Biased sampling for efficient black-box adversarial attacks (2019) ICCV. IEEE, pp. 4957-4965; Cao, Q., Shen, L., Xie, W., Parkhi, O.M., Zisserman, A., VGGFace2: A dataset for recognising faces across pose and age (2018) FG. IEEE Computer Society, pp. 67-74; Carlini, N., Wagner, D.A., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy. IEEE Computer Society, pp. 39-57; Chen, C., Seff, A., Kornhauser, A.L., Xiao, J., DeepDriving: Learning affordance for direct perception in autonomous driving (2015) ICCV. IEEE Computer Society, pp. 2722-2730; Chen, J., Jordan, M.I., Wainwright, M.J., HopSkipJumpAttack: A query-efficient decision-based attack (2020) IEEE Symposium on Security and Privacy. IEEE, pp. 1277-1294; Chen, P., Zhang, H., Sharma, Y., Yi, J., Hsieh, C., ZOO: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) AISec@CCS. ACM, pp. 15-26; Cheng, M., Le, T., Chen, P., Zhang, H., Yi, J., Hsieh, C., Query-efficient hard-label black-box attack: An optimization-based approach (2019) ICLR (Poster), , OpenReview. net; Cheng, M., Singh, S., Chen, P.H., Chen, P., Liu, S., Hsieh, C., Sign-opt: A query-efficient hard-label adversarial attack (2020) ICLR. OpenReview. Net; Cheng, S., Dong, Y., Pang, T., Su, H., Zhu, J., Improving black-box adversarial attacks with a transfer-based prior (2019) NeurIPS, pp. 10932-10942; Deng, J., Dong, W., Socher, R., Li, L., Li, K., Li, F., ImageNet: A large-scale hierarchical image database (2009) CVPR. IEEE Computer Society, pp. 248-255; Dong, Y., Su, H., Wu, B., Li, Z., Liu, W., Zhang, T., Zhu, J., Efficient decision-based black-box adversarial attacks on face recognition (2019) CVPR. Computer Vision Foundation / IEEE, pp. 7714-7722; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR (Poster); Gu, J., Bradbury, J., Xiong, C., Li, K.V.O., Socher, R., Non-autoregressive neural machine translation (2018) ICLR (Poster), , OpenReview. net; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) CVPR. IEEE Computer Society, pp. 770-778; Ilyas, A., Engstrom, L., Athalye, A., Lin, J., Black-box adversarial attacks with limited queries and information (2018) ICML (Proceedings of Machine Learning Research Vol. 80), pp. 2142-2151; Kalantidis, Y., Mellina, C., Osindero, S., Cross-dimensional weighting for aggregated deep convolutional features (2016) ECCV Workshops (1), pp. 685-701. , (Lecture Notes in Computer Science vol. 9913) . Springer; Karpathy, A., Toderici, G., Shetty, S., Leung, T., Sukthankar, R., Li, F., Large-scale video classification with convolutional neural networks (2014) CVPR. IEEE Computer Society, pp. 1725-1732; Kingma, D.P., Ba, J., Adam: A method for stochastic optimization (2015) 3rd International Conference on Learning Representations, ICLR 2015, , http://arxiv.org/abs/1412.6980, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial examples in the physical world (2017) ICLR (Workshop), , OpenReview. net; Li, H., Xu, X., Zhang, X., Yang, S., Li, B., QEBA: Query-efficient boundary-based blackbox attack (2020) CVPR. IEEE, pp. 1218-1227; Li, J., Ji, R., Liu, H., Hong, X., Gao, Y., Tian, Q., Universal perturbation attack against image retrieval (2019) ICCV. IEEE, pp. 4898-4907; Liu, S., Kailkhura, B., Chen, P., Ting, P., Chang, S., Amini, L., Zeroth-order stochastic variance reduction for nonconvex optimization (2018) NeurIPS, pp. 3731-3741; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) ICLR (Poster), , OpenReview. net; Liu, Z., Zhao, Z., Larson, M.A., Who's afraid of adversarial queries: The impact of image modifications on content-based image retrieval (2019) Proceedings of the 2019 on International Conference on Multimedia Retrieval, ICMR 2019, pp. 306-314. , https://doi.org/10.1145/3323873.3325052, Ottawa, ON, Canada, June 10-13, 2019; Long, J., Shelhamer, E., Darrell, T., Fully convolutional networks for semantic segmentation (2015) CVPR. IEEE Computer Society, pp. 3431-3440; Ma, X., Wang, Z., Li, H., Zhang, P., Ouyang, W., Fan, X., Accurate monocular 3d object detection via color-embedded 3d reconstruction for autonomous driving (2019) ICCV. IEEE, pp. 6850-6859; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) ICLR (Poster), , OpenReview. net; Moosavi-Dezfooli, S., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) CVPR. IEEE Computer Society, pp. 86-94; Moosavi-Dezfooli, S., Fawzi, A., Frossard, P., DeepFool: A simple and accurate method to fool deep neural networks (2016) CVPR. IEEE Computer Society, pp. 2574-2582; Radenovic, F., Iscen, A., Tolias, G., Avrithis, Y., Chum, O., Revisiting oxford and Paris: Large-scale image retrieval benchmarking (2018) CVPR. IEEE Computer Society, pp. 5706-5715; Radenovic, F., Tolias, G., Chum, O., Fine-tuning cnn image retrieval with no human annotation (2019) IEEE Trans. Pattern Anal. Mach. Intell., 41 (7), pp. 1655-1668. , 2019; Schönberger, J.L., Radenovic, F., Chum, O., Frahm, J., From single image query to detailed 3d reconstruction (2015) CVPR. IEEE Computer Society, pp. 5126-5134; Schroff, F., Kalenichenko, D., Philbin, J., FaceNet: A unified embedding for face recognition and clustering (2015) CVPR. IEEE Computer Society, pp. 815-823; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) ICLR; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S.E., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) CVPR. IEEE Computer Society, pp. 1-9; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R., Intriguing properties of neural networks (2014) ICLR (Poster); Tolias, G., Radenovic, F., Chum, O., Targeted mismatch adversarial attack: Query with a flower to retrieve the tower (2019) ICCV. IEEE, pp. 5036-5045; Tolias, G., Sicre, R., Jégou, H., Particular object retrieval with integral max-pooling of cnn activations (2016) ICLR (Poster); Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, L., Polosukhin, I., Attention is all you need (2017) NIPS, pp. 5998-6008; Wan, J., Wang, D., Chu-Hong Hoi, S., Wu, P., Zhu, J., Zhang, Y., Li, J., Deep learning for content-based image retrieval: A comprehensive study (2014) ACM Multimedia. ACM, pp. 157-166; Wierstra, D., Schaul, T., Glasmachers, T., Sun, Y., Peters, J., Schmidhuber, J., Natural evolution strategies (2014) J. Mach. Learn. Res., 15 (1), pp. 949-980. , http://dl.acm.org/citation.cfm?id=2638566, 2014; Williams, R.J., Simple statistical gradient-following algorithms for connectionist reinforcement learning (1992) Mach. Learn., 8, pp. 229-256. , https://doi.org/10.1007/BF00992696, 1992; Wu, X., He, R., Sun, Z., Tan, T., A light cnn for deep face representation with noisy labels (2018) IEEE Trans. Inf. Forensics Secur., 13 (11), pp. 2884-2896. , 2018; Xia, R., Pan, Y., Lai, H., Liu, C., Yan, S., Supervised hashing for image retrieval via image representation learning (2014) AAAI, pp. 2156-2162. , AAAI Press; Yang, E., Liu, T., Deng, C., Tao, D., Adversarial examples for hamming space search (2020) IEEE Trans. Cybern., 50 (4), pp. 1473-1484. , 2020; Zhao, G., Zhang, M., Liu, J., Wen, J., Unsupervised adversarial attacks on deep feature-based retrieval with gan (2019) CoRR, , 2019 abs/1907. 05793; Zhong, Y., Deng, W., Towards transferable adversarial attack against deep face recognition (2021) IEEE Trans. Inf. Forensics Secur., 16, pp. 1452-1466. , 2021; Zhou, M., Niu, Z., Wang, L., Zhang, Q., Hua, G., Adversarial ranking attack and defense (2020) CoRR, , 2020 abs/2002. 11293",,,ACM SIGIR,"Association for Computing Machinery, Inc","44th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2021",11 July 2021 through 15 July 2021,,170067,,9.78E+12,,,English,SIGIR - Proc. Int. ACM SIGIR Conf. Res. Dev. Inf. Retr.,Conference Paper,Final,"All Open Access, Bronze",Scopus,2-s2.0-85111695579
"Zhang W., Yi P.",57276189600;7005532157;,A Robust Transfer Method of Neural Network based on Knowledge Distillation [一种基于知识蒸馏的神经网络鲁棒性迁移方法],2021,Journal of Cyber Security,6,4,,60,71,,,10.19363/J.cnki.cn10-1380/tn.2021.07.04,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113753414&doi=10.19363%2fJ.cnki.cn10-1380%2ftn.2021.07.04&partnerID=40&md5=6b5a34c151685a449a0625321cf81f9a,"School of Cyber Science and Engineering, Shanghai Jiao Tong University, Shanghai, 200240, China","Zhang, W., School of Cyber Science and Engineering, Shanghai Jiao Tong University, Shanghai, 200240, China; Yi, P., School of Cyber Science and Engineering, Shanghai Jiao Tong University, Shanghai, 200240, China","In recent years, neural networks have shown very powerful performance in many fields, but researchers have found that by adding imperceptible interference to the input, neural network decisions can be changed. Such samples are called adversarial samples. At present, the most common method for defending adversarial examples is adversarial training, but the training cost of adversarial training is very high. We propose a knowledge purification scheme (Robust-KD) combining feature maps and Jacobian matrix constraints. By migrating robust features from a robust network, we can obtain considerable white box defense capabilities at relatively low training costs. We have conducted a lot of experiments on the Cifar10, Cifar100 and ImageNet datasets. Experiments have proved the effectiveness of the scheme. Even under a very powerful white box attack, our model still has good classification accuracy. © 2021, China Science Publishing & Media LTD. All right reserved.",Adversarial examples; Knowledge distillation; Model robustness; Transfer learning,,,,,,"LeCun, Y, Bengio, Y, Hinton, G., Deep Learning (2015) Nature, 521 (7553), pp. 436-444. , [J]; Lin, C H, Chang, C C, Chen, Y S, COCO-GAN: Generation by Parts via Conditional Coordinating (2019) 2019 IEEE/CVF International Conference on Computer Vision, pp. 4511-4520. , [C]; Touvron, H, Vedaldi, A, Douze, M, Fixing the train-test resolution discrepancy (2019) Advances in Neural Information Processing Systems, pp. 8252-8262. , [C]; Szegedy, C, Zaremba, W, Sutskever, I, Intriguing properties of neural networks (2013), [J]. arXiv preprint arXiv:1312.6199; Eykholt, K, Evtimov, I, Fernandes, E, Robust Physical-World Attacks on Deep Learning Visual Classification (2018) 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 1625-1634. , [C]; Madry, A, Makelov, A, Schmidt, L, Towards Deep Learning Models Resistant to Adversarial Attacks (2017), [EB/OL]; Shafahi, A, Saadatpanah, P, Zhu, C, Adversarially Robust Transfer Learning (2019), [EB/OL]; Hinton, G, Vinyals, O, Dean, J., Distilling the knowledge in a neural network (2015), [J]. arXiv preprint arXiv:1503.02531; Zagoruyko, S, Komodakis, N., Paying more Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer (2016), [EB/OL]; Etmann, C, Lunz, S, Maass, P, On the Connection between Adversarial Robustness and Saliency Map Interpretability (2019), [EB/OL]; Pan, S J, Yang, Q., A Survey on Transfer Learning (2010) IEEE Transactions on Knowledge and Data Engineering, 22 (10), pp. 1345-1359. , [J]; Deng, J, Dong, W, Socher, R, ImageNet: A Large-Scale Hierarchical Image Database (2009) 2009 IEEE Conference on Computer Vision and Pattern Recognition, pp. 248-255. , [C]; Goodfellow, I J, Shlens, J, Szegedy, C., Explaining and harnessing adversarial examples (2014), [J]. arXiv preprint arXiv:1412.6572; Zhang, H C, Wang, J Y., Defense Against Adversarial Attacks Using Feature Scattering-Based Adversarial Training (2019) Advances in Neural Information Processing Systems, pp. 1831-1841. , [C]; Zhang, H Y, Yu, Y D, Jiao, J T, Theoretically Principled Trade-off between Robustness and Accuracy (2019), [EB/OL]; Ross, A S, Doshi-Velez, F., Improving the Adversarial Robustness and Interpretability of Deep Neural Networks by Regularizing Their Input Gradients (2017), [EB/OL]; Hoffman, J, Roberts, D A, Yaida, S., Robust Learning with Jacobian Regularization (2019), [EB/OL]; Le, Y, Yang, X., Tiny imagenet visual recognition challenge (2015) CS 231N, p. 7. , [J]; Li, Z, Hoiem, D., Learning without forgetting (2017) IEEE transactions on pattern analysis and machine intelligence, 40 (12), pp. 2935-2947. , [J]; Goldberger, Gordon, Greenspan, An Efficient Image Similarity Measure Based on Approximations of KL-Divergence between Two Gaussian Mixtures (2003) Ninth IEEE International Conference on Computer Vision, pp. 487-493. , [C]; Qian, G, Sural, S, Gu, Y, Similarity between Euclidean and cosine angle distance for nearest neighbor queries (2004) The 2004 ACM symposium on Applied computing, pp. 1232-1237. , [C]; He, K M, Zhang, X Y, Ren, S Q, Deep Residual Learning for Image Recognition (2016) 2016 IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778. , [C]; Bottou, L., Large-Scale Machine Learning with Stochastic Gradient Descent (2010) Proceedings of COMPSTAT'2010, pp. 177-186. , [C]; Paszke, A, Gross, S, Chintala, S, Automatic differentiation in pytorch (2017) Advances in Neural Information Processing Systems Workshop, , [C]; Dong, Y P, Liao, F Z, Pang, T, Boosting Adversarial Attacks with Momentum (2018) 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 9185-9193. , [C]; Carlini, N, Wagner, D., Towards Evaluating the Robustness of Neural Networks [C] (2017) 2017 IEEE symposium on security and privacy, pp. 39-57; Qin, C L, Martens, J, Gowal, S, Adversarial Robustness through Local Linearization (2019), [EB/OL]; Drucker, H, Le Cun, Y., Double Backpropagation Increasing Generalization Performance (1991) IJCNN-91-Seattle International Joint Conference on Neural Networks, pp. 145-150. , [C]; Chan, A, Tay, Y, Ong, Y S, Jacobian Adversarially Regularized Networks for Robustness (2019), [EB/OL]; Hein, M, Andriushchenko, M., Formal guarantees on the robustness of a classifier against adversarial manipulation (2017) Advances in Neural Information Processing Systems, pp. 2266-2276. , [C]; Wong, E, Schmidt, F, Metzen, J H, Scaling Provable Adversarial Defenses (2018), [EB/OL]; Ma, X J, Li, B, Wang, Y S, Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality (2018), [EB/OL]; Krishna, K, Murty, M N., Genetic K-means algorithm (1999) IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics), 29 (3), pp. 433-439. , [J]; Meng, D, Chen, H., Magnet: a two-pronged defense against adversarial examples (2017) The 2017 ACM SIGSAC conference on computer and communications security, pp. 135-147. , [C]; Xu, W L, Evans, D, Qi, Y J., Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks (2017), [EB/OL]; , (3), p. 13. , 王科迪, 易平. 人工智能对抗环境下的模型鲁棒性研究综述[J]. 信息安全学报, 2020, 5 22","Yi, P.; School of Cyber Science and Engineering, China; 电子邮件: yiping@sjtu.edu.cn",,,Chinese Academy of Sciences,,,,,20961146,,,,Chinese,J. Cyber Secur.,Article,Final,,Scopus,2-s2.0-85113753414
"Chen J., Zhang L., Zheng H., Wang X., Ming Z.",12794406900;57218658746;57202093207;57221290162;36447695600;,DeepPoison: Feature transfer based stealthy poisoning attack for DNNs,2021,IEEE Transactions on Circuits and Systems II: Express Briefs,68,7,9359658,2618,2622,,,10.1109/TCSII.2021.3060896,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101765729&doi=10.1109%2fTCSII.2021.3060896&partnerID=40&md5=46da42e708b94cde95a4506c93929ba9,"Institute of Cyberspace Security, Zhejiang University of Technology, Hangzhou, 310023, China; College of Information Engineering, Zhejiang University of Technology, Hangzhou, 310023, China; Institute of Computing Innovation, Zhejiang University, Hangzhou, 310007, China","Chen, J., Institute of Cyberspace Security, Zhejiang University of Technology, Hangzhou, 310023, China, College of Information Engineering, Zhejiang University of Technology, Hangzhou, 310023, China; Zhang, L., College of Information Engineering, Zhejiang University of Technology, Hangzhou, 310023, China; Zheng, H., College of Information Engineering, Zhejiang University of Technology, Hangzhou, 310023, China; Wang, X., College of Information Engineering, Zhejiang University of Technology, Hangzhou, 310023, China; Ming, Z., Institute of Computing Innovation, Zhejiang University, Hangzhou, 310007, China","Deep neural networks are susceptible to poisoning attacks by purposely polluted training data with specific triggers. As existing episodes mainly focused on attack success rate with patch-based samples, defense algorithms can easily detect these poisoning samples. We propose DeepPoison, a novel adversarial network of one generator and two discriminators, to address this problem. Specifically, the generator automatically extracts the target class' hidden features and embeds them into benign training samples. One discriminator controls the ratio of the poisoning perturbation. The other discriminator works as the target model to testify the poisoning effects. The novelty of DeepPoison lies in that the generated poisoned training samples are indistinguishable from the benign ones by both defensive methods and manual visual inspection, and even benign test samples can achieve the attack. Extensive experiments have shown that DeepPoison can achieve a state-of-the-art attack success rate, as high as 91.74%, with only 7% poisoned samples on publicly available datasets LFW and CASIA. Furthermore, we have experimented with high-performance defense algorithms such as autodecoder defense and DBSCAN cluster detection and showed the resilience of DeepPoison. © 2004-2012 IEEE.",Deep neural networks; feature transfer; generative adversarial network; poisoning attack; stealthiness,Network security; Sampling; Adversarial networks; Cluster detection; Feature transfers; Poisoning attacks; Poisoning effects; State of the art; Training sample; Visual inspection; Deep neural networks,,,,,"Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Proc. Adv. Neural Inf. Process. Syst., pp. 1097-1105; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 770-778; Graves, A., Mohamed, A.-R., Hinton, G., Speech recognition with deep recurrent neural networks (2013) Proc. IEEE Int. Conf. Acoust. Speech Signal Process., pp. 6645-6649; Sutskever, I., Vinyals, O., Le, Q.V., Sequence to sequence learning with neural networks (2014) Proc. Adv. Neural Inf. Process. Syst., pp. 3104-3112; Chen, J., Wu, Y., Jia, C., Zheng, H., Huang, G., Customizable text generation via conditional text generative adversarial network (2020) Neurocomputing, 416, pp. 125-135. , Nov; Rubinstein, B.I., ANTIDOTE: Understanding and defending against poisoning of anomaly detectors (2009) Proc. 9th ACM SIGCOMM Conf. Internet Meas., pp. 1-14; Barreno, M., Nelson, B., Sears, R., Joseph, A.D., Tygar, J.D., Can machine learning be secure? (2006) Proc. ACM Symp. Inf. Comput. Commun. Security, pp. 16-25; Chen, X., Liu, C., Li, B., Lu, K., Song, D., (2017) Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning; Gu, T., Dolan-Gavitt, B., Garg, S., (2017) Badnets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain; Shafahi, A., Poison frogs! targeted clean-label poisoning attacks on neural networks (2018) Proc. Adv. Neural Inf. Process. Syst., pp. 6103-6113; Chen, J., Zheng, H., Su, M., Du, T., Lin, C., Ji, S., Invisible poisoning: Highly stealthy targeted poisoning attack (2019) Proc. Int. Conf. Inf. Security Cryptol., pp. 173-198; Deng, L., The MNIST database of handwritten digit images for machine learning research [best of the Web] (2012) IEEE Signal Process. Mag., 29 (6), pp. 141-142. , Nov; Li, H., Liu, H., Ji, X., Li, G., Shi, L., CIFAR10-DVS: An eventstream dataset for object classification (2017) Front. Neurosci., 11, p. 309. , May; Huang, G.B., Ramesh, M., Berg, T., Learned-Miller, E., Labeled faces in the wild: A database for studying face recognition in unconstrained environments (2007) Coll. Info. Comput. Sci., Univ. Massachusetts, , Amherst, MA, USA, Rep. 07-49, Oct; Li, S., Yi, D., Lei, Z., Liao, S., The casia NIR-VIS 2.0 face database Proc. IEEE Conf. Comput. Vis. Pattern Recognit. Workshops, 2013, pp. 348-353; Szegedy, C., Going deeper with convolutions (2015) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 1-9; Zhao, P., Wang, S., Gongye, C., Wang, Y., Fei, Y., Lin, X., Fault sneaking attack: A stealthy framework for misleading deep neural networks (2019) Proc. 56th ACM/IEEE Design Autom. Conf. (DAC), pp. 1-6; Saha, A., Subramanya, A., Pirsiavash, H., Hidden trigger backdoor attacks (2020) Proc. AAAI Conf. Artif. Intell., 34, pp. 11957-11965; Du, M., Jia, R., Song, D., (2019) Robust Anomaly Detection and Backdoor Attack Detection Via Differential Privacy; Wang, B., Neural cleanse: Identifying and mitigating backdoor attacks in neural networks (2019) Proc. IEEE Symp. Security Privacy (SP), pp. 707-723; Liu, Y., Lee, W.-C., Tao, G., Ma, S., Aafer, Y., Zhang, X., Abs: Scanning neural networks for back-doors by artificial brain stimulation (2019) Proc. ACM SIGSAC Conf. Comput. Commun. Security, pp. 1265-1282; Salem, A., Wen, R., Backes, M., Ma, S., Zhang, Y., (2020) Dynamic Backdoor Attacks against Machine Learning Models","Ming, Z.; Institute of Computing Innovation, China; 电子邮件: mingzhangyan@gmail.com",,,Institute of Electrical and Electronics Engineers Inc.,,,,,15497747,,,,English,IEEE Trans. Circuits Syst. Express Briefs,Article,Final,,Scopus,2-s2.0-85101765729
"Liu P., Sun L., Mao X., Dai L., Guo S., Yang Y.",57225153492;57221137565;57225140690;57225146452;57225863912;57225153779;,A CycleGAN Adversarial Attack Method Based on Output Diversification Initialization,2021,Journal of Physics: Conference Series,1948,1,12041,,,,,10.1088/1742-6596/1948/1/012041,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109270755&doi=10.1088%2f1742-6596%2f1948%2f1%2f012041&partnerID=40&md5=b3fcde295e67baa4c67d9ec8443f4d8f,"Information Engineering University, Zheng Zhou, China","Liu, P., Information Engineering University, Zheng Zhou, China; Sun, L., Information Engineering University, Zheng Zhou, China; Mao, X., Information Engineering University, Zheng Zhou, China; Dai, L., Information Engineering University, Zheng Zhou, China; Guo, S., Information Engineering University, Zheng Zhou, China; Yang, Y., Information Engineering University, Zheng Zhou, China","The powerful image generation capabilities of generative adversarial networks (GAN) bring great threats to applications related to images. Style transfer networks realize the style transform between image domains through which we can easily modify images like portraits and calligraphy. To eliminate the negative impact caused by the forged images, there emerged technical methods to detect forged images, which might trigger remedial actions afterwards but cannot prevent maliciously tampered content from spreading over network media. Therefore, some scholars put forward the idea of protecting images from hostile generative networks with adversarial attack. However, the initial random noise of adversarial perturbation cannot be effectively mapped to the output space. In order to improve the visual effect of adversarial attacks, this paper proposes an adversarial attack algorithm based on output diversification initialization (ODI) for CycleGAN. We firstly utilize output diversification initialization to find an effective starting point for the adversarial attack, and then we use Project Gradient Descent (PGD) to iteratively attack the style transfer network by modifying the adversarial loss function. Experimental results demonstrate that the introduction of ODI can effectively enlarge the distance between the adversarial output and the original output. It achieves better results in identifying the forged images generated by the targeted model, and does not significantly increase the disturbance, which can guarantee the normal use of original images. © Published under licence by IOP Publishing Ltd.",,Gradient methods; Internet of things; Adversarial networks; Attack methods; Gradient descent; Image generations; Original images; Remedial actions; Transfer network; Visual effects; Artificial intelligence,,,,,"Goodfellow, I, Pougetabadie, J, Mirza, M, (2014) Generative Adversarial Nets Neural Information Processing Systems, pp. 2672-2680; Yu, R, Wang, X, Xie, X, (2019) IEEE/CVF International Conference on Computer Vision (ICCV) VTNFP: An Image-Based Virtual Try-On Network With Body and Clothing Feature Preservation, pp. 10510-10519; Zhu, J Y, Park, T, Isola, P, Efros, A A, (2017) IEEE International Conference on Computer Vision Unpaired Image-to-image Translation Using Cycle-consistent Adversarial Networks; Isola, P, Zhu, J Y, Zhou, T, Efros, A A, (2017) IEEE Conference on Computer Vision and Pattern Recognition Image-to-image Translation with Conditional Adversarial Networks, pp. 1125-1134; Natsume, R, Yatagawa, T, Morishima, S, Rsgan: Faceswapping and editing using face and hair representation in latent spaces (2018) ACM SIGGRAPH; Nirkin, Y, Keller, Y, Hassner, T, (2014) International Conference on Learning Representations FSGAN: Subject agnostic face swapping and reenactment; https://github.com/deepfakes/faceswap, Faceswap: Deepfakes software for all; Mccloskey, S, Albright, M, (2018) Detecting GAN-generated Imagery using Color Cues Computer Vision and Pattern Recognition; Goodfellow, I, Shlens, J, Szegedy, C, (2015) International Conference on Learning Representations Explaining and Harnessing Adversarial Examples; Madry, A, Makelov, A, Schmidt, L, International Conference on Learning Representations 2018 Towards Deep Learning Models Resistant to Adversarial Attacks; Tashiro, Y, Song, Y, Ermon, S, (2020) Diversity can be transferred: Output Diversification for White-and Black-box Attacks Neural Information Processing Systems; Choi, Y, Choi, M, Kim, M, Stargan: Unified generative adversarial networks for multi-domain image-to-image translation the (2019) IEEE Conference on Computer Vision and Pattern Recognition, pp. 8789-8797; Ming, Y L, Oncel, T, Coupled generative adversarial networks (2016) Neural Information Processing Systems, pp. 469-477; Amélie, R, Bousmalis, K, Gouws, S, (2020) XGAN: Unsupervised Image-to-Image Translation for many-to-many Mappings Domain Adaptation for Visual Understanding; Szegedy, C, Zaremba, W, Sutskever, I, (2014) International Conference on Learning Representations Intriguing properties of neural networks; Kurakin, A, Goodfellow, I, Bengio, S, (2017) International Conference on Learning Representations Adversarial examples in the physical world; Baluja, S, Fischer, I, (2017) Adversarial transformation networks: Learning to generate adversarial examples, , arXiv preprint arXiv:1703.09387; Xiao, C W, Li, B, Zhu, J Y, Twenty-Seventh International Joint Conference on Artificial Intelligence (IJCAI) Generating Adversarial Examples with Adversarial Networks (2018), pp. 3905-3911. , [C]; Dario, P, Marco, M, Massimo, B, (2019) IEEE European Symposium on Security and Privacy Workshops (EuroS&PW) Adversarial out-domain examples for generative models; Shan, S, Wenger, E, Zhang, J, (2020) USENIX Security Symposium Fawkes: protecting privacy against unauthorized deep learning models; Yeh, C Y, Chen, H W, Tsai, S L, (2020) IEEE Winter Applications of Computer Vision Workshops (WACVW) Disrupting image-translation-based deepfake algorithms with adversarial attacks; Ruiz, N, Bargal, S A, Sclaroff, S, (2020) Disrupting deepfakes: adversarial attacks against conditional image translation networks and facial manipulation systems, , arXiv preprint arXiv: 2004.01279","Liu, P.; Information Engineering UniversityChina; 电子邮件: ycxxtgcjzl@163.com",,,IOP Publishing Ltd,"2021 2nd International Conference on Internet of Things, Artificial Intelligence and Mechanical Automation, IoTAIMA 2021",14 May 2021 through 16 May 2021,,169947,17426588,,,,English,J. Phys. Conf. Ser.,Conference Paper,Final,"All Open Access, Bronze",Scopus,2-s2.0-85109270755
"Hu Y., Sun S.",57216877060;8892785100;,RL-VAEGAN: Adversarial defense for reinforcement learning agents via style transfer,2021,Knowledge-Based Systems,221,,106967,,,,,10.1016/j.knosys.2021.106967,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102967148&doi=10.1016%2fj.knosys.2021.106967&partnerID=40&md5=3afd153854affbbbe563ae1d00e35e0c,"School of Computer Science and Technology, East China Normal University, 3663 North Zhongshan Road, Shanghai, 200062, China","Hu, Y., School of Computer Science and Technology, East China Normal University, 3663 North Zhongshan Road, Shanghai, 200062, China; Sun, S., School of Computer Science and Technology, East China Normal University, 3663 North Zhongshan Road, Shanghai, 200062, China","Reinforcement learning (RL) agents parameterized by deep neural networks have achieved great success in many domains. However, deep RL policies have been shown to be vulnerable to adversarial attacks, i.e., inputs with slight perturbations should result in a substantial agent failure. Inspired by recent advances in deep generative networks that have greatly facilitated the development of adversarial attacks, in this paper, we investigate the adversarial robustness of RL agents and propose a novel defense framework for RL based on the idea of style transfer. More precisely, our defense framework containing variational autoencoders (VAEs) and generative adversarial networks (GANs), called RL-VAEGAN, learns the distribution of the styles of the original and adversarial states, respectively, and naturally eliminates the threat of adversarial attacks for RL agents by transferring adversarial states to unperturbed legitimate one under the shared-content latent space assumption. We empirically show that our methods are effective against the state-of-the-art methods in white-box and black-box scenarios with diverse magnitudes of perturbations. © 2021 Elsevier B.V.",Adversarial attack; Adversarial defense; Reinforcement learning; Robust agents; Trusted artificial intelligence,Autonomous agents; Deep neural networks; Intelligent agents; Multi agent systems; Network security; Adversarial attack; Adversarial defense; Autoencoders; Learning policy; Neural-networks; Parameterized; Reinforcement learning agent; Reinforcement learnings; Robust agent; Trusted artificial intelligence; Reinforcement learning,,,,,"Zheng, G., Zhang, F., Zheng, Z., Xiang, Y., Yuan, N.J., Xie, X., Li, Z., DRN: A deep reinforcement learning framework for news recommendation (2018), pp. 167-176. , World Wide Web Conference; Shalev-Shwartz, S., Shammah, S., Shashua, A., Safe, multi-agent, reinforcement learning for autonomous driving (2016), pp. 1-13. , arXiv preprint; Lillicrap, T.P., Hunt, J.J., Pritzel, A., Heess, N., Erez, T., Tassa, Y., Silver, D., Wierstra, D., Continuous control with deep reinforcement learning (2016), pp. 1-14. , International Conference on Machine Learning; Duan, Y., Chen, X., Houthooft, R., Schulman, J., Abbeel, P., Benchmarking deep reinforcement learning for continuous control (2016), pp. 1329-1338. , International Conference on Machine Learning; Lin, Y., Hong, Z., Liao, Y., Shih, M., Liu, M., Sun, M., Tactics of adversarial attack on deep reinforcement learning agents (2017), pp. 1-7. , arXiv preprint; Ben-Tal, A., El Ghaoui, L., Nemirovski, A., Robust Optimization, Vol. 28 (2009); Biggio, B., Roli, F., Wild patterns: Ten years after the rise of adversarial machine learning (2018) Pattern Recognit., 84, pp. 317-331; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015), pp. 1-11. , International Conference on Machine Learning; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014), pp. 1-10. , International Conference on Machine Learning; Han, K., Li, Y., Hang, J., Adversary resistant deep neural networks via advanced feature nullification (2019) Knowl.-Based Syst., 179, pp. 108-116; Jia, R., Liang, P., Adversarial examples for evaluating reading comprehension systems (2017), pp. 1-11. , Conference on Empirical Methods in Natural Language Processing; Carlini, N., Wagner, D., Audio adversarial examples: Targeted attacks on speech-to-text (2018), pp. 1-7. , IEEE Security and Privacy Workshops; Schmidt, L., Santurkar, S., Tsipras, D., Talwar, K., Madry, A., Adversarially robust generalization requires more data (2018), pp. 5014-5026. , Advances in Neural Information Processing Systems; Dimitris Tsipras, L.E.A.T., Shibani Santurkar, Y., Madry, A., There is no free lunch in adversarial robustness (but there are unexpected benefits) (2018), pp. 1-19. , arXiv preprint; Bubeck, S., Lee, Y.T., Price, E., Razenshteyn, I., Adversarial examples from computational constraints (2019), pp. 831-840. , International Conference on Machine Learning; Ilyas, A., Santurkar, S., Tsipras, D., Engstrom, L., Tran, B., Madry, A., Adversarial examples are not bugs, they are features (2019) Advances in Neural Information Processing Systems, pp. 125-136; Raghunathan, A., Xie, S.M., Yang, F., Duchi, J., Liang, P., Understanding and mitigating the tradeoff between robustness and accuracy (2020), pp. 1-26. , arXiv preprint; Gilmer, J., Metz, L., Faghri, F., Schoenholz, S.S., Raghu, M., Wattenberg, M., Goodfellow, I., (2018), pp. 1-14. , Adversarial spheres, in: Workshop of International Conference on Learning Representations; Huang, S., Papernot, N., Goodfellow, I., Duan, Y., Abbeel, P., Adversarial attacks on neural network policies (2017), pp. 1-10. , arXiv preprint; Pattanaik, A., Tang, Z., Liu, S., Bommannan, G., Chowdhary, G., Robust deep reinforcement learning with adversarial attacks (2018), pp. 2040-2042. , International Conference on Autonomous Agents and Multiagent Systems; Kos, J., Song, D., Delving into adversarial attacks on deep policies (2017), pp. 1-4. , arXiv preprint; Pinto, L., Davidson, J., Sukthankar, R., Gupta, A., Robust adversarial reinforcement learning (2017), pp. 1-12. , arXiv preprint; Pan, X., Seita, D., Gao, Y., Canny, J., Risk averse robust adversarial reinforcement learning (2019), pp. 8522-8528. , International Conference on Robotics and Automation; Sutton, R.S., McAllester, D.A., Singh, S.P., Mansour, Y., Policy gradient methods for reinforcement learning with function approximation (2000) Advances in Neural Information Processing Systems, pp. 1057-1063; Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.A., Veness, J., Bellemare, M.G., Graves, A., Ostrovski, G., Human-level control through deep reinforcement learning (2015) Nature, 518 (7540), pp. 529-533; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017), pp. 39-57. , IEEE Symposium on Security and Privacy; Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2017), pp. 1-22. , arXiv preprint; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2016), pp. 1-24. , arXiv preprint; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017), pp. 506-519. , Proceedings of the ACM on Asia Conference on Computer and Communications Security; Huang, X., Liu, M., Belongie, S., Kautz, J., Multimodal unsupervised image-to-image translation (2018), pp. 172-189. , European Conference on Computer Vision; Zhu, J.-Y., Park, T., Isola, P., Efros, A.A., Unpaired image-to-image translation using cycle-consistent adversarial networks (2017), pp. 2223-2232. , International Conference on Computer Vision; Gatys, L.A., Ecker, A.S., Bethge, M., Image style transfer using convolutional neural networks (2016), pp. 2414-2423. , Conference on Computer Vision and Pattern; Schulman, J., Levine, S., Abbeel, P., Jordan, M., Moritz, P., Trust region policy optimization (2015), pp. 1889-1897. , International Conference on Machine Learning; Mnih, V., Badia, A.P., Mirza, M., Graves, A., Lillicrap, T., Harley, T., Silver, D., Kavukcuoglu, K., Asynchronous methods for deep reinforcement learning (2016), pp. 1928-1937. , International Conference on Machine Learning; Behzadan, V., Munir, A., Vulnerability of deep reinforcement learning to policy induction attacks (2017) International Conference on Machine Learning and Data Mining in Pattern Recognition, pp. 262-275. , Springer; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2016), pp. 1-14. , arXiv preprint; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016), pp. 372-387. , IEEE European Symposium on Security and Privacy; García, J., Majadas, R., Fernández, F., Learning adversarial attack policies through multi-objective reinforcement learning (2020) Eng. Appl. Artif. Intell., 96; Tretschk, E., Oh, S.J., Fritz, M., Sequential attacks on agents for long-term adversarial goals (2018), pp. 1-9. , arXiv preprint; Baluja, S., Fischer, I., Learning to attack: Adversarial transformation networks (2018) Proc. AAAI Conf. Artif. Intell., 32 (1), pp. 1-9; Kiourti, P., Wardega, K., Jha, S., Li, W., Trojdrl: Trojan attacks on deep reinforcement learning agents (2019), pp. 1-17. , arXiv preprint; Miyato, T., Dai, A.M., Goodfellow, I., Adversarial training methods for semi-supervised text classification (2016), pp. 1-11. , arXiv preprint; Han, Y., Rubinstein, B.I., Abraham, T., Alpcan, T., De Vel, O., Erfani, S., Hubczenko, D., Montague, P., Reinforcement learning for autonomous defence in software-defined networking (2018) International Conference on Decision and Game Theory for Security, pp. 145-165. , Springer; Behzadan, V., Munir, A., Whatever does not kill deep reinforcement learning, makes it stronger (2017), pp. 1-8. , arXiv preprint; Behzadan, V., Munir, A., Mitigation of policy manipulation attacks on deep Q-networks with parameter-space noise (2018) International Conference on Computer Safety, Reliability, and Security, pp. 406-417. , Springer; Fortunato, M., Azar, M.G., Piot, B., Menick, J., Osband, I., Graves, A., Mnih, V., Pietquin, O., (2017), pp. 1-21. , Noisy networks for exploration, in: International Conference on Learning Representations; Moosavi-Dezfooli, S., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017), pp. 1765-1773. , Conference on Computer Vision and Pattern; Abdullah, M.A., Ren, H., Ammar, H.B., Milenkovic, V., Luo, R., Zhang, M., Wang, J., Wasserstein robust reinforcement learning (2019), pp. 1-22. , arXiv preprint; Barnett, S.A., Convergence problems with generative adversarial networks (gans) (2018), pp. 1-47. , arXiv preprint; Tessler, C., Efroni, Y., Mannor, S., Action robust reinforcement learning and applications in continuous control (2019), pp. 1-29. , arXiv preprint; Singh, R., Zhang, Q., Chen, Y., Improving robustness via risk averse distributional reinforcement learning (2020), pp. 1-11. , arXiv preprint; Lin, Y.-C., Liu, M.-Y., Sun, M., Huang, J.-B., Detecting adversarial attacks on neural network policies with visual foresight (2017), arXiv preprint; Havens, A., Jiang, Z., Sarkar, S., Online robust policy learning in the presence of unknown adversaries (2018) Adv. Neural Inf. Process. Syst., 31, pp. 9916-9926; Xiao, C., Li, B., Zhu, J.-Y., He, W., Liu, M., Song, D., Generating adversarial examples with adversarial networks (2018), pp. 1-8. , arXiv preprint; Jandial, S., Mangla, P., Varshney, S., Balasubramanian, V., (2019), pp. 1-4. , Advgan++: Harnessing latent layers for adversary generation, in: International Conference on Computer Vision Workshops; Zhao, Z., Dua, D., Singh, S., Generating natural adversarial examples (2017), pp. 1-15. , arXiv preprint; Samangouei, P., Kabkab, M., Chellappa, R., Defense-gan: Protecting classifiers against adversarial attacks using generative models (2018), pp. 1-17. , International Conference on Machine Learning; Liu, M., Breuel, T., Kautz, J., Unsupervised image-to-image translation networks (2017) Advances in Neural Information Processing Systems, pp. 700-708; Larsen, A.B.L., Sønderby, S.K., Larochelle, H., Winther, O., Autoencoding beyond pixels using a learned similarity metric (2016), pp. 1558-1566. , International Conference on Machine Learning; Kingma, D.P., Welling, M., Auto-encoding variational bayes (2013), pp. 1-14. , arXiv preprint; Rifai, S., Vincent, P., Muller, X., Glorot, X., Bengio, Y., Contractive auto-encoders: Explicit invariance during feature extraction (2011), pp. 833-840. , International Conference on Machine Learning; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, pp. 2672-2680; Arjovsky, M., Chintala, S., Bottou, L., Wasserstein gan (2017), pp. 1-32. , arXiv preprint; Brockman, G., Cheung, V., Pettersson, L., Schneider, J., Schulman, J., Tang, J., Zaremba, W., Openai gym (2016), pp. 1-4. , arXiv preprint","Sun, S.; School of Computer Science and Technology, 3663 North Zhongshan Road, China; 电子邮件: slsun@cs.ecnu.edu.cn",,,Elsevier B.V.,,,,,9507051,,KNSYE,,English,Knowl Based Syst,Article,Final,,Scopus,2-s2.0-85102967148
"Neekhara P., Dolhansky B., Bitton J., Ferrer C.C.",57211639826;37088614000;57219748124;57193797605;,Adversarial threats to deepfake detection: A practical perspective,2021,IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops,,,,923,932,,,10.1109/CVPRW53098.2021.00103,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116022545&doi=10.1109%2fCVPRW53098.2021.00103&partnerID=40&md5=e1b67d9887052a8d8c6b7494f6f29b21,UC San Diego,"Neekhara, P., UC San Diego; Dolhansky, B., UC San Diego; Bitton, J., UC San Diego; Ferrer, C.C., UC San Diego","Facially manipulated images and videos or DeepFakes can be used maliciously to fuel misinformation or defame individuals. Therefore, detecting DeepFakes is crucial to increase the credibility of social media platforms and other media sharing web sites. State-of-the art DeepFake detection techniques rely on neural network based classification models which are known to be vulnerable to adversarial examples. In this work, we study the vulnerabilities of state-of-the-art DeepFake detection methods from a practical stand point. We perform adversarial attacks on DeepFake detectors in a black box setting where the adversary does not have complete knowledge of the classification models. We study the extent to which adversarial perturbations transfer across different models and propose techniques to improve the transferability of adversarial examples. We also create more accessible attacks using Universal Adversarial Perturbations which pose a very feasible attack scenario since they can be easily shared amongst attackers. We perform our evaluations on the winning entries of the DeepFake Detection Challenge (DFDC) and demonstrate that they can be easily bypassed in a practical attack scenario by designing transferable and accessible adversarial attacks.1 © 2021 IEEE.",,Attacks scenarios; Black boxes; Classification models; Detection methods; Network-based; Neural-networks; Perturbation transfer; Social media platforms; State of the art; Web-sites; Computer vision,,,,,"Afchar, D., Nozick, V., Yamagishi, J., Echizen, I., MesoNet: A compact facial video forgery detection network (2018) InWorkshop on Information Forensics and Security (WIFS), , 2; Amerini, I., Galteri, L., Caldelli, R., Bimbo, A.D., Deepfake video detection through optical flow based CNN (2019) International Conference on Computer Vision (ICCV) Workshops, , 2; Athalye, A., Engstrom, L., Ilyas, A., Kwok, K., Synthesizing robust adversarial examples (2018) International Conference on Machine Learning (ICML), , 4; Behjati, M., Moosavi-Dezfooli, S.-M., Baghshah, M.S., Frossard, P., Universal adversarial attacks on text classifiers (2019) International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 7345-7349. , 3, 5; Carlini, N., Farid, H., (2020) Evading Deepfake-image Detectors with White- And Black-box Attacks, , 1, 3; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Symposium on Security and Privacy, pp. 39-57. , 3, 4; Cheng, S., Dong, Y., Pang, T., Su, H., Zhu, J., Improving black-box adversarial attacks with a transfer-based prior (2019) Advances in Neural Information Processing Systems (NIPS), pp. 10934-10944. , 3; Chollet, F., Xception: Deep learning with depthwise separable convolutions (2017) Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1251-1258. , 2, 6; https://github.com/ntech-lab/deepfakedetection-challenge, Azat Davletshin. 2, 6; Deng, J., Guo, J., Ververas, E., Kotsia, I., Zafeiriou, S., Conference on Computer Vision and Pattern Recognition (CVPR), , RetinaFace: Single-shot multi-level face localisation in the wild. 6; Dolhansky, B., Bitton, J., Pflaum, B., Lu, J., Howes, R., Wang, M., Ferrer, C.C., (2020) The DeepFake Detection Challenge (DFDC) Dataset, , 1, 2; Dolhansky, B., Howes, R., Pflaum, B., Baram, N., Ferrer, C.C., (2019) The DeepFake Detection Challenge (DFDC) Preview Dataset, , 2, 6; Apurva, G., Jain, S., (2020) Adversarial Perturbations Fool Deepfake Detectors, , 1, 3; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations (ICLR), , 1, 3; https://github.com/cuihaoleo/kaggle-dfdc, Cui Hao. 2, 6; Karras, T., Laine, S., Aila, T., A style-based generator architecture for generative adversarial networks (2019) Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4401-4410. , 2; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , 4; Li, J., Wang, Y., Wang, C., Tai, Y., Qian, J., Yang, J., Wang, C., Huang, F., DSFD: dual shot face detector. 6, In Conference on Computer Vision and Pattern Recognition (CVPR); Li, Y., Lyu, S., Exposing deepfake videos by detecting face warping artifacts (2019) Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pp. 46-52. , 2; Liu, H., Ji, R., Li, J., Zhang, B., Gao, Y., Wu, Y., Huang, F., Universal adversarial perturbation via prior driven uncertainty approximation (2019) International Conference on Computer Vision (ICCV), , 3; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and blackbox attacks (2017) International Conference on Learning Representations (ICLR), , 3; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) Conference on Computer Vision and Pattern Recognition (CVPR), , 3, 5; Mopuri, K.R., Garg, U., Venkatesh Babu, R., (2017) Fast Feature Fool: A Data Independent Approach to Universal Adversarial Perturbations, , 3; Neekhara, P., Hussain, S., Jere, M., Koushanfar, F., McAuley, J., (2020) Adversarial Deepfakes: Evaluating Vulnerability of Deepfake Detectors to Adversarial Examples, , 1, 2, 3, 4, 6; Paarth, N., Hussain, S., Prakhar, P., Dubnov, S., McAuley, J., Koushanfar, F., Universal adversarial perturbations for speech recognition systems (2019) Interspeech, , 3, 5; Nirkin, Y., Keller, Y., Hassner, T., FSGAN: Subject agnostic face swapping and reenactment (2019) Conference on Computer Vision and Pattern Recognition (CVPR), pp. 7184-7193. , 2; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples, , 3; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, B., Swami, A., Practical black-box attacks against machine learning (2017) ACM Asia Conference on Computer and Communications Security, pp. 506-519. , 3; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) ACM on Asia Conference on Computer and Communications Security, , 3; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2016) European Symposium on Security and Privacy (EuroS&P), , 3; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Symposium on Security and Privacy (SP), pp. 582-597. , 4; Rahmouni, N., Nozick, V., Yamagishi, J., Echizen, I., Distinguishing computer graphics from natural images using convolution neural networks (2017) Workshop on Information Forensics and Security (WIFS), , 2; Mopuri, K.R., Uppala, P.K., Babu, R.V., Ask, acquire, and attack: Data-free uap generation using class impressions (2018) European Conference on Computer Vision (ECCV), pp. 19-34. , 3; Rossler, A., Cozzolino, D., Verdoliva, L., Riess, C., Thies, J., Niessner, M., FaceForensics++: Learning to detect manipulated facial images (2019) International Conference on Computer Vision (ICCV), , 2; https://github.com/selimsef/dfdcdeepfakechallenge, Selim Seferbekov. 2, 3, 6; Shi, Y., Wang, S., Han, Y., Curls & whey: Boosting black-box adversarial attacks (2019) Conference on Computer Vision and Pattern Recognition (CVPR), , 3; Song, D., Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Tram`er, F., Kohno, T., Physical adversarial examples for object detectors (2018) USENIX Workshop on Offensive Technologies, , 3; Springenberg, J.T., Dosovitskiy, A., Brox, T., Riedmiller, M., Striving for simplicity: The all convolutional net (2015) International Conference on Learning Representations (ICLR), , 2; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , 1, 3; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations (ICLR), , 1, 3; Tan, M., Le, Q.V., (2019) Efficientnet: Rethinking Model Scaling for Convolutional Neural Networks, , 6; Verdoliva, L., (2020) Media Forensics and Deepfakes: An Overview, , 1; Westerlund, M., The emergence of deepfake technology: A review (2019) Technology Innovation Management Review, 9, pp. 40-53. , 1; Zakharov, E., Shysheya, A., Burkov, E., Lempitsky, V., Few-shot adversarial learning of realistic neural talking head models (2019) International Conference on Computer Vision (ICCV), pp. 9459-9468. , 2; Zhang, K., Zhang, Z., Li, Z., Qiao, Y., Joint face detection and alignment using multitask cascaded convolutional networks (2016) IEEE Signal Processing Letters, 23 (10), pp. 1499-1503. , 6; Zhou, W., Hou, X., Chen, Y., Tang, M., Huang, X., Gan, X., Yang, Y., Transferable adversarial perturbations (2018) European Conference on Computer Vision (ECCV), pp. 452-467. , 3",,,,IEEE Computer Society,"2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, CVPRW 2021",19 June 2021 through 25 June 2021,,171537,21607508,9.78E+12,,,English,IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recogn. Workshops,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85116022545
"Chin T.-W., Zhang C., Marculescu D.",57271078900;57219502648;7004688039;,Renofeation: A simple transfer learning method for improved adversarial robustness,2021,IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops,,,,3237,3246,,,10.1109/CVPRW53098.2021.00362,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116015687&doi=10.1109%2fCVPRW53098.2021.00362&partnerID=40&md5=1d26881614f16dee92faaf987516fa1e,Carnegie Mellon University; Microsoft Cloud and AI; University of Texas at Austin,"Chin, T.-W., Carnegie Mellon University; Zhang, C., Microsoft Cloud and AI; Marculescu, D., Carnegie Mellon University, University of Texas at Austin","Fine-tuning through knowledge transfer from a pre-trained model on a large-scale dataset is a widely spread approach to effectively build models on small-scale datasets. In this work, we show that a recent adversarial attack designed for transfer learning via re-training the last linear layer can successfully deceive models trained with transfer learning via end-to-end fine-tuning. This raises security concerns for many industrial applications. In contrast, models trained with random initialization without transfer are much more robust to such attacks, although these models often exhibit much lower accuracy. To this end, we propose noisy feature distillation, a new transfer learning method that trains a network from random initialization while achieving clean-data performance competitive with fine-tuning. © 2021 IEEE.",,Computer vision; Distillation; Large dataset; Learning systems; Contrast models; Data performance; End to end; Fine tuning; Knowledge transfer; Large-scale datasets; Simple++; Small scale; Transfer learning; Transfer learning methods; Knowledge management,,,,,"Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 Ieee Symposium on Security and Privacy (Sp), pp. 39-57. , IEEE 2; Chen, P., Zhang, H., Sharma, Y., Yi, J., Hsieh, C., Zoo: Zeroth order optimization based blackbox attacks to deep neural networks without training substitute models (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 15-26. , 2; Chin, T., Ding, R., Zhang, C., Marculescu, D., (2019) Legr: Filter Pruning Via Learned Global Ranking, , 6; Cui, Y., Song, Y., Sun, C., Howard, A., Belongie, S., Large scale fine-grained categorization and domain-specific transfer learning (2018) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , June. 1, 2; Weiguang Ding, G., Wang, L., Jin, X., (2019) AdverTorch v0.1: An Adversarial Robustness Toolbox Based on Pytorch, , 5; Donahue, J., Jia, Y., Vinyals, O., Hoffman, J., Zhang, N., Tzeng, E., Darrell, T., Decaf: A deep convolutional activation feature for generic visual recognition (2014) International Conference on Machine Learning, pp. 647-655. , 1, 2; Ge, W., Yu, Y., Borrowing treasures from the wealthy: Deep transfer learning through selective joint finetuning (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1086-1095. , 2; Goldblum, M., Fowl, L., Feizi, S., Goldstein, T., (2019) Adversarially Robust Distillation, , 2; Goodfellow, I.J., (2014) Jonathon Shlens, and Christian Szegedy. Explaining and Harnessing Adversarial Examples, , 2; Cloud Automll, , https://cloud.google.com/automl, 1; He, K., Girshick, R., Dollár, P., Rethinking imagenet pre-training (2019) Proceedings of the IEEE International Conference on Computer Vision, pp. 4918-4927. , 1, 2; Hinton, G.E., Srivastava, N., Krizhevsky, A., Sutskever, I., Salakhutdinov, R.R., (2012) Improving Neural Networks by Preventing Co-adaptation of Feature Detectors, , 4; Izmailov, P., Podoprikhin, D., Garipov, T., Vetrov, D., Gordon Wilson, A., (2018) Averaging Weights Leads to Wider Optima and Better Generalization, , 4; Jang, Y., Lee, H., Ju Hwang, S., Shin, J., Learning what and where to transfer (2019) Proceedings of the 36th International Conference on Machine Learning of Proceedings of Machine Learning Research, 97, pp. 3030-3039. , In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, Long Beach, California, USA, 09-15 Jun. PMLR. 2; Khosla, A., Jayadevaprakash, N., Yao, B., Li, F., Novel dataset for fine-grained image categorization: Stanford dogs (2011) Proc. CVPR Workshop on Fine-Grained Visual Categorization (FGVC), 2. , 3, 5; Lee, C., Cho, K., Kang, W., (2019) Mixout: Effective Regularization to Finetune Large-scale Pretrained Language Models, , 2; Li, H., Chaudhari, P., Yang, H., Lam, M., Ravichandran, A., Bhotika, R., Soatto, S., Rethinking the hyperparameters for fine-tuning (2020) International Conference on Learning Representations, , 2, 4; Li, X., Xiong, H., Wang, H., Rao, Y., Liu, L., Huan, J., Delta: Deep learning transfer using feature map with attention for convolutional networks (2019) International Conference on Learning Representations, , 1, 2, 3, 4; (2017) Food Classification with Custom Vision Service, , https://www.microsoft.com/developerblog/2017/05/12/food-classification-custom-vision-service/, Olga Liakhovich and Claudius Mbemba, May. 1; Liu, Y., Chen, X., Liu, C., Song, D., (2016) Delving into Transferable Adversarial Examples and Blackbox Attacks, , 2; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , 2; Nilsback, M., Zisserman, A., Automated flower classification over a large number of classes (2008) 2008 Sixth Indian Conference on Computer Vision, Graphics & Image Processing, pp. 722-729. , IEEE 3, 5; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples, , 2; Quattoni, A., Torralba, A., Recognizing indoor scenes (2009) 2009 IEEE Conference on Computer Vision and Pattern Recognition, pp. 413-420. , IEEE 3, 5; Raghu, M., Zhang, C., Kleinberg, J., Bengio, S., Transfusion: Understanding transfer learning for medical imaging (2019) Advances in Neural Information Processing Systems, 32, pp. 3342-3352. , In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, and R. Garnett, editors, . Curran Associates, Inc 1; Raghu, M., Zhang, C., Kleinberg, J., Bengio, S., Transfusion: Understanding transfer learning for medical imaging (2019) Advances in Neural Information Processing Systems, pp. 3342-3352. , 2; Rezaei, S., Liu, X., A target-agnostic attack on deep models: Exploiting security vulnerabilities of transfer learning (2020) International Conference on Learning Representations, , 1, 2, 3, 5, 8; Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., Chen, L., Mobilenetv2: Inverted residuals and linear bottlenecks (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4510-4520. , 6; Shafahi, A., Saadatpanah, P., Zhu, C., Ghiasi, A., Studer, C., Jacobs, D., Goldstein, T., Adversarially robust transfer learning (2020) International Conference on Learning Representations, , 2; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition, , 1, 2; Stamoulis, D., Ding, R., Wang, D., Lymberopoulos, D., Priyantha, B., Liu, J., Marculescu, D., (2019) Single-path Nas: Designing Hardware-efficient Convnets in Less Than 4 Hours, , 6; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , 2; Tompson, J., Goroshin, R., Jain, A., LeCun, Y., Bregler, C., Efficient object localization using convolutional networks (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 648-656. , 4; Wang, K., Gao, X., Zhao, Y., Li, X., Dou, D., Xu, C., Pay attention to features, transfer learn faster {cnn}s (2020) International Conference on Learning Representations, , 2, 6; Wang, S., Wang, X., Zhao, P., Wen, W., Kaeli, D., Chin, P., Lin, X., Defensive dropout for hardening deep neural networks under adversarial attacks (2018) Proceedings of the International Conference on Computer-Aided Design, pp. 1-8. , 4; Wang, Y.-X., Ramanan, D., Hebert, M., Growing a brain: Fine-tuning by increasing model capacity (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2471-2480. , 2; Welinder, P., Branson, S., Mita, T., Wah, C., Schroff, F., Belongie, S., Perona, P., (2010) Caltech-UCSD Birds 200, , Technical Report CNS-TR-2010-001, California Institute of Technology 1, 3, 5; Wu, B., Dai, X., Zhang, P., Wang, Y., Sun, F., Wu, Y., Tian, Y., Keutzer, K., Fbnet: Hardware-aware efficient convnet design via differentiable neural architecture search (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 10734-10742. , 6; Xuhong, L., Grandvalet, Y., Davoine, F., Explicit inductive bias for transfer learning with convolutional networks (2018) International Conference on Machine Learning, pp. 2825-2834. , 1, 2, 3, 4; Yao, B., Jiang, X., Khosla, A., Lai Lin, A., Guibas, L., Fei-Fei, L., Human action recognition by learning bases of action attributes and parts (2011) 2011 International Conference on Computer Vision, pp. 1331-1338. , IEEE 3, 5; Yosinski, J., Clune, J., Bengio, Y., Lipson, H., How transferable are features in deep neural networks? (2014) Advances in Neural Information Processing Systems, pp. 3320-3328. , 1, 2",,,,IEEE Computer Society,"2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, CVPRW 2021",19 June 2021 through 25 June 2021,,171537,21607508,9.78E+12,,,English,IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recogn. Workshops,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85116015687
"Na Y., Kim J.H., Lee K., Park J., Hwang J.Y., Choi J.P.",57219742467;57204051896;57215845124;57204046269;26535988800;7501391429;,Domain Adaptive Transfer Attack-Based Segmentation Networks for Building Extraction from Aerial Images,2021,IEEE Transactions on Geoscience and Remote Sensing,59,6,9153039,5171,5182,,5,10.1109/TGRS.2020.3010055,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104905001&doi=10.1109%2fTGRS.2020.3010055&partnerID=40&md5=85ed988ea7fca88355579aa784274886,"Department of Information and Communication Engineering, Daegu Gyeongbuk Institute of Science and Technology (DGIST), Daegu, South Korea; Agency for Defense Development, Daejeon, South Korea; Dabeeo Inc., Seoul, South Korea","Na, Y., Department of Information and Communication Engineering, Daegu Gyeongbuk Institute of Science and Technology (DGIST), Daegu, South Korea; Kim, J.H., Agency for Defense Development, Daejeon, South Korea; Lee, K., Department of Information and Communication Engineering, Daegu Gyeongbuk Institute of Science and Technology (DGIST), Daegu, South Korea; Park, J., Dabeeo Inc., Seoul, South Korea; Hwang, J.Y., Department of Information and Communication Engineering, Daegu Gyeongbuk Institute of Science and Technology (DGIST), Daegu, South Korea; Choi, J.P., Department of Information and Communication Engineering, Daegu Gyeongbuk Institute of Science and Technology (DGIST), Daegu, South Korea","Semantic segmentation models based on convolutional neural networks (CNNs) have gained much attention in relation to remote sensing and have achieved remarkable performance for the extraction of buildings from high-resolution aerial images. However, the issue of limited generalization for unseen images remains. When there is a domain gap between the training and test data sets, the CNN-based segmentation models trained by a training data set fail to segment buildings for the test data set. In this article, we propose segmentation networks based on a domain adaptive transfer attack (DATA) scheme for building extraction from aerial images. The proposed system combines the domain transfer and the adversarial attack concepts. Based on the DATA scheme, the distribution of the input images can be shifted to that of the target images while turning images into adversarial examples against a target network. Defending adversarial examples adapted to the target domain can overcome the performance degradation due to the domain gap and increase the robustness of the segmentation model. Cross-data set experiments and ablation study are conducted for three different data sets: the Inria aerial image labeling data set, the Massachusetts building data set, and the WHU East Asia data set. Compared with the performance of the segmentation network without the DATA scheme, the proposed method shows improvements in the overall intersection over union (IoU). Moreover, it is verified that the proposed method outperforms even when compared with feature adaptation (FA) and output space adaptation (OSA). © 1980-2012 IEEE.",Adversarial network; building extraction; domain adaptation; semantic segmentation,Antennas; Buildings; Convolutional neural networks; Extraction; Remote sensing; Semantics; Statistical tests; Building extraction; Domain transfers; Feature adaptation; High-resolution aerial images; Performance degradation; Segmentation models; Semantic segmentation; Training data sets; Image segmentation; algorithm; image classification; network analysis; segmentation,,,,,"Maggiori, E., Tarabalka, Y., Charpiat, G., Alliez, P., Can semantic labeling methods generalize to any city? The Inria aerial image labeling benchmark (2017) Proc. IEEE Int. Geosci. Remote Sens. Symp. (IGARSS), pp. 3226-3229. , Jul; Mnih, V., (2013) Machine Learning for Aerial Image Labeling, , Ph.D. dissertation, Dept. Comput. Sci., Univ. Toronto, ON, Canada; Ji, S., Wei, S., Lu, M., Fully convolutional networks for multisource building extraction from an open aerial and satellite imagery data set (2019) IEEE Trans. Geosci. Remote Sens., 57 (1), pp. 574-586. , Jan; Guo, Y., Ji, J., Lu, X., Huo, H., Fang, T., Li, D., Global-local attention network for aerial scene classification (2019) IEEE Access, 7, pp. 67200-67212; Blundell, J.S., Opitz, D.W., Object recognition and feature extraction from imagery: The feature analyst approach (2006) Int. Arch. Photogram., Remote Sens. Spatial Inf. Sci., 36 (4), p. C42; Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324. , Nov; Chen, S., Wang, H., Xu, F., Jin, Y.-Q., Target classification using the deep convolutional networks for SAR images (2016) IEEE Trans. Geosci. Remote Sens., 54 (8), pp. 4806-4817. , Aug; Luus, F.P.S., Salmon, B.P., Van Den Bergh, F., Maharaj, B.T.J., Multiview deep learning for land-use classification (2015) IEEE Geosci. Remote Sens. Lett., 12 (12), pp. 2448-2452. , Dec; Chen, Y., Zhao, X., Jia, X., Spectral-spatial classification of hyperspectral data based on deep belief network (2015) IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens., 8 (6), pp. 2381-2392. , Jun; Li, W., Liu, H., Wang, Y., Li, Z., Jia, Y., Gui, G., Deep learningbased classification methods for remote sensing images in urban built-up areas (2019) IEEE Access, 7, pp. 36274-36284; Liu, Y., Zhong, Y., Qin, Q., Scene classification based on multiscale convolutional neural network (2018) IEEE Trans. Geosci. Remote Sens., 56 (12), pp. 7109-7121. , Dec; Liu, Q., Hang, R., Song, H., Li, Z., Learning multiscale deep features for high-resolution satellite image scene classification (2018) IEEE Trans. Geosci. Remote Sens., 56 (1), pp. 117-126. , Jan; Diao, W., Sun, X., Zheng, X., Dou, F., Wang, H., Fu, K., Efficient saliency-based object detection in remote sensing images using deep belief networks (2016) IEEE Geosci. Remote Sens. Lett., 13 (2), pp. 137-141. , Feb; Chen, X., Xiang, S., Liu, C.-L., Pan, C.-H., Vehicle detection in satellite images by hybrid deep convolutional neural networks (2014) IEEE Geosci. Remote Sens. Lett., 11 (10), pp. 1797-1801. , Oct; Lin, Z., Ji, K., Leng, X., Kuang, G., Squeeze and excitation rank faster R-CNN for ship detection in SAR images (2019) IEEE Geosci. Remote Sens. Lett., 16 (5), pp. 751-755. , May; Deng, Z., Sun, H., Zhou, S., Zhao, J., Learning deep ship detector in SAR images from scratch (2019) IEEE Trans. Geosci. Remote Sens., 57 (6), pp. 4021-4039. , Jun; Maggiori, E., Charpiat, G., Tarabalka, Y., Alliez, P., Recurrent neural networks to correct satellite image classification maps (2017) IEEE Trans. Geosci. Remote Sens., 55 (9), pp. 4962-4971. , Sep; Mou, L., Xiang Zhu, X., (2018) RiFCN: Recurrent Network in Fully Convolutional Network for Semantic Segmentation of High Resolution Remote Sensing Images, , http://arxiv.org/abs/1805.02091; Li, X., Yao, X., Fang, Y., Building-A-nets: Robust building extraction from high-resolution remote sensing images with adversarial networks (2018) IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens., 11 (10), pp. 3680-3687. , Oct; Goodfellow, I., Generative adversarial nets (2014) Proc. Adv. Neural Inf. Process. Syst., pp. 2672-2680; Hu, T., Wang, Y., Chen, Y., Lu, P., Wang, H., Wang, G., Sobel heuristic kernel for aerial semantic segmentation (2018) Proc. 25th IEEE Int. Conf. Image Process. (ICIP), pp. 3074-3078. , Oct; Gupta, S., Mazumdar, S.G., Sobel edge detection algorithm (2013) Int. J. Comput. Sci. Manage. Res., 2 (2), pp. 1578-1583. , Feb; Kim, J.H., Objects segmentation from high-resolution aerial images using U-Net with pyramid pooling layers (2019) IEEE Geosci. Remote Sens. Lett., 16 (1), pp. 115-119. , Jan; Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J., Pyramid scene parsing network (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 6230-6239. , Jul; Ronneberger, O., Fischer, P., Brox, T., U-net: Convolutional networks for biomedical image segmentation Proc. Med. Image Comput. Comput.-Assisted Intervent, 2015, pp. 234-241; Ganin, Y., Domain-adversarial training of neural networks (2016) J. Mach. Learn. Res., 17 (2), pp. 5901-5935; Bousmalis, K., Silberman, N., Dohan, D., Erhan, D., Krishnan, D., Unsupervised pixel-level domain adaptation with generative adversarial networks (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 3722-3731. , Jul; Chen, Y.-H., Chen, W.-Y., Chen, Y.-T., Tsai, B.-C., Wang, Y.-C.-F., Sun, M., No more discrimination: Cross city adaptation of road scene segmenters (2017) Proc. IEEE Int. Conf. Comput. Vis. (ICCV), pp. 2011-2020. , Oct; Hoffman, J., Wang, D., Yu, F., Darrell, T., (2016) FCNs in the Wild: Pixel-level Adversarial and Constraint-based Adaptation, , http://arxiv.org/abs/1612.02649; Tsai, Y.-H., Hung, W.-C., Schulter, S., Sohn, K., Yang, M.-H., Chandraker, M., Learning to adapt structured output space for semantic segmentation (2018) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., pp. 7472-7481. , Jun; Goodfellow, I., (2017) NIPS 2016 Tutorial: Generative Adversarial Networks, , http://arxiv.org/abs/1701.00160; Huang, S., Papernot, N., Goodfellow, I., Duan, Y., Abbeel, P., (2017) Adversarial Attacks on Neural Network Policies, , http://arxiv.org/abs/1702.02284; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , http://arxiv.org/abs/1412.6572; Szegedy, C., (2013) Intriguing Properties of Neural Networks, , http://arxiv.org/abs/1312.6199; Baluja, S., Fischer, I., (2017) Adversarial Transformation Networks: Learning to Generate Adversarial Examples, , http://arxiv.org/abs/1703.09387; Volpi, R., Namkoong, H., Sener, O., Duchi, J., Murino, V., Savarese, S., Generalizing to unseen domains via adversarial data augmentation (2018) Proc. NIPS, pp. 5334-5344. , Dec; Van Der Maaten, L., Hinton, G., Visualizing data using t-SNE (2008) J. Mach. Learn. Res., 9, pp. 2579-2605. , Nov; Long, J., Shelhamer, E., Darrell, T., Fully convolutional networks for semantic segmentation (2015) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 3431-3440. , Jun; Minh Quan, T., Hildebrand, D.G.C., Jeong, W.-K., (2016) FusionNet: A Deep Fully Residual Convolutional Neural Network for Image Segmentation in Connectomics, , http://arxiv.org/abs/1612.05360; Hu, J., Shen, L., Albanie, S., Sun, G., Wu, E., (2017) Squeeze-and-excitation Networks, , http://arxiv.org/abs/1709.01507; Zhang, Y., Tian, Y., Kong, Y., Zhong, B., Fu, Y., Residual dense network for image super-resolution (2018) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., pp. 2472-2481. , Jun; Huang, G., Liu, Z., Van Der Maaten, L., Weinberger, K.Q., Densely connected convolutional networks (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 2261-2269. , Jul; Ioffe, S., Szegedy, C., Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015) Proc. Int. Conf. Mach. Learn, pp. 448-456; Abadi, M., TensorFlow: A system for large-scale machine learning (2016) Proc. OSDI, 16, pp. 265-283; Kingma, D.P., Ba, J., (2014) Adam: A Method for Stochastic Optimization, , http://arxiv.org/abs/1412.6980; Rahman, M.A., Wang, Y., Optimizing intersection-over-union in deep neural networks for image segmentation (2016) Proc. 12th Int. Symp. I, Adv. Vis. Comput. (ISVC), pp. 234-244. , Las Vegas, NV, USA, Dec., 2016; Lu, K., Sun, Y., Ong, S.-H., Dual-resolution U-Net: Building extraction from aerial images (2018) Proc. 24th Int. Conf. Pattern Recognit. (ICPR), pp. 489-494. , Aug; (2019) Inria Aerial Image Labeling Benchmark Leader Board, , https://project.inria.fr/aerialimagelabeling/leaderboard/, Accessed: Jun. 9; Chatterjee, B., Poullis, C., On building classification from remote sensor imagery using deep neural networks and the relation between classification and reconstruction accuracy using border localization as proxy (2019) Proc. 16th Conf. Comput. Robot Vis. (CRV), pp. 41-48. , May","Kim, J.H.; Agency for Defense DevelopmentSouth Korea; 电子邮件: kjh1127@add.re.kr",,,Institute of Electrical and Electronics Engineers Inc.,,,,,1962892,,IGRSD,,English,IEEE Trans Geosci Remote Sens,Article,Final,"All Open Access, Green",Scopus,2-s2.0-85104905001
"Li Z., Feng C., Wu M., Yu H., Zheng J., Zhu F.",57202927569;57215203955;8301222100;56647076100;37087960400;23394127500;,Adversarial robustness via attention transfer,2021,Pattern Recognition Letters,146,,,172,178,,,10.1016/j.patrec.2021.03.011,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103630302&doi=10.1016%2fj.patrec.2021.03.011&partnerID=40&md5=e11594bee370ecd35d64f1ee5f342536,"School of Computer and Computing Science, Zhejiang University City College, Hangzhou, 310015, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, 310027, China; National Centre for Computer Animation, Bournemouth University, Poole, BH12 5BB, United Kingdom; College of Computer Science and Engineering, Zhejiang University of Technology, Hangzhou, 310014, China","Li, Z., School of Computer and Computing Science, Zhejiang University City College, Hangzhou, 310015, China; Feng, C., College of Computer Science and Technology, Zhejiang University, Hangzhou, 310027, China; Wu, M., School of Computer and Computing Science, Zhejiang University City College, Hangzhou, 310015, China; Yu, H., National Centre for Computer Animation, Bournemouth University, Poole, BH12 5BB, United Kingdom; Zheng, J., College of Computer Science and Engineering, Zhejiang University of Technology, Hangzhou, 310014, China; Zhu, F., School of Computer and Computing Science, Zhejiang University City College, Hangzhou, 310015, China","Deep neural networks are known to be vulnerable to adversarial attacks. The empirical analysis in our study suggests that attacks tend to induce diverse network architectures to shift the attention to irrelevant regions. Motivated by this observation, we propose a regularization technique which enforces the attentions to be well aligned via the knowledge transfer mechanism, thereby encouraging the robustness. Resultant model exhibits unprecedented robustness, securing 63.81% adversarial accuracy where the prior art is 51.59% on CIFAR-10 dataset under PGD attacks. In addition, we go beyond performance to analytically investigate the proposed method as an effective defense. Significantly flattened loss landscape can be observed, demonstrating the promise of the proposed method for improving robustness and thus the deployment in security-sensitive settings. © 2021 Elsevier B.V.",Adversarial defense; Representation learning; Robustness; Transfer learning; Visual attention,Arts computing; Behavioral research; Deep neural networks; Knowledge management; Network architecture; Robustness (control systems); Adversarial defense; Empirical analysis; Knowledge transfer mechanisms; Neural-networks; Prior arts; Regularization technique; Representation learning; Robustness; Transfer learning; Visual Attention; Network security,,,,,"Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2013) arXiv preprint arXiv:1312.6199; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndić, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Joint European conference on machine learning and knowledge discovery in databases, pp. 387-402. , Springer; Pei, K., Cao, Y., Yang, J., Jana, S., Deepxplore: Automated whitebox testing of deep learning systems (2017) proceedings of the 26th Symposium on Operating Systems Principles, pp. 1-18; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in neural information processing systems, pp. 2672-2680; Papernot, N., McDaniel, P., Goodfellow, I., Transferability in machine learning: from phenomena to black-box attacks using adversarial samples (2016) arXiv preprint arXiv:1605.07277; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia conference on computer and communications security, pp. 506-519; Biggio, B., Roli, F., Wild patterns: ten years after the rise of adversarial machine learning (2018) Pattern Recognit., 84, pp. 317-331; Evtimov, I., Eykholt, K., Fernandes, E., Kohno, T., Li, B., Prakash, A., Rahmati, A., Song, D., Robust physical-world attacks on machine learning models (2017) arXiv preprint arXiv:1707.08945, 2 (3), p. 4; Mirjalili, V., Ross, A., Soft biometric privacy: Retaining biometric utility of face images while perturbing gender (2017) 2017 IEEE International joint conference on biometrics (IJCB), pp. 564-573. , IEEE; Melis, M., Demontis, A., Biggio, B., Brown, G., Fumera, G., Roli, F., Is deep learning safe for robot vision? adversarial examples against the icub humanoid (2017) Proceedings of the IEEE International Conference on Computer Vision Workshops, pp. 751-759; Biggio, B., Fumera, G., Roli, F., Pattern recognition systems under attack: design issues and research challenges (2014) Int. J. Pattern Recognit Artif Intell., 28 (7), p. 1460002; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) 2016 IEEE Symposium on Security and Privacy (SP), pp. 582-597. , IEEE; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2014) arXiv preprint arXiv:1412.6572; Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., Ensemble adversarial training: attacks and defenses (2017) arXiv preprint arXiv:1705.07204; Yan, Z., Guo, Y., Zhang, C., Deep defense: Training dnns with improved adversarial robustness (2018) Advances in Neural Information Processing Systems, pp. 419-428; Cisse, M., Bojanowski, P., Grave, E., Dauphin, Y., Usunier, N., Parseval networks: Improving robustness to adversarial examples (2017) Proceedings of the 34th International Conference on Machine Learning-Volume 70, pp. 854-863. , JMLR. org; Lee, H., Han, S., Lee, J., Generative adversarial trainer: defense to adversarial perturbations with gan (2017) arXiv preprint arXiv:1705.03387; Meng, D., Chen, H., Magnet: a two-pronged defense against adversarial examples (2017) Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pp. 135-147; Gu, S., Rigazio, L., Towards deep neural network architectures robust to adversarial examples (2014) arXiv preprint arXiv:1412.5068; Xie, C., Wu, Y., Maaten, L.V.D., Yuille, A.L., He, K., Feature denoising for improving adversarial robustness (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 501-509; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2017) arXiv preprint arXiv:1706.06083; Zhang, H., Yu, Y., Jiao, J., Xing, E.P., Ghaoui, L.E., Jordan, M.I., Theoretically principled trade-off between robustness and accuracy (2019) arXiv preprint arXiv:1901.08573; Gupta, S., Dube, P., Verma, A., Improving the affordability of robustness training for dnns (2020) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, pp. 780-781; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2014) arXiv preprint arXiv:1409.1556; Huang, G., Liu, Z., Van Der Maaten, L., Weinberger, K.Q., Densely connected convolutional networks (2017) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 4700-4708; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770-778; Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., Torralba, A., Learning deep features for discriminative localization (2016) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2921-2929; Selvaraju, R.R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., Batra, D., Grad-cam: Visual explanations from deep networks via gradient-based localization (2017) Proceedings of the IEEE international conference on computer vision, pp. 618-626; Miyato, T., Maeda, S.-I., Koyama, M., Ishii, S., Virtual adversarial training: a regularization method for supervised and semi-supervised learning (2018) IEEE Trans Pattern Anal Mach Intell, 41 (8), pp. 1979-1993; Mao, C., Zhong, Z., Yang, J., Vondrick, C., Ray, B., Metric learning for adversarial robustness (2019) Advances in Neural Information Processing Systems, pp. 478-489; Qin, C., Martens, J., Gowal, S., Krishnan, D., Dvijotham, K., Fawzi, A., De, S., Kohli, P., Adversarial robustness through local linearization (2019) Advances in Neural Information Processing Systems, pp. 13824-13833; Kannan, H., Kurakin, A., Goodfellow, I., Adversarial logit pairing (2018) arXiv preprint arXiv:1803.06373; Goodman, D., Li, X., Huan, J., Wei, T., Improving adversarial robustness via attention and adversarial logit pairing (2019) arXiv preprint arXiv:1908.11435; Hendrycks, D., Gimpel, K., Visible progress on adversarial images and a new saliency map (2016) CoRR; Hinton, G., Vinyals, O., Dean, J., Distilling the knowledge in a neural network (2015) arXiv preprint arXiv:1503.02531; Mahendran, A., Vedaldi, A., Visualizing deep convolutional neural networks using natural pre-images (2016) Int. J. Comput. Vis., 120 (3), pp. 233-255; Engstrom, L., Ilyas, A., Athalye, A., Evaluating and understanding the robustness of adversarial logit pairing (2018) arXiv preprint arXiv:1807.10272; Ilyas, A., Santurkar, S., Tsipras, D., Engstrom, L., Tran, B., Madry, A., Adversarial examples are not bugs, they are features (2019) Advances in Neural Information Processing Systems, pp. 125-136; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 ieee symposium on security and privacy (sp), pp. 39-57. , IEEE; Uesato, J., O'Donoghue, B., Oord, A.V.D., Kohli, P., Adversarial risk and the dangers of evaluating against weak attacks (2018) arXiv preprint arXiv:1802.05666","Li, Z.; School of Computer and Computing Science, China; 电子邮件: lizr@zucc.edu.cn",,,Elsevier B.V.,,,,,1678655,,,,English,Pattern Recogn. Lett.,Article,Final,,Scopus,2-s2.0-85103630302
"Wang Y., Ding X., Yang Y., Ding L., Ward R., Wang Z.J.",57202875900;57196224471;24741309800;36997821700;57203349794;11241026700;,Perception matters: Exploring imperceptible and transferable anti-forensics for GAN-generated fake face imagery detection,2021,Pattern Recognition Letters,146,,,15,22,,1,10.1016/j.patrec.2021.03.009,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102974642&doi=10.1016%2fj.patrec.2021.03.009&partnerID=40&md5=2257e0a0a6717b5e27314b20daf77fd6,"Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, V6T1Z4, Canada; Department of Statistics, University of British Columbia, Vancouver, V6T1Z4, Canada; School of Marine Science and Technology, Northwestern Polytechnical University, Xi'an, 710102, China; School of Information and Communications Engineering, Xi'an Jiaotong University, Xi'an, 710048, China","Wang, Y., Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, V6T1Z4, Canada, School of Marine Science and Technology, Northwestern Polytechnical University, Xi'an, 710102, China; Ding, X., Department of Statistics, University of British Columbia, Vancouver, V6T1Z4, Canada; Yang, Y., School of Marine Science and Technology, Northwestern Polytechnical University, Xi'an, 710102, China; Ding, L., Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, V6T1Z4, Canada, School of Information and Communications Engineering, Xi'an Jiaotong University, Xi'an, 710048, China; Ward, R., Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, V6T1Z4, Canada; Wang, Z.J., Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, V6T1Z4, Canada","Recently, generative adversarial networks (GANs) can generate photo-realistic fake facial images which are perceptually indistinguishable from real face photos, promoting research on fake face detection. Though fake face forensics can achieve high detection accuracy, their anti-forensic counterparts are less investigated. Here we explore more imperceptible and transferable anti-forensics for fake face imagery detection based on adversarial attacks. Since facial and background regions are often smooth, even small perturbation could cause noticeable perceptual impairment in fake face images. Therefore it makes existing transfer-based adversarial attacks ineffective as an anti-forensic method. Our perturbation analysis reveals the intuitive reason of the perceptual degradation issue when directly applying such existing attacks. We then propose a novel adversarial attack method, better suitable for image anti-forensics, in the transformed color domain by considering visual perception. Conceptually simple yet effective, the proposed method can fool both deep learning and non-deep learning based forensic detectors, achieving higher adversarial transferability and significantly improved visual quality. Specially, when adversaries consider imperceptibility as a constraint, the proposed anti-forensic method achieves the state-of-the-art attacking performances in the transfer-based black-box setting (i.e. around 30% higher attack transferability than baseline attacks). More imperceptible and more transferable, the proposed method raises new security concerns to fake face imagery detection. We have released our code for public use, and hopefully the proposed method can be further explored in related forensic applications as an anti-forensic benchmark. © 2021 Elsevier B.V.",Fake face imagery anti-forensics; Imperceptible attacks; Improved adversarial attack; Transferable attacks,Deep learning; Digital forensics; Face recognition; Image enhancement; Adversarial networks; Anti-Forensics; Detection accuracy; Faces detection; Facial images; Fake face imagery anti-forensic; Imperceptible attack; Improved adversarial attack; Photo-realistic; Transferable attack; Benchmarking,,,,,"Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in neural information processing systems, pp. 2672-2680; Karras, T., Aila, T., Laine, S., Lehtinen, J., Progressive growing of gans for improved quality, stability, and variation (2018) International Conference on Learning Representations; Karras, T., Laine, S., Aila, T., A style-based generator architecture for generative adversarial networks (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4401-4410; Karras, T., Laine, S., Aittala, M., Hellsten, J., Lehtinen, J., Aila, T., Analyzing and improving the image quality of stylegan (2020) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 8110-8119; Li, H., Chen, H., Li, B., Tan, S., Can forensic detectors identify gan generated images? (2018) 2018 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC), pp. 722-727. , IEEE; Tariq, S., Lee, S., Kim, H., Shin, Y., Woo, S.S., Detecting both machine and human created fake face images in the wild (2018) Proceedings of the 2nd International Workshop on Multimedia Privacy and Security, pp. 81-87. , ACM; Mo, H., Chen, B., Luo, W., Fake faces identification via convolutional neural network (2018) Proceedings of the 6th ACM Workshop on Information Hiding and Multimedia Security, pp. 43-47. , ACM; Satter, R., Experts: spy used ai-generated face to connect with targets (2019) Washington Post; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) aInternational Conference on Learning Representations; Kodovsky, J., Fridrich, J., Holub, V., Ensemble classifiers for steganalysis of digital media (2012) IEEE Trans. Inf. Forensics Secur., 7 (2), pp. 432-444; Marra, F., Gragnaniello, D., Verdoliva, L., Poggi, G., Do gans leave artificial fingerprints? (2019) 2019 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR), pp. 506-511. , IEEE; Yu, N., Davis, L.S., Fritz, M., Attributing fake images to gans: Learning and analyzing gan fingerprints (2019) Proceedings of the IEEE International Conference on Computer Vision, pp. 7556-7566; McCloskey, S., Albright, M., Detecting gan-generated imagery using color cues (2018) arXiv preprint arXiv:1812.08247; Wang, S.-Y., Wang, O., Zhang, R., Owens, A., Efros, A.A., Cnn-generated images are surprisingly easy to spot…for now (2020) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 7; Li, H., Li, B., Tan, S., Huang, J., Identification of deep network generated images using disparities in color components (2020) Signal Processing, p. 107616; Stamm, M.C., Wu, M., Liu, K.R., Information forensics: an overview of the first decade (2013) IEEE Access, 1, pp. 167-200; Piva, A., An overview on image forensics (2013) ISRN Signal Processing, 2013; Qian, Z., Zhang, X., Improved anti-forensics of jpeg compression (2014) Journal of Systems and Software, 91, pp. 100-108; Radford, A., Metz, L., Chintala, S., Unsupervised representation learning with deep convolutional generative adversarial networks (2016) International Conference on Learning Representations; Miyato, T., Kataoka, T., Koyama, M., Yoshida, Y., Spectral normalization for generative adversarial networks (2018) International Conference on Learning Representations; Zhang, H., Goodfellow, I., Metaxas, D., Odena, A., Self-attention generative adversarial networks (2019) International Conference on Machine Learning, pp. 7354-7363. , PMLR; Durall, R., Keuper, M., Keuper, J., Watch your up-convolution: Cnn based generative deep neural networks are failing to reproduce spectral distributions (2020) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 7890-7899; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: a simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2574-2582; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 9185-9193; Gragnaniello, D., Marra, F., Poggi, G., Verdoliva, L., Perceptual quality-preserving black-box attack against deep learning image classifiers (2019) arXiv preprint arXiv:1902.07776; Akhtar, N., Mian, A., Threat of adversarial attacks on deep learning in computer vision: a survey (2018) IEEE Access, 6, pp. 14410-14430; Marra, F., Gragnaniello, D., Verdoliva, L., On the vulnerability of deep learning to adversarial attacks for camera model identification (2018) Signal Process. Image Commun., 65, pp. 240-248; Barni, M., Kallas, K., Nowroozi, E., Tondi, B., On the transferability of adversarial examples against cnn-based image forensics (2019) ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 8286-8290. , IEEE; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) International Conference on Learning Representations; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in neural information processing systems, pp. 1097-1105; Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., Chen, L.-C., Mobilenetv2: Inverted residuals and linear bottlenecks (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4510-4520; Mittal, A., Soundararajan, R., Bovik, A.C., Making a ǣcompletely blindǥ image quality analyzer (2012) IEEE Signal Process. Lett., 20 (3), pp. 209-212; Zhang, R., Isola, P., Efros, A.A., Shechtman, E., Wang, O., The unreasonable effectiveness of deep features as a perceptual metric (2018) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 586-595; Zhang, L., Zhang, L., Mou, X., Zhang, D., Fsim: a feature similarity index for image quality assessment (2011) IEEE Trans. Image Process., 20 (8), pp. 2378-2386; Zhao, Z., Liu, Z., Larson, M., Towards large yet imperceptible adversarial image perturbations with perceptual color distance (2020) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 1039-1048","Yang, Y.; School of Marine Science and Technology, China; 电子邮件: yxyang@nwpu.edu.cn",,,Elsevier B.V.,,,,,1678655,,,,English,Pattern Recogn. Lett.,Article,Final,"All Open Access, Green",Scopus,2-s2.0-85102974642
"Calzavara S., Cazzaro L., Lucchese C.",36630085200;57224637759;8873518400;,AMEBA: An Adaptive Approach to the Black-Box Evasion of Machine Learning Models,2021,ASIA CCS 2021 - Proceedings of the 2021 ACM Asia Conference on Computer and Communications Security,,,,292,306,,,10.1145/3433210.3453114,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108120195&doi=10.1145%2f3433210.3453114&partnerID=40&md5=17af4ab131b588dd163c14014333321e,"Università Ca' Foscari Venezia, Venezia, Italy","Calzavara, S., Università Ca' Foscari Venezia, Venezia, Italy; Cazzaro, L., Università Ca' Foscari Venezia, Venezia, Italy; Lucchese, C., Università Ca' Foscari Venezia, Venezia, Italy","Machine learning models are vulnerable to evasion attacks, where the attacker starts from a correctly classified instance and perturbs it so as to induce a misclassification. In the black-box setting where the attacker only has query access to the target model, traditional attack strategies exploit a property known as transferability, i.e., the empirical observation that evasion attacks often generalize across different models. The attacker can thus rely on the following two-step attack strategy: (i) query the target model to learn how to train a surrogate model approximating it; and (ii) craft evasion attacks against the surrogate model, hoping that they ""transfer""to the target model. This attack strategy is sub-optimal, because it assumes a strict separation of the two steps and under-approximates the possible actions that a real attacker might take. In this work we propose AMEBA, the first adaptive approach to the black-box evasion of machine learning models. AMEBA builds on a well-known optimization problem, known as Multi-Armed Bandit, to infer the best alternation of actions spent for surrogate model training and evasion attack crafting. We experimentally show on public datasets that AMEBA outperforms traditional two-step attack strategies. © 2021 ACM.",adversarial machine learning; evasion attacks; transferability,Protozoa; Adaptive approach; Attack strategies; Machine learning models; Misclassifications; Multi armed bandit; Optimization problems; Surrogate model; Target model; Machine learning,,,,,"Bhagoji, A.N., He, W., Li, B., Song, D., Practical black-box attacks on deep neural networks using efcient query mechanisms (2018) Eccv (Lecture Notes in Computer Science, 11216), pp. 158-174. , Springer; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Srndic, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Ecml Pkdd (Lecture Notes in Computer Science, 8190), pp. 387-402. , Springer; Biggio, B., Roli, F., Wild patterns: Ten years after the rise of adversarial machine learning (2018) Pattern Recognit., 84, pp. 317-331. , 2018; Brendel, W., Rauber, J., Bethge, M., Decision-based adversarial attacks: Reliable attacks against black-box machine learning models (2018) ICLR. OpenReview.net; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) AISec@CCS, pp. 15-26; Cheng, M., Le, T., Chen, P.-Y., Zhang, H., Yi, J., Hsieh, C.-J., Query-efcient hard-label black-box attack: An optimization-based approach (2019) ICLR. OpenReview.net; Cheng, S., Dong, Y., Pang, T., Su, H., Zhu, J., Improving black-box adversarial attacks with a transfer-based prior (2019) NeurIPS., pp. 10932-10942; Demontis, A., Melis, M., Pintor, M., Jagielski, M., Biggio, B., Oprea, A., Nita-Rotaru, C., Roli, F., Why do adversarial attacks transfer? Explaining transferability of evasion and poisoning attacks (2019) Usenix Security, pp. 321-338. , USENIX Association; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2018) Cvpr, pp. 9185-9193. , IEEE Computer Society; Dong, Y., Pang, T., Su, H., Zhu, J., Evading defenses to transferable adversarial examples by translation-invariant attacks (2019) CVPR. Computer Vision Foundation, pp. 4312-4321; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR. OpenReview.net; Ilyas, A., Engstrom, L., Athalye, A., Lin, J., Black-box adversarial attacks with limited queries and information (2018) ICML. Pmlr, pp. 2142-2151; Ilyas, A., Engstrom, L., Madry, A., Prior convictions: Black-box adversarial attacks with bandits and priors (2019) ICLR. OpenReview.net; Juuti, M., Atli, B.G., Asokan, N., Making targeted black-box evasion attacks efective and efcient (2019) AISec@CCS 2019, pp. 83-94; Lecun, Y., Bottou, L., Bengio, Y., Hafner, P., Gradient-based learning applied to document recognition (1998) Proc. Ieee, 86 (12), pp. 2278-2324. , 1998; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) ICLR. OpenReview.net; Lowd, D., Meek, C., Good (2005) Ceas, , http://www.ceas.cc/papers-2005/125.pdf, Word Attacks on Statistical Spam Filters; Naseer, M., Khan, S.H., Khan, M.H., Khan, F.S., Porikli, F., Cross-domain transferability of adversarial perturbations (2019) NeurIPS., pp. 12885-12895; Papernot, N., McDaniel, P.D., Goodfellow, I.J., Trans-ferability in machine learning: From phenomena to black-box attacks using adversarial samples (2016) CoRR, , http://arxiv.org/abs/1605.07277, abs/1605.07277 (2016); Papernot, N., McDaniel, P.D., Goodfellow, I.J., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) AsiaCCS, pp. 506-519; Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Duchesnay, E., Scikit-learn: Machine learning in python (2011) Journal of Machine Learning Research, 12, pp. 2825-2830. , 2011; Rozsa, A., Rudd, E.M., Boult, T.E., Adversarial diversity and hard positive generation (2016) Cvpr Workshops, pp. 410-417. , IEEE Computer Society; Russo, D., Van Roy, B., Kazerouni, A., Osband, I., Wen, Z., A tutorial on thompson sampling (2018) Foundations and Trends in Machine Learning, 11 (1), pp. 1-96. , 2018; Slivkins, A., Introduction to multi-Armed bandits (2019) Foundations and Trends in Machine Learning, 12 (1-2), pp. 1-286. , 2019; Suciu, O., Marginean, R., Kaya, Y., Hal Daumé, I.I.I., Dumitras, T., When does machine learning fail? Generalized transferability for evasion and poisoning attacks (2018) Usenix Security, pp. 1299-1316. , USENIX Association; Sutton, R.S., Barto, A.G., (2018) Reinforcement Learning: An Introduction, , MIT press; Suya, F., Chi, J., Evans, D., Tian, Y., Hybrid batch attacks: Finding black-box adversarial examples with limited queries (2020) Usenix, pp. 1327-1344. , USENIX Association; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R., Intriguing properties of neural networks (2014) ICLR. OpenReview.net; Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I.J., Boneh, D., McDaniel, P.D., Ensemble adversarial training: Attacks and defenses (2018) ICLR. OpenReview.net; Wu, D., Wang, Y., Xia, S.-T., Bailey, J., Ma, X., Skip connections matter: On the transferability of adversarial examples generated with resnets (2020) ICLR. OpenReview.net; Xie, C., Zhang, Z., Zhou, Y., Bai, S., Wang, J., Ren, Z., Yuille, A.L., Improving transferability of adversarial examples with input diversity (2019) CVPR. Computer Vision Foundation, pp. 2730-2739",,,ACM SIGSAC,"Association for Computing Machinery, Inc","16th ACM Asia Conference on Computer and Communications Security, ASIA CCS 2021",7 June 2021 through 11 June 2021,,169424,,9.78E+12,,,English,ASIA CCS - Proc. ACM Asia Conf. Comput. Commun. Secur.,Conference Paper,Final,,Scopus,2-s2.0-85108120195
"Shahid A.M., Fraz M.M., Shahzad M.",57224472888;26666028400;57211012854;,Large Scale Face Recognition in the Wild: Technical Challenges and Research Directions,2021,"2021 International Conference on Digital Futures and Transformative Technologies, ICoDT2 2021",,,9441525,,,,,10.1109/ICoDT252288.2021.9441525,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107691536&doi=10.1109%2fICoDT252288.2021.9441525&partnerID=40&md5=ceb0e5649ea0e5ad6b340a6dd2ac93e5,"National University of Sciences and Technology (NUST), School of Electrical Engineering and Computer Science, Islamabad, Pakistan","Shahid, A.M., National University of Sciences and Technology (NUST), School of Electrical Engineering and Computer Science, Islamabad, Pakistan; Fraz, M.M., National University of Sciences and Technology (NUST), School of Electrical Engineering and Computer Science, Islamabad, Pakistan; Shahzad, M., National University of Sciences and Technology (NUST), School of Electrical Engineering and Computer Science, Islamabad, Pakistan","Face recognition (FR) is the most effective and preferable biometric technique for both verification and identification of humans as compared to iris, voice, retina eye scanning, fingerprint, gait, hand, and ear geometry. FR is the most highlighted and fast-growing research area in computer vision for the past couple of years. It is observed in the literature that most techniques don't perform well because of unconstrained environments like occlusion, noise, position, angle of view, lighting, illumination, ageing, bad picture quality, low resolution, blurriness, and in many cases uncertainty in data. In this paper, a critical review on prior mentioned issues and their proposed solutions to resolve these issues are analyzed and presented through the state of the art techniques which has been proposed in the literature. Apart from this, it has been observed that various new techniques are applied in the form of loss function revamping, adding regularization, using transfer/reinforcement learning, and some new proposed architectures in the literature. © 2021 IEEE.",Adversarial Attacks; Face Recognition; Reinforcement Learning; Systematic Review,Transfer learning; Biometric techniques; Critical review; Loss functions; Picture quality; Proposed architectures; State-of-the-art techniques; Technical challenges; Unconstrained environments; Face recognition,,,,,"Yazgan, H.R., Soysal, F.Y.S., Gür, A., Comparison performances of pso and ga to tuning pid controller for the dc motor (2019) Sakarya University Journal of Science, 23 (2), pp. 162-174; Menhas, M.I., Wang, L., Fei, M., Pan, H., Comparative performance analysis of various binary coded pso algorithms in multivariable pid controller design (2012) Expert Systems with Applications, 39, pp. 4390-4401; Ang, K.H., Chong, G., Li, Y., Pid control system analysis, design and technology (2005) Ieee Transactions on Control System Technology, 13, pp. 559-576; Nagaraj, B., Murugananth, N., A comparative study of pid controller thning using ga, ep, pso and aco (2010) 2010 International Conference on Communications Control and Computing Technologies; Marsh, P., Turn on tune in-where can the pid controllers go next (1998) New Electron, 31 (4), pp. 31-32; Astrom, K.J., Hagglund, T., (1995) Pid Controllers: Theory, Design and Tuning, , 2 Ed. Lund: Instrument Society of America; Bequette, B.W., (2003) Process Control: Modeling, Design and Simulation, , Upper Saddle River: Pearson Education; Mirjalili, S., Mirjalili, S.M., Lewis, A., Grey wolf optimizer (2014) Advances in Engineering Software, 69, pp. 46-61; Kennedy, J., Eberhart, R., Particle swarm optimization (1995) Proceedings of ICNN'95-International Conference on Neural Networks; Holland, J.H., (1975) Adaptation in Natural and Artificial Systems, , Cambridge: MIT Press; Ouyang, P., Pano, V., Comparative study of de pso and ga for position domain pid controller tuning Algorithms, 2 (15), pp. 697-711; Mirjalili, S., Lewis, A., The whale optimization algorithm (2016) Advances in Engineering Software, 95, pp. 51-67; Zahir, A., Alhady, S., Othman, W., Ahmad, M., Genetic algorithm optimization of pid controller for brushed dc motor (2018) Intelligent Manufacturing & Mechatronics, pp. 427-437; Samakwong, T., Assawinchaichote, W., Pid controller design for electro-hydraulic servo valve system with genetic algorithm (2016) International Electrical Engineering Congress-Chiang Mai: Procedia Computer Science, 86; Jain, N., Parmar, G., Gupta, R., Khanam, I., Performance evaluation of gwo/pid approach in control of ball hoop system with different objective functions and perturbation (2018) Cogent Engineering, 5, p. 1465328; Altintas, G., Aydin, Y., Optimization of fractional and integer order pid parameters using big bang big crunch and genetic algorithms for a maglev system (2017) Ifac Papers on Line, 50 (1), pp. 4881-4886",,,,Institute of Electrical and Electronics Engineers Inc.,"2021 International Conference on Digital Futures and Transformative Technologies, ICoDT2 2021",20 May 2021 through 21 May 2021,,169305,,9.78E+12,,,English,"Int. Conf. Digit. Futur. Transform. Technol., ICoDT2",Conference Paper,Final,,Scopus,2-s2.0-85107691536
"Lee X.Y., Esfandiari Y., Tan K.L., Sarkar S.",57195241397;57218567066;57212350200;55066244300;,Query-based targeted action-space adversarial policies on deep reinforcement learning agents,2021,ICCPS 2021 - Proceedings of the 2021 ACM/IEEE 12th International Conference on Cyber-Physical Systems (with CPS-IoT Week 2021),,,3450537,87,97,,,10.1145/3450267.3450537,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104193690&doi=10.1145%2f3450267.3450537&partnerID=40&md5=359626ffd47e7771ac27e644c7f5ad4d,"Department of Mechanical Engineering, Iowa State University, Ames, IA, United States","Lee, X.Y., Department of Mechanical Engineering, Iowa State University, Ames, IA, United States; Esfandiari, Y., Department of Mechanical Engineering, Iowa State University, Ames, IA, United States; Tan, K.L., Department of Mechanical Engineering, Iowa State University, Ames, IA, United States; Sarkar, S., Department of Mechanical Engineering, Iowa State University, Ames, IA, United States","Advances in computing resources have resulted in the increasing complexity of cyber-physical systems (CPS). As the complexity of CPS evolved, the focus has shifted to deep reinforcement learning-based (DRL) methods for control of these systems. This is in part due to: 1) difficulty of obtaining accurate models of complex CPS for traditional control 2) DRL algorithms' capability of learning control policies from data which can be adapted and scaled to real, complex CPS. To securely deploy DRL in production, it is essential to examine the weaknesses of DRL-based controllers (policies) towards malicious attacks from all angles. This work investigates targeted attacks in the action-space domain (actuation attacks), which perturbs the outputs of a controller. We show that a black-box attack model that generates perturbations with respect to an adversarial goal can be formulated as another reinforcement learning problem. Thus, an adversarial policy can be trained using conventional DRL methods. Experimental results showed that adversarial policies which only observe the nominal policy's output generate stronger attacks than adversarial policies that observe the nominal policy's input and output. Further analysis revealed that nominal policies whose outputs are frequently at the boundaries of the action space are naturally more robust towards adversarial policies. Lastly, we propose the use of adversarial training with transfer learning to induce robust behaviors into the nominal policy, which decreases the rate of successful targeted attacks by approximately 50%. © 2021 ACM.",adversarial attacks; adversarial policies; adversarial training; black-box attacks; deep reinforcement learning,Controllers; Cyber Physical System; Embedded systems; Intelligent agents; Internet of things; Learning systems; Reinforcement learning; Transfer learning; Computing resource; Cyber-physical systems (CPS); Input and outputs; Learning control; Malicious attack; Reinforcement learning agent; Robust behavior; Targeted actions; Deep learning,,,,,"Barreno, M., Nelson, B., Joseph, A.D., Doug Tygar, J., The security of machine learning (2010) Machine Learning, 81 (2), pp. 121-148. , 2010; Basseville, M., Nikiforov, I.V., (1993) Detection of Abrupt Changes: Theory and Application; Behzadan, V., Munir, A., Vulnerability of deep reinforcement learning to policy induction attacks (2017) Machine Learning and Data Mining in Pattern Recognition, pp. 262-275. , Springer International Publishing, Cham, Petra Perner (Ed.); Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndi, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Machine Learning and Knowledge Discovery in Databases, pp. 387-402. , Springer Berlin Heidelberg, Berlin, Heidelberg, Hendrik Blockeel, Kristian Kersting, Siegfried Nijssen, and Filip Železný (Eds.); Chen, T., Liu, J., Xiang, Y., Niu, W., Tong, E., Han, Z., Adversarial attack and defense in reinforcement learning-from ai security view (2019) Cybersecurity, 2 (1), p. 11. , 2019; Esfandiari, Y., Balu, A., Ebrahimi, K., Vaidya, U., Elia, N., Sarkar, S., A fast saddle-point dynamical system approach to robust deep learning (2019) AAAI Workshop, , https://arxiv.org/abs/1910.08623, 2019; Furuta, R., Inoue, N., Yamasaki, T., PixelRL: Fully convolutional network with reinforcement learning for image processing (2020) IEEE Transactions on Multimedia, 22 (7), pp. 1704-1719. , https://doi.org/10.1109/TMM.2019.2960636, 2020; Gleave, A., Dennis, M., Wild, C., Kant, N., Levine, S., Russell, S., Adversarial policies: Attacking deep reinforcement learning (2019) International Conference on Learning Representations, , https://arxiv.org/abs/1905.10615, 2019; Goodfellow, I., Shlens, J., Szegedy, C., (2015) Explaining and Harnessing Adversarial Examples; Guo, Z., Shi, D., Henrik Johansson, K., Shi, L., Optimal linear cyber-attack on remote state estimation (2016) IEEE Transactions on Control of Network Systems, 4 (1), pp. 4-13. , 2016; Ketabchi Haghighat, A., Ravichandra-Mouli, V., Chakraborty, P., Esfandiari, Y., Arabi, S., Sharma, A., Applications of deep learning in intelligent transportation systems (2020) Journal of Big Data Analytics in Transportation, 2 (2), pp. 115-145. , 2020; Havens, A.J., Jiang, Z., Sarkar, S., Online robust policy learning in the presence of unknown adversaries (2018) Proceedings of the 32nd International Conference on Neural Information Processing Systems (Montréal, Canada) (NIPS'18), pp. 9938-9948. , Curran Associates Inc., Red Hook, NY, USA; Hengst, B., (2010) Hierarchical Reinforcement Learning, pp. 495-502. , https://doi.org/10.1007/978-0-387-30164-8_363, Springer US, Boston, MA; Hernandez-Leal, P., Kartal, B., Taylor, M.E., A survey and critique of multiagent deep reinforcement learning (2019) Autonomous Agents and Multi-Agent Systems, 33 (6), pp. 750-797. , 2019; Huang, S., Papernot, N., Goodfellow, I., Duan, Y., Abbeel, P., Adversarial attacks on neural network policies (2017) ICLR Workshop, , https://arxiv.org/abs/1702.02284, 2017; Ilahi, I., Usama, M., Qadir, J., Umar Janjua, M., Al-Fuqaha, A., Thai Hoang, D., Niyato, D., (2020) Challenges and Countermeasures for Adversarial Attacks on Deep Reinforcement Learning; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2017) ICLR Workshop, , https://arxiv.org/abs/1607.02533, 2017; Yeow Lee, X., Balu, A., Stoecklein, D., Ganapathysubramanian, B., Sarkar, S., A case study of deep reinforcement learning for engineering design: Application to microfluidic devices for flowsculpting (2019) Journal of Mechanical Design, 141 (11). , 2019; Yeow Lee, X., Ghadai, S., Liang Tan, K., Hegde, C., Sarkar, S., Spatiotemporally constrained action space attacks on deep reinforcement learning agents (2020) Proceedings of the AAAI Conference on Artificial Intelligence, 34 (4), pp. 4577-4584. , https://doi.org/10.1609/aaai.v34i04.5887, Apr. 2020; Yeow Lee, X., Saha, S.K., Sarkar, S., Giera, B., Automated detection of part quality during two-photon lithography via deep learning (2020) Additive Manufacturing, 36, p. 101444. , 2020; Longhi, S., Monteriù, A., Fault detection and isolation of linear discrete-time periodic systems using the geometric approach (2017) IEEE Trans. Automat. Control, 62 (3), pp. 1518-1523. , 2017; Lore, K.G., Sweet, N., Kumar, K., Ahmed, N., Sarkar, S., Deep value of information estimators for collaborative human-machine information gathering (2016) 2016 ACM/IEEE 7th International Conference on Cyber-Physical Systems (ICCPS), pp. 1-10. , https://doi.org/10.1109/ICCPS.2016.7479095; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) International Conference on Learning Representations; Mandlekar, A., Zhu, Y., Garg, A., Fei-Fei, L., Savarese, S., Adversarially robust policy learning: Active construction of physically-plausible perturbations (2017) 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 3932-3939. , https://doi.org/10.1109/IROS.2017.8206245; Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.A., Veness, J., Bellemare, M.G., Graves, A., Ostrovski, G., Human-level control through deep reinforcement learning (2015) Nature, 518 (7540), pp. 529-533. , 2015; Seyyed Mozaffari, F., Karimipour, H., Parizi, R.M., (2020) Learning Based Anomaly Detection in Critical Cyber-Physical Systems, pp. 107-130. , https://doi.org/10.1007/978-3-030-45541-5_6, Springer International Publishing, Cham; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security (Abu Dhabi, United Arab Emirates) (Asia CCS '17), pp. 506-519. , https://doi.org/10.1145/3052973.3053009, Association for Computing Machinery, New York, NY, USA; Pattanaik, A., Tang, Z., Liu, S., Bommannan, G., Chowdhary, G., Robust deep reinforcement learning with adversarial attacks (2018) Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems (Stockholm, Sweden) (AAMAS '18), pp. 2040-2042. , International Foundation for Autonomous Agents and Multiagent Systems, Richland, SC; Popova, M., Isayev, O., Tropsha, A., Deep reinforcement learning for de novo drug design (2018) Science Advances, 4 (7), p. eaap7885. , 2018; Ray, A., Achiam, J., Amodei, D., (2019) Benchmarking Safe Exploration in Deep Reinforcement Learning, , 2019; Russo, A., Proutiere, A., (2019) Optimal Attacks on Reinforcement Learning Policies; Schulman, J., Wolski, F., Dhariwal, P., Radford, A., Klimov, O., (2017) Proximal Policy Optimization Algorithms; Sun, J., Zhang, T., Xie, X., Ma, L., Zheng, Y., Chen, K., Liu, Y., Stealthy and efficient adversarial attacks against deep reinforcement learning (2020) Proceedings of the AAAI Conference on Artificial Intelligence, 34 (4), pp. 5883-5891. , https://doi.org/10.1609/aaai.v34i04.6047, Apr. 2020; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2014) Intriguing Properties of Neural Networks; Tan, K.L., Esfandiari, Y., Lee, X.Y., Aakanksha, Sarkar, S., Robustifying reinforcement learning agents via action space adversarial training (2020) 2020 American Control Conference (ACC), pp. 3959-3964. , https://doi.org/10.23919/ACC45564.2020.9147846; Liang Tan, K., Poddar, S., Sarkar, S., Sharma, A., Deep reinforcement learning for adaptive traffic signal control (2019) Dynamic Systems and Control Conference, , 59162. American Society of Mechanical Engineers, V003T18A006; Tessler, C., Efroni, Y., Mannor, S., Action robust reinforcement learning and applications in continuous control (2019) Proceedings of the 36th International Conference on Machine Learning (Proceedings of Machine Learning Research Vol. 97), pp. 6215-6224. , http://proceedings.mlr.press/v97/tessler19a.html, Kamalika Chaudhuri and Ruslan Salakhutdinov (Eds.) PMLR; Vamvoudakis, K.G., Hespanha, J.P., Sinopoli, B., Mo, Y., Detection in adversarial environments (2014) IEEE Trans. Automat. Control, 59 (12), pp. 3209-3223. , 2014; Watkins, H.C.C.J., Dayan, P., Q-learning (1992) Machine Learning, 8 (3), pp. 279-292. , https://doi.org/10.1007/BF00992698, 01 May 1992; Zhao, Y., Shumailov, I., Cui, H., Gao, X., Mullins, R., Anderson, R., Blackbox attacks on reinforcement learning agents using approximated temporal information (2020) 2020 50th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops (DSN-W), pp. 16-24. , https://doi.org/10.1109/DSNW50199.2020.00013",,,ACM SIGBED;IEEE TCRTS,"Association for Computing Machinery, Inc","12th ACM/IEEE International Conference on Cyber-Physical Systems, ICCPS 2021, part of CPS-IoT Week 2021",19 May 2021 through 21 May 2021,,168186,,9.78E+12,,,English,ICCPS - Proc. ACM/IEEE Int. Conf. Cyber-Phys. Syst. CPS-IoT Week,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85104193690
"Shriver D., Elbaum S., Dwyer M.",57195286099;6604075891;7005193693;,Artifact: Reducing DNN Properties to Enable Falsification with Adversarial Attacks,2021,Proceedings - International Conference on Software Engineering,,,,162,163,,2,10.1109/ICSE-Companion52605.2021.00068,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108904457&doi=10.1109%2fICSE-Companion52605.2021.00068&partnerID=40&md5=4ff031315dae47e5340fa69c6ed2471a,"Department of Computer Science, University of Virginia CharlottesvilleVA, United States","Shriver, D., Department of Computer Science, University of Virginia CharlottesvilleVA, United States; Elbaum, S., Department of Computer Science, University of Virginia CharlottesvilleVA, United States; Dwyer, M., Department of Computer Science, University of Virginia CharlottesvilleVA, United States","We present an artifact to accompany Reducing DNN Properties to Enable Falsification with Adversarial Attacks which includes the DNNF tool, data and scripts to facilitate the replication of its study. The artifact is both reusable and available. DNNF is available on Github, and we provide an artifact to reproduce our study as a VirtualBox virtual machine image. Full replication of the study requires 64GB of memory and 8 CPU cores. Users should know how to use VirtualBox, as well as have basic knowledge of the bash shell. © 2021 IEEE.",adversarial attacks; falsification; formal methods; neural nets,Neural networks; Technology transfer; Adversarial attack; CPU cores; Property; Virtual machine image; Formal methods,,,,,"Katz, G., Barrett, C.W., Dill, D.L., Julian, K., Kochenderfer, M.J., Reluplex: An efficient SMT solver for verifying deep neural networks (2017) Computer Aided Verification-29th International Conference, CAV 2017, pp. 97-117. , Heidelberg, Germany, July 24-28, 2017, Proceedings, Part I; Odena, A., Olsson, C., Andersen, D., Goodfellow, I., Tensorfuzz: Debugging neural networks with coverage-guided fuzzing (2019) Proceedings of the 36th International Conference on Machine Learning, Volume 97 of Proceedings of Machine Learning Research, pp. 4901-4911. , Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, Long Beach, California, USA, 09-15 Jun. PMLR; (2017) Open Neural Network Exchange, , https://github.com/onnx/onnx; Papernot, N., Faghri, F., Carlini, N., Goodfellow, I., Feinman, R., Kurakin, A., Xie, C., Long, R., (2018) Technical Report on the Cleverhans v2. 1. 0 Adversarial Examples Library; Shriver, D., Elbaum, S.G., Dwyer, M.B., Reducing dnn properties to enable falsification with adversarial attacks (2021) Proceedings of the International Conference on Software Engineering; Shriver, D., Xu, D., Elbaum, S.G., Dwyer, M.B., (2020) DNNV, , https://github.com/dlshriver/DNNV; Wang, S., Pei, K., Whitehouse, J., Yang, J., Jana, S., Efficient formal safety analysis of neural networks (2018) NeurIPS, pp. 6369-6379",,,,IEEE Computer Society,"43rd IEEE/ACM International Conference on Software Engineering: Companion, ICSE-Companion 2021",25 May 2021 through 28 May 2021,,170991,2705257,9.78E+12,PCSED,,English,Proc Int Conf Software Eng,Conference Paper,Final,,Scopus,2-s2.0-85108904457
"Pal B., Gupta D., Rashed-Al-mahfuz M., Alyami S.A., Moni M.A.",57197069959;57223692519;55183890600;57190760454;35119094400;,Vulnerability in deep transfer learning models to adversarial fast gradient sign attack for covid-19 prediction from chest radiography images,2021,Applied Sciences (Switzerland),11,9,4233,,,,3,10.3390/app11094233,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106068156&doi=10.3390%2fapp11094233&partnerID=40&md5=ca54b50e1dab97c89e489d6a2de5069a,"Department of Computer Science & Engineering, Rajshahi University of Engineering & Technology, Rajshahi, 6204, Bangladesh; Department of Computer Science and Engineering, University of Rajshahi, Rajshahi, 6205, Bangladesh; Department of Mathematics and Statistics, Imam Mohammad Ibn Saud Islamic University, Riyadh, 13318, Saudi Arabia; WHO Collaborating Centre on eHealth, School of Public Health and Community Medicine, UNSW Sydney, Sydney, NSW  2052, Australia; Healthy Ageing Theme, The Garvan Institute of Medical Research, Darlinghurst, NSW  2010, Australia","Pal, B., Department of Computer Science & Engineering, Rajshahi University of Engineering & Technology, Rajshahi, 6204, Bangladesh; Gupta, D., Department of Computer Science & Engineering, Rajshahi University of Engineering & Technology, Rajshahi, 6204, Bangladesh; Rashed-Al-mahfuz, M., Department of Computer Science and Engineering, University of Rajshahi, Rajshahi, 6205, Bangladesh; Alyami, S.A., Department of Mathematics and Statistics, Imam Mohammad Ibn Saud Islamic University, Riyadh, 13318, Saudi Arabia; Moni, M.A., WHO Collaborating Centre on eHealth, School of Public Health and Community Medicine, UNSW Sydney, Sydney, NSW  2052, Australia, Healthy Ageing Theme, The Garvan Institute of Medical Research, Darlinghurst, NSW  2010, Australia","The COVID-19 pandemic requires the rapid isolation of infected patients. Thus, high-sensitivity radiology images could be a key technique to diagnose patients besides the polymerase chain reaction approach. Deep learning algorithms are proposed in several studies to detect COVID-19 symptoms due to the success in chest radiography image classification, cost efficiency, lack of expert radiologists, and the need for faster processing in the pandemic area. Most of the promising algorithms proposed in different studies are based on pre-trained deep learning models. Such open-source models and lack of variation in the radiology image-capturing environment make the diagnosis system vulnerable to adversarial attacks such as fast gradient sign method (FGSM) attack. This study therefore explored the potential vulnerability of pre-trained convolutional neural network algorithms to the FGSM attack in terms of two frequently used models, VGG16 and Inception-v3. Firstly, we developed two transfer learning models for X-ray and CT image-based COVID-19 classification and analyzed the performance extensively in terms of accuracy, precision, recall, and AUC. Secondly, our study illustrates that misclassification can occur with a very minor perturbation magnitude, such as 0.009 and 0.003 for the FGSM attack in these models for X-ray and CT images, respectively, without any effect on the visual perceptibility of the perturbation. In addition, we demonstrated that successful FGSM attack can decrease the classification performance to 16.67% and 55.56% for X-ray images, as well as 36% and 40% in the case of CT images for VGG16 and Inception-v3, respectively, without any human-recognizable perturbation effects in the adversarial images. Finally, we analyzed that correct class probability of any test image which is supposed to be 1, can drop for both considered models and with increased perturbation; it can drop to 0.24 and 0.17 for the VGG16 model in cases of X-ray and CT images, respectively. Thus, despite the need for data sharing and automated diagnosis, practical deployment of such program requires more robustness. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",Adversarial attack; COVID-19; Deep learning; FGSM attack; Radiology images,,,,,,"Wang, W., Xu, Y., Gao, R., Lu, R., Han, K., Wu, G., Tan, W., Detection of SARS-CoV-2 in different types of clinical specimens (2020) JAMA, 323, pp. 1843-1844. , [CrossRef]; Zheng, C., Deng, X., Fu, Q., Zhou, Q., Feng, J., Ma, H., Liu, W., Wang, X., Deep learning-based detection for COVID-19 from chest CT using weak label (2020) MedRxiv, , [CrossRef]; Fang, Y., Zhang, H., Xie, J., Lin, M., Ying, L., Pang, P., Ji, W., Sensitivity of chest CT for COVID-19: Comparison to RT-PCR (2020) Radiology, 296, pp. E115-E117. , [CrossRef]; Huang, C., Wang, Y., Li, X., Ren, L., Zhao, J., Hu, Y., Zhang, L., Gu, X., Clinical features of patients infected with 2019 novel coronavirus in Wuhan, China (2020) Lancet, 395, pp. 497-506. , [CrossRef]; Lei, J., Li, J., Li, X., Qi, X., CT imaging of the 2019 novel coronavirus (2019-nCoV) pneumonia (2020) Radiology, 295, p. 18. , [CrossRef] [PubMed]; Song, F., Shi, N., Shan, F., Zhang, Z., Shen, J., Lu, H., Ling, Y., Shi, Y., Emerging 2019 novel coronavirus (2019-nCoV) pneumonia (2020) Radiology, 295, pp. 210-217. , [CrossRef] [PubMed]; Ng, M.Y., Lee, E.Y., Yang, J., Yang, F., Li, X., Wang, H., Lui, M.M.S., Khong, P.L., Imaging profile of the COVID-19 infection: Radiologic findings and literature review (2020) Radiology, 2, p. e200034. , [CrossRef] [PubMed]; Ai, T., Yang, Z., Hou, H., Zhan, C., Chen, C., Lv, W., Tao, Q., Xia, L., Correlation of chest CT and RT-PCR testing forcoronavirus disease 2019 (COVID-19) in China: A report of 1014 cases (2020) Radiology, 296, pp. E32-E40. , [CrossRef] [PubMed]; (2018) FDA Permits Marketing of Artificial Intelligence-Based Device to Detect Certain Diabetes-Related Eye Problems, , https://www.fda.gov/news-events/press-announcements/fda-permits-marketing-artificial-intelligence-based-device-detect-certain-diabetes-related-eye, FDA. Silver Spring, DM, Department of Health and Human Services (accessed on 15 April 2021); Ardila, D., Kiraly, A.P., Bharadwaj, S., Choi, B., Reicher, J.J., Peng, L., Tse, D., Corrado, G., End-to-end lung cancer screening with three-dimensional deep learning on low-dose chest computed tomography (2019) Nat. Med, 25, pp. 954-961. , [CrossRef]; Suzuki, K., Overview of deep learning in medical imaging (2017) Radiol. Phys. Technol, 10, pp. 257-273. , [CrossRef]; Gozes, O., Frid-Adar, M., Greenspan, H., Browning, P.D., Zhang, H., Ji, W., Bernheim, A., Siegel, E., Rapid AI Development Cycle for the Coronavirus (covid-19) Pandemic: Initial Results for Automated Detection and Patient Monitoring Using Deep Learning CT Image Analysis, , https://arxiv.org/ftp/arxiv/papers/2003/2003.05037.pdf, arXiv 2020, arXiv:2003.05037. (accessed on 15 April 2021); Li, L., Qin, L., Xu, Z., Yin, Y., Wang, X., Kong, B., Bai, J., Song, Q., Artificial intelligence distinguishes COVID-19 from community acquired pneumonia on chest CT (2020) Radiology, , [CrossRef]; Wang, S., Kang, B., Ma, J., Zeng, X., Xiao, M., Guo, J., Cai, M., Meng, X., A deep learning algorithm using CT images to screen for Corona Virus Disease (COVID-19) (2020) MedRxiv, , [CrossRef]; Narin, A., Kaya, C., Pamuk, Z., Automatic Detection of Coronavirus Disease (covid-19) Using X-ray Images and Deep Convolu-tional Neural Networks, , https://arxiv.org/ftp/arxiv/papers/2003/2003.10849.pdf, arXiv 2020, arXiv:2003.10849. (accessed on 15 April 2021); Makris, A., Kontopoulos, I., Tserpes, K., COVID-19 detection from chest X-ray images using Deep Learning and Convolutional Neural Networks Proceedings of the 11th Hellenic Conference on Artificial Intelligence, pp. 60-66. , Athens, Greece, 2–4 September 2020; Karim, M., Döhmen, T., Rebholz-Schuhmann, D., Decker, S., Cochez, M., Beyan, O., DeepCOVIDExplainer: Explainable Covid-19 Predictions Based on Chest X-ray Images, , https://arxiv.org/pdf/2004.04582.pdf, arXiv 2020, arXiv:2004.04582. (accessed on 15 April 2021); Asnaoui, K.E., Chawki, Y., Idri, A., Automated methods for detection and classification pneumonia based on X-ray images using deep learning, , https://arxiv.org/ftp/arxiv/papers/2003/2003.14363.pdf, arXiv 2020, arXiv:2003.14363. (accessed on 15 April 2021); Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and harnessing adversarial examples, , https://arxiv.org/pdf/1412.6572.pdf, arXiv arXiv:1412.6572. (accessed on 15 April 2021); Simon, G., (1971) Principles of Chest X-ray Diagnosis, , Butterworths: Oxford, MA, USA; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks Proceedings of the 2016 IEEE Symposium on Security and Privacy (SP), pp. 582-597. , San Jose, CA, USA, 23–25 May 2016; Grosse, K., Papernot, N., Manoharan, P., Backes, M., McDaniel, P., Adversarial Examples for Malware Detection (2017) Proceedings of the 22nd European Symposium on Research in Computer Security, pp. 62-79. , Oslo, Norway, 11–15 September Springer: Berlin/Heidelberg, Germany, 2017; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , https://arxiv.org/pdf/1607.02533.pdf, (accessed on 15 April 2021); Melis, M., Demontis, A., Biggio, B., Brown, G., Fumera, G., Roli, F., Is deep learning safe for robot vision? Adversarial examples against the icub humanoid Proceedings of the IEEE International Conference on Computer Vision Workshops, pp. 751-759. , Venice, Italy, 22–29 October 2017; Cohen, J.P., Morrison, P., Dao, L., Roth, K., Duong, T.Q., Ghassemi, M., Covid-19 Image Data Collection: Prospective Predictions Are the Future, , https://arxiv.org/pdf/2006.11988.pdf, arXiv 2020, arXiv:2006.11988. (accessed on 15 April 2021); Yang, X., He, X., Zhao, J., Zhang, Y., Zhang, S., Xie, P., COVID-CT-Dataset: A CT Scan Dataset about COVID-19, , arXiv 2020, arXiv:2003.13865; Pal, B., Ahmed, B., A deep domain adaption approach for object recognition using Multiple Model Consistency analysis Proceedings of the 2016 9th International Conference on Electrical and Computer Engineering (ICECE), pp. 562-565. , Dhaka, Bangladesh, 20–22 December 2016; O’Shea, K., Nash, R., (2015) An Introduction to Convolutional Neural Networks, , https://arxiv.org/pdf/1511.08458.pdf, arXiv arXiv:1511.08458v2. (accessed on 15 April 2021); Simonyan, K., Zisserman, A., (2014) Very deep convolutional networks for large-scale image recognition, , https://arxiv.org/pdf/1409.1556.pdf, arXiv arXiv:1409.1556. (accessed on 15 April 2021); Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826. , Las Vegas, NV, USA, 27–30 June 2016; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 427-436. , Boston, MA, USA, 7–12 June 2015; Tramer, F., Carlini, N., Brendel, W., Madry, A., On Adaptive Attacks to Adversarial Example Defenses, , https://arxiv.org/pdf/2002.08347.pdf, arXiv 2020, arXiv:2002.08347. (accessed on 15 April 2021); Chen, J., Qian, L., Urakov, T., Gu, W., Liang, L., Adversarial robustness study of convolutional neural network for lumbar disk shape reconstruction from MR images (2021) Medical Imaging 2021: Image Processing; International Society for Optics and Photonics, 11596, p. 1159615. , Washington, DC, USA; Yuan, X., He, P., Zhu, Q., Li, X., Adversarial examples: Attacks and defenses for deep learning (2019) IEEE Trans. Neural Netw. Learn. Syst, 30, pp. 2805-2824. , [CrossRef] [PubMed]; Lu, J., Issaranon, T., Forsyth, D., Safetynet: Detecting and rejecting adversarial examples robustly Proceedings of the IEEE International Conference on Computer Vision, pp. 446-454. , Venice, Italy, 22–29 October 2017; Ma, L., Liang, L., Increasing-Margin Adversarial (IMA) Training to Improve Adversarial Robustness of Neural Networks, , https://arxiv.org/pdf/2005.09147.pdf, arXiv 2021, arXiv:2005.09147. (accessed on 15 April 2021)","Moni, M.A.; WHO Collaborating Centre on eHealth, Australia; 电子邮件: m.moni@unsw.edu.au",,,MDPI AG,,,,,20763417,,,,English,Appl. Sci.,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85106068156
"Ulybyshev D., Yilmaz I., Northern B., Kholodilo V., Rogers M.",56732908700;57219317333;57219057884;57219053032;56788035100;,Trustworthy Data Analysis and Sensor Data Protection in Cyber-Physical Systems,2021,SAT-CPS 2021 - Proceedings of the 2021 ACM Workshop on Secure and Trustworthy Cyber-Physical Systems,,,3450432,13,22,,,10.1145/3445969.3450432,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107457972&doi=10.1145%2f3445969.3450432&partnerID=40&md5=84bc36fba503238ce33856abeea2189a,"Tennessee Technological University, Cookeville, TN, United States","Ulybyshev, D., Tennessee Technological University, Cookeville, TN, United States; Yilmaz, I., Tennessee Technological University, Cookeville, TN, United States; Northern, B., Tennessee Technological University, Cookeville, TN, United States; Kholodilo, V., Tennessee Technological University, Cookeville, TN, United States; Rogers, M., Tennessee Technological University, Cookeville, TN, United States","Cyber-Physical Systems are widely used in critical infrastructures such as the power grids, water purification systems, nuclear plants, oil refinery and compressor plants, food manufacturing, etc. Anomalies in these systems can be a result of cybersecurity attacks, failed sensors or communication channels. Undetected anomalies may lead to process failure, cause financial damage and have significant impact on human lives. Thus, it is important to detect anomalies at early stages and to protect data in Cyber-Physical Systems. In this paper, we propose the novel on-the-fly NIST-compliant key generation scheme for a secure data container used to transfer and store sensor data. The data container delivers data from the low-level field sensors to high-level data analysis servers in a protected form. It provides data confidentiality and integrity, as well as data origin integrity, a fine-grained role-based and attribute-based access control. As a result, the anomaly detector runs on trustworthy data sets, protected from unauthorized adversarial modifications. Our solution can be easily integrated with many existing Cyber-Physical Systems and IT infrastructures since our secure data container supports RESTful API and is implemented in two modifications: (1) signed, watermarked and encrypted spreadsheet file; (2) signed and encrypted JSON file. In addition, we implemented several machine learning models based on a Random Forest, a k-Nearest Neighbors, a Support Vector Machine and a Neural Network algorithms for the detection of various anomalies and attacks in a gas pipeline system. We will demonstrate that our anomaly detection models achieve high detection rate with an average accuracy of 97.7% for two industrial data sets collected by the Mississippi State University's Critical Infrastructure Protection Center and Oak Ridge National Laboratories (ORNL) © 2021 ACM.",anomaly detection; cyber-physical systems; data privacy; key management; machine learning,Access control; Anomaly detection; Containers; Critical infrastructures; Cryptography; Cyber Physical System; Decision trees; Electric power transmission networks; Information analysis; Nearest neighbor search; Nuclear power plants; Oils and fats; Privacy by design; Public works; Support vector machines; Anomaly detection models; Attribute based access control; Critical infrastructure protection; Machine learning models; Mississippi State University; Neural network algorithm; Oak ridge national laboratories; Water purification systems; Embedded systems,,,,,"Adhikari, U., Pan, S., Morris, T., Borges, R., Beaver, J., (2015) Industrial Control System (ICS) Cyber Attack Datasets, , https://sites.google.com/a/uah.edu/tommy-morris-uah/ics-data-sets, Retrieved December 17, 2020; Aktiengesellschaft, S., (2021) Terms of Use, , https://new.siemens.com/global/en/general/terms-of-use.html, Retrieved February 24, 2021; Beaver, J.M., Borges-Hink, R.C., Buckner, M., An evaluation of machine learning methods to detect malicious SCADA communications (2013) 2013 12th International Conference on Machine Learning and Applications, 2, pp. 54-59; Chang, C.-C., Lin, C.-J., LIBSVM: A library for support vector machines (2011) Acm Transactions on Intelligent Systems and Technology (TIST), 2 (3), pp. 1-27. , 2011; (2021), https://www.qt.io/trademark/, The Qt Company. 2020. QtR is a registered trademark of The Qt Company Ltd. and its subsidiaries. Retrieved January 3; (2020), www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/publications.aspx, Microsoft Corporation. 2020. Publications, Seminars, &Conferences Guidelines. Retrieved December 17; Daemen, J., Rijmen, V., (1999) Aes Proposal: Rijndael, , 1999; Davis, J., Goadrich, M., The relationship between precision-recall and roc curves (2006) Proceedings of the 23rd International Conference on Machine Learning, pp. 233-240; Fielding, R.T., Taylor, R.N., (2000) Architectural Styles and the Design of Network-based Software Architectures, 7. , University of California, Irvine Irvine; (2020), https://nodejs.org/static/documents/trademark-policy.pdf, Node.js Foundation. 2020. Node.js Foundation Trademark Guidelines for the Node.js Marks. Retrieved December 17; www.apache.org/foundation/marks/faq/, The Apache Software Foundation. 2019. Frequently Asked Questions about the ASF's Trademarks and their allowable uses. Retrieved December 25, 2020; www.linuxmark.org/programs/legal/trademark/attribution, The LINUX Foundation. 2020. The LINUX Mark. Retrieved January 08, 2021; Gao, W., Morris, T.H., On cyber attacks and signature based intrusion detection for modbus based industrial control systems (2014) Journal of Digital Forensics, Security and Law, 9 (1), p. 3. , 2014; Goutte, C., Gaussier, E., A probabilistic interpretation of precision, recall and F-score, with implication for evaluation (2005) European Conference on Information Retrieval, pp. 345-359. , Springer; https://www.php.net/copyright.php, PHP Group. 2020. Website Copyright. Retrieved January 08, 2021; Grover, L.K., A fast quantum mechanical algorithm for database search (1996) Proceedings of the Twenty-eighth Annual Acm Symposium on Theory of Computing, pp. 212-219; Head, J.D., Zerner, M.C., A Broyden- Fletcher-Goldfarb-Shanno optimization procedure for molecular geometries (1985) Chemical Physics Letters, 122 (3), pp. 264-270. , 1985; Hink, R.C.B., Beaver, J.M., Buckner, M.A., Morris, T., Adhikari, U., Pan, S., Machine learning for power system disturbance and cyber-attack discrimination (2014) 2014 7th International Symposium on Resilient Control Systems (ISRCS), pp. 1-8; https://www.docker.com/legal/trademark-guidelines, Docker Inc. 2020. Docker Trademark Guidelines. Retrieved December 20, 2020; www.intel.com/content/www/us/en/trademarks/intel.html, Intel Inc. 2020. IntelR Trademark &Company Name Usage Guidelines. Retrieved April 24, 2020; https://www.openssl.org/policies/trademark.html, OpenSSL Foundation Inc. 2017. Trademark Policy. Retrieved January 7, 2021; Keller, J.M., Gray, M.R., Givens, J.A., A fuzzy k-nearest neighbor algorithm (1985) Ieee Transactions on Systems, Man, and Cybernetics, 4, pp. 580-585. , 1985; Kleinmann, A., Wool, A., Automatic construction of statechartbased anomaly detection models for multi-threaded industrial control systems (2017) Acm Transactions on Intelligent Systems and Technology (TIST), 8 (4), pp. 1-21. , 2017; Liaw, A., Wiener, M., Classification and regression by random forest (2002) R News, 2 (3), pp. 18-22. , 2002; Lilien, L., Bhargava, B., A scheme for privacy-preserving data dissemination (2006) Ieee Transactions on Systems, Man, and Cybernetics-Part A: Systems and Humans, 36 (3), pp. 503-506. , 2006; Maas, A.L., Hannun, A.Y., Ng, A.Y., Rectifier nonlinearities improve neural network acoustic models (2013) Proc. Icml, 30, p. 3; Maglaras, L.A., Jiang, J., Intrusion detection in scada systems using machine learning techniques (2014) 2014 Science and Information Conference, pp. 626-631; Mithu, M.R.A., Kholodilo, V., Manicavasagam, R., Ulybyshev, D., Rogers, M., Secure industrial control system with intrusion detection (2020) the Thirty-Third International Flairs Conference; Morris, T., Vaughn, R., Dandass, Y., A retrofit network intrusion detection system for modbus rtu and ascii industrial control systems (2012) 2012 45th Hawaii International Conference on System Sciences, pp. 2338-2345; Ng, A.Y., Feature selection, L 1 vs. L 2 regularization, and rotational invariance (2004) Proceedings of the Twenty-first International Conference on Machine Learning, 78; www.modbus.org/specs.php, Modbus Organization. 2021. Modbus protocol. Retrieved January 08, 2021; Othmane, L.B., Lilien, L., Protecting privacy of sensitive data dissemination using active bundles (2009) 2009 World Congress on Privacy, Security, Trust and the Management of E-Business, pp. 202-213; Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Dubourg, V., Scikit-learn: Machine learning in python (2011) The Journal of Machine Learning Research, 12, pp. 2825-2830. , 2011; https://www.raspberrypi.org/trademark-rules/, Raspberry Pi. 2020. Raspberry Pi Trademark Rules and Guidelines. Retrieved December 23, 2020; Ranchal, R., Bhargava, B., Angin, P., Othmane, L.B., Epics: A framework for enforcing security policies in composite web services (2018) Ieee Transactions on Services Computing, 12 (3), pp. 415-428. , 2018; https://www.se.com/us/en/about-us/legal/terms-of-use.jsp, Schneider Electric Industries SAS. 2014. Terms of Use. Retrieved February 24, 2021; Stefanidis, K., Voyiatzis, A.G., An hmm-based anomaly detection approach for scada systems (2016) Ifip International Conference on Information Security Theory and Practice, pp. 85-99. , Springer; Story, M., Congalton, R.G., Accuracy assessment: A user's perspective (1986) Photogrammetric Engineering and Remote Sensing, 52 (3), pp. 397-399. , 1986; Suykens, J.A.K., Vandewalle, J., Least squares support vector machine classifiers (1999) Neural Processing Letters, 9 (3), pp. 293-300. , 1999; Turan, M.S., Barker, E.B., Burr, W.E., Chen, L., (2010) Sp 800-132. Recommendation for Password-based Key Derivation: Part 1: Storage Applications; Ulybyshev, D., Bare, C., Bellisario, K., Kholodilo, V., Northern, B., Solanki, A., O'Donnell, T., Protecting electronic health records in transit and at rest (2020) Ieee 33-rd International Symposium on Computer-Based Medical Systems (CBMS), pp. 449-452. , Institute of Electrical and Electronics Engineers; Xiao, L., Boyd, S., Kim, S.-J., Distributed average consensus with least-mean-square deviation (2007) Journal of Parallel and Distributed Computing, 67 (1), pp. 33-46. , 2007; Yilmaz, I., Kapoor, K., Siraj, A., Abouyoussef, M., (2021) Privacy Protection of Grid Users Data with Blockchain and Adversarial Machine Learning, , 2021; Yilmaz, I., Masum, R., (2019) Expansion of Cyber Attack Data from Unbalanced Datasets Using Generative Techniques, , 2019; Yilmaz, I., Masum, R., Siraj, A., Addressing imbalanced data problem with generative adversarial network for intrusion detection (2020) 2020 Ieee 21st International Conference on Information Reuse and Integration for Data Science (IRI), pp. 25-30; Yilmaz, I., Siraj, A., (2020) Avoiding Occupancy Detection from Smart Meter Using Adversarial Machine Learning, , 2020; Yilmaz, I., Siraj, A., Ulybyshev, D., Improving DGAbased malicious domain classifiers for malware defense with adversarial machinelearning (2020) 2020 Ieee 4th Conference on Information &Communication Technology (CICT), pp. 1-6",,,ACM SIGSAC,"Association for Computing Machinery, Inc","1st ACM Workshop on Secure and Trustworthy Cyber-Physical Systems, SaT-CPS 2021",28-Apr-21,,169182,,9.78E+12,,,English,SAT-CPS - Proc. ACM Workshop Secure Trustworthy Cyber-Phys. Syst.,Conference Paper,Final,,Scopus,2-s2.0-85107457972
"Black C., Scott-Hayward S.",57223708779;54917376600;,A Survey on the Verification of Adversarial Data Planes in Software-Defined Networks,2021,"SDN-NFV Sec 2021 - Proceedings of the 2021 ACM International Workshop on Software Defined Networks and Network Function Virtualization Security, co-located with CODAYSPY 2021",,,,3,10,,,10.1145/3445968.3452092,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106017313&doi=10.1145%2f3445968.3452092&partnerID=40&md5=d7731b6137a2889402c6c5caad5962b3,"Queen's University Belfast, Centre for Secure Information Technologies, Belfast, United Kingdom","Black, C., Queen's University Belfast, Centre for Secure Information Technologies, Belfast, United Kingdom; Scott-Hayward, S., Queen's University Belfast, Centre for Secure Information Technologies, Belfast, United Kingdom","As network policies are becoming increasingly nuanced and complex, so too are the mechanisms required to ensure that the network is functioning as intended. In particular, since the dawn of software-defined networking and the shift towards high-level descriptions of intended network policy, traditional tools such as ping and traceroute have been insufficient to test that complex data plane configurations have been correctly implemented. As a result, novel data plane verification solutions have been proposed that use formal methods to ensure that network policies are adhered to and that the data plane is free of bugs. While the number of these verification solutions continues to grow, only a few are equipped to verify the data plane when a malicious adversary is present. As research continues to expand the remit of data plane functionality, these solutions may become key to securing an increasingly valuable attack target. In this survey, we review the work that has been dedicated to preventing and detecting attacks on data planes in software-defined networks and discuss some of the unsolved problems in this field that must be addressed in future adversarial verification solutions. © 2021 ACM.",adversarial data plane; data plane security; data plane verification; SDN security; software-defined networking (SDN),Complex networks; Formal verification; Network security; Software defined networking; Software testing; Surveys; Transfer functions; Attack target; Complex data; Data planes; Detecting attacks; High level description; Malicious adversaries; Network policy; Unsolved problems; Network function virtualization,,,,,"Agrawal, A., Kim, C., Intel Tofino2-A 12.9 tbps P4-programmable ethernet switch (2020) 2020 IEEE Hot Chips 32 Symposium (HCS). IEEE Computer Society, pp. 1-32; Jane Anderson, C., Foster, N., Guha, A., Jeannin, J.-B., Kozen, D., Schlesinger, C., Walker, D., NetKAT: Semantic foundations for networks (2014) Acm Sigplan Notices, 49 (1), pp. 113-126; Tahmasbi Arashloo, M., Koral, Y., Greenberg, M., Rexford, J., Walker, D., SNAP: Stateful network-wide abstractions for packet processing (2016) Proceedings of the 2016 ACM SIGCOMM Conference., pp. 29-43; Bates, A., Butler, K., Haeberlen, A., Sherr, M., Zhou, W., Let SDN be your eyes: Secure forensics in data center networks (2014) Proceedings of the NDSS Workshop on Security of Emerging Network Technologies (SENT'14); Benton, K., Jean Camp, L., Small, C., OpenFlow vulnerability assessment (2013) Proceedings of the Second ACM SIGCOMM Workshop on Hot Topics in Software Defined Networking., pp. 151-152; Bosshart, P., Daly, D., Gibb, G., Izzard, M., McKeown, N., Rexford, J., Schlesinger, C., Varghese, G., P4: Programming protocol-independent packet processors (2014) ACM SIGCOMM Computer Communication Review, 44 (3), pp. 87-95; Bosshart, P., Gibb, G., Kim, H.-S., Varghese, G., McKeown, N., Izzard, M., Mujica, F., Horowitz, M., Forwarding metamorphosis: Fast programmable match-action processing in hardware for SDN (2013) ACM SIGCOMM Computer Communication Review, 43 (4), pp. 99-110; Bu, K., Yang, Y., Guo, Z., Yang, Y., Li, X., Zhang, S., FlowCloak: Defeating middlebox-bypass attacks in software-defined networking (2018) IEEE INFOCOM 2018-IEEE Conference on Computer Communications. IEEE, pp. 396-404; Cao, J., Li, Q., Xie, R., Sun, K., Gu, G., Xu, M., Yang, Y., The crosspath attack: Disrupting the {SDN} control channel via shared links (2019) 28th {USENIX} Security Symposium ({USENIX} Security 19)., pp. 19-36; Casado, M., Freedman, M.J., Pettit, J., Luo, J., McKeown, N., Shenker, S., Ethane: Taking control of the enterprise (2007) ACM SIGCOMM Computer Communication Review, 37 (4), pp. 1-12; Chao, T.-W., Ke, Y.-M., Chen, B.-H., Chen, J.-L., Hsieh, C.J., Lee, S.-C., Hsiao, H.-C., Securing data planes in softwaredefined networks (2016) 2016 IEEE NetSoft Conference and Workshops (NetSoft). IEEE, pp. 465-470; Chi, P.-W., Kuo, C.-T., Guo, J.-W., Lei, C.-L., How to detect a compromised SDN switch (2015) Proceedings of the 2015 1st IEEE Conference on Network Softwarization (NetSoft). IEEE, pp. 1-6; Chiu, Y.-C., Lin, P.-C., Rapid detection of disobedient forwarding on compromised OpenFlow switches (2017) 2017 International Conference on Computing, Networking and Communications (ICNC)., pp. 672-677; Dhawan, M., Poddar, R., Mahajan, K., Mann, V., SPHINX: Detecting security attacks in software-defined networks (2015) Ndss, 15, pp. 8-11; Dumitru, M.V., Dumitrescu, D., Raiciu, C., Can we exploit buggy P4 programs? (2020) Proceedings of the Symposium on SDN Research., pp. 62-68; Fayaz, S.K., Sekar, V., Testing stateful and dynamic data planes with FlowTest (2014) Proceedings of the Third Workshop on Hot Topics in Software Defined Networking., pp. 79-84; Fayaz, S.K., Yu, T., Tobioka, Y., Chaki, S., Sekar, V., BUZZ: Testing context-dependent policies in stateful networks (2016) 13th {USENIX} Symposium on Networked Systems Design and Implementation ({NSDI} 16)., pp. 275-289; Feldmann, A., Heyder, P., Kreutzer, M., Schmid, S., Seifert, J., Shulman, H., Thimmaraju, K., Sieberg, J., NetCo: Reliable routing with unreliable routers (2016) 2016 46th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshop (DSN-W)., pp. 128-135; Handigol, N., Heller, B., Jeyakumar, V., Mazieres, D., McKeown, N., I know what your packet did last hop: Using packet histories to troubleshoot networks (2014) 11th {USENIX} Symposium on Networked Systems Design and Implementation ({NSDI} 14)., pp. 71-85; Hu, H., Han, W., Ahn, G.-J., Zhao, Z., FLOWGUARD: Building robust firewalls for software-defined networks (2014) Proceedings of the Third Workshop on Hot Topics in Software Defined Networking., pp. 97-102; Kamisiński, A., Fung, C., Flowmon: Detecting malicious switches in software-defined networks (2015) Proceedings of the 2015 Workshop on Automated Decision Making for Active Cyber Defense., pp. 39-45; Kandoi, R., Antikainen, M., Denial-of-service attacks in Open-Flow SDN networks (2015) 2015 IFIP/IEEE International Symposium on Integrated Network Management (IM). IEEE, pp. 1322-1326; Kang, N., Liu, Z., Rexford, J., Walker, D., Optimizing the "" one big switch"" abstraction in software-defined networks (2013) Proceedings of the Ninth ACM Conference on Emerging Networking Experiments and Technologies., pp. 13-24; Kang, Q., Xue, L., Morrison, A., Tang, Y., Chen, A., Luo, X., Programmable in-network security for context-aware {BYOD} policies (2020) 29th {USENIX} Security Symposium ({USENIX} Security 20)., pp. 595-612; Khurshid, A., Zou, X., Zhou, W., Caesar, M., Brighten Godfrey, P., Veriflow: Verifying network-wide invariants in real time (2013) Presented As Part of the 10th {USENIX} Symposium on Networked Systems Design and Implementation ({NSDI} 13)., pp. 15-27; Kodeswaran, S., Arashloo, M.T., Tammana, P., Rexford, J., Tracking P4 program execution in the data plane (2020) Proceedings of the Symposium on SDN Research., pp. 117-122; Kuźniar, M., Perešini, P., Kostić, D., What you need to know about SDN flow tables (2015) International Conference on Passive and Active Network Measurement., pp. 347-359. , Springer; Li, Q., Zou, X., Huang, Q., Zheng, J., Lee, P.P.C., Dynamic packet forwarding verification in SDN (2019) IEEE Transactions on Dependable and Secure Computing, 16 (6), pp. 915-929. , https://doi.org/10.1109/TDSC.2018.2810880; Li, Y., Yin, X., Wang, Z., Yao, J., Shi, X., Wu, J., Zhang, H., Wang, Q., A survey on network verification and testing with formal methods: Approaches and challenges (2018) IEEE Communications Surveys & Tutorials, 21 (1), pp. 940-969; Liu, J., Hallahan, W., Schlesinger, C., Sharif, M., Lee, J., Soule, R., Wang, H., Foster, N., P4v: Practical verification for programmable data planes (2018) Proceedings of the 2018 Conference of the ACM Special Interest Group on Data Communication., pp. 490-503; McKeown, N., Anderson, T., Balakrishnan, H., Parulkar, G., Peterson, L., Rexford, J., Shenker, S., Turner, J., OpenFlow: Enabling innovation in campus networks (2008) ACM SIGCOMM Computer Communication Review, 38 (2), pp. 69-74; Musumeci, F., Ionata, V., Paolucci, F., Cugini, F., Tornatore, M., Machine-learning-assisted DDoS attack detection with P4 language (2020) IEEE International Conference on Communications, 2020; Notzli, A., Khan, J., Fingerhut, A., Barrett, C., Athanas, P., P4pktgen: Automated test case generation for p4 programs (2018) Proceedings of the Symposium on SDN Research., pp. 1-7; Pickett, G., (2015) Staying Persistent in Software Defined Networks. Black Hat Briefings, 2015; Sasaki, T., Pappas, C., Lee, T., Hoefler, T., Perrig, A., SDNsec: Forwarding accountability for the SDN data plane (2016) 2016 25th International Conference on Computer Communication and Networks (ICCCN)., pp. 1-10; Scott-Hayward, S., Arumugam, T., OFMTL-SEC: State-based security for software defined networks (2018) 2018 IEEE Conference on Network Function Virtualization and Software Defined Networks (NFV-SDN)., pp. 1-7. , https://doi.org/10.1109/NFV-SDN.2018.8725686; Scott-Hayward, S., Natarajan, S., Sezer, S., A survey of security in software defined networks (2016) IEEE Communications Surveys Tutorials, 18 (1), pp. 623-654. , https://doi.org/10.1109/COMST.2015.2453114; Shaghaghi, A., Ali Kaafar, M., Jha, S., Wedgetail: An intrusion prevention system for the data plane of software defined networks (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security., pp. 849-861; Shimizu, T., Kitagawa, N., Ohshima, K., Yamai, N., WhiteRabbit: Scalable software-defined network data-plane verification method through time scheduling (2019) IEEE Access, 7, pp. 97296-97306; Thang, N.C., Park, M., An efficient defense method for compromised switch and middlebox-bypass attacks in service function chaining (2020) Journal of Communications and Networks, 22 (6), pp. 493-504; Thimmaraju, K., Schiff, L., Schmid, S., Preacher: Network policy checker for adversarial environments (2019) 2019 38th Symposium on Reliable Distributed Systems (SRDS)., pp. 32-3209; Thimmaraju, K., Shastry, B., Fiebig, T., Hetzelt, F., Seifert, J.-P., Feldmann, A., Schmid, S., Taking control of SDN-based cloud systems via the data plane (2018) Proceedings of the Symposium on SDN Research., pp. 1-15; Wang, R., Butnariu, D., Rexford, J., OpenFlow-based server load balancing gone wild (2011) Hot-ICE, 11, p. 12; Zhang, M., Li, G., Wang, S., Liu, C., Chen, A., Hu, H., Gu, G., Wu, J., Poseidon: Mitigating volumetric DDoS attacks with programmable switches (2020) Proceedings of NDSS; Zhang, P., Dan Zhang, H., Li, Q., Verifying rule enforcement in software defined networks with REV (2020) IEEE/ACM Transactions on Networking, 28 (2), pp. 917-929; Zhang, P., Xu, S., Yang, Z., Li, H., Li, Q., Wang, H., Hu, C., Foces: Detecting forwarding anomalies in software defined networks (2018) 2018 IEEE 38th International Conference on Distributed Computing Systems (ICDCS). IEEE, pp. 830-840",,,ACM SIGSAC,"Association for Computing Machinery, Inc","2021 ACM International Workshop on Software Defined Networks and Network Function Virtualization Security, SDN-NFV Sec 2021, co-located with CODAYSPY 2021",28-Apr-21,,168625,,9.78E+12,,,English,"SDN-NFV Sec - Proc. ACM Int. Workshop Softw. Defined Networks Netw. Funct. Virtualiz. Secur., co-located CODAYSPY",Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85106017313
"Zhang Z., Yang X., Huang K.",57223299561;56415219100;13403476100;,Attacking Sequential Learning Models with Style Transfer Based Adversarial Examples,2021,Journal of Physics: Conference Series,1880,1,12021,,,,,10.1088/1742-6596/1880/1/012021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105453494&doi=10.1088%2f1742-6596%2f1880%2f1%2f012021&partnerID=40&md5=2a9be0097a8c1a760b6f3f99f7f32175,"School of Advanced Technology, Xi'An Jiaotong-Liverpool University, China","Zhang, Z., School of Advanced Technology, Xi'An Jiaotong-Liverpool University, China; Yang, X., School of Advanced Technology, Xi'An Jiaotong-Liverpool University, China; Huang, K., School of Advanced Technology, Xi'An Jiaotong-Liverpool University, China","In the field of deep neural network security, it has been recently found that non-sequential networks are vulnerable to adversarial examples. There are however few studies to investigate the adversarial attack on sequential tasks. To this end, in this paper, we propose a novel method to generate adversarial examples for sequential tasks. Specifically, an image style transfer method is used to generate for a Scene Text Recognition (STR) network adversarial examples, which are only different from the original image on the style. While they will not interfere with the recognition of image information by human vision, the adversarial examples would significantly mislead the recognition results of sequential networks. Moreover, based on a black-box attack, both in digital and physical environments, we show that the proposed method can use cross text shape information and attack successfully the TPS-ResNet-BiLSTM-Attention (TRBA) and Convolutional Recurrent Neural Network (CRNN) models. Finally, we demonstrate further that physical adversarial examples can easily mislead commercial recognition algorithms, e.g. iFLYTEK and Youdao, suggesting that STR models are also highly vulnerable to attacks from adversarial examples. © Published under licence by IOP Publishing Ltd.",,Character recognition; Computer vision; Convolutional neural networks; Deep neural networks; Network security; Commercial recognition; Image information; Original images; Physical environments; Sequential learning; Sequential task; Shape information; Transfer method; Recurrent neural networks,,,,,"Kaizhu, Huang, Amir, Hussain, Qiufeng, Wang, Zhang, Rui, (2019) Deep learning: Fundamentals, theory, and applications (springer), , ISBN 978-3-030-06072-5 2019; Yisen, Wang, Xuejiao, Deng, Songbai, Pu, Zhiheng, Huang, (2017) Residual convolutional CTC networks for automatic speech recognition CoRR 1702.07793; Kaiming, He, Xiangyu, Zhang, Shaoqing, Ren, Sun, Jian, (2016) 2016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2016, , (Las Vegas, NV, USA, June 27-30, 2016) Deep residual learning for image recognition 770-778 IEEE Computer Society; Chenyi, Chen, Ari, Seff, Kornhauser, Alain L., Jianxiong, Xiao, (2015) 2015 IEEE International Conference on Computer Vision, ICCV 2015, , (Santiago, Chile, December 7-13, 2015) Deepdriving: Learning affordance for direct perception in autonomous driving 2722-2730 IEEE Computer Society; Guanyu, Yang, Kaizhu, Huang, Rui, Zhang, John, Goulermas, Amir, Hussain, (2020) European Conference on Machine Learning Inductive generalized zero-shot learning with adversarial relation network; Shufei, Zhang, Kaizhu, Huang, Rui, Zhang, Hussain, Amir, (2019) IEEE Fifteen Conference on Data Mining (ICDM'2019) Generalized adversarial training in riemannian space; Chunchun, Lyu, Kaizhu, Huang, Hai-Ning, Liang, (2015) IEEE Fifteen Conference on Data Mining (ICDM'2015) A unified gradient regularization family for adversarial examples; Hendrik, Metzen Jan, Chaithanya, Kumar Mummadi, Thomas, Brox, Fischer, Volker, (2017) IEEE International Conference on Computer Vision, ICCV 2017, , 2017 (Venice, Italy, October 22-29) Universal adversarial perturbations against semantic image segmentation 2774-2783 IEEE Computer Society; Xing, Xu, Jiefu, Chen, Jinhui, Xiao, Lianli, Gao, Fumin, Shen, Shen, Heng Tao, (2020) 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition What machines see is not what they get: Fooling scene text recognition models with adversarial text images 12301-12311 IEEE; Leon, A., Alexander, Gatys, Ecker, S., Bethge, Matthias, (2016) 2016 IEEE Conference on Computer Vision and Pattern Recognition Image style transfer using convolutional neural networks, pp. 2414-2423. , IEEE Computer Society; Jeonghun, Baek, Geewook, Kim, Junyeop, Lee, Sungrae, Park, Dongyoon, Han, Sangdoo, Yun, Joon, Oh Seong, Hwalsuk, Lee, What is wrong with scene text recognition model comparisons? dataset and model analysis (2019), 2019 ICCV 4714-4722; Max, Jaderberg, Karen, Simonyan, Andrea, Vedaldi, Andrew, Zisserman, (2014) Synthetic data and artificial neural networks for natural scene text recognition CoRR 1406.2227; Ankush, Gupta, Andrea, Vedaldi, Zisserman, Andrew, (2016) 2016 IEEE Conference on Computer Vision and Pattern Recognition Synthetic data for text localisation in natural images, pp. 2315-2324","Huang, K.; School of Advanced Technology, China; 电子邮件: kaizhu.huang@xjtlu.edu.cn",,,IOP Publishing Ltd,"5th International Conference on Machine Vision and Information Technology, CMVIT 2021",26-Feb-21,,168714,17426588,,,,English,J. Phys. Conf. Ser.,Conference Paper,Final,"All Open Access, Bronze",Scopus,2-s2.0-85105453494
"Wang C., Dani J., Li X., Jia X., Wang B.",57210864682;57223131583;56084233300;57190676267;14834411600;,Adaptive Fingerprinting: Website Fingerprinting over Few Encrypted Traffic,2021,CODASPY 2021 - Proceedings of the 11th ACM Conference on Data and Application Security and Privacy,,,,149,160,,3,10.1145/3422337.3447835,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104973872&doi=10.1145%2f3422337.3447835&partnerID=40&md5=7353ec7854a2e69c00d727ce80c7a8c4,"University of Cincinnati, Cincinnati, United States","Wang, C., University of Cincinnati, Cincinnati, United States; Dani, J., University of Cincinnati, Cincinnati, United States; Li, X., University of Cincinnati, Cincinnati, United States; Jia, X., University of Cincinnati, Cincinnati, United States; Wang, B., University of Cincinnati, Cincinnati, United States","Website fingerprinting attacks can infer which website a user visits over encrypted network traffic. Recent studies can achieve high accuracy (e.g., 98%) by leveraging deep neural networks. However, current attacks rely on enormous encrypted traffic data, which are time-consuming to collect. Moreover, large-scale encrypted traffic data also need to be recollected frequently to adjust the changes in the website content. In other words, the bootstrap time for carrying out website fingerprinting is not practical. In this paper, we propose a new method, named Adaptive Fingerprinting, which can derive high attack accuracy over few encrypted traffic by leveraging adversarial domain adaption. With our method, an attacker only needs to collect few traffic rather than large-scale datasets, which makes website fingerprinting more practical in the real world. Our extensive experimental results over multiple datasets show that our method can achieve 89% accuracy over few encrypted traffic in the closed-world setting and 99% precision and 99% recall in the open-world setting. Compared to a recent study (named Triplet Fingerprinting), our method is much more efficient in pre-training time and is more scalable. Moreover, the attack performance of our method can outperform Triplet Fingerprinting in both the closed-world evaluation and open-world evaluation. © 2021 ACM.",adversarial domain adaption; encrypted traffic; transfer learning,Cryptography; Data privacy; Deep neural networks; Large dataset; Bootstrap time; Domain adaptions; Encrypted traffic; High-accuracy; Large-scale datasets; Multiple data sets; Network traffic; Web site contents; Websites,,,,,"(2016) WTF-PAD, , https://github.com/wtfpad/wtfpad; (2018), https://github.com/onionpop/tor-browser-crawler, tor-browser-crawler; (2021), https://github.com/SmartHomePrivacyProject/AdaptiveFingerprinting, AdaptiveFingerprinting; Abe, K., Goto, S., Fingerprinting attack on tor anonymity using deep learning (2016) Proc. Of Aisa Pacic Advanced Network (APAN); Bhat, S., Lu, D., Kwon, A., Devadas, S., Var-cnn: A data-ecientwebsite fingerprinting attack based on deep learning (2019) Proc. Of PETS'19; Cadena, W.D., Mitseva, A., Hiller, J., Penekamp, J., Reuter, S., Filter, J., Engel, T., Panchenko, A., Tracsliver: Finghting website fingerprinting attacks with trac splitting (2020) Proc. Of ACM CCS'20; Cai, X., Nithyanand, R., Johnson, R., Cs-buflo: A congrestion sensitive website fingerprinting defense (2014) Proc. Of 13th ACM Workshop on Privacy in Electronic Society; Cui, W., Chen, T., Fields, C., Chen, J., Sierra, A., Chan-Tin, E., Revisting assumtions for website fingerprinting attacks (2019) Proc. Of ACM ASIACCS'19; Dyer, K.P., Coull, S.E., Ristenpart, T., Shrimpton, T., Peek-a-boo, i still see you: Why ecient trac analysis countermeasures fail (2012) Proc. Of IEEE S&P'12; Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette, F., Marchand, M., Lempitsky, V., Domain-adversarial tranining of neural networks (2016) Journal of Machine Learning Research (2016); Gong, J., Wang, T., Zero-delay lightweight defenses against website fingerprinting (2020) Proc. Of USENIX Security'20; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Proc. Of the International Conference on Nerual Information Processing Systems (NIPS 2014); Hayes, J., Danezis, G., K-fingerprinting: A robust scalable website fingerprinting technique (2016) Proc. Of USENIX Security'16; Henri, S., Garcia-Aviles, G., Serrano, P., Banchs, A., Thiran, P., Protecting against website fingerprinting with multihoming (2020) Proc. Of PETS'20; Hermann, D., Wendolsky, R., Federrath, H., Website fingertinging: Attacking popular privacy enhancing tehnologies with the multinomial naive-bayes classier (2009) Proc. Of ACM Workshop on Cloud Computing Security; Ho, D., Liang, E., Stoica, I., Abbeel, P., Chen, X., Population based augmentation: Ecient learning of augmentation policy schedules (2019) Proc. Of ICML'19; Imani, M., Rahman, M.S., Mathews, N., Wright, M., (2019) Mockingbird: Defending against Deep-Learning-Based Website Fingerprinting Attacks with Adversarial Traces, , https://arxiv.org/pdf/1902.06626.pdf, 2019; Jansen, R., Juarez, M., Galvez, R., Elahi, T., Diaz, C., Inside job: Applying trac analysis to measure tor from within (2018) Proc. Of NDSS'18; Juarez, M., Afroz, S., G.Acar, Diaz, C., Greenstadt, R., Acriticial evaluation of website fingerprinting attacks (2014) Proc. Of ACM CCS'14; Juarez, M., Imani, M., Perry, M., Diaz, C., Wright, M., Toward an ecient website fingerprinting defense (2016) Proc. Of ESORICS'16; Koch, G., Zemel, R., Salakhutdinov, R., Siamese neural networks for one-shot image recognition (2015) Proc. Of the 32th International Conference on Machine Learning (ICML'15); Li, S., Guo, H., Hopper, N., Measuring information leakage inwebsite fingerprinting attacks and defenses (2018) Proc. Of ACM CCS'18; Liberatore, M., Neil Levine, B., Inferring the source of encrypted http connections (2006) Proc. Of ACM CCS'06; Long, M., Wang, J., Learning transferable features with deep adaptation networks (2015) Proc. Of ICML'15; Van Der Maaten, L., Hinton, G., Visualizing data using t-sne (2008) Journal of Machine Learning Research, 9, pp. 2579-2605. , Nov 2008; Nasr, M., Bahramali, A., Houmansadr, A., (2020) Blind Adversarial Network Perturbations, , https://arxiv.org/pdf/2002.06495.pdf, 2020; Eun Oh, S., Sunkam, S., Hopper, N., P-fp: Extraction, classication, and predication of website fingerprints (2019) Proc. Of PETS'19; Pan, S.J., Yang, Q., A survey on transfer learning (2009) IEEE Transactions on Knowledge and Data Engineering, , 2009; Panchenko, A., Lanze, F., Zinnen, A., Henze, M., Penekamp, J., Wehrle, K., Engel, T., Website fingerprinting at internet scale (2016) Proc. Of NDSS'16; Parki, O.M., Vedaldi, A., Zisserman, A., Deep face recognition (2015) British Machine Vision Association; Rimmer, V., Preuveneers, D., Juarez, M., Goethem, T.V., Joosen, W., Automated website fingerprinting through deep learning (2018) Proc. Of NDSS'18; Schro, F., Kalenichenko, D., Philbin, J., Facenet: A unied embedding for face recognition and clustering (2015) Proc. Of IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Shorten, C., Khoshgoftaar, T.M., A survey on image data augmentation for deep learning (2019) Journal of Big Data, 6 (60). , 2019; Shusterman, A., Kang, L., Haskal, Y., Meltser, Y., Mittal, P., Oren, Y., Yarom, Y., Robust website fingerprinting through the cache occupancy channel (2019) Proc. Of USENIX Security'19; Sirinam, P., Imani, M., Juarez, M., Wright, M., Deep fingerprinting: Understanding website fingerprinting defenses with deep learning (2018) Proc. Of ACM CCS'18; Sirinam, P., Mathews, N., Saidur Rahman, M., Wright, M., Triplet fingerprinting: More practical and portable website fingerprinting with n-shot learning (2019) Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security., pp. 1131-1148; Sun, B., Feng, J., Saenko, K., Return of frustratingly easy domain adaption (2016) Proc. Of AAAI Conference on Articial Intelligence; Taigman, Y., Yang, M., Ranzato, M.A., Wolf, L., Deepface: Closing the gap to human-level performance in face verication (2014) Proc. Of IEEE CVPR'14; Tzeng, E., Homan, J., Saenko, K., Darrell, T., Adversarial discriminative domain adaptation (2017) Proc. Of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Tzeng, E., Homan, J., Zhang, N., Saenko, K., Darrell, T., Domain Confusion, D., For Domain Invariance, M., (2014), https://arxiv.org/pdf/1412.3474.pdf, 2014; Wang, T., High precision open-world website fingerprinting (2020) Proc. Of IEEE S&P'20; Wang, T., Cai, X., Nithyanand, R., Johnson, R., Goldberg, I., Eective attacks and provable defenses for website ngerprinting (2014) 23rd {USENIX} Security Symposium ({USENIX} Security 14)., pp. 143-157; Xiang Cui, T., Nithyannand, R., Johnson, R., Goldberg, I., Eective attacks on provable denfenses for website fingerprinting (2014) Proc. Of 23rd USENIX Security Symposium; Wang, T., Goldberg, I., On realistically attacking tor with website fingerprinting (2016) Proc. Of PETS'16; Wang, T., Goldberg, I., Walkie-talkie: An ecient defense against passive website fingerprinting attacks (2017) Proc. Of USENIX Security'17; Xu, Y., Wang, T., Li, Q., Gong, Q., Chen, Y., Jiang, Y., A multi-tab website fingerprinting attack (2018) Proc. Of ACSAC'18; Yosinski, J., Clune, J., Bengio, Y., Lipson, H., How transferable are features in deep neural networks (2014) Advances in Neural Information Processing Systems., pp. 3320-3328; Zhou, Z., Feng, J., Deep forest: Towards an alternative to deep neural networks (2017) Proceedings of the 26th International Joint Conference on Articial Intelligence., pp. 3553-3559; Zhuang, F., Qi, Z., Duan, K., Xi, D., Zhu, Y., Zhu, H., Xiong, H., He, Q., A comprehensive survey on transfer learning (2020) Proc. IEEE, , 2020",,,ACM SIGSAC,"Association for Computing Machinery, Inc","11th ACM Conference on Data and Application Security and Privacy, CODASPY 2021",26 April 2021 through 28 April 2021,,168332,,9.78E+12,,,English,CODASPY - Proc. ACM Conf. Data Appl. Secur. Priv.,Conference Paper,Final,,Scopus,2-s2.0-85104973872
"Li C., Chen X., Wang H., Wang P., Zhang Y., Wang W.",57219791829;24823835800;36081400400;57219793701;57225165975;55876753100;,End-to-end attack on text-based CAPTCHAs based on cycle-consistent generative adversarial network,2021,Neurocomputing,433,,,223,236,,1,10.1016/j.neucom.2020.11.057,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100206839&doi=10.1016%2fj.neucom.2020.11.057&partnerID=40&md5=75eb85a31438e5c6b4b155a7672c002b,"College of Cybersecurity, Sichuan University, Chengdu, 610065, China; College of Cybersecurity and the Cybersecurity Research Institute, Sichuan University, Chengdu, 610065, China; College of Computer Science, Sichuan University, Chengdu, 610065, China; College of Art, Sichuan University, Chengdu, 610065, China","Li, C., College of Cybersecurity, Sichuan University, Chengdu, 610065, China; Chen, X., College of Cybersecurity and the Cybersecurity Research Institute, Sichuan University, Chengdu, 610065, China; Wang, H., College of Cybersecurity, Sichuan University, Chengdu, 610065, China; Wang, P., College of Computer Science, Sichuan University, Chengdu, 610065, China; Zhang, Y., College of Art, Sichuan University, Chengdu, 610065, China; Wang, W., College of Cybersecurity and the Cybersecurity Research Institute, Sichuan University, Chengdu, 610065, China","As a widely deployed security scheme, text-based completely automated public Turing tests to tell computers and humans apart (CAPTCHAs) have become increasingly unable to resist machine learning-based attacks. So far, many researchers have conducted studies on approaches for attacking text-based CAPTCHAs deployed by different companies, such as Microsoft, Amazon, and Apple, and achieved specific results. However, most of these attacks have shortcomings, such as the poor portability of attack methods, which require a series of data preprocessing steps and rely on large amounts of labeled CAPTCHAs. In this study, we propose an efficient and simple end-to-end attack method based on cycle-consistent generative adversarial networks (Cycle-GANs). Compared to previous studies, our approach significantly reduces the cost of data labeling. Additionally, this method has high portability. It can attack ordinary text-based CAPTCHA schemes only by modifying a few configuration parameters, which makes the attack easier to execute. First, we train CAPTCHA synthesizers based on the Cycle-GAN to generate some fake samples. Basic recognizers based on a convolutional recurrent neural network are trained using the fake data. Subsequently, an active transfer learning method is employed to optimize the basic recognizer utilizing tiny amounts of labeled real-world CAPTCHA samples. Our approach efficiently cracked the CAPTCHA schemes deployed by 10 popular websites, indicating that our attack method may be universal. Additionally, we analyzed the current most popular anti-recognition mechanisms. The results show that the combination of more anti-recognition mechanisms can improve the security of CAPTCHAs. However, the improvement is limited. Conversely, generating more complex CAPTCHAs may cost more resources and reduce the usability of CAPTCHAs. © 2020",Active transfer learning; CAPTCHAs; CRNN; Cycle-GAN,Convolutional neural networks; Cost reduction; Electronic mail filters; Learning systems; Recurrent neural networks; Transfer learning; Adversarial networks; Attack methods; Configuration parameters; Data labeling; Data preprocessing; Recognition mechanism; Security scheme; Transfer learning methods; Network security; Article; artificial neural network; completely automated public turing test to tell computer and human apart; computer analysis; computer security; convolutional neural network; cycle consistent generative adversarial network; data analysis; data processing; mathematical computing; mathematical model; priority journal; process optimization; web browser,,,,,"Torky, M., Meligy, A., Ibrahim, H., Securing online social networks against bad bots based on a necklace captcha approach (2016) Proceedings of the 12th International Computer Engineering Conference (ICENCO), pp. 158-163. , IEEE; Kim, D., Sample, L., Search prevention with captcha against web indexing: A proof of concept (2019) Proceedings of the 22nd International Conference on Computational Science and Engineering (CSE), pp. 219-224. , IEEE; Gelernter, N., Herzberg, A., Tell me about yourself: The malicious captcha attack (2016) Proceedings of the 25th International Conference on World Wide Web (WWW), pp. 999-1008; Tang, M., Gao, H., Zhang, Y., Liu, Y., Zhang, P., Wang, P., Research on deep learning techniques in breaking text-based captchas and designing image-based captcha (2018) IEEE Transactions on Information Forensics and Security (TIFS), 13, pp. 2522-2537; Shah, M., Harras, K., Hitting three birds with one system: A voice-based captcha for the modern user (2018) Proceedings of the 22nd IEEE International Conference on Web Services (ICWS), pp. 257-264; Gao, H., Wang, W., Qi, J., Wang, X., Liu, X., Yan, J., The robustness of hollow captchas (2013) Proceedings of the 20th ACM SIGSAC Conference on Computer and Communications Security (CCS), pp. 1075-1086. , ACM; Gao, H., Tang, M., Liu, Y., Zhang, P., Liu, X., Research on the security of microsoft's two-layer captcha (2017) IEEE Transactions on Information Forensics and Security (TIFS), 12, pp. 1671-1685; Ye, G., Tang, Z., Fang, D., Zhu, Z., Feng, Y., Xu, P., Chen, X., Wang, Z., Yet another text captcha solver: A generative adversarial network based approach (2018) Proceedings of the 25th ACM SIGSAC Conference on Computer and Communications Security (CCS), pp. 332-348. , ACM; Xu, X., Liu, L., Li, B., A survey of captcha technologies to distinguish between human and computer (2020) Neurocomputing, 408, pp. 292-307; Yan, C., Li, Z., Zhang, Y., Liu, Y., Ji, X., Zhang, Y., Depth image denoising using nuclear norm and learning graph model (2020) ACM Transactions on Multimedia Computing Communications and Applications; George, D., Lehrach, W., Kansky, K., Lázaro-Gredilla, M., Laan, C., Marthi, B., Lou, X., Wang, H., A generative vision model that trains with high data efficiency and breaks text-based captchas (2017) Science, 358, p. 2612; Goodfellow, I.J., Bulatov, Y., Ibarz, J., Arnoud, S., Shet, V., Multi-digit number recognition from street view imagery using deep convolutional neural networks (2014) Proceedings of the 2nd International Conference on Learning Representations (ICLR); Zi, Y., Gao, H., Cheng, Z., Liu, Y., An end-to-end attack on text captchas (2019) IEEE Transactions on Information Forensics and Security (TIFS), 15, pp. 753-766; Zhu, J.-Y., Park, T., Isola, P., Efros, A.A., Unpaired image-to-image translation using cycle-consistent adversarial networks (2017) Proceedings of the IEEE International Conference on Computer Vision (ICCV), pp. 2223-2232; Shi, B., Bai, X., Yao, C., An end-to-end trainable neural network for image-based sequence recognition and its application to scene text recognition (2016) IEEE Transactions on Pattern Analysis and Machine Intelligence, 39, pp. 2298-2304; Mori, G., Malik, J., Recognizing objects in adversarial clutter: Breaking a visual captcha (2003) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), vol. 1, , IEEE pp. I–I; Chellapilla, K., Simard, P.Y., Using machine learning to break visual human interaction proofs (hips) (2005) Proceedings of Advances in Neural Information Processing Systems (NIPS), pp. 265-272; Simard, P.Y., Szeliski, R., Benaloh, J., Couvreur, J., Calinov, I., Using character recognition and segmentation to tell computer from humans (2003) Proceedings of the 7th International Conference on Document Analysis and Recognition (CDAR), pp. 418-423. , IEEE; Yan, J., El Ahmad, A.S., A low-cost attack on a microsoft captcha (2008) Proceedings of the 15th ACM SIGSAC Conference on Computer and Communications Security (CCS), pp. 543-554. , ACM; Franc, V., Hlaváč, V., License plate character segmentation using hidden markov chains (2005) Joint Pattern Recognition Symposium, pp. 385-392. , Springer; Starostenko, O., Cruz-Perez, C., Uceda-Ponga, F., Alarcon-Aquino, V., Breaking text-based captchas with variable word and character orientation (2015) Pattern Recognition, 48, pp. 1101-1112; Liu, P., Guo, J.-M., Wu, C.-Y., Cai, D., Fusion of deep learning and compressed domain features for content-based image retrieval (2017) IEEE Transactions on Image Processing, 26, pp. 5706-5717; Yan, C., Gong, B., Wei, Y., Gao, Y., Deep multi-view enhancement hashing for image retrieval (2020) IEEE Transactions on Pattern Analysis and Machine Intelligence, , 1–1; Schlemper, J., Caballero, J., Hajnal, J.V., Price, A.N., Rueckert, D., A deep cascade of convolutional neural networks for dynamic mr image reconstruction (2017) IEEE transactions on Medical Imaging, 37, pp. 491-503; Yan, C., Shao, B., Zhao, H., Ning, R., Zhang, Y., Xu, F., 3d room layout estimation from a single rgb image (2020) IEEE Transactions on Multimedia, , 1–1; Zhang, K., Zuo, W., Chen, Y., Meng, D., Zhang, L., Beyond a gaussian denoiser: Residual learning of deep cnn for image denoising (2017) IEEE Transactions on Image Processing, 26, pp. 3142-3155; Zhang, L., Xie, Y., Luan, X., He, J., Captcha automatic segmentation and recognition based on improved vertical projection (2017) Proceedings of the 9th IEEE International Conference on Communication Software and Networks (ICCSN), pp. 1167-1172. , IEEE; Isola, P., Zhu, J.-Y., Zhou, T., Efros, A.A., Image-to-image translation with conditional adversarial networks (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1125-1134; Shi, W., Caballero, J., Huszár, F., Totz, J., Aitken, A.P., Bishop, R., Rueckert, D., Wang, Z., Real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1874-1883; Kingma, D.P., Ba, J., Adam: A method for stochastic optimization (2015) Proceedings of the 3rd International Conference on Learning Representations (ICLR); Xu, B., Wang, N., Chen, T., Li, M., (2015), Empirical evaluation of rectified activations in convolutional network arXiv preprint arXiv:1505.00853; Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., Chen, X., Improved techniques for training gans (2016) Proceedings of Advances in Neural Information Processing Systems (NIPS), pp. 2234-2242; Lucic, M., Kurach, K., Michalski, M., Gelly, S., Bousquet, O., Are gans created equal? A large-scale study (2018) Proceedings of Advances in Neural Information Processing Systems (NIPS), pp. 700-709; Zhang, R., Isola, P., Efros, A.A., Colorful image colorization (2016), pp. 649-666. , Proceedings of European Conference on Computer Vision (ECCV), Springer; Schuster, M., Paliwal, K.K., Bidirectional recurrent neural networks (1997) IEEE Transactions on Signal Processing, 45, pp. 2673-2681; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 770-778; Huang, G., Liu, Z., Van Der Maaten, L., Weinberger, K.Q., Densely connected convolutional networks (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4700-4708; Wang, Z., Bovik, A.C., A universal image quality index (2002) IEEE Signal Processing Letters (SPL), 9, pp. 81-84; Huynh-Thu, Q., Ghanbari, M., Scope of validity of psnr in image/video quality assessment (2008) Electronics Letters, 44, pp. 800-801; Guizar-Sicairos, M., Thurman, S.T., Fienup, J.R., Efficient subpixel image registration algorithms (2008) Optics Letters, 33, pp. 156-158; Roberts, J.W., Van Aardt, J.A., Ahmed, F.B., Assessment of image fusion procedures using entropy, image quality, and multispectral classification (2008) Journal of Applied Remote Sensing, 2; Maes, F., Collignon, A., Vandermeulen, D., Marchal, G., Suetens, P., Multimodality image registration by maximization of mutual information (1997) IEEE Transactions on Medical Imaging (TMI), 16, pp. 187-198; Zhang, R., Isola, P., Efros, A.A., Shechtman, E., Wang, O., The unreasonable effectiveness of deep features as a perceptual metric (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 586-595; Bursztein, E., Martin, M., Mitchell, J., Text-based captcha strengths and weaknesses (2011) Proceedings of the 18th ACM SIGSAC Conference on Computer and Communications Security (CCS), pp. 125-138. , ACM; Osadchy, M., Hernandez-Castro, J., Gibson, S., Dunkelman, O., Pérez-Cabo, D., No bot expects the deepcaptcha! introducing immutable adversarial examples, with applications to captcha generation (2017) IEEE Transactions on Information Forensics and Security, 12, pp. 2640-2653; Shi, C., Ji, S., Liu, Q., Liu, C., Chen, Y., He, Y., Liu, Z., Wang, T., Text captcha is dead? A large scale deployment and empirical study (2020) The 27th ACM Conference on Computer and Communications Security","Chen, X.; College of Cybersecurity and the Cybersecurity Research Institute, China; 电子邮件: chenxsh@scu.edu.cn",,,Elsevier B.V.,,,,,9252312,,NRCGE,,English,Neurocomputing,Article,Final,"All Open Access, Green",Scopus,2-s2.0-85100206839
"Yang X., Liu W., Zhang S., Liu W., Tao D.",56967214100;36739405100;36057765700;57209524802;57218623508;,Targeted Attention Attack on Deep Learning Models in Road Sign Recognition,2021,IEEE Internet of Things Journal,8,6,9245511,4980,4990,,1,10.1109/JIOT.2020.3034899,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098760780&doi=10.1109%2fJIOT.2020.3034899&partnerID=40&md5=cf002caa2de7548ea6f16a53e506bacb,"School of Computer Science, Faculty of Engineering and Information Technology, University of Technology Sydney, Sydney, NSW, Australia; School of Information and Control Engineering, China University of Petroleum (East China), Qingdao, China; College of Information Engineering, Shenzhen University, Shenzhen, China; School of Computer Science, Faculty of Engineering, University of Sydney, Darlington, NSW, Australia","Yang, X., School of Computer Science, Faculty of Engineering and Information Technology, University of Technology Sydney, Sydney, NSW, Australia; Liu, W., School of Information and Control Engineering, China University of Petroleum (East China), Qingdao, China; Zhang, S., College of Information Engineering, Shenzhen University, Shenzhen, China; Liu, W., School of Computer Science, Faculty of Engineering, University of Sydney, Darlington, NSW, Australia; Tao, D., School of Computer Science, Faculty of Engineering, University of Sydney, Darlington, NSW, Australia","Real-world traffic sign recognition is an important step toward building autonomous vehicles, most of which highly dependent on deep neural networks (DNNs). Recent studies demonstrated that DNNs are surprisingly susceptible to adversarial examples. Many attack methods have been proposed to understand and generate adversarial examples, such as gradient-based attack, score-based attack, decision-based attack, and transfer-based attacks. However, most of these algorithms are ineffective in real-world road sign attack, because 1) iteratively learning perturbations for each frame is not realistic for a fast moving car and 2) most optimization algorithms traverse all pixels equally without considering their diverse contribution. To alleviate these problems, this article proposes the targeted attention attack (TAA) method for real-world road sign attack. Specifically, we have made the following contributions: 1) we leverage the soft attention map to highlight those important pixels and skip those zero-contributed areas-This also helps to generate natural perturbations; 2) we design an efficient universal attack that optimizes a single perturbation/noise based on a set of training images under the guidance of the pretrained attention map; 3) we design a simple objective function that can be easily optimized; and 4) we evaluate the effectiveness of TAA on real-world data sets. Experimental results validate that the TAA method improves the attack successful rate (nearly 10%) and reduces the perturbation loss (about a quarter) compared with the popular RP2 method. Additionally, our TAA also provides good properties, e.g., transferability and generalization capability. We provide code and data to ensure the reproducibility: https://github.com/AdvAttack/RoadSignAttack. © 2014 IEEE.",Adversarial machine learning; deep neural networks (DNNs); physical world attack; traffic sign recognition,Deep neural networks; Iterative methods; Pattern recognition; Pixels; Roads and streets; Traffic signs; Generalization capability; Learning models; Natural perturbations; Objective functions; Optimization algorithms; Reproducibilities; Road sign recognition; Traffic sign recognition; Deep learning,,,,,"Ning, H., Farha, F., Mohammad, Z.N., Daneshmand, M., A survey and tutorial on ?connection exploding meets efficient communication? In the Internet of Things (2020) IEEE Internet Things J., Early Access, , May 22; Zanella, A., Bui, N., Castellani, A., Vangelista, L., Zorzi, M., Internet of Things for smart cities (2014) IEEE Internet Things J, 1 (1), pp. 22-32. , Feb; Jin, J., Gubbi, J., Marusic, S., Palaniswami, M., An information framework for creating a smart city through Internet of Things (2014) IEEE Internet Things J, 1 (2), pp. 112-121. , Apr; Gong, Y., Li, Z., Zhang, J., Liu, W., Zheng, Y., Kirsch, C., Networkwide crowd flow prediction of sydney trains via customized online nonnegative matrix factorization (2018) Proc. 27th ACM Int. Conf. Inf. Knowl. Manag. (CIKM, pp. 1243-1252; Kuutti, S., Fallah, S., Katsaros, K., Dianati, M., McCullough, F., Mouzakitis, A., A survey of the state-of-The-Art localization techniques and their potentials for autonomous vehicle applications (2018) IEEE Internet Things J, 5 (2), pp. 829-846. , Apr; Zheng, Y., Wang, J., Li, K., Smoothing traffic flow via control of autonomous vehicles (2020) IEEE Internet Things J, 7 (5), pp. 3882-3896. , May; Nguyen, H., Liu, W., Rivera, P., Chen, F., TrafficWatch: Real-Time traffic incident detection and monitoring using social media (2016) Proc. Pac.-Asia Conf. Knowl. Disc. Data Min. (PAKDD, pp. 540-551; Stallkamp, J., Schlipsing, M., Salmen, J., Igel, C., The german traffic sign recognition benchmark: A multi-class classification competition."" in (2011) Proc. Int. Joint Conf. Neural Netw, pp. 1453-1460; Kim, J., Misu, T., Chen, Y.-T., Tawari, A., Canny, J., Grounding human-To-vehicle advice for self-driving vehicles (2019) Proc IEEE Conf. Comput. Vis. Pattern Recognit, pp. 10591-10599; Szegedy, C., Intriguing properties of neural networks (2013), arXiv 1312.6199; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv 1412.6572; Braytee, A., Liu, W., Kennedy, P., A cost-sensitive learning strategy for feature extraction from imbalanced data (2016) Proc. Int. Conf. Neural Inf. Process. (ICONIP, pp. 78-86; Zeng, X., Adversarial attacks beyond the image space (2019) Proc IEEE Conf. Comput. Vis. Pattern Recognit, pp. 4302-4311; Liu, W., Chawla, S., A quadratic mean based supervised learning model for managing data skewness (2011) Proc SIAM Int. Conf. Data Min, pp. 188-198; Akhtar, N., Mian, A., Threat of adversarial attacks on deep learning in computer vision: A survey (2018) IEEE Access, 6, pp. 14410-14430; Chen, C., Seff, A., Kornhauser, A., Xiao, J., DeepDriving: Learning affordance for direct perception in autonomous driving (2015) Proc IEEE Int. Conf. Comput. Vis, pp. 2722-2730; Su, J., Vargas, D.V., Sakurai, K., One pixel attack for fooling deep neural networks (2019) IEEE Trans. Evol. Comput, 23 (5), pp. 828-841. , Oct; Narodytska, N., Kasiviswanathan, S.P., Simple black-box adversarial perturbations for deep networks (2016), 1612.06299; Eykholt, K., Robust physical-world attacks on deep learning visual classification (2018) Proc IEEE Conf. Comput. Vis. Pattern Recognit, pp. 1625-1634; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial examples in the physical world (2016), arXiv 1607.02533; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., DeepFool: A simple and accurate method to fool deep neural networks (2016) Proc IEEE Conf. Conf. Comput. Vis. Pattern Recognit, pp. 2574-2582; Dong, Y., Boosting adversarial attacks with momentum (2018) Proc IEEE Conf. Comput. Vis. Pattern Recognit, pp. 9185-9193. , Jun; Xiang, Y., Xu, Y., Li, Y., Ma, W., Xuan, Q., Liu, Y., Side-channel gray-box attack for DNNs (2020) IEEE Trans. Circuits Syst. II, Exp. Briefs, Early Access, , Jul. 27; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Proc IEEE Symp. Security Privacy (SP, pp. 39-57; Hayes, J., Danezis, G., Machine learning as an adversarial service: Learning black-box adversarial examples (2017), 1708.05207; Ilyas, A., Black-box adversarial attacks with limited queries and information (2018) Proc. 35th Int. Conf. Mach. Learn ICML, pp. 2142-2151; Zhao, P., Chen, P.-Y., Wang, S., Lin, X., Towards query-efficient black-box adversary with zeroth-order natural gradient descent."" in (2020) Proc. AAAI, pp. 6909-6916; Brendel, W., Rauber, J., Bethge, M., (2017) Decision-based Adversarial Attacks: Reliable Attacks against Black-box Machine Learning Models, , arXiv 1712.04248; Schott, L., Rauber, J., Bethge, M., Brendel, W., (2018) Towards the First Adversarially Robust Neural Network Model on MNIST, , arXiv 1805, 09190; Chen, J., Jordan, M.I., (2019) Boundary Attack++: Query-efficient Decision-based Adversarial Attack, , arXiv 1904, 02144; Chen, J., Jordan, M.I., Wainwright, M.J., HopSkipJumpAttack: A query-efficient decision-based attack (2020) Proc IEEE Symp. Security Privacy (SP, pp. 1277-1294; Li, H., Xu, X., Zhang, X., Yang, S., Li, B., QEBA: Query-efficient boundary-based blackbox attack (2020) Proc IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR, pp. 1218-1227. , Jun; Xiao, C., Zhu, J.-Y., Li, B., He, W., Liu, M., Song, D., (2018) Spatially Transformed Adversarial Examples, , 1801, 02612; Engstrom, L., Tran, B., Tsipras, D., Schmidt, L., Madry, A., Exploring the landscape of spatial robustness (2019) Proc. 36th Int. Conf. Mach. Learn, pp. 1802-1811; Wang, L., Cho, W., Yoon, K.-J., Deceiving image-To-image translation networks for autonomous driving with adversarial perturbations (2020) IEEE Robot. Autom. Lett, 5 (2), pp. 1421-1428. , Jun; Chen, J., Wang, D., Chen, H., Explore the transformation space for adversarial images (2020) Proc. 10th ACM Conf. Data Appl. Security Privacy, pp. 109-120; Liu, D.C., Nocedal, J., On the limited memory BFGs method for large scale optimization (1989) Math. Program, 45 (1-3), pp. 503-528; Li, J., Cai, T., Deng, K., Wang, X., Sellis, T., Xia, F., Communitydiversified influence maximization in social networks (2020) Inf. Syst, 92 (11). , Sep, Art; Cai, T., Target-Aware holistic influence maximization in spatial social networks (2020) IEEE Trans. Knowl. Data Eng., Early Access, , Jun. 17; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-The-Art face recognition (2016) Proc ACM SIGSAC Conf. Comput. Commun. Security, pp. 1528-1540; Wang, F., Residual attention network for image classification (2017) Proc IEEE Conf. Comput. Vis. Pattern Recognit, pp. 3156-3164; Mnih, V., Recurrent models of visual attention (2014) Proc. Adv. Neural Inf. Process. Syst, pp. 2204-2212; He, K., Zhang, X., Ren, S., Sun, J., Identity mappings in deep residual networks (2016) Proc. Eur. Conf. Comput. Vis, pp. 630-645; Mogelmose, A., Trivedi, M.M., Moeslund, T.B., Vision-based traffic sign detection and analysis for intelligent driver assistance systems: Perspectives and survey (2012) IEEE Trans. Intell. Transp. Syst, 13 (4), pp. 1484-1497. , Dec; Stallkamp, J., Schlipsing, M., Salmen, J., Igel, C., Man vs. computer: Benchmarking machine learning algorithms for traffic sign recognition (2012) Neural Netw, 32, pp. 323-332. , Mar; Chan, R.H., Ho, C.-W., Nikolova, M., Salt-And-pepper noise removal by median-Type noise detectors and detail-preserving regularization (2005) IEEE Trans. Image Process, 14 (10), pp. 1479-1485. , Oct; Rauber, J., Brendel, W., Bethge, M., FoolBox: A python toolbox to benchmark the robustness of machine learning models (2017), arXiv 1707.04131; Reinhard, E., Heidrich, W., Debevec, P., Pattanaik, S., Ward, G., Myszkowski, K., (2010) High Dynamic Range Imaging: Acquisition, Display, and Image-Based Lighting. London, U.K.: Morgan Kaufmann","Zhang, S.; School of Computer Science, Australia; 电子邮件: slzhang.szu@gmail.com",,,Institute of Electrical and Electronics Engineers Inc.,,,,,23274662,,,,English,IEEE Internet Things J.,Article,Final,,Scopus,2-s2.0-85098760780
"Zhang C., Tang Z., Zuo Y., Li K., Li K.",57219801935;7403306139;57209601363;57203906672;57199454104;,A robust generative classifier against transfer attacks based on variational auto-encoders,2021,Information Sciences,550,,,57,70,,1,10.1016/j.ins.2020.10.044,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095602989&doi=10.1016%2fj.ins.2020.10.044&partnerID=40&md5=1a01b1f0f3d4a100d0d4ddda13e65f9f,"College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; National Supercomputing Center in Changsha, China; Department of Computer Science, State University of New York, New York, United States","Zhang, C., College of Computer Science and Electronic Engineering, Hunan University, Changsha, China, National Supercomputing Center in Changsha, China; Tang, Z., College of Computer Science and Electronic Engineering, Hunan University, Changsha, China, National Supercomputing Center in Changsha, China; Zuo, Y., College of Computer Science and Electronic Engineering, Hunan University, Changsha, China, National Supercomputing Center in Changsha, China; Li, K., College of Computer Science and Electronic Engineering, Hunan University, Changsha, China, National Supercomputing Center in Changsha, China; Li, K., College of Computer Science and Electronic Engineering, Hunan University, Changsha, China, Department of Computer Science, State University of New York, New York, United States","Deep neural networks (DNNs) are vulnerable to adversarial examples. Even under black-box setting that is without access to the target model, transfer-based attacks can easily fool the DNNs. To alleviate this problem, we propose a robust classification model against transfer attacks based on the framework of variational Auto-Encoders (VAEs) which are probabilistic generative models and have been successfully used to a large mount of tasks. Specifically, our model simulates the data generative process with several multivariate Gaussian distributions and DNNs: (1) We assume that the latent embedding generated by an encoder (a DNN) of each category corresponds to a multivariate Gaussian distribution. (2) A decoder (a DNN) is proposed to decodes the latent embedding into an observable. (3) Theoretical analysis illustrates that our model can predict data's labels by maximizing the lower bound on the log-likelihood for each category utilizing Bayes’ theorem with excellent robustness against transfer attacks. Inference in our model is done in a variational way so the Stochastic Gradient Variational Bayes (SGVB) estimator and reparamerization trick can be utilized to optimize the evidence lower bound (ELBO). The experiments with quantitative comparisons show that our approach reaches state-of-the-art with significantly better robustness. © 2020 Elsevier Inc.",Adversarial examples; Robustness; Transfer attacks; VAEs,Decoding; Deep neural networks; Embeddings; Gaussian distribution; Image segmentation; Learning systems; Signal encoding; Stochastic systems; Generative classifiers; Generative process; Multivariate Gaussian Distributions; Quantitative comparison; Robust classification; State of the art; Stochastic gradient; Variational bayes; Stochastic models,,,,,"Athalye, A., Carlini, N., Wagner, D., (2018), Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples. arXiv preprint arXiv:1802.00420; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP), pp. 39-57. , IEEE; Cheng, S., Dong, Y., Pang, T., Su, H., Zhu, J., Improving black-box adversarial attacks with a transfer-based prior (2019) Adv. Neural Inform. Process. Syst., pp. 10932-10942; Cisse, M., Bojanowski, P., Grave, E., Dauphin, Y., Usunier, N., Parseval networks: Improving robustness to adversarial examples (2017), pp. 854-863. , Proceedings of the 34th International Conference on Machine Learning-Volume 70, JMLR. org; Dhillon, G.S., Azizzadenesheli, K., Lipton, Z.C., Bernstein, J., Kossaifi, J., Khanna, A., Anandkumar, A., (2018), Stochastic activation pruning for robust adversarial defense. arXiv preprint arXiv:1803.01442; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2018) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 9185-9193; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017), Detecting adversarial samples from artifacts. arXiv preprint arXiv:1703.00410; Fetaya, E., Jacobsen, J., Grathwohl, W., (2020), R.S., Zemel, Understanding the limitations of conditional generative models, in: International Conference on Learning Representations (ICLR 2020); Goodfellow, I.J., Shlens, J., Szegedy, C., (2014), Explaining and harnessing adversarial examples. arXiv preprint arXiv:1412.6572; He, K., Zhang, X., Ren, S., Sun, J., Delving deep into rectifiers: Surpassing human-level performance on imagenet classification (2015) Proceedings of the IEEE international conference on computer vision, pp. 1026-1034; Jia, X., Wei, X., Cao, X., Foroosh, H., Comdefend: An efficient image compression model to defend adversarial examples (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 6084-6092; Kingma, D.P., Welling, M., (2013), Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114; Kurakin, A., Goodfellow, I., Bengio, S., (2016), Adversarial machine learning at scale. arXiv preprint arXiv:1611.01236; Kurakin, A., Goodfellow, I., Bengio, S., Dong, Y., Liao, F., Liang, M., Pang, T., Xie, C., (2018), pp. 195-231. , C., Adversarial attacks and defences competition, in: The NIPS’17 Competition: Building Intelligent Systems. Springer; Li, X., She, J., Collaborative variational autoencoder for recommender systems (2017) Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining, pp. 305-314. , ACM; Li, Y., Bradshaw, J., Sharma, Y., Are generative classifiers more robust to adversarial attacks? (2019) International Conference on Machine Learning (ICML), pp. 3804-3814; Li, Y., Li, L., Wang, L., Zhang, T., Gong, B., (1905), Nattack: Learning the distributions of adversarial examples for an improved black-box attack on deep neural networks. arXiv preprint arXiv00441, 2019b; Liu, Y., Chen, X., Liu, C., Song, D., (2017), Delving into transferable adversarial examples and black-box attacks. Fifth International Conference on Learning Representations (ICLR 2017); Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., (2017), On detecting adversarial perturbations. arXiv preprint arXiv:1702.04267; Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P., Deepfool: a simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2574-2582; Papernot, N., Mcdaniel, P., Goodfellow, I., Transferability in machine learning: from phenomena to black-box attacks using adversarial samples (2016), Cryptography and Security; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia conference on computer and communications security, pp. 506-519; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) 2016 IEEE European Symposium on Security and Privacy (EuroS&P), pp. 372-387. , IEEE; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) in: 2016 IEEE Symposium on Security and Privacy (SP), pp. 582-597. , IEEE; Razavi, A., van den Oord, A., Vinyals, O., Generating diverse high-fidelity images with vq-vae-2 (2019) Adv. Neural Inform. Process. Syst., pp. 14837-14847; Salimans, T., Karpathy, A., Chen, X., Kingma, D.P., (2017), Pixelcnn++: Improving the pixelcnn with discretized logistic mixture likelihood and other modifications. arXiv preprint arXiv:1701.05517; Schott, L., Rauber, J., Bethge, M., Brendel, W., Towards the first adversarially robust neural network model on mnist (2019), pp. 1-16. , Seventh International Conference on Learning Representations (ICLR 2019); Sitawarin, C., Wagner, D., (2019), Defending against adversarial examples with k-nearest neighbor. arXiv preprint arXiv:1906.09525; Smith, L., Gal, Y., (2018), Understanding measures of uncertainty for adversarial example detection. arXiv preprint arXiv:1803.08533; Song, Y., Kim, T., Nowozin, S., Ermon, S., Kushman, N., (2017), Pixeldefend: Leveraging generative models to understand and defend against adversarial examples. arXiv preprint arXiv:1710.10766; Su, D., Zhang, H., Chen, H., Yi, J., Chen, P.Y., Gao, Y., Is robustness the cost of accuracy?–a comprehensive study on the robustness of 18 deep image classification models (2018) Proceedings of the European Conference on Computer Vision (ECCV), pp. 631-648; Sun, P., Moses, D.A., Chang, E.F., Modeling neural dynamics during speech production using a state space variational autoencoder (2019) 2019 9th International IEEE/EMBS Conference on Neural Engineering (NER), pp. 428-432. , IEEE; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013), Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199; Tan, M., Le, Q.V., (2019), Efficientnet: Rethinking model scaling for convolutional neural networks. arXiv preprint arXiv:1905.11946; Touvron, H., Vedaldi, A., Douze, M., Jégou, H., Fixing the train-test resolution discrepancy (2019) Adv. Neural Inform. Process. Syst., pp. 8250-8260; Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2017), Ensemble adversarial training: Attacks and defenses. arXiv preprint arXiv:1705.07204; Tsipras, D., Santurkar, S., Engstrom, L., Turner, A., Madry, A., (2018), Robustness may be at odds with accuracy. arXiv preprint arXiv:1805.12152; Wang, F., Jiang, M., Qian, C., Yang, S., Li, C., Zhang, H., Wang, X., Tang, X., Residual attention network for image classification (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3156-3164; Wang, W., Gan, Z., Xu, H., Zhang, R., Wang, G., Shen, D., Chen, C., Carin, L., (2019), Topic-guided variational autoencoders for text generation. arXiv preprint arXiv:1903.07137; Wong, E., Rice, L., Kolter, J.Z., Fast is better than free: Revisiting adversarial training (2020), International Conference on Learning Representations (ICLR 2020); Wu, L., Zhu, Z., Tai, C., (2018), Understanding and enhancing the transferability of adversarial examples. arXiv preprint arXiv:1802.09707; Xu, W., Sun, H., Deng, C., Tan, Y., Variational autoencoder for semi-supervised text classification (2017) Thirty-First AAAI Conference on Artificial Intelligence, pp. 3358-3364","Tang, Z.; College of Computer Science and Electronic Engineering, China; 电子邮件: ztang@hnu.edu.cn",,,Elsevier Inc.,,,,,200255,,ISIJB,,English,Inf Sci,Article,Final,,Scopus,2-s2.0-85095602989
"Chan P.P.K., Luo F., Chen Z., Shu Y., Yeung D.S.",7403497727;57198347882;57221855867;56446261700;7103391375;,Transfer learning based countermeasure against label flipping poisoning attack,2021,Information Sciences,548,,,450,460,,2,10.1016/j.ins.2020.10.016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096699940&doi=10.1016%2fj.ins.2020.10.016&partnerID=40&md5=450e53019d0c9680d8084dd84f078718,"The School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; The School of Computer Science and Technology, Zhejiang University, Hangzhou, China; Past President, Systems, Man, and Cybernetics Society, IEEE","Chan, P.P.K., The School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; Luo, F., The School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; Chen, Z., The School of Computer Science and Engineering, South China University of Technology, Guangzhou, China, The School of Computer Science and Technology, Zhejiang University, Hangzhou, China; Shu, Y., The School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; Yeung, D.S., Past President, Systems, Man, and Cybernetics Society, IEEE","Recent studies indicate that a classifier is vulnerable in an adversarial environment. The label flipping attack aims to mislead the training process. Some countermeasures have been proposed, but are usually designed for a particular classifier only, or may cause information loss. This study aims to investigate a generic model which fully utilizes the contaminated samples in learning. We assume a small untainted dataset is obtained from an application in addition to a contaminated dataset. The adversarial learning problem is formulated as transfer learning in which the influence of contaminated samples is reduced by only extracting the information similar to the untainted samples from the contaminated set using transfer learning. Our study considers a popular method, TrAdaBoost, and indicates that its performance is closely related to the initialized weights of samples. A initialization method is devised specifically for an adversarial setting to avoid assigning a large weight to the contaminated samples. The experimental results confirm that TrAdaBoost extracts only the benign knowledge from the contaminated set successfully. Moreover, our proposed initialization method significantly enhances the robustness of the model. This study presents a promising direction using transfer learning to defend against poisoning attacks. © 2020 Elsevier Inc.",Adversarial Learning; Label Flipping Attack; Poisoning Attack; Robustness; Transfer Learning,Classification (of information); Contamination; Adversarial environments; Adversarial learning; Generic modeling; Information loss; Initialization methods; Poisoning attacks; Tradaboost; Training process; Transfer learning,,,,,"Martínez Torres, J., Iglesias Comesaña, C., García-Nieto, P.J., Review: machine learning techniques applied to cybersecurity (2019) Int. J. Mach. Learn. Cybern., 10 (10), pp. 2823-2836; Biggio, B., Akhtar, Z., Fumera, G., Marcialis, G.L., Roli, F., Security evaluation of biometric authentication systems under real spoofing attacks (2012) IET Biometr., 1 (1), pp. 11-24; Chan, P.P., Wang, Y., Yeung, D.S., Adversarial attack against deep reinforcement learning with static reward impact map (2020) Proceedings of the 2020 ACM Asia Conference on Computer and Communications Security; Chan, P.P.K., Liu, W., Chen, D., Yeung, D.S., Zhang, F., Wang, X., Hsu, C., Face liveness detection using a flash against 2d spoofing attack (2018) IEEE Trans. Inf. Forensics Secur., 13 (2), pp. 521-534; Biggio, B., Fumera, G., Roli, F., Security evaluation of pattern classifiers under attack, arXiv: Learning; Chen, K., Chan, P.P.K., Zhang, F., Li, Q., Shilling attack based on item popularity and rated item correlation against collaborative filtering (2019) Int. J. Mach. Learn. Cybern., 10 (7), pp. 1833-1845; Barreno, M., Nelson, B., Joseph, A.D., Tygar, J.D., The security of machine learning (2010) Mach. Learn., 81 (2), pp. 121-148; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Biggio, B., Nelson, B., Laskov, P., Poisoning attacks against support vector machines (2012) Proceedings of International Conference on Machine Learning ICML’12, pp. 1467-1474; Nelson, B., Barreno, M., Jack, F., Anthony, C., Joseph, D., Rubinstein, B.I.P., Saini, U., Xia, K., Exploiting machine learning to subvert your spam filter (2008) Proceedings of the First USENIX Workshop on LargeScale Exploits and Emergent Threats; Xiao, H., Biggio, B., Nelson, B., Xiao, H., Eckert, C., Roli, F., Support vector machines under adversarial label contamination (2015) Neurocomputing, 160, pp. 53-62; Buhrmester, M.D., Kwang, T., Gosling, S.D., Amazon's mechanical turk: a new source of inexpensive, yet high-quality, data? (2011) Perspect. Psychol. Sci., 6 (1), pp. 3-5; Adomavicius, G., Tuzhilin, A., Toward the next generation of recommender systems: a survey of the state-of-the-art and possible extensions (2005) IEEE Trans. Knowl. Data Eng., 17 (6), pp. 734-749; Huang, R., Xu, B., Schuurmans, D., Szepesv??ri, C., Learning with a strong adversary, CoRR; Biggio, B., Fumera, G., Roli, F., Multiple classifier systems for robust classifier design in adversarial environments (2010) Int. J. Mach. Learn. Cybern., 1 (1), pp. 27-41; Demontis, A., Biggio, B., Fumera, G., Giacinto, G., Roli, F., Infinity-norm support vector machines against adversarial label contamination (2017) ITASEC, pp. 106-115; Chan, P.P.K., He, Z., Li, H., Hsu, C., Data sanitization against adversarial label contamination based on data complexity (2018) Int. J. Mach. Learn. Cybern., 9 (6), pp. 1039-1052; Barreno, M., Nelson, B., Sears, R., Joseph, A.D., Tygar, J.D., (2006), pp. 16-25. , Can machine learning be secure; Chan, P.P.K., He, Z., Hu, X., Tsang, E.C.C., Yeung, D.S., Ng, W.W.Y., https://link.springer.com/article/10.1007/s13042-020-01159-7, Causative label flip attack detection with data complexity measures, Int. J. Mach. Learn. Cybern; Pan, S.J., Yang, Q., A survey on transfer learning (2010) IEEE Trans. Knowl. Data Eng., 22 (10), pp. 1345-1359; Dai, W., Yang, Q., Xue, G., Yu, Y., (2007), pp. 193-200. , Boosting for transfer learning 227; Talo, M., Baloglu, U.B., (2019), pp. 176-188. , zal Yildirim, U. Rajendra Acharya, Application of deep transfer learning for automated brain abnormality classification using mr images, Cogn. Syst. Res. 54; Jiang, S., Mao, H., Ding, Z., Fu, Y., Deep decision tree transfer boosting (2020) IEEE Trans. Neural Networks Learn. Syst., 31 (2), pp. 383-395; Zhang, X., Zhuang, Y., Wang, W., Pedrycz, W., Transfer boosting with synthetic instances for class imbalanced object recognition (2018) IEEE Trans. Cybern., 48 (1), pp. 357-370; Freund, Y., Schapire, R.E., (1996), pp. 148-156. , Experiments with a new boosting algorithm; Chen, L., Zhou, S., Sparse algorithm for robust lssvm in primal space (2018) Neurocomputing, 275, pp. 2880-2891; Xiao, H., Xiao, H., Eckert, C., (2012), pp. 870-875. , Adversarial label flips attack on support vector machines; Biggio, B., Nelson, B., Laskov, P., (2011), pp. 97-112. , Support vector machines under adversarial label noise 20; Paudice, A., Munozgonzalez, L., Lupu, E., Label sanitization against label flipping poisoning attacks, arXiv: Machine Learning; Chan, P., Yeung, D., Ng, W., Lin, C.-M., Liu, J., Dynamic fusion method using localized generalization error model (2012) Inf. Sci., 217, pp. 1-20; Fan, C., Zeng, L., Feng, Y., Cheng, G., Huang, J., Liu, Z., A novel learning-based approach for efficient dismantling of networks (2020) Int. J. Mach. Learn. Cybern., 11 (9), pp. 2101-2111; Wang, X., Xing, H., Li, Y., Hua, Q., Dong, C., Pedrycz, W., A study on relationship between generalization abilities and fuzziness of base classifiers in ensemble learning (2015) IEEE Trans. Fuzzy Syst., 23 (5), pp. 1638-1654; Wang, X., Wang, R., Xu, C., Discovering the relationship between generalization and uncertainty by incorporating complexity of classification (2018) IEEE Trans. Cybern., 48 (2), pp. 703-715; Valyon, J., Horvath, G., A robust ls-svm regression (2007) World Acad. Sci., Eng. Technol. Int. J. Comput. Electr. Autom. Control Inf., 1 (7), pp. 2237-2242; You, L., Jizhen, L., Yaxin, Q., A new robust least squares support vector machine for regression with outliers (2011) Procedia Eng., 15, pp. 1355-1360; Carlini, N., Athalye, A., Papernot, N., Brendel, W., Rauber, J., Tsipras, D., Goodfellow, I., Kurakin, A., On evaluating adversarial robustness, arXiv: Learning; Akhtar, N., Mian, A., Threat of adversarial attacks on deep learning in computer vision: a survey (2018) IEEE Access, 6, pp. 14410-14430; Yu, C., Wang, J., Chen, Y., Qin, X., Transfer channel pruning for compressing deep domain adaptation models (2019) Int. J. Mach. Learn. Cybern., 10 (11), pp. 3129-3144; Wen, Y., Qin, Y., Qin, K., Lu, X., Liu, P., Online transfer learning with multiple decision trees (2019) Int. J. Mach. Learn. Cybern., 10 (10), pp. 2941-2962; Dua, D., Graff, C., (2017), http://archive.ics.uci.edu/ml, UCI machine learning repository. URL:; https://spamassassin.apache.org/index.html, Apache spamassassin. URL:; Abdelhamid, N., Ayesh, A., Thabtah, F., Phishing detection based associative classification data mining (2014) Expert Syst. Appl., 41 (13), pp. 5948-5959","Chan, P.P.K.; The School of Computer Science and Engineering, China",,,Elsevier Inc.,,,,,200255,,ISIJB,,English,Inf Sci,Article,Final,,Scopus,2-s2.0-85096699940
"Luo Z., Li Q., Zheng J.",57222244914;57281758900;57192111276;,A study of adversarial attacks and detection on deep learning-based plant disease identification,2021,Applied Sciences (Switzerland),11,4,1878,1,16,,1,10.3390/app11041878,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101963229&doi=10.3390%2fapp11041878&partnerID=40&md5=6c089a2a78d97cdb5f6f8be84601043a,"Department of Computer Science and Engineering, New Mexico Institute of Mining and Technology, Socorro, NM  87801, United States","Luo, Z., Department of Computer Science and Engineering, New Mexico Institute of Mining and Technology, Socorro, NM  87801, United States; Li, Q., Department of Computer Science and Engineering, New Mexico Institute of Mining and Technology, Socorro, NM  87801, United States; Zheng, J., Department of Computer Science and Engineering, New Mexico Institute of Mining and Technology, Socorro, NM  87801, United States","Transfer learning using pre-trained deep neural networks (DNNs) has been widely used for plant disease identification recently. However, pre-trained DNNs are susceptible to adversarial attacks which generate adversarial samples causing DNN models to make wrong predictions. Successful adversarial attacks on deep learning (DL)-based plant disease identification systems could result in a significant delay of treatments and huge economic losses. This paper is the first attempt to study adversarial attacks and detection on DL-based plant disease identification. Our results show that adversarial attacks with a small number of perturbations can dramatically degrade the performance of DNN models for plant disease identification. We also find that adversarial attacks can be effectively defended by using adversarial sample detection with an appropriate choice of features. Our work will serve as a basis for developing more robust DNN models for plant disease identification and guiding the defense against adversarial attacks. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",Adversarial attacks; Adversarial sample detection; Deep learning; Plant disease identification; White-box attacks,,,,,,"Savary, S., Willocquet, L., Pethybridge, S.J., Esker, P., McRoberts, N., Nelson, A., The global burden of pathogens and pests on major food crops (2019) Nat. Ecol. Evol, 3, pp. 430-439; Martinelli, F., Scalenghe, R., Davino, S., Panno, S., Scuderi, G., Ruisi, P., Villa, P., Dandekar, A.M., Advanced methods of plant disease detection. A review (2015) Agron. Sustain. Dev, 35, pp. 1-25; Chen, J., Chen, J., Zhang, D., Sun, Y., Nanehkaran, Y.A., Using deep transfer learning for image-based plant disease identification (2020) Comput. Electron. Agric, 173, p. 105393; Waheed, A., Goyal, M., Gupta, D., Khanna, A., Hassanien, A.E., Pandey, H.M., An optimized dense convolutional neural network model for disease recognition and classification in corn leaf (2020) Comput. Electron. Agric, 175, p. 105456; Ferentinos, K.P., Deep learning models for plant disease detection and diagnosis (2018) Comput. Electron. Agric, 145, pp. 311-318; Wolfert, S., Ge, L., Verdouw, C., Bogaardt, M.J., Big Data in Smart Farming—A review (2017) Agric. Syst, 153, pp. 69-80; Kaur, S., Pandey, S., Goel, S., Plants Disease Identification and Classification Through Leaf Images: A Survey (2019) Arch. Comput. Methods Eng, 26, pp. 507-530; Hossain, E., Hossain, M.F., Rahaman, M.A., A Color and Texture Based Approach for the Detection and Classification of Plant Leaf Disease Using KNN Classifier Proceedings of the 2019 International Conference on Electrical, Computer and Communication Engineering (ECCE), pp. 1-6. , Cox’s Bazar, Bangladesh, 7–9 February 2019; Golhani, K., Balasundram, S.K., Vadamalai, G., Pradhan, B., A review of neural networks in plant disease detection using hyperspectral data (2018) Inf. Process. Agric, 5, pp. 354-371; Padol, P.B., Yadav, A.A., SVM classifier based grape leaf disease detection Proceedings of the 2016 Conference on Advances in Signal Processing (CASP), pp. 175-179. , Pune, India, 9–11 June 2016; Sandika, B., Avil, S., Sanat, S., Srinivasu, P., Random forest based classification of diseases in grapes from images captured in uncontrolled environments Proceedings of the 2016 IEEE 13th International Conference on Signal Processing (ICSP), pp. 1775-1780. , Chengdu, China, 6–10 November 2016; Kamilaris, A., Prenafeta-Boldú, F.X., Deep learning in agriculture: A survey (2018) Comput. Electron. Agric, 147, pp. 70-90; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521, pp. 436-444; Le, N.Q.K., Fertility-GRU: Identifying Fertility-Related Proteins by Incorporating Deep-Gated Recurrent Units and Original Position-Specific Scoring Matrix Profiles (2019) J. Proteome Res, 18, pp. 3503-3511; Le, N.Q.K., Do, D.T., Hung, T.N.K., Lam, L.H.T., Huynh, T.T., Nguyen, N.T.K., A Computational Framework Based on Ensemble Deep Neural Networks for Essential Genes Identification (2020) Int. J. Mol. Sci, 21, p. 9070; Tan, C., Sun, F., Kong, T., Zhang, W., Yang, C., Liu, C., (2018) A Survey on Deep Transfer Learning BT—Artificial Neural Networks and Machine Learning—ICANN 2018, pp. 270-279. , Springer International Publishing: Cham, Switzerland; Too, E.C., Yujian, L., Njuki, S., Yingchun, L., A comparative study of fine-tuning deep learning models for plant disease identification (2019) Comput. Electron. Agric, 161, pp. 272-279; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) Proceedings of the 3rd International Conference on Learning Representations, ICLR 2015—Conference Track Proceedings, , San Diego, CA, USA, 7–9 May; He, K., Zhang, X., Ren, S., Sun, J., Deep Residual Learning for Image Recognition Proceedings of the 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 770-778. , Las Vegas, NV, USA, 27–30 June 2016; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions Proceedings of the 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1-9. , Boston, MA, USA, 7–12 June 2015; Huang, G., Liu, Z., Maaten, L.V.D., Weinberger, K.Q., Densely Connected Convolutional Networks Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2261-2269. , Honolulu, HI, USA, 22–25 July 2017; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) Proceedings of the 2nd International Conference on Learning Representations, ICLR 2014, , Banff, AB, Canada, 14–16 April; Ren, K., Zheng, T., Qin, Z., Liu, X., Adversarial Attacks and Defenses in Deep Learning (2020) Engineering, 6, pp. 346-360; Rezaei, S., Liu, X., A Target-Agnostic Attack on Deep Models: Exploiting Security Vulnerabilities of Transfer Learning Proceedings of the 8th International Conference on Learning Representations, ICLR 2020, Virtual Conference, , Addis Ababa, Ethiopia, 26–30 April 2020; Cruz, A.C., Luvisi, A., De Bellis, L., Ampatzidis, Y., X-FIDO: An Effective Application for Detecting Olive Quick Decline Syndrome with Deep Learning and Data Fusion (2017) Front. Plant Sci, 8, p. 1741; Ngugi, L.C., Abelwahab, M., Abo-Zahhad, M., Tomato leaf segmentation algorithms for mobile phone applications using deep learning (2020) Comput. Electron. Agric, 178, p. 105788; Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L., ImageNet: A Large-Scale Hierarchical Image Database (2009) Proceedings of the 2009 IEEE Conference on Computer Vision and Pattern Recognition, , Miami, FL, USA, 20–25 June; Guo, Y., Shi, H., Kumar, A., Grauman, K., Rosing, T., Feris, R., SpotTune: Transfer Learning Through Adaptive Fine-Tuning (2019) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), , Long Beach, CA, USA, 16–20 June; Fuentes, A., Yoon, S., Kim, S.C., Park, D.S., A Robust Deep-Learning-Based Detector for Real-Time Tomato Plant Diseases and Pests Recognition (2017) Sensors, 17, p. 2022; Jiang, P., Chen, Y., Liu, B., He, D., Liang, C., Real-Time Detection of Apple Leaf Diseases Using Deep Learning Approach Based on Improved Convolutional Neural Networks (2019) IEEE Access, 7, pp. 59069-59080; Darwish, A., Ezzat, D., Hassanien, A.E., An optimized model based on convolutional neural networks and orthogonal learning particle swarm optimization algorithm for plant diseases diagnosis (2020) Swarm Evol. Comput, 52, p. 100616; Hernández, S., López, J.L., Uncertainty quantification for plant disease detection using Bayesian deep learning (2020) Appl. Soft Comput, 96, p. 106597; Maeda-Gutiérrez, V., Galván-Tejada, C.E., Zanella-Calzada, L.A., Celaya-Padilla, J.M., Galván-Tejada, J.I., Gamboa-Rosales, H., Luna-García, H., Olvera-Olvera, C.A., Comparison of Convolutional Neural Network Architectures for Classification of Tomato Plant Diseases (2020) Appl. Sci, 10, p. 1245; Ramcharan, A., Baranowski, K., McCloskey, P., Ahmed, B., Legg, J., Hughes, D.P., Deep Learning for Image-Based Cassava Disease Detection (2017) Front. Plant Sci, 8, p. 1852; Zhong, Y., Zhao, M., Research on deep learning in apple leaf disease recognition (2020) Comput. Electron. Agric, 168, p. 105146; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the Inception Architecture for Computer Vision Proceedings of 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2818-2826. , Las Vegas, NV, USA, 27–30 June 2016; Ioffe, S., Szegedy, C., Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift Proceedings of the 32nd International Conference on Machine Learning (PMLR 37), pp. 448-456. , Lille, France, 6–11 July 2015; Carlini, N., Wagner, D., Towards Evaluating the Robustness of Neural Networks Proceedings of the 2017 IEEE Symposium on Security and Privacy (SP), pp. 39-57. , San Jose, CA, USA, 22–26 May 2017; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards Deep Learning Models Resistant to Adversarial Attacks (2018) Proceedings of the 6th International Conference on Learning Representations, ICLR 2018, , Vancouver, BC, Canada, 30 April–3 May; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) Proceedings of the 3rd International Conference on Learning Representations, ICLR 2015, , San Diego, CA, USA, 7–9 May; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial Examples in the Physical World Proceedings of the 5th International Conference on Learning Representations, ICLR 2017, , Toulon, France, 24–26 April 2017; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a Defense to Adversarial Perturbations Against Deep Neural Networks Proceedings of the 2016 IEEE Symposium on Security and Privacy, SP 2016, pp. 582-597. , San Jose, CA, USA, 22–26 May 2016; Dziugaite, G.K., Ghahramani, Z., Roy, D.M., A Study of the Effect of JPG Compression on Adversarial Images (2016) Proceedings of the International Society for Bayesian Analysis (ISBA 2016) World Meeting, , Sardinia, Italy, 13–17 June; Ross, A.S., Doshi-Velez, F., Improving the Adversarial Robustness and Interpretability of Deep Neural Networks by Regularizing their Input Gradients Proceedings of the 32nd AAAI Conference on Artificial Intelligence, AAAI 2018, pp. 1660-1669. , New Orleans, LA, USA, 2–7 February 2018; Athalye, A., Carlini, N., Wagner, D., Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples Proceedings of the 35th International Conference on Machine Learning, ICML 2018, pp. 436-448. , Vienna, Austria, 25–31 July 2018; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts, , arXiv arXiv:1703.00410; Lu, J., Issaranon, T., Forsyth, D., SafetyNet: Detecting and Rejecting Adversarial Examples Robustly Proceedings of the IEEE International Conference on Computer Vision, pp. 446-454. , Venice, Italy, 22–29 October 2017; Ma, X., Li, B., Wang, Y., Erfani, S.M., Wijewickrema, S., Schoenebeck, G., Song, D., Bailey, J., Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality (2018) Proceedings of the 6th International Conference on Learning Representations, ICLR 2018, , Vancouver, BC, Canada, 30 April–3 May; Mohanty, S.P., Hughes, D.P., Salathé, M., Using deep learning for image-based plant disease detection (2016) Front. Plant Sci, 7, p. 1419","Zheng, J.; Department of Computer Science and Engineering, United States; 电子邮件: jun.zheng@nmt.edu",,,MDPI AG,,,,,20763417,,,,English,Appl. Sci.,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85101963229
"Li Y., Su H., Zhu J.",57219568796;37017428500;56734692500;,AdvCapsNet: To defense adversarial attacks based on Capsule networks,2021,Journal of Visual Communication and Image Representation,75,,103037,,,,,10.1016/j.jvcir.2021.103037,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100425847&doi=10.1016%2fj.jvcir.2021.103037&partnerID=40&md5=65c52f56be246bcf39e0799ad686ef41,"Department of Computer Science and Technology, Tsinghua University, Beijing, 100084, China; Institute for AI, THBI Lab, Tsinghua University, Beijing, 100084, China","Li, Y., Department of Computer Science and Technology, Tsinghua University, Beijing, 100084, China; Su, H., Institute for AI, THBI Lab, Tsinghua University, Beijing, 100084, China; Zhu, J., Institute for AI, THBI Lab, Tsinghua University, Beijing, 100084, China","Convolutional neural networks have achieved the state-of-the-art results across numerous applications, but recent work finds that these models can be easily fooled by adversarial perturbations. This is partially due to gradient calculation instability, which may be amplified throughout network layers (Liao et al., 2018). To address this issue, we propose a novel AdvCapsNet derived from Capsule (Sabour et al., 2017), which utilizes a significantly more complicated non-linearity, to defend against adversarial attacks. In this paper, we focus on the transfer-based black-box adversarial attacks, which are more practical than their white-box counterparts. Specifically, we investigate vanilla Capsule's robustness and boost its performance by introducing an adversarial loss function as regularization. The weight updating between capsule layers is implemented via dynamic routing regularized by the additional adversarial term. Extensive experiments demonstrate that the proposed AdvCapsNet can significantly boost Capsule's robustness and that AdvCapsNet is far more resistance to adversarial attacks than alternative baselines, including both CNN- and Capsule-based defense models. © 2021",Adversarial; Capsule; Defense; Robustness,Convolutional neural networks; Network security; Black boxes; Dynamic routing; Gradient calculations; Loss functions; State of the art; White box; Network layers,,,,,"He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016), pp. 770-778. , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Tan, M., Le, Q.V., Efficientnet: Rethinking model scaling for convolutional neural networks (2019), arXiv preprint; Schroff, F., Kalenichenko, D., Philbin, J., Facenet: A unified embedding for face recognition and clustering (2015), pp. 815-823. , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Taigman, Y., Yang, M., Ranzato, M., Wolf, L., Deepface: Closing the gap to human-level performance in face verification (2014), pp. 1701-1708. , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Chen, L.-C., Zhu, Y., Papandreou, G., Schroff, F., Adam, H., Encoder-decoder with atrous separable convolution for semantic image segmentation (2018), pp. 801-818. , Proceedings of the European Conference on Computer Vision (ECCV); Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J., Pyramid scene parsing network (2017), pp. 2881-2890. , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Milletari, F., Navab, N., Ahmadi, S.-A., V-net: Fully convolutional neural networks for volumetric medical image segmentation (2016) 2016 Fourth International Conference on 3D Vision (3DV), pp. 565-571. , IEEE; Bojarski, M., Del Testa, D., Dworakowski, D., Firner, B., Flepp, B., Goyal, P., Jackel, L.D., Zhang, J., End to end learning for self-driving cars (2016), arXiv preprint; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2013), arXiv preprint; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2014), arXiv preprint; Hinton, G.E., Sabour, S., Frosst, N., Matrix capsules with EM routing (2018) ICLR; Sabour, S., Frosst, N., Hinton, G.E., Dynamic routing between capsules (2017) Advances in Neural Information Processing Systems, pp. 3856-3866; Kurakin, A., Boneh, D., Tramèr, F., Goodfellow, I., Papernot, N., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2018); Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2018), pp. 9185-9193. , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2017), arXiv preprint; Liao, F., Liang, M., Dong, Y., Pang, T., Hu, X., Zhu, J., Defense against adversarial attacks using high-level representation guided denoiser (2018), pp. 1778-1787. , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Kannan, H., Kurakin, A., Goodfellow, I., Adversarial logit pairing (2018), arXiv preprint; Du, Y., Zhao, X., He, M., Guo, W., A novel capsule based hybrid neural network for sentiment classification (2019) IEEE Access, 7, pp. 39321-39328; LaLonde, R., Bagci, U., Capsules for object segmentation (2018), arXiv preprint; Duarte, K., Rawat, Y., Shah, M., Videocapsulenet: A simplified network for action detection (2018) Advances in Neural Information Processing Systems, pp. 7610-7619; Wang, D., Liu, Q., An optimization view on dynamic routing between capsules (2018); Zhang, S., Zhou, Q., Wu, X., Fast dynamic routing based on weighted kernel density estimation (2018) International Symposium on Artificial Intelligence and Robotics, pp. 301-309. , Springer; Kosiorek, A.R., Sabour, S., Teh, Y.W., Hinton, G.E., Stacked capsule autoencoders (2019), arXiv preprint; Frosst, N., Sabour, S., Hinton, G., DARCCC: Detecting adversaries by reconstruction from class conditional capsules (2018), arXiv preprint; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) 2016 IEEE Symposium on Security and Privacy (SP), pp. 582-597. , IEEE; Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2017), arXiv preprint; Zhang, Y., Liang, P., Defending against whitebox adversarial attacks via randomized discretization (2019), arXiv preprint; Li, P., Yi, J., Zhou, B., Zhang, L., Improving the robustness of deep neural networks via adversarial training with triplet loss (2019), arXiv preprint; Liu, X., Cheng, M., Zhang, H., Hsieh, C.-J., Towards robust neural networks via random self-ensemble (2018), pp. 369-385. , Proceedings of the European Conference on Computer Vision (ECCV); Pang, T., Xu, K., Du, C., Chen, N., Zhu, J., Improving adversarial robustness via promoting ensemble diversity (2019), arXiv preprint; Li, X., Ji, S., Defense-VAE: A fast and accurate defense against adversarial attacks (2018), arXiv preprint; Krizhevsky, A., Nair, V., Hinton, G., The CIFAR-10 dataset (2014), http://www.cs.toronto.edu/kriz/cifar.html, online: 55; Howard, J., Imagenette (2019), https://github.com/fastai/imagenette/; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., Imagenet: A large-scale hierarchical image database (2009) 2009 IEEE Conference on Computer Vision and Pattern Recognition, pp. 248-255. , IEEE; LeCun, Y., Cortes, C., Burges, C., MNIST Handwritten digit database (2010), http://yann.lecun.com/exdb/mnist, ATT Labs [Online]. Available: 2; Xiao, H., Rasul, K., Vollgraf, R., Fashion-MNIST: a novel image dataset for benchmarking machine learning algorithms (2017), CoRR abs/1708.07747; LeCun, Y., Huang, F.J., Bottou, L., Learning methods for generic object recognition with invariance to pose and lighting (2004), 2. , Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition II–104 Vol.2; Su, D., Zhang, H., Chen, H., Yi, J., Chen, P.-Y., Gao, Y., Is robustness the cost of accuracy?–A comprehensive study on the robustness of 18 deep image classification models (2018), pp. 631-648. , Proceedings of the European Conference on Computer Vision (ECCV); Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2014), arXiv preprint; Huang, G., Liu, Z., (2017), pp. 4700-4708. , L. Van Der Maaten, K.Q. Weinberger, Densely connected convolutional networks, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition","Li, Y.; Department of Computer Science and Technology, China; 电子邮件: li-yq17@mails.tsinghua.edu.cn",,,Academic Press Inc.,,,,,10473203,,JVCRE,,English,J Visual Commun Image Represent,Article,Final,,Scopus,2-s2.0-85100425847
"Sagduyu Y.E., Shi Y., Erpek T.",6507416617;36141159700;36100030900;,Adversarial Deep Learning for Over-the-Air Spectrum Poisoning Attacks,2021,IEEE Transactions on Mobile Computing,20,2,8887196,306,319,,9,10.1109/TMC.2019.2950398,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099592230&doi=10.1109%2fTMC.2019.2950398&partnerID=40&md5=3df70db6321b938d392fc73138641006,"Intelligent Automation Inc., Rockville, MD  20855, United States; Department of Electrical and Computer Engineering, Virginia Tech, Arlington, VA  22203, United States","Sagduyu, Y.E., Intelligent Automation Inc., Rockville, MD  20855, United States; Shi, Y., Department of Electrical and Computer Engineering, Virginia Tech, Arlington, VA  22203, United States; Erpek, T., Department of Electrical and Computer Engineering, Virginia Tech, Arlington, VA  22203, United States","An adversarial deep learning approach is presented to launch over-the-air spectrum poisoning attacks. A transmitter applies deep learning on its spectrum sensing results to predict idle time slots for data transmission. In the meantime, an adversary learns the transmitter's behavior (exploratory attack) by building another deep neural network to predict when transmissions will succeed. The adversary falsifies (poisons) the transmitter's spectrum sensing data over the air by transmitting during the short spectrum sensing period of the transmitter. Depending on whether the transmitter uses the sensing results as test data to make transmit decisions or as training data to retrain its deep neural network, either it is fooled into making incorrect decisions (evasion attack) or the transmitter's algorithm is retrained incorrectly for future decisions (causative attack). Both attacks are energy efficient and hard to detect (stealth) compared to jamming the long data transmission period, and substantially reduce the throughput. A dynamic defense is designed for the transmitter that deliberately makes a small number of incorrect transmissions (selected by the confidence score on channel classification) to manipulate the adversary's training data. This defense effectively fools the adversary (if any) and helps the transmitter sustain its throughput with or without an adversary present. © 2002-2012 IEEE.",adversarial attacks; Adversarial machine learning; causative attack; deep learning; defense; evasion attack; exploratory attack; jamming; spectrum poisoning,Classification (of information); Data transfer; Deep neural networks; Energy efficiency; Network security; Neural networks; Transmitters; Channel classification; Confidence score; Energy efficient; Learning approach; Over the airs; Poisoning attacks; Spectrum sensing; Training data; Deep learning,,,,,"Clancy, C., Stuntebeck, H.J., O'Shea, T., Applications of machine learning to cognitive radio networks (2007) Ieee Wireless Commun., 14 (4), pp. 47-52. , Aug; Chen, M., Challita, U., Saad, W., Yin, C., Debbah, M., Artificial neural networks-based machine learning for wireless networks: A tutorial (2019) Ieee Commun. Surv. Tut, , July; Simeone, O., A very short introduction to machine learning with applications to communication systems (2018) Ieee Trans. Cogn. Commun. Netw., 4 (4), pp. 648-664. , Dec; Lee, W., Kim, M., Cho, D., (2017) Deep Sensing: Cooperative Spectrum Sensing Based on Convolutional Neural Networks; Ye, H., Li, G.Y., Juang, B.-H., Power of deep learning for channel estimation and signal detection in OFDM systems (2018) Ieee Wireless Commun. Lett., 7 (1), pp. 114-117. , Feb; Shi, Y., Sagduyu, Y.E., Erpek, T., Davaslioglu, K., Lu, Z., Li, J., Adversarial deep learning for cognitive radio security: Jamming attack and defense strategies (2018) Proc. Ieee Int. Conf. Commun. Workshop Promises Challenges Mach. Learn. Commun. Netw., pp. 1-6; Erpek, T., Sagduyu, Y.E., Shi, Y., Deep learning for launching and mitigating wireless jamming attacks (2019) Ieee Trans. Cogn. Commun. Netw., 5 (1), pp. 2-14. , Mar; O'Shea, T., Corgan, J., Clancy, C., Convolutional radio modulation recognition networks (2016) Proc. Int. Conf. Eng. Appl. Neural Netw., pp. 213-226; Davaslioglu, K., Sagduyu, Y.E., Generative adversarial learning for spectrum sensing (2018) Proc. Ieee Int. Conf. Commun., pp. 1-6; Xu, W., Trappe, W., Zhang, Y., Wood, T., The feasibility of launching and detecting jamming attacks in wireless networks (2005) Proc. Acm Int. Symp. Mobile Ad Hoc Netw. Comput., pp. 46-57; Zou, Y., Zhu, J., Yang, L., Liang, Y.-C., Yao, Y.-D., Securing physical-layer communications for cognitive radio networks (2015) Ieee Commun. Mag., 53 (9), pp. 48-54. , Sep; Clancy, T.C., Goergen, N., Security in cognitive radio networks: Threats and mitigation (2008) Proc. Ieee Conf. Cogn. Radio Oriented Wireless Netw. Commun., pp. 1-8; Yuan, Z., Niyato, D., Li, H., Song, J.B., Han, Z., Defeating primary user emulation attacks using belief propagation in cognitive radio networks (2012) Ieee J. Sel. Areas Commun., 30 (10), pp. 1850-1860. , Nov; Chen, R., Park, J., Bian, K., Robust distributed spectrum sensing in cognitive radio networks (2008) Proc. Ieee Conf. Comput. Commun., pp. 1876-1884; Fredrikson, M., Jha, S., Ristenpart, T., Model inversion attacks that exploit confidence information and basic countermeasures (2015) Proc. Acm Sigsac Conf. Comput. Commun. Security, pp. 1322-1333; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2017) Proc. Int. Conf. Learn. Representations, , Apr; Biggio, B., Evasion attacks against machine learning at test time (2013) Proc. Eur. Conf. Mach. Learn. Princ. Pract. Knowl. Discovery Databases, pp. 387-402; Biggio, B., Nelson, B., Laskov, P., Poisoning attacks against support vector machines (2012) Proc. Int. Conf. Mach. Learn., pp. 1467-1474; Sagduyu, Y.E., Ephremides, A., A game-theoretic analysis of denial of service attacks in wireless random access (2009) J. Wireless Netw., 15, pp. 651-666; Kurakin, A., Adversarial attacks and defences competition (2018) The Nips '17 Competition: Building Intell. Syst. The Springer Ser. Challenges Mach. Learn, , S. Escalera and M. Weimer, Eds., Springer, Cham; Ateniese, G., Mancini, L., Spognardi, A., Villani, A., Vitali, D., Felici, G., Hacking smart machines with smarter ones: How to extract meaningful data from machine learning classifiers (2015) Int. J. Security Netw., 10, pp. 137-150; Tramer, F., Zhang, F., Juels, A., Reiter, M., Ristenpart, T., Stealing machine learning models via prediction APIs (2016) Proc. 25th Usenix Conf. Security Symp., pp. 601-618; Shi, Y., Sagduyu, Y.E., Davaslioglu, K., Li, J., Active deep learning attacks under strict rate limitations for online API calls (2018) Proc. Ieee Symp. Technologies Homeland Security, pp. 1-6; Sadeghi, M., Larsson, E.G., Adversarial attacks on deep-learning based radio signal classification (2019) Ieee Wireless Commun. Lett., 8 (1), pp. 213-216. , Feb; Flowers, B., Buehrer, R.M., Headley, W.C., Evaluating adversarial evasion attacks in the context of wireless communications (2019) Ieee Trans. Inf. Forensics Secur., Early Access, , Aug. 8; Hameed, M.Z., Gyorgy, A., Gunduz, D., (2019) Communication without Interception: Defense against Deep-learning-based Modulation Detection; Kokalj-Filipovic, S., Miller, R., (2019) Adversarial Examples in Rf Deep Learning: Detection of the Attack and Its Physical Robustness; Weerasinghe, S., Alpcan, T., Erfani, S.M., Leckie, C., Pourbeik, P., Riddle, J., Deep learning based game-theoretical approach to evade jamming attacks (2018) Proc. Int. Conf. Decis. Game Theory Security, pp. 386-397; Shi, Y., Erpek, T., Sagduyu, Y.E., Li, J.H., Spectrum data poisoning with adversarial deep learning (2018) Proc. Ieee Military Commun. Conf., pp. 407-412; Zou, Y., Zhu, J., Yang, L., Liang, Y., Yao, Y., Securing physical-layer communications for cognitive radio networks (2015) Ieee Commun. Mag., 53 (9), pp. 48-54. , Sep; Penna, F., Sun, Y., Dolecek, L., Cabric, D., Detecting and counteracting statistical attacks in cooperative spectrum sensing (2012) Ieee Trans. Signal Process., 60 (4), pp. 1806-1822. , Apr; Yut, F.R., Tang, H., Huang, M., Lit, Z., Mason, P.C., Defense against spectrum sensing data falsification attacks in mobile ad hoc networks with cognitive radios (2009) Proc. Ieee Military Commun. Conf., pp. 1-7; Sagduyu, Y.E., Berry, R., Ephremides, A., Jamming games in wireless networks with incomplete information (2011) Ieee Commun. Mag., 49 (8), pp. 112-118. , Aug; Sagduyu, Y.E., Berry, R., Ephremides, A., MAC games for distributed wireless network security with incomplete information of selfish and malicious user types (2009) Proc. Ieee Int. Conf. Game Theory Netw., pp. 130-139; Lu, Z., Sagduyu, Y.E., Li, J., Securing the backpressure algorithm for wireless networks (2017) Ieee Trans. Mobile Comput., 16 (4), pp. 1136-1148. , Apr; Lu, Z., Wang, C., Enabling network anti-inference via proactive strategies: A fundamental perspective (2017) IEEE/ACM Trans. Netw., 25 (1), pp. 43-55. , Feb; Ferdowsi, A., Saad, W., Deep learning for signal authentication and security in massive Internet of Things systems (2019) Ieee Trans. Commun., 67 (2), pp. 1371-1387. , Feb; Han, G., Xiao, L., Poor, H.V., Two-dimensional anti-jamming communication based on deep reinforcement learning (2017) Proc. Ieee Int. Conf. Acoust. Speech Signal Process., pp. 2087-2091; Wu Y Zhao, Z., Yin, Z., Luo, H., Jamming signals classification using convolutional neural network (2017) Proc. Ieee Int. Symp. Signal Process. Inf. Technol., pp. 062-067; Topal, O.A., Gecgel, S., Eksioglu, E.M., Karabulut Kurt, G., (2019) Identification of Smart Jammers: Learning Based Approaches Using Wavelet Representation; Xiao, L., Jiang, D., Xu, D., Zhu, H., Zhang, Y., Poor, V., Two-dimensional anti-jamming mobile communication based on reinforcement learning (2018) Ieee Trans. Veh. Technol., 67 (10), pp. 9499-9512. , Oct; Xiao, L., Xie, C., Min, M., Zhuang, W., User-centric view of unmanned aerial vehicle transmission against smart attacks (2018) Ieee Trans. Veh. Technol., 67 (4), pp. 3420-3430. , Apr; Liang, Y., Cai, Z., Yu, J., Han, Q., Li, Y., Deep learning based inference of private information using embedded sensors in smart devices (2018) Ieee Netw., 32 (4), pp. 8-14. , Jul./Aug; Bergstra, J., Bengio, Y., Random search for hyper-parameter optimization (2012) J. Mach. Learn. Res., 13, pp. 281-305; Abadi, M., (2015) TensorFlow: Large-scale Machine Learning on Heterogeneous Systems, , Software available from tensorflow.org; Xiao, L., Jiang, D., Xu, D., Su, W., An, N., Wang, D., Secure mobile crowdsensing based on deep learning (2018) China Commun., 15 (10), pp. 1-11; Xiao, L., Wan, X., Su, W., Tang, Y., Anti-jamming underwater transmission with mobility and learning (2018) Ieee Commun. Lett., 22 (3), pp. 542-545. , Mar; Li, L., Jamieson, K., DeSalvo, G., Rostamizadeh, A., Talwalkar, A., Hyperband: A novel bandit-based approach to hyperparameter optimization (2017) J. Mach. Learn. Res., 18 (1), pp. 6765-6816. , Jan","Erpek, T.; Department of Electrical and Computer Engineering, United States; 电子邮件: terpek@vt.edu",,,Institute of Electrical and Electronics Engineers Inc.,,,,,15361233,,,,English,IEEE Trans. Mob. Comput.,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85099592230
"Bousnina N., Zheng L., Mikram M., Ghouzali S., Minaoui K.",57193958073;36959977700;23397604200;24528316000;55312226700;,Unraveling robustness of deep face anti-spoofing models against pixel attacks,2021,Multimedia Tools and Applications,80,5,,7229,7246,,2,10.1007/s11042-020-10041-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094165314&doi=10.1007%2fs11042-020-10041-1&partnerID=40&md5=e15e95e27680b6452703317f592452c6,"LRIT - CNRST URAC n∘. 29, Faculty of Sciences Rabat, IT Center, Mohammed V University Morocco, Rabat, Morocco; Image Processing Team, Data Science, Shopee Singapore, Singapore, Singapore; Meridian Team, LYRICA Laboratory, School of Information Sciences, Rabat, Morocco; Information Technology Department, College of Computer and Information Sciences, King Saud University Riyadh, Riyadh, Saudi Arabia","Bousnina, N., LRIT - CNRST URAC n∘. 29, Faculty of Sciences Rabat, IT Center, Mohammed V University Morocco, Rabat, Morocco; Zheng, L., Image Processing Team, Data Science, Shopee Singapore, Singapore, Singapore; Mikram, M., Meridian Team, LYRICA Laboratory, School of Information Sciences, Rabat, Morocco; Ghouzali, S., Information Technology Department, College of Computer and Information Sciences, King Saud University Riyadh, Riyadh, Saudi Arabia; Minaoui, K., LRIT - CNRST URAC n∘. 29, Faculty of Sciences Rabat, IT Center, Mohammed V University Morocco, Rabat, Morocco","In the last few decades, deep-learning-based face verification and recognition systems have had enormous success in solving complex security problems. However, it has been recently shown that such efficient frameworks are vulnerable to face-spoofing attacks, which has led researchers to build proficient anti-facial-spoofing (or liveness detection) models as an additional security layer. In response, increasingly challenging and tricky attacks have been launched to fool these anti-spoofing mechanisms. In this context, this paper presents the results of an analytical study on transfer-learning-based convolutional neural networks (CNNs) for face liveness detection and differential evolution-based adversarial attacks to evaluate the efficiency of face anti-spoofing classifiers against adversarial attacks. Specifically, experiments were conducted under different use-case scenarios on four face anti-spoofing databases to highlight practical criteria that can be used in the development of countermeasures to address face-spoofing issues. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.",Convolutional neural networks; Deep learning; Differential evolution; Face liveness detection; Spoofing attacks,Convolutional neural networks; Deep learning; Evolutionary algorithms; Optimization; Transfer learning; Analytical studies; Differential Evolution; Face Verification; Liveness detection; Recognition systems; Security problems; Spoofing attacks; Use case scenario; Face recognition,,,,,"Atoum, Y., Liu, Y., Jourabloo, A., Liu, X., Face anti-spoofing using patch and depth-based CNNs (2017) IEEE International Joint Conference on Biometrics (IJCB), pp. 319-328; Bose, A.J., Aarabi, P., Adversarial attacks on face detectors using neural net based constrained optimization (2018) Arxiv; Botelho De Souza, G., Papa, J.P., Marana, A.N., (2018) On the Learning of Deep Local Features for Robust Face Spoofing Detection; Boulkenafet, Z., Komulainen, J., Li, L., Feng, X., Hadid, A., OULU-NPU: A mobile face presentation attack database with real-world variations (2017) 12Th IEEE International Conference on Automatic Face & Gesture Recognition (FG, 2017, pp. 612-618; Carlini, N., Wagner, D., (2017) Towards Evaluating the Robustness of Neural Networks.; Chen, X., Liu, C., Li, B., Lu, K., Song, D., (2017) Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning; Chingovska, I., Anjos, A., Marcel, S., On the effectiveness of local binary patterns in face anti-spoofing (2012) International Conference of Biometrics Special Interest Group (BIOSIG), pp. 1-7; Chingovska, I., Yang, J., Le, Z., Yi, D., Li, S., Kahm, O., Glaser, C., Marcel, S., The 2nd competition on counter measures to 2d face spoofing attacks (2013) IAPR Int. Conference on Biometrics (ICB), pp. 1-6; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., (2018) Boosting Adversarial Attacks with Momentum; Erdogmus, N., Marcel, S., Spoofing in 2D face recognition with 3d masks and anti-spoofing with kinect (2013) IEEE Sixth International Conference on Biometrics: Theory, Applications and Systems (BTAS), pp. 1-6; Feng, L., Po, L.M., Li, Y., Xu, X., Yuan, F., Chun-HoCheung, T., Cheung, K.W., Integration of image quality and motion cues for face anti-spoofing: a neural network approach (2016) J Vis Commun Image Represent, 38, pp. 451-460; Fourati, E., Elloumi, W., Chetouani, A., Anti-spoofing in face recognition-based biometric authentication using image quality assessment (2020) Multimed Tools Appl, 79, pp. 865-889; Gan, J., Li, S., Zhai, Y., Liu, C., 3D convolutional neural network based on face anti-spoofing (2017) 2Nd International Conference on Multimedia and Image Processing (ICMIP), pp. 1-5; Goodfellow, I.J., Shlens, J., Szegedy, C., (2015) Explaining and Harnessing Adversarial Examples. Arxiv, p. 14126572; Goswami, G., Agarwal, A., Ratha, N., Singh, R., Vatsa, M., Detecting and mitigating adversarial perturbations for robust face recognition (2019) Int J Comput Vis (IJCV), 127, pp. 719-742; Hadid, A., Face biometrics under spoofing attacks: Vulnerabilities, countermeasures, open issues, and research directions (2014) IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), pp. 113-118; Hu, W., Te, G., He, J., Chen, D., Guo, Z., (2018) Exploring hypergraph representation on face anti-spoofing beyond 2D attacks; (2017) Competition on Generalized Face Presentation Attack Detection in Mobile Authentication Scenarios, , https://sites.google.com/site/faceantispoofing/, accessed 26 August 2019 (2017); (2016) Information Technology Biometric Presentation Attack Detection Part 1: Framework, , https://www.iso.org/standard/53227.html, accessed 26 August 2019; Jiawei, S.V.D.V., Sakurai, K., Attacking convolutional neural network using differential evolution (2019) IPSJ Trans Comput Vis Appl, 11, pp. 1-12; Jourabloo, A., Liu, Y., Liu, X., (2018) Face De-Spoofing: Anti-Spoofing via Noise Modeling.; Komulainen, J., (2015) Software-Based Countermeasures to 2D Facial Spoofing Attacks, , PhD thesis; Kose, N., Dugelay, J.L., On the vulnerability of face recognition systems to spoofing mask attacks (2013) IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 2357-2361; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutionalneural networks (2017) Adv Neural Inf Process Syst (NIPS,), 60, pp. 1097-1105; Kurakin, A., Goodfellow, I., Bengio, S., (2017) Adversarial Examples in the Physical World; Kurakin, A., Goodfellow, I., Bengio, S., (2017) Adversarial Machine Learning at Scale; Li, L., Feng, X., Boulkenafet, Z., Xia, Z., Li, M., Hadid, A., An original face anti-spoofing approach using partial convolutional neural network (2016) Sixth International Conference on Image Processing Theory, Tools and Applications (IPTA), pp. 1-6; Li, L., Correia, P.L., Hadid, A., Face recognition under spoofing attacks: countermeasures and research directions (2018) IET Biom, 7, pp. 3-14; Li, H., Li, W., Cao, H., Wang, S., Huang, F., Kot, A.C., Unsupervised domain adaptation for face anti-spoofing (2018) IEEE Transactions on Information Forensics and Security, 13; Liu, Y., Jourabloo, A., Liu, X., Learning deep models for face anti-spoofing: Binary or auxiliary supervision (2018) IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 389-398; Liu, Y., Stehouwer, J., Jourabloo, A., Liu, X., (2019) Deep Tree Learning for Zero-Shot Face Anti-Spoofing, p. 190402860; Liu, Y., Tai, Y., Li, J., Ding, S., Wang, C., Huang, F., Li, D., Ji, R., (2019) Aurora guard: Real-time face anti-spoofing via light reflection; Liu, A., Wan, J., Escalera, S., Escalante, H.J., Tan, Z., Yuan, Q., Wang, K., Li, S.Z., Multi-modal face anti-spoofing attack detection challenge at CVPR2019 (2019) IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops; Lucena, O., Junior, A., Moia, V., Souza, R., Valle, E., Lotufo, R., Transfer learning using convolutional neural networks for face anti-spoofing (2017) International Conference Image Analysis and Recognition (ICIAR), pp. 27-34; Moosavi-Dezfooli, S.M., Fawzi, A., Fawzi, O., Frossard, P., (2017) Universal Adversarial Perturbations; Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2574-2582; Nagpal, C., Dubey, S.R., (2019) A performance evaluation of convolutional neural networks for face anti spoofing; Nguyen, M.D., Bui, Q.M., Your face is NOT your password (2009) Black Hat DC; Papernot, N., McDaniel, P., Goodfellow, I.J., Jha, S.K., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) ACM on Asia Conference on Computer and Communications Security, pp. 506-519; Patel, K., Han, H., Jain, A.K., Secure face unlock: Spoof detection on smartphones (2016) IEEE Trans Inf Forens Secur, 11, pp. 2268-2283; Patel, K., Han, H., Jain, A.K., Cross-database face antispoofing with robust feature representation (2016) Chinese Conference on Biometric Recognition (CCBR), pp. 611-619; Peng, F., Qin, L., Long, M., Face presentation attack detection using guided scale texture (2018) Multimed Tools Appl, 77, pp. 1-27; Redmon, J., Farhadi, A., (2016) YOLO9000: Better, Faster, Stronger; Saon, G., Kuo, H.K.J., Rennie, S., Picheny, M., (2015) The IBM 2015 English Conversational Telephone Speech Recognition System; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., (2019) A General Framework for Adversarial Examples with Objectives. Arxiv, p. 180100349; Simonyan, K., Zisserman, A., (2015) Very Deep Convolutional Networks for Large-Scale Image Recognition; Song, Q., Wu, Y., Yang, L., (2018) Attacks on State-Of-The-Art Face Recognition Using Attentional Adversarial Attack Generative Network; Souza, L., Oliveira, L., Pamplona, M., Papa, J.P., How far did we get in face spoofing detection? (2018) Eng Appl Artif Intell, 72, pp. 368-381; Storn, R., Price, K., Differential evolution a simple and efficient heuristic for global optimization over continuous spaces (1997) J Glob Optim, 11, pp. 341-359; Su, J., Vargas, D.V., Kouichi, S., (2018) One Pixel Attack for Fooling Deep Neural Networks.; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Rob, F., Intriguing properties of neural networks (2014) ICLR; (2010) Trusted Biometrics under Spoofing Attacks (TABULA RASA)., , http://www.tabularasa-euproject.org/; Tu, X., Zhang, H., Xie, M., Luo, Y., Zhang, Y., Ma, Z., (2019) Deep Transfer across Domains for Face Anti-Spoofing; Tu, X., Zhang, H., Xie, M., Luo, Y., Zhang, Y., Ma, Z., (2019) Enhance the Motion Cues for Face Anti-Spoofing Using CNN-LSTM Architecture; (2016) Unique Identification Authority of India (UIDAI)., , https://uidai.gov.in; Ur Rehman, Y.A., Po, L.M., Liu, M., Zou, Z., Ou, W., Zhao, Y., Face liveness detection using convolutional-features fusion of real and deep network generated face images (2019) J Vis Commun Image Represent, 59, pp. 574-582; Wang, Z., Zhao, C., Qin, Y., Zhou, Q., Qi, G., Wan, J., Lei, Z., (2019) Exploiting Temporal and Depth Information for Multi-Frame Face Anti-Spoofing; Wen, D., Han, H., Jain, A.K., Face spoof detection with image distortion analysis (2015) IEEE Trans Inf Forens Secur, 10, pp. 746-761; Yang, J., Lei, Z., Li, S.Z., Learn convolutional neural network for face anti-spoofing (2014) Computer Science. Arxiv, 1408 (5601), pp. 373-384; Zhang, Z., Yan, J., Liu, S., Lei, Z., Yi, D., Li, S.Z., A face antispoofing database with diverse attacks (2012) 5Th IAPR International Conference on Biometrics (ICB), pp. 26-31; Zhang, K., Zhang, Z., Li, Z., Qiao, Y., Joint face detection and alignment using multitask cascaded convolutional networks (2016) IEEE Signal Process Lett, 23, pp. 1499-1503; Zhou, Z., Tang, D., Wang, X., Han, W., Liu, X., Zhang, K., (2018) Invisible mask: Practical attacks on face recognition with infrared","Bousnina, N.; LRIT - CNRST URAC n∘. 29, Morocco; 电子邮件: naimabousnina2@gmail.com",,,Springer,,,,,13807501,,MTAPF,,English,Multimedia Tools Appl,Article,Final,,Scopus,2-s2.0-85094165314
"Li L., Rezapour A., Tzeng W.-G.",57222156469;56986338700;7102717705;,A Black-Box Adversarial Attack via Deep Reinforcement Learning on the Feature Space,2021,"2021 IEEE Conference on Dependable and Secure Computing, DSC 2021",,,9346264,,,,,10.1109/DSC49826.2021.9346264,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101725518&doi=10.1109%2fDSC49826.2021.9346264&partnerID=40&md5=51fb3ed442a7b4095d4e26769466b0c8,"National Chiao Tung University, Computer Science Department, Hsinchu, 30050, Taiwan","Li, L., National Chiao Tung University, Computer Science Department, Hsinchu, 30050, Taiwan; Rezapour, A., National Chiao Tung University, Computer Science Department, Hsinchu, 30050, Taiwan; Tzeng, W.-G., National Chiao Tung University, Computer Science Department, Hsinchu, 30050, Taiwan","In this paper we propose a novel black-box adversarial attack by using the reinforcement learning to learn the characteristics of the target classifier C. Our method does not need to find a substitute classifier that resembles C with respect to its structure and parameters. Instead, our method learns an optimal attacking policy of guiding the attacker to build an adversarial image from the original image. We work on the feature space of images, instead of the pixels of images directly. Our method achieves better results on many measures. Our method achieves 94.5 % attack success rate on a well-Trained digit classifier. Our adversarial images have better imperceptibility even though the norm distances to original images are larger than other methods. Since our method works on the characteristics of a classifier, it has better transferability. The transfer rate of our method could reach 52.1 % for a targeted class and 65.9% for a non-Targeted class. This improves over previous results of single-digit transfer rates. Also, we show that it is harder to defend our attack by incorporating defense mechanisms, such as MagNet, which uses a denoising technique. We show that our method achieves 65% attack success rate even though the target classifier employs MagNet to defend. © 2021 IEEE.",adversarial attack; adversarial defense; adversarial example; autoen-coder; black-box attack; deep reinforcement learning; image processing; machine learning,Magnets; Reinforcement learning; Black boxes; De-noising techniques; Defense mechanism; Digit classifier; Feature space; Non-targeted; Original images; Transfer rates; Deep learning,,,,,"Alzantot, M., Sharma, Y., Chakraborty, S., Zhang, H., Hsieh, C.-J., Srivastava, M.B., GenAttack: Practical black-box attacks with gradient-free optimization (2019) Genetic and Evolutionary Computation Conference, pp. 1111-1119; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy (S&P, pp. 39-57; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., ZOO: Zeroth order optimization based blackbox attacks to deep neural networks without training substitute models (2017) 10th ACM Workshop on Artificial Intelligence and Security, pp. 15-26; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Li, F.-F., ImageNet: A large-scale hierarchical image database (2009) IEEE Conference on Computer Vision and Pattern Recognition, pp. 248-255; Gao, X., Tan, Y.-A., Jiang, H., Zhang, Q., Kuang, X., Boosting targeted black-box attacks via ensemble substitute training and linear augmentation (2019) Applied Sciences, 9 (11); Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) Third International Conference on Learning Representations (ICLR; Krizhevsky, A., Sutskever, I., Hinton, G., ImageNet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2016) ArXiv Preprint arXiv:1607, 2533; Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proceedings of the IEEE, 86 (11), pp. 2278-2324; Luo, B., Liu, Y., Wei, L., Xu, Q., Towards imperceptible and robust adversarial example attacks against neural networks (2018) Thirty-Second AAAI Conference on Artificial Intelligence (AAAI-18, pp. 1652-1659; Meng, D., Chen, H., MagNet: A two-pronged defense against adversarial examples (2017) ACM SIGSAC Conference on Computer and Communications Security, pp. 135-147; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., DeepFool: A simple and accurate method to fool deep neural networks (2016) IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) ACM on Asia Conference on Computer and Communications Security, pp. 506-519; Samangouei, P., Kabkab, M., Chellappa, R., Defense-GAN: Protecting classifiers against adversarial attacks using generative models (2018) Sixth International Conference on Learning Representations (ICLR; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint arXiv:1312 6199; Xiao, C., Li, B., Zhu, J.-Y., He, W., Liu, M., Song, D., Generating adversarial examples with adversarial networks (2018) Twenty-Seventh International Joint Conference on Artificial Intelligence (IJCAI-18, pp. 3905-3911",,,,Institute of Electrical and Electronics Engineers Inc.,"2021 IEEE Conference on Dependable and Secure Computing, DSC 2021",30 January 2021 through 2 February 2021,,167103,,9.78E+12,,,English,"IEEE Conf. Dependable Secure Comput., DSC",Conference Paper,Final,,Scopus,2-s2.0-85101725518
"Deng X., Fang Z., Zheng Y., Wang Y., Huang J., Wang X., Cao T.",57211155608;57208813818;56693243700;57222230446;57222220744;57192631022;15064935700;,Adversarial examples with transferred camouflage style for object detection,2021,Journal of Physics: Conference Series,1738,1,12130,,,,,10.1088/1742-6596/1738/1/012130,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101937963&doi=10.1088%2f1742-6596%2f1738%2f1%2f012130&partnerID=40&md5=60751f9ec8dab8a82bc514274013670a,"Institute of Command and Control Engineering, Army Engineering University, Nanjing, Jiangsu, 210000, China; PLA Army Academy of Artillery and Air Defense, Nanjing, Jiangsu, 210000, China","Deng, X., Institute of Command and Control Engineering, Army Engineering University, Nanjing, Jiangsu, 210000, China; Fang, Z., Institute of Command and Control Engineering, Army Engineering University, Nanjing, Jiangsu, 210000, China; Zheng, Y., Institute of Command and Control Engineering, Army Engineering University, Nanjing, Jiangsu, 210000, China, PLA Army Academy of Artillery and Air Defense, Nanjing, Jiangsu, 210000, China; Wang, Y., Institute of Command and Control Engineering, Army Engineering University, Nanjing, Jiangsu, 210000, China; Huang, J., Institute of Command and Control Engineering, Army Engineering University, Nanjing, Jiangsu, 210000, China; Wang, X., Institute of Command and Control Engineering, Army Engineering University, Nanjing, Jiangsu, 210000, China, PLA Army Academy of Artillery and Air Defense, Nanjing, Jiangsu, 210000, China; Cao, T., Institute of Command and Control Engineering, Army Engineering University, Nanjing, Jiangsu, 210000, China","Most of existing adversarial examples attacking methods for object detection models aim at generating subtle perturbation which is invisible to human vision. However, some perturbations with stronger intensity are equally effective and can even make the objects in adversarial examples more invisible. In this paper, an attack model based on the Generative Adversarial Network and style transfer method is designed to craft and add perturbation with camouflage style to the object area in the image. Experiments on PASCAL VOC 2012 dataset demonstrated that Adversarial examples generated from our model can attack both proposal-based detectors and regression-based object detection models effectively, and reduce the visual saliency of the objects. © 2020 Published under licence by IOP Publishing Ltd.",,Computer networks; Object recognition; Adversarial networks; Attack model; Human vision; Transfer method; Visual saliency; Object detection,,,,,"Moosavi-Dezfooli, S. M., Fawzi, A., Fawzi, O., Frossard, P., (2017) Universal adversarial perturbations Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Goodfellow, I. J., Shlens, J., Szegedy, C., (2015) Explaining and Harnessing Adversarial Examples, , arXiv preprint arXiv:1412.6572; Baluja, S., Fischer, I., (2017) Adversarial Transformation Networks: Learning to Generate Adversarial Examples, , arXiv preprint arXiv:1703.09387; Aditi, Raghunathan, Jacob, Steinhardt, Percy, Liang, (2018) Certified defenses against adversarial examples, , arXiv preprint arXiv:1801.09344; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a Defense to Adversarial Perturbations against Deep Neural Networks (2016) IEEE Symposium on Security and Privacy (SP), pp. 582-597; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., (2017) Adversarial Examples for Semantic Segmentation and Object Detection, , arXiv preprint arXiv:1703.08603; Cihang, Xie, Jianyu, Wang, Zhishuai, Zhang, Yuyin, Zhou, Lingxi, Xie, Alan, Yuille, (2017) Adversarial examples for semantic segmentation and object detection ICCV, , IEEE; Ren, S. Q., He, K. M., Girshick, R., Sun, J., Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks (2017) IEEE Trans. Pattern Anal. Mach. Intell, 39, pp. 142-158; Shang-Tse, Chen, Cory, Cornelius, Jason, Martin, Horng, Chau Duen, (2018) Robust physical adversarial attack on faster r-cnn object detector, , arXiv preprint arXiv:1804.05810; Wei, X, Liang, S, Chen, N, Transferable Adversarial Attacks for Image and Video Object Detection (2018), [J]; Mirza, M, Osindero, S., Conditional Generative Adversarial Nets (2014), [J] arXiv preprint arXiv:1411.1784; Huang, L, Gao, C, Zhou, Y, Universal Physical Camouflage Attacks on Object Detectors (2019), [J]; Duan, R, Ma, X, Wang, Y, Adversarial Camouflage: Hiding Physical-World Attacks with Natural Styles (2020), [J]; Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., SSD: Single shot multibox detector ECCV (2016); Johnson, J, Alahi, A, Fei-Fei, L., Perceptual Losses for Real-Time Style Transfer and Super-Resolution (2016), [J]; Karen, Simonyan, Andrew, Zisserman, (2014) Very deep convolutional networks for large-scale image recognition, , arXiv preprint arXiv:1409.1556; Sugano, Y., Matsushita, Y., Sato, Y., Calibration-free gaze sensing using saliency maps (2010) Proc. CVPR, pp. 2667-2674; Wang, W, Shen, J, Dong, X, Inferring Salient Objects from Human Fixations (2019) IEEE Transactions on Pattern Analysis and Machine Intelligence, pp. 1-1. , [J]; Kim, J, Han, D, Tai, Y W, Salient Region Detection via High-Dimensional Color Transform (2014) IEEE Transactions on Image Processing, 25, pp. 1-1. , [J]","Cao, T.; Institute of Command and Control Engineering, China; 电子邮件: 1700710318@mails.guet.edu.cn",,,IOP Publishing Ltd,"2020 2nd International Conference on Electronics and Communication, Network and Computer Technology, ECNCT 2020",23 October 2020 through 25 October 2020,,167311,17426588,,,,English,J. Phys. Conf. Ser.,Conference Paper,Final,"All Open Access, Bronze",Scopus,2-s2.0-85101937963
"Zhang Z., Qiao K., Chen J., Liang N.",57219506943;57188641013;56016202000;57203978839;,Based on Max-Min Framework Transferable Adversarial Attacks,2021,"2021 6th International Conference on Signal and Image Processing, ICSIP 2021",,,,1075,1082,,,10.1109/ICSIP52628.2021.9688630,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125202672&doi=10.1109%2fICSIP52628.2021.9688630&partnerID=40&md5=d60f9ed69f0cee859bf85cab76af5959,"Force Information Engineering University, Academy of Information Systems Engineering, PLA Strategy Support, Zhengzhou, China","Zhang, Z., Force Information Engineering University, Academy of Information Systems Engineering, PLA Strategy Support, Zhengzhou, China; Qiao, K., Force Information Engineering University, Academy of Information Systems Engineering, PLA Strategy Support, Zhengzhou, China; Chen, J., Force Information Engineering University, Academy of Information Systems Engineering, PLA Strategy Support, Zhengzhou, China; Liang, N., Force Information Engineering University, Academy of Information Systems Engineering, PLA Strategy Support, Zhengzhou, China","Though deep neural networks perform challenging tasks excellently, they are susceptible to adversarial examples, which mislead classifiers by applying human-imperceptible perturbations on clean inputs. Under the query-free black-box scenario, adversarial examples are hard to transfer to unknown models, and several methods have been proposed with the low transferability. To settle such issue, we design a max-min framework inspired by input transformations, which are beneficial to both the adversarial attacks and defenses. Explicitly, we decrease loss values with inputs' affine transformations as a defense in the minimum procedure, and then increase loss values with the momentum iterative algorithm as an attack in the maximum procedure. To further improve the transferability, we determine transformed values with the max-min framework. Extensive experiments on the ImageNet dataset demonstrate that our defense-guided transferable attacks achieve impressive promotion on transferability. Experimentally, we show that the attack success rate of our method reaches to 58.38% on average, which outperforms the state-of-the-art method by 12.1% on the normally trained models and 11.13% on the adversarially trained models. Additionally, we provide a novel insight on the improvement of transferability, and our method is expected to be a benchmark for assessing the robustness of deep models. © 2021 IEEE.",Affine transformation; Black-box attack; Max-min framework; Transferability,Computer vision; Deep neural networks; Iterative methods; Affine transformations; Black boxes; Black-box attack; Input transformation; Input-affine; Iterative algorithm; Max-min framework; Max/min; Transferability; Transformed values; Network security,,,,,"Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) Proceedings of the 2015 IEEE Conference on Computer Vision and Pattern Recognition, , Massachusetts, Boston, USA, 8-10 June; He, K., Zhang, X., Ren, S., Sun, J., Identity mappings in deep residual networks (2016) Proceedings of the 14th European Conference on Computer Vision, pp. 630-645. , Amsterdam, The Netherlands, 8-16 October; Zhang, Z., Qiao, S., Xie, C., Shen, W., Wang, B., Yuille, A.L., Single-shot object detection with enriched semantics (2018) Proceedings of the 2018 IEEE Conference on Computer Vision and Pattern Recognition, pp. 5813-5821. , Salt Lake City, UT, USA, 19-21 June; Redmon, J., Farhadi, A., (2018) YOLOv3: An Incremental Improvement; Zheng, L., Yang, Y., Tian, Q., SIFT Meets CNN: A decade survey of instance retrieval (2018) IEEE Transactions on Pattern Analysis and Machine Intelligence, 40, pp. 1224-1244; Bojarski, M., Del Testa, D., Dworakowski, D., Firner, B., Flepp, B., Goyal, P., Jackel, L.D., Zhao, J., (2016) End to End Learning for Self-driving Cars; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) Proceedings of the 6th International Conference on Learning Representations, , Vancouver, Canada, 30-3 April-May; Ranjan, R., Sankaranarayanan, S., Castillo, C.D., Chellappa, R., (2017) Improving Network Robustness Against Adversarial Attacks with Compact Convolution; Moosavidezfooli, S., Fawzi, A., Fawzi, O., Frossard, P., Soatto, S., Robustness of classifiers to universal perturbations: A geometric perspective (2018) Proceedings of the 6th International Conference on Learning Representations, , Vancouver, Canada, 30-3 April-May; Gao, J., Wang, B., Lin, Z., Xu, W., Qi, Y., DeepCloak: Masking deep neural network models for robustness against adversarial samples (2017) Proceedings of the 5th International Conference on Learning Representations, , Palais des Congrès Neptune, Toulon, France, 24-26 April; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, Intriguing properties of neural networks (2014) Proceedings of the 2nd International Conference on Learning Representations, , Banff, AB, Canada, 14-16 April; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Proceedings of the 38th IEEE Symposium on Security and Privacy, pp. 39-57. , San Jose, CA, US, 22-24 May; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) Proceedings of the 3rd International Conference on Learning Representations, , San Diego, CA, US, 7-9 May; Tramer, F., Kurakin, A., Papernot, N., Goodfellow, I.J., Boneh, D., Mcdaniel, P., Ensemble adversarial training: Attacks and defenses (2018) Proceedings of the 6th International Conference on Learning Representations, , Vancouver, Canada, 30-3 April-May; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial examples in the physical world (2017) Proceedings of the 5th International Conference on Learning Representations, , Palais des Congrès Neptune, Toulon, France, 24-26 April; Chen, P., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.J., ZOO: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 15-26. , Dallas, TX, US, 3 Novermber; Ilyas, A., Engstrom, L., Athalye, A., Lin, J., Black-box adversarial Attacks with limited queries and information (2018) Proceedings of the 35th International Conference on Machine Learning, pp. 2137-2146. , Stockholmsmassan, Stockholm, Sweden, 10-15 July; Tu, C., Ting, P., Chen, P., Liu, S., Zhang, H., Yi, J., Hsieh, C., Cheng, S., AutoZOOM: Autoencoder-based zeroth order optimization method for attacking black-box neural networks (2019) Proceedings of the 33rd the Association for the Advance of Artificial Intelligence, pp. 742-749. , Honolulu, Haiwii, US, 27-1 Jan-Feb; Brendel, W., Rauber, J., Bethge, M., Decision-based adversarial attacks: Reliable attacks against black-box machine learning models (2018) Proceedings of the 6th International Conference on Learning Representations, , Vancouver, Canada, 30-3 April-May; Chen, J., Jordan, M.I., Wainwright, M.J., HopSkipJumpAttack: A queryefficient decision-based attack (2020) Proceedings of the 41st IEEE Symposium on Security and Privacy, pp. 720-737. , Virtual, 18-20 May; Li, H., Xu, X., Zhang, X., Yang, S., Li, B., QEBA: Query-efficient boundarybased black-box bttack (2020) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1221-1230. , 16-18 June; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 9185-9193. , Salt Lake City, UT, USA, 18-22 June; Xie, C., Zhang, Z., Zhou, Y., Bai, S., Wang, J., Ren, Z., Yuille, A.L., Improving transferability of adversarial examples with input diversity (2020) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2730-2739. , Long Beach, CA, US, 16-20 June; Liu, Y., Chen, X., Liu, C., Song, D., Delving into Transferable Adversarial examples and black-box sttacks (2017) Proceedings of the 5th International Conference on Learning Representations, , Palais des Congrès Neptune, Toulon, France, 24-26 April; Tramer, F., Papernot, N., Goodfellow, I.J., Boneh, D., Mcdaniel, P.D., (2017) The Space of Transferable Adversarial Examples; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A.L., Mitigating adversarial effects through randomization (2018) Proceedings of the 6th International Conference on Learning Representations, , Vancouver, Canada, 30-3 April-May; Shorten, C., Khoshgoftaar, T.M., A survey on image data augmentation for deep learning (2019) Journal of Big Data, 6, pp. 1-48; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Proceedings of the 37th IEEE Symposium on Security and Privacy, pp. 582-597. , San Jose, CA, US, 23-25 May; Cisse, M., Bojanowski, P., Grave, E., Dauphin, Y., Usunier, N., Parseval Networks: Improving robustness to adversarial examples (2017) Proceedings of the 5th International Conference on Learning Representations, , Palais des Congrès Neptune, Toulon, France, 24-26 April; Shaham, U., Garritano, J., Yamada, Y., Weinberger, E., Cloninger, A., Cheng, X., Stanton, K.P., Kluger, Y., (2018) Defending Against Adversarial Images Using Basis Functions Transformations; Guo, C., Rana, M., Cisse, M., Laurens, V.D.M., Countering adversarial images using input transformations (2018) Proceedings of the 6th International Conference on Learning Representations, , Vancouver, Canada, 30-3 April-May; Xie, C., Wu, Y., Maaten L, V.D., Yuille, A.L., He, K., Feature denoising for improving adversarial robustness (2020) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2730-2739. , Long Beach, CA, US, 16-20 June 501-509; Deng, J., Dong, W., Socher, R., Li, L.J., Li, F.F., ImageNet: A large-scale hierarchical image database (2009) Proceedings of the 2009 IEEE Conference on Computer Vision and Pattern Recognition, pp. 248-255. , Miami Beach, Florida, US, 20-25 June; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826. , Las Vegas, Nevada, US, 26-1 June-July; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A., Inception-v4, Inception-ResNet and the impact of residual connections on learning (2016) Proceedings of the 30th the Association for the Advance of Artificial Intelligence, pp. 4278-4284. , Phoenix, Arizona, US, 12-17 Feb; Chattopadhyay, A., Sarkar, A., Howlader, P., Balasubramanian, V.N., Grad-CAM++: Improved visual explanations for ddeep convolutional networks (2018) Proceedings of the 2018 IEEE Winter Conference on Applications of Computer Vision, pp. 839-847. , Lake Tahoe, CA, US, 12-15 March",,,Southeast University,Institute of Electrical and Electronics Engineers Inc.,"6th International Conference on Signal and Image Processing, ICSIP 2021",22 October 2021 through 24 October 2021,,176696,,9.78E+12,,,English,"Int. Conf. Signal Image Process., ICSIP",Conference Paper,Final,,Scopus,2-s2.0-85125202672
"Won Y.-S., Chatterjee S., Jap D., Basu A., Bhasin S.",57217080594;57195279027;56541537700;21833638600;35118585900;,DeepFreeze: Cold Boot Attacks and High Fidelity Model Recovery on Commercial EdgeML Device,2021,"IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers, ICCAD",2021-November,,,,,,,10.1109/ICCAD51958.2021.9643512,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124155429&doi=10.1109%2fICCAD51958.2021.9643512&partnerID=40&md5=bce5189b5799fa45355863410120a830,"Temasek Laboratories, Nanyang Technological University, Singapore, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore, Singapore; Department of Electrical Engineering, City University of Hong Kong, Hong Kong","Won, Y.-S., Temasek Laboratories, Nanyang Technological University, Singapore, Singapore; Chatterjee, S., School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore, Singapore; Jap, D., Temasek Laboratories, Nanyang Technological University, Singapore, Singapore; Basu, A., School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore, Singapore, Department of Electrical Engineering, City University of Hong Kong, Hong Kong; Bhasin, S., Temasek Laboratories, Nanyang Technological University, Singapore, Singapore","EdgeML accelerators like Intel Neural Compute Stick 2 (NCS) can enable efficient edge-based inference with complex pre-trained models. The models are loaded in the host (like Raspberry Pi) and then transferred to NCS for inference. In this paper, we demonstrate practical and low-cost cold boot based model recovery attacks on NCS to recover the model architecture and weights, loaded from the Raspberry Pi. The architecture is recovered with 100% success and weights with an error rate of 0.04%. The recovered model reports maximum accuracy loss of 0.5% as compared to original model and allows high fidelity transfer of adversarial examples. We further extend our study to other cold boot attack setups reported in the literature with higher error rates leading to accuracy loss as high as 70%. We then propose a methodology based on knowledge distillation to correct the erroneous weights in recovered model, even without access to original training data. The proposed attack remains unaffected by the model encryption features of the OpenVINO and NCS framework. © 2021 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.",Cold Boot Attack; EdgeML; Intel Neural Compute Stick 2; Model Recovery,Cryptography; Distillation; Accuracy loss; Cold boot attack; Edge-based; Edgeml; Error rate; High-fidelity modeling; Intel neural compute stick 2; Low-costs; Model recovery; Recovery attacks; Recovery,,,,,"Chen, J., Ran, X., Deep learning with edge computing: A review (2019) Proceedings of The IEEE, 107 (8), pp. 1655-1674; Neural Compute Stick 2, , https://software.intel.com/content/www/us/en/develop/hardware/neural-compute-stick.html; Batina, L., Bhasin, S., Jap, D., Picek, S., CSI NN: Reverse engineering of neural network architectures through electromagnetic side channel (2019) 28th USENIX Security Symposium, USENIX Security 2019, pp. 515-532. , https://www.usenix.org/conference/usenixsecurity19/presentation/batina, Santa Clara, CA, USA, August 14-16, 2019, N. Heninger andTraynor, Eds. USENIX Association, Online; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations, ICLR; Liu, W., Chang, C.-H., Zhang, F., Lou, X., Imperceptible misclassification attack on deep learning accelerator by glitch injection (2020) 2020 57th ACM/IEEE Design Automation Conference (DAC), pp. 1-6; Gongye, C., Fei, Y., Wahl, T., Reverse-engineering deep neural networks using floating-point timing side-channels (2020) 2020 57th ACM/IEEE Design Automation Conference (DAC), pp. 1-6; Halderman, J.A., Schoen, S.D., Heninger, N., Clarkson, W., Paul, W., Calandrino, J.A., Feldman, A.J., Felten, E.W., Lest we remember: Cold-boot attacks on encryption keys (2009) Communications of The ACM, 52 (5), pp. 91-98; Jagielski, M., Carlini, N., Berthelot, D., Kurakin, A., Papernot, N., High accuracy and high fidelity extraction of neural networks 29th {USENIX} Security Symposium ({USENIX} Security 20), 2020, pp. 1345-1362; Segerdahl, O., Saarinen, P., An ice-cold boot to break bitlocker (2018) BlueHat Security Conference; Bauer, J., Gruhn, M., Freiling, F.C., Lest we forget: Cold-boot attacks on scrambled ddr3 memory (2016) Digital Investigation, 16, pp. S65-S74; Tilo, M., Michael, S., Freiling, F.C., FrosT: Forensic recovery of scrambled telephones (2014) Proceedings of The International Conference on Applied Cryptography and Network Security, pp. 373-388; Won, Y.-S., Park, J.-Y., Han, D.-G., Bhasin, S., Practical cold boot attack on iot device-case study on raspberry pi (2020) 2020 IEEE International Symposium on The Physical and Failure Analysis of Integrated Circuits (IPFA), pp. 1-4; Tramèr, F., Zhang, F., Juels, A., Reiter, M.K., Ristenpart, T., Stealing machine learning models via prediction apis (2016) 25th {USENIX} Security Symposium ({USENIX} Security 16), pp. 601-618; Breier, J., Jap, D., Hou, X., Bhasin, S., Liu, Y., Sniff: Reverse Engineering of Neural Networks with Fault Attacks, , arXiv preprint; Dubey, A., Cammarota, R., Aysu, A., MaskedNet: A pathway for secure inference against power side-channel attacks (2019) CoRR, , http://arxiv.org/abs/1910.13063, abs/1910.13063, Online; Hua, W., Zhang, Z., Suh, G.E., Reverse engineering convolutional neural networks through side-channel information leaks (2018) Proceedings of The 55th Annual Design Automation Conference, DAC 2018, pp. 41-46. , https://doi.org/10.1145/3195970.3196105, San Francisco, CA, USA, June 24-29, 2018. ACM, Online; Hinton, G., Vinyals, O., Dean, J., (2015) Distilling The Knowledge in A Neural Network, , arXiv preprint; Gou, J., Yu, B., Maybank, S.J., Tao, D., Knowledge distillation: A survey (2021) International Journal of Computer Vision, 129 (6), pp. 1789-1819; Hu, X., Liang, L., Deng, L., Li, S., Xie, X., Ji, Y., Ding, Y., Xie, Y., Neural network model extraction attacks in edge devices by hearing architectural hints (2019) CoRR, , http://arxiv.org/abs/1903.03916, abs/1903.03916, Online; Yu, H., Ma, H., Yang, K., Zhao, Y., Jin, Y., Deepem: Deep neural networks model recovery through em side-channel information leakage (2020) 2020 IEEE International Symposium on Hardware Oriented Security and Trust (HOST), pp. 209-218; Dubey, A., Cammarota, R., Aysu, A., MaskedNet: The first hardware inference engine aiming power side-channel protection (2020) 2020 IEEE International Symposium on Hardware Oriented Security and Trust (HOST), pp. 197-208; Intel OpenVINO Toolkit, , https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit.html; Encrypted Models with OpenVINO, , https://docs.openvinotoolkit.org/latest/openvino_docs_IE_DG_protecting_model_guide.html; Hong, S., Frigo, P., Kaya, Y., Giuffrida, C., Dumitras, T., Terminal brain damage: Exposing the graceless degradation in deep neural networks under hardware fault attacks (2019) 28th {USENIX} Security Symposium ({USENIX} Security 19), pp. 497-514; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) 3rd International Conference on Learning Representations, ICLR 2015, , http://arxiv.org/abs/1412.6572, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings, Y. Bengio and Y. LeCun, Eds, Online; Fredrikson, M., Lantz, E., Jha, S., Lin, S., Page, D., Ristenpart, T., Privacy in pharmacogenetics: An end-to-end case study of personalized warfarin dosing (2014) 23rd {USENIX} Security Symposium ({USENIX} Security 14), pp. 17-32; Fredrikson, M., Jha, S., Ristenpart, T., Model inversion attacks that exploit confidence information and basic countermeasures (2015) Proceedings of The 22nd ACM SIGSAC Conference on Computer and Communications Security, pp. 1322-1333",,,Cadence;FutureWei Technologies;Synopsys,Institute of Electrical and Electronics Engineers Inc.,"40th IEEE/ACM International Conference on Computer-Aided Design, ICCAD 2021",1 November 2021 through 4 November 2021,,175842,10923152,9.78E+12,DICDF,,English,IEEE ACM Int. Conf. Comput. Des. Dig. Tech. Pap. ICCAD,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85124155429
"Inkawhich N., Liang K.J., Zhang J., Yang H., Li H., Chen Y.",57194798606;57202922615;57207799161;57203286881;57204886743;57226339141;,Can Targeted Adversarial Examples Transfer When the Source and Target Models Have No Label Space Overlap?,2021,Proceedings of the IEEE International Conference on Computer Vision,2021-October,,,41,50,,,10.1109/ICCVW54120.2021.00011,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123051724&doi=10.1109%2fICCVW54120.2021.00011&partnerID=40&md5=5d0bf28a9627445c5d675ef5a4538e0c,Duke University; Facebook AI,"Inkawhich, N., Duke University; Liang, K.J., Facebook AI; Zhang, J., Duke University; Yang, H., Duke University; Li, H., Duke University; Chen, Y., Duke University","We design blackbox transfer-based targeted adversarial attacks for an environment where the attacker's source model and the target blackbox model may have disjoint label spaces and training datasets. This scenario significantly differs from the ""standard""blackbox setting, and warrants a unique approach to the attacking process. Our methodology begins with the construction of a class correspondence matrix between the whitebox and blackbox label sets. During the online phase of the attack, we then leverage representations of highly related proxy classes from the whitebox distribution to fool the blackbox model into predicting the desired target class. Our attacks are evaluated in three complex and challenging test environments where the source and target models have varying degrees of conceptual overlap amongst their unique categories. Ultimately, we find that it is indeed possible to construct targeted transfer-based adversarial attacks between models that have non-overlapping label spaces! We also analyze the sensitivity of attack success to properties of the clean data. Finally, we show that our transfer attacks serve as powerful adversarial priors when integrated with query-based methods, markedly boosting query efficiency and adversarial success. © 2021 IEEE.",,Black box modelling; Black boxes; Disjoint labels; Label sets; Label space; matrix; Source models; Target class; Target model; Training dataset; Computer vision,,,,,"Bendale, A., Boult, T.E., Towards open set deep networks (2016) CVPR; Joey Bose, A., Gidel, G., Berard, H., Cianflone, A., Vincent, P., Lacoste-Julien, S., Hamilton, W.L., Adversarial example games (2020) NeurIPS; Cheng, S., Dong, Y., Pang, T., Su, H., Zhu, J., Improving black-box adversarial attacks with a transfer-based prior (2019) NeurIPS; Deng, J., Dong, W., Socher, R., Li, L., Li, K., Li, F., Imagenet: A large-scale hierarchical image database (2009) CVPR; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2018) CVPR; Dong, Y., Pang, T., Su, H., Zhu, J., Evading defenses to transferable adversarial examples by translation-invariant attacks (2019) CVPR; Geirhos, R., Rubisch, P., Michaelis, C., Bethge, M., Wichmann, F.A., Brendel, W., Imagenet-trained cnns are biased towards texture; Increasing shape bias improves accuracy and robustness (2019) ICLR; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) CVPR; Huang, G., Liu, Z., Van Der Maaten, L., Weinberger, K.Q., Densely connected convolutional networks (2017) CVPR; Huang, Q., Katsman, I., Gu, Z., He, H., Belongie, S.J., Lim, S., Enhancing adversarial example transferability with an intermediate level attack (2019) ICCV; Ilyas, A., Engstrom, L., Athalye, A., Lin, J., Black-box adversarial attacks with limited queries and information (2018) ICML; Inkawhich, N., Liang, K.J., Carin, L., Chen, Y., Transferable perturbations of deep feature distributions (2020) ICLR; Inkawhich, N., Liang, K.J., Wang, B., Inkawhich, M., Carin, L., Chen, Y., Perturbing across the feature hierarchy to improve standard and strict blackbox attack transferability (2020) NeurIPS; Inkawhich, N., Wen, W., Helen Li, H., Chen, Y., Feature space perturbations yield more transferable adversarial examples (2019) CVPR; Jo, J., Bengio, Y., (2017) Measuring the Tendency of CNNs to Learn Surface Statistical Regularities; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial machine learning at scale (2017) ICLR; Kurakin, A., Goodfellow, I.J., Bengio, S., Dong, Y., Liao, F., Liang, M., Pang, T., Abe, M., Adversarial attacks and defences competition (2018) CoRR, , abs/1804.00097; Lee, S., Park, C., Lee, H., Yi, J., Lee, J., Yoon, S., Removing undesirable feature contributions using out-of-distribution data (2021) ICLR; Li, Q., Guo, Y., Chen, H., Practical no-box adversarial attacks against dnns (2020) NeurIPS; Li, Q., Guo, Y., Chen, H., Yet another intermediate-level attack (2020) ECCV; Lin, J., Song, C., He, K., Wang, L., Hopcroft, J.E., Nesterov accelerated gradient and scale invariance for adversarial attacks (2020) ICLR; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and blackbox attacks (2017) ICLR; Lu, Y., Jia, Y., Wang, J., Li, B., Chai, W., Carin, L., Velipasalar, S., Enhancing crosstask black-box transferability of adversarial examples with dispersion reduction (2020) CVPR; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) ICLR; Miller, G.A., Wordnet: A lexical database for english (1995) Communications of the ACM, 38 (11), pp. 39-41; Naseer, M., Khan, S.H., Haris Khan, M., Shahbaz Khan, F., Porikli, F., Cross-domain transferability of adversarial perturbations (2019) NeurIPS; Mai Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) CVPR; https://pytorch.org/vision/0.8/models.html; Rozsa, A., Günther, M., Boult, T.E., LOTS about attacking deep features (2017) IJCB; Sandler, M., Howard, A.G., Zhu, M., Zhmoginov, A., Chen, L., Mobilenetv2: Inverted residuals and linear bottlenecks (2018) CVPR; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) ICLR; Tu, C., Ting, P., Chen, P., Liu, S., Zhang, H., Yi, J., Hsieh, C., Cheng, S., Autozoom: Autoencoder-based zeroth order optimization method for attacking black-box neural networks (2019) AAAI; Wang, H., Ge, S., Lipton, Z., Xing, E.P., Learning robust global representations by penalizing local predictive power (2019) NeurIPS; Wu, D., Wang, Y., Xia, S., Bailey, J., Ma, X., Skip connections matter: On the transferability of adversarial examples generated with resnets (2020) ICLR; Xie, C., Zhang, Z., Zhou, Y., Bai, S., Wang, J., Ren, Z., Yuille, A.L., Improving transferability of adversarial examples with input diversity (2019) CVPR; Xie, S., Girshick, R.B., Dollár, P., Tu, Z., He, K., Aggregated residual transformations for deep neural networks (2017) CVPR; Zagoruyko, S., Komodakis, N., Wide residual networks (2016) BMVC; Zhao, Z., Liu, Z., Larson, M.A., On success and simplicity: A second look at transferable targeted attacks (2020) CoRR, , abs/2012.11207; Zhou, B., Lapedriza, A., Khosla, A., Oliva, A., Torralba, A., Places: A 10 million image database for scene recognition (2017) IEEE Transactions on Pattern Analysis and Machine Intelligence","Inkawhich, N.; Duke University电子邮件: nathan.inkawhich@duke.edu",,CVF;IEEE,Institute of Electrical and Electronics Engineers Inc.,"18th IEEE/CVF International Conference on Computer Vision Workshops, ICCVW 2021",11 October 2021 through 17 October 2021,,174685,15505499,9.78E+12,PICVE,,English,Proc IEEE Int Conf Comput Vision,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85123051724
[无可用作者姓名],[无可用的作者 ID],"1st CAAI International Conference on Artificial Intelligence, CICAI 2021",2021,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),13069 LNAI,,,,,1226,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122596270&partnerID=40&md5=ab79fbba11953344bcc6a78171203e19,,,The proceedings contain 101 papers. The special focus in this conference is on Artificial Intelligence. The topics include: Diagnosis of Childhood Autism Using Multi-modal Functional Connectivity via Dynamic Hypergraph Learning; CARNet: Automatic Cerebral Aneurysm Classification in Time-of-Flight MR Angiography by Leveraging Recurrent Neural Networks; White-Box Attacks on the CNN-Based Myoelectric Control System; MMG-HCI: A Non-contact Non-intrusive Real-Time Intelligent Human-Computer Interaction System; DSGSR: Dynamic Semantic Generation and Similarity Reasoning for Image-Text Matching; phase Partition Based Virtual Metrology for Material Removal Rate Prediction in Chemical Mechanical Planarization Process; SAR Target Recognition Based on Model Transfer and Hinge Loss with Limited Data; Neighborhood Search Acceleration Based on Deep Reinforcement Learning for SSCFLP; GBCI: Adaptive Frequency Band Learning for Gender Recognition in Brain-Computer Interfaces; DiffGNN: Capturing Different Behaviors in Multiplex Heterogeneous Networks for Recommendation; hybrid Domain Convolutional Neural Network for Memory Efficient Training; brightening the Low-Light Images via a Dual Guided Network; learning Multi-scale Underexposure Image Correction; optimizing Loss Function for Uni-modal and Multi-modal Medical Registration; registration of 3D Point Clouds Based on Voxelization Simplify and Accelerated Iterative Closest Point Algorithm; few-shot Weighted Style Matching for Glaucoma Detection; Lightweight Convolutional SNN for Address Event Representation Signal Recognition; in-the-Wild Facial Highlight Removal via Generative Adversarial Networks; A Cross-Layer Fusion Multi-target Detection and Recognition Method Based on Improved FPN Model in Complex Traffic Environment; various Plug-and-Play Algorithms with Diverse Total Variation Methods for Video Snapshot Compressive Imaging; graph-Based Exercise- and Knowledge-Aware Learning Network for Student Performance Prediction; EEG Signals Classification in Time-Frequency Images by Fusing Rotation-Invariant Local Binary Pattern and Gray Level Co-occurrence Matrix Features; reduced-reference Perceptual Discrepancy Learning for Image Restoration Quality Assessment; EFENet: Reference-Based Video Super-Resolution with Enhanced Flow Estimation.,,,,,,,,,Fang L.Chen Y.Zhai G.Wang J.Wang R.Dong W.,,Springer Science and Business Media Deutschland GmbH,"1st CAAI International Conference on Artificial Intelligence, CICAI 2021",5 June 2021 through 6 June 2021,,270479,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Review,Final,,Scopus,2-s2.0-85122596270
[无可用作者姓名],[无可用的作者 ID],"1st CAAI International Conference on Artificial Intelligence, CICAI 2021",2021,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),13070 LNAI,,,,,1226,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122582092&partnerID=40&md5=9721a83a263d65a3ae1a42e37275dbc4,,,The proceedings contain 101 papers. The special focus in this conference is on Artificial Intelligence. The topics include: Diagnosis of Childhood Autism Using Multi-modal Functional Connectivity via Dynamic Hypergraph Learning; CARNet: Automatic Cerebral Aneurysm Classification in Time-of-Flight MR Angiography by Leveraging Recurrent Neural Networks; White-Box Attacks on the CNN-Based Myoelectric Control System; MMG-HCI: A Non-contact Non-intrusive Real-Time Intelligent Human-Computer Interaction System; DSGSR: Dynamic Semantic Generation and Similarity Reasoning for Image-Text Matching; phase Partition Based Virtual Metrology for Material Removal Rate Prediction in Chemical Mechanical Planarization Process; SAR Target Recognition Based on Model Transfer and Hinge Loss with Limited Data; Neighborhood Search Acceleration Based on Deep Reinforcement Learning for SSCFLP; GBCI: Adaptive Frequency Band Learning for Gender Recognition in Brain-Computer Interfaces; DiffGNN: Capturing Different Behaviors in Multiplex Heterogeneous Networks for Recommendation; hybrid Domain Convolutional Neural Network for Memory Efficient Training; brightening the Low-Light Images via a Dual Guided Network; learning Multi-scale Underexposure Image Correction; optimizing Loss Function for Uni-modal and Multi-modal Medical Registration; registration of 3D Point Clouds Based on Voxelization Simplify and Accelerated Iterative Closest Point Algorithm; few-shot Weighted Style Matching for Glaucoma Detection; Lightweight Convolutional SNN for Address Event Representation Signal Recognition; in-the-Wild Facial Highlight Removal via Generative Adversarial Networks; A Cross-Layer Fusion Multi-target Detection and Recognition Method Based on Improved FPN Model in Complex Traffic Environment; various Plug-and-Play Algorithms with Diverse Total Variation Methods for Video Snapshot Compressive Imaging; graph-Based Exercise- and Knowledge-Aware Learning Network for Student Performance Prediction; EEG Signals Classification in Time-Frequency Images by Fusing Rotation-Invariant Local Binary Pattern and Gray Level Co-occurrence Matrix Features; reduced-reference Perceptual Discrepancy Learning for Image Restoration Quality Assessment; EFENet: Reference-Based Video Super-Resolution with Enhanced Flow Estimation.,,,,,,,,,Fang L.Chen Y.Zhai G.Wang J.Wang R.Dong W.,,Springer Science and Business Media Deutschland GmbH,"1st CAAI International Conference on Artificial Intelligence, CICAI 2021",5 June 2021 through 6 June 2021,,270479,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Review,Final,,Scopus,2-s2.0-85122582092
"Perez J.C., Alfarra M., Jeanneret G., Rueda L., Thabet A., Ghanem B., Arbelaez P.",57204290085;57211444932;57219508462;57218920129;54788625000;24331436200;6505891154;,Enhancing Adversarial Robustness via Test-time Transformation Ensembling,2021,Proceedings of the IEEE International Conference on Computer Vision,2021-October,,,81,91,,,10.1109/ICCVW54120.2021.00015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122450860&doi=10.1109%2fICCVW54120.2021.00015&partnerID=40&md5=c08b9724c6f8ff121062651097bff9ab,"King Abdullah University of Science And Technology (KAUST); Universidad De Los Andes, Center For Research And Formation In Artificial Intelligence","Perez, J.C., King Abdullah University of Science And Technology (KAUST), Universidad De Los Andes, Center For Research And Formation In Artificial Intelligence; Alfarra, M., King Abdullah University of Science And Technology (KAUST); Jeanneret, G., Universidad De Los Andes, Center For Research And Formation In Artificial Intelligence; Rueda, L., Universidad De Los Andes, Center For Research And Formation In Artificial Intelligence; Thabet, A., King Abdullah University of Science And Technology (KAUST); Ghanem, B., King Abdullah University of Science And Technology (KAUST); Arbelaez, P., Universidad De Los Andes, Center For Research And Formation In Artificial Intelligence","Deep learning models are prone to being fooled by imperceptible perturbations known as adversarial attacks. In this work, we study how equipping models with Test-time Transformation Ensembling (TTE) can work as a reliable defense against such attacks. While transforming the input data, both at train and test times, is known to enhance model performance, its effects on adversarial robustness have not been studied. Here, we present a comprehensive empirical study of the impact of TTE, in the form of widely-used image transforms, on adversarial robustness. We show that TTE consistently improves model robustness against a variety of powerful attacks without any need for re-training, and that this improvement comes at virtually no trade-off with accuracy on clean samples. Finally, we show that the benefits of TTE transfer even to the certified robustness domain, in which TTE provides sizable and consistent improvements. © 2021 IEEE.",,Computer vision; Economic and social effects; Metadata; Empirical studies; Image transforms; Input datas; Learning models; Model robustness; Modeling performance; Test time; Trade off; Deep learning,,,,,"Andriushchenko, M., Croce, F., Flammarion, N., Hein, M., Square attack: A query-efficient black-box adversarial attack via random search (2020) Proceedings of the European Conference on Computer Vision (ECCV), , IEEE 2, 3; Athalye, A., Carlini, N., Wagner, D., Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples (2018) International Conference on Machine Learning (ICML), , 2, 6; Athalye, A., Engstrom, L., Ilyas, A., Kwok, K., Synthesizing robust adversarial examples (2018) International Conference on Machine Learning (ICML), , 2; Bambach, S., Crandall, D., Smith, L., Yu, C., Toddler-inspired visual object learning (2018) Advances in Neural Information Processing Systems (NeurIPS), , 1; Bremner, J.G., (1994) Infancy, , Wiley 1; Carlini, N., Athalye, A., Papernot, N., Brendel, W., Rauber, J., Tsipras, D., Goodfellow, I., Kurakin, A., (2019) On Evaluating Adversarial Robustness, , 2; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP), , 1, 4; Carmon, Y., Raghunathan, A., Schmidt, L., Duchi, J.C., Liang, P.S., Unlabeled data improves adversarial robustness (2019) Advances in Neural Information Processing Systems (NeurIPS), , 2; Chen, J., Cheng, Y., Gan, Z., Gu, Q., Liu, J., (2020) Efficient Robust Training Via Backward Smoothing, , 2; Chen, T., Liu, S., Chang, S., Cheng, Y., Amini, L., Wang, Z., Adversarial robustness: From self-supervised pre-training to fine-tuning (2020) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), , 2; Cohen, J., Rosenfeld, E., Kolter, Z., Certified adversarial robustness via randomized smoothing (2019) International Conference on Machine Learning (ICML), , 2, 8; Croce, F., Hein, M., Minimally distorted adversarial examples with a fast adaptive boundary attack (2020) International Conference on Machine Learning (ICML), , 3; Croce, F., Hein, M., Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks (2020) International Conference on Machine Learning (ICML), , 2, 3, 7; Cubuk, E.D., Zoph, B., Mane, D., Vasudevan, V., Le, Q.V., Autoaugment: Learning augmentation strategies from data (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , 2; Deng, J., Dong, W., Socher, R., Li, L., Li, K., Li, F., Imagenet: A large-scale hierarchical image database (2009) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , 2, 4; Dong, Y., Fu, Q., Yang, X., Pang, T., Su, H., Xiao, Z., Zhu, J., Benchmarking adversarial robustness on image classification (2020) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), , 2, 4; Dong, Y., Su, H., Wu, B., Li, Z., Liu, W., Zhang, T., Zhu, J., Efficient decision-based blackbox adversarial attacks on face recognition (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , 2; Gilmer, J., Ford, N., Carlini, N., Cubuk, E., Adversarial examples are a natural consequence of test error in noise (2019) Proceedings of the International Conference on Machine Learning (ICML), , 1; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations (ICLR), , 1, 2; Gowal, S., Qin, C., Uesato, J., Mann, T., Kohli, P., (2020) Uncovering the Limits of Adversarial Training Against Norm-bounded Adversarial Examples, , 4, 5; He, K., Zhang, X., Ren, S., Sun, J., Delving deep into rectifiers: Surpassing human-level performance on imagenet classification (2015) Proceedings of the IEEE International Conference on Computer Vision (ICCV), , 1; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , 2, 4, 6; Hendrycks, D., Lee, K., Mazeika, M., Using pre-training can improve model robustness and uncertainty (2019) International Conference on Machine Learning (ICML), , 2, 4, 5; Jayaraman, S., Smith, L.B., Faces in early visual environments are persistent not just frequent (2019) Vision Research, , 1; Kim, I., Kim, Y., Sungwoong, K., Learning loss for test-time augmentation (2020) Advances in Neural Information Processing Systems (NeurIPS), , 2; Kim, M., Tack, J., Ju Hwang, S., Adversarial self-supervised contrastive learning (2020) Advances in Neural Information Processing Systems (NeurIPS), , 2; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images, , In University of Toronto, Canada 4; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems (NeurIPS), , 1, 2, 4; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2017) International Conference on Learning Representations Workshop (ICLRW), , 2; Li, Y., Qi, H., Dai, J., Ji, X., Wei, Y., Fully convolutional instance-aware semantic segmentation (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , 2; Liu, X., Cheng, M., Zhang, H., Hsieh, C., Towards robust neural networks via random selfensemble (2018) Proceedings of the European Conference on Computer Vision (ECCV), , 2; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) International Conference on Learning Representations (ICLR), , 1, 2, 4; McQuillan, M.E., Smith, L.B., Yu, C., Bates, J.E., Parents influence the visual learning environment through children's manual actions (2020) Child Development, , 1; Mikolov, T., Chen, K., Corrado, G.S., Dean, J., (2013) Efficient Estimation of Word Representations in Vector Space, , 1; Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D., Riedmiller, M., (2013) Playing Atari with Deep Reinforcement Learning, , 1; Moosavi-Dezfooli, S., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , 2; Moshkov, N., Mathe, B., Kertesz-Farkas, A., Hollandi, R., Horvath, P., (2020) Test-time Augmentation for Deep Learning-based Cell Segmentation on Microscopy Images, , 2; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, , 6; Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Chintala, S., Pytorch: An imperative style, high-performance deep learning library (2019) Advances in Neural Information Processing Systems (NeurIPS), , 2; Perry, L.K., Samuelson, L.K., Malloy, L.M., Schiffer, R.N., Learn locally, think globally: Exemplar variability supports higher-order generalization and word learning (2010) Psychological Science, , 1; Piaget, J., Inhelder, B., (2008) The Psychology of the Child, , Basic Books 1; Raff, E., Sylvester, J., Forsyth, S., McLean, M., Barrage of random transforms for adversarially robust defense (2019) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), , 2; Raghunathan, A., Steinhardt, J., Liang, P., Certified defenses against adversarial examples (2018) International Conference on Learning Representations (ICLR), , 2; Salman, H., Li, J., Razenshteyn, I., Zhang, P., Zhang, H., Bubeck, S., Yang, G., Provably robust deep learning via adversarially trained smoothed classifiers (2019) Advances in Neural Information Processing Systems (NeurIPS), , 2, 8; Sehwag, V., Wang, S., Mittal, P., Jana, S., Hydra: Pruning adversarially robust neural networks (2020) Advances in Neural Information Processing Systems (NeurIPS), , 2, 4, 5; Sermanet, P., Eigen, D., Zhang, X., Mathieu, M., Fergus, R., Lecun, Y., Overfeat: Integrated recognition, localization and detection using convolutional networks (2014) International Conference on Learning Representations (ICLR), , 2; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) International Conference on Learning Representations (ICLR), , 2, 4; Sitawarin, C., Chakraborty, S., Wagner, D., (2020) Improving Adversarial Robustness Through Progressive Hardening, , 4, 5; Slone, L.K., Smith, L.B., Yu, C., Selfgenerated variability in object images predicts vocabulary growth (2019) Developmental Science, , 1, 2; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) Computer Vision and Pattern Recognition (CVPR), , 2; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations (ICLR), , 1; Wang, H., Wu, X., Huang, Z., Xing, E.P., High-frequency component helps explain the generalization of convolutional neural networks (2020) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), , 7; Wang, Y., Zou, D., Yi, J., Bailey, J., Ma, X., Gu, Q., Improving adversarial robustness requires revisiting misclassified examples (2019) International Conference on Learning Representations (ICLR), , 2, 4, 5; Wong, E., Kolter, Z., Provable defenses against adversarial examples via the convex outer adversarial polytope (2018) International Conference on Machine Learning (ICML), , 2; Wu, D., Xia, S., Wang, Y., Adversarial weight perturbation helps robust generalization (2020) Advances in Neural Information Processing Systems (NeurIPS), , 2, 4, 5; Xie, C., Wu, Y., Van Der Maaten, L., Yuille, A.L., He, K., Feature denoising for improving adversarial robustness (2019) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , 1, 2, 4, 5, 6; Yin, D., Gontijo Lopes, R., Shlens, J., Dogus Cubuk, E., Gilmer, J., A fourier perspective on model robustness in computer vision (2019) Advances in Neural Information Processing Systems (NeurIPS), , 7; Zagoruyko, S., Komodakis, N., Wide residual networks (2016) British Machine Vision Conference (BMVC), , 6; Zagoruyko, S., Lerer, A., Lin, T.-Y., Pinheiro, P.O., Gross, S., Chintala, S., Dollár, P., A multipath network for object detection (2016) British Machine Vision Conference (BMVC), , 2; Zhai, R., Dan, C., He, D., Zhang, H., Gong, B., Ravikumar, P., Hsieh, C., Wang, L., Macer: Attack-free and scalable robust training via maximizing certified radius (2020) International Conference on Learning Representations (ICLR), , 2, 8; Zhang, H., Yu, Y., Jiao, J., Xing, E.P., El Ghaoui, L., Jordan, M.I., Theoretically principled trade-off between robustness and accuracy (2019) International Conference on Machine Learning (ICML), , 2, 4, 5",,,CVF;IEEE,Institute of Electrical and Electronics Engineers Inc.,"18th IEEE/CVF International Conference on Computer Vision Workshops, ICCVW 2021",11 October 2021 through 17 October 2021,,174685,15505499,9.78E+12,PICVE,,English,Proc IEEE Int Conf Comput Vision,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85122450860
[无可用作者姓名],[无可用的作者 ID],"15th China Conference on Wireless Sensor Networks, CWSN 2021",2021,Communications in Computer and Information Science,1509 CCIS,,,,,261,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121863785&partnerID=40&md5=4c0ec424c87a3fae00e364854c7f8ac3,,,The proceedings contain 19 papers. The special focus in this conference is on Wireless Sensor Networks. The topics include: UACHR: Accurate CSI-Based Human Behavior Recognition Using Gaussian Goodness; a Fast General Image Encryption Method Based on Deep Learning Compressed Sensing and Compound Chaotic System; cascading Failure Mitigation Strategy for Urban Road Traffic Networks; analysis and Countermeasure Design on Adversarial Patch Attacks; online Offloading of Delay-Sensitive Tasks in Fog Computing; a Data Download Scheme Based on Vehicle Mobile Information in Internet of Vehicles; a Novel Method Based on Random Matrix Theory and Mean Shift Clustering for Spectrum Sensing; A Consensus Algorithm with Leadership Transfer-LTRaft; Load Balancing in Heterogeneous Network with SDN: A Survey; a Novel Distance Estimation Model and Its Use to Node Localization; UAV Task Allocation Method Using Swarm Intelligence Optimization Algorithm; OP-RAW: A RAW Grouping Algorithm Based on Outage Probability for Industrial Internet of Things; acousticPose: Acoustic-Based Human Pose Estimation; smartphones-Based Non-contact Children’s Posture Evaluation; research on Military Application of Operating System for Internet of Things; application of Intelligent Traffic Scene Recognition Based on Computer Vision; eRRGe: Balancing Accuracy and Efficiency of Respiratory Monitoring Using Smart Watch by Combining Peak Detection and Regression Model.,,,,,,,,,Cui L.Xie X.,,Springer Science and Business Media Deutschland GmbH,"15th China Conference on Wireless Sensor Networks, CWSN 2021",22 October 2021 through 25 October 2021,,270009,18650929,9.79E+12,,,English,Commun. Comput. Info. Sci.,Conference Review,Final,,Scopus,2-s2.0-85121863785
"Tian J., Wang B., Li J., Wang Z.",57194338911;14042909700;57212317241;57226052226;,Adversarial Attacks and Defense for CNN based Power Quality Recognition in Smart Grid,2021,IEEE Transactions on Network Science and Engineering,,,,,,,,10.1109/TNSE.2021.3135565,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121812635&doi=10.1109%2fTNSE.2021.3135565&partnerID=40&md5=071e8658c15c63bd2bf5f1c79e49bd97,"Air Force Engineering University, 66488 Xi'an, Shaanxi, China, 710077 (e-mail: tianjiwei2016@163.com); Air Force Engineering University, 66488 Xi'an, Shaanxi, China, (e-mail: adhd2016@163.com); Henan University of Technology, 47901 Zhengzhou, Henan, China, (e-mail: jingli20zz@aliyun.com); Air Force Engineering University, 66488 Xi'an, Shaanxi, China, (e-mail: wangzhen4013@163.com)","Tian, J., Air Force Engineering University, 66488 Xi'an, Shaanxi, China, 710077 (e-mail: tianjiwei2016@163.com); Wang, B., Air Force Engineering University, 66488 Xi'an, Shaanxi, China, (e-mail: adhd2016@163.com); Li, J., Henan University of Technology, 47901 Zhengzhou, Henan, China, (e-mail: jingli20zz@aliyun.com); Wang, Z., Air Force Engineering University, 66488 Xi'an, Shaanxi, China, (e-mail: wangzhen4013@163.com)","Vulnerability of various machine learning methods to adversarial examples has been recently explored in the literature. Power systems which use these vulnerable methods face a huge threat against adversarial examples. To this end, we first propose a signal-specific method and a universal signal-agnostic method to attack power systems using generated adversarial examples. Second, black-box attacks based on transferable characteristics and the above two methods are also proposed and evaluated. Third, adversarial training is adopted to defend systems against adversarial attacks. Experimental analyses demonstrate that the signal-specific attack method provides less perturbation compared to the FGSM (Fast Gradient Sign Method), and the signal-agnostic attack method can generate perturbations misclassifying most natural signals with high probability. Furthermore, the attack method based on the universal signal-agnostic algorithm has a higher transfer rate of black-box attacks than the attack method based on the signal-specific algorithm. In addition, the results show that the proposed adversarial training improves robustness of power systems to adversarial examples. IEEE",Adversarial example; adversarial training; Deep learning; neural network; Perturbation methods; Power quality; Power systems; Security; Task analysis; Training; universal perturbation,Deep neural networks; Job analysis; Perturbation techniques; Power quality; Quality control; Smart power grids; Adversarial example; Adversarial training; Deep learning; Neural-networks; Perturbation method; Power; Power system; Security; Task analysis; Universal perturbation; Electric power transmission networks,,,,,,,,,IEEE Computer Society,,,,,23274697,,,,English,IEEE Trans. Netw. Sci. Eng.,Article,Article in Press,,Scopus,2-s2.0-85121812635
[无可用作者姓名],[无可用的作者 ID],"26th Australasian Conference on Information Security and Privacy, ACISP 2021",2021,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),13083 LNCS,,,,,714,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120041079&partnerID=40&md5=de3f886a2c0d6de133088063bdaeee45,,,"The proceedings contain 35 papers. The special focus in this conference is on Information Security and Privacy. The topics include: An Anonymous Trace-and-Revoke Broadcast Encryption Scheme; security Analysis of End-to-End Encryption for Zoom Meetings; CCA Secure Attribute-Hiding Inner Product Encryption from Minimal Assumption; optimal Randomized Partial Checking for Decryption Mix Nets; a Novel Proof of Shuffle: Exponentially Secure Cut-and-Choose; Private Decision Tree Evaluation with Constant Rounds via (Only) Fair SS-4PC; partially-Fair Computation from Timed-Release Encryption and Oblivious Transfer; concise Mercurial Subvector Commitments: Definitions and Constructions; a Secure Cross-Shard View-Change Protocol for Sharding Blockchains; Chosen Ciphertext Secure Functional Encryption from Constrained Witness PRF; efficient Unique Ring Signature for Blockchain Privacy Protection; Redactable Transactions in Consortium Blockchain: Controlled by Multi-authority CP-ABE; transparency or Anonymity Leak: Monero Mining Pools Data Publication; mind the Scraps: Attacking Blockchain Based on Selfdestruct; a Blockchain-Enabled Federated Learning Model for Privacy Preservation: System Design; ALRS: An Adversarial Noise Based Privacy-Preserving Data Sharing Mechanism; non-interactive, Secure Verifiable Aggregation for Decentralized, Privacy-Preserving Learning; towards Visualizing and Detecting Audio Adversarial Examples for Automatic Speech Recognition; oriole: Thwarting Privacy Against Trustworthy Deep Learning Models; puncturable Identity-Based Encryption from Lattices; Updatable Trapdoor SPHFs: Modular Construction of Updatable Zero-Knowledge Arguments and More; Optimizing Bootstrapping and Evaluating Large FHE Gates in the LWE-Based GSW-FHE; forward-Secure Group Encryptions from Lattices; anonymous Lattice Identity-Based Encryption with Traceable Identities; lattice-Based Secure Biometric Authentication for Hamming Distance; A Trustless GQ Multi-signature Scheme with Identifiable Abort; Verifiable Obtained Random Subsets for Improving SPHINCS+ ; small Superset and Big Subset Obfuscation; algebraic Attacks on Round-Reduced Keccak.",,,,,,,,,Baek J.Ruj S.,,Springer Science and Business Media Deutschland GmbH,"26th Australasian Conference on Information Security and Privacy, ACISP 2021",1 December 2021 through 3 December 2021,,268279,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Review,Final,,Scopus,2-s2.0-85120041079
"Khong T.T.T., Nakada T., Nakashima Y.",57223041718;57203068390;7201863420;,Flexible Bayesian inference by weight transfer for robust deep neural networks,2021,IEICE Transactions on Information and Systems,E104D,11,,1981,1991,,,10.1587/transinf.2021EDP7046,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119427955&doi=10.1587%2ftransinf.2021EDP7046&partnerID=40&md5=ae40bbf89e93ac8b3abc378ac90c5c44,"Nara Institute of Science and Technology, Ikoma-shi, 630–0192, Japan","Khong, T.T.T., Nara Institute of Science and Technology, Ikoma-shi, 630–0192, Japan; Nakada, T., Nara Institute of Science and Technology, Ikoma-shi, 630–0192, Japan; Nakashima, Y., Nara Institute of Science and Technology, Ikoma-shi, 630–0192, Japan","Adversarial attacks are viewed as a danger to Deep Neural Networks (DNNs), which reveal a weakness of deep learning models in security-critical applications. Recent findings have been presented adversarial training as an outstanding defense method against adversaries. Nonetheless, adversarial training is a challenge with respect to big datasets and large networks. It is believed that, unless making DNN architectures larger, DNNs would be hard to strengthen the robustness to adversarial examples. In order to avoid iteratively adversarial training, our algorithm is Bayes without Bayesian Learning (BwoBL) that performs the ensemble inference to improve the robustness. As an application of transfer learning, we use learned parameters of pretrained DNNs to build Bayesian Neural Networks (BNNs) and focus on Bayesian inference without costing Bayesian learning. In comparison with no adversarial training, our method is more robust than activation functions designed to enhance adversarial robustness. Moreover, BwoBL can easily integrate into any pretrained DNN, not only Convolutional Neural Networks (CNNs) but also other DNNs, such as Self-Attention Networks (SANs) that outperform convolutional counterparts. BwoBL is also convenient to apply to scaling networks, e.g., ResNet and EfficientNet, with better performance. Especially, our algorithm employs a variety of DNN architectures to construct BNNs against a diversity of adversarial attacks on a large-scale dataset. In particular, under l∞ norm PGD attack of pixel perturbation ϵ = 4/255 with 100 iterations on ImageNet, our proposal in ResNets, SANs, and EfficientNets increase by 58.18% top-5 accuracy on average, which are combined with naturally pretrained ResNets, SANs, and EfficientNets. This enhancement is 62.26% on average below l2 norm C&amp;W attack. The combination of our proposed method with pretrained EfficientNets on both natural and adversarial images (EfficientNet-ADV) drastically boosts the robustness resisting PGD and C&amp;W attacks without additional training. Our EfficientNet-ADVB7 achieves the cutting-edge top-5 accuracy, which is 92.14% and 94.20% on adversarial ImageNet generated by powerful PGD and C&amp;W attacks, respectively. Copyright © 2021 The Institute of Electronics, Information and Communication Engineers",Adversarial attacks; Adversarial training; Bayesian neural network; Deep neural network; Image classification,Bayesian networks; Convolution; Convolutional neural networks; Image classification; Inference engines; Iterative methods; Large dataset; Network architecture; Adversarial attack; Adversarial training; Bayesian inference; Bayesian learning; Bayesian neural networks; Images classification; Learning models; Neural network architecture; Security critical applications; Weight transfer; Deep neural networks,,,,,"Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) 2nd Int. Conf. Learning Representations - ICLR 2014, pp. 1-10. , arXiv:1312.6199; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) 3rd Int. Conf. Learning Representations - ICLR 2015, pp. 1-11. , arXiv:1412.6572; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2018) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 9185-9193; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP), pp. 39-57. , IEEE; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) 6th Int. Conf. Learning Representations - ICLR 2018, pp. 1-28. , arXiv:1706.06083; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proc. 2017 ACM on Asia Conf. Computer and Communications Security, pp. 506-519. , April; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) 2016 IEEE Symposium on Security and Privacy (SP), pp. 582-597. , IEEE; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) Proc. 10th ACM Workshop on Artificial Intelligence and Security, pp. 3-14. , Nov; Dhillon, G.S., Azizzadenesheli, K., Lipton, Z.C., Bernstein, J., Kossaifi, J., Khanna, A., Anandkumar, A., Stochastic activation pruning for robust adversarial defense (2018) ICLR 2018, pp. 1-13. , arXiv preprint arXiv:1803.01442; Zhang, H., Weng, T.W., Chen, P.Y., Hsieh, C.J., Daniel, L., Efficient neural network robustness certification with general activation functions (2018) Advances in Neural Information Processing Systems NIPS, pp. 4939-4948; Rozsa, A., Boult, T.E., (2019) Improved adversarial robustness by reducing open space risk via tent activations, pp. 1-15. , arXiv preprint arXiv:1908.02435; Wang, B., Lin, A., Yin, P., Zhu, W., Bertozzi, A.L., Osher, S.J., Adversarial defense via the data-dependent activation, total variation minimization, and adversarial training (2020) Inverse Problems & Imaging, 15 (1), p. 129. , Feb; Tavakoli, M., Agostinelli, F., Baldi, P., Splash: Learnable activation functions for improving accuracy and adversarial robustness (2021) Neural Networks, 140, pp. 1-12. , Aug; Ye, N., Zhu, Z., Bayesian adversarial learning (2018) Proc. 32nd Int. Conf. Neural Information Processing Systems, pp. 6892-6901; Liu, X., Cheng, M., Zhang, H., Hsieh, C.J., Towards robust neural networks via random self-ensemble (2018) Proc. European Conf. Comput. Vis. (ECCV), pp. 369-385; Liu, X., Li, Y., Wu, C., Hsieh, C.J., Adv-bnn: Improved adversarial defense through robust bayesian neural network (2019) 7th Int. Conf. Learning Representations, pp. 21-29; Khong, T.T.T., Nakada, T., Nakashima, Y., Bayes without bayesian learning for resisting adversarial attacks (2020) 2020 Eighth Int. Symp. Computing and Networking (CANDAR), pp. 221-227; Bishop, C.M., (1995) Bayesian methods for neural networks, , Technical report, Aston University, Birmingham; Neal, R.M., (2012) Bayesian learning for neural networks, , Springer Science & Business Media; Blundell, C., Cornebise, J., Kavukcuoglu, K., Wierstra, D., Weight uncertainty in neural networks (2015) 32nd Int. Conf. Machine Learning, JMLR: W&CP, pp. 1-10. , arXiv:1505.05424; Barber, D., Bishop, C.M., Ensemble learning in bayesian neural networks (1998) Nato ASI Series F Computer and Systems Sciences, 168, pp. 215-238; Gal, Y., Ghahramani, Z., (2015) Bayesian convolutional neural networks with bernoulli approximate variational inference, pp. 1-12. , arXiv preprint arXiv:1506.02158; Adversarial example generation, , https://pytorch.org/tutorials/beginner/fgsmtutorial.html, [Online], Available; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2016) 5th Int. Conf. Learning Representations, ICLR 2017 - Workshop Track Proceedings, pp. 1-14. , arXiv:1607.02533; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) 2016 IEEE European symposium on security and privacy (EuroS&P), pp. 372-387. , IEEE; Zantedeschi, V., Nicolae, M.I., Rawat, A., Efficient defenses against adversarial attacks (2017) Proc. 10th ACM Workshop on Artificial Intelligence and Security, pp. 39-49. , Nov; Xie, C., Wu, Y., Maaten, L.v.d., Yuille, A.L., He, K., Feature denoising for improving adversarial robustness (2019) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 501-509; Shafahi, A., Najibi, M., Ghiasi, A., Xu, Z., Dickerson, J., Studer, C., Davis, L.S., Goldstein, T., Adversarial training for free! (2019) Advances in Neural Information Processing Systems, pp. 3358-3369; Wong, E., Rice, L., Kolter, J.Z., Fast is better than free: Revisiting adversarial training 8th Int. Conf. Learning Representations, ICLR 2020, pp. 1-17. , arXiv:2001.03994, 2020; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2017) 5th Int. Conf. Learning Representations - ICLR 2017, pp. 1-17. , arXiv:1611.01236; Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2018) 6th Int. Conf. Learning Representations, ICLR 2018, pp. 1-22. , arXiv:1705.07204; Wang, S., Manning, C., Fast dropout training (2013) International Conf. Mach. Learn., JMLR: W&CP, pp. 118-126. , June; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 770-778; Tan, M., Le, Q.V., Efficientnet: Rethinking model scaling for convolutional neural networks (2019) 36th Int. Conf. Machine Learning, ICML 2019, pp. 10691-10700; Torchvision models, , https://pytorch.org/docs/stable/torchvision/models.html, [Online], Available; Efficientnet pytorch, , https://github.com/lukemelas/EfficientNet-PyTorch, [Online], Available; Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, L., Polosukhin, I., Attention is all you need (2017) 31st Conf. Neural Information Processing Systems (NIPS 2017), pp. 1-15. , arXiv:1706.03762; Wang, F., Jiang, M., Qian, C., Yang, S., Li, C., Zhang, H., Wang, X., Tang, X., Residual attention network for image classification (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 3156-3164; Zhang, H., Goodfellow, I., Metaxas, D., Odena, A., Self-attention generative adversarial networks (2019) International Conf. Mach. Learn, pp. 7354-7363. , PMLR; Ramachandran, P., Parmar, N., Vaswani, A., Bello, I., Levskaya, A., Shlens, J., (2019) Stand-alone self-attention in vision models, , arXiv preprint arXiv:1906.05909; Zhao, H., Jia, J., Koltun, V., Exploring self-attention for image recognition (2020) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit, pp. 10076-10085; Xie, C., Tan, M., Gong, B., Wang, J., Yuille, A.L., Le, Q.V., Adversarial examples improve image recognition (2020) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit, pp. 819-828; Ding, G.W., Wang, L., Jin, X., (2019) Advertorch v0.1: An adversarial robustness toolbox based on pytorch, pp. 1-6. , arXiv preprint arXiv:1902.07623; Wan, Q., Fu, X., Fast-bcnn: Massive neuron skipping in bayesian convolutional neural networks (2020) 2020 53rd Annual IEEE/ACM Int. Symp. Microarchitecture (MICRO), pp. 229-240. , IEEE","Khong, T.T.T.; Nara Institute of Science and TechnologyJapan; 电子邮件: khong.thithuthao.ko3@is.naist.jp",,,Institute of Electronics Information Communication Engineers,,,,,9168532,,ITISE,,English,IEICE Trans Inf Syst,Article,Final,"All Open Access, Bronze",Scopus,2-s2.0-85119427955
"Teng X., Zhang H., Li B., Yang C., Zhao X.",57337305100;56979581400;57222069255;57336885000;24829651200;,Generation of Environment-Irrelevant Adversarial Digital Camouflage Patterns,2021,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),13031 LNAI,,,336,346,,,10.1007/978-3-030-89188-6_25,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119019095&doi=10.1007%2f978-3-030-89188-6_25&partnerID=40&md5=3b2bd1b196b2c4f86e487cfdfa25fd6c,"School of Computer Science and Technology, Southwest University of Science and Technology, Sichuan, Mianyang, 621010, China; School of Science, Southwest University of Science and Technology, Sichuan, Mianyang, 621010, China","Teng, X., School of Computer Science and Technology, Southwest University of Science and Technology, Sichuan, Mianyang, 621010, China; Zhang, H., School of Science, Southwest University of Science and Technology, Sichuan, Mianyang, 621010, China; Li, B., School of Computer Science and Technology, Southwest University of Science and Technology, Sichuan, Mianyang, 621010, China; Yang, C., School of Computer Science and Technology, Southwest University of Science and Technology, Sichuan, Mianyang, 621010, China; Zhao, X., School of Computer Science and Technology, Southwest University of Science and Technology, Sichuan, Mianyang, 621010, China","Digital camouflage is the most common and effective means to combat military reconnaissance. Traditional digital camouflage generation methods must regenerate camouflage images according to the current environment. When the environment changes, generated camouflage images may be detected by neural network classification models. We present a digital camouflage generation model based on disentangled representation, which can decompose images into a content space and a style space, thereby recombining the current content of the environment image with different digital camouflage styles. When the environment changes, our model can generate digital camouflage images based on the original environment content and the corresponding digital camouflage style, without obtaining the current environment image. To counter the detection of the classification models, we design a category reordering function to mislead the classification result of the classification model. Experiments show that the proposed method can generate digital camouflage images in different seasons and successfully implement an adversarial attack on the classification model. © 2021, Springer Nature Switzerland AG.",Adversarial attack; Camouflage generation; Disentangled representation; Style transfer,Neural networks; 'current; Adversarial attack; Camouflage generation; Classification models; Disentangled representation; Environment change; Generation method; Military reconnaissance; Neural network classification; Style transfer; Computers,,,,,"Cuthill, I.C., (2019) Camouflage. J. Zool., 308 (2), pp. 75-92; Zhuo, L., Chen, X.Q., Xie, Z.P., Jiang, X.J., Bi, D.K., Simulation learning method for discovery of camouflage targets based on deep neural networks (2019) Laser Optoelectron. Progress, 56 (7); Yang, X., Xu, W.D., Jia, Q., Li, L., Research on digital camouflage pattern generation algorithm based on adversarial autoencoder network (2020) Int. J. Pattern Recogn. Artif. Intell., 34 (6); Yang, X., Research on extraction and reproduction of deformation camouflage spots based on generative adversarial network model (2020) Defence Technol, 16 (3), pp. 555-563; Alfimtsev, A.N., Sakulin, S.A., Loktev, D.A., Kovalenko, A.O., Devyatkov, V.V., Hostis humani ET mashinae: Adversarial camouflage generation (2019) J. Adv. Res. Dyn. Control Syst., 11 (2), pp. 506-516; Zheng, Y., Zhang, X., Wang, F., Cao, T., Sun, M., Wang, X., Detection of people with camouflage pattern via dense deconvolution network (2018) IEEE Signal Process. Lett., 26 (1), pp. 29-33; Mathieu, M., Zhao, J., Sprechmann, P., Ramesh, A., Lecun, Y., (2016) Disentangling Factors of Variation in Deep Representations Using Adversarial Training, , NeurIPS; Gatys, L., Ecker, A.S., Bethge, M., (2015) Texture Synthesis Using Convolutional Neural Networks, , NeurIPS; Gatys, L.A., Ecker, A.S., Bethge, M., Image style transfer using convolutional neural networks (2016) CVPR; Huang, X., Liu, M.-Y., Belongie, S., Kautz, J., Multimodal unsupervised image-to-image translation (2018) ECCV 2018. LNCS, Vol. 11207, pp. 179-196. , https://doi.org/10.1007/978-3-030-01219-9_11, Ferrari, V., Hebert, M., Sminchisescu, C., Weiss, Y. (eds.), pp. , Springer, Cham; Lee, H.-Y., Tseng, H.-Y., Huang, J.-B., Singh, M., Yang, M.-H., Diverse image-to-image translation via disentangled representations (2018) ECCV 2018. LNCS, Vol. 11205, pp. 36-52. , https://doi.org/10.1007/978-3-030-01246-5_3, Ferrari, V., Hebert, M., Sminchisescu, C., Weiss, Y. (eds.), pp. , Springer, Cham; Szegedy, C., (2014) Intriguing Properties of Neural Networks, , ICLR; Simonyan, K., Zisserman, A., (2015) Very Deep Convolutional Networks for Large-Scale Image Recognition, , ICLR; Zhu, J.Y., Park, T., Isola, P., Efros, A.A., Unpaired image-to-image translation using cycle-consistent adversarial networks (2017) ICCV; Wang, Z., Bovik, A.C., Sheikh, H.R., Simoncelli, E.P., Image quality assessment: From error visibility to structural similarity (2004) IEEE Trans. Image Process., 13 (4), pp. 600-612","Zhang, H.; School of Science, Sichuan, China; 电子邮件: zhanghui@swust.edu.cn",Pham D.N.Theeramunkong T.Governatori G.Liu F.,,Springer Science and Business Media Deutschland GmbH,"18th Pacific Rim International Conference on Artificial Intelligence, PRICAI 2021",8 November 2021 through 12 November 2021,,267459,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,,Scopus,2-s2.0-85119019095
"Zanddizari H., Zeinali B., Chang J.M.",57202137057;56898964700;57298070100;,Generating Black-Box Adversarial Examples in Sparse Domain,2021,IEEE Transactions on Emerging Topics in Computational Intelligence,,,,,,,,10.1109/TETCI.2021.3122467,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118679531&doi=10.1109%2fTETCI.2021.3122467&partnerID=40&md5=3b949e638916f48ce077af25ddf7c52f,"Department of Electrical Engineering, University of South Florida, Tampa, FL 33620 USA (e-mail: hadiz@usf.edu).; Department of Electrical Engineering, University of South Florida, Tampa, FL 33620 USA (e-mail: behnamz@usf.edu).; Department of Electrical Engineering, University of South Florida, Tampa, FL 33620 USA (e-mail: chang5@usf.edu).","Zanddizari, H., Department of Electrical Engineering, University of South Florida, Tampa, FL 33620 USA (e-mail: hadiz@usf.edu).; Zeinali, B., Department of Electrical Engineering, University of South Florida, Tampa, FL 33620 USA (e-mail: behnamz@usf.edu).; Chang, J.M., Department of Electrical Engineering, University of South Florida, Tampa, FL 33620 USA (e-mail: chang5@usf.edu).","Applications of machine learning (ML) models and convolutional neural networks (CNNs) have been rapidly increased. Although state-of-the-art CNNs provide high accuracy in many applications, recent investigations show that such networks are highly vulnerable to adversarial attacks. The black-box adversarial attack is one type of attack that the attacker does not have any knowledge about the model or the training dataset, but it has some input data set and their labels. In this paper, we propose a novel approach to generate a black-box attack in sparse domain whereas the most important information of an image can be observed. Our investigation shows that large sparse (LaS) components play a critical role in the performance of image classifiers. Under this presumption, to generate adversarial example, we transfer an image into a sparse domain and put a threshold to choose only <formula><tex>$k$</tex></formula> LaS components. In contrast to the very recent works that randomly perturb <formula><tex>$k$</tex></formula> low frequency (LoF) components, we perturb <formula><tex>$k$</tex></formula> LaS components either randomly (query-based) or in the direction of the most correlated sparse signal from a different class. We show that LaS components contain some middle or higher frequency components information which leads fooling image classifiers with a fewer number of queries. We demonstrate the effectiveness of this approach by fooling six state-of-the-art image classifiers, the TensorFlow Lite (TFLite) model of Google Cloud Vision platform, and YOLOv5 model as an object detection algorithm. Mean squared error (MSE) and peak signal to noise ratio (PSNR) are used as quality metrics. We also present a theoretical proof to connect these metrics to the level of perturbation in the sparse domain. IEEE",Adaptation models; black-box attack; Computational modeling; Convolutional neural network; deep learning; Dictionaries; Discrete cosine transforms; Frequency-domain analysis; Perturbation methods; sparse representation; Training,,,,,,,,,,Institute of Electrical and Electronics Engineers Inc.,,,,,2471285X,,,,English,IEEE Trans. Emerging Topics Comp. Intell.,Article,Article in Press,"All Open Access, Green",Scopus,2-s2.0-85118679531
"Fan Y., Li Y., Cui H., Yang H., Zhang Y., Wang W.",57218847424;57224744826;57192212989;57207949350;57214252546;57272010000;,An Intrusion Detection Framework for IoT Using Partial Domain Adaptation,2021,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),13005 LNCS,,,36,50,,,10.1007/978-3-030-89137-4_3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118117887&doi=10.1007%2f978-3-030-89137-4_3&partnerID=40&md5=3883635e03fa81bac0bb8c8ebb45154f,"Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China","Fan, Y., Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China, School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; Li, Y., Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China, School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; Cui, H., Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Yang, H., Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Zhang, Y., Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China, School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; Wang, W., Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China, School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China","With the rapid development of the Internet of Things (IoT), the security problem of IoT is becoming increasingly prominent. Deep learning (DL) has achieved success in network intrusion detection systems (NIDS) for IoT. Its capability of automatically extracting high-dimensional features from data and finding the association between data make it easy to identify abnormal activity from network traffic. However, DL method requires a large amount of labeled data, which is very time-consuming and expensive. Due to the privacy of IoT data, it is hard to collect enough data to train models. Also, the heterogeneity of IoT makes the NID model trained from the data collected from one IoT unable to be directly applied to another one. To address the problem, domain adaptation (DA) has been used by transferring the knowledge from the domain with huge amounts of labeled data to the domain with less or unlabeled data. However, previous DA methods generally assume the same label spaces between source and target domain, which is not feasible in a complex real environment of IoT. In this paper, we propose a NID framework using a weighted adversarial nets-based partial domain adaptation method to address this problem of inconsistent label spaces by mapping two domains to a domain-invariant feature space. The proposal can train a highly accurate NID model through the knowledge transfer from the abundant public labeled dataset of the traditional Internet to the unlabeled dataset of IoT. In addition, the proposed scheme can detect unknown attacks in the IoT with the help of knowledge from the traditional Internet. Moreover, the proposed scheme is an online NID detection which is more suitable for real IoT application. The experiments results demonstrate that our proposed scheme can achieve a good performance to detect attacks. © 2021, Springer Nature Switzerland AG.",Intrusion detection; IoT; Partial domain adaptation,Deep learning; Internet of things; Knowledge management; Adaptation methods; Detection framework; Domain adaptation; In networks; Intrusion-Detection; Label space; Labeled data; Network intrusion detection systems; Partial domain adaptation; Security problems; Intrusion detection,,,,,"Gubbi, J., Buyya, R., Marusic, S., Palaniswami, M., Internet of Things (IoT): A vision, architectural elements, and future directions (2013) Futur. Gener. Comput. Syst., 29 (7), pp. 1645-1660; Chaabouni, N., Network intrusion detection for IoT security based on learning techniques (2019) IEEE Commun. Surv. Tutor., 21 (3), pp. 2671-2701; Tavallaee, M., Bagheri, E., Lu, W., Ghorbani, A.A., A detailed analysis of the KDD CUP 99 data set (2009) Proceedings of the Second IEEE Symposium on Computational Intelligence for Security and Defence Applications, pp. 1-6. , pp; Lippmann, R., Haines, J.W., Fried, D.J., Korba, J., Das, K., DARPA off-line intrusion detection evaluation (2000) Comput. Netw., 34 (4), pp. 579-595; Bostani, H., Sheikhan, M., Hybrid of anomaly-based and specification-based IDS for Internet of Things using unsupervised OPF based on MapReduce approach (2017) Comput. Commun., 98, pp. 52-71; Pajouh, H.H., A two-layer dimension reduction and two-tier classification model for anomaly-based intrusion detection in IoT backbone networks (2016) IEEE Trans. Emerg. Top. Comput., 7, pp. 314-323; Lopez-Martin, M., Carro, B., Sanchez-Esguevillas, A., Lloret, J., Conditional vari-ational autoencoder for prediction and feature recovery applied to intrusion detection in IoT (2017) Sensors, 17 (9), p. 1967; Mirsky, Y., Doitshman, T., Elovici, Y., Shabtai, A., (2018) Kitsune: An Ensemble of Autoencoders for Online Network Intrusion Detection. Arxiv Preprint Arxiv, 1802, p. 09089; Hodo, E., Threat analysis of IoT networks using artificial neural network intrusion detection system (2016) 2016 International Symposium on Networks, Computers and Communications (ISNCC), Pp. 1–6. IEEE; Zhao, J., Shetty, S., Pan, J.W., Feature-based transfer learning for network security (2017) MILCOM 2017-2017 IEEE Military Communications Conference; Zhao, J., Shetty, S., Pan, J.W., Kamhoua, C., Kwiat, K., Transfer learning for detecting unknown network attacks. EURASIP J. Inf. Secur. 2019 (2019) Article No, p. 1; Singla, A., Bertino, E., Verma, D., Preparing network intrusion detection deep learning models with minimal data using adversarial domain adaptation (2020) The 15Th ACM Asia Conference on Computer and Communications Security, pp. 127-140. , pp; Pan, S.J., Yang, Q., A survey on transfer learning (2009) IEEE Trans. Knowl. Data Eng., 22 (10), pp. 1345-1359; Wang, M., Deng, W., Deep visual domain adaptation: A survey (2018) Neurocomputing, 312, pp. 135-153; Tzeng, E., Hoffman, J., Zhang, N., Saenko, K., Darrell, T., (2014) Deep Domain Confusion: Maximizing for Domain Invariance, , arXiv preprint arXiv; Ben-David, S., A theory of learning from different domains (2010) Mach. Learn., 79 (1), pp. 151-175; Sun, B., Saenko, K.: Deep CORAL: correlation alignment for deep domain adaptation. In: Hua, G., Jégou, H. (eds.) ECCV 2016. LNCS, vol. 9915, pp. 443–450. Springer, Cham (2016). https://doi.org/10.1007/978-3-319-49409-8 35; Fan, C., A review of deep domain adaptation: General situation and complex situation (2020) Acta Automatica Sinica, 46, pp. 1-34; Zhang, J., Ding, Z.W., Li, W.Q., Ogunbona, P., Importance weighted adversarial nets for partial domain adaptation (2018) IEEE Conference on Computer Vision and Pattern Recognition; Ganin, Y., Domain-adversarial training of neural networks (2016) J. Mach. Learn. Res., 17 (1), pp. 2096-2030; Goodfellow, I., Generative adversarial nets (2014) Advances in Neural Information Processing Systems; Sharafaldin, I., Habibi Lashkari, A., Ghorbani, A.A., Toward generating a new intrusion detection dataset and intrusion traffic characterization (2018) 4Th International Conference on Information Systems Security and Privacy (ICISSP); Palatucci, M., Pomerleau, D., Hinton, G.E., Mitchell, T.M., Zero-shot learning with semantic output codes (2009) 23Rd Annual Conference on Neural Information Processing Systems, pp. 1401-1408. , pp","Fan, Y.; Institute of Information Engineering, China; 电子邮件: fanyulin@iie.ac.cn",Lu W.Sun K.Yung M.Liu F.,,Springer Science and Business Media Deutschland GmbH,"3rd International Conference on Science of Cyber Security, SciSec 2021",13 August 2021 through 15 August 2021,,266909,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,,Scopus,2-s2.0-85118117887
"Marulli F., Verde L., Campanile L.",35190759500;56902382400;57207770179;,Exploring data and model poisoning attacks to deep learning-based NLP systems,2021,Procedia Computer Science,192,,,3570,3579,,1,10.1016/j.procs.2021.09.130,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116922484&doi=10.1016%2fj.procs.2021.09.130&partnerID=40&md5=bdd9c6e94db10582de39cd67012dfa4c,"Department of Maths and Physics, Università degli Studi della CampaniaL. Vanvitelli, Caserta, Italy","Marulli, F., Department of Maths and Physics, Università degli Studi della CampaniaL. Vanvitelli, Caserta, Italy; Verde, L., Department of Maths and Physics, Università degli Studi della CampaniaL. Vanvitelli, Caserta, Italy; Campanile, L., Department of Maths and Physics, Università degli Studi della CampaniaL. Vanvitelli, Caserta, Italy","Natural Language Processing (NLP) is being recently explored also to its application in supporting malicious activities and objects detection. Furthermore, NLP and Deep Learning have become targets of malicious attacks too. Very recent researches evidenced that adversarial attacks are able to affect also NLP tasks, in addition to the more popular adversarial attacks on deep learning systems for image processing tasks. More precisely, while small perturbations applied to the data set adopted for training typical NLP tasks (e.g., Part-of-Speech Tagging, Named Entity Recognition, etc..) could be easily recognized, models poisoning, performed by the means of altered data models, typically provided in the transfer learning phase to a deep neural networks (e.g., poisoning attacks by word embeddings), are harder to be detected. In this work, we preliminary explore the effectiveness of a poisoned word embeddings attack aimed at a deep neural network trained to accomplish a Named Entity Recognition (NER) task. By adopting the NER case study, we aimed to analyze the severity of such a kind of attack to accuracy in recognizing the right classes for the given entities. Finally, this study represents a preliminary step to assess the impact and the vulnerabilities of some NLP systems we adopt in our research activities, and further investigating some potential mitigation strategies, in order to make these systems more resilient to data and models poisoning attacks. © 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (https://creativecommons.org/licenses/by-nc-nd/4.0) Peer-review under responsibility of the scientific committee of KES International.",Data poisoning attacks; Deep learning vulnerabilities; Natural language processing; Poisoned word embeddings; Reliable machine learning,Computational linguistics; Deep neural networks; Embeddings; Object detection; Speech recognition; Activity detection; Data poisoning attack; Deep learning vulnerability; Embeddings; ITS applications; Malicious activities; Named entity recognition; Poisoned word embedding; Poisoning attacks; Reliable machine learning; Natural language processing systems,,,,,"Bojanowski, P., Grave, E., Joulin, A., Mikolov, T., Enriching word vectors with subword information (2017) Transactions of the Association for Computational Linguistics, 5, pp. 135-146; Burkart, N., Huber, M.F., A survey on the explainability of supervised machine learning (2021) Journal of Artificial Intelligence Research, 70, pp. 245-317; Carlini, N., Terzis, A., (2021) Poisoning and Backdooring Contrastive Learning; Chen, X., Liu, C., Li, B., Lu, K., Song, D., (2017) Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning; Daelemans, W., Explanation in computational stylometry (2013) International Conference on Intelligent Text Processing and Computational Linguistics, pp. 451-462. , Springer; Dai, J., Chen, C., Li, Y., A backdoor attack against lstm-based text classification systems (2019) IEEE Access, 7, pp. 138872-138878; De Mauro, T., Chiari, I., Il nuovo vocabolario di base della lingua italiana (2016) Internazionale, , https://www.internazionale.it/opinione/tullio-de-mauro/2016/12/23/il-nuovo-vocabolario-di-base-della-lingua-italiana, 28/11/2020; Devlin, J., Chang, M.W., Lee, K., Toutanova, K., (2018) Bert: Pre-Training of Deep Bidirectional Transformers for Language Understanding; Di Martino, B., Marulli, F., Lupi, P., Cataldi, A., A machine learning based methodology for automatic annotation and anonymisation of privacy-related items in textual documents for justice domain (2020) Conference on Complex, Intelligent, and Software Intensive Systems, pp. 530-539. , Springer; Gao, Y., Doan, B.G., Zhang, Z., Ma, S., Zhang, J., Fu, A., Nepal, S., Kim, H., (2020) Backdoor Attacks and Countermeasures on Deep Learning: A Comprehensive Review; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial networks (2020) Communications of the ACM, 63, pp. 139-144; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Jia, R., Liang, P., (2017) Adversarial Examples for Evaluating Reading Comprehension Systems; Kurita, K., Michel, P., Neubig, G., (2020) Weight Poisoning Attacks on Pre-Trained Models; Li, J., Sun, A., Han, J., Li, C., A survey on deep learning for named entity recognition (2020) IEEE Transactions on Knowledge and Data Engineering; Li, P.H., Dong, R.P., Wang, Y.S., Chou, J.C., Ma, W.Y., Leveraging linguistic structures for named entity recognition with bidirectional recursive neural networks (2017) Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pp. 2664-2669; Martinelli, F., Marulli, F., Mercaldo, F., Marrone, S., Santone, A., Enhanced privacy and data protection using natural language processing and artificial intelligence (2020) 2020 International Joint Conference on Neural Networks (IJCNN), pp. 1-8; Marulli, F., Pota, M., Esposito, M., A comparison of character and word embeddings in bidirectional lstms for pos tagging in Italian (2018) International Conference on Intelligent Interactive Multimedia Systems and Services, pp. 14-23. , Springer; Mikolov, T., Chen, K., Corrado, G., Dean, J., (2013) Efficient Estimation of Word Representations in Vector Space; Muñoz-González, L., Biggio, B., Demontis, A., Paudice, A., Wongrassamee, V., Lupu, E.C., Roli, F., Towards poisoning of deep learning algorithms with back-gradient optimization (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 27-38; Pennington, J., Socher, R., Manning, C.D., Glove: Global vectors for word representation (2014) Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 1532-1543; Sun, M., Tang, J., Li, H., Li, B., Xiao, C., Chen, Y., Song, D., (2018) Data Poisoning Attack against Unsupervised Node Embedding Methods; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks; Wallace, E., Zhao, T., Feng, S., Singh, S., Concealed data poisoning attacks on nlp models (2021) Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 139-150; Wang, S., Nepal, S., Rudolph, C., Grobler, M., Chen, S., Chen, T., Backdoor attacks against transfer learning with pre-trained deep learning models (2020) IEEE Transactions on Services Computing; Yang, W., Li, L., Zhang, Z., Ren, X., Sun, X., He, B., (2021) Be Careful about Poisoned Word Embeddings: Exploring the Vulnerability of the Embedding Layers in Nlp Models; Zhang, W.E., Sheng, Q.Z., Alhazmi, A., Li, C., Adversarial attacks on deep-learning models in natural language processing: A survey (2020) ACM Transactions on Intelligent Systems and Technology (TIST), 11, pp. 1-41; Zhao, Z., Dua, D., Singh, S., (2017) Generating Natural Adversarial Examples","Marulli, F.; Department of Maths and Physics, Italy; 电子邮件: fiammetta.marulli@unicampania.it",Watrobski J.Salabun W.Toro C.Zanni-Merk C.Howlett R.J.Jain L.C.Jain L.C.,,Elsevier B.V.,"25th KES International Conference on Knowledge-Based and Intelligent Information and Engineering Systems, KES 2021",8 September 2021 through 10 September 2021,,172181,18770509,,,,English,Procedia Comput. Sci.,Conference Paper,Final,"All Open Access, Gold",Scopus,2-s2.0-85116922484
"Zhang Y., Wang Z., Zhang B., Wen Y., Meng D.",57211268232;55498125600;57221047969;56421083900;55308382800;,Black-Box Buster: A Robust Zero-Shot Transfer-Based Adversarial Attack Method,2021,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),12919 LNCS,,,39,54,,,10.1007/978-3-030-88052-1_3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116013213&doi=10.1007%2f978-3-030-88052-1_3&partnerID=40&md5=0a3b0f8ffba86dec222a7563c54c89b8,"Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China","Zhang, Y., Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China, School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; Wang, Z., Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China, School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; Zhang, B., Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Wen, Y., Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Meng, D., Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China","Recent black-box adversarial attacks can take advantage of transferable adversarial examples generated by a similar substitute model to successfully fool the target model. However, these substitute models are either pre-trained models or trained with the target model’s training examples, which is hard to obtain because of the security and privacy of training data. In this paper, we proposed a zero-shot adversarial black-box attack method that can generate high-quality training examples for the substitute models, which are balanced among the classification labels and close to the distribution of the real training examples of the target models. The experiments demonstrate the effectiveness of our method that significantly improves the non-target black-box attack success rate around 20%–30% of the adversarial examples generated by the substitute models. © 2021, Springer Nature Switzerland AG.",Adversarial attack; Substitute model; Zero data,Computers; Adversarial attack; Attack methods; Black boxes; High quality; Security and privacy; Substitute model; Target model; Training data; Training example; Zero data; Artificial intelligence,,,,,"Athalye, A., Carlini, N., Wagner, D., Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples (2018) Proceedings of the 35Th International Conference on Machine Learning, pp. 274-283. , pp; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy (SP), pp. 39-57. , pp., 2017; Chen, J., Jordan, M.I., Wainwright, M.J., HopSkipJumpAttack: A query-efficient decision-based attack (2020) IEEE Symposium on Security and Privacy (SP), pp. 1277-1294. , pp., 2020; Chen, P.Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.J., ZOO: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) Proceedings of the 10Th ACM Workshop on Artificial Intelligence and Security, pp. 15-26. , pp; Correia-Silva, J.R., Berriel, R.F., Badue, C., de Souza, A.F., Oliveira-Santos, T., Copycat CNN: Stealing knowledge by persuading confession with random non-labeled data (2018) International Joint Conference on Neural Networks (IJCNN), pp. 1-8. , pp., 2018; Demontis, A., Why do adversarial attacks transfer? Explaining transferability of evasion and poisoning attacks (2019) 28Th USENIX Security Symposium (USENIX Security 19), pp. 321-338. , pp; Ding, G.W., Wang, L., Jin, X., (2019) Advertorch V0.1: An Adversarial Robustness Toolbox Based on Pytorch, , CoRR; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2018) IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 9185-9193. , pp., 2018; Goodfellow, I., Generative adversarial networks (2014) Advances in Neural Information Processing Systems, 3; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) 3Rd International Conference on Learning Representations ICLR; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 770-778. , pp., 2016; Huang, Q., Katsman, I., Gu, Z., He, H., Belongie, S., Lim, S.N., Enhancing adversarial example transferability with an intermediate level attack (2019) IEEE/CVF International Conference on Computer Vision (ICCV), pp. 4732-4741. , pp., 2019; Krizhevsky, A., Hinton, G., Learning multiple layers of features from tiny images (2009) Technical Report, 1; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial examples in the physical world (2017) 5Th International Conference on Learning Representations ICLR, Workshop Track Proceedings; Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) 5Th International Conference on Learning Representations ICLR; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) 6Th International Conference on Learning Representations ICLR; Orekondy, T., Schiele, B., Fritz, M., Knockoff nets: Stealing functionality of black-box models (2019) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Pp. 4954–, 4963; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519. , pp; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) 3Rd International Conference on Learning Representations ICLR; Szegedy, C., Intriguing properties of neural networks (2014) 2Nd International Conference on Learning Representations ICLR; Tu, C., AutoZOOM: Autoencoder-based zeroth order optimization method for attacking black-box neural networks (2019) The Thirty-Third AAAI Conference on Artificial Intelligence, pp. 742-749. , pp; Zhou, M., Wu, J., Liu, Y., Liu, S., Zhu, C., DaST: Data-free substitute training for adversarial attacks (2020) IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 231-240. , pp., 2020","Wen, Y.; Institute of Information Engineering, China; 电子邮件: wenyu@iie.ac.cn",Gao D.Li Q.Guan X.Liao X.,,Springer Science and Business Media Deutschland GmbH,"23rd International Conference on Information and Communications Security, ICICS 2021",19 November 2021 through 21 November 2021,,265649,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,,Scopus,2-s2.0-85116013213
"Han W., Pang B., Wu Y.",57232271800;57217434751;56030126800;,Robust Transfer Learning with Pretrained Language Models through Adapters,2021,"ACL-IJCNLP 2021 - 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Proceedings of the Conference",2,,,854,861,,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115842016&partnerID=40&md5=084c664a3c610ab3dcd585ce0a3149ed,"Beijing Institute for General Artificial Intelligence, Beijing, China; Department of Statistics, University of California, Los Angeles, United States","Han, W., Beijing Institute for General Artificial Intelligence, Beijing, China; Pang, B., Department of Statistics, University of California, Los Angeles, United States; Wu, Y., Department of Statistics, University of California, Los Angeles, United States","Transfer learning with large pretrained transformer-based language models like BERT has become a dominating approach for most NLP tasks. Simply fine-tuning those large language models on downstream tasks or combining it with task-specific pretraining is often not robust. In particular, the performance considerably varies as the random seed changes or the number of pretraining and/or fine-tuning iterations varies, and the fine-tuned model is vulnerable to adversarial attack. We propose a simple yet effective adapter-based approach to mitigate these issues. Specifically, we insert small bottleneck layers (i.e., adapter) within each layer of a pretrained model, then fix the pretrained layers and train the adapter layers on the downstream task data, with (1) task-specific unsupervised pretraining and then (2) task-specific supervised training (e.g., classification, sequence labeling). Our experiments demonstrate that such a training scheme leads to improved stability and adversarial robustness in transfer learning to various downstream tasks. © 2021 Association for Computational Linguistics.",,Classification (of information); Transfer learning; Down-stream; Fine tuning; Language model; Performance; Pre-training; Random seeds; Sequence Labeling; Simple++; Supervised trainings; Transfer learning; Computational linguistics,,,,,"Clark, Kevin, Luong, Minh-Thang, Le, Quoc V, Manning, Christopher D, (2020) Electra: Pre-training text encoders as discriminators rather than generators, , arXiv preprint arXiv:2003.10555; Devlin, Jacob, Chang, Ming-Wei, Lee, Kenton, Toutanova, Kristina, BERT: Pre-training of deep bidirectional transformers for language understanding (2019) Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pp. 4171-4186. , Minneapolis, Minnesota. Association for Computational Linguistics; Gururangan, Suchin, Marasović, Ana, Swayamdipta, Swabha, Lo, Kyle, Beltagy, Iz, Downey, Doug, Smith, Noah A, (2020) Don't stop pretraining: Adapt language models to domains and tasks, , arXiv preprint arXiv:2004.10964; Houlsby, Neil, Giurgiu, Andrei, Jastrzebski, Stanislaw, Morrone, Bruna, De Laroussilhe, Quentin, Gesmundo, Andrea, Attariyan, Mona, Gelly, Sylvain, Parameter-efficient transfer learning for nlp (2019) International Conference on Machine Learning, pp. 2790-2799. , PMLR; Lan, Zhenzhong, Chen, Mingda, Goodman, Sebastian, Gimpel, Kevin, Sharma, Piyush, Soricut, Radu, Albert: A lite bert for self-supervised learning of language representations (2019) International Conference on Learning Representations; Lee, Cheolhyoung, Cho, Kyunghyun, Kang, andWanmo, Mixout: Effective regularization to finetune large-scale pretrained language models (2019) International Conference on Learning Representations; Lee, Jinhyuk, Yoon, Wonjin, Kim, Sungdong, Kim, Donghyeon, Kim, Sunkyu, So, Chan Ho, Kang, Jaewoo, Biobert: A pre-trained biomedical language representation model for biomedical text mining (2020) Bioinformatics, 36 (4), pp. 1234-1240; Lewis, Mike, Ghazvininejad, Marjan, Ghosh, Gargi, SidaWang, Armen, Zettlemoyer, Luke, Pre-training via paraphrasing (2020) Advances in Neural Information Processing Systems, 33; Li, Linyang, Ma, Ruotian, Guo, Qipeng, Xue, Xiangyang, Qiu, Xipeng, (2020) Bert-attack: Adversarial attack against bert using bert, , arXiv preprint arXiv:2004.09984; Liu, Hairong, Ma, Mingbo, Huang, Liang, Xiong, Hao, He, Zhongjun, Robust neural machine translation with joint textual and phonetic embedding (2019) Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pp. 3044-3049. , Florence, Italy. Association for Computational Linguistics; Moosavi-Dezfooli, Seyed-Mohsen, Fawzi, Alhussein, Frossard, Pascal, Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2574-2582; Mosbach, Marius, Andriushchenko, Maksym, Klakow, Dietrich, On the stability of fine-tuning bert: Misconceptions, explanations, and strong baselines (2020) International Conference on Learning Representations; Nguyen, Dat Quoc, Vu, Thanh, Nguyen, Anh Tuan, BERTweet: A pre-trained language model for English Tweets (2020) Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pp. 9-14; Nijkamp, Erik, Pang, Bo, Wu, Ying Nian, Xiong, Caiming, SCRIPT: Self-critic PreTraining of transformers (2021) Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 5196-5202. , Online. Association for Computational Linguistics; Peters, Matthew E, Ruder, Sebastian, Smith, Noah A, To tune or not to tune? adapting pretrained representations to diverse tasks (2019) Proceedings of the 4th Workshop on Representation Learning for NLP (RepL4NLP-2019), pp. 7-14; Pfeiffer, Jonas, Kamath, Aishwarya, Rücklé, Andreas, Cho, Kyunghyun, Gurevych, Iryna, (2020) Adapterfusion: Non-destructive task composition for transfer learning, , arXiv preprint arXiv:2005.00247; Pfeiffer, Jonas, Rücklé, Andreas, Poth, Clifton, Kamath, Aishwarya, Vulić, Ivan, Ruder, Sebastian, Cho, Kyunghyun, Gurevych, Iryna, Adapterhub: A framework for adapting transformers (2020) Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pp. 46-54. , b pages; Phang, Jason, Févry, Thibault, Bowman, Samuel R, (2018) Sentence encoders on stilts: Supplementary training on intermediate labeled-data tasks, , arXiv preprint arXiv:1811.01088; Raffel, Colin, Shazeer, Noam, Roberts, Adam, Lee, Katherine, Narang, Sharan, Matena, Michael, Zhou, Yanqi, Liu, Peter J, Exploring the limits of transfer learning with a unified text-to-text transformer (2020) Journal of Machine Learning Research, 21 (140), pp. 1-67; Ren, Shuhuai, Deng, Yihe, He, Kun, Che, Wanxiang, Generating natural language adversarial examples through probability weighted word saliency (2019) Proceedings of the 57th annual meeting of the association for computational linguistics, pp. 1085-1097; Ruder, Sebastian, (2019) Neural transfer learning for natural language processing, , Ph.D. thesis, NUI Galway; Sun, Lichao, Hashimoto, Kazuma, Yin, Wenpeng, Asai, Akari, Li, Jia, Yu, Philip, Xiong, Caiming, (2020) Adv-bert: Bert is not robust on misspellings! generating nature adversarial samples on bert, , arXiv preprint arXiv:2003.04985; Vaswani, Ashish, Shazeer, Noam, Parmar, Niki, Uszkoreit, Jakob, Jones, Llion, Gomez, Aidan N, Kaiser, Łukasz, Polosukhin, Illia, Attention is all you need (2017) Advances in neural information processing systems, pp. 5998-6008; Wang, Alex, Singh, Amanpreet, Michael, Julian, Hill, Felix, Levy, Omer, Bowman, Samuel, Glue: A multi-task benchmark and analysis platform for natural language understanding (2018) Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, pp. 353-355; Wolf, Thomas, Debut, Lysandre, Sanh, Victor, Chaumond, Julien, Delangue, Clement, Moi, Anthony, Cistac, Pierric, Rush, Alexander, Transformers: State-of-the-art natural language processing (2020) Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pp. 38-45. , Online. Association for Computational Linguistics",,,Amazon Science;Apple;Bloomberg Engineering;et al.;Facebook AI;Google Research,Association for Computational Linguistics (ACL),"Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL-IJCNLP 2021",1 August 2021 through 6 August 2021,,173031,,9.78E+12,,,English,"ACL-IJCNLP - Annu. Meet. Assoc. Comput. Linguist. Int. Jt. Conf. Nat. Lang. Process., Proc. Conf.",Conference Paper,Final,,Scopus,2-s2.0-85115842016
"Wang J., Liu Q., Liu C., Yin J.",57199506724;7406291780;49861647700;57197730919;,GAN-Based Adversarial Patch for Malware C2 Traffic to Bypass DL Detector,2021,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),12918 LNCS,,,78,96,,,10.1007/978-3-030-86890-1_5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115825813&doi=10.1007%2f978-3-030-86890-1_5&partnerID=40&md5=b61a7e7f7cf3104c5c201f6f4acb14d6,"Institute of Information Engineering, Chinese Academy of Sciences, Beijing, 100093, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, 100049, China","Wang, J., Institute of Information Engineering, Chinese Academy of Sciences, Beijing, 100093, China, School of Cyber Security, University of Chinese Academy of Sciences, Beijing, 100049, China; Liu, Q., Institute of Information Engineering, Chinese Academy of Sciences, Beijing, 100093, China, School of Cyber Security, University of Chinese Academy of Sciences, Beijing, 100049, China; Liu, C., Institute of Information Engineering, Chinese Academy of Sciences, Beijing, 100093, China, School of Cyber Security, University of Chinese Academy of Sciences, Beijing, 100049, China; Yin, J., Institute of Information Engineering, Chinese Academy of Sciences, Beijing, 100093, China","The constantly evolving malware brings great challenges to network security defense. Fortunately, deep learning (DL)-based system achieved good performance in the malware command and control (C2) traffic detection field due to its excellent representation capabilities. However, DL models have been shown to be vulnerable to evasion attacks, that is, DL models can easily be misled by adding subtle perturbations to the original samples. In this paper, we propose a GAN-based evasion method, which can help malware C2 traffic bypass the DL detector. Our main contributions contain: (1) directly generate adversarial traffic that can implement malicious functions by inserting additional adversarial patches in the original flow; (2) adaptively imitating victim’s normal traffic by training GAN in victim environment, and introducing transfer learning to reduce the additional victim resource usage caused by GAN training. Results show that the adversarial patch generated by GAN can prevent malware C2 traffic from being detected with 51.4% success rate. The higher time efficiency and smaller malware impact make our method more suitable for real attacks. © 2021, Springer Nature Switzerland AG.",Evasion attacks; GAN; Malware C2 traffic; Transfer learning,Deep learning; Network security; Command and control (C2); Evasion attack; GAN; Learning models; Malware c2 traffic; Networks security; Performance; Security defense; Traffic detection; Transfer learning; Malware,,,,,"https://github.com/caesar0301/pkt2flow; https://github.com/malwaredllc/byob; Arjovsky, M., Chintala, S., Bottou, L., (2017), Wasserstein GAN; Brown, T.B., Mané, D., Roy, A., Abadi, M., Gilmer, J., Adversarial patch (2017) Corr Abs/1712, p. 09665. , http://arxiv.org/abs/1712.09665; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP), Pp. 39–57. IEEE; Cheng, Q., Zhou, S., Shen, Y., Kong, D., Wu, C., (2021) Packet-Level Adversarial Network Traffic Crafting Using Sequence Generative Adversarial Networks; Chernikova, A., Oprea, A., (2020) FENCE: Feasible Evasion Attacks on Neural Networks in Constrained Environments; Clements, J., Yang, Y., Sharma, A., Hu, H., Lao, Y., (2019) Rallying Adversarial Techniques against Deep Learning for Network Security; Goodfellow, I.J., Shlens, J., Szegedy, C., (2015) Explaining and Harnessing Adversarial Examples; Ibitoye, O., Shafiq, O., Matrawy, A., Analyzing adversarial attacks against deep learning for intrusion detection in IoT networks (2019) IEEE Global Communications Conference (GLOBECOM), pp. 1-6. , pp., 2019; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Machine Learning at Scale. Arxiv Preprint Arxiv, 1611, p. 01236; Li, J., Zhou, L., Li, H., Yan, L., Zhu, H., Dynamic traffic feature camouflaging via generative adversarial networks (2019) IEEE Conference on Communications and Network Security (CNS), pp. 268-276. , pp., 2019; Li, R., Xiao, X., Ni, S., Zheng, H., Xia, S., Byte segment neural network for network traffic classification (2018) IEEE/ACM 26Th International Symposium on Quality of Service (Iwqos), pp. 1-10. , pp., 2018; Lin, Z., Shi, Y., Xue, Z., (2019) IDSGAN: Generative Adversarial Networks for Attack Generation against Intrusion Detection; Liu, C., He, L., Xiong, G., Cao, Z., Li, Z., FS-Net: A flow sequence network for encrypted traffic classification (2019) IEEE Conference on Computer Communications, IEEE INFOCOM, pp. 1171-1179. , pp., 2019; Lotfollahi, M., Siavoshani, M.J., Zade, R.S.H., Saberian, M., Deep Packet: A novel approach for encrypted traffic classification using deep learning (2020) Soft. Comput., 24 (3), pp. 1999-2012; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks. Arxiv Preprint Arxiv, 1706, p. 06083; Marín, G., Casas, P., Capdehourat, G., RawPower: Deep learning based anomaly detection from raw network traffic measurements (2018) Proceedings of the ACM SIGCOMM 2018 Conference on Posters and Demos, pp. 75-77. , pp; Marín, G., Casas, P., Capdehourat, G., Deep in the dark-deep learning-based malware traffic detection without expert knowledge (2019) IEEE Security and Privacy Workshops (SPW), pp. 36-42. , pp., 2019; Novo, C., Morla, R., Flow-based detection and proxy-based evasion of encrypted malware c2 traffic (2020) Proceedings of the 13Th ACM Workshop on Artificial Intelligence and Security, Aisec 2020, pp. 83-91. , pp., Association for Computing Machinery, New York; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) 2016 IEEE European Symposium on Security and Privacy (EuroS&P), Pp. 372–387. IEEE; Rigaki, M., Garcia, S., Bringing a GAN to a knife-fight: Adapting malware communication to avoid detection (2018) IEEE Security and Privacy Workshops (SPW), pp. 70-75. , pp., 2018; Szegedy, C., Zaremba, W., Sutskever, I., (2013) Intriguing Properties of Neural Networks. Arxiv Preprint Arxiv, 1312, p. 6199; Wang, W., Zhu, M., Zeng, X., Ye, X., Sheng, Y., Malware traffic classification using convolutional neural network for representation learning (2017) International Conference on Information Networking (ICOIN), pp. 712-717. , pp., 2017; Wang, Z., The applications of deep learning on traffic identification (2015) Blackhat USA, 24 (11), pp. 1-10","Liu, C.; Institute of Information Engineering, China; 电子邮件: liuchaoge@iie.ac.cn",Gao D.Li Q.Guan X.Liao X.,,Springer Science and Business Media Deutschland GmbH,"23rd International Conference on Information and Communications Security, ICICS 2021",19 November 2021 through 21 November 2021,,265649,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,,Scopus,2-s2.0-85115825813
"Sahay R., Brinton C.G., Love D.J.",57208580283;35770243900;7202200691;,A Deep Ensemble-based Wireless Receiver Architecture for Mitigating Adversarial Attacks in Automatic Modulation Classification,2021,IEEE Transactions on Cognitive Communications and Networking,,,,,,,,10.1109/TCCN.2021.3114154,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115726818&doi=10.1109%2fTCCN.2021.3114154&partnerID=40&md5=b6c91780ce2770f62027b7ebfcd716a7,"School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, 47907 USA. (e-mail: sahayr@purdue.edu); School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, 47907 USA.","Sahay, R., School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, 47907 USA. (e-mail: sahayr@purdue.edu); Brinton, C.G., School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, 47907 USA.; Love, D.J., School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, 47907 USA.","Deep learning-based automatic modulation classification (AMC) models are susceptible to adversarial attacks. Such attacks inject specifically crafted wireless interference into transmitted signals to induce erroneous classification predictions. Furthermore, adversarial interference is transferable in black box environments, allowing an adversary to attack multiple deep learning models with a single perturbation crafted for a particular classification model. In this work, we propose a novel wireless receiver architecture to mitigate the effects of adversarial interference in various black box attack environments. We begin by evaluating the architecture uncertainty environment, where we show that adversarial attacks crafted to fool specific AMC DL architectures are not directly transferable to different DL architectures. Next, we consider the domain uncertainty environment, where we show that adversarial attacks crafted on time domain and frequency domain features to not directly transfer to the altering domain. Using these insights, we develop our Assorted Deep Ensemble (ADE) defense, which is an ensemble of deep learning architectures trained on time and frequency domain representations of received signals. Through evaluation on two wireless signal datasets under different sources of uncertainty, we demonstrate that our ADE obtains substantial improvements in AMC classification performance compared with baseline defenses across different adversarial attacks and potencies. IEEE",Adversarial attacks; automatic modulation classification; Communication system security; Deep learning; Interference; machine learning in communications; Receivers; Time-domain analysis; Uncertainty; Wireless communication; wireless security.,Architecture; Classification (of information); Deep learning; Frequency domain analysis; Modulation; Uncertainty analysis; Adversarial attack; Automatic modulation; Automatic modulation classification; Communication system security; Deep learning; Interference; Machine learning in communication; Modulation classification; Receiver; Time-domain analysis; Uncertainty; Wireless communications; Wireless security; Wireless security.; Time domain analysis,,,,,,,,,Institute of Electrical and Electronics Engineers Inc.,,,,,23327731,,,,English,IEEE Trans. Cogn. Commun. Netw.,Article,Article in Press,"All Open Access, Green",Scopus,2-s2.0-85115726818
"Li J., Du Z., Zhu L., Ding Z., Lu K., Shen H.T.",56460678900;57212380844;55710390400;36633871400;26642997600;7404523209;,Divergence-agnostic Unsupervised Domain Adaptation by Adversarial Attacks,2021,IEEE Transactions on Pattern Analysis and Machine Intelligence,,,,,,,3,10.1109/TPAMI.2021.3109287,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114718617&doi=10.1109%2fTPAMI.2021.3109287&partnerID=40&md5=5fabe768138b617fcf8afa9f300f14c2,"School of Computer Science and Engineering, University of Electronic Science and Technology of China, 12599 Chengdu, Sichuan, China, (e-mail: lijin117@yeah.net); SCSE, Chengdu, Sichuan, China, (e-mail: dzk1996411@163.com); School of Information Systems, Singapore Management University, SINGAPORE, Singapore, Singapore, (e-mail: leizhu0608@gmail.com); Department of Computer Science, Tulane University, 5783 New Orleans, Louisiana, United States, 70118-5665 (e-mail: zding1@tulane.edu); Computer Science and Engineering, University of Electronic Science and Technology of China, 12599 Chengdu, Sichuan, China, (e-mail: kel@uestc.edu.cn); School of Computer Science and Engineering, University of Electronic Science and Technology of China, 12599 Chengdu, Sichuhan, China, 610054 (e-mail: shenhengtao@hotmail.com)","Li, J., School of Computer Science and Engineering, University of Electronic Science and Technology of China, 12599 Chengdu, Sichuan, China, (e-mail: lijin117@yeah.net); Du, Z., SCSE, Chengdu, Sichuan, China, (e-mail: dzk1996411@163.com); Zhu, L., School of Information Systems, Singapore Management University, SINGAPORE, Singapore, Singapore, (e-mail: leizhu0608@gmail.com); Ding, Z., Department of Computer Science, Tulane University, 5783 New Orleans, Louisiana, United States, 70118-5665 (e-mail: zding1@tulane.edu); Lu, K., Computer Science and Engineering, University of Electronic Science and Technology of China, 12599 Chengdu, Sichuan, China, (e-mail: kel@uestc.edu.cn); Shen, H.T., School of Computer Science and Engineering, University of Electronic Science and Technology of China, 12599 Chengdu, Sichuhan, China, 610054 (e-mail: shenhengtao@hotmail.com)","Conventional machine learning algorithms suffer the problem that the model trained on existing data fails to generalize well to the data sampled from other distributions. To tackle this issue, unsupervised domain adaptation (UDA) transfers the knowledge learned from a well-labeled source domain to a different but related target domain where labeled data is unavailable. In this paper, we consider a more practical yet challenging UDA setting where either the source domain data or the target domain data are unknown. Technically, we investigate UDA from a novel view --- adversarial attack --- and tackle the divergence-agnostic adaptive learning problem in a unified framework. Specifically, we first report the motivation of our approach by investigating the inherent relationship between UDA and adversarial attacks. Then we elaborately design adversarial examples to attack the training model and harness these adversarial examples. We argue that the generalization ability of the model would be significantly improved if it can defend against our attack, so as to improve the performance on the target domain. Theoretically, we analyze the generalization bound for our method based on domain adaptation theories. Extensive experimental results verify that our method is able to achieve a favorable performance compared with previous ones. IEEE",Adaptation models; adversarial attacks; Data models; domain generalization; Feature extraction; Measurement; model adaptation; Neural networks; Semantics; Training; transfer learning; Unsupervised domain adaptation,Machine learning; Adaptive learning; Conventional machines; Domain adaptation; Generalization ability; Generalization bound; Target domain; Training model; Unified framework; Learning algorithms,,,,,,,,,IEEE Computer Society,,,,,1628828,,ITPID,,English,IEEE Trans Pattern Anal Mach Intell,Article,Article in Press,,Scopus,2-s2.0-85114718617
"Nie Z., Lin Y., Yan M., Cao Y., Ning S.",57229895800;55714566600;57235615700;57236740400;57236183900;,An Adversarial Training Method for Improving Model Robustness in Unsupervised Domain Adaptation,2021,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),12817 LNAI,,,3,13,,,10.1007/978-3-030-82153-1_1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113779102&doi=10.1007%2f978-3-030-82153-1_1&partnerID=40&md5=cece8d66fb799aeb2aabc95146e3819c,"School of Software, Yunnan University, Kunming, Yunnan, China; Key Laboratory in Software Engineering of Yunnan Province, Kunming, China","Nie, Z., School of Software, Yunnan University, Kunming, Yunnan, China; Lin, Y., School of Software, Yunnan University, Kunming, Yunnan, China, Key Laboratory in Software Engineering of Yunnan Province, Kunming, China; Yan, M., School of Software, Yunnan University, Kunming, Yunnan, China; Cao, Y., School of Software, Yunnan University, Kunming, Yunnan, China; Ning, S., School of Software, Yunnan University, Kunming, Yunnan, China","The easily-perturbed nature of deep neural network makes it vulnerable to adversarial attacks, and such vulnerability has become a major threat to the security of machine learning. The transferability of adversarial samples further increases the threat. Adversarial training has made considerable progress in defending against adversarial samples. In transfer learning, unsupervised domain adaptation is an important research branch, however, due to the label of the target domain samples can’t be obtained, it is difficult to implement adversarial training. In this paper, we found that using source domain data for adversarial training and adding the generated adversarial perturbation to the target domain data could effectively enhance the robustness of the transferred model. Experimental results showed that our proposed method can not only ensure the model’s classification accuracy, but also greatly improve the model’s defense performance against adversarial attacks. In simple, our proposed method not only guarantees the transfer of knowledge, but also realizes the transfer of model robustness. It is the main contribution of this paper. © 2021, Springer Nature Switzerland AG.",Adversarial attack; Adversarial training; Robustness; Transfer learning; Unsupervised domain adaption,Deep learning; Deep neural networks; Knowledge management; Network security; Classification accuracy; Domain adaptation; Model robustness; Target domain; Training methods; Transfer of knowledge; Transfer learning,,,,,"Szegedy, C., (2013) Intriguing Properties of Neural Networks. Arxiv Preprint Arxiv, 1312, p. 6199; Szegedy, C., Going deeper with convolutions (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9. , , pp; Shafahi, A., (2019) Adversarially Robust Transfer Learning. Arxiv Preprint Arxiv, 1905, p. 08232; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples. Arxiv Preprint Arxiv, 1412, p. 6572; Su, J., Vargas, D.V., Sakurai, K., One pixel attack for fooling deep neural networks (2019) IEEE Trans. Evol. Comput., 23 (5), pp. 828-841; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1765-1773. , , pp; Qiu, H., Dong, T., Zhang, T., Lu, J., Memmi, G., Qiu, M., Adversarial attacks against network intrusion detection in IoT systems (2020) IEEE Internet Things J; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks. Arxiv Preprint Arxiv, 1706, p. 06083; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP), Pp. 39–57. IEEE; Shafahi, A., (2019) Adversarial Training for Free! Arxiv Preprint Arxiv, 1904, p. 12843; Zhang, D., Zhang, T., Lu, Y., Zhu, Z., Dong, B., (2019) You Only Propagate Once: Accelerating Adversarial Training via Maximal Principle. Arxiv Preprint Arxiv, 1905, p. 00877; Wong, E., Rice, L., Kolter, J.Z., (2020) Fast is Better than Free: Revisiting Adversarial Training. Arxiv Preprint Arxiv, 2001, p. 03994; Andriushchenko, M., Flammarion, N., (2020) Understanding and Improving Fast Adversarial Training. Arxiv Preprint Arxiv, 2007, p. 02617; Zeng, Y., Qiu, H., Memmi, G., Qiu, M.: A data augmentation-based defense method against adversarial attacks in neural networks. In: Qiu, M. (ed.) ICA3PP 2020. LNCS, vol. 12453, pp. 274–289. Springer, Cham (2020). https://doi.org/10. 1007/978-3-030-60239-0 19; Saito, K., Watanabe, K., Ushiku, Y., Harada, T., Maximum classifier discrepancy for unsupervised domain adaptation (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3723-3732. , , pp; Li, Y., Song, Y., Jia, L., Gao, S., Li, Q., Qiu, M., Intelligent fault diagnosis by fusing domain adversarial training and maximum mean discrepancy via ensemble learning (2020) IEEE Trans. Ind. Inf., 17, pp. 2833-2841; Zhou, W., Transferable adversarial perturbations (2018) Proceedings of the European Conference on Computer Vision (ECCV), pp. 452-467. , , pp; Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., Ng, A.Y., (2011) Reading Digits in Natural Images with Unsupervised Feature Learning; Lecun, Y., (1998) The MNIST Database of Handwritten Digits, , http://yann.lecun. com/exdb/mnist/; Moiseev, B., Konev, A., Chigorin, A., Konushin, A.: Evaluation of traffic sign recognition methods trained on synthetically generated data. In: Blanc-Talon, J., Kasinski, A., Philips, W., Popescu, D., Scheunders, P. (eds.) ACIVS 2013. LNCS, vol. 8192, pp. 576–583. Springer, Cham (2013). https://doi.org/10.1007/978-3-319-02895-8 52; Stallkamp, J., Schlipsing, M., Salmen, J., Igel, C., The German traffic sign recognition benchmark: A multi-class classification competition (2011) The 2011 International Joint Conference on Neural Networks, pp. 1453-1460. , , pp. , IEEE; Dong, Y., Deng, Z., Pang, T., Su, H., Zhu, J., (2020) Adversarial Distributional Training for Robust Deep Learning. Arxiv Preprint Arxiv, 2002, p. 05999; Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses. Arxiv Preprint Arxiv, 1705, p. 07204","Lin, Y.; School of Software, China; 电子邮件: linying@ynu.edu.cn",Qiu H.Zhang C.Fei Z.Qiu M.Kung S.,,Springer Science and Business Media Deutschland GmbH,"14th International Conference on Knowledge Science, Engineering and Management, KSEM 2021",14 August 2021 through 16 August 2021,,263589,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,,Scopus,2-s2.0-85113779102
"Rampini A., Pestarini F., Cosmo L., Melzi S., Rodolà E.",57211780791;57223755919;55547250300;56567935900;36100662500;,Universal Spectral Adversarial Attacks for Deformable Shapes,2021,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,,,,3215,3225,,1,10.1109/CVPR46437.2021.00323,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113657158&doi=10.1109%2fCVPR46437.2021.00323&partnerID=40&md5=50c0fada102215eab58c7314366563c1,"Sapienza University of Rome, Italy","Rampini, A., Sapienza University of Rome, Italy; Pestarini, F., Sapienza University of Rome, Italy; Cosmo, L., Sapienza University of Rome, Italy; Melzi, S., Sapienza University of Rome, Italy; Rodolà, E., Sapienza University of Rome, Italy","Machine learning models are known to be vulnerable to adversarial attacks, namely perturbations of the data that lead to wrong predictions despite being imperceptible. However, the existence of “universal” attacks (i.e., unique perturbations that transfer across different data points) has only been demonstrated for images to date. Part of the reason lies in the lack of a common domain, for geometric data such as graphs, meshes, and point clouds, where a universal perturbation can be defined. In this paper, we offer a change in perspective and demonstrate the existence of universal attacks for geometric data (shapes). We introduce a computational procedure that operates entirely in the spectral domain, where the attacks take the form of small perturbations to short eigenvalue sequences; the resulting geometry is then synthesized via shape-from-spectrum recovery. Our attacks are universal, in that they transfer across different shapes, different representations (meshes and point clouds), and generalize to previously unseen data. © 2021 IEEE",,Computational geometry; Computer vision; AS graph; Computational procedures; Datapoints; Deformable shapes; Eigen-value; Geometric data; Machine learning models; Point-clouds; Small perturbations; Spectral domains; Eigenvalues and eigenfunctions,,,,,"Aflalo, Y., Brezis, H., Kimmel, R., On the optimality of shape and data representation in the spectral domain (2015) SIAM Journal on Imaging Sciences, 8 (2), pp. 1141-1160; Athalye, A., Carlini, N., Wagner, D., Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples (2018) Proc. ICML, 80, pp. 274-283; Bando, S., Urakawa, H., Generic properties of the eigenvalue of the Laplacian for compact riemannian manifolds (1983) Tohoku Mathematical Journal, Second Series, 35 (2), pp. 155-172; Brown, T.B., Mané, D., Roy, A., Abadi, M., Gilmer, J., (2017) Adversarial Patch; Carlini, N., Wagner, D.A., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy, SP 2017, pp. 39-57. , San Jose, CA, USA, May 22-26, 2017, IEEE Computer Society; Chaturvedi, A., Abijith, K.P., Garain, U., (2019) Exploring the Robustness of Nmt Systems to Nonsensical Inputs; Chaubey, A., Agrawal, N., Barnwal, K., Guliani, K.K., Mehta, P., (2020) Universal Adversarial Perturbations: A Survey; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, AISec'17, pp. 15-26. , New York, NY, USA, ACM; Chen, Y., Nadji, Y., Kountouras, A., Monrose, F., Perdisci, R., Antonakakis, M., Vasiloglou, N., Practical attacks against graph-based clustering (2017) Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pp. 1125-1142; Clarenz, U., Rumpf, M., Telea, A., Finite elements on point based surfaces (2004) Proceedings of the First Eurographics Conference on Point-Based Graphics, pp. 201-211. , Eurographics Association; Cosmo, L., Panine, M., Rampini, A., Ovsjanikov, M., Bronstein, M.M., Rodolà, E., Isospectralization, or how to hear shape, style, and correspondence (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 7529-7538; Dai, H., Li, H., Tian, T., Huang, X., Wang, L., Zhu, J., Song, L., (2018) Adversarial Attack on Graph Structured Data; Defferrard, M., Bresson, X., Vandergheynst, P., Convolutional neural networks on graphs with fast localized spectral filtering (2016) Proceedings of the 30th International Conference on Neural Information Processing Systems, NIPS'16, pp. 3844-3852. , Red Hook, NY, USA, Curran Associates Inc; Gao, J., Lanchantin, J., Soffa, M.L., Qi, Y., Black-box generation of adversarial text sequences to evade deep learning classifiers (2018) 2018 IEEE Security and Privacy Workshops (SPW), pp. 50-56; Gleave, A., Dennis, M., Kant, N., Wild, C., Levine, S., Russell, S., (2019) Adversarial Policies: Attacking Deep Reinforcement Learning; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Hamdi, A., Rojas, S., Thabet, A., Ghanem, B., (2019) Advpc: Transferable Adversarial Perturbations on 3d Point Clouds; Hayes, J., Danezis, G., Learning universal adversarial perturbations with generative models (2018) 2018 IEEE Security and Privacy Workshops (SPW), pp. 43-49; He, Z., Rakin, A.S., Fan, D., Parametric noise injection: Trainable randomness to improve deep neural network robustness against adversarial attack (2019) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , June; Metzen, J.H., Kumar, M.C., Brox, T., Fischer, V., Universal adversarial perturbations against semantic image segmentation (2017) Proceedings of the IEEE International Conference on Computer Vision, pp. 2755-2764; Jin, D., Jin, Z., Zhou, J.T., Szolovits, P., (2019) Is Bert Really Robust? Natural Language Attack on Text Classification and Entailment; Kac, M., Can one hear the shape of a drum? (1966) The American Mathematical Monthly, 73 (4), pp. 1-23; Khoury, M., Hadfield-Menell, D., (2019) Adversarial Training with Voronoi Constraints; Kingma, D.P., Ba, J., (2014) Adam: A Method for Stochastic Optimization; Li, Y., Li, L., Wang, L., Zhang, T., Gong, B., Nattack: Learning the distributions of adversarial examples for an improved black-box attack on deep neural networks (2019) Proceedings of the 36th International Conference on Machine Learning, 97, pp. 3866-3876; Liu, D., Yu, R., Su, H., Extending adversarial attacks and defenses to deep 3d point cloud classifiers (2019) 2019 IEEE International Conference on Image Processing (ICIP), pp. 2279-2283; Liu, Y., Chen, X., Liu, C., Song, D., (2016) Delving into Transferable Adversarial Examples and Black-Box Attacks; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) Proc. ICLR; Magnus, J.R., On differentiating eigenvalues and eigenvectors (1985) Econometric Theory, pp. 179-191; Mariani, G., Cosmo, L., Bronstein, A., Rodolà, E., Generating adversarial surfaces via band-limited perturbations (2020) Computer Graphics Forum, 39 (5), pp. 253-264; Marin, R., Rampini, A., Castellani, U., Rodolà, E., Ovsjanikov, M., Melzi, S., Instant recovery of shape from spectrum via latent space connections International Conference on 3D Vision (3DV), p. 2020; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1765-1773; Mopuri, K.R., Ganeshan, A., Babu, R.V., Generalizable data-free objective for crafting universal adversarial perturbations (2018) IEEE Transactions on Pattern Analysis and Machine Intelligence, 41 (10), pp. 2452-2465; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-Box Attacks Using Adversarial Samples; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, ASIA CCS'17, pp. 506-519. , New York, NY, USA, ACM; Pinkall, U., Polthier, K., Computing discrete minimal surfaces and their conjugates (1993) Experimental Mathematics, 2 (1), pp. 15-36; Poursaeed, O., Katsman, I., Gao, B., Belongie, S., Generative adversarial perturbations (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4422-4431; Qi, C.R., Su, H., Mo, K., Guibas, L.J., PointNet: Deep learning on point sets for 3d classification and segmentation (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 652-660; Ranjan, A., Bolkart, T., Sanyal, S., Black, M.J., Generating 3D faces using convolutional mesh autoencoders (2018) European Conference on Computer Vision (ECCV); Ranjan, A., Bolkart, T., Sanyal, S., Black, M.J., Generating 3D faces using convolutional mesh autoencoders (2018) European Conference on Computer Vision (ECCV), Volume Lecture Notes in Computer Science, 11207, pp. 725-741. , Springer, Cham, Sept; Mopuri, K.R., Ojha, U., Garg, U., Babu, R.V., NAG: Network for adversary generation (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 742-751; Rony, J., Hafemann, L.G., Oliveira, L.S., Ayed, I.B., Sabourin, R., Granger, E., Decoupling direction and norm for efficient gradient-based L2 adversarial attacks and defenses (2019) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , June; Sarkar, A., Gupta, N.K., Iyengar, R., (2019) Enforcing Linearity in Dnn Succours Robustness and Adversarial Image Generation; Shafahi, A., Najibi, M., Xu, Z., Dickerson, J.P., Davis, L.S., Goldstein, T., Universal adversarial training Proc. AAAI, p. 2020; Sun, M., Tang, J., Li, H., Li, B., Xiao, C., Chen, Y., Song, D., (2018) Data Poisoning Attack Against Unsupervised Node Embedding Methods; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks; Tsai, T., Yang, K., Ho, T.-Y., Jin, Y., Robust adversarial objects against deep learning models Proc. AAAI, p. 2020; Wen, Y., Lin, J., Chen, K., Jia, K., (2019) Geometry-Aware Generation of Adversarial and Cooperative Point Clouds; Xiang, C., Qi, C.R., Li, B., Generating 3d adversarial point clouds (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 9136-9144; Xiao, C., Yang, D., Li, B., Deng, J., Liu, M., MeshadV: Adversarial meshes for visual recognition (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 6898-6907; Xie, C., Wu, Y., van der Maaten, L., Yuille, A.L., He, K., Feature denoising for improving adversarial robustness (2019) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 501-509. , June; Xu, H., Ma, Y., Liu, H., Deb, D., Liu, H., Tang, J., Jain, A., (2019) Adversarial Attacks and Defenses in Images, Graphs and Text: A Review; Zang, X., Xie, Y., Chen, J., Yuan, B., (2020) Graph Universal Adversarial Attacks: A Few Bad Actors Ruin Graph Learning Models; Zhang, H., Yu, Y., Jiao, J., Xing, E., Ghaoui, L.E., Jordan, M., Theoretically principled trade-off between robustness and accuracy (2019) Proceedings of the 36th International Conference on Machine Learning, Volume 97 of Proceedings of Machine Learning Research, pp. 7472-7482. , Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, Long Beach, California, USA, 09-15 Jun PMLR; Zhang, H., Zheng, T., Gao, J., Miao, C., Su, L., Li, Y., Ren, K., Data poisoning attack against knowledge graph embedding (2019) Proceedings of the 28th International Joint Conference on Artificial Intelligence, pp. 4853-4859. , AAAI Press; Zhang, Y., Liang, G., Salem, T., Jacobs, N., Defense-pointnet: Protecting pointnet against adversarial attacks (2019) 2019 IEEE International Conference on Big Data (Big Data), pp. 5654-5660; Zhang, Y., Liang, P., Defending against whitebox adversarial attacks via randomized discretization (2019) Proceedings of Machine Learning Research, 89, pp. 684-693. , Kamalika Chaudhuri and Masashi Sugiyama, editors; Zhao, Y., Wu, Y., Chen, C., Lim, A., (2020) On Isometry Robustness of Deep 3d Point Cloud Models Under Adversarial Attacks; Zuffi, S., Kanazawa, A., Jacobs, D., Black, M.J., 3D menagerie: Modeling the 3D shape and pose of animals (2017) IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), , July; Zügner, D., Akbarnejad, A., Günnemann, S., Adversarial attacks on neural networks for graph data (2018) Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pp. 2847-2856",,,,IEEE Computer Society,"2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2021",19 June 2021 through 25 June 2021,,174911,10636919,9.78E+12,PIVRE,,English,Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85113657158
"Jia S., Song Y., Ma C., Yang X.",57211167888;55613370800;57203342753;7406503333;,IoU Attack: Towards Temporally Coherent Black-Box Adversarial Attack for Visual Object Tracking,2021,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,,,,6705,6714,,1,10.1109/CVPR46437.2021.00664,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113634355&doi=10.1109%2fCVPR46437.2021.00664&partnerID=40&md5=95f2b94b30c6bc56e4c59128111820e0,"MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, China; Tencent AI Lab","Jia, S., MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, China; Song, Y., Tencent AI Lab; Ma, C., MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, China; Yang, X., MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, China","Adversarial attack arises due to the vulnerability of deep neural networks to perceive input samples injected with imperceptible perturbations. Recently, adversarial attack has been applied to visual object tracking to evaluate the robustness of deep trackers. Assuming that the model structures of deep trackers are known, a variety of white-box attack approaches to visual tracking have demonstrated promising results. However, the model knowledge about deep trackers is usually unavailable in real applications. In this paper, we propose a decision-based black-box attack method for visual object tracking. In contrast to existing black-box adversarial attack methods that deal with static images for image classification, we propose IoU attack that sequentially generates perturbations based on the predicted IoU scores from both current and historical frames. By decreasing the IoU scores, the proposed attack method degrades the accuracy of temporal coherent bounding boxes (i.e., object motions) accordingly. In addition, we transfer the learned perturbations to the next few frames to initialize temporal motion attack. We validate the proposed IoU attack on state-of-the-art deep trackers (i.e., detection based, correlation filter based, and long-term trackers). Extensive experiments on the benchmark datasets indicate the effectiveness of the proposed IoU attack method. The source code is available at https://github.com/VISION-SJTU/IoUattack. © 2021 IEEE",,Computer vision; Model structures; Tracking (position); Attack methods; Black boxes; Decision-based; Input sample; Model knowledge; Real applications; Static images; Visual object tracking; Visual Tracking; White box; Deep neural networks,,,,,"Bhat, G., Danelljan, M., van Gool, L., Timofte, R., Learning discriminative model prediction for tracking (2019) ICCV; Brendel, W., Rauber, J., Bethge, M., Decision-based adversarial attacks: Reliable attacks against black-box machine learning models (2018) ICLR; Chen, X., Yan, X., Zheng, F., Jiang, Y., Xia, S.-T., Zhao, Y., Ji, R., One-shot adversarial attacks on visual tracking with dual attention (2020) CVPR; Chen, Z., Zhong, B., Li, G., Zhang, S., Ji, R., Siamese box adaptive network for visual tracking (2020) CVPR; Dai, K., Zhang, Y., Wang, D., Li, J., Lu, H., Yang, X., High-performance long-term tracking with meta-updater (2020) CVPR; Danelljan, M., Bhat, G., Khan, F.S., Felsberg, M., ECO: Efficient convolution operators for tracking (2017) CVPR; Danelljan, M., van Gool, L., Timofte, R., Probabilistic regression for visual tracking (2020) CVPR; Dong, Y., Su, H., Wu, B., Li, Z., Liu, W., Zhang, T., Zhu, J., Efficient decision-based black-box adversarial attacks on face recognition (2019) CVPR; Dong, Y., Su, H., Wu, B., Li, Z., Liu, W., Zhang, T., Zhu, J., Efficient decision-based black-box adversarial attacks on face recognition (2019) CVPR; Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Xiao, C., Prakash, A., Song, D., Robust physical-world attacks on deep learning models (2018) CVPR; Fan, H., Lin, L., Yang, F., Chu, P., Deng, G., Yu, S., Bai, H., Ling, H., LASOT: A high-quality benchmark for large-scale single object tracking (2019) ICCV; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR; Guo, D., Wang, J., Cui, Y., Wang, Z., Chen, S., SiamCar: Siamese fully convolutional classification and regression for visual tracking (2020) CVPR; Guo, Q., Xie, X., Juefei-Xu, F., Ma, L., Li, Z., Xue, W., Feng, W., Liu, Y., Spark: Spatial-aware online incremental attack against visual tracking ECCV, p. 2020; Ilyas, A., Engstrom, L., Athalye, A., Lin, J., Black-box adversarial attacks with limited queries and information (2018) ICML; Jia, S., Ma, C., Song, Y., Yang, X., Robust tracking against adversarial attacks ECCV, p. 2020; Jung, I., Son, J., Baek, M., Han, B., Real-time mdnet (2018) ECCV; Galoogahi, H.K., Fagg, A., Huang, C., Ramanan, D., Lucey, S., Need for speed: A benchmark for higher frame rate object tracking (2017) ICCV; Kristan, M., Leonardis, A., Matas, J., Felsberg, M., Pflugfelder, R., Zajc, L.C., Vojir, T., Eldesokey, A., The sixth visual object tracking vot2018 challenge results (2018) ECCV Workshop; Kristan, M., Leonardis, A., Matas, J., Felsberg, M., Pflugfelder, R., Zajc, L.C., Vojir, T., Eldesokey, A., The visual object tracking vot2016 challenge results (2016) ECCV Workshop; Kristan, M., Matas, J., Leonardis, A., Felsberg, M., Pflugfelder, R., Kamarainen, J.-K., Zajc, L.C., Berg, A., The seventh visual object tracking vot2019 challenge results (2019) ECCV Workshop; Li, B., Wu, W., Wang, Q., Zhang, F., Xing, J., Yan, J., SiAmRPn++: Evolution of siamese visual tracking with very deep networks (2019) CVPR; Li, B., Yan, J., Wu, W., Zhu, Z., Hu, X., High performance visual tracking with siamese region proposal network (2018) CVPR; Liang, S., Wei, X., Yao, S., Cao, X., Efficient adversarial attacks for visual object tracking ECCV, p. 2020; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) ICLR; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) CVPR; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) CVPR; Mueller, M., Smith, N., Ghanem, B., A benchmark and simulator for uav tracking (2016) ECCV; Muller, M., Bibi, A., Giancola, S., Alsubaihi, S., Ghanem, B., TrackingNet: A large-scale dataset and benchmark for object tracking in the wild (2018) ECCV; Nam, H., Han, B., Learning multi-domain convolutional neural networks for visual tracking (2016) CVPR; Pan, T., Song, Y., Yang, T., Jiang, W., Liu, W., (2021) Videomoco: Contrastive Video Representation Learning with Temporally Adversarial Examples; Pu, S., Song, Y., Ma, C., Zhang, H., Yang, M.-H., Deep attentive tracking via reciprocative learning (2018) NIPS; Qi, G., Gong, L., Song, Y., Ma, K., Zheng, Y., (2021) Stabilized Medical Image Attacks; Ren, S., He, K., Girshick, R., Sun, J., Faster R-CNN: Towards real-time object detection with region proposal networks (2015) NIPS; Song, Y., Ma, C., Gong, L., Zhang, J., Lau, R.W.H., Yang, M.-H., CREST: Convolutional residual learning for visual tracking (2017) ICCV; Song, Y., Ma, C., Wu, X., Gong, L., Bao, L., Zuo, W., Shen, C., Yang, M.-H., Vital: Visual tracking via adversarial learning (2018) CVPR; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) ICLR; Voigtlaender, P., Luiten, J., Torr, P.H.S., Leibe, B., Siam R-CNN: Visual tracking by re-detection (2020) CVPR; Wang, N., Song, Y., Ma, C., Zhou, W., Liu, W., Li, H., Unsupervised deep tracking (2019) CVPR; Wang, N., Zhou, W., Song, Y., Ma, C., Liu, W., Li, H., Unsupervised deep representation learning for real-time tracking (2021) IJCV; Wiyatno, R.R., Xu, A., Physical adversarial textures that fool visual object tracking (2019) ICCV; Wu, Y., Lim, J., Yang, M.-H., Object tracking benchmark (2015) TPAMI; Xie, C., Wu, Y., van der Maaten, L., Yuille, A.L., He, K., Feature denoising for improving adversarial robustness (2019) CVPR; Yan, B., Wang, D., Lu, H., Yang, X., Cooling-shrinking attack: Blinding the tracker with imperceptible noises (2020) CVPR; Yan, B., Zhao, H., Wang, D., Lu, H., Yang, X., 'Skimming-perusal'tracking: A framework for real-time and robust long-term tracking (2019) ICCV; Zhang, L., Gonzalez-Garcia, A., van de Weijer, J., Danelljan, M., Khan, F.S., Learning the model update for siamese trackers (2019) ICCV; Zhang, Z., Peng, H., Deeper and wider siamese networks for real-time visual tracking (2019) CVPR; Zhao, S., Ma, X., Zheng, X., Bailey, J., Chen, J., Jiang, Y.-G., Clean-label backdoor attacks on video recognition models (2020) CVPR","Ma, C.; MoE Key Lab of Artificial Intelligence, China; 电子邮件: chaoma@sjtu.edu.cn",,,IEEE Computer Society,"2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2021",19 June 2021 through 25 June 2021,,174911,10636919,9.78E+12,PIVRE,,English,Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85113634355
"Wu W., Su Y., Lyu M.R., King I.",57209642543;56717004400;7006811415;7102275781;,Improving the Transferability of Adversarial Samples with Adversarial Transformations,2021,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,,,,9020,9029,,2,10.1109/CVPR46437.2021.00891,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113623225&doi=10.1109%2fCVPR46437.2021.00891&partnerID=40&md5=e7de7db00cd4934d9b38d63b8e537967,"Department of Computer Science and Engineering, The Chinese University of Hong Kong","Wu, W., Department of Computer Science and Engineering, The Chinese University of Hong Kong; Su, Y., Department of Computer Science and Engineering, The Chinese University of Hong Kong; Lyu, M.R., Department of Computer Science and Engineering, The Chinese University of Hong Kong; King, I., Department of Computer Science and Engineering, The Chinese University of Hong Kong","Although deep neural networks (DNNs) have achieved tremendous performance in diverse vision challenges, they are surprisingly susceptible to adversarial examples, which are born of intentionally perturbing benign samples in a human-imperceptible fashion. It thus poses security concerns on the deployment of DNNs in practice, particularly in safety- and security-sensitive domains. To investigate the robustness of DNNs, transfer-based attacks have attracted a growing interest recently due to their high practical applicability, where attackers craft adversarial samples with local models and employ the resultant samples to attack a remote black-box model. However, existing transfer-based attacks frequently suffer from low success rates due to overfitting to the adopted local model. To boost the transferability of adversarial samples, we propose to improve the robustness of synthesized adversarial samples via adversarial transformations. Specifically, we employ an adversarial transformation network to model the most harmful distortions that can destroy adversarial noises and require the synthesized adversarial samples to become resistant to such adversarial transformations. Extensive experiments on the ImageNet benchmark showcase the superiority of our method to state-of-the-art baselines in attacking both undefended and defended models. © 2021 IEEE.",,Computer vision; Black box modelling; Local model; Network transfers; Overfitting; Performance; Safety and securities; State of the art; Synthesised; Deep neural networks,,,,,"Bhagoji, A.N., He, W., Li, B., Song, D., Practical black-box attacks on deep neural networks using efficient query mechanisms (2018) European Conference on Computer Vision, pp. 158-174. , Springer, 2; Biggio, B., Roli, F., Wild patterns: Ten years after the rise of adversarial machine learning (2018) Pattern Recognition, 84, pp. 317-331. , 1, 2; Carlini, N., Athalye, A., Papernot, N., Brendel, W., Rauber, J., Tsipras, D., Goodfellow, I., Madry, A., (2019) On Evaluating Adversarial Robustness, , 6; Cohen, J., Rosenfeld, E., Kolter, Z., Certified adversarial robustness via randomized smoothing (2019) International Conference on Machine Learning, pp. 1310-1320. , 2, 3, 7; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 9185-9193. , 1, 2, 3, 7; Dong, Y., Pang, T., Su, H., Zhu, J., Evading defenses to transferable adversarial examples by translation-invariant attacks (2019) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , 2, 3, 6, 7; Gatys, L.A., Ecker, A.S., Bethge, M., Image style transfer using convolutional neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2414-2423. , 2, 3; Goodfellow, I.J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., (2014) Generative Adversarial Networks, , arXiv preprint 4; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) Proceedings of the International Conference on Learning Representations (ICLR), , 1, 2, 3, 4, 7; Guo, C., Gardner, J., You, Y., Wilson, A.G., Weinberger, K., Simple black-box adversarial attacks (2019) International Conference on Machine Learning, pp. 2484-2493. , 1, 2; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) IEEE International Conference on Computer Vision (ICCV), pp. 770-778. , 6; He, K., Zhang, X., Ren, S., Sun, J., Identity mappings in deep residual networks (2016) The European Conference on Computer Vision (ECCV), pp. 630-645. , Springer, 1, 6; Huang, Z., Zhang, T., Black-box adversarial attack with transferable model-based embedding (2020) International Conference on Learning Representations, , 2; Jia, X., Wei, X., Cao, X., Foroosh, H., ComDefend: An efficient image compression model to defend adversarial examples (2019) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), , June 3, 7; Kingma, D.P., Ba, J., ADaM: A method for stochastic optimization (2015) International Conference on Learning Representations (ICLR), , 5; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems (NIPS), pp. 1097-1105. , Curran Associates, Inc, 1; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2017) ICLR Workshop, 1 (5), p. 7; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2017) International Conference on Learning Representations (ICLR), , 1, 3, 7; Li, Y., Bai, S., Xie, C., Liao, Z., Shen, X., Yuille, A.L., Regional homogeneity: Towards learning transferable universal adversarial perturbations against defenses (2020) European Conference on Computer Vision, , 2; Liao, F., Liang, M., Dong, Y., Pang, T., Hu, X., Zhu, J., Defense against adversarial attacks using high-level representation guided denoiser (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1778-1787. , 3, 7; Lin, J., Song, C., He, K., Wang, L., Hopcroft, J.E., Nesterov accelerated gradient and scale invariance for adversarial attacks (2020) International Conference on Learning Representations, , 2, 3, 6, 7, 8; Liu, C., Chen, L.-C., Schroff, F., Adam, H., Hua, W., Yuille, A.L., Fei-Fei, L., Autodeeplab: Hierarchical neural architecture search for semantic image segmentation (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 82-92. , 1; Liu, Z., Liu, Q., Liu, T., Xu, N., Lin, X., Wang, Y., Wen, W., Feature distillation: DNN-Oriented JPEG compression against adversarial examples (2019) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), , June 3, 7; Luo, X., Zhan, R., Chang, H., Yang, F., Milanfar, P., Distortion agnostic deep watermarking (2020) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 13548-13557. , 2, 3, 4; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) Proceedings of the International Conference on Learning Representations (ICLR), , 1, 4, 7; Maqueda, A.I., Loquercio, A., Gallego, G., García, N., Scaramuzza, D., Event-based vision meets deep learning on steering prediction for self-driving cars (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 5419-5427. , 1; Nesterov, Y., A method for unconstrained convex minimization problem with the rate of convergence O (1/k^ 2) (1983) Doklady an Ussr, 269, pp. 543-547. , 3; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519. , 1, 2; Polyak, B.T., Some methods of speeding up the convergence of iteration methods (1964) USSR Computational Mathematics and Mathematical Physics, 4 (5), pp. 1-17. , 3; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Fei-Fei, L., ImageNet large scale visual recognition challenge (2015) International Journal of Computer Vision, , 6; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) International Conference on Learning Representations (ICLR), 1 (4), p. 5; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., Inception-v4, Inception-ResNet and the impact of residual connections on learning (2017) The Thirty-First AAAI Conference on Artificial Intelligence, , 6; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) IEEE International Conference on Computer Vision (ICCV), , 6; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations (ICLR), , 1; Tan, M., Le, Q., EfficientNet: Rethinking model scaling for convolutional neural networks (2019) International Conference on Machine Learning, pp. 6105-6114. , 1; Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2018) International Conference on Learning Representations (ICLR), , 1, 3, 7; Wu, W., Su, Y., Chen, X., Zhao, S., King, I., Lyu, M.R., Tai, Y.-W., Boosting the transferability of adversarial samples via attention (2020) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1161-1170. , 1; Wu, W., Su, Y., Chen, X., Zhao, S., King, I., Lyu, M.R., Tai, Y.-W., Towards global explanations of convolutional neural networks with concept attribution (2020) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 8652-8661. , 1; Wu, W., Xu, H., Zhong, S., Lyu, M.R., King, I., Deep validation: Toward detecting real-world corner cases for deep neural networks (2019) Proceedings of the 49th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN), pp. 125-137. , IEEE, 1; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., Mitigating adversarial effects through randomization (2018) International Conference on Learning Representations, 3, p. 7; Xie, C., Wu, Y., van der Maaten, L., Yuille, A.L., He, K., Feature denoising for improving adversarial robustness (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 501-509. , 3; Xie, C., Zhang, Z., Zhou, Y., Bai, S., Wang, J., Ren, Z., Yuille, A.L., Improving transferability of adversarial examples with input diversity (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2730-2739. , 2, 3, 4, 7; Xu, H., Chen, Z., Wu, W., Jin, Z., Kuo, S.-Y., Lyu, M., NV-DNN: Towards fault-tolerant DNN systems with N-version programming (2019) The 49th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops (DSN-W), pp. 44-47. , IEEE, 1; Zhou, W., Hou, X., Chen, Y., Tang, M., Huang, X., Gan, X., Yang, Y., Transferable adversarial perturbations (2018) The European Conference on Computer Vision (ECCV), , 1; Zhu, J., Kaplan, R., Johnson, J., Fei-Fei, L., Hidden: Hiding data with deep networks (2018) Proceedings of the European Conference on Computer Vision (ECCV), pp. 657-672. , 2, 3, 4",,,,IEEE Computer Society,"2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2021",19 June 2021 through 25 June 2021,,174911,10636919,9.78E+12,PIVRE,,English,Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit,Conference Paper,Final,,Scopus,2-s2.0-85113623225
"Xiao Z., Gao X., Fu C., Dong Y., Gao W., Zhang X., Zhou J., Zhu J.",57195693259;57209293537;57211407737;57191433539;57225919528;57203328013;57199295167;56734692500;,Improving transferability of adversarial patches on face recognition with generative models,2021,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,,,,11840,11849,,1,10.1109/CVPR46437.2021.01167,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113621541&doi=10.1109%2fCVPR46437.2021.01167&partnerID=40&md5=9d2ca50df42c531b86881a15566d2283,RealAI; Ant Financial; Tsinghua University; Beijing Institute of Technology; Nanyang Technological University,"Xiao, Z., RealAI; Gao, X., RealAI, Beijing Institute of Technology; Fu, C., Ant Financial; Dong, Y., RealAI, Tsinghua University; Gao, W., RealAI, Nanyang Technological University; Zhang, X., Ant Financial; Zhou, J., Ant Financial; Zhu, J., Tsinghua University","Face recognition is greatly improved by deep convolutional neural networks (CNNs). Recently, these face recognition models have been used for identity authentication in security sensitive applications. However, deep CNNs are vulnerable to adversarial patches, which are physically realizable and stealthy, raising new security concerns on the real-world applications of these models. In this paper, we evaluate the robustness of face recognition models using adversarial patches based on transferability, where the attacker has limited accessibility to the target models. First, we extend the existing transfer-based attack techniques to generate transferable adversarial patches. However, we observe that the transferability is sensitive to initialization and degrades when the perturbation magnitude is large, indicating the overfitting to the substitute models. Second, we propose to regularize the adversarial patches on the low dimensional data manifold. The manifold is represented by generative models pre-trained on legitimate human face images. Using face-like features as adversarial perturbations through optimization on the manifold, we show that the gaps between the responses of substitute models and the target models dramatically decrease, exhibiting a better transferability. Extensive digital world experiments are conducted to demonstrate the superiority of the proposed method in the black-box setting. We apply the proposed method in the physical world as well. © 2021 IEEE",,Computer vision; Convolutional neural networks; Deep neural networks; Data manifolds; Generative model; Identity authentication; Low dimensional; Overfitting; Patch based; Real-world; Recognition models; Sensitive application; Target model; Face recognition,,,,,"Abdal, R., Qin, Y., Wonka, P., Image2Stylegan: How to embed images into the stylegan latent space? (2019) Proceedings of the IEEE International Conference on Computer Vision, pp. 4432-4441. , 5, 6, 7; Athalye, A., Engstrom, L., Ilyas, A., Kwok, K., Synthesizing robust adversarial examples (2018) International Conference on Machine Learning, pp. 284-293. , PMLR, 3; Brown, T.B., Mané, D., Roy, A., Abadi, M., Gilmer, J., (2017) Adversarial Patch, , arXiv preprint 2, 3; Deng, J., Guo, J., Xue, N., Zafeiriou, S., ArcFace: Additive angular margin loss for deep face recognition (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4690-4699. , 1, 5; Dong, Y., Fu, Q.-A., Yang, X., Pang, T., Su, H., Xiao, Z., Zhu, J., Benchmarking adversarial robustness on image classification (2020) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 321-331. , 1; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 9185-9193. , 2, 3, 4, 6; Dong, Y., Pang, T., Su, H., Zhu, J., Evading defenses to transferable adversarial examples by translation-invariant attacks (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4312-4321. , 2, 4, 6; Dong, Y., Su, H., Wu, B., Li, Z., Liu, W., Zhang, T., Zhu, J., Efficient decision-based black-box adversarial attacks on face recognition (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 7714-7722. , 3, 5; Evtimov, I., Eykholt, K., Fernandes, E., Kohno, T., Li, B., Prakash, A., Rahmati, A., Song, D., (2017) Robust Physical-World Attacks on Machine Learning Models, 2 (3). , arXiv preprint 4, 2, 3; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint 2, 4; Huang, G.B., Ramesh, M., Berg, T., Learned-Miller, E., (2007) Labeled Faces in the Wild: A Database for Studying Face Recognition in Unconstrained Environments, , Technical Report 07-49, University of Massachusetts, Amherst, October 5; Karras, T., Aila, T., Laine, S., Lehtinen, J., (2017) Progressive Growing of Gans for Improved Quality, Stability, and Variation, , arXiv preprint 5, 7; Karras, T., Laine, S., Aila, T., A style-based generator architecture for generative adversarial networks (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4401-4410. , 5, 6, 7; Karras, T., Laine, S., Aittala, M., Hellsten, J., Lehtinen, J., Aila, T., Analyzing and improving the image quality of stylegan (2020) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 8110-8119. , 5, 7; Kingma, D.P., Ba, J., (2014) Adam: A Method for Stochastic Optimization, , arXiv preprint 4, 5; Qiu, H., Xiao, C., Yang, L., Yan, X., Lee, H., Li, B., SemantiCADV: Generating adversarial examples via attribute-conditioned image editing (2020) European Conference on Computer Vision, pp. 19-37. , Springer, 2, 5, 8; Schroff, F., Kalenichenko, D., Philbin, J., FaceNet: A unified embedding for face recognition and clustering (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 815-823. , 1, 5; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proceedings of the 2016 Acm Sigsac Conference on Computer and Communications Security, pp. 1528-1540. , 1, 2, 3; Song, D., Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Tramer, F., Kohno, T., Physical adversarial examples for object detectors (2018) 12th (USENIX) Workshop on Offensive Technologies ((WOOT) 18), , 2, 3; Song, Y., Shu, R., Kushman, N., Ermon, S., Constructing unrestricted adversarial examples with generative models (2018) Advances in Neural Information Processing Systems, pp. 8312-8323. , 2; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint 1; Tu, C.-C., Ting, P., Chen, P.-Y., Liu, S., Zhang, H., Yi, J., Hsieh, C.-J., Cheng, S.-M., AutoZoom: Autoencoder-based zeroth order optimization method for attacking black-box neural networks (2019) Proceedings of the AAAI Conference on Artificial Intelligence, 33, pp. 742-749. , 2; Wang, H., Wang, Y., Zhou, Z., Ji, X., Gong, D., Zhou, J., Li, Z., Liu, W., Cosface: Large margin cosine loss for deep face recognition (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 5265-5274. , 1, 5; Wu, Z., Lim, S.-N., Davis, L., Goldstein, T., (2019) Making an Invisibility Cloak: Real World Adversarial Attacks on Object Detectors, , arXiv preprint 2; Xiao, C., Li, B., Zhu, J.-Y., He, W., Liu, M., Song, D., (2018) Generating Adversarial Examples with Adversarial Networks, , arXiv preprint 2; Xie, C., Zhang, Z., Zhou, Y., Bai, S., Wang, J., Ren, Z., Yuille, A.L., Improving transferability of adversarial examples with input diversity (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2730-2739. , 2, 3, 4, 6; Yang, C., Kortylewski, A., Xie, C., Cao, Y., Yuille, A., PatchatTack: A black-box texture-based attack with reinforcement learning (2020) European Conference on Computer Vision, pp. 681-698. , Springer, 2; Zhao, Z., Dua, D., Singh, S., (2017) Generating Natural Adversarial Examples, , arXiv preprint 2","Xiao, Z.; RealAI电子邮件: zihao.xiao@real.ai
Zhu, J.; Tsinghua University电子邮件: dcszj@tsinghua.edu.cn",,,IEEE Computer Society,"2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2021",19 June 2021 through 25 June 2021,,174911,10636919,9.78E+12,PIVRE,,English,Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85113621541
"Chen Z., Xie L., Pang S., He Y., Zhang B.",57212484869;35189768200;55643891500;57219590947;57222998060;,MagDr: Mask-guided Detection and Reconstruction for Defending Deepfakes,2021,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,,,,9010,9019,,1,10.1109/CVPR46437.2021.00890,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113617166&doi=10.1109%2fCVPR46437.2021.00890&partnerID=40&md5=8e1f0e744c0e2695ad56f889f650c46b,Xi'an Jiaotong University; Huawei Inc; Tencent Blade Team,"Chen, Z., Xi'an Jiaotong University; Xie, L., Huawei Inc; Pang, S., Xi'an Jiaotong University; He, Y., Xi'an Jiaotong University; Zhang, B., Tencent Blade Team","Deepfakes raised serious concerns on the authenticity of visual contents. Prior works revealed the possibility to disrupt deepfakes by adding adversarial perturbations to the source data, but we argue that the threat has not been eliminated yet. This paper presents MagDR, a mask-guided detection and reconstruction pipeline for defending deepfakes from adversarial attacks. MagDR starts with a detection module that defines a few criteria to judge the abnormality of the output of deepfakes, and then uses it to guide a learnable reconstruction procedure. Adaptive masks are extracted to capture the change in local facial regions. In experiments, MagDR defends three main tasks of deepfakes, and the learned reconstruction pipeline transfers across input data, showing promising performance in defending both black-box and white-box attacks. © 2021 IEEE.",,Computer vision; Black boxes; Detection modules; Input datas; Local facial regions; Main tasks; Performance; Reconstruction procedure; Source data; Visual content; White box; Pipelines,,,,,"Carlini, N., Athalye, A., Papernot, N., Brendel, W., Rauber, J., Tsipras, D., Goodfellow, I., Kurakin, A., (2019) On Evaluating Adversarial Robustness, , arXiv preprint 3, 7; Carlini, N., Farid, H., (2020) Evading Deepfake-Image Detectors with White- and Black-Box Attacks, , 2, 3; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) ACM Workshop on Artificial Intelligence and Security (AISec), , 3; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 Ieee Symposium on Security and Privacy (Sp), pp. 39-57. , IEEE, 2, 3; Chen, Z., Xie, L., Pang, S., He, Y., Tian, Q., (2019) Appending Adversarial Frames for Universal Video Attack, , 2; Choi, Y., Choi, M., Kim, M., Ha, J.W., Kim, S., Choo, J., Stargan: Unified generative adversarial networks for multi-domain image-to-image translation (2018) Proc. IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2, p. 3; Cohen, G., Sapiro, G., Giryes, R., Detecting adversarial samples using influence functions and nearest neighbors (2020) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), , June 6, 7; Dang, H., Liu, F., Stehouwer, J., Liu, X., Jain, A., On the detection of digital face manipulation (2020) Proc. IEEE/CVF Conference on Computer Vision and Pattern Recognition, , 2; Dziugaite, G.K., Ghahramani, Z., Roy, D.M., (2016) A Study of the Effect of Jpg Compression on Adversarial Images, , 2, 7, 8; Gandhi, A., Jain, S., (2020) Adversarial Perturbations Fool Deepfake Detectors, , 2, 3; Gonzalez-Sosa, E., Fierrez, J., Vera-Rodriguez, R., Alonso-Fernandez, F., Facial soft biometrics for recognition in the wild: Recent works, annotation and COTS evaluation (2018) IEEE Transactions on Information Forensics and Security, 13 (8), pp. 2001-2014. , 2; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , 2; He, Z., Zuo, W., Kan, M., Shan, S., Chen, X., Attgan: Facial attribute editing by only changing what you want (2019) IEEE Transactions on Image Processing, 28 (11), pp. 5464-5478. , 2; Herley, C., van Oorschot, P.C., Sok: Science, security and the elusive goal of security as a scientific pursuit (2017) 2017 IEEE Symposium on Security and Privacy (S&P), pp. 99-120. , IEEE, 3; Karras, T., Aila, T., Laine, S., Lehtinen, J., Progressive growing of GANs for improved quality, stability, and variation (2018) Proc. International Conference on Learning Representations, , 2; Karras, T., Laine, S., Aila, T., A style-based generator architecture for generative adversarial networks (2019) Proc. IEEE/CVF Conference on Computer Vision and Pattern Recognition, , 2; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , 2, 3; Lee, C.-H., Liu, Z., Wu, L., Luo, P., (2019) Maskgan: Towards Diverse and Interactive Facial Image Manipulation, , arXiv preprint 4; Li, L., Bao, J., Yang, H., Chen, D., Wen, F., (2019) Faceshifter: Towards High Fidelity and Occlusion Aware Face Swapping, , arXiv preprint 2; Li, L., Bao, J., Zhang, T., Yang, H., Chen, D., Wen, F., Guo, B., Face x-ray for more general face forgery detection (2020) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 5001-5010. , 3; Liang, B., Li, H., Su, M., Li, X., Shi, W., Wang, X., Detecting adversarial image examples in deep neural networks with adaptive noise reduction (2019) IEEE Transactions on Dependable and Secure Computing, p. 1. , 3; Liu, M., Ding, Y., Xia, M., Liu, X., Ding, E., Zuo, W., Wen, S., STGAN: A unified selective transfer network for arbitrary image attribute editing (2019) Proc. IEEE/CVF Conference on Computer Vision and Pattern Recognition, , 2; Liu, Z., Luo, P., Wang, X., Tang, X., Deep learning face attributes in the wild (2015) Proceedings of International Conference on Computer Vision (ICCV), , December 2, 6; Lu, J., Issaranon, T., Forsyth, D., SafeTyNet: Detecting and rejecting adversarial examples robustly (2017) Proceedings of the IEEE International Conference on Computer Vision, pp. 446-454. , 2, 3, 6, 7; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , 2, 3; Meng, D., Chen, H., Magnet: A two-pronged defense against adversarial examples (2017) Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pp. 135-147. , 2, 3, 6, 7, 8; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., (2017) On Detecting Adversarial Perturbations, , arXiv preprint 2, 3, 6, 7; Mirsky, Y., Lee, W., (2020) The Creation and Detection of Deepfakes: A Survey, , 2; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) CVPR, , 2; Mustafa, A., Khan, S.H., Hayat, M., Shen, J., Shao, L., Image super-resolution as a defense against adversarial attacks (2020) IEEE Transactions on Image Processing, 29, pp. 1711-1724. , 2, 7, 8; Neekhara, P., Hussain, S., Jere, M., Koushanfar, F., McAuley, J., (2020) Adversarial Deepfakes: Evaluating Vulnerability of Deepfake Detectors to Adversarial Examples, , 2, 3; Neves, J.C., Tolosana, R., Vera-Rodriguez, R., Lopes, V., Proença, H., Fierrez, J., Ganprintr: Improved fakes and evaluation of the state-of-the-art in face manipulation detection (2020) IEEE Journal of Selected Topics in Signal Processing, , 2; Nirkin, Y., Keller, Y., Hassner, T., FSGAN: Subject agnostic face swapping and reenactment (2019) Proceedings of the IEEE International Conference on Computer Vision, pp. 7184-7193. , 2; Prakash, A., Moran, N., Garber, S., DiLillo, A., Storer, J., Deflecting adversarial attacks with pixel deflection (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 8571-8580. , 7, 8; Pumarola, A., Agudo, A., Martinez, A.M., Sanfeliu, A., Moreno-Noguer, F., Ganimation: Anatomically-aware facial animation from a single image (2018) Proceedings of the European Conference on Computer Vision (ECCV), pp. 818-833. , 2, 3; Rathgeb, C., Botaljov, A., Stockhardt, F., Isadskiy, S., Debiasi, L., Uhl, A., Busch, C., PRNU-based Detection of Facial Retouching (2020) IET Biometrics, , 2, 3; Rossler, A., Cozzolino, D., Verdoliva, L., Riess, C., Thies, J., Nießner, M., Faceforensics++: Learning to detect manipulated facial images (2019) Proceedings of the IEEE International Conference on Computer Vision, pp. 1-11. , 2, 6; Ruiz, N., Bargal, S.A., Sclaroff, S., (2020) Disrupting Deepfakes: Adversarial Attacks Against Conditional Image Translation Networks and Facial Manipulation Systems, , 2, 3, 6, 7, 8; Samangouei, P., Kabkab, M., Chellappa, R., (2018) Defense-Gan: Protecting Classifiers Against Adversarial Attacks Using Generative Models, , 2; Stehouwer, J., Dang, H., Liu, F., Liu, X., Jain, A., (2019) On the Detection of Digital Face Manipulation, , arXiv preprint 3; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , 2; Thies, J., Zollhöfer, M., Nießner, M., Deferred neural rendering: Image Synthesis using Neural Textures (2019) ACM Transactions on Graphics, 38 (66), pp. 1-12. , 2; Thies, J., Zollhofer, M., Stamminger, M., Theobalt, C., Nießner, M., Face2Face: Real-time face capture and reenactment of RGB videos (2016) Proc. IEEE/CVF Conference on Computer Vision and Pattern Recognition, , 2; Tolosana, R., Vera-Rodriguez, R., Fierrez, J., Morales, A., Ortega-Garcia, J., (2020) Deepfakes and Beyond: A Survey of Face Manipulation and Fake Detection, , 2; Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses, , arXiv preprint 3; Wang, S.-Y., Wang, O., Zhang, R., Owens, A., Efros, A.A., Cnn-generated images are surprisingly easy to spot... For now (2020) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 7. , 3; Wei, Y., Gan, Z., Li, W., Lyu, S., Chang, M.-C., Zhang, L., Gao, J., Zhang, P., Maggan: High-resolution face attribute editing with mask-guided generative adversarial network (2020) Proceedings of the Asian Conference on Computer Vision (ACCV), , November 4; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., Mitigating adversarial effects through randomization (2018) International Conference on Learning Representations, , 2, 7, 8; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., Adversarial examples for semantic segmentation and object detection (2017) ICCV, , 2; Xu, W., Evans, D., Qi, Y., Feature squeezing: Detecting adversarial examples in deep neural networks (2018) Proceedings 2018 Network and Distributed System Security Symposium, , 3; Xu, Y., Wu, B., Shen, F., Fan, Y., Zhang, Y., Shen, H.T., Liu, W., Exact adversarial attack to image captioning via structured output learning with latent variables (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4135-4144. , 2; Yang, Y., Zhang, G., Katabi, D., Xu, Z., (2019) Me-Net: Towards Effective Adversarial Robustness with Matrix Estimation, , arXiv preprint 7, 8; Yeh, C.-Y., Chen, H.-W., Tsai, S.-L., Wang, S.-D., Disrupting image-translation-based deepfake algorithms with adversarial attacks (2020) The IEEE Winter Conference on Applications of Computer Vision (WACV) Workshops, , March 2, 3; Yu, C., Wang, J., Peng, C., Gao, C., Yu, G., Sang, N., BiseNet: Bilateral segmentation network for real-time semantic segmentation (2018) ECCV, , 4; Yuan, X., He, P., Zhu, Q., Li, X., Adversarial examples: Attacks and defenses for deep learning (2019) IEEE Transactions on Neural Networks and Learning Systems, pp. 1-20. , 01 3; Zhang, X., Karaman, S., Chang, S.F., Detecting and simulating artifacts in GaN fake images (2019) Proc. IEEE International Workshop on Information Forensics and Security, , 2, 3; Zhu, J.-Y., Park, T., Isola, P., Efros, A.A., Unpaired image-to-image translation using cycle-consistent adversarial networks (2017) Proceedings of the IEEE International Conference on Computer Vision, pp. 2223-2232. , 2, 3",,,,IEEE Computer Society,"2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2021",19 June 2021 through 25 June 2021,,174911,10636919,9.78E+12,PIVRE,,English,Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85113617166
"Wang Y., Song X., Xu T., Feng Z., Wu X.-J.",57219018574;8304894200;56733963300;55185136000;56191888600;,From RGB to Depth: Domain Transfer Network for Face Anti-Spoofing,2021,IEEE Transactions on Information Forensics and Security,16,,,4280,4290,,,10.1109/TIFS.2021.3102448,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112201292&doi=10.1109%2fTIFS.2021.3102448&partnerID=40&md5=ff7eb9b15d901f3e92cbbc6e17e128a3,"School of Artificial Intelligence and Computer Science, Jiangnan University, Wuxi, 214122, China; Centre for Vision, Speech and Signal Processing, University of Surrey, Guildford, GU2 7XH, United Kingdom; Department of Computer Science, University of Surrey, Guildford, GU2 7XH, United Kingdom","Wang, Y., School of Artificial Intelligence and Computer Science, Jiangnan University, Wuxi, 214122, China; Song, X., School of Artificial Intelligence and Computer Science, Jiangnan University, Wuxi, 214122, China; Xu, T., Centre for Vision, Speech and Signal Processing, University of Surrey, Guildford, GU2 7XH, United Kingdom; Feng, Z., Centre for Vision, Speech and Signal Processing, University of Surrey, Guildford, GU2 7XH, United Kingdom, Department of Computer Science, University of Surrey, Guildford, GU2 7XH, United Kingdom; Wu, X.-J., School of Artificial Intelligence and Computer Science, Jiangnan University, Wuxi, 214122, China","With the rapid development in face recognition, most of the existing systems can perform very well in unconstrained scenarios. However, it is still a very challenging task to detect face spoofing attacks, thus face anti-spoofing has become one of the most important research topics in the community. Though various anti-spoofing models have been proposed, the generalisation capability of these models usually degrades for unseen attacks in the presence of challenging appearance variations, e.g., background, illumination, diverse spoofing materials and low image quality. To address this issue, we propose to use a Generative Adversarial Network (GAN) that transfers an input face image from the RGB domain to the depth domain. The generated depth clue enables biometric preservation against challenging appearance variations and diverse image qualities. To be more specific, the proposed method has two main stages. The first one is a GAN-based domain transfer module that converts an input image to its corresponding depth map. By design, a live face image should be transferred to a depth map whereas a spoofing face image should be transferred to a plain (black) image. The aim is to improve the discriminative capability of the proposed system. The second stage is a classification model that determines whether an input face image is live or spoofing. Benefit from the use of the GAN-based domain transfer module, the latent variables can effectively represent the depth information, complementarily enhancing the discrimination of the original RGB features. The experimental results obtained on several benchmarking datasets demonstrate the effectiveness of the proposed method, with superior performance over the state-of-the-art methods. The source code of the proposed method is publicly available at https://github.com/coderwangson/DFA. © 2005-2012 IEEE.",domain transfer; Face anti-spoofing; generative adversarial network,Benchmarking; Image quality; Adversarial networks; Classification models; Depth information; Domain transfers; Existing systems; Research topics; Spoofing attacks; State-of-the-art methods; Face recognition,,,,,"Taigman, Y., Yang, M., Ranzato, M., Wolf, L., DeepFace: Closing the gap to human-level performance in face verification (2014) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 1701-1708. , Jun; Akbari, A., Awais, M., Feng, Z., Farooq, A., Kittler, J., Distribution cognisant loss for cross-database facial age estimation with sensitivity analysis (2020) IEEE Trans. Pattern Anal. Mach. Intell., , early access, Oct. 7; Khalid, S.S., Resolution invariant face recognition using a distillation approach (2020) IEEE Trans. Biometrics, Behav., Identity Sci., 2 (4), pp. 410-420. , Oct; Shao, C., Biased feature learning for occlusion invariant face recognition (2020) Proc. 29th Int. Joint Conf. Artif. Intell., pp. 666-672. , Jul; Hernandez-Ortega, J., Fierrez, J., Morales, A., Galbally, J., Introduction to face presentation attack detection (2019) Handbook of Biometric Anti-Spoofing, pp. 187-206. , Cham, Switzerland: Springer; Hadid, A., Evans, N., Marcel, S., Fierrez, J., Biometrics systems under spoofing attack: An evaluation methodology and lessons learned (2015) IEEE Signal Process. Mag., 32 (5), pp. 20-30. , Sep; Galbally, J., Marcel, S., Fierrez, J., Biometric antispoofing methods: A survey in face recognition (2014) IEEE Access, 2, pp. 1530-1552; Chingovska, I., Anjos, A., Marcel, S., On the effectiveness of local binary patterns in face anti-spoofing (2012) Proc. Int. Conf. Biometrics Special Interest Group (BIOSIG), pp. 1-7; Boulkenafet, Z., Komulainen, J., Hadid, A., Face antispoofing using speeded-up robust features and Fisher vector encoding (2017) IEEE Signal Process. Lett., 24 (2), pp. 141-145. , Feb; Dalal, N., Triggs, B., Histograms of oriented gradients for human detection (2005) Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit., 1, pp. 886-893. , Jun; Yang, J., Lei, Z., Li, S.Z., (2014) Learn Convolutional Neural Network for Face Anti-spoofing, , http://arxiv.org/abs/1408.5601; Li, L., Feng, X., Boulkenafet, Z., Xia, Z., Li, M., Hadid, A., An original face anti-spoofing approach using partial convolutional neural network (2016) Proc. 6th Int. Conf. Image Process. Theory, Tools Appl. (IPTA), pp. 1-6. , Dec; Atoum, Y., Liu, Y., Jourabloo, A., Liu, X., Face anti-spoofing using patch and depth-based CNNs (2017) Proc. IEEE Int. Joint Conf. Biometrics (IJCB), pp. 319-328. , Oct; Liu, Y., Jourabloo, A., Liu, X., Learning deep models for face antispoofing: Binary or auxiliary supervision (2018) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., pp. 389-398. , Jun; Zhang, Z., Yan, J., Liu, S., Lei, Z., Yi, D., Li, S.Z., A face antispoofing database with diverse attacks (2012) Proc. 5th IAPR Int. Conf. Biometrics (ICB), pp. 26-31. , Mar; Feng, Y., Wu, F., Shao, X., Wang, Y., Zhou, X., Joint 3D face reconstruction and dense alignment with position map regression network (2018) Computer Vision-ECCV 2018. Springer, pp. 557-574; Pereira, T.D.F., Face liveness detection using dynamic texture (2014) EURASIP J. Image Video Process., 2014 (1), p. 2. , Dec; Galbally, J., Marcel, S., Fierrez, J., Image quality assessment for fake biometric detection: Application to iris, fingerprint, and face recognition (2013) IEEE Trans. Image Process., 23 (2), pp. 710-724. , Nov; Patel, K., Han, H., Jain, A., Secure face unlock: Spoof detection on smartphones (2016) IEEE Trans. Inf. Forensics Security, 11 (10), pp. 2268-2283. , Jun; Boulkenafet, Z., Komulainen, J., Hadid, A., Face anti-spoofing based on color texture analysis (2015) Proc. IEEE Int. Conf. Image Process. (ICIP), pp. 2636-2640. , Sep; Boulkenafet, Z., Komulainen, J., Hadid, A., Face spoofing detection using colour texture analysis (2016) IEEE Trans. Inf. Forensics Security, 11 (8), pp. 1818-1830. , Aug; Pan, G., Sun, L., Wu, Z., Lao, S., Eyeblink-based anti-spoofing in face recognition from a generic webcamera (2007) Proc. IEEE 11th Int. Conf. Comput. Vis., pp. 1-8; Kollreider, K., Fronthaler, H., Faraj, M.I., Bigun, J., Real-time face detection and motion analysis with application in 'liveness' assessment (2007) IEEE Trans. Inf. Forensics Security, 2 (3), pp. 548-558. , Aug; Komulainen, J., Hadid, A., Pietikäinen, M., Anjos, A., Marcel, S., Complementary countermeasures for detecting scenic face spoofing attacks (2013) Proc. Int. Conf. Biometrics (ICB), pp. 1-7. , Jun; Agarwal, A., Singh, R., Vatsa, M., Face anti-spoofing using Haralick features (2016) Proc. IEEE 8th Int. Conf. Biometrics Theory, Appl. Syst. (BTAS), pp. 1-6. , Sep; Siddiqui, T.A., Face anti-spoofing with multifeature videolet aggregation (2016) Proc. 23rd Int. Conf. Pattern Recognit. (ICPR), pp. 1035-1040. , Dec; Bao, W., Li, H., Li, N., Jiang, W., A liveness detection method for face recognition based on optical flow field (2009) Proc. Int. Conf. Image Anal. Signal Process., pp. 233-236; Lucena, O., Junior, A., Moia, V., Souza, R., Valle, E., Lotufo, R., Transfer learning using convolutional neural networks for face antispoofing (2017) Image Analysis and Recognition, pp. 27-34. , Cham, Switzerland: Springer; Feng, Z.-H., Kittler, J., Awais, M., Wu, X.-J., Rectified wing loss for efficient and robust facial landmark localisation with convolutional neural networks (2019) Int. J. Comput. Vis., 128, pp. 2126-2145. , Dec; Patel, K., Han, H., Jain, A., Cross-database face antispoofing with robust feature representation (2016) Proc. Chin. Conf. Biometric Recognit, pp. 611-619. , Cham, Switzerland: Springer; Feng, L., Po, L., Li, Y., Integration of image quality and motion cues for face anti-spoofing: A neural network approach (2016) J. Vis. Commun. Image Represent., 38 (1), pp. 451-460. , Jul; Xu, Z., Li, S., Deng, W., Learning temporal features using LSTMCNN architecture for face anti-spoofing (2015) Proc. 3rd IAPR Asian Conf. Pattern Recognit. (ACPR), pp. 141-145. , Nov; Gan, J., Li, S., Zhai, Y., Liu, C., 3D convolutional neural network based on face anti-spoofing (2017) Proc. 2nd Int. Conf. Multimedia Image Process. (ICMIP), pp. 1-5. , Mar; Jia, Y., Zhang, J., Shan, S., Chen, X., (2020) Single-side Domain Generalization for Face Anti-spoofing, , http://arxiv.org/abs/2004.14043; Tu, X., Zhang, H., Xie, M., Luo, Y., Zhang, Y., Ma, Z., Deep transfer across domains for face antispoofing (2019) J. Electron. Imag., 28 (4); Pérez-Cabo, D., Jiménez-Cabello, D., Costa-Pazo, A., López-Sastre, R.J., Deep anomaly detection for generalized face anti-spoofing (2019) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. Workshops (CVPRW), pp. 1591-1600. , Jun; Fatemifar, S., Arashloo, S.R., Awais, M., Kittler, J., Spoofing attack detection by anomaly detection (2019) Proc. IEEE Int. Conf. Acoust., Speech Signal Process. (ICASSP), pp. 8464-8468. , May; Goodfellow, I., Generative adversarial nets (2014) Advances in Neural Information Processing Systems 27, pp. 2672-2680. , Red Hook, NY, USA: Curran Associates; Hu, C., Feng, Z., Wu, X., Kittler, J., Dual encoder-decoder based generative adversarial networks for disentangled facial representation learning (2020) IEEE Access, 8, pp. 130159-130171; Song, X., Chen, Y., Feng, Z.-H., Hu, G., Yu, D.-J., Wu, X.-J., SP-GAN: Self-growing and pruning generative adversarial networks (2021) IEEE Trans. Neural Netw. Learn. Syst., 32 (6), pp. 2458-2469. , Jun; Li, C., Wand, M., Precomputed real-time texture synthesis with Markovian generative adversarial networks (2016) Computer Vision- ECCV 2016, pp. 702-716. , Cham, Switzerland: Springer; Pathak, D., Krähenbühl, P., Donahue, J., Darrell, T., Efros, A.A., Context encoders: Feature learning by inpainting (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 2536-2544. , Jun; Ledig, C., Photo-realistic single image super-resolution using a generative adversarial network (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 105-114. , Jul; Isola, P., Zhu, J.-Y., Zhou, T., Efros, A.A., Image-to-image translation with conditional adversarial networks (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 5967-5976. , Jul; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 770-778. , Jun; Boulkenafet, Z., Komulainen, J., Li, L., Feng, X., Hadid, A., OULUNPU: A mobile face presentation attack database with real-world variations (2017) Proc. 12th IEEE Int. Conf. Autom. Face Gesture Recognit. (FG), pp. 612-618. , May; Wen, D., Han, H., Jain, A.K., Face spoof detection with image distortion analysis (2015) IEEE Trans. Inf. Forensics Security, 10 (4), pp. 746-761. , Apr; Information Technology-Biometric Presentation Attack Detection-Part 1: Framework, document ISO/IEC JTC 1/SC 37 Biometrics, International Organization for Standardization, 2016; Huang, G., Liu, Z., Maaten Der, L.Van, Weinberger, K.Q., Densely connected convolutional networks (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 4700-4708. , Jul; Zhang, K., Zhang, Z., Li, Z., Qiao, Y., Joint face detection and alignment using multitask cascaded convolutional networks (2016) IEEE Signal Process. Lett., 23 (10), pp. 1499-1503. , Oct; Kingma, D.P., Ba, J., (2014) Adam: A Method for Stochastic Optimization, , http://arxiv.org/abs/1412.6980; Chen, H., Chen, Y., Tian, X., Jiang, R., A cascade face spoofing detector based on face anti-spoofing R-CNN and improved retinex LBP (2019) IEEE Access, 7, pp. 170116-170133; Zhou, F., Face anti-spoofing based on multi-layer domain adaptation (2019) Proc. IEEE Int. Conf. Multimedia Expo Workshops (ICMEW), pp. 192-197. , Jul; Li, H., He, P., Wang, S., Rocha, A., Jiang, X., Kot, A.C., Learning generalized deep feature representation for face anti-spoofing (2018) IEEE Trans. Inf. Forensics Security, 13 (10), pp. 2639-2652. , Oct; Chen, H., Hu, G., Lei, Z., Chen, Y., Robertson, N.M., Li, S.Z., Attention-based two-stream convolutional networks for face spoofing detection (2020) IEEE Trans. Inf. Forensics Security, 15, pp. 578-593; Galbally, J., Marcel, S., Face anti-spoofing based on general image quality assessment (2014) Proc. 22nd Int. Conf. Pattern Recognit., pp. 1173-1178. , Aug; Boulkenafet, Z., A competition on generalized software-based face presentation attack detection in mobile scenarios (2017) Proc. IEEE Int. Joint Conf. Biometrics (IJCB), pp. 688-696. , Oct; Jourabloo, A., Liu, Y., Liu, X., Face de-spoofing: Anti-spoofing via noise modeling (2018) Proc. Eur. Conf. Comput. Vis. (ECCV), pp. 290-306; Yang, X., Face anti-spoofing: Model matters, so does data (2019) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 3502-3511. , Jun; Liu, Y., Stehouwer, J., Liu, X., (2020) On Disentangling Spoof Trace for Generic Face Anti-spoofing, , http://arxiv.org/abs/2007.09273; Wang, Z., Deep spatial gradient and temporal depth learning for face anti-spoofing (2020) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 5042-5051. , Jun; Shao, R., Lan, X., Li, J., Yuen, P.C., Multi-adversarial discriminative deep domain generalization for face presentation attack detection (2019) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 10023-10031. , Jun; Wang, G., Han, H., Shan, S., Chen, X., Unsupervised adversarial domain adaptation for cross-domain face presentation attack detection (2021) IEEE Trans. Inf. Forensics Security, 16, pp. 56-69; Menotti, D., Deep representations for iris, face, and fingerprint spoofing detection (2015) IEEE Trans. Inf. Forensics Security, 10 (4), pp. 864-879. , Apr; Tu, X., (2019) Learning Generalizable and Identity-discriminative Representations for Face Anti-spoofing, , http://arxiv.org/abs/1901.05602; Selvaraju, R.R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., Batra, D., Grad-CAM: Visual explanations from deep networks via gradient-based localization (2017) Proc. IEEE Int. Conf. Comput. Vis. (ICCV), pp. 618-626. , Oct; Hernandez-Ortega, J., Fierrez, J., Morales, A., Tome, P., Time analysis of pulse-based face anti-spoofing in visible and NIR (2018) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. Workshops (CVPRW), pp. 657-6578. , Jun","Song, X.; School of Artificial Intelligence and Computer Science, China; 电子邮件: x.song@jiangnan.edu.cn",,,Institute of Electrical and Electronics Engineers Inc.,,,,,15566013,,,,English,IEEE Trans. Inf. Forensics Secur.,Article,Final,"All Open Access, Green",Scopus,2-s2.0-85112201292
"Ong D.S., Chan C.S., Ng K.W., Fan L., Yang Q.",57222191063;57194450557;57218717926;56152335900;57226847285;,Protecting Intellectual Property of Generative Adversarial Networks from Ambiguity Attacks,2021,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,,,,3629,3638,,3,10.1109/CVPR46437.2021.00363,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111484905&doi=10.1109%2fCVPR46437.2021.00363&partnerID=40&md5=17a9f4feac4714f8982e2ea323947d71,"University of Malaya, Malaysia; WeBank AI Lab; Hong Kong University of Science and Technology, Hong Kong","Ong, D.S., University of Malaya, Malaysia; Chan, C.S., University of Malaya, Malaysia; Ng, K.W., WeBank AI Lab; Fan, L., WeBank AI Lab; Yang, Q., Hong Kong University of Science and Technology, Hong Kong","Ever since Machine Learning as a Service emerges as a viable business that utilizes deep learning models to generate lucrative revenue, Intellectual Property Right (IPR) has become a major concern because these deep learning models can easily be replicated, shared, and re-distributed by any unauthorized third parties. To the best of our knowledge, one of the prominent deep learning models - Generative Adversarial Networks (GANs) which has been widely used to create photorealistic image are totally unprotected despite the existence of pioneering IPR protection methodology for Convolutional Neural Networks (CNNs). This paper therefore presents a complete protection framework in both black-box and white-box settings to enforce IPR protection on GANs. Empirically, we show that the proposed method does not compromise the original GANs performance (i.e. image generation, image super-resolution, style transfer), and at the same time, it is able to withstand both removal and ambiguity attacks against embedded watermarks. Codes are available at https://github.com/dingsheng-ong/ipr-gan. © 2021 IEEE",,Computer vision; Convolutional neural networks; Deep learning; Intellectual property; Black boxes; Convolutional neural network; Intellectual property rights; Intellectual property rights protections; Learning models; Machine-learning; Photorealistic images; Protection methodology; Third parties; White box; Generative adversarial networks,,,,,"Adi, Y., Baum, C., Cisse, M., Pinkas, B., Keshet, J., Turning your weakness into a strength: Watermarking deep neural networks by backdooring (2018) 27th {USENIX} Security Symposium ({USENIX} Security 18), pp. 1615-1631; Asikuzzaman, M., Pickering, M.R., An overview of digital video watermarking (2018) IEEE Transactions on Circuits and Systems for Video Technology, 28 (9), pp. 2131-2153; Chen, H., Rohani, B.D., Koushanfar, F., (2018) DeepMarks: A Digital Fingerprinting Framework for Deep Neural Networks, , Apr; Cordts, M., Omran, M., Ramos, S., Rehfeld, T., Enzweiler, M., Benenson, R., Franke, U., Schiele, B., The cityscapes dataset for semantic urban scene understanding (2016) CVPR, pp. 3213-3223; Creswell, A., White, T., Dumoulin, V., Arulkumaran, K., Sengupta, B., Bharath, A.A., Generative adversarial networks: An overview (2018) IEEE Signal Processing Magazine, 35, pp. 53-65; Rohani, B.D., Chen, H., Koushanfar, F., (2018) DeepSigns: A Generic Watermarking Framework for IP Protection of Deep Learning Models, , Apr; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., ImageNet: A large-scale hierarchical image database (2009) CVPR; Erfani, Y., Pichevar, R., Rouat, J., Audio watermarking using spikegram and a two-dictionary approach (2017) IEEE Transactions on Information Forensics and Security, 12 (4), pp. 840-852; Fan, L., Ng, K.W., Chan, C.S., Rethinking deep neural network ownership verification: Embedding passports to defeat ambiguity attacks (2019) NeurIPS, pp. 4714-4723; Fang, H., Zhang, W., Zhou, H., Cui, H., Yu, N., Screen-shooting resilient watermarking (2019) IEEE Transactions on Information Forensics and Security, 14 (6), pp. 1403-1418; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) NeurIPS, pp. 2672-2680; Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., Hochreiter, S., Gans trained by a two time-scale update rule converge to a local nash equilibrium (2017) NeurIPS, pp. 6626-6637; Hwang, M.-J., Lee, J., Lee, M., Kang, H.-G., SVD-based adaptive qim watermarking on stereo audio signals (2018) IEEE Transactions on Multimedia, 20 (1), pp. 45-54; Jia, G., Potkonjak, M., Watermarking deep neural networks for embedded systems (2018) IEEE/ACM International Conference on Computer-Aided Design (ICCAD), pp. 1-8; Krizhevsky, A., Nair, V., Hinton, G., Cifar-10 (Canadian Institute for Advanced Research); Le Merrer, E., Perez, P., Trédan, G., Adversarial frontier stitching for remote neural network watermarking (2020) Neural Computing and Applications, 32 (13), pp. 9233-9244; Ledig, C., Theis, L., Huszár, F., Caballero, J., Cunningham, A., Acosta, A., Aitken, A., Wang, Z., Photo-realistic single image super-resolution using a generative adversarial network (2017) CVPR, pp. 4681-4690; Lin, Z.-X., Peng, F., Long, M., A low-distortion reversible watermarking for 2d engineering graphics based on region nesting (2018) IEEE Transactions on Information Forensics and Security, 13 (9), pp. 2372-2382; Mareen, H., de Praeter, J., van Wallendael, G., Lambert, P., A scalable architecture for uncompressed-domain watermarked videos (2019) IEEE Transactions on Information Forensics and Security, 14 (6), pp. 1432-1444; Miyato, T., Kataoka, T., Koyama, M., Yoshida, Y., Spectral normalization for generative adversarial networks (2018) ICLR; Mun, S.-M., Nam, S.-H., Jang, H.-U., Kim, D., Lee, H.-K., (2017) A Robust Blind Watermarking Using Convolutional Neural Network; Nadeau, A., Sharma, G., An audio watermark designed for efficient and robust resynchronization after analog playback (2017) IEEE Transactions on Information Forensics and Security, 12 (6), pp. 1393-1405; Nezhadarya, E., Wang, Z.J., Ward, R.K., Robust image watermarking based on multiscale gradient direction quantization (2011) IEEE Transactions on Information Forensics and Security, 6 (4), pp. 1200-1213; Radford, A., Metz, L., Chintala, S., (2015) Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks; Uchida, Y., Nagai, Y., Sakazawa, S., Satoh, S., Embedding watermarks into deep neural networks (2017) Proceedings of the 2017 ACM on International Conference on Multimedia Retrieval, pp. 269-277; Vukoti, V., Chappelier, V., Furon, T., Are deep neural networks good for blind image watermarking? (2018) International Workshop on Information Forensics and Security (WIFS), pp. 1-7; Wang, Z., Bovik, A.C., Sheikh, H.R., Simoncelli, E.P., Image quality assessment: From error visibility to structural similarity (2004) IEEE Transactions on Image Processing, 13 (4), pp. 600-612; Welinder, P., Branson, S., Mita, T., Wah, C., Schroff, F., Belongie, S., Perona, P., (2010) Caltech-UCSD Birds 200, , Technical California Institute of Technology; Zhang, J., Chen, D., Liao, J., Zhang, W., Hua, G., Yu, N., Passport-aware normalization for deep model protection (2020) NeurIPS; Zhang, J., Gu, Z., Jang, J., Wu, H., Stoecklin, M.P., Huang, H., Molloy, I., Protecting intellectual property of deep neural networks with watermarking (2018) Proceedings of the 2018 on Asia Conference on Computer and Communications Security (ASIACCS), pp. 159-172; Zhu, J., Kaplan, R., Johnson, J., Fei-Fei, L., Hidden: Hiding data with deep networks (2018) ECCV, pp. 682-697; Zhu, J.-Y., Park, T., Isola, P., Efros, A.A., Unpaired image-to-image translation using cycle-consistent adversarial networks (2017) ICCV; Zhu, J.-Y., Park, T., Isola, P., Efros, A.A., Unpaired image-to-image translation using cycle-consistent adversarial networks (2017) ICCV, pp. 2223-2232","Chan, C.S.; University of MalayaMalaysia; 电子邮件: cs.chan@um.edu.my",,,IEEE Computer Society,"2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2021",19 June 2021 through 25 June 2021,,174911,10636919,9.78E+12,PIVRE,,English,Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit,Conference Paper,Final,,Scopus,2-s2.0-85111484905
"Xu H., Wang R., Raizman L., Rabinovich Z.",57226796918;57219437425;57226681005;15056688900;,Transferable environment poisoning: Training-time attack on reinforcement learning,2021,"Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS",3,,,1386,1394,,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111184575&partnerID=40&md5=830d738743ed2d7e10c064b8a82d0e80,"Nanyang Technological University, Singapore; University of Waterloo, Waterloo, Canada","Xu, H., Nanyang Technological University, Singapore; Wang, R., Nanyang Technological University, Singapore; Raizman, L., University of Waterloo, Waterloo, Canada; Rabinovich, Z., Nanyang Technological University, Singapore","Studying adversarial attacks on Reinforcement Learning (RL) agents has become a key aspect of developing robust, RL-based solutions. Test-time attacks, which target the post-learning performance of an RL agent's policy, have been well studied in both white- and black-box settings. More recently, however, state-of-the-art works have shifted to investigate training-time attacks on RL agents, i.e., forcing the learning process towards a target policy designed by the attacker. Alas, these SOTA works continue to rely on white-box settings and/or use a reward-poisoning approach. In contrast, this paper studies environment-dynamics poisoning attacks at training time. Furthermore, while environment-dynamics poisoning presumes a transfer-learning capable agent, it also allows us to expand our approach to black-box attacks. Our overall framework, inspired by hierarchical RL, seeks the minimal environment-dynamics manipulation that will prompt the momentary policy of the agent to change in a desired manner. We show the attack efficiency by comparing it with the reward-poisoning approach, and empirically demonstrate the transferability of the environment-poisoning attack strategy. Finally, we seek to exploit the transferability of the attack strategy to handle black-box settings. © 2021 International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org). All rights reserved.",Environment Poisoning; Reinforcement Learning; Security,Dynamics; Multi agent systems; Reinforcement learning; Transfer learning; Attack strategies; Environment dynamics; Learning performance; Learning process; Poisoning attacks; Reinforcement learning agent; State of the art; Training time; Autonomous agents,,,,,"Agre, Philip E, (1988) The dynamic structure of everyday life, , Technical Report. Massachusetts Institute of Technology Cambridge Artificial Intelligence Lab; Behzadan, Vahid, Munir, Arslan, Vulnerability of Deep Reinforcement Learning to Policy Induction Attacks (2017) Proceedings of the 13th International Conference on Machine Learning and Data Mining in Pattern Recognition, pp. 262-275. , Springer, New York, USA; Brown, Daniel S, Niekum, Scott, Machine Teaching for Inverse Reinforcement Learning: Algorithms and Applications (2019) Proceedings of the 33th AAAI Conference on Artificial Intelligence, 33, pp. 7749-7758. , AAAI press, Hawaii, USA; Fujimoto, Scott, van Hoof, Herke, Meger, David, Addressing Function Approximation Error in Actor-Critic Methods (2018) Proceedings of the 35th International Conference on Machine Learning, pp. 1587-1596. , PMLR, Stockholmsmässan, Stockholm Sweden; Grover, Aditya, Al-Shedivat, Maruan, Gupta, Jayesh, Burda, Yuri, Edwards, Harrison, Learning Policy Representations in Multiagent Systems (2018) Proceedings of the 35th International Conference on Machine Learning, pp. 1802-1811. , PMLR, Stockholmsmässan, Stockholm Sweden; Henderson, Peter, Islam, Riashat, Bachman, Philip, Pineau, Joelle, Precup, Doina, Meger, David, Deep Reinforcement Learning that Matters (2017) Proceedings of the 31th AAAI Conference on Artificial Intelligence, 1, p. 26. , AAAI press, California, USA; Huang, Sandy, Papernot, Nicolas, Goodfellow, Ian, Duan, Yan, Abbeel, Pieter, Adversarial Attacks on Neural Network Policies (2017) Proceedings of the 5th International Conference on Learning Representations (Workshop), , ICLR, Vancouver, BC, Canada; Inkawhich, Matthew, Chen, Yiran, Li, Hai, Snooping Attacks on Deep Reinforcement Learning (2019) Proceedings of the 18th International Conference on Autonomous Agents and Multiagent Systems, pp. 557-565. , IFAAMS, Auckland, New Zealand; Keren, Sarah, Pineda, Luis, Gal, Avigdor, Karpas, Erez, Zilberstein, Shlomo, Equi-Reward Utility Maximizing Design in Stochastic Environments (2017) Proceedings of the 26th International Joint Conference on Artificial Intelligence, pp. 4353-4360. , IJCAI, Melbourne, Australia; Kos, Jernej, Song, Dawn, Delving into Adversarial Attacks on Deep Policies (2017) Proceedings of the 5th International Conference on Learning Representations (Workshop), p. 6. , ICLR, Vancouver, BC, Canada; Lin, Yenchen, Hong, Zhangwei, Liao, Yuan-Hong, Shih, Mengli, Liu, Mingyu, Sun, Min, Tactics of Adversarial Attack on Deep Reinforcement Learning Agents (2017) Proceedings of the 28th International Joint Conference on Artificial Intelligence, pp. 3756-3762. , IJCAI, Melbourne, Australia; Ma, Yuzhe, Zhang, Xuezhou, Sun, Wen, Zhu, Jerry, Policy Poisoning in Batch Reinforcement Learning and Control (2019) Proceedings of the 33th Conference on Neural Information Processing Systems, pp. 14570-14580. , ACM, Vancouver, Canada; Mnih, Volodymyr, Kavukcuoglu, Koray, Silver, David, Rusu, Andrei A, Veness, Joel, Bellemare, Marc G, Graves, Alex, Ostrovski, Georg, Human-level Control through Deep Reinforcement Learning (2015) Nature, 518 (7540), pp. 529-533. , (2015); Pan, Xinlei, Wang, Weiyao, Zhang, Xiaoshuai, Li, Bo, Yi, Jinfeng, Song, Dawn, How You Act Tells a Lot: Privacy-leaking Attack on Deep Reinforcement learning (2019) Proceedings of the 18th International Conference on Autonomous Agents and MultiAgent Systems, pp. 368-376. , IFAAMS, Auckland, New Zealand; Papernot, Nicolas, McDaniel, Patrick, Goodfellow, Ian, (2016) Transferability in Machine Learning: from Phenomena to Black-box Attacks using Adversarial Samples; Parameswaran, Kamalaruban, Devidze, Rati, Cevher, Volkan, Singla, Adish, Interactive Teaching Algorithms for Inverse Reinforcement Learning (2019) Proceedings of the 28th International Joint Conference on Artificial Intelligence, pp. 2692-2700. , IJCAI, Macao, China; Portelas, Rémy, Colas, Cédric, Weng, Lilian, Hofmann, Katja, Oudeyer, Pierre-Yves, Automatic Curriculum Learning for Deep RL: A Short Survey (2020) Proceedings of the 29th International Joint Conference on Artificial Intelligence. IJCAI, pp. 4819-4825. , Yokohama, Japan; Rabinovich, Zinovi, Dufton, Lachlan, Larson, Kate, Jennings, Nick, Cultivating desired behaviour: Policy teaching via environment-dynamics tweaks (2010) Proceedings of the 10th International Conference on Autonomous Agents and MultiAgent Systems, pp. 1097-1104. , IFAAMS, Toronto, Canada; Rached, Ziad, Alajaji, Fady, Campbell, L Lorne, The Kullback-Leibler Divergence Rate between Markov Sources (2004) IEEE Transactions on Information Theory, 50 (5), pp. 917-921. , (2004); Rakhsha, Amin, Radanovic, Goran, Devidze, Rati, Zhu, Xiaojin, Singla, Adish, Policy Teaching via Environment Poisoning: Training-time Adversarial Attacks against Reinforcement Learning (2020) Proceedings of the 37th International Conference on Machine Learning, pp. 7974-7984. , PMLR, Vienna, Austria; Randløv, Jette, Shaping in Reinforcement Learning by Changing the Physics of the Problem (2000) Proceedings of the 27th International Conference on Machine Learning, pp. 767-774. , PMLR, Stanford, CA, USA; Sutton, Richard S, Barto, Andrew G, (2018) Reinforcement Learning: An Introduction, , MIT press, Cambridge, Massachusetts, USA; Tretschk, Edgar, Oh, Seong Joon, Fritz, Mario, Sequential Attacks on Agents for Long-Term Adversarial Goals (2018) Proceedings of the ACM Computer Science in Cars Symposium, , ACM, Munich, Germany; Wang, Rundong, Yu, Runsheng, An, Bo, Rabinovich, Zinovi, I2HRL: Interactive Influence-based Hierarchical Reinforcement Learning (2020) Proceedings of the 29th International Joint Conference on Artificial Intelligence. IJCAI, pp. 3131-3138. , Yokohama, Japan; Zhang, Haoqi, Parkes, David C, Value-Based Policy Teaching with Active Indirect Elicitation (2008) Proceedings of the 23th AAAI Conference on Artificial Intelligence, 8, pp. 208-214. , AAAI press, Chicago, Illinois; Zhang, Haoqi, Parkes, David C, Chen, Yiling, Policy Teaching through Reward Function Learning (2009) Proceedings of the 10th ACMConference on Electronic Commerce, pp. 295-304. , Association for Computing Machinery, New York, NY, United States, California, USA; Zhang, Xuezhou, Ma, Yuzhe, Singla, Adish, Zhu, Xiaojin, Adaptive Reward-Poisoning Attacks against Reinforcement Learning (2020) Proceedings of the 37th International Conference on Machine Learning, pp. 11225-11234. , PMLR, Vienna, Austria",,,,International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS),"20th International Conference on Autonomous Agents and Multiagent Systems, AAMAS 2021",3 May 2021 through 7 May 2021,,170834,15488403,9.78E+12,,,English,"Proc. Int. Joint Conf. Auton. Agents Multiagent Syst., AAMAS",Conference Paper,Final,,Scopus,2-s2.0-85111184575
"Zhu Y., Jiang Y., Peng Z., Huang W.",56172399900;56173779100;57226322605;57218084514;,Fast category-hidden adversarial attack against semantic image segmentation,2021,International Journal of Computational Intelligence Systems,14,1,,1823,1830,,,10.2991/ijcis.d.210620.002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111171563&doi=10.2991%2fijcis.d.210620.002&partnerID=40&md5=3baa650144f9bb2d2b4b97768e326bf0,"School of Computer and Information Engineering, Hanshan Normal University, Qiaodong Street, Xiangqiao District, Chaozhou, 521041, China","Zhu, Y., School of Computer and Information Engineering, Hanshan Normal University, Qiaodong Street, Xiangqiao District, Chaozhou, 521041, China; Jiang, Y., School of Computer and Information Engineering, Hanshan Normal University, Qiaodong Street, Xiangqiao District, Chaozhou, 521041, China; Peng, Z., School of Computer and Information Engineering, Hanshan Normal University, Qiaodong Street, Xiangqiao District, Chaozhou, 521041, China; Huang, W., School of Computer and Information Engineering, Hanshan Normal University, Qiaodong Street, Xiangqiao District, Chaozhou, 521041, China","In semantic segmentation, category-hidden attack is a malicious adversarial attack which manipulates a specific category without affecting the recognition of other objects. A popular method is the nearest-neighbor algorithm, which modifies the segmentation map by replacing a target category with other categories close to it. Nearest-neighbor method aims to restrict the strength of perturbation noise that is imperceptive to both human eyes and segmentation algorithms. However, its spatial search adds lots of computational burden. In this paper, we propose two fast methods, dot-based method and line-based method, which are able to quickly complete the category transfers in logits maps without spatial search. The advantages of our two methods result from generating the logits maps by modifying the probability distribution of the category channels. Both of our methods are global, and the location and size of objects to hide are not cared, so their processing speed is very fast. The dot-based algorithm takes the pixel as the unit of calculation, and the line-based algorithm combines the category distribution characteristics of the horizontal direction to calculate. Experiments verify the effectiveness and efficiency compared with nearest-neighbor method. Specifically, in the segmentation map modification step, our methods are 5 times and 65 times faster than nearest-neighbor, respectively. In the small perturbation attack experiment, dot-based method gets the fastest speed, while different datasets and different setting experiments indicate that the line-based method is able to achieve faster and better adversarial segmentation results in most cases. © 2021 The Authors. Published by Atlantis Press B.V.",Adversarial example; Category-hidden adversarial attack (CHAA); Deep neural networks (DNNs); Logits map; Semantic segmentation,Probability distributions; Semantics; Distribution characteristics; Effectiveness and efficiencies; Line based algorithm; Nearest neighbor algorithm; Nearest neighbor method; Segmentation algorithms; Semantic image segmentations; Semantic segmentation; Image segmentation,,,,,"Szegedy, C., Zaremba, W., Bruna, I., Intriguing properties of neural networks (2014) Proceedings of the International Conference on Learning Representations (ICLR), pp. 1-10. , Banff, Canada; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Proceedings of the 2017 IEEE Symposium on Security and Privacy (SP), pp. 39-57. , San Jose, CA, USA; Papernot, N., McDanie, P., Jha, S., The limitations of deep learning in adversarial settings (2016) Proceedings of The, 2016, pp. 372-387. , IEEE European Symposium on Security and Privacy (EuroS&P), Saar-brucken, Germany; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) Proceedings of the International Conference on Learning Representations (ICML), , Lille, France; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial machine learning at scale (2017) Proceedings of the International Conference on Learning Representations (ICLR), , Toulon, France; Su, J., Vargas, D.V., Kouichi, S., One pixel attack for fooling deep neural networks (2019) IEEE Trans. Evol. Comput., 23, pp. 828-841; Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Las Vegas, NV, USA, pp. 2574-2582; Arnab, A., Miksik, O., Torr, P.H., On the robustness of semantic segmentation models to adversarial attacks (2018) In Proceedings of International Conference on Computer Vision and Pattern Recognition (CVPR), Salt Lake City, UT, USA, pp. 888-897; Xiao, C., Deng, R., Li, B., Characterizing adversarial examples based on spatial consistency information for semantic segmenta-tion (2018) Proceedings of European Conference on Computer Vision (ECCV), , Munich, Germany; Shen, G., Mao, C., Yang, J., (2019) Advspade: Realistic Unrestricted Attacks for Semantic, , https://arxiv.org/abs/1910.02354; Chen, L., Xu, W., (2020) Attacking Optical Character Recognition (OCR) Systems with Adversarial Watermarks, , https://arxiv.org/abs/2002.03095; Naseer, M., Khan, S.H., Rahman, S., (2018) Task-Generalizable Adversarial Attack Based on Perceptual Metric, , https://arxiv.org/abs/1811.09020v3; Boloor, A., Garimella, K., He, X., Attacking vision-based per-ception in end-to-end autonomous driving models (2020) J. Syst. Archit., 110; Poursaeed, O., Katsman, I., Gao, B., Generative adversarial perturbations (2018) In Proceedings of IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Salt Lake City, UT, USA; Metzen, J.H., Kumar, M.C., Brox, T., Universal adversarial perturbations against semantic image segmentation (2017) In Proceedings of IEEE International Conference on Computer Vision (ICCV), Venice, Italy, pp. 2774-2783; Fischer, V., Kumar, M.C., Metzen, J.H., Adversarial examples for semantic image segmentation (2017) Proceedings of the International Conference on Learning Representations (ICLR), , Toulon, France; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Adversarial examples for semantic segmentation and object detection (2017) Proceedings of the IEEE International Conference on Computer Vision (ICCV), pp. 1369-1378. , Venice, Italy; Osahor, U., Nasrabadi, N., Deep adversarial attack on target detection systems (2019) In Artificial Intelligence and Machine Learning for Multi-Domain Operations Applications, International Society for Optics and Photonics, Baltimore, MD, USA; Miyato, T., Dai, A.M., Goodfellow, I.J., Adversarial training methods for semi-supervised text classification (2016) Proceedings of the International Conference on Learning Representations (ICLR), , San Juan, Puerto Rico; Ronneberger, O., Fischer, P., Brox, T., U-net: Convolutional networks for biomedical image segmentation (2015) In Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI), Munich, Germany, pp. 234-241; Everingham, M., Eslami, S.M., van Gool, L., The Pascal visual object classes challenge: A retrospective (2015) Int. J. Comput. Vis., 111, pp. 98-136; Cordts, M., Omran, M., Ramos, S., Rehfeld, T., The cityscapes dataset for semantic urban scene understanding (2016) In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Las Vegas, NV, USA, pp. 3213-3223","Jiang, Y.; School of Computer and Information Engineering, Qiaodong Street, Xiangqiao District, China; 电子邮件: jyz366@163.com",,,Atlantis Press,,,,,18756891,,,,English,Int. J. Comput. Intell. Syst.,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85111171563
"Wen H., Fang J., Wu J., Zheng Z.",57225034544;57209203097;55760584700;25224189400;,Transaction-based hidden strategies against general phishing detection framework on ethereum,2021,Proceedings - IEEE International Symposium on Circuits and Systems,2021-May,,9401091,,,,1,10.1109/ISCAS51556.2021.9401091,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109026843&doi=10.1109%2fISCAS51556.2021.9401091&partnerID=40&md5=62b49f7881ac4aa65f0ca21f01dc9bff,"School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, 510006, China; Department of Electrical Engineering, City University of Hong Kong, Hong Kong","Wen, H., School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, 510006, China; Fang, J., Department of Electrical Engineering, City University of Hong Kong, Hong Kong; Wu, J., School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, 510006, China; Zheng, Z., School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, 510006, China","With the prosperous development of blockchain technologies in the past few years, some cybercrimes have emerged in the blockchain ecosystem, such as the phishing scams on Ethereum. To alleviate these security problems, a few anomaly detection frameworks were proposed. Specifically, previous studies usually model the transfer relationship between accounts in the blockchain ecosystem as a transaction network, where nodes represent accounts and edges represent the corresponding transaction records. Inspired by the adversarial attacks on graph data, we believe the robustness of existing detection frameworks still needs to be further verified even though they have achieved good performance. In this paper, a phishing detection framework based on feature learning and a phishing hidden framework based on inserting transaction records are proposed, respectively. Experimental results show the effectiveness of our phishing detection framework and the superiority of the phishing hidden strategies, which indicate that existing phishing detection frameworks are lack of robustness and still need further improvement against malicious attacks. © 2021 IEEE",,Blockchain; Computer crime; Ecosystems; Ethereum; Network security; Anomaly detection frameworks; Cyber-crimes; Detection framework; Feature learning; Malicious attack; Phishing detections; Security problems; Transaction records; Anomaly detection,,,,,"Narayanan, A., Bonneau, J., Felten, E., Miller, A., Goldfeder, S., (2016) Bitcoin and Cryptocurrency Technologies: A Comprehensive Introduction, , Princeton University Press; Yuan, Y., Wang, F., Blockchain and cryptocurrencies: Model, techniques, and applications (2018) IEEE Transactions on Systems, Man, and Cybernetics: Systems, 48 (9), pp. 1421-1428; Vasek, M., Moore, T., There's no free lunch, even using bitcoin: Tracking the popularity and profits of virtual currency scams (2015) Proceedings of the Financial Cryptography and Data Security, pp. 44-61. , Berlin, Heidelberg: Springer; Chen, W., Zheng, Z., Cui, J., Ngai, E., Zheng, P., Zhou, Y., Detecting ponzi schemes on ethereum: Towards healthier blockchain technology (2018) Proceedings of the 2018 World Wide Web Conference, pp. 1409-1418. , Republic and Canton of Geneva, CHE: ACM; Meiklejohn, S., Pomarole, M., Jordan, G., Levchenko, K., McCoy, D., Voelker, G.M., Savage, S., A fistful of bitcoins: Characterizing payments among men with no names (2013) Proceedings of the 2013 Conference on Internet Measurement Conference, pp. 127-140. , New York, NY, USA: ACM; Khonji, M., Iraqi, Y., Jones, A., Phishing detection: A literature survey (2013) IEEE Communications Surveys & Tutorials, 15 (4), pp. 2091-2121; The Rise of Cybercrime on Ethereum, , https://blog.chainalysis.com/reports/the-rise-of-cybercrime-on-ethereum/, Online; Lin, D., Wu, J., Yuan, Q., Zheng, Z., T-edge: Temporal weighted multidigraph embedding for ethereum transaction network analysis (2020) Frontiers in Physics, 8, p. 204; Lin, D., Wu, J., Yuan, Q., Zheng, Z., Modeling and understanding ethereum transaction records via a complex network approach (2020) IEEE Transactions on Circuits and Systems II: Express Briefs, 67 (11), pp. 2737-2741; Farrugia, S., Ellul, J., Azzopardi, G., Detection of illicit accounts over the ethereum blockchain (2020) Expert Systems with Applications, 150, p. 113318; Baek, H., Oh, J., Kim, C.Y., Lee, K., A model for detecting cryptocurrency transactions with discernible purpose (2019) Proceedings of the 2019 Eleventh International Conference on Ubiquitous and Future Networks (ICUFN), pp. 713-717. , Zagreb, Croatia, Croatia: IEEE; Wu, J., Liu, J., Chen, W., Huang, H., Zheng, Z., Zhang, Y., Detecting mixing services via mining bitcoin transaction network with hybrid motifs (2021) IEEE Transactions on Systems, Man, and Cybernetics: Systems, pp. 1-13. , to be published; Wu, J., Yuan, Q., Lin, D., You, W., Chen, W., Chen, C., Zheng, Z., Who are the phishers? Phishing scam detection on ethereum via network embedding (2020) IEEE Transactions on Systems, Man, and Cybernetics: Systems, pp. 1-11. , to be published; Yuan, Q., Huang, B., Zhang, J., Wu, J., Zhang, H., Zhang, X., Detecting phishing scams on ethereum based on transaction records (2020) Proceedings of the 2020 IEEE International Symposium on Circuits and Systems, pp. 1-5. , Sevilla, Spain: IEEE; Sun, L., Dou, Y., Yang, C., Wang, J., Yu, P.S., Li, B., (2018) Adversarial Attack and Defense on Graph Data: A Survey, , arXiv preprint; Dai, H., Li, H., Tian, T., Huang, X., Wang, L., Zhu, J., Song, L., Adversarial attack on graph structured data (2018) Proceedings of the 35th International Conference on Machine Learning, pp. 1123-1132. , Stockholmsmässan, Stockholm, Sweden: ICML; Zügner, D., Akbarnejad, A., Günnemann, S., Adversarial attacks on neural networks for graph data (2018) Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pp. 2847-2856. , New York, NY, USA: ACM; Zhang, Q., Fang, J., Zhang, J., Wu, J., Xia, Y., Zheng, Z., Cross entropy attack on deep graph infomax (2020) Proceedings of the 2020 IEEE International Symposium on Circuits and Systems, pp. 1-5; Cortes, C., Vapnik, V., Support-vector networks (1995) Machine Learning, 20 (3), pp. 273-297; Cover, T., Hart, P., Nearest neighbor pattern classification (1967) IEEE Transactions on Information Theory, 13 (1), pp. 21-27; Freund, Y., Schapire, R.E., Experiments with a new boosting algorithm (1996) Proceedings of the Thirteenth International Conference on International Conference on Machine Learning, pp. 148-156. , San Francisco, CA, USA: Citeseer","Wu, J.; School of Computer Science and Engineering, China; 电子邮件: wujiajing@mail.sysu.edu.cn",,,Institute of Electrical and Electronics Engineers Inc.,"53rd IEEE International Symposium on Circuits and Systems, ISCAS 2021",22 May 2021 through 28 May 2021,,169837,2714310,9.78E+12,PICSD,,English,Proc IEEE Int Symp Circuits Syst,Conference Paper,Final,,Scopus,2-s2.0-85109026843
"Carey A.N., Mai H., Zhan J., Mehmood A.",57222723902;57224979053;24402381500;36133731600;,Adversarial attacks against image-based malware detection using autoencoders,2021,Proceedings of SPIE - The International Society for Optical Engineering,11735,,117350A,,,,,10.1117/12.2587923,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108840145&doi=10.1117%2f12.2587923&partnerID=40&md5=57cf557425de7c57d1099a48cd82aa71,"University of Arkansas, Fayetteville, AR, United States; Air Force Research Laboratory, Wright-Patterson Air Force Base, Ohio, United States","Carey, A.N., University of Arkansas, Fayetteville, AR, United States; Mai, H., University of Arkansas, Fayetteville, AR, United States; Zhan, J., University of Arkansas, Fayetteville, AR, United States; Mehmood, A., Air Force Research Laboratory, Wright-Patterson Air Force Base, Ohio, United States","Over the past decade, deep learning approaches have been applied to the detection of malicious software, otherwise known as malware. Despite their improved performance compared to conventional detection methods such as static and dynamic analysis, however, deep learning-based malware detection systems have been shown to be vulnerable to adversarial attacks. Few image-based malware detection systems have been proposed, especially those that evaluate their performance against adversarial attacks. Furthermore, little research has been done beyond the classification of malware targeted at Windows (PE) or Android systems, leaving entire realms such as Mac (Mach-O), Linux (ELF), and embedded software unexplored and unprotected. These realms, specifically embedded software, are used in critical technology such as avionic systems and special care must be taken to ensure their safety. In this paper, we present an image-based malware detection system on PE, ELF, MachO, and embedded C code files. The system’s architecture incorporates layers of encoders that are taken from independently-trained autoencoders and multi-layer perceptron that returns the output of the network. We evaluate the performance of the system against adversarial attacks, or the misclassification of a malware file as a benign, by adding gradient based perturbations to unused sections of the malware often referred to as the slack bits. The network achieves an accuracy of 96.51% on non-adversarial PE and ELF files, 95.45% on transfer learned non-adversarial Mach-O files, and 99.2% on transfer learned non-adversarial synthetic plane files. For the classification of adversarial examples, the network achieved a 81% success rate of misclassification on adversarial PE and ELF files and a 99% success rate of misclassification on adversarial synthetic plane files. © 2021 SPIE",Adversarial Attack; Machine Learning; Malware Detection,Avionics; Computer operating systems; Deep learning; Embedded software; Embedded systems; Firmware; Learning systems; Multilayer neural networks; Pattern recognition; Android systems; Conventional detection; Critical technologies; Learning approach; Malware detection; Misclassifications; Multi layer perceptron; Static and dynamic analysis; Malware,,,,,"Kolosnjaji, B., Demontis, A., Biggio, B., Maiorca, D., Giacinto, G., Eckert, C., Roli, F., (2018) Adversarial malware binaries: Evading deep learning for malware detection in executables; Kreuk, F., Barak, A., Aviv-Reuven, S., Baruch, M., Pinkas, B., Keshet, J., (2018) Deceiving end-to-end deep learning malware detectors using adversarial examples; Suciu, O., Coull, S. E., Johns, J., (2018) Exploring adversarial examples in malware detection; Goodfellow, I. J., Shlens, J., Szegedy, C., (2014) Explaining and harnessing adversarial examples; Pinto, D. R., Duarte, J. C., Sant’Ana, R., A deep learning approach to the malware classification problem using autoencoders (2019) Proceedings of the XV Brazilian Symposium on Information Systems], SBSI’19, , [Association for Computing Machinery, New York, NY, USA; Paola, A. D., Favaloro, S., Gaglio, S., Re, G. L., Morana, M., (2018) Malware detection through low-level features and stacked denoising autoencoders, , [ITASEC]; Liu, X., Zhang, J., Lin, Y., Li, H., (2018) Atmpa: Attacking machine learning-based malware visualization detection methods via adversarial examples; Nataraj, L., Karthikeyan, S., Jacob, G., Manjunath, B. S., Malware images: Visualization and automatic classification (2011) Proceedings of the 8th International Symposium on Visualization for Cyber Security], , [VizSec’11, Association for Computing Machinery, New York, NY, USA; Kebede, T. M., Djaneye-Boundjou, O., Narayanan, B. N., Ralescu, A., Kapp, D., Classification of malware programs using autoencoders based deep learning architecture and its application to the microsoft malware classification challenge (big 2015) dataset (2017) 2017 IEEE National Aerospace and Electronics Conference (NAECON)], pp. 70-75; Vi, B. N., Noi Nguyen, H., Nguyen, N. T., Truong Tran, C., Adversarial examples against image-based malware classification systems (2019) 2019 11th International Conference on Knowledge and Systems Engineering (KSE)], pp. 1-5; Yuan, X., He, P., Zhu, Q., Li, X., (2017) Adversarial examples: Attacks and defenses for deep learning; Ronen, R., Radu, M., Feuerstein, C., Yom-Tov, E., Ahmadi, M., (2018) Microsoft malware classification challenge; Grosse, K., Papernot, N., Manoharan, P., Backes, M., McDaniel, P., Adversarial examples for malware detection (2017) Computer Security – ESORICS 2017], pp. 62-79. , [Foley, S. N., Gollmann, D., and Snekkenes, E., eds., Springer International Publishing, Cham; Carey, A. N., Zhan, J., A cancelable multi-modal biometric based encryption scheme for medical images (2020) IEEE International Conference on Big Data, pp. 3711-3720; Berman, D., Buczak, A., Chavis, J., Corbett, C., A survey of deep learning methods for cyber security (2019) Information, 10, p. 122. , (04); Chalapathy, R., Chawla, S., (2019) Deep learning for anomaly detection: A survey; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing properties of neural networks; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z. B., Swami, A., (2015) The limitations of deep learning in adversarial settings; Carlini, N., Wagner, D., (2016) Towards evaluating the robustness of neural networks; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., (2015) Deepfool: a simple and accurate method to fool deep neural networks; Hu, W., Tan, Y., (2017) Black-box attacks against rnn based malware detection algorithms; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z. B., Swami, A., (2016) Practical black-box attacks against machine learning; Rosenberg, I., Shabtai, A., Rokach, L., Elovici, Y., (2017) Generic black-box end-to-end attack against state of the art api call based malware classifiers; Hu, W., Tan, Y., (2017) Generating adversarial malware examples for black-box attacks based on gan; Zhao, Z., Dua, D., Singh, S., (2017) Generating natural adversarial examples; Akhtar, N., Mian, A., (2018) Threat of adversarial attacks on deep learning in computer vision: A survey; (2020) Securing cyber in the sky - layered cybersecurity needed to protect aviation ecosystem, , Raytheon, (3); Cleave, K. V., (2017) Experts working with homeland security hacked into boeing 757, , (11)","Carey, A.N.; University of ArkansasUnited States; 电子邮件: ancarey@uark.edu",Alam M.S.,The Society of Photo-Optical Instrumentation Engineers (SPIE),SPIE,Pattern Recognition and Tracking XXXII 2021,12 April 2021 through 16 April 2021,,169682,0277786X,9.78E+12,PSISD,,English,Proc SPIE Int Soc Opt Eng,Conference Paper,Final,,Scopus,2-s2.0-85108840145
"Yadav S., Ross A.",57216089937;7402568052;,CIT-GAN: Cyclic image translation generative adversarial network with application in iris presentation attack detection,2021,"Proceedings - 2021 IEEE Winter Conference on Applications of Computer Vision, WACV 2021",,,,2411,2420,,,10.1109/WACV48630.2021.00246,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108535145&doi=10.1109%2fWACV48630.2021.00246&partnerID=40&md5=52a75421563ff87a82f02295b7f48ad3,"Michigan State University, United States","Yadav, S., Michigan State University, United States; Ross, A., Michigan State University, United States","In this work, we propose a novel Cyclic Image Translation Generative Adversarial Network (CIT-GAN) for multi-domain style transfer. To facilitate this, we introduce a Styling Network that has the capability to learn style characteristics of each domain represented in the training dataset. The Styling Network helps the generator to drive the translation of images from a source domain to a reference domain and generate synthetic images with style characteristics of the reference domain. The learned style characteristics for each domain depend on both the style loss and domain classification loss. This induces variability in style characteristics within each domain. The proposed CIT-GAN is used in the context of iris presentation attack detection (PAD) to generate synthetic presentation attack (PA) samples for classes that are under-represented in the training set. Evaluation using current state-of-the-art iris PAD methods demonstrates the efficacy of using such synthetically generated PA samples for training PAD methods. Further, the quality of the synthetically generated samples is evaluated using Frechet Inception Distance (FID) score. Results show that the quality of synthetic images generated by the proposed method is superior to that of other competing methods, including StarGan. © 2021 IEEE.",,Computer vision; Quality control; Attack detection; Detection methods; Image translation; Learn+; Multi-domains; Reference domains; Synthetic images; Training dataset; Training sets; Under-represented; Generative adversarial networks,,,,,"Almahairi, A., Rajeswar, S., Sordoni, A., Bachman, P., Courville, A., (2018) Augmented CycleGAN: Learning Many-to-many Mappings from Unpaired Data; Bodade, R., Talbar, S., Fake iris detection: A holistic approach (2011) International Journal of Computer Applications, 19 (2), pp. 1-7; Boyd, A., Yadav, S., Swearingen, T., Kuehlkamp, A., Trokielewicz, M., Benjamin, E., Maciejewicz, P., Flynn, P., Post-mortem iris recognition-a survey and assessment of the state of the art (2020) IEEE Access, 8, pp. 136570-136593; Cai, J., Hu, H., Shan, S., Chen, X., Fcsr-gan: End-to-end learning for joint face completion and super-resolution (2019) 14th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2019), pp. 1-8; Chang, H., Lu, J., Yu, F., Finkelstein, A., Paired cyclegan: Asymmetric style transfer for applying and removing makeup (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 40-48; Chen, C., Ross, A., A multi-task convolutional neural network for joint iris detection and presentation attack detection (2018) IEEE Winter Applications of Computer Vision Workshops (WACVW), pp. 44-51; Cho, W., Choi, S., Keetae Park, D., Shin, I., Choo, J., Image-to-image translation via group-wise deep whitening-and-coloring transformation (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 10639-10647; Choi, Y., Choi, M., Kim, M., Ha, J., Kim, S., Choo, J., Stargan: Unified generative adversarial networks for multi-domain image-to-image translation (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 8789-8797; Choi, Y., Uh, Y., Yoo, J., Ha, J., Stargan v2: Diverse image synthesis for multiple domains (2020) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 8188-8197; Czajka, A., Iris liveness detection by modeling dynamic pupil features (2016) Handbook of Iris Recognition, pp. 439-467. , Springer; Czajka, A., Bowyer, K.W., Presentation attack detection for iris recognition: An assessment of the state-ofthe-art (2018) ACM Computing Surveys (CSUR), 51 (4), pp. 1-35; Das, P., McGrath, J., Fang, Z., Boyd, A., Jang, G., Mohammadi, A., Purnapatra, S., Trokielewicz, M., Iris liveness detection competition (livdet-iris)-the 2020 edition (2020) IEEE International Joint Conference on Biometrics (IJCB); Daugman, J., Demodulation by complex-valued wavelets for stochastic pattern recognition (2003) International Journal of Wavelets, Multiresolution and Information Processing, 1 (1), pp. 1-17; Doyle, J.S., Bowyer, K.W., Robust detection of textured contact lenses in iris recognition using bsif (2015) IEEE Access, 3, pp. 1672-1683; Doyle, J.S., Flynn, P.J., Bowyer, K.W., Automated classification of contact lens type in iris images (2013) International Conference on Biometrics (ICB), pp. 1-6; Gatys, L.A., Ecker, A.S., Bethge, M., (2015) A Neural Algorithm of Artistic Style; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems (NIPS), pp. 2672-2680; Gupta, P., Behera, S., Vatsa, M., Singh, R., On iris spoofing using print attack (2014) 22nd International Conference on Pattern Recognition, pp. 1681-1686; Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., Hochreiter, S., Gans trained by a two time-scale update rule converge to a local nash equilibrium (2017) Advances in Neural Information Processing Systems, pp. 6626-6637; Hoffman, S., Sharma, R., Ross, A., Iris+ocular: Generalized iris presentation attack detection using multiple convolutional neural networks (2019) IAPR International Conference on Biometrics (ICB); Jain, A.K., Nandakumar, K., Ross, A., 50 years of biometric research: Accomplishments, challenges, and opportunities (2016) Pattern Recognition Letters, 79, pp. 80-105; Karras, T., Laine, S., Aila, T., A style-based generator architecture for generative adversarial networks (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4401-4410; Kohli, N., Yadav, D., Vatsa, M., Singh, R., Noore, A., Detecting medley of iris spoofing attacks using desist (2016) IEEE International Conference on Biometrics Theory, Applications and Systems (BTAS), pp. 1-6; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Joo Lee, S., Ryoung Park, K., Joo Lee, Y., Bae, K., Hie Kim, J., Multifeature-based fake iris detection method (2007) Optical Engineering, 46 (12), pp. 1-10; Pacut, A., Czajka, A., Aliveness detection for iris biometrics (2006) Proceedings of 40th Annual International Carnahan Conference on Security Technology, pp. 122-129; Raghavendra, R., Busch, C., Presentation attack detection algorithm for face and iris biometrics (2014) European Signal Processing Conference (EUSIPCO), pp. 1387-1391; Ross, A., Banerjee, S., Chen, C., Chowdhury, A., Mirjalili, V., Sharma, R., Swearingen, T., Yadav, S., Some research problems in biometrics: The future beckons (2019) IAPR International Conference on Biometrics (ICB); Salimans, T., Zhang, H., Radford, A., Metaxas, D., (2018) Improving GANs Using Optimal Transport; Sharma, R., Ross, A., D-netpad: An explainable and interpretable iris presentation attack detector (2020) IEEE International Joint Conference on Biometrics (IJCB); Shrivastava, A., Pfister, T., Tuzel, O., Susskind, J., Wang, W., Webb, R., Learning from simulated and unsupervised images through adversarial training (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2107-2116; Sun, Z., Zhang, H., Tan, T., Wang, J., Iris image classification based on hierarchical visual codebook (2014) IEEE Transactions on Pattern Analysis and Machine Intelligence, 36 (6), pp. 1120-1133; Van Den Oord, A., Kalchbrenner, N., Espeholt, L., Vinyals, O., Graves, A., Conditional image generation with CNN decoders (2016) Advances in Neural Information Processing Systems (NIPS), pp. 4790-4798; Yadav, S., Chen, C., Ross, A., Synthesizing iris images using rasgan with application in presentation attack detection (2019) IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW); Yadav, S., Chen, C., Ross, A., Relativistic discriminator: A one-class classifier for generalized iris presentation attack detection (2020) IEEE Winter Conference on Applications of Computer Vision, pp. 2635-2644; Yambay, D., Becker, B., Kohli, N., Yadav, D., Czajka, A., Bowyer, K.W., Schuckers, S., Noore, A., Livdet iris 2017-iris liveness detection competition (2017) IEEE International Joint Conference on Biometrics (IJCB), pp. 733-741; Yang, D., Hong, S., Jang, Y., Zhao, T., Lee, H., (2019) Diversity-sensitive Conditional Generative Adversarial Networks; Zenati, H., Sheng Foo, C., Lecouat, B., Manek, G., Ramaseshan Chandrasekhar, V., (2018) Efficient GAN-based Anomaly Detection",,,Adobe;Amazon;Kitware;Robot;Verisk,Institute of Electrical and Electronics Engineers Inc.,"2021 IEEE Winter Conference on Applications of Computer Vision, WACV 2021",5 January 2021 through 9 January 2021,,170847,,9.78E+12,,,English,"Proc. - IEEE Winter Conf. Appl. Comput. Vis., WACV",Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85108535145
[无可用作者姓名],[无可用的作者 ID],Disruptive Technologies in Information Sciences V,2021,Proceedings of SPIE - The International Society for Optical Engineering,11751,,,,,113,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107880045&partnerID=40&md5=e535cbde01d762950e98d16127cccfab,,,"The proceedings contain 13 papers. The topics discussed include: deep learning to predict the modulation schemes of real OFDM signals; aspects of hyperdimensional computing for robotics: transfer learning, cloning, extraneous sensors, and network topology; towards adaptive and curious artificial agents: learning, perception, and planning in dynamic uncertain environments; deep neural network model optimizations for resource constrained tactical edge computing platforms; efficient normalization techniques to optimize AI models for deployment in tactical edge; adversarial robustness of machine learning-based indoor positioning systems; automating defense against adversarial attacks: discovery of vulnerabilities and application of multi-INT imagery to protect deployed models; holistic defenses against microarchitectural attacks; and Zigbee as a candidate standard for use in anomaly detection in IoT LANs.",,,,,,,,,Blowers M.Hall R.D.Dasari V.R.,The Society of Photo-Optical Instrumentation Engineers (SPIE),SPIE,Disruptive Technologies in Information Sciences V 2021,12 April 2021 through 16 April 2021,,169244,0277786X,9.78E+12,PSISD,,English,Proc SPIE Int Soc Opt Eng,Conference Review,Final,,Scopus,2-s2.0-85107880045
"Demetrio L., Biggio B., Lagorio G., Roli F., Armando A.",57205738855;23090165100;56618171700;57194734588;57190072464;,Functionality-Preserving Black-Box Optimization of Adversarial Windows Malware,2021,IEEE Transactions on Information Forensics and Security,16,,9437194,3469,3478,,5,10.1109/TIFS.2021.3082330,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107222735&doi=10.1109%2fTIFS.2021.3082330&partnerID=40&md5=e554cb8bd35ea5cafe0228cc94029e21,"Department of Electrical and Electronic Engineering, PRA Lab, University of Cagliari, Cagliari, Italy; Computer Security Laboratory (CSecLab), University of Genoa, Genoa, Italy","Demetrio, L., Department of Electrical and Electronic Engineering, PRA Lab, University of Cagliari, Cagliari, Italy; Biggio, B., Department of Electrical and Electronic Engineering, PRA Lab, University of Cagliari, Cagliari, Italy; Lagorio, G., Computer Security Laboratory (CSecLab), University of Genoa, Genoa, Italy; Roli, F., Department of Electrical and Electronic Engineering, PRA Lab, University of Cagliari, Cagliari, Italy; Armando, A., Computer Security Laboratory (CSecLab), University of Genoa, Genoa, Italy","Windows malware detectors based on machine learning are vulnerable to adversarial examples, even if the attacker is only given black-box query access to the model. The main drawback of these attacks is that: ( i ) they are query-inefficient, as they rely on iteratively applying random transformations to the input malware; and ( ii ) they may also require executing the adversarial malware in a sandbox at each iteration of the optimization process, to ensure that its intrusive functionality is preserved. In this paper, we overcome these issues by presenting a novel family of black-box attacks that are both query-efficient and functionality-preserving, as they rely on the injection of benign content (which will never be executed) either at the end of the malicious file, or within some newly-created sections. Our attacks are formalized as a constrained minimization problem which also enables optimizing the trade-off between the probability of evading detection and the size of the injected payload. We empirically investigate this trade-off on two popular static Windows malware detectors, and show that our black-box attacks can bypass them with only few queries and small payloads, even when they only return the predicted labels. We also evaluate whether our attacks transfer to other commercial antivirus solutions, and surprisingly find that they can evade, on average, more than 12 commercial antivirus engines. We conclude by discussing the limitations of our approach, and its possible future extensions to target malware classifiers based on dynamic analysis. © 2005-2012 IEEE.",Adversarial examples; black-box optimization; evasion attacks; machine learning; malware detection,Computer viruses; Constrained optimization; Anti virus; Anti-virus engines; Black boxes; Black-box optimization; Constrained minimization problem; On-machines; Possible futures; Trade off; Economic and social effects,,,,,"Saxe, J., Berlin, K., Deep neural network based malware detection using two dimensional binary program features (2015) Proc. 10th Int. Conf. Malicious Unwanted Softw. (MALWARE), pp. 11-20. , Oct; Kolosnjaji, B., Zarras, A., Webster, G., Eckert, C., Deep learning for classification of malware system call sequences (2016) Proc. Australas. Joint Conf. Artif. Intell. Cham, Switzerland: Springer, pp. 137-149; Hardy, W., Chen, L., Hou, S., Ye, Y., Li, X., DL4MD: A deep learning framework for intelligent malware detection (2016) Proc. Int. Conf. Data Mining (DMIN), pp. 61-67; David, O.E., Netanyahu, N.S., DeepSign: Deep learning for automatic malware signature generation and classification (2015) Proc. Int. Joint Conf. Neural Netw. (IJCNN), pp. 1-8. , Jul; Romeo, I.I., Theodorides, M., Afroz, S., Wagner, D., Adversarially robust malware detection using monotonic classification (2018) Proc. 4th ACM Int. Workshop Secur. Privacy Anal., pp. 54-63. , Mar; Anderson, H.S., Roth, P., (2018) EMBER: An Open Dataset for Training Static PE Malware Machine Learning Models, , http://arxiv.org/abs/1804.04637, arXiv:1804.04637; Raff, E., Barker, J., Sylvester, J., Brandon, R., Catanzaro, B., Nicholas, C.K., Malware detection by eating a whole EXE (2018) Proc. 32nd AAAI Workshops, New Orleans, LA, USA, pp. 268-276. , Feb; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I., Tygar, J.D., Adversarial machine learning (2011) Proc. 4th AISec, pp. 43-58; Biggio, B., Roli, F., Wild patterns: Ten years after the rise of adversarial machine learning (2018) Pattern Recognit., 84, pp. 317-331. , Dec; Demetrio, L., Biggio, B., Lagorio, G., Roli, F., Armando, A., Explaining vulnerabilities of deep learning to adversarial malware binaries (2019) Proc. 3rd Italian Conf. Cyber Secur. (ITASEC), pp. 1-13; Kolosnjaji, B., Adversarial malware binaries: Evading deep learning for malware detection in executables (2018) Proc. 26th Eur. Signal Process. Conf. (EUSIPCO), pp. 533-537. , Sep; Kreuk, F., Barak, A., Aviv-Reuven, S., Baruch, M., Pinkas, B., Keshet, J., (2018) Adversarial Examples on Discrete Sequences for Beating Whole-binary Malware Detection, , https://arxiv.org/abs/1802.04528v1, arXiv:1802.04528v1; Castro, R.L., Schmitt, C., Rodosek, G.D., ARMED: How automatic malware modifications can evade static detection?"" in Proc. 5th Int. Conf. Inf. Manage. (ICIM) (2019), pp. 20-27. , Mar; Castro, R.L., Schmitt, C., Rodosek, G.D., Aimed: Evolving malware with genetic programming to evade detection (2019) Proc. 18th Int. Conf. TrustCom, pp. 240-247; Anderson, H.S., Kharkar, A., Filar, B., Roth, P., Evading machine learning malware detection (2017) Proc. BlackHat; Rosenberg, I., Shabtai, A., Rokach, L., Elovici, Y., Generic blackbox end-to-end attack against state of the art API call based malware classifiers (2018) Proc. RAID. Cham, Switzerland: Springer, pp. 490-510; Hu, W., Tan, Y., (2017) Generating Adversarial Malware Examples for Black-box Attacks Based on GAN, , http://arxiv.org/abs/1702.05983, arXiv:1702.05983; Tong, L., Li, B., Hajaj, C., Xiao, C., Zhang, N., Vorobeychik, Y., Improving robustness of ML classifiers against realizable evasion attacks using conserved features (2019) Proc. USENIX Secur., pp. 285-302; Xu, W., Qi, Y., Evans, D., Automatically evading classifiers (2016) Proc. NDSS, pp. 21-24; Ke, G., LightGBM: A highly efficient gradient boosting decision tree (2017) Proc. NIPS, pp. 3146-3154; Moody, J., Fast learning in multi-resolution hierarchies (1989) Proc. NIPS, pp. 29-39; Demetrio, L., Coull, S.E., Biggio, B., Lagorio, G., Armando, A., Roli, F., (2020) Adversarial EXEmples: A Survey and Experimental Evaluation of Practical Attacks on Machine Learning for Windows Malware Detection, , http://arxiv.org/abs/2008.07125, arXiv:2008.07125; Suciu, O., Coull, S.E., Johns, J., Exploring adversarial examples in malware detection (2019) Proc. IEEE Secur. Privacy Workshops (SPW), pp. 8-14. , May; Wenzl, M., Merzdovnik, G., Ullrich, J., Weippl, E., From hack to elaborate technique-A survey on binary rewriting (2019) ACM Comput. Surv., 52 (3), pp. 1-37. , Jul; Paszke, A., PyTorch: An imperative style, high-performance deep learning library (2019) Proc. NIPS, pp. 8026-8037; Fortin, F.-A., De Rainville, F.-M., Gardner, M.-A.G., Parizeau, M., Gagné, C., DEAP: Evolutionary algorithms made easy (2012) J. Mach. Lang. Res., 13, pp. 2171-2175. , Jul; Goodfellow, I., Generative adversarial nets (2014) Proc. NIPS, pp. 2672-2680; Rndic, N., Laskov, P., Practical evasion of a learning-based classifier: A case study (2014) Proc. IEEE Symp. Secur. Privacy, pp. 197-211. , May; Smutz, C., Stavrou, A., Malicious PDF detection using metadata and structural features (2012) Proc. 28th Annu. Comput. Secur. Appl. Conf. (ACSAC), pp. 239-248; Ceschin, F., Botacin, M., Gomes, H.M., Oliveira, L., Grégio, A., Shallow security: On the creation of adversarial variants to evade machine learning-based malware detectors (2019) Proc. 3rd Reversing Offensive-Oriented Trends Symp., pp. 1-9; Afianian, A., Niksefat, S., Sadeghiyan, B., Baptiste, D., Malware dynamic analysis evasion techniques: A survey (2020) ACM Comput. Surv., 52 (6), pp. 1-28. , Jan; Aghakhani, H., When malware is Packin' heat; Limits of machine learning classifiers based on static analysis features (2020) Proc. Netw. Distrib. Syst. Secur. Symp., pp. 1-20; Demetrio, L., Biggio, B., (2021) Secml-malware: A Python Library for Adversarial Robustness Evaluation of Windows Malware Classifiers, , https://arxiv.org/abs/2104.12848andhttps://github.com/zangobot/secmlmalware, arXiv:2104.12848","Demetrio, L.; Department of Electrical and Electronic Engineering, Italy; 电子邮件: luca.demetrio93@unica.it",,,Institute of Electrical and Electronics Engineers Inc.,,,,,15566013,,,,English,IEEE Trans. Inf. Forensics Secur.,Article,Final,"All Open Access, Green",Scopus,2-s2.0-85107222735
"Müller N.M., Böttinger K.",57211168855;55533323900;,Adversarial Vulnerability of Active Transfer Learning,2021,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),12695 LNCS,,,116,127,,,10.1007/978-3-030-74251-5_10,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105853884&doi=10.1007%2f978-3-030-74251-5_10&partnerID=40&md5=d96cad4a0b5072ff6f112d4d830b3b50,"Fraunhofer AISEC, Garching near Munich, Germany","Müller, N.M., Fraunhofer AISEC, Garching near Munich, Germany; Böttinger, K., Fraunhofer AISEC, Garching near Munich, Germany","Two widely used techniques for training supervised machine learning models on small datasets are Active Learning and Transfer Learning. The former helps to optimally use a limited budget to label new data. The latter uses large pre-trained models as feature extractors and enables the design of complex, non-linear models even on tiny datasets. Combining these two approaches is an effective, state-of-the-art method when dealing with small datasets. In this paper, we share an intriguing observation: Namely, that the combination of these techniques is particularly susceptible to a new kind of data poisoning attack: By adding small adversarial noise on the input, it is possible to create a collision in the output space of the transfer learner. As a result, Active Learning algorithms no longer select the optimal instances, but almost exclusively the ones injected by the attacker. This allows an attacker to manipulate the active learner to select and include arbitrary images into the data set, even against an overwhelming majority of unpoisoned samples. We show that a model trained on such a poisoned dataset has a significantly deteriorated performance, dropping from 86% to 34% test accuracy. We evaluate this attack on both audio and image datasets and support our findings empirically. To the best of our knowledge, this weakness has not been described before in literature. © 2021, Springer Nature Switzerland AG.",,Budget control; Data handling; Information analysis; Large dataset; Statistical tests; Supervised learning; Transfer learning; Active learners; Active Learning; Active-learning algorithm; Feature extractor; Non-linear model; Poisoning attacks; State-of-the-art methods; Supervised machine learning; Learning algorithms,,,,,"ResNet and ResNetV2. https://keras.io/api/applications/resnet/. Accessed on 26 Nov 2020; STL-10 dataset (2011). http://ai.stanford.edu/∼acoates/stl10/. Accessed 26 Nov 2020; Google audio set (2017). https://research.google.com/audioset/. Accessed 26 Nov 2020; Biggio, B., Nelson, B., Laskov, P., (2012) Poisoning Attacks against Support Vector Machines, , arXiv preprint arXiv; Chan, Y.S., Ng, H.T., Domain adaptation with active learning for word sense disambiguation (2007) Proceedings of the 45Th Annual Meeting of the Association of Computational Linguistics, pp. 49-56. , Prague, Czech Republic, pp. , Association for Computational Linguistics, June; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778. , , pp; Jagielski, M., Oprea, A., Biggio, B., Liu, C., Nita-Rotaru, C., Li, B., Manipulating machine learning: Poisoning attacks and countermeasures for regression learning (2018) 2018 IEEE Symposium on Security and Privacy (SP), pp. 19-35. , , pp. , IEEE; Kale, D., Liu, Y., Accelerating active learning with transfer learning (2013) 2013 IEEE 13Th International Conference on Data Mining, pp. 1085-1090. , , pp. , December; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images, , Citeseer; Li, B., Vorobeychik, Y., Chen, X., (2016) A General Retraining Framework for Scalable Adversarial Classification, , arXiv preprint arXiv; Li, K., Zhang, T., Malik, J., Approximate feature collisions in neural nets (2019) Advances in Neural Information Processing Systems, pp. 15842-15850. , , pp; Miller, B., Adversarial active learning (2014) Proceedings of the 2014 Workshop on Artificial Intelligent and Security Workshop, pp. 3-14. , , pp; Pan, S.J., Yang, Q., A survey on transfer learning (2009) IEEE Trans. Knowl. Data Eng., 22 (10), pp. 1345-1359; Plakal, M., Ellis, D., YAMNet. github.com/tensorflow/models/tree/master/ research/audioset/yamnet; Settles, B., (2009) Active Learning Literature Survey, , Technical report; Shafahi, A., Poison frogs! Targeted clean-label poisoning attacks on neural networks (2018) Advances in Neural Information Processing Systems, pp. 6103-6113. , , pp; Shi, X., Fan, W., Ren, J.: Actively transfer domain knowledge. In: Daelemans, W., Goethals, B., Morik, K. (eds.) ECML PKDD 2008, Part II. LNCS (LNAI), vol. 5212, pp. 342–357. Springer, Heidelberg (2008). https://doi.org/10.1007/978-3-540-87481-2 23; Wang, X., Huang, T.-K., Schneider, J., Active transfer learning under model shift (2014) Proceedings of the 31St International Conference on Machine Learning, 32, pp. 1305-1313. , Xing, E.P., Jebara, T. (eds.) , Bejing, China. Proceedings of Machine Learning Research, vol., pp. , PMLR, Jun; Yang, L., Hanneke, S., Carbonell, J., A theory of transfer learning with applications to active learning (2013) Mach. Learn., 90 (2), pp. 161-189. , https://doi.org/10.1007/s10994-012-5310-y; Zhu, C., (2019) Transferable Clean-Label Poisoning Attacks on Deep Neural Nets. Arxiv Preprint Arxiv, 1905, p. 05897","Müller, N.M.; Fraunhofer AISECGermany; 电子邮件: nicolas.mueller@aisec.fraunhofer.de",Abreu P.H.Rodrigues P.P.Fernandez A.Gama J.,,Springer Science and Business Media Deutschland GmbH,"19th International Symposium on Intelligent Data Analysis, IDA 2021",26 April 2021 through 28 April 2021,,257969,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85105853884
"Huang H., Liu X.",57191493908;57218100650;,Local Migration Model of Images Based on Deep Learning against Adversarial Attacks,2021,IEEE Transactions on Computers,,,,,,,,10.1109/TC.2021.3075715,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105033841&doi=10.1109%2fTC.2021.3075715&partnerID=40&md5=a351e761546cb1db267deab3f37f0d3f,"the School of Information Engineering, Jingdezhen Ceramic Institute, Jingdezhen, Jingdezhen Ceramic Institute, 26478 Jingdezhen, Jiangxi, China, (e-mail: jdz_hh@qq.com); the School of Information Engineering, Jingdezhen Ceramic Institute, 26478 Jingdezhen, Jiangxi, China, 333403 (e-mail: 1332250394@qq.com)","Huang, H., the School of Information Engineering, Jingdezhen Ceramic Institute, Jingdezhen, Jingdezhen Ceramic Institute, 26478 Jingdezhen, Jiangxi, China, (e-mail: jdz_hh@qq.com); Liu, X., the School of Information Engineering, Jingdezhen Ceramic Institute, 26478 Jingdezhen, Jiangxi, China, 333403 (e-mail: 1332250394@qq.com)","Deep Neural Networks (DNNs) have achieved remarkable results in various tasks. However, DNNs are easily deceived by small input disturbances, which are called adversarial attacks. The adversarial attack is to deliberately add some subtle interference that humans cannot detect to the input sample, causing the model to give a wrong output with high confidence. Deep-Learning-as-a-Service (DLaaS) has become a current hot trend, and it also introduces challenging security issues. Therefore, in this paper, we propose a local migration model of confrontational attack images based on deep learning. The confrontational examples of the physical world are disguised as natural styles through the migration model to deceive human observers. Specifically, the model converts the small counter-interference into a specific pattern, and then camouflages the foreground or background or local target area of the image to achieve a high degree of invisibility. Due to the flexibility of the interference setting of this method, it can be used to help DNNs assess their robustness, and it can be used to achieve privacy protection and data security detection. IEEE",adversarial attacks; Ceramics; Deep learning; Deep neural network; Feature extraction; Image segmentation; image style transfer; local migration model; Neural networks; privacy protection; Semantics; Training,Data privacy; Deep neural networks; Learning systems; High confidence; Human observers; Migration model; Physical world; Privacy protection; Security detection; Security issues; Small inputs; Deep learning,,,,,,,,,IEEE Computer Society,,,,,189340,,ITCOB,,English,IEEE Trans Comput,Article,Article in Press,,Scopus,2-s2.0-85105033841
[无可用作者姓名],[无可用的作者 ID],"21st International Conference on Parallel and Distributed Computing, Applications, and Technologies, PDCAT 2020",2021,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),12606 LNCS,,,,,400,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104471968&partnerID=40&md5=59f0e6e3812a20d6411101d385ec3eef,,,"The proceedings contain 35 papers. The special focus in this conference is on Parallel and Distributed Computing, Applications, and Technologies. The topics include: On the Non-ergodic Convergence Rate of the Directed Nonsmooth Composite Optimization; 6D Pose Estimation Based on the Adaptive Weight of RGB-D Feature; blockchain-Based Secure Outsourcing of Fully Homomorphic Encryption Using Hidden Ideal Lattice; multiple Projections Learning for Dimensional Reduction; Preventing DDoS Attacks on Bitcoin Memory Pool by the Dynamic Fee Threshold Mechanism; The Compiler of DFC: A Source Code Converter that Transform the Dataflow Code to the Multi-threaded C Code; online Learning-Based Co-task Dispatching with Function Configuration in Edge Computing; System-Level FPGA Routing for Logic Verification with Time-Division Multiplexing; protein Interresidue Contact Prediction Based on Deep Learning and Massive Features from Multi-sequence Alignment; heterogeneous Software Effort Estimation via Cascaded Adversarial Auto-Encoder; see Fine Color from the Rough Black-and-White; data Aggregation Aware Routing for Distributed Training; a New Integer Programming Model for the File Transfer Scheduling Problem; approximation Algorithms for the General Cluster Routing Problem; maximizing Group Coverage in Social Networks; lightLayers: Parameter Efficient Dense and Convolutional Layers for Image Classification; the Hybrid Navigation Method in Face of Dynamic Obstacles; a Relaxed Balanced Lock-Free Binary Search Tree; A Dynamic Parameter Tuning Method for High Performance SpMM; data Caching Based Transfer Optimization in Large Scale Networks; a Novel Distributed Reinforcement Learning Method for Classical Chinese Poetry Generation; second-Order Convolutional Neural Network Based on Cholesky Compression Strategy; submodular Maximization with Bounded Marginal Values; the Prize-Collecting k-Steiner Tree Problem.",,,,,,,,,Zhang Y.Xu Y.Tian H.,,Springer Science and Business Media Deutschland GmbH,"21st International Conference on Parallel and Distributed Computing, Applications, and Technologies, PDCAT 2020",28 December 2020 through 30 December 2020,,255869,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Review,Final,,Scopus,2-s2.0-85104471968
[无可用作者姓名],[无可用的作者 ID],"European Conference on Machine Learning and Knowledge Discovery in Databases, ECML PKDD 2020",2021,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),12457 LNAI,,,,,3406,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103275499&partnerID=40&md5=e3043f59540a43a1f2c0b0b8f05ca8c9,,,"The proceedings contain 205 papers. The special focus in this conference is on Machine Learning and Knowledge Discovery in Databases. The topics include: Adversarial Learned Molecular Graph Inference and Generation; A Generic and Model-Agnostic Exemplar Synthetization Framework for Explainable AI; quality Guarantees for Autoencoders via Unsupervised Adversarial Attacks; metric Learning for Categorical and Ambiguous Features: An Adversarial Method; learning Implicit Generative Models by Teaching Density Estimators; Reprogramming GANs via Input Noise Design; on Saliency Maps and Adversarial Robustness; scalable Backdoor Detection in Neural Networks; an Algorithmic Framework for Decentralised Matrix Factorisation; exponential Convergence of Gradient Methods in Concave Network Zero-Sum Games; federated Multi-view Matrix Factorization for Personalized Recommendations; FedMAX: Mitigating Activation Divergence for Accurate and Communication-Efficient Federated Learning; Model-Based Clustering with HDBSCAN*; incremental Sensitivity Analysis for Kernelized Models; off-the-Grid: Fast and Effective Hyperparameter Search for Kernel Clustering; low-Regret Algorithms for Strategic Buyers with Unknown Valuations in Repeated Posted-Price Auctions; partial Label Learning via Subspace Representation and Global Disambiguation; online Partial Label Learning; network Cooperation with Progressive Disambiguation for Partial Label Learning; partial Label Learning via Self-Paced Curriculum Strategy; adaptive Momentum Coefficient for Neural Network Optimization; option Encoder: A Framework for Discovering a Policy Basis in Reinforcement Learning; EgoMap: Projective Mapping and Structured Egocentric Memory for Deep RL; ELSIM: End-to-End Learning of Reusable Skills Through Intrinsic Motivation; graph-Based Motion Planning Networks; graph Diffusion Wasserstein Distances; towards Interpretable Multi-task Learning Using Bilevel Programming; deep Learning, Grammar Transfer, and Transportation Theory; inductive Unsupervised Domain Adaptation for Few-Shot Classification via Clustering; bayesian Optimization with Missing Inputs.",,,,,,,,,Hutter F.Kersting K.Lijffijt J.Valera I.,,Springer Science and Business Media Deutschland GmbH,"European Conference on Machine Learning and Knowledge Discovery in Databases, ECML PKDD 2020",14 September 2020 through 18 September 2020,,255919,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Review,Final,,Scopus,2-s2.0-85103275499
[无可用作者姓名],[无可用的作者 ID],"European Conference on Machine Learning and Knowledge Discovery in Databases, ECML PKDD 2020",2021,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),12459 LNAI,,,,,3406,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103249675&partnerID=40&md5=aa54e9a430a556f78b896a89cd1ceb72,,,"The proceedings contain 205 papers. The special focus in this conference is on Machine Learning and Knowledge Discovery in Databases. The topics include: Adversarial Learned Molecular Graph Inference and Generation; A Generic and Model-Agnostic Exemplar Synthetization Framework for Explainable AI; quality Guarantees for Autoencoders via Unsupervised Adversarial Attacks; metric Learning for Categorical and Ambiguous Features: An Adversarial Method; learning Implicit Generative Models by Teaching Density Estimators; Reprogramming GANs via Input Noise Design; on Saliency Maps and Adversarial Robustness; scalable Backdoor Detection in Neural Networks; an Algorithmic Framework for Decentralised Matrix Factorisation; exponential Convergence of Gradient Methods in Concave Network Zero-Sum Games; federated Multi-view Matrix Factorization for Personalized Recommendations; FedMAX: Mitigating Activation Divergence for Accurate and Communication-Efficient Federated Learning; Model-Based Clustering with HDBSCAN*; incremental Sensitivity Analysis for Kernelized Models; off-the-Grid: Fast and Effective Hyperparameter Search for Kernel Clustering; low-Regret Algorithms for Strategic Buyers with Unknown Valuations in Repeated Posted-Price Auctions; partial Label Learning via Subspace Representation and Global Disambiguation; online Partial Label Learning; network Cooperation with Progressive Disambiguation for Partial Label Learning; partial Label Learning via Self-Paced Curriculum Strategy; adaptive Momentum Coefficient for Neural Network Optimization; option Encoder: A Framework for Discovering a Policy Basis in Reinforcement Learning; EgoMap: Projective Mapping and Structured Egocentric Memory for Deep RL; ELSIM: End-to-End Learning of Reusable Skills Through Intrinsic Motivation; graph-Based Motion Planning Networks; graph Diffusion Wasserstein Distances; towards Interpretable Multi-task Learning Using Bilevel Programming; deep Learning, Grammar Transfer, and Transportation Theory; inductive Unsupervised Domain Adaptation for Few-Shot Classification via Clustering; bayesian Optimization with Missing Inputs.",,,,,,,,,Hutter F.Kersting K.Lijffijt J.Valera I.,,Springer Science and Business Media Deutschland GmbH,"European Conference on Machine Learning and Knowledge Discovery in Databases, ECML PKDD 2020",14 September 2020 through 18 September 2020,,255919,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Review,Final,,Scopus,2-s2.0-85103249675
[无可用作者姓名],[无可用的作者 ID],"European Conference on Machine Learning and Knowledge Discovery in Databases, ECML PKDD 2020",2021,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),12461 LNAI,,,,,3406,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103246929&partnerID=40&md5=21823dbf56167339e0a3bf4d79dc703d,,,"The proceedings contain 205 papers. The special focus in this conference is on Machine Learning and Knowledge Discovery in Databases. The topics include: Adversarial Learned Molecular Graph Inference and Generation; A Generic and Model-Agnostic Exemplar Synthetization Framework for Explainable AI; quality Guarantees for Autoencoders via Unsupervised Adversarial Attacks; metric Learning for Categorical and Ambiguous Features: An Adversarial Method; learning Implicit Generative Models by Teaching Density Estimators; Reprogramming GANs via Input Noise Design; on Saliency Maps and Adversarial Robustness; scalable Backdoor Detection in Neural Networks; an Algorithmic Framework for Decentralised Matrix Factorisation; exponential Convergence of Gradient Methods in Concave Network Zero-Sum Games; federated Multi-view Matrix Factorization for Personalized Recommendations; FedMAX: Mitigating Activation Divergence for Accurate and Communication-Efficient Federated Learning; Model-Based Clustering with HDBSCAN*; incremental Sensitivity Analysis for Kernelized Models; off-the-Grid: Fast and Effective Hyperparameter Search for Kernel Clustering; low-Regret Algorithms for Strategic Buyers with Unknown Valuations in Repeated Posted-Price Auctions; partial Label Learning via Subspace Representation and Global Disambiguation; online Partial Label Learning; network Cooperation with Progressive Disambiguation for Partial Label Learning; partial Label Learning via Self-Paced Curriculum Strategy; adaptive Momentum Coefficient for Neural Network Optimization; option Encoder: A Framework for Discovering a Policy Basis in Reinforcement Learning; EgoMap: Projective Mapping and Structured Egocentric Memory for Deep RL; ELSIM: End-to-End Learning of Reusable Skills Through Intrinsic Motivation; graph-Based Motion Planning Networks; graph Diffusion Wasserstein Distances; towards Interpretable Multi-task Learning Using Bilevel Programming; deep Learning, Grammar Transfer, and Transportation Theory; inductive Unsupervised Domain Adaptation for Few-Shot Classification via Clustering; bayesian Optimization with Missing Inputs.",,,,,,,,,Dong Y.Mladenic D.Saunders C.,,Springer Science and Business Media Deutschland GmbH,"European Conference on Machine Learning and Knowledge Discovery in Databases, ECML PKDD 2020",14 September 2020 through 18 September 2020,,255919,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Review,Final,,Scopus,2-s2.0-85103246929
[无可用作者姓名],[无可用的作者 ID],"European Conference on Machine Learning and Knowledge Discovery in Databases, ECML PKDD 2020",2021,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),12460 LNAI,,,,,3406,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103238204&partnerID=40&md5=33c44ec4b44dc1dd74ab29194d02925d,,,"The proceedings contain 205 papers. The special focus in this conference is on Machine Learning and Knowledge Discovery in Databases. The topics include: Adversarial Learned Molecular Graph Inference and Generation; A Generic and Model-Agnostic Exemplar Synthetization Framework for Explainable AI; quality Guarantees for Autoencoders via Unsupervised Adversarial Attacks; metric Learning for Categorical and Ambiguous Features: An Adversarial Method; learning Implicit Generative Models by Teaching Density Estimators; Reprogramming GANs via Input Noise Design; on Saliency Maps and Adversarial Robustness; scalable Backdoor Detection in Neural Networks; an Algorithmic Framework for Decentralised Matrix Factorisation; exponential Convergence of Gradient Methods in Concave Network Zero-Sum Games; federated Multi-view Matrix Factorization for Personalized Recommendations; FedMAX: Mitigating Activation Divergence for Accurate and Communication-Efficient Federated Learning; Model-Based Clustering with HDBSCAN*; incremental Sensitivity Analysis for Kernelized Models; off-the-Grid: Fast and Effective Hyperparameter Search for Kernel Clustering; low-Regret Algorithms for Strategic Buyers with Unknown Valuations in Repeated Posted-Price Auctions; partial Label Learning via Subspace Representation and Global Disambiguation; online Partial Label Learning; network Cooperation with Progressive Disambiguation for Partial Label Learning; partial Label Learning via Self-Paced Curriculum Strategy; adaptive Momentum Coefficient for Neural Network Optimization; option Encoder: A Framework for Discovering a Policy Basis in Reinforcement Learning; EgoMap: Projective Mapping and Structured Egocentric Memory for Deep RL; ELSIM: End-to-End Learning of Reusable Skills Through Intrinsic Motivation; graph-Based Motion Planning Networks; graph Diffusion Wasserstein Distances; towards Interpretable Multi-task Learning Using Bilevel Programming; deep Learning, Grammar Transfer, and Transportation Theory; inductive Unsupervised Domain Adaptation for Few-Shot Classification via Clustering; bayesian Optimization with Missing Inputs.",,,,,,,,,Dong Y.Mladenic D.Saunders C.,,Springer Science and Business Media Deutschland GmbH,"European Conference on Machine Learning and Knowledge Discovery in Databases, ECML PKDD 2020",14 September 2020 through 18 September 2020,,255919,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Review,Final,,Scopus,2-s2.0-85103238204
[无可用作者姓名],[无可用的作者 ID],"European Conference on Machine Learning and Knowledge Discovery in Databases, ECML PKDD 2020",2021,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),12458 LNAI,,,,,3406,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103235645&partnerID=40&md5=653fb05ce66ad807cb96737bbc0566ca,,,"The proceedings contain 205 papers. The special focus in this conference is on Machine Learning and Knowledge Discovery in Databases. The topics include: Adversarial Learned Molecular Graph Inference and Generation; A Generic and Model-Agnostic Exemplar Synthetization Framework for Explainable AI; quality Guarantees for Autoencoders via Unsupervised Adversarial Attacks; metric Learning for Categorical and Ambiguous Features: An Adversarial Method; learning Implicit Generative Models by Teaching Density Estimators; Reprogramming GANs via Input Noise Design; on Saliency Maps and Adversarial Robustness; scalable Backdoor Detection in Neural Networks; an Algorithmic Framework for Decentralised Matrix Factorisation; exponential Convergence of Gradient Methods in Concave Network Zero-Sum Games; federated Multi-view Matrix Factorization for Personalized Recommendations; FedMAX: Mitigating Activation Divergence for Accurate and Communication-Efficient Federated Learning; Model-Based Clustering with HDBSCAN*; incremental Sensitivity Analysis for Kernelized Models; off-the-Grid: Fast and Effective Hyperparameter Search for Kernel Clustering; low-Regret Algorithms for Strategic Buyers with Unknown Valuations in Repeated Posted-Price Auctions; partial Label Learning via Subspace Representation and Global Disambiguation; online Partial Label Learning; network Cooperation with Progressive Disambiguation for Partial Label Learning; partial Label Learning via Self-Paced Curriculum Strategy; adaptive Momentum Coefficient for Neural Network Optimization; option Encoder: A Framework for Discovering a Policy Basis in Reinforcement Learning; EgoMap: Projective Mapping and Structured Egocentric Memory for Deep RL; ELSIM: End-to-End Learning of Reusable Skills Through Intrinsic Motivation; graph-Based Motion Planning Networks; graph Diffusion Wasserstein Distances; towards Interpretable Multi-task Learning Using Bilevel Programming; deep Learning, Grammar Transfer, and Transportation Theory; inductive Unsupervised Domain Adaptation for Few-Shot Classification via Clustering; bayesian Optimization with Missing Inputs.",,,,,,,,,Hutter F.Kersting K.Lijffijt J.Valera I.,,Springer Science and Business Media Deutschland GmbH,"European Conference on Machine Learning and Knowledge Discovery in Databases, ECML PKDD 2020",14 September 2020 through 18 September 2020,,255919,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Review,Final,,Scopus,2-s2.0-85103235645
"Qu X., Ong Y., Gupta A.",57190405716;7006735298;57218701794;,Frame-Correlation Transfers Trigger Economical Attacks on Deep Reinforcement Learning Policies,2021,IEEE Transactions on Cybernetics,,,,,,,1,10.1109/TCYB.2020.3041265,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099581026&doi=10.1109%2fTCYB.2020.3041265&partnerID=40&md5=8b5703df868933cbbb92592ffcaa62bd,"Computational Intelligence Lab, School of Computer Science and Engineering, Nanyang Technological University, Singapore 639798.; Data Science and Artificial Intelligence Research Centre, School of Computer Science and Engineering, Nanyang Technological University, Singapore 639798, also with the Singtel Cognitive and Artificial Intelligence Lab for Enterprises, Nanyang Technological University, Singapore 639798, and also with the Singapore Institute of Manufacturing Technology (SIMTech), Agency for Science, Technology and Research, Singapore.; Singapore Institute of Manufacturing Technology, Agency for Science, Technology and Research, Singapore (e-mail: abhishek_gupta@simtech.a-star.edu.sg)","Qu, X., Computational Intelligence Lab, School of Computer Science and Engineering, Nanyang Technological University, Singapore 639798.; Ong, Y., Data Science and Artificial Intelligence Research Centre, School of Computer Science and Engineering, Nanyang Technological University, Singapore 639798, also with the Singtel Cognitive and Artificial Intelligence Lab for Enterprises, Nanyang Technological University, Singapore 639798, and also with the Singapore Institute of Manufacturing Technology (SIMTech), Agency for Science, Technology and Research, Singapore.; Gupta, A., Singapore Institute of Manufacturing Technology, Agency for Science, Technology and Research, Singapore (e-mail: abhishek_gupta@simtech.a-star.edu.sg)","Adversarial attack can be deemed as a necessary prerequisite evaluation procedure before the deployment of any reinforcement learning (RL) policy. Most existing approaches for generating adversarial attacks are gradient based and are extensive, viz., perturbing every pixel of every frame. In contrast, recent advances show that gradient-free selective perturbations (i.e., attacking only selected pixels and frames) could be a more realistic adversary. However, these attacks treat every frame in isolation, ignoring the relationship between neighboring states of a Markov decision process; thus resulting in high computational complexity that tends to limit their real-world plausibility due to the tight time constraint in RL. Given the above, this article showcases the first study of how transferability across frames could be exploited for boosting the creation of minimal yet powerful attacks in image-based RL. To this end, we introduce three types of frame-correlation transfers (FCTs) (i.e., anterior case transfer, random projection-based transfer, and principal components-based transfer) with varying degrees of computational complexity in generating adversaries via a genetic algorithm. We empirically demonstrate the tradeoff between the complexity and potency of the transfer mechanism by exploring four fully trained state-of-the-art policies on six Atari games. Our FCTs dramatically speed up the attack generation compared to existing methods, often reducing the computation time required to nearly zero; thus, shedding light on the real threat of real-time attacks in RL. IEEE",Adversarial attack; deep reinforcement learning (DRL); transfer optimization,Computational complexity; Genetic algorithms; Markov processes; Pixels; Reinforcement learning; Computation time; Frame correlations; Markov Decision Processes; Principal Components; Random projections; State of the art; Time constraints; Transfer mechanisms; Deep learning,,,,,,,,,Institute of Electrical and Electronics Engineers Inc.,,,,,21682267,,,,English,IEEE Trans. Cybern.,Article,Article in Press,,Scopus,2-s2.0-85099581026
[无可用作者姓名],[无可用的作者 ID],"19th International Conference on Hybrid Intelligent Systems, HIS 2019, and the 14th International Conference on Information Assurance and Security, IAS 2019",2021,Advances in Intelligent Systems and Computing,1179 AISC,,,,,453,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089754110&partnerID=40&md5=ab51da3b735bb9e23109c29a27dbf29e,,,"The proceedings contain 43 papers. The special focus in this conference is on Hybrid Intelligent Systems. The topics include: Heterogeneous engineering in intelligent logistics; welcome message; dimension reduction with extraction methods (principal component analysis - Self organizing map - Isometric mapping) in indonesian language text documents clustering; extracting unknown repeated pattern in tiled images; convolutional deep learning network for handwritten arabic script recognition; diversity in recommendation system: A cluster based approach; contribution on arabic handwriting recognition using deep neural network; analyzing and enhancing processing speed of k-medoid algorithm using efficient large scale processing frameworks; multiple criteria fake reviews detection based on spammers’ indicators within the belief function theory; data clustering using environmental adaptation method; soft computing, data mining, and machine learning approaches in detection of heart disease: A review; a novel cad system for breast dce-mri based on textural analysis using several machine learning methods; an adversarial learning mechanism for dealing with the class-imbalance problem in land-cover classification; reducing data volume in instance based learning; an integrated fuzzy anp-topsis approach to rank and assess e-commerce web sites; implementation of block chain technology in public distribution system; chaotic salp swarm optimization using svm for class imbalance problems; three-layer security for password protection using rdh, aes and ecc; clothing classification using deep cnn architecture based on transfer learning; identification of botnet attacks using hybrid machine learning models; congestion control in vehicular ad-hoc networks (vanet’s): A review; advances in cyber security paradigm: A review; recursive tangent algorithm for path planning in autonomous systems.",,,,,,,,,Abraham A.Shandilya S.K.Garcia-Hernandez L.Varela M.L.,,Springer,"19th International Conference on Hybrid Intelligent Systems, HIS 2019, and the 14th International Conference on Information Assurance and Security, IAS 2019",10 December 2019 through 12 December 2019,,243659,21945357,9.78E+12,,,English,Adv. Intell. Sys. Comput.,Conference Review,Final,,Scopus,2-s2.0-85089754110
"Shrestha P., Liu Z., Saxena N.",57031498700;57221048025;57206303753;,IvoriWatch: Exploring Transparent Integrity Verification of Remote User Input Leveraging Wearables,2020,ACM International Conference Proceeding Series,,,3427279,706,716,,,10.1145/3427228.3427279,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098052191&doi=10.1145%2f3427228.3427279&partnerID=40&md5=0383abf347e6e17b742c98feff0c2571,"University of Florida, United States; University of Alabama at Birmingham, United States","Shrestha, P., University of Florida, United States; Liu, Z., University of Alabama at Birmingham, United States; Saxena, N., University of Alabama at Birmingham, United States","Several sensitive operations, such as financial transactions, email construction, configurations of safety-critical devices (e.g., medical devices or smart home systems), are often performed via web interfaces from a host machine, usually a desktop or laptop PC. It is typically easy to secure the communication link between the local host machine and the remote server, for example, via a standard cryptographic protocol (e.g., TLS). However, if the host machine itself is compromised with a trojan or malware, the malicious adversary can manipulate the user-provided input (e.g., money transfer information, email content and configuration data) that can lead to severe consequences, including financial loss, damage of reputation, security breach, and even put human lives in danger. In this paper, we introduce the notion of integrity verification for the user-provided input leveraging a wrist-worn wearable device (e.g., a watch or a bracelet). Specifically, we propose IvoriWatch1, a transparent and secure integrity verification mechanism, that inspects the user-provided input from a compromised host machine to a remote server for its integrity before acting upon the input. IvoriWatch requires the user to wear a wrist-wearable (either on one hand or both hands for better security). It verifies the validity of the payload/input received at the remote server by comparing it (i.e., the corresponding sequence of keyboard regions - left or right) with the predicted ones based on the wrist motions captured by the wrist-wearable. Only when the user input sufficiently correlates with the wrist motion data, the input is considered legitimate. We build a prototype implementation of IvoriWatch on an Android smartwatch as the wrist-wearable and a desktop PC terminal as a host machine, and evaluate it under benign and adversarial settings. Our results suggest that IvoriWatch can correctly detect the legitimacy of the input in the benign setting, and the manipulated as well as unintended input from a malicious program in the adversarial settings with minimal errors. Although IvoriWatch uses wrist movements for integrity verification, it is not a biometric scheme. © 2020 ACM.",Input Manipulation Attack and Mitigation; Integrity Verification; Wearable Device,Automation; Electronic mail; Losses; Malware; mHealth; Personal computers; Safety engineering; Security systems; Cryptographic protocols; Financial transactions; Integrity verifications; Malicious adversaries; Prototype implementations; Security breaches; Smart-home system; Wearable devices; Wearable technology,,,,,"Acar, A., Aksu, H., Selcuk Uluagac, A., Akkaya, K., (2018) WACA: Wearable-Assisted Continuous Authentication. ArXiv Preprint; Alzomai, M., Alfayyadh, B., Josang, A., McCullagh, A., (2008) An Exprimental Investigation of the Usability of Transaction Authorization in Online Bank Security Systems, , 2008; (2018) APNs Overview, , https://goo.gl/k37dLV, Apple Inc. Last Accessed: February 1, 2018; Chen, H., Zhang, Y., Zhang, Z., Fang, Y., Liu, H., Yao, C., Exploring the relation between EMG sampling frequency and hand motion recognition accuracy (2017) 2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC). IEEE, pp. 1139-1144; Intelligence Blog, D., (2017) How Trojans Withdraw Money from Your Account, , https://defintel.com/blog/index.php/2017/08/how-trojans-withdrawmoney-from-your-Account.html, Last Accessed: 14th June, 2020; Dhar, A., Yu, D., Kostiainen, K., (2017) INTEGRIKEY: Integrity Protection of User Input for Remote Configuration of Safety-Critical Devices, , 2017; Security Inc, D., (2018) Duo Mobile: Duo Security, , https://duo.com/solutions/features/user-experience/easy-Authentication; (2018) Firebase Cloud Messaging | Firebase, , https://firebase.google.com/docs/cloud-messaging/, Last Accessed: February 1, 2018.Google Inc; (2018) Google 2-Step Verification, , https://www.google.com/landing/2step/, Google Inc; Jang, Y., Chung, S.P., Payne, B.D., Lee, W., Gyrus: A framework for user-intent monitoring of text-based networked applications (2014) NDSS; Kiljan, S., Vranken, H., Van Eekelen, M., What you enter is what you sign: Input integrity in an online banking environment (2014) 2014 Workshop on Socio-Technical Aspects in Security and Trust. IEEE, pp. 40-47; Liu, X., Chen, T., Qian, F., Guo, Z., Xiaozhu Lin, F., Wang, X., Chen, K., Characterizing smartwatch usage in the wild (2017) International Conference on Mobile Systems, Applications, and Services. ACM; Mare, S., Molina Markham, A., Cornelius, C., Peterson, R., Kotz, D., Zebra: Zero-effort bilateral recurring authentication (2014) 2014 IEEE Symposium on Security and Privacy. IEEE, pp. 705-720; McCune, J.M., Parno, B.J., Perrig, A., Reiter, M.K., Isozaki, H., Flicker: An execution infrastructure for TCB minimization (2008) Proceedings of the 3rd ACM SIGOPS/EuroSys European Conference on Computer Systems 2008. 315-328; (2018) Windows Push Notification Services (WNS) Overview, , https://goo.gl/sTmGPK, Last Accessed: July 26, 2018.Microsoft Inc; Poyraz, E., Memik, G., Analyzing power consumption and characterizing user activities on smartwatches: Summary (2016) International Symposium on Workload Characterization (IISWC), , 2016. IEEE; Ravi, N., Dandekar, N., Mysore, P., Littman, M.L., Activity recognition from accelerometer data (2005) Aaai, 5, pp. 1541-1546; Schluessler, T., Goglin, S., Johnson, E., Is a bot at the controls Detecting input data attacks (2007) Proceedings of the 6th ACM SIGCOMM Workshop on Network and System Support for Games, pp. 1-6; (2020) Wearable Sensor Technology | Wireless IMU | ECG | EMG | GSR, , https://www.shimmersensing.com/, Shimmer Inc; Sophos Ltd. 2020. 13 Years Jail for Bank Robbers Who Used Trojan Horse, , https://nakedsecurity.sophos.com/2009/11/16/13-years-jail-bank-robberstrojan-horse/; Szydlowski, M., Kruegel, C., Kirda, E., Secure input for web applications (2007) Twenty-Third Annual Computer Security Applications Conference (ACSAC 2007). IEEE, pp. 375-384; (2020) English Paragraph Typing Test, p. 2020. , https://thepracticetest.com/typing/tests/practice-paragraphs/, Last Accessed: 7th June, The Practice Test; (2017) Simple Exploit Allows Attackers to Modify Email Content - even after It's Sent!, , https://rb.gy/lrz3fq, The Hacker News; Weigold, T., Hiltgen, A., (2011) Secure Confirmation of Sensitive Transaction Data in Modern Internet Banking Services, 2",,,Applied Computer Security Associates (ACSA),Association for Computing Machinery,"36th Annual Computer Security Applications Conference, ACSAC 2020",7 December 2020 through 11 December 2020,,165673,,9.78E+12,,,English,ACM Int. Conf. Proc. Ser.,Conference Paper,Final,,Scopus,2-s2.0-85098052191
"Yilmaz I., Siraj A., Ulybyshev D.",57219317333;57205902758;56732908700;,Improving DGA-Based malicious domain classifiers for malware defense with adversarial machine learning,2020,"4th IEEE Conference on Information and Communication Technology, CICT 2020",,,9311925,,,,4,10.1109/CICT51604.2020.9311925,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100195241&doi=10.1109%2fCICT51604.2020.9311925&partnerID=40&md5=0663b76e8e4e4685965b267623b18699,"Tennessee Technological University, Department of Computer Science, Cookeville, United States","Yilmaz, I., Tennessee Technological University, Department of Computer Science, Cookeville, United States; Siraj, A., Tennessee Technological University, Department of Computer Science, Cookeville, United States; Ulybyshev, D., Tennessee Technological University, Department of Computer Science, Cookeville, United States","Domain Generation Algorithms (DGAs) are used by adversaries to establish Command and Control (CC) server communications during cyber attacks. Blacklists of known/identified CC domains are used as one of the defense mechanisms. However, static blacklists generated by signaturebased approaches can neither keep up nor detect never-seen-before malicious domain names. To address this weakness, we applied a DGA-based malicious domain classifier using the Long Short-Term Memory (LSTM) method with a novel feature engineering technique. Our model's performance shows a greater accuracy compared to a previously reported model. Additionally, we propose a new adversarial machine learning-based method to generate never-before-seen malware-related domain families. We augment the training dataset with new samples to make the training of the models more effective in detecting never-before-seen malicious domain names. To protect blacklists of malicious domain names against adversarial access and modifications, we devise secure data containers to store and transfer blacklists. © 2020 IEEE.",Adversarial Machine Learning; Data Privacy; Domain Generation Algorithms; Long Short-Term Memory,Command and control systems; Long short-term memory; Machine learning; Network security; Command and control; Cyber-attacks; Defense mechanism; Feature engineerings; Generation algorithm; Server communications; Signature-based approach; Training dataset; Malware,,,,,"(2020) Domain Generation Algorithm, , https://en.wikipedia.org/wiki/Domaingenerationalgorithm, September; Yadav, S., Reddy, A.K.K., Reddy, A., Ranjan, S., Detecting algorithmically generated malicious domain names (2010) Proc. Of the 10th ACM SIGCOMM Conf. Of Internet Measurement. ACM, pp. 48-61; Yu, B., Pan, J., Hu, J., Nascimento, A., De Cock, M., Character level based detection of dga domain names (2018) 2018 Intl. Joint Conf. On Neural Networks (IJCNN). IEEE, pp. 1-8; Yilmaz, I., (2020) Practical Fast Gradient Sign Attack against Mammographic Image Classifier; Yilmaz, I., Masum, R., Siraj, A., Addressing imbalanced data problem with generative adversarial network for intrusion detection (2020) 2020 IEEE 21st Intl. Conf. On Information Reuse and Integration for Data Science (IRI), pp. 25-30. , IEEE Computer Society; Ulybyshev, D., Bare, C., Bellisario, K., Kholodilo, V., Northern, B., Solanki, A., O'Donnell, T., Protecting electronic health records in transit and at rest (2020) 2020 IEEE 33rd Intl. Symp. On Computer-Based Medical Systems (CBMS), pp. 449-452; (2018) How Do i Know if i'M on A Spam Blacklist?, , https://www.pinpointe.com/blog/how-do-i-know-if-im-on-a-spam-blacklist, September; Ligh, M., Adair, S., Hartstein, B., Richard, M., (2010) Malware Analyst's Cookbook and DVD: Tools and Techniques for Fighting Malicious Code, , Wiley Publishing; Yen, T.-F., Reiter, M.K., Are your hosts trading or plotting? Telling p2p file-sharing and bots apart (2010) 2010 IEEE 30th Intl. Conf. On Distributed Computing Systems. IEEE, pp. 241-252; Manni, J., Aziz, A., Gong, F., Loganathan, U., Amin, M., (2015) Networkbased Binary File Extraction and Analysis for Malware Detection, , Jan. 13; Anderson, H.S., Woodbridge, J., Filar, B., Deepdga: Adversariallytuned domain generation and detection (2016) Proc. Of the 2016 ACM Workshop on Artificial Intelligence and Security. ACM, pp. 13-21; Yilmaz, I., Masum, R., (2019) Expansion of Cyber Attack Data from Unbalanced Datasets Using Generative Techniques; Curtin, R.R., Gardner, A.B., Grzonkowski, S., Kleymenov, A., Mosquera, A., Detecting dga domains with recurrent neural networks and side information (2019) Proc. Of the 14th Intl. Conf. Of Availability, Reliability and Security, pp. 1-10; Zhauniarovich, Y., Khalil, I., Yu, T., Dacier, M., A survey on malicious domains detection through dns data analysis (2018) ACM Computing Surveys (CSUR), 51 (4), pp. 1-36; Othmane, L.B., Lilien, L., Protecting privacy of sensitive data dissemination using active bundles (2009) 2009 World Congress on Privacy, Security, Trust and the Management of E-Business. IEEE, pp. 202-213; Ranchal, R., (2015) Cross-domain Data Dissemination and Policy Enforcement; Mithu, M.R.A., Kholodilo, V., Manicavasagam, R., Ulybyshev, D., Rogers, M., Secure industrial control system with intrusion detection (2020) The 33rd Intl. Flairs Conf.; Lilien, L., Bhargava, B., A scheme for privacy-preserving data dissemination (2006) IEEE Trans. On Systems, Man, and Cybernetics-Part A: Systems and Humans, 36 (3), pp. 503-506; Hochreiter, S., The vanishing gradient problem during learning recurrent neural nets and problem solutions (1998) Intl. Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, 6 (2), pp. 107-116; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9 (8), pp. 1735-1780; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; (2020) Cosine Similarity, , https://en.wikipedia.org/wiki/Cosinesimilarity, September; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples; (2020) Majestic Million, , https://majestic.com/reports, September; Plohmann, D., Yakdan, K., Klatt, M., Bader, J., Gerhards-Padilla, E., A comprehensive measurement study of domain generating malware (2016) 25th {USENIX} Security Symp. ({USENIX} Security 16), pp. 263-278",,,,Institute of Electrical and Electronics Engineers Inc.,"4th IEEE Conference on Information and Communication Technology, CICT 2020",3 December 2020 through 5 December 2020,,166450,,9.78E+12,,,English,,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85100195241
"Tian Y., Wang Y., Tong E., Niu W., Chang L., Chen Q.A., Li G., Liu J.",57221045656;57195494558;42762175500;25028470300;57169276800;56379253400;56336374700;7410116593;,Exploring data correlation between feature pairs for generating constraint-based adversarial examples,2020,Proceedings of the International Conference on Parallel and Distributed Systems - ICPADS,2020-December,,9359196,430,437,,,10.1109/ICPADS51040.2020.00064,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102347796&doi=10.1109%2fICPADS51040.2020.00064&partnerID=40&md5=2ab39ba0201190a241d2c6eec5d3d7b9,"Beijing Key Laboratory of Security and Privacy in Intelligent Transportation, Beijing Jiaotong University, Beijing, China; Guangxi Key Laboratory of Trusted Software, Guilin University of Electronic Technology, Guilin, China; University of California, Irvine, United States; Australia Centre for Cyber Security Research and Innovation, Deakin University, Geelong, Australia","Tian, Y., Beijing Key Laboratory of Security and Privacy in Intelligent Transportation, Beijing Jiaotong University, Beijing, China; Wang, Y., Beijing Key Laboratory of Security and Privacy in Intelligent Transportation, Beijing Jiaotong University, Beijing, China; Tong, E., Beijing Key Laboratory of Security and Privacy in Intelligent Transportation, Beijing Jiaotong University, Beijing, China; Niu, W., Beijing Key Laboratory of Security and Privacy in Intelligent Transportation, Beijing Jiaotong University, Beijing, China; Chang, L., Guangxi Key Laboratory of Trusted Software, Guilin University of Electronic Technology, Guilin, China; Chen, Q.A., University of California, Irvine, United States; Li, G., Australia Centre for Cyber Security Research and Innovation, Deakin University, Geelong, Australia; Liu, J., Beijing Key Laboratory of Security and Privacy in Intelligent Transportation, Beijing Jiaotong University, Beijing, China","Adversarial example (AE), an input that is modified slightly to cause a machine learning system to produce erroneous outputs, has seen significant studies recently. Unfortunately, the fine data perturbation of AE ignores to keep potential data correlations between feature pairs. Thus, such AE will be easily filtered by configuring data correlations as basic filtering rules. In this paper, avoiding not to be filtered as well as causing false classification, an advanced robust AE generation attack is proposed. We first define four basic data correlations called strict linear constraint, approximate linear constraint, addition boundary constraint and zero multiplication constraint. Then, based on embedding multiple data correlations into one constraint matrix from the Pearson analysis, our approach can enable a Hadamard product of the constraint matrix and the sign of gradient matrix to craft perturbations, keeping consistent data correlations. Experimental results on intrusion detection system (IDS) indicate: 1) Nearly all AEs from original IFGSM are invalid by filtering according to basic data correlations; 2) In our method, AEs against a targeted DNN-based classifier can achieve an attack success rate of 99%, with transfer attack ability of 94% average success rate to attack other different mainstream classifiers. © 2020 IEEE.",Adversarial examples generation; Deep neural network; Feature constraints; Pearson correlation coefficient,Distributed database systems; Intrusion detection; Learning systems; Network security; Turing machines; Boundary constraints; Constraint-based; Data correlations; Data perturbation; Filtering rules; Hadamard products; Intrusion Detection Systems; Linear constraints; Matrix algebra,,,,,"He, K., Zhang, X., Ren, S., Deep residual learning for image recognition[c] (2016) Ieee Conference on Computer Vision &Pattern Recognition. Ieee Computer Society; Chan, W., Jaitly, N., Le, Q., Listen, attend and spell: A neural network for large vocabulary conversational speech recognition[c] (2016) 2016 Ieee International Conference on Acoustics, Speech and Signal Processing (Icassp); Yang, C., Liu, Z., Zhao, D., Network representation learning with rich text information[C] (2015) Twenty-Fourth International Joint Conference on Artificial Intelligence.; Zhang, M., Zhang, Y., Zhang, L., Deeproad: Gan-based metamorphic testing and input validation framework for autonomous driving systems[c] (2018) Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering., pp. 132-142; Szegedy, C., Zaremba, W., Sutskever, I., (2013) Intriguing Properties of Neural Networks[J]; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples[C] (2015) ICML.; Chen, T., Liu, J., Xiang, Y., Adversarial attack and defense in reinforcement learning-from AI security view[J] (2019) Cybersecurity, 2 (1), pp. 1-22; Sharif, M., Bhagavatula, S., Bauer, L., Accessorize to a crime: Real and stealthy attacks on state-of-The-art face recognition[c] (2016) Acm Sigsac Conference. Acm; Grosse, K., Papernot, N., Manoharan, P., Adversarial examples for malware detection[C] (2017) European Symposium on Research in Computer Security. Springer, pp. 62-79. , Cham; Duan, R., Ma, X., Wang, Y., (2020) Adversarial Camouflage: Hiding Physical-World Attacks with Natural Styles[J; Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks[C] Proceedings of the Ieee Conference on Computer Vision and Pattern Recognition., 2016, pp. 2574-2582; Papernot, N., McDaniel, P., Jha, S., The limitations of deep learning in adversarial settings[C] (2016) 2016 Ieee European Symposium on Security and Privacy (EuroS&P). Ieee, pp. 372-387; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks[C] (2017) 2017 Ieee Symposium on Security and Privacy (Sp). Ieee, pp. 39-57; Xiao, C., Li, B., Zhu, J.Y., (2018) Generating Adversarial Examples with Adversarial Networks[J]; Qiu, H., Xiao, C., Yang, L., (2019) SemanticAdv: Generating Adversarial Examples Via Attribute-conditional Image Editing[J].; Moosavi-Dezfooli, S.M., Fawzi, A., Fawzi, O., Universal adversarial perturbations[C] (2017) Proceedings of the Ieee Conference on Computer Vision and Pattern Recognition., pp. 1765-1773; He, Y., Generating adversarial examples against machine learning based intrusion detector in industrial control system[d] (2019) Zhejiang University; Hota, H.S., Shrivas, A.K., Decision tree techniques applied on nslkdd data and its comparison with various feature selection techniques[m] (2014) Advanced Computing, Networking and Informatics-Volume 1. Springer, Cham, pp. 205-211; Dhanabal, L., Shantharajah, S.P., A study on nsl-kdd dataset for intrusion detection system based on classification algorithms[j] (2015) International Journal of Advanced Research in Computer and Communication Engineering, 4 (6), pp. 446-452; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World[J]; Samanta, S., Mehta, S., (2017) Towards Crafting Text Adversarial Samples[J]; Liang, B., Li, H., Su, M., (2017) Deep Text Classification Can Be Fooled[J]; Al-Dujaili, A., Huang, A., Hemberg, E., Adversarial deep learning for robust detection of binary encoded malware[C] (2018) 2018 Ieee Security and Privacy Workshops (SPW). Ieee, pp. 76-82; Lin, Z., Shi, Y., Xue, Z., (2018) Idsgan: Generative Adversarial Networks for Attack Generation against Intrusion Detection[J]; Verhoeff, T., Delay-insensitive codes-an overview[J] (1988) Distributed Computing, 3 (1), pp. 1-8","Tong, E.; Beijing Key Laboratory of Security and Privacy in Intelligent Transportation, China; 电子邮件: edtong@bjtu.edu.cn
Niu, W.; Beijing Key Laboratory of Security and Privacy in Intelligent Transportation, China; 电子邮件: niuwj@bjtu.edu.cn",,IEEE Computer Society,IEEE Computer Society,"26th IEEE International Conference on Parallel and Distributed Systems, ICPADS 2020",2 December 2020 through 4 December 2020,,167505,15219097,9.78E+12,PIPSF,,English,Proc Int Conf Parallel Distrib Syst ICPADS,Conference Paper,Final,,Scopus,2-s2.0-85102347796
"Jiang M., Wang Y., Gou G., Cai W., Xiong G., Shi J.",57214780421;57207002220;57190497334;57219599622;55733323100;57211340125;,PST: A More Practical Adversarial Learning-based Defense against Website Fingerprinting,2020,"2020 IEEE Global Communications Conference, GLOBECOM 2020 - Proceedings",,,9322307,,,,,10.1109/GLOBECOM42002.2020.9322307,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100372639&doi=10.1109%2fGLOBECOM42002.2020.9322307&partnerID=40&md5=b44f4682b14f289017be07758e48415c,"Institute of Information Engineering, Chinese Academy of Sciences, China; School of Cyber Security, University of Chinese Academy of Sciences, China; National Computer Network Emergency Response Technical Team, Coordination Center of China, China","Jiang, M., Institute of Information Engineering, Chinese Academy of Sciences, China, School of Cyber Security, University of Chinese Academy of Sciences, China; Wang, Y., National Computer Network Emergency Response Technical Team, Coordination Center of China, China; Gou, G., Institute of Information Engineering, Chinese Academy of Sciences, China, School of Cyber Security, University of Chinese Academy of Sciences, China; Cai, W., Institute of Information Engineering, Chinese Academy of Sciences, China, School of Cyber Security, University of Chinese Academy of Sciences, China; Xiong, G., Institute of Information Engineering, Chinese Academy of Sciences, China, School of Cyber Security, University of Chinese Academy of Sciences, China; Shi, J., Institute of Information Engineering, Chinese Academy of Sciences, China, School of Cyber Security, University of Chinese Academy of Sciences, China","To prevent serious privacy leakage from website fingerprinting (WF) attacks, many traditional or adversarial WF defenses have been released. However, traditional WF defenses such as Walkie-Talkie (W-T) still generate patterns that might be captured by the deep learning (DL) based WF attacks, which are not effective. Adversarial perturbation based WF defenses better confuse WF attacks, but their requirements for the entire original traffic trace and perturbating any points including historical packets or cells of the network traffic are not practical. To deal with the effectiveness and practicality issues of existing defenses, we proposed a novel WF defense in this paper, called PST. Given a few past bursts of a trace as input, PST Predicts subsequent fuzzy bursts with a neural network, then Searches small but effective adversarial perturbation directions based on observed and predicted bursts, and finally Transfers the perturbation directions to the remaining bursts. Our experimental results over a public closed-world dataset demonstrate that PST can successfully break the network traffic pattern and achieve a high evasion rate of 87.6%, beating W-T by more than 31.59% at the same bandwidth overhead, with only observing 10 transferred bursts. Moreover, our defense adapts to WF attacks dynamically, which could be retrained or updated. © 2020 IEEE.",Adversarial Machine Learning; Anonymity Communication; Deep Learning; Privacy; Website Fingerprinting attack and defense,Network security; Privacy by design; Websites; Adversarial learning; Bandwidth overheads; Network traffic; Privacy leakages; Traffic traces; Walkie talkies; Deep learning,,,,,"Panchenko, A., Lanze, F., Pennekamp, J., Engel, T., Zinnen, A., Henze, M., Wehrle, K., Website fingerprinting at internet scale (2016) NDSS; Hayes, J., Danezis, G., K-fingerprinting: A robust scalable website fingerprinting technique (2016) 25th USENIX Security Symposium (USENIX Security 16), pp. 1187-1203; Sirinam, P., Imani, M., Juarez, M., Wright, M., Deep fingerprinting: Undermining website fingerprinting defenses with deep learning (2018) Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, pp. 1928-1943; Abe, K., Goto, S., Fingerprinting attack on tor anonymity using deep learning (2016) Proceedings of the Asia-Pacific Advanced Network, 42, pp. 15-20; Rimmer, V., Preuveneers, D., Juarez, M., Van Goethem, T., Joosen, W., (2017) Automated Website Fingerprinting through Deep Learning; Cai, X., Zhang, X.C., Joshi, B., Johnson, R., Touching from a distance: Website fingerprinting attacks and defenses (2012) Proceedings of the 2012 ACM Conference on Computer and Communications Security, pp. 605-616; Juarez, M., Imani, M., Perry, M., Diaz, C., Wright, M., Toward an efficient website fingerprinting defense (2016) European Symposium on Research in Computer Security, pp. 27-46. , Springer; Wang, T., Goldberg, I., Walkie-talkie: An efficient defense against passive website fingerprinting attacks (2017) 26th USENIX Security Symposium (USENIX Security 17), pp. 1375-1390; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 Ieee Symposium on Security and Privacy (Sp). IEEE, pp. 39-57; Brendel, W., Rauber, J., Bethge, M., (2017) Decision-based Adversarial Attacks: Reliable Attacks against Black-box Machine Learning Models; Usama, M., Qayyum, A., Qadir, J., Al-Fuqaha, A., Black-box adversarial machine learning attack on network traffic classification (2019) 2019 15th International Wireless Communications Mobile Computing Conference (IWCMC), pp. 84-89; Imani, M., Rahman, M.S., Wright, M., Adversarial traces for website fingerprinting defense (2018) Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, pp. 2225-2227; Li, J., Zhou, L., Li, H., Yan, L., Zhu, H., Dynamic traffic feature camouflaging via generative adversarial networks (2019) 2019 IEEE Conference on Communications and Network Security (CNS). IEEE, pp. 268-276; Gong, Y., Li, B., Poellabauer, C., Shi, Y., (2019) Real-time Adversarial Attacks; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9 (8), pp. 1735-1780; Bahdanau, D., Cho, K., Bengio, Y., (2014) Neural Machine Translation by Jointly Learning to Align and Translate; Rauber, J., Brendel, W., Bethge, M., Foolbox: A python toolbox to benchmark the robustness of machine learning models (2017) Reliable Machine Learning in the Wild Workshop, 34th International Conference on Machine Learning, , http://arxiv.org/abs/1707.04131","Shi, J.; Institute of Information Engineering, China; 电子邮件: shijunzheng@iie.ac.cn",,6G Office;Chunghwa Telecom;et al.;Foxconn;Huawei;Mediatek,Institute of Electrical and Electronics Engineers Inc.,"2020 IEEE Global Communications Conference, GLOBECOM 2020",7 December 2020 through 11 December 2020,,166751,,9.78E+12,,,English,"IEEE Glob. Commun. Conf., GLOBECOM - Proc.",Conference Paper,Final,,Scopus,2-s2.0-85100372639
"Xue Y., Xie M., Roshan U.",57209342667;57209337138;7801662730;,On the transferability of adversarial examples between convex and 01 loss models,2020,"Proceedings - 19th IEEE International Conference on Machine Learning and Applications, ICMLA 2020",,,9356306,1460,1467,,3,10.1109/ICMLA51294.2020.00226,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100338018&doi=10.1109%2fICMLA51294.2020.00226&partnerID=40&md5=ce4d414436f9a9b145f8265aa02daa45,"New Jersey Institute of Technology, Department of Computer Science, Newark, United States","Xue, Y., New Jersey Institute of Technology, Department of Computer Science, Newark, United States; Xie, M., New Jersey Institute of Technology, Department of Computer Science, Newark, United States; Roshan, U., New Jersey Institute of Technology, Department of Computer Science, Newark, United States","The 01 loss gives different and more accurate boundaries than convex loss models in the presence of outliers. Could the difference of boundaries translate to adversarial examples that are non-transferable between 01 loss and convex models? We explore this empirically in this paper by studying transferability of adversarial examples between linear 01 loss and convex (hinge) loss models, and between dual layer neural networks with sign activation and 01 loss vs sigmoid activation and logistic loss. We first show that white box adversarial examples do not transfer effectively between convex and 01 loss and between 01 loss models compared to between convex models. As a result of this non-transferability we see that convex substitute model black box attacks are less effective on 01 loss than convex models. Interestingly we also see that 01 loss substitute model attacks are ineffective on both convex and 01 loss models mostly likely due to the non-uniqueness of 01 loss models. We show intuitively by example how the presence of outliers can cause different decision boundaries between 01 and convex loss models which in turn produces adversaries that are non-transferable. Indeed we see on MNIST that adversaries transfer between 01 loss and convex models more easily than on CIFAR10 and ImageNet which are likely to contain outliers. We show intuitively by example how the non-continuity of 01 loss makes adversaries non-transferable in a dual layer neural network. We discretize CIFAR10 features to be more like MNIST and find that it does not improve transferability, thus suggesting that different boundaries due to outliers are more likely the cause of non-transferability. As a result of this non-transferability we show that our dual layer sign activation network with 01 loss can attain robustness on par with simple convolutional networks. © 2020 IEEE.",01 loss; adversarial attacks; convolutional neural networks; deep learning; stochastic coordinate descent; transferability of adversarial examples,Chemical activation; Convolutional neural networks; Machine learning; Network layers; Statistics; Black boxes; Convex models; Convolutional networks; Decision boundary; Dual layer; Loss model; Non-transferability; Nonuniqueness; Multilayer neural networks,,,,,"Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2016) 2016 Ieee European Symposium on Security and Privacy (EuroS&P), pp. 372-387; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Machine Learning at Scale; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 Ieee Symposium on Security and Privacy (Sp), pp. 39-57; Brendel, W., Rauber, J., Bethge, M., (2017) Decision-based Adversarial Attacks: Reliable Attacks against Black-box Machine Learning Models; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks; Raghunathan, A., Michael Xie, S., Yang, F., Duchi, J.C., Liang, P., (2019) Adversarial Training Can Hurt Generalization; Zhang, H., Yu, Y., Jiao, J., Xing, E.P., El Ghaoui, L., Jordan, M.I., (2019) Theoretically Principled Trade-off between Robustness and Accuracy; Athalye, A., Carlini, N., Wagner, D., (2018) Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples; Ghiasi, A., Shafahi, A., Goldstein, T., (2020) Breaking Certified Defenses: Semantic Adversarial Examples with Spoofed Robustness Certificates; Xie, M., Xue, Y., Roshan, U., Stochastic coordinate descent for 0/1 loss and its sensitivity to adversarial attacks (2019) Proceedings of 18th Ieee International Conference on Machine Learning and Applications-ICMLA 2019, , page to appear; Nguyen, T., Sanner, S., Algorithms for direct 0-1 loss optimization in binary classification (2013) Proceedings of the 30th International Conference on Machine Learning, pp. 1085-1093; Bartlett, P.L., Jordan, M.I., McAuliffe, J.D., Large margin classifiers: Convex loss, low noise, and convergence rates. In s. Thrun, l.k. Saul, and b. Schölkopf, editors (2004) Advances in Neural Information Processing Systems, 16, pp. 1173-1180. , MIT Press; Ben-David, S., Eiron, N., Long, P.M., On the difficulty of approximately maximizing agreements (2003) Journal of Computer and System Sciences, 66 (3), pp. 496-514; Zhai, S., Xia, T., Tan, M., Wang, S., Direct 0-1 loss minimization and margin maximization with boosting. In c.j.c. Burges, l. Bottou, m. Welling, z. Ghahramani, and k.q. Weinberger, editors (2013) Advances in Neural Information Processing Systems, 26, pp. 872-880. , Curran Associates, Inc; Tang, Y., Li, X., Xu, Y., Liu, S., Ouyang, S., A mixed integer programming approach to maximum margin 0-1 loss classification (2014) 2014 International Radar Conference, pp. 1-6; Shalev-Shwartz, S., Shamir, O., Sridharan, K., (2011) Learning Linear and Kernel Predictors with the 0-1 Loss Function; Li, L., Lin, H., Optimizing 0/1 loss for perceptrons by random coordinate descent (2007) Neural Networks, 2007. Ijcnn 2007. International Joint Conference on, pp. 749-754; Courbariaux, M., Hubara, I., Soudry, D., El-Yaniv, R., Bengio, Y., (2016) Binarized Neural Networks: Training Deep Neural Networks with Weights and Activations Constrained To+ 1 or-1; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proceedings of the Ieee, 86 (11), pp. 2278-2324; Krizhevsky, A., (2009) Learning Multiple Layers of Features from Tiny Images; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Fei-Fei, L., Imagenet large scale visual recognition challenge (2015) International Journal of Computer Vision (IJCV), 115 (3), pp. 211-252; Shai, S., Shamir, O., Sridharan, K., Learning linear and kernel predictors with the 0-1 loss function (2011) Ijcai Proceedings-International Joint Conference on Artificial Intelligence, 22 (3); Alpaydin, E., (2004) Machine Learning, , MIT Press; Manwani, N., Sastry, P.S., Noise tolerance under risk minimization (2013) Ieee Transactions on Cybernetics, 43 (3), pp. 1146-1151; Ghosh, A., Manwani, N., Sastry, P.S., Making risk minimization tolerant to label noise (2015) Neurocomputing, 160, pp. 93-107; Lyu, Y., Tsang, I.W., (2019) Curriculum Loss: Robust Learning and Generalization against Label Corruption; Bottou, L., Large-scale machine learning with stochastic gradient descent (2010) Proceedings of COMPSTAT'2010, pp. 177-186. , Springer; Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Chintala, S., Pytorch: An imperative style, high-performance deep learning library (2019) Advances in Neural Information Processing Systems, 32, pp. 8024-8035. , In h. Wallach, h. Larochelle, a. Beygelzimer, f. Da lche buc, e. Fox, and r. Garnett, editors Curran Associates, Inc; Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Duchesnay, E., Scikit-learn: Machine learning in python (2011) Journal of Machine Learning Research, 12, pp. 2825-2830; Tsipras, D., Santurkar, S., Engstrom, L., Turner, A., Madry, A., (2018) Robustness May Be at Odds with Accuracy; Weiguang Ding, G., Yik Chau Lui Xiaomeng Jin, K., Wang, L., Huang, R., On the sensitivity of adversarial robustness to input data distributions (2019) Proceedings of the Ieee Conference on Computer Vision and Pattern Recognition Workshops, pp. 13-16; Panda, P., Chakraborty, I., Roy, K., Discretization based solutions for secure machine learning against adversarial attacks (2019) Ieee Access, 7, pp. 70157-70168; Galloway, A., Taylor, G.W., Moussa, M., (2017) Attacking Binarized Neural Networks; Chen, J., Jordan, M.I., Wainwright, M.J., (2019) Hopskipjumpattack: A Query-efficient Decision-based Attack, (3)",,Wani M.A.Luo F.Li X.Dou D.Bonchi F.,,Institute of Electrical and Electronics Engineers Inc.,"19th IEEE International Conference on Machine Learning and Applications, ICMLA 2020",14 December 2020 through 17 December 2020,,167387,,9.78E+12,,,English,"Proc. - IEEE Int. Conf. Mach. Learn. Appl., ICMLA",Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85100338018
"Arnab A., Miksik O., Torr P.H.S.",57113566800;55064235900;56821543600;,On the robustness of semantic segmentation models to adversarial attacks,2020,IEEE Transactions on Pattern Analysis and Machine Intelligence,42,12,8725541,3040,3053,,4,10.1109/TPAMI.2019.2919707,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095668120&doi=10.1109%2fTPAMI.2019.2919707&partnerID=40&md5=aeca1fe701fe642c3a319dfe099f6e75,"University of Oxford, Oxford, OX1 2JD, United Kingdom","Arnab, A., University of Oxford, Oxford, OX1 2JD, United Kingdom; Miksik, O., University of Oxford, Oxford, OX1 2JD, United Kingdom; Torr, P.H.S., University of Oxford, Oxford, OX1 2JD, United Kingdom","Deep Neural Networks (DNNs) have demonstrated exceptional performance on most recognition tasks such as image classification and segmentation. However, they have also been shown to be vulnerable to adversarial examples. This phenomenon has recently attracted a lot of attention but it has not been extensively studied on multiple, large-scale datasets and structured prediction tasks such as semantic segmentation which often require more specialised networks with additional components such as CRFs, dilated convolutions, skip-connections and multiscale processing. In this paper, we present what to our knowledge is the first rigorous evaluation of adversarial attacks on modern semantic segmentation models, using two large-scale datasets.We analyse the effect of different network architectures, model capacity and multiscale processing, and show that many observations made on the task of classification do not always transfer to this more complex task. Furthermore, we show how mean-field inference in deep structured models, multiscale processing (and more generally, input transformations) naturally implement recently proposed adversarial defenses. Our observations will aid future efforts in understanding and defending against adversarial examples. Moreover, in the shorter term, we show how to effectively benchmark robustness and show which segmentation models should currently be preferred in safety-critical applications due to their inherent robustness. © 2020 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.",Adversarial attacks; Convolutional neural networks; Deep learning; Machine learning security; Semantic segmentation,Benchmarking; Classification (of information); Deep neural networks; Large dataset; Network architecture; Safety engineering; Semantics; Input transformation; Large-scale datasets; Multiscale processing; Rigorous evaluation; Safety critical applications; Segmentation models; Semantic segmentation; Structured prediction; Image segmentation; article; human; human experiment,,,,,"Arnab, A., Jayasumana, S., Zheng, S., Torr, P.H.S., Higher order conditional random fields in deep neural networks (2016) Proc. Eur. Conf. Comput. Vis, pp. 524-540; Arnab, A., Miksik, O., Torr, P.H., On the robustness of semantic segmentation models to adversarial attacks (2018) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 888-897; Arnab, A., Zheng, S., Jayasumana, S., Romera-Paredes, B., Larsson, M., Kirillov, A., Savchynskyy, B., Torr, P.H.S., Conditional randomfieldsmeet deep neural networks for semantic segmentation: Combining probabilistic graphical models with deep learning for structured prediction (2018) IEEE Signal Process. Mag, 35 (1), pp. 37-52. , Jan; Athalye, A., Carlini, N., (2018) On the Robustness of the Cvpr 2018 White-box Adversarial Example Defenses, , arXiv:1804.03286; Athalye, A., Carlini, N., Wagner, D., Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples (2018) Proc. Int. Conf. Mach. Learn, pp. 274-283; Athalye, A., Sutskever, I., Synthesizing robust adversarial examples (2018) Proc. Int. Conf. Mach. Learn, pp. 284-293; Badrinarayanan, V., Kendall, A., Cipolla, R., Seg Net: A deep convolutional encoder-decoder architecture for image segmentation (2017) IEEE Trans. Pattern Anal. Mach. Intell, 39 (12), pp. 2481-2495; Barrow, H.G., Tenenbaum, J., Interpreting line drawings as three-dimensional surfaces (1981) Artif. Intell, 17, pp. 75-116; Bengio, Y., Leonard, N., Courville, A., (2013) Estimating or Propagating Gradients through Stochastic Neurons for Conditional Computation, , arXiv:1308.3432; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Srndific, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Proc. Joint Eur. Conf. Mach. Learn. Knowl. Discovery Databases, pp. 387-402; Biggio, B., Nelson, B., Laskov, P., Poisoning attacks against support vector machines (2012) Proc. Int. Conf. Mach. Learn, pp. 1467-1474; Brown, T.B., Mane, D., Roy, A., Abadi, M., Gilmer, J., Adversarial patch (2017) Proc. Conf. Neural Inf. Process. Syst., pp. 1-5; Buckman, J., Roy, A., Raffel, C., Goodfellow, I., Thermometer encoding: One hot way to resist adversarial examples (2018) Proc. Int. Conf. Learn. Representations; Bunel, R., Turkaslan, I., Torr, P.H., Kohli, P., Kumar, M.P., Piecewise linear neural network verification: A comparative study (2018) Proc. Conf. Neural Inf. Process. Syst, pp. 4790-4799; Carbonetto, P., Freitas, N.D., Conditional mean field (2007) Proc. Int. Conf. Neural Inf. Process. Syst, pp. 201-208; Carlini, N., Wagner, D., (2016) Defensive Distillation Is Not Robust to Adversarial Examples, , arXiv:1607.04311v1; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) Proc. 10th Acm Workshop Artif. Intell. Secur, pp. 3-14; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Proc. IEEE Symp. Secur. Privacy, pp. 39-57; Chalupka, K., Perona, P., Eberhardt, F., Visual causal feature learning (2015) Proc. Conf. Uncertainty Artif. Intell., pp. 181-190; Chandra, S., Kokkinos, I., Fast, exact and multi-scale inference for semantic image segmentation with deep Gaussian CRFs (2016) Proc. Eur. Conf. Comput. Vis, pp. 402-418; Chen, L.-C., Papandreou, G., Kokkinos, I., Murphy, K., Yuille, A.L., Semantic image segmentation with deep convolutional nets and fully connected CRFs (2015) Proc. Int. Conf. Learn. Representations; Chen, L.-C., Papandreou, G., Kokkinos, I., Murphy, K., Yuille, A.L., Deep Lab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected CRFs (2017) IEEE Trans. Pattern Anal.Mach. Intell, 40 (4), pp. 834-848; Cisse, M., Adi, Y., Neverova, N., Keshet, J., Houdini: Fooling deep structured prediction models (2017) Proc. Int. Conf. Neural Inf. Process. Syst., pp. 6977-6987; Cisse, M., Bojanowski, P., Grave, E., Dauphin, Y., Usunier, N., Parseval networks: Improving robustness to adversarial examples (2017) Proc. Int. Conf. Mach. Learn, pp. 854-863; Cordts, M., Omran, M., Ramos, S., Rehfeld, T., Enzweiler, M., Benenson, R., Franke, U., Schiele, B., The cityscapes dataset for semantic urban scene understanding (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 3213-3223; Cubuk, E.D., Zoph, B., Schoenholz, S.S., Le, Q.V., Intriguing properties of adversarial examples (2018) Proc. Int. Conf. Learn. Representations; Dai, J., He, K., Sun, J., Box Sup: Exploiting bounding boxes to supervise convolutional networks for semantic segmentation (2015) Proc. IEEE Int. Conf. Comput. Vis, pp. 1635-1643; Dalvi, N., Domingos, P., Sanghai, S., Verma, D., Adversarial classification (2004) Proc. 10th Acm Sigkdd Int. Conf. Knowl. Discovery Data Mining, pp. 99-108; Dziugaite, G.K., Ghahramani, Z., Roy, D.M., (2016) A Study of the Effect of Jpg Compression on Adversarial Images, , arXiv:1608.00853v1; Esteva, A., Kuprel, B., Novoa, R.A., Ko, J., Swetter, S.M., Blau, H.M., Thrun, S., Dermatologist-level classification of skin cancer with deep neural networks (2017) Nature, 542, pp. 115-118; Everingham, M., Van Gool, L., Williams, C.K., Winn, J., Zisserman, A., The pascal visual object classes (VOC) challenge (2010) Int. J. Comput. Vis, 88, pp. 303-338; Evtimov, I., Eykholt, K., Fernandes, E., Kohno, T., Li, B., Prakash, A., Rahmati, A., Song, D., Robust physical-world attacks on machine learning models (2018) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 1625-1634; Fawzi, A., Frossard, P., Manitest: Are classifiers really invariant? (2015) Proc. Brit. Mach. Vis. Conf, pp. 1061-10613; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts, , arXiv:1703.00410v2; Fischer, V., Kumar, M.C., Metzen, J.H., Brox, T., Adversarial examples for semantic image segmentation (2017) Proc. Int. Conf. Learn. Representations Workshop; Forsyth, D.A., Malik, J., Fleck, M.M., Greenspan, H., Leung, T., Belongie, S., Carson, C., Bregler, C., (1996) Finding Pictures of Objects in Large Collections of Images, , Berlin, Germany: Springer; Gao, J., Wang, B., Qi, Y., Deep mask: Masking DNN models for robustness against adversarial samples (2017) Proc. Int. Conf. Learn. Representations Workshop; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) Proc. Int. Conf. Learn. Representations; Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., (2017) On the (Statistical) Detection of Adversarial Examples, , arXiv:1702.06280v1; Gu, S., Rigazio, L., Towards deep neural network architectures robust to adversarial examples (2015) Proc. Int. Conf. Learn. Representations Workshop; Guo, C., Rana, M., Cisse, M., Van Der Maaten, L., Countering adversarial images using input transformations (2018) Proc. Int. Conf. Learn. Representations; Hariharan, B., Arbelaez, P., Bourdev, L., Maji, S., Malik, J., Semantic contours from inverse detectors (2011) Proc. IEEE Int. Conf. Comput. Vis., pp. 991-998; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 770-778; He, W., Wei, J., Chen, X., Carlini, N., Song, D., Adversarial example defenses: Ensembles of weak defenses are not strong (2017) Proc. 11th Usenix Workshop Offensive Technol, pp. 1-11; Henriques, J.F., Vedaldi, A., Warped convolutions: Efficient invariance to spatial transformations (2017) Proc. Int. Conf. Mach. Learn, pp. 1461-1469; Janai, J., Guney, F., Behl, A., Geiger, A., (2017) Computer Vision for Autonomous Vehicles: Problems, Datasets and State-of-the-art, , arXiv:1704.05519v1; Katz, G., Barrett, C., Dill, D.L., Julian, K., Kochenderfer, M.J., Reluplex: An efficient SMT solver for verifying deep neural networks (2017) Proc. Int. Conf. Comput. Aided Verification, pp. 97-117; Kerckhoffs, A., La cryptographie militaire (1883) J. des Sci. Militaires, 9, pp. 5-83; Koh, P.W., Liang, P., Understanding black-box predictions via influence functions (2017) Proc. Int. Conf. Mach. Learn, pp. 1885-1894; Krahenbuhl, P., Koltun, V., Efficient inference in fully connected CRFs with Gaussian edge potentials (2011) Proc. Int. Conf. Neural Inf. Process. Syst, pp. 109-117; Krizhevsky, A., Sutskever, I., Hinton, G.E., Image Net classification with deep convolutional neural networks (2012) Proc. Int. Conf. Neural Inf. Process. Syst, pp. 1097-1105; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2017) Proc. Int. Conf. Learn. Representations Workshop; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2017) Proc. Int. Conf. Learn. Representations; Liao, F., Liang, M., Dong, Y., Pang, T., Zhu, J., Hu, X., Defense against adversarial attacks using high-level representation guided denoiser (2018) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 1778-1787; Lin, G., Shen, C., Reid, I., Efficient piecewise training of deep structured models for semantic segmentation (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 3194-3203; Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Dollear, P., Zitnick, C.L., Microsoft COCO: Common objects in context (2014) Proc. Eur. Conf. Comput. Vis, pp. 740-755; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) Proc. Int. Conf. Learn. Representations; Long, J., Shelhamer, E., Darrell, T., Fully convolutional networks for semantic segmentation (2015) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 640-651; Lu, J., Sibai, H., Fabry, E., Forsyth, D., No need to worry about adversarial examples in object detection in autonomous vehicles (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. Workshop, pp. 1-9; Lu, J., Sibai, H., Fabry, E., Forsyth, D., (2017) Standard Detectors Aren't (Currently) Fooled by Physical Adversarial Stop Signs, , arXiv:1710.03337v1; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) Proc. Int. Conf. Learn. Representations; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., On detecting adversarial perturbations (2017) Proc. Int. Conf. Learn. Representations; Metzen, J.H., Kumar, M.C., Brox, T., Fischer, V., Universal adversarial perturbations against semantic image segmentation (2017) Proc. IEEE Int. Conf. Comput. Vis, pp. 2774-2783; Metzen, J.H., Kumar, M.C., Brox, T., Fischer, V., Universal adversarial perturbations against semantic image segmentation (2017) Proc. IEEE Int. Conf. Comput. Vis, pp. 2774-2783; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 86-94; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deep Fool: A simple and accurate method to fool deep neural networks (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 2574-2582; Murphy, K.P., (2012) Machine Learning: A Probabilistic Perspective, , Cambridge, MA, USA: MIT Press; Narodytska, N., Kasiviswanathan, S.P., Simple black-box adversarial perturbations for deep networks (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. Workshops, pp. 1310-1318; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples, , arXiv:1605.07277v1; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proc. ACMAsia Conf. Comput. Commun. Secur, pp. 506-519; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Proc. IEEE Eur. Symp. Secur. Privacy, pp. 372-387; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Proc. IEEE Symp. Secur. Privacy, pp. 582-597; Paszke, A., Chaurasia, A., Kim, S., Culurciello, E., (2016) E Net: A Deep Neural Network Architecture for Real-time Semantic Segmentation, , arXiv:1606.02147v1; Pepik, B., Benenson, R., Ritschel, T., Schiele, B., What is holding back convnets for detection? (2015) Proc. German Conf. Pattern Recognit, pp. 517-528; Prakash, A., Moran, N., Garber, S., DiLillo, A., Storer, J., Deflecting adversarial attacks with pixel deflection (2018) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 8571-8580; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proc. 23rd Acm Sigsac Conf. Comput. Commun. Secur, pp. 1528-1540; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) Proc. Int. Conf. Learn. Representations; Song, Y., Kim, T., Nowozin, S., Ermon, S., Kushman, N., Pixel Defend: Leveraging generative models to understand and defend against adversarial examples (2018) Proc. Int. Conf. Learn. Representations; Su, J., Vargas, D., Kouichi, S., One pixel attack for fooling deep neural networks (2019) IEEE Trans. Evol. Comput., , doi: 10.1109/TEVC.2019.2890858; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 2818-2826; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) Proc. Int. Conf. Learn. Representations; Tramer, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2018) Proc. Int. Conf. Learn. Representations; Uesato, J., O'Donoghue, B., Oord, A.V.D., Kohli, P., Adversarial risk and the dangers of evaluating against weak attacks (2018) Proc. Int. Conf. Mach. Learn, pp. 5025-5034; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., Mitigating adversarial effects through randomization (2018) Proc. Int. Conf. Learn. Representations; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., Adversarial examples for semantic segmentation and object detection (2017) Proc. IEEE Int. Conf. Comput. Vis, pp. 1378-1387; Xu, W., Evans, D., Qi, Y., Feature squeezing: Detecting adversarial examples in deep neural networks (2017) Proc. Conf. Neural Inf. Process. Syst, pp. 1-16; Xu, X., Chen, X., Liu, C., Rohrbach, A., Darell, T., Song, D., Fooling vision and language models despite localization and attention mechanism (2018) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 4951-4961; Yu, F., Koltun, V., Multi-scale context aggregation by dilated convolutions (2016) Proc. Int. Conf. Learn. Representations; Zhao, H., Qi, X., Shen, X., Shi, J., Jia, J., IC Net for real-time semantic segmentation on high-resolution images (2018) Proc. Eur. Conf. Comput. Vis, pp. 405-420; Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J., Pyramid scene parsing network (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 6230-6239; Zheng, S., Jayasumana, S., Romera-Paredes, B., Vineet, V., Su, Z., Du, D., Huang, C., Torr, P., Conditional random fields as recurrent neural networks (2015) Proc. IEEE Int. Conf. Comput. Vis, pp. 1529-1537","Arnab, A.; University of OxfordUnited Kingdom; 电子邮件: anurag.arnab@eng.ox.ac.uk",,,IEEE Computer Society,,,,,1628828,,ITPID,31150338,English,IEEE Trans Pattern Anal Mach Intell,Article,Final,"All Open Access, Green",Scopus,2-s2.0-85095668120
"Dong Z., Sun X., Dong J., Zhao H.",57219528050;56366080900;22634069200;57217257692;,Adversarial Metric Knowledge Distillation,2020,ACM International Conference Proceeding Series,,,,159,164,,,10.1145/3442555.3442581,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105740120&doi=10.1145%2f3442555.3442581&partnerID=40&md5=0c40d9454b492ac11465b707c2b50001,"Ocean University of China, China","Dong, Z., Ocean University of China, China; Sun, X., Ocean University of China, China; Dong, J., Ocean University of China, China; Zhao, H., Ocean University of China, China","Knowledge distillation is dedicated to improving the performance of light weight networks by transferring knowledge during the training process. Meanwhile, it is important to apply knowledge distillation on different situations. The previous knowledge distillation method with adversarial samples uses a traditional knowledge distillation loss to let the student learn a good decision boundary. In this paper, we propose a novel method named Adversarial Metric Knowledge Distillation (AMKD), which utilizes adversarial samples to transfer the dark knowledge from the teacher to student. We select adversarial samples which are close to the decision boundary of two classes to metric the distance with negative class samples employing triplet loss constraint. The method guarantees the student network learning relationships among samples by quantitative metric learning. Therefore, we not only transfer information of the decision boundary but also ensure the student network can always maintain a proper distance from other negative classes. This can be another good exploration for knowledge distillation with adversarial samples. The experiments on CIFAR-10, CIFAR-100 and Tiny ImageNet datasets verify that the proposed knowledge distillation method works effectively on improving the student network performance. © 2020 ACM.",Adversarial attack; Knowledge distillation; Metric learning; Triplet loss,Distillation; Image enhancement; Knowledge management; Students; Decision boundary; Distillation method; Light weight; Quantitative metric; Student network; Traditional knowledge; Training process; Transfer information; Distilleries,,,,,"Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Proceedings of the Advances in Neural Information Processing Systems; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition&quot;, , arXiv preprint; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Howard, A., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H., Mobilenets: Efficient convolutional neural networks for mobile vision applications (2017) Computer Vision and Pattern Recognition; Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., Chen, L., Mobilenetv2: Inverted residuals and linear bottlenecks (2018) Proceedings of the Computer Vision and Pattern Recognition; Howard, A., Sandler, M., Chu, G., Chen, L., Chen, B., Tan, M., Wang, W., Vasudevan, V.K., Searching for mobilenetv3 (2019) Computer Vision and Pattern Recognition; Zhang, X., Zhou, X., Lin, M., Sun, J., Shufflenet: An extremely efficient convolutional neural network for mobile devices (2018) Proceedings of the Computer Vision and Pattern Recognition; Ma, N., Zhang, X., Zheng, H.-T., Sun, J., Shufflenet v2: Practical guidelines for efficient cnn architecture design (2018) Proceedings of the Proceedings of the European Conference on Computer Vision (ECCV; Cheng, Y., Wang, D., Zhou, P., Zhang, T., (2017) A Survey of Model Compression and Acceleration for Deep Neural Networks, , arXiv preprint; Hinton, G., Vinyals, O., Dean, J., (2015) Distilling the Knowledge in a Neural Network, , arXiv preprint; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint; Cao, X., Gong, N.Z., Mitigating evasion attacks to deep neural networks via region-based classification (2017) Proceedings of the Annual Computer Security Applications Conference; Chopra, S., Hadsell, R., Lecun, Y., Learning a similarity metric discriminatively, with application to face verification (2005) Proceedings of the Computer Vision and Pattern Recognition; Schroff, F., Kalenichenko, D., Philbin, J., FaceNet: A unified embedding for face recognition and clustering (2015) Proceedings of the Computer Vision and Pattern Recognition; Heo, B., Lee, M., Yun, S., Choi, J.Y., Knowledge Distillation with Adversarial Samples Supporting Decision Boundary (2019) Proceedings of the National Conference on Artificial Intelligence; Moosavidezfooli, S., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the Computer Vision and Pattern Recognition; Muller, R., Kornblith, S., Hinton, G.E., (2019) When Does Label Smoothing Help, , arXiv: Learning; Krizhevsky, A., Hinton, G., Learning multiple layers of features from tiny images (2009) Handbook of Systemic Autoimmune Diseases, 1; Chrabaszcz, P., Loshchilov, I., Hutter, F., A downsampled variant of imagenet as an alternative to the cifar datasets (2017) Computer Vision and Pattern Recognition; Zagoruyko, S., Komodakis, N., (2016) Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks Via Attention Transfer, , arXiv preprint; Yim, J., Joo, D., Bae, J., Kim, J., A gift from knowledge distillation: Fast optimization, network minimization and transfer learning (2017) Proceedings of the Computer Vision and Pattern Recognition; Heo, B., Lee, M., Yun, S., Choi, J.Y., Knowledge transfer via distillation of activation boundaries formed by hidden neurons (2019) Proceedings of the National Conference on Artificial Intelligence; Heo, B., Kim, J., Yun, S., Park, H., Kwak, N., Choi, J.Y., A comprehensive overhaul of feature distillation (2019) Proceedings of the International Conference on Computer Vision; Zhang, L., Song, J., Gao, A., Chen, J., Bao, C., Ma, K., (2019) Be Your Own Teacher: Improve the Performance of Convolutional Neural Networks Via Self Distillation, , Learning; Chen, H., Wang, Y., Xu, C., Yang, Z., Liu, C., Shi, B., Xu, C., Tian, Q., Datafree learning of student networks (2019) Proceedings of the International Conference on Computer Vision; Tung, F., Mori, G., Similarity-preserving knowledge distillation (2019) Proceedings of the International Conference on Computer Vision; Peng, B., Jin, X., Li, D., Zhou, S., Wu, Y., Liu, J., Zhang, Z., Liu, Y., Correlation congruence for knowledge distillation (2019) Proceedings of the International Conference on Computer Vision; Hoffer, E., Ailon, N., (2014) Deep Metric Learning Using Triplet Network, , Learning; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2013) Computer Vision and Pattern Recognition; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2017) Machine Learning; Shi, Y., Wang, S., Han, Y., Curls &amp; Whey: Boosting black-box adversarial attacks (2019) Proceedings of the Computer Vision and Pattern Recognition; Mao, C., Zhong, Z., Yang, J., Vondrick, C., Ray, B., Metric learning for adversarial robustness (2019) Proceedings of the Neural Information Processing Systems; Balntas, V., Riba, E., Ponsa, D., Mikolajczyk, K., Learning local feature descriptors with triplets and shallow convolutional neural networks (2016) Proceedings of the British Machine Vision Conference",,,,Association for Computing Machinery,"6th International Conference on Communication and Information Processing, ICCIP 2020",27 November 2020 through 29 November 2020,,168697,,9.78E+12,,,English,ACM Int. Conf. Proc. Ser.,Conference Paper,Final,,Scopus,2-s2.0-85105740120
"Wu Y., Li Z., Van Nostrand N., Liu J.",57215315290;57215844154;57220745974;56380662800;,Security and privacy in the age of cordless power world: Poster abstract,2020,SenSys 2020 - Proceedings of the 2020 18th ACM Conference on Embedded Networked Sensor Systems,,,,717,718,,2,10.1145/3384419.3430416,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097566064&doi=10.1145%2f3384419.3430416&partnerID=40&md5=88886bdf22d2bc17e05fce79e60d531c,"University of Tennessee, Knoxville, TN, United States","Wu, Y., University of Tennessee, Knoxville, TN, United States; Li, Z., University of Tennessee, Knoxville, TN, United States; Van Nostrand, N., University of Tennessee, Knoxville, TN, United States; Liu, J., University of Tennessee, Knoxville, TN, United States","In this work, we conduct the first study to explore the potential security and privacy vulnerabilities of cordless power transfer techniques, particularly Qi wireless charging for mobile devices. We demonstrate the communication established between the charger and the charging device could be easily interfered with and eavesdropped. Specifically, through stealthily placing an adversarial coil on the wireless charger, an adversary can hijack the communication channel and inject malicious data bits which can take control of the charging process. Moreover, by simply taping two wires on the wireless charger, an adversary can eavesdrop Qi messages, which carry rich information highly correlated with the charging device's activities, from the measured primary coil voltage. We examine the extent to which this side-channel leaks private information about the smartphone's activities while being charged (e.g., detect and identify incoming calls and messages from different apps). Experimental results demonstrate the capability of an adversary to inject any desired malicious packets to take over the charging process, and the primary coil voltage side channel can leak private information of the smartphone's activities while being charged. © 2020 ACM.",man-in-the-middle attack; side-channel attack; wireless charging,Embedded systems; Energy transfer; Mobile security; Security systems; Smartphones; Wireless power transfer; Charging device; Charging process; Highly-correlated; Malicious packets; Power transfers; Private information; Security and privacy; Side-channel; Wireless charging,,,,,"(2020) EVALSTWBC-EP: Qi MP-A15 15W Wireless Charger TX Evaluation Kit Based on STWBC-EP, , https://www.st.com/content/st-com/en/products/evaluation-tools/solution-evaluation-tools/psu-and-convertersolution-eval-boards/evalstwbc-ep.html, ST Microelectronics, Accessed September, 2020; Van Wageningen, D., Staring, T., The Qi wireless power standard (2010) Proceedings of 14th International Power Electronics and Motion Control Conference EPE-PEMC 2010., , IEEE, S15-25",,,ACM SIGARCH;ACM SIGBED;ACM SIGCOMM;ACM SIGMETRICS;ACM SIGMOBILE;ACM SIGOPS,"Association for Computing Machinery, Inc","18th ACM Conference on Embedded Networked Sensor Systems, SenSys 2020",16 November 2020 through 19 November 2020,,165222,,9.78E+12,,,English,SenSys - Proc. ACM Conf. Embedded Networked Sens. Syst.,Conference Paper,Final,,Scopus,2-s2.0-85097566064
"Shi Z., Yao W., Li Z., Zeng L., Zhao Y., Zhang R., Tang Y., Wen J.",57214888115;57031158100;57218690492;57201877338;57221285561;57221190872;56359259500;7402701729;,"Artificial intelligence techniques for stability analysis and control in smart grids: Methodologies, applications, challenges and future directions",2020,Applied Energy,278,,115733,,,,24,10.1016/j.apenergy.2020.115733,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090030802&doi=10.1016%2fj.apenergy.2020.115733&partnerID=40&md5=f47c157912e541d57a4e4dcd18ad7722,"State Key Laboratory of Advanced Electromagnetic Engineering and Technology, School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, Wuhan, 430074, China; China Electric Power Research Institute, Beijing, 100192, China","Shi, Z., State Key Laboratory of Advanced Electromagnetic Engineering and Technology, School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, Wuhan, 430074, China; Yao, W., State Key Laboratory of Advanced Electromagnetic Engineering and Technology, School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, Wuhan, 430074, China; Li, Z., State Key Laboratory of Advanced Electromagnetic Engineering and Technology, School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, Wuhan, 430074, China; Zeng, L., State Key Laboratory of Advanced Electromagnetic Engineering and Technology, School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, Wuhan, 430074, China; Zhao, Y., State Key Laboratory of Advanced Electromagnetic Engineering and Technology, School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, Wuhan, 430074, China; Zhang, R., State Key Laboratory of Advanced Electromagnetic Engineering and Technology, School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, Wuhan, 430074, China; Tang, Y., China Electric Power Research Institute, Beijing, 100192, China; Wen, J., State Key Laboratory of Advanced Electromagnetic Engineering and Technology, School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, Wuhan, 430074, China","Smart grid is the new trend for clean, sustainable, efficient and reliable energy generation, delivery and use. To ensure stable and secure operation is essential for the smart grid, which needs effective stability analysis and control. As the smart grid has evolved through a growing scale of interconnection, increasing integration of renewable energy, widespread operation of direct current power transmission systems, and liberalization of electricity markets, the stability characteristics of it are much more complex than the past. Due to these changes, conventional stability analysis and control approaches have a series of drawbacks in terms of speed, effectiveness and economy. On the contrary, the emerging artificial intelligence (AI) techniques provide powerful and promising tools for stability analysis and control in smart grids and have attracted growing attention. This paper aims to give a comprehensive and clear picture of recent advances in this research area. First, we present a general overview of AI, including its definitions, history and state-of-the-art methodologies. And then, this paper gives a comprehensive review of its applications to security assessment, stability assessment, fault diagnosis, and stability control in smart grids. These applications have achieved impressive results. Nevertheless, we also identify some major challenges these applications face in practice: high requirements on data, imbalanced learning, interpretability of AI, difficulties in transfer learning, the robustness of AI to communication quality, and the robustness against attack or adversarial examples. Furthermore, we provide suggestions for potential important future investigation directions to overcome these challenges and bridge the gap between research and practice. © 2020 Elsevier Ltd",Artificial intelligence; Machine learning; Smart grid; Stability analysis; Stability control,Electric power transmission; Electric power transmission networks; Energy efficiency; Robustness (control systems); Smart power grids; Stability; Transfer learning; Artificial intelligence techniques; Communication quality; Direct current power; Imbalanced Learning; Integration of renewable energies; Security assessment; Stability analysis; Stability assessment; Electric power system stability; artificial intelligence; control system; methodology; smart grid; stability analysis,,,,,,,,,,,,,,,,,,,,,,,,
"nalysis and practical mitigation strategies. In: 70th Annu Conf Prot Relay Eng""","Yao, W.; State Key Laboratory of Advanced Electromagnetic Engineering and Technology, China; 电子邮件: w.yao@hust.edu.cn",,,Elsevier Ltd,,,,,3062619,,APEND,,English,Appl. Energy,Article,Final,,Scopus,2-s2.0-85090030802,,,,,,,,,,,,,,,,,,,,,,,
[无可用作者姓名],[无可用的作者 ID],"2020 IEEE International Conference on Communications, Control, and Computing Technologies for Smart Grids, SmartGridComm 2020",2020,"2020 IEEE International Conference on Communications, Control, and Computing Technologies for Smart Grids, SmartGridComm 2020",,,,,,597,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099483767&partnerID=40&md5=6caab59c38c7683e5f0bc9156e3931c5,,,The proceedings contain 93 papers. The topics discussed include: network-aware mitigation of undetectable PMU time synchronization attacks; communication and computation resource allocation and offloading for edge intelligence enabled fault detection system in smart grid; side channel security of smart meter data compression techniques; power system state estimation using gauss-newton unrolled neural networks with trainable priors; generative adversarial networks and transfer learning for non-intrusive load monitoring in smart grids; mitigating cascading failures via local responses; demand-side scheduling based on multi-agent deep actor-critic learning for smart grids; edge layer design and optimization for smart grids; and achieving sensor identification and data flow integrity in critical cyber-physical infrastructures.,,,,,,,,,,,Institute of Electrical and Electronics Engineers Inc.,"2020 IEEE International Conference on Communications, Control, and Computing Technologies for Smart Grids, SmartGridComm 2020",11 November 2020 through 13 November 2020,,166255,,9.78E+12,,,English,"IEEE Int. Conf. Commun., Control, Comput. Technol. Smart Grids, SmartGridComm",Conference Review,Final,,Scopus,2-s2.0-85099483767
"Khamaiseh S.Y., Alsmadi I., Al-Alaj A.",57193878341;17433667400;42261161800;,Deceiving Machine Learning-Based Saturation Attack Detection Systems in SDN,2020,"2020 IEEE Conference on Network Function Virtualization and Software Defined Networks, NFV-SDN 2020 - Proceedings",,,9289908,44,50,,6,10.1109/NFV-SDN50289.2020.9289908,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099265222&doi=10.1109%2fNFV-SDN50289.2020.9289908&partnerID=40&md5=a945337be6d8aa65ead0f4eabe51edc7,"Monmouth University, Dept. of Computer Science and Software Eng., West Long Branch, NJ, United States; Texas Am, Dept. of Computing and Cyber Security, San Antonio, TX, United States; Virginia Wesleyan University, Department of Computer Science, Norfolk/Virginia, Beach, VA, United States","Khamaiseh, S.Y., Monmouth University, Dept. of Computer Science and Software Eng., West Long Branch, NJ, United States; Alsmadi, I., Texas Am, Dept. of Computing and Cyber Security, San Antonio, TX, United States; Al-Alaj, A., Virginia Wesleyan University, Department of Computer Science, Norfolk/Virginia, Beach, VA, United States","Recently, different machine learning-based detection systems are proposed to detect DDoS saturation attacks in Software-defined Networking (SDN). Meanwhile, different research studies highlight the vulnerabilities of adapting such systems in SDN. For instance, an adversary can fool the machine learning classifiers of these systems by crafting specific adversarial attack samples, preventing the detection of DoS saturation attacks. To better understand the security properties of these classifiers in adversarial settings, this paper investigates the robustness of the supervised and unsupervised machine learning classifiers against adversarial attacks. First, we propose an adversarial testing tool that can generate adversarial attacks that avoid the detection of four saturation attacks (i.e., SYN, UDP, ICMP, and TCP-SARFU), by perturbing different traffic features. Second, we propose a machine learning-based saturation attack detection system that utilizes different supervised and unsupervised machine learning classifiers as a testing platform. The experimental results demonstrate that the generated adversarial attacks can reduce the detection performance of the proposed detection system dramatically. Specifically, the detection performance of the four saturation attacks was decreased by more than 90% across several machine learning classifiers. This indicates that the proposed adversarial testing tool can effectively compromise the machine learning-based saturation attack detection systems. © 2020 IEEE.",adversarial attacks; DoS saturation attacks; machine learning-based detection systems; software-defined networking,Machine learning; Software defined networking; Transfer functions; Turing machines; Detection performance; Research studies; Saturation attacks; Security properties; Software defined networking (SDN); Testing platforms; Traffic features; Unsupervised machine learning; Network function virtualization,,,,,"Swami, R., Dave, M., Ranga, V., Software-defined networking-based ddos defense mechanisms (2019) Acm Computing Surveys (CSUR), 52 (2), pp. 1-36; Khamaiseh, S., Serra, E., Xu, D., Vswitchguard: Defending openflow switches against saturation attacks (2020) Ieee Computer Society Signature Conference on Computers, Software and Applications (COMPSAC), , ieee; Li, Z., Xing, W., Khamaiseh, S., Xu, D., Detecting saturation attacks based on self-similarity of openflow traffic (2020) Ieee Transactions on Network and Service Management, 17 (1), pp. 607-621; Hu, D., Hong, P., Chen, Y., Fadm: Ddos flooding attack detection and mitigation system in software-defined networking (2017) Globecom 2017-2017 Ieee Global Communications Conference. Ieee; Sommer, R., Paxson, V., Outside the closed world: On using machine learning for network intrusion detection (2010) 2010 Ieee Symposium on Security and Privacy, pp. 305-316. , ieee; Nguyen, T.N., The challenges in ml-based security for sdn (2018) 2018 2nd Cyber Security in Networking Conference (CSNet), pp. 1-9; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) 2016 Ieee European Symposium on Security and Privacy (EuroS&P), pp. 372-387. , ieee; Abusnaina, A., Khormali, A., Nyang, D., Yuksel, M., Mohaisen, A., Examining the robustness of learning-based ddos detection in software defined networks (2019) 2019 Ieee Conference on Dependable and Secure Computing (DSC), pp. 1-8. , ieee; Aiken, J., Scott-Hayward, S., Investigating adversarial attacks against network intrusion detection systems in sdns (2019) 2019 Ieee Conference on Network Function Virtualization and Software Defined Networks (NFV-SDN), pp. 1-7. , ieee; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Machine Learning at Scale, , arXiv preprint; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the Ieee Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Papernot, N., Faghri, F., Carlini, N., Goodfellow, I.J., Feinman, R., Ku-Rakin, A., Xie, C., McDaniel, P., (2016) Technical Report on the Cleverhans V2.1.0 Adversarial Examples Library, , arXiv: Learning; Abaid, Z., Kaafar, M.A., Jha, S., Quantifying the impact of adversarial evasion attacks on machine learning based android malware classifiers (2017) 2017 Ieee 16th International Symposium on Network Computing and Applications (NCA), pp. 1-10. , ieee; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Srndić, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 387-402. , Springer; Sultana, N., Chilamkurti, N., Peng, W., Alhadad, R., Survey on sdn based network intrusion detection system using machine learning approaches (2019) Peer-to-Peer Networking and Applications, 12 (2), pp. 493-501; Khamaiseh, S., Serra, E., Li, Z., Xu, D., Detecting saturation attacks in sdn via machine learning (2019) 2019 4th International Conference on Computing, Communications and Security (ICCCS), , ieee; Wang, R., Jia, Z., Ju, L., An entropy-based distributed ddos detection mechanism in software-defined networking (2015) 2015 Ieee Trustcom/BigDataSE/ISPA, 1, pp. 310-317. , ieee",,Horner L.Tutschku K.de la Oliva A.Scott-Hayward S.Tacca M.Caltais G.Parzyjegla H.,Huawei;Intel,Institute of Electrical and Electronics Engineers Inc.,"2020 IEEE Conference on Network Function Virtualization and Software Defined Networks, NFV-SDN 2020",9 November 2020 through 12 November 2020,,166086,,9.78E+12,,,English,"IEEE Conf. Netw. Funct. Virtualiz. Softw. Defined Networks, NFV-SDN - Proc.",Conference Paper,Final,,Scopus,2-s2.0-85099265222
"Hashemi M.J., Keller E.",57204688692;55434382400;,Enhancing Robustness against Adversarial Examples in Network Intrusion Detection Systems,2020,"2020 IEEE Conference on Network Function Virtualization and Software Defined Networks, NFV-SDN 2020 - Proceedings",,,9289869,37,43,,7,10.1109/NFV-SDN50289.2020.9289869,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099223816&doi=10.1109%2fNFV-SDN50289.2020.9289869&partnerID=40&md5=0d6ec662aa1169dea4a043eccc485bd4,"University of Colorado Boulder, Department of Computer Science, Boulder, CO, United States; University of Colorado Boulder, Department of Electrical Computer and Energy Engineering, Boulder, CO, United States","Hashemi, M.J., University of Colorado Boulder, Department of Computer Science, Boulder, CO, United States; Keller, E., University of Colorado Boulder, Department of Electrical Computer and Energy Engineering, Boulder, CO, United States","The increase of cyber attacks in both the numbers and varieties in recent years demands to build a more sophisticated network intrusion detection system (NIDS). These NIDS perform better when they can monitor all the traffic traversing through the network like when being deployed on a Software-Defined Network (SDN). Because of the inability to detect zeroday attacks, signature-based NIDS which were traditionally used for detecting malicious traffic are beginning to get replaced by anomaly-based NIDS built on neural networks. However, recently it has been shown that such NIDS have their own drawback namely being vulnerable to the adversarial example attack. Moreover, they were mostly evaluated on the old datasets which don't represent the variety of attacks network systems might face these days. In this paper, we present Reconstruction from Partial Observation (RePO) as a new mechanism to build an NIDS with the help of denoising autoencoders capable of detecting different types of network attacks in a low false alert setting with an enhanced robustness against adversarial example attack. Our evaluation conducted on a dataset with a variety of network attacks shows denoising autoencoders can improve detection of malicious traffic by up to 29% in a normal setting and by up to 45% in an adversarial setting compared to other recently proposed anomaly detectors. © 2020 IEEE.",Adversarial Example; Anomaly Detection; Intrusion Detection Systems; Neural Networks,Computer crime; Intrusion detection; Learning systems; Network security; Rhenium compounds; Software defined networking; Transfer functions; Anomaly detector; Anomaly-based NIDS; Malicious traffic; Network intrusion detection systems; Network systems; New mechanisms; Partial observation; Zero day attack; Network function virtualization,,,,,"(2019) Internet Security Threat Report, , https://www.symantec.com/security-center/threat-report, Symantec; (2016) Cyber-Attack against Ukrainian Critical Infrastructure, , www.ics-cert.us-cert.gov/alerts/IR-ALERT-H-16-056-01, ics-cert; Kumar, R.S.S., Wicker, A., Swann, M., Practical machine learning for cloud intrusion detection: Challenges and the way forward (2017) Proceedings of the 10th Acm Workshop on Artificial Intelligence and Security, Ser. AISec '17, pp. 81-90. , New York, ny, usa: acm; Ahmad, I., Namal, S., Ylianttila, M., Gurtov, A., Security in software defined networks: A survey (2015) Ieee Communications Surveys Tutorials, 17 (4), pp. 2317-2346; Lee, S., Kim, J., Shin, S., Porras, P., Yegneswaran, V., Athena: A framework for scalable anomaly detection in software-defined networks (2017) 2017 47th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN), pp. 249-260; Khraisat, A., Gondal, I., Vamplew, P., Kamruzzaman, J.A., Survey of intrusion detection systems: Techniques, datasets and challenges (2019) Cybersecurity, 2; Al-Qatf, M., Lasheng, Y., Al-Habib, M., Al-Sabahi, K., Deep learning approach combining sparse autoencoder with svm for network intrusion detection (2018) Ieee Access, 6, pp. 52843-52856; Yu, Y., Long, J., Cai, Z., Network intrusion detection through stacking dilated convolutional autoencoders (2017) Security and Communication Networks, 2017; Yin, C., Zhu, Y., Liu, S., Fei, J., Zhang, H., An enhancing framework for botnet detection using generative adversarial networks (2018) 2018 International Conference on Artificial Intelligence and Big Data (ICAIBD), pp. 228-234. , May; Malaiya, R.K., Kwon, D., Kim, J., Suh, S.C., Kim, H., Kim, I., An empirical evaluation of deep learning for network anomaly detection (2018) 2018 International Conference on Computing, Networking and Communications (ICNC), pp. 893-898. , March; Mirsky, Y., Doitshman, T., Elovici, Y., Shabtai, A., Kitsune: An ensemble of autoencoders for online network intrusion detection (2018) Network and Distributed System Security Symposium 2018 (NDSS'18); Zong, B., Song, Q., Min, M.R., Cheng, W., Lumezanu, C., Cho, D., Chen, H., Deep autoencoding gaussian mixture model for unsupervised anomaly detection (2018) International Conference on Learning Representations; Zenati, H., Foo, C.S., Lecouat, B., Manek, G., Chandrasekhar, V.R., Efficient gan-based anomaly detection (2018) CoRR, , http://arxiv.org/abs/1802.06222, vol. abs/1802.06222, [Online]; Chalapathy, R., Chawla, S., Deep learning for anomaly detection: A survey (2019) CoRR, , vol. abs/1901.03407; Hashemi, M.J., Cusack, G., Keller, E., Towards evaluation of nidss in adversarial setting (2019) Proceedings of the 3rd Acm CoNEXT Workshop on Big DAta, Machine Learning and Artificial Intelligence for Data Communication Networks, Ser. Big-DAMA '19, pp. 14-21; Aiken, J., Scott-Hayward, S., Investigating adversarial attacks against network intrusion detection systems in sdns (2019) 2019 Ieee Conference on Network Function Virtualization and Software Defined Networks (NFV-SDN), pp. 1-7; Vincent, P., Larochelle, H., Bengio, Y., Manzagol, P.-A., Extracting and composing robust features with denoising autoencoders (2008) Proceedings of the 25th International Conference on Machine Learning, Ser. Icml '08, pp. 1096-1103; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Srndic, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) ECML/PKDD; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint; Carlini, N., Wagner, D., Audio adversarial examples: Targeted attacks on speech-to-text (2018) Deep Learning and Security Workshop; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-Art face recognition (2016) Proceedings of the 2016 Acm Sigsac Conference on Computer and Communications Security, Ser. Ccs '16, pp. 1528-1540; Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Xiao, C., Prakash, A., Song, D., Robust physical-world attacks on deep learning visual classification (2018) Computer Vision and Pattern Recognition; Grosse, K., Papernot, N., Manoharan, P., Backes, M., McDaniel, P., Adversarial examples for malware detection (2017) Computer Security-ESORICS 2017-22nd European Symposium on Research in Computer Security, Proceedings, Germany, 1, pp. 62-79; Sharafaldin, I., Lashkari, A.H., Ghorbani, A.A., Toward generating a new intrusion detection dataset and intrusion traffic characterization (2018) 4th International Conference on Information Systems Security and Privacy (ICISSP); Axelsson, S., The base-rate fallacy and the difficulty of intrusion detection (2000) Acm Trans. Inf. Syst. Secur., 3 (3), pp. 186-205. , http://doi.acm.org/10.1145/357830.357849, Aug, [Online]",,Horner L.Tutschku K.de la Oliva A.Scott-Hayward S.Tacca M.Caltais G.Parzyjegla H.,Huawei;Intel,Institute of Electrical and Electronics Engineers Inc.,"2020 IEEE Conference on Network Function Virtualization and Software Defined Networks, NFV-SDN 2020",9 November 2020 through 12 November 2020,,166086,,9.78E+12,,,English,"IEEE Conf. Netw. Funct. Virtualiz. Softw. Defined Networks, NFV-SDN - Proc.",Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85099223816
"Dong Z., Tang L., Tian C.",57197749445;57221910226;36795489500;,Distilling Knowledge in Adversarial Attack,2020,"Proceedings - 2020 7th International Conference on Dependable Systems and Their Applications, DSA 2020",,,9331245,226,233,,,10.1109/DSA51864.2020.00040,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100557708&doi=10.1109%2fDSA51864.2020.00040&partnerID=40&md5=d759df50c8ecfc50e38c61fced7446e0,"Xidian University, Ictt and Isn Laboratory, Xi'an, China","Dong, Z., Xidian University, Ictt and Isn Laboratory, Xi'an, China; Tang, L., Xidian University, Ictt and Isn Laboratory, Xi'an, China; Tian, C., Xidian University, Ictt and Isn Laboratory, Xi'an, China","Neural networks show great vulnerability under the threat of adversarial examples. By adding small perturbation to a clean image, neural networks with high classification accuracy can be completely fooled. Transferability which allows adversarial examples to transfer to networks of unknown structures, makes adversarial examples even more harmful. In this paper, we reveal that transferability of adversarial examples is closely related to inter-category information. With that in mind, we propose a simple technique to improve the transferability of adversarial examples. This method makes use of the ideology called knowledge distillation to obtain more information from known structure and datasets. It can be integrated into any gradient methods to generate adversarial examples. We carry out experiments on single, multiple and serialized multiple model scenarios. The results show that knowledge distillation is effective in extracting adversarial information for enhancing transferability. © 2020 IEEE.",Adversarial Attack; Knowledge Distillation,Distillation; Distilleries; Gradient methods; Classification accuracy; Clean images; Multiple-modeling; Small perturbations; Neural networks,,,,,"Carlini, N., Wagner, D.A., Towards evaluating the robustness of neural networks (2017) 2017 Ieee Symposium on Security and Privacy, Sp 2017, pp. 39-57. , https://doi.org/10.1109/SP.2017.49, San Jose, CA, USA, May 22-26, 2017. IEEE Computer Society [Online]; Papernot, N., McDaniel, P.D., Goodfellow, I.J., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against deep learning systems using adversarial examples (2016) CoRR, , http://arxiv.org/abs/1602.02697, vol. abs/1602.02697 [Online]; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) 5th International Conference on Learning Representations, Iclr 2017, , https://openreview.net/forum?id=Sys6GJqxl, Toulon, France, April 24-26, 2017, Conference Track Proceedings. OpenReview.net [Online]; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems 25:26th Annual Conference on Neural Information Processing Systems 2012., pp. 1106-1114. , http://papers.nips.cc/paper/4824-imagenetclassification-with-deep-convolutional-neural-networks, Proceedings of a meeting held December 3-6, 2012, Lake Tahoe, Nevada, United States, P. L. Bartlett, F. C. N. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger, Eds. [Online]; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R., Intriguing properties of neural networks (2014) 2nd International Conference on Learning Representations, Iclr 2014, , http://arxiv.org/abs/1312.6199, Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings, Y. Bengio and Y.' LeCun, Eds., [Online]; Hinton, G.E., Vinyals, O., Dean, J., Distilling the knowledge in a neural network (2015) CoRR, , http://arxiv.org/abs/1503.02531, vol. abs/1503.02531, [Online]; Dietterich, T.G., Ensemble methods in machine learning (2000) Multiple Classifier Systems, First International Workshop, Mcs 2000, pp. 1-15. , https://doi.org/10.1007/3-540-45014-91, Cagliari, Italy, June21-23, 2000, Proceedings, ser. Lecture Notes in Computer Science, J. Kittler and F. Roli, Eds., vol. 1857. Springer [Online]; Lin, J., Song, C., He, K., Wang, L., Hopcroft, J.E., Nesterov accelerated gradient and scale invariance for adversarial attacks (2020) 8th International Conference on Learning Representations, Iclr 2020, , https://openreview.net/forum?id=SJlHwkBYDH, Addis Ababa, Ethiopia April 26-30 OpenReview.net 2020. [Online]; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Fei-Fei, L., Imagenet Lsvrc 2012 Validationset (Object Detection); Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) 2016 Ieee Conference on Computer Vision and Pattern Recognition, Cvpr 2016, pp. 2818-2826. , https://doi.org/10.1109/CVPR.2016.308, Las Vegas, NV, USA, June 27-30, 2016. IEEE Computer Society [Online]; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., Inception-v4, inception-resnet and the impact of residual connections on learning (2017) Proceedings of the Thirty-First Aaai Conference on Artificial Intelligence, pp. 4278-4284. , http://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14806, February 4-9 San Francisco, California, USA, S. P. Singh and S. Markovitch, Eds. AAAI Press 2017 [Online]; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) 3rd International Conference on Learning Representations, Iclr 2015, , http://arxiv.org/abs/1409.1556, San Diego, CA, USA, May 79 Conference Track Proceedings, Y. BengioandY. LeCun, Eds. 2015. [Online]; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) 2016 Ieee Conference on Computer Vision and Pattern Recognition, Cvpr 2016, pp. 770-778. , https://doi.org/10.1109/CVPR.2016.90, Las Vegas, NV, USA, June 27-30, 2016. IEEE Computer Society [Online]; Tramer, F., Kurakin, A., Papernot, N., Goodfellow, I.J., Boneh, D., McDaniel, P.D., Ensemble adversarial training: Attacks and defenses (2018) 6th International Conference on Learning Representations, Iclr 2018, , https://openreview.net/forum?id=rkZvSe-RZ, Vancouver, BC, Canada, April 30-May 3, 2018, Conference Track Proceedings. OpenReview.net [Online]; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2018) 2018 Ieee Conference on Computer Vision and Pattern Recognition, Cvpr 2018, p. 91859193. , http://openaccess.thecvf.com/contentcvpr2018/html/DongBoostingAdversarialAttacksCVPR2018paper.html, Salt Lake City, UT, USA, June 18-22, 2018. IEEE Computer Society [Online]; Milton, M.A.A., Evaluation of momentum diverse input iterative fast gradient sign method (M-DI2-FGSM) based attack method on MCS 2018 adversarial attacks on black box face recognition system (2018) CoRR, , http://arxiv.org/abs/1806.08970, vol. abs/ 1806. 08970 [Online]; Dong, Y., Pang, T., Su, H., Zhu, J., Evading defenses to transferable adversarial examples by translation-invariant attacks (2019) Ieee Conference on Computer Vision and Pattern Recognition, Cvpr 2019, pp. 4312-4321. , http://openaccess.thecvf.com/contentCVPR2019/html/DongEvadingDefensestoTransferableAdversarialExamplesbyTranslation-InvariantAttacksCVPR2019paper.html, Long Beach, CA, USA, June 16-20, 2019. Computer Vision Foundation / IEEE [Online]","Tian, C.; Xidian University, China; 电子邮件: ctian@xidian.edu.cn",,,Institute of Electrical and Electronics Engineers Inc.,"7th International Conference on Dependable Systems and Their Applications, DSA 2020",28 November 2020 through 29 November 2020,,166757,,9.78E+12,,,English,"Proc. - Int. Conf. Dependable Syst. Their Appl., DSA",Conference Paper,Final,,Scopus,2-s2.0-85100557708
"Thakur S., Breslin J.G.",25825693800;7004753954;,An Edge Colouring-based Collaborative Routing Protocol for Blockchain Offline Channels,2020,"Proceedings - 2020 IEEE International Conference on Blockchain, Blockchain 2020",,,9284710,343,350,,,10.1109/Blockchain50366.2020.00050,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099265847&doi=10.1109%2fBlockchain50366.2020.00050&partnerID=40&md5=13747953b07d9d9ef739eab4a256831f,"National University of Ireland, Galway, Ireland","Thakur, S., National University of Ireland, Galway, Ireland; Breslin, J.G., National University of Ireland, Galway, Ireland","A Path-based Fund Transfer (PBT) in blockchain offline channel networks or in credit networks, uses a path among the offline channels to transfer funds among the peers who do not have mutual channels. A routing algorithm for PBT finds a suitable path for PBT execution. The problems with the landmark-based routing algorithms for PBT executions are as follows: (1) PBTs through hubs may cause privacy problems as a few landmarks can collude to find the sender and the receiver of a PBT, (2) Landmarks can be targeted with DoS or Eclipse attack. Unavailability of landmarks will lead to a high failure rate of PBT and (3) the unavailability of nodes for PBT execution creates cuts in the trees maintained by landmark-based routing protocols, which will lead to failure of PBT execution. In this paper, we mitigate the above problems with routing algorithms for PBT execution with a graph edge colouring-based routing protocol. In this routing protocol, every peer maintains a set of small subgraphs of the channel network with a particular topology. The peers exchange such subgraph information to find an appropriate path for PBT execution. Our contributions are as follows: (1) We develop a distributed algorithm to find subgraphs maintained by a peer. We prove that despite sharing subgraph information, our protocol preserves the privacy of the sender and the receiver of a PBT. (2) We prove that the proposed protocol is secure against adversarial peers initially agrees to participate in PBT execution and included in the trees or subgraphs computed by landmark-based or our edge colour-based routing algorithm, but later they do not participate in PBT execution. (3) We show that trees built by landmark-based algorithms require more frequent rebuilding as values in individual channels are changed over time compared with subgraphs to be maintained by the peers. (4) We show that the success rate and time to execute PBT for the proposed edge colouring-based routing algorithm is competitive against the landmark-based routing algorithm. (5) We show that DoS attacks resulting unavailability of peers have less impact on the proposed routing algorithm compared with landmark-based routing algorithms. © 2020 IEEE.",Bitcoin Lightning Network; Fund Transfer Protocols; Offline Channels,Blockchain; Denial-of-service attack; Failure analysis; Forestry; Graph algorithms; Graph structures; Navigation; Routing protocols; Trees (mathematics); Channel network; Credit networks; Edge-colouring; Failure rate; Graph edges; Offline channel; Path-based; Privacy problems; Privacy by design,,,,,"Poon, J., Dryja, T., The Bitcoin Lightning Network:Scalable Off-Chain Instant Payments, , https://lightning.network/lightning-networkpaper.pdf, [Online]; Malavolta, G., Moreno-Sanchez, P., Kate, A., Maffei, M., Silentwhispers: Enforcing security and privacy in decentralized credit networks (2016) Iacr Cryptology EPrint Archive, p. 1054. , vol. 2016; Roos, S., Moreno-Sanchez, P., Kate, A., Goldberg, I., (2017) Settling Payments Fast and Private: Efficient Decentralized Routing for Path-based Transactions, , http://arxiv.org/abs/1709.05748, CoRR, vol. abs/1709.05748, [Online]; Raiden Network, , http://raiden.network/, accessed 2018; Prihodko, P., Zhigulin, S., Sahno, M., Ostrovskiy, A., Osuntokun, O., (2016) Flare : An Approach to Routing in Lightning Network White Paper; Khalil, R., Gervais, A., Revive: Rebalancing offblockchain payment networks (2017) Proceedings of the 2017 Acm Sigsac Conference on Computer and Communications Security, pp. 439-453. , http://doi.acm.org/10.1145/3133956.3134033, ser. CCS '17. New York, NY, USA: ACM, [Online]; Thakur, S., Breslin, J., Collusion attack from hubs in the blockchain offline channel network (2019) 1st International Conference on Mathematical Research for Blockchain; Thakur, S., Breslin, J.G., A balanced routing algorithm for blockchain offline channels using flocking (2020) Blockchain and Applications, pp. 79-86. , J. Prieto, A. K. Das, S. Ferretti, A. Pinto, and J. M. Corchado, Eds. Cham: Springer International Publishing; Adler, B., Weiss, R., Similarity of automorphisms of the torus (1970) Memoires of the American Mathematical, Society; Trahtman, A.N., The road coloring problem (2009) Israel Journal of Mathematics, 172 (1), pp. 51-60. , https://doi.org/10.1007/s11856-009-0062-5, Jul, [Online]; Trahtman, A., An algorithm for road coloring (2012) Journal of Discrete Algorithms, 16, pp. 213-223. , http://www.sciencedirect.com/science/article/pii/S1570866712001001, selected papers from the 22nd International Workshop on Combinatorial Algorithms (IWOCA 2011). [Online]; Béal, M.-P., Perrin, D., A quadratic algorithm for road coloring (2014) Discrete Applied Mathematics, 169, pp. 15-29. , http://www.sciencedirect.com/science/article/pii/S0166218X13005751, [Online]",,,,Institute of Electrical and Electronics Engineers Inc.,"3rd IEEE International Conference on Blockchain, Blockchain 2020",2 November 2020 through 6 November 2020,,165802,,9.78E+12,,,English,"Proc. - IEEE Int. Conf. Blockchain, Blockchain",Conference Paper,Final,,Scopus,2-s2.0-85099265847
"Wei J., Lü D., Lu X., Sun G.",57220859666;7403078966;55687442500;35732407500;,Improved Method to Craft Universal Perturbations Based on Fast Feature Fool [基于快速特征欺骗的通用扰动生成改进方法],2020,Yingyong Kexue Xuebao/Journal of Applied Sciences,38,6,,986,994,,,10.3969/j.issn.0255-8297.2020.06.015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097785678&doi=10.3969%2fj.issn.0255-8297.2020.06.015&partnerID=40&md5=47df2f9b5d6a7579b64f38fbd9ad5c9c,"School of Communication and Information Engineering, Shanghai University, Shanghai, 200444, China","Wei, J., School of Communication and Information Engineering, Shanghai University, Shanghai, 200444, China; Lü, D., School of Communication and Information Engineering, Shanghai University, Shanghai, 200444, China; Lu, X., School of Communication and Information Engineering, Shanghai University, Shanghai, 200444, China; Sun, G., School of Communication and Information Engineering, Shanghai University, Shanghai, 200444, China","Although deep neural networks have been widely applied in recent years, they are readily fooled by adversarial input perturbations which are imperceptible to humans. Such vulnerability to adversarial attacks has imposed threats for system deployment in security-crucial setting, thus it is necessary to study the risky generation method of perturbations to boost the anti-risk capability. As a universal perturbation, fast feature fool (FFF) is an effective attacking method for visual tasks. Beyond solely mixing the convolutional layer's output irrespective of the input activation status, this paper improves the FFF method by maximizing the feature difference between the input image and corresponding adversarial image during which the contributions of multiple convolutional layers are weighted differently. Experimental results demonstrate that the improved FFF actually has obtained higher success attacking rate and stronger cross-model transfer ability than the original one. © 2020, Editorial Office of Journal of Applied Sciences. All right reserved.",Deep neural networks; Fast feature fool (FFF); Feature difference; Universal perturbations,,,,,,"Krizhevsky, A, Sutskever, I, Hinton, G E., ImageNet classification with deep convolutional neural networks (2017) Communications of the ACM, 60 (6), pp. 84-90. , [J]; Ren, S Q, He, K M, Girshick, R, Faster R-CNN: towards real-time object detection with region proposal networks (2017) IEEE Transactions on Pattern Analysis and Machine Intelligence, 39 (6), pp. 1137-1149. , [J]; Sutskever, I, Vinyals, O, Le, V., Sequence to sequence learning with neural networks (2014) Advances in Neural Information Processing Systems, pp. 3104-3112. , [C] Montreal, Canada; Szegedy, C, Zaremba, W, Sutskeve, R I, Intriguing properties of neural networks (2014) International Conference on Learning Representations, pp. 64-70. , [C] Banff, Canada; Zhang, S S, Zuo, X, Liu, J W., The problem of the adversarial examples in deep learning (2018) Chinese Journal of Computers, 41 (8), pp. 1886-1904. , 张思思, 左信, 刘建伟. 深度学习中的对抗样本问题[J]. 计算机学报, 2018, 41(8): 1886-1904. [J]. (in Chinese); Mahendran, A, Vedaldi, A., Understanding deep image representations by inverting them (2015) IEEE Conference on Computer Vision and Pattern Recognition, pp. 188-5196. , [C] Boston, USA; Goodfellow, I, Shlens, J, Szegedy, C., Explaining and harnessing adversarial examples[J/OL] https://arxiv.org/abs/1412.6572, [2014-12-20]; Kurakin, A, Goodfellow, I, Bengio, S., Adversarial examples in the physical world https://arxiv.org/abs/1607.02533, [J/OL]. [2016-07-08]; Carlini, N, Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy, pp. 39-57. , [C] San Jose, USA; Moosavi-Dezfooli, S M, Fawzi, A, Frossard, P., DeepFool: a simple and accurate method to fool deep neural networks (2016) IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582. , [C] Las Vegas, USA; Moosavi-Dezfooli, S M, Fawzi, A, Fawzi, O, Universal adversarial perturbations (2017) IEEE Conference on Computer Vision and Pattern Recognition, pp. 86-94. , [C] Honolulu, USA; Mopuri, K R, Garg, U, Babu, V., Fast feature fool: a data independent approach to universal adversarial perturbations https://arxiv.org/abs/1707.05572, [J/OL]. [2017-07-18]; Mopuri, K R, Ganeshan, A, Babu, R., Generalizable data-free objective for crafting universal adversarial perturbations (2019) IEEE Transactions on Pattern Analysis and Machine Intelligence, 41 (10), pp. 2452-2465. , [J]; Ross, A S, Doshivelez, F., Improving the adversarial robustness and interpretability of deep neural networks by regularizing their input gradients (2018) AAAI Conference on Artificial Intelligence, pp. 1660-1669. , [C] New Orleans, USA; Miyato, T, Maeda, S, Koyama, M, Distributional smoothing with virtual adversarial training https://arxiv.org/abs/1507.00677, [J/OL]. [2016-06-11]; Song, C, Cheng, H P, Wu, C., A multi-strength adversarial training method to mitigate adversarial attacks (2018) IEEE Computer Society Annual Symposium on VLSI, pp. 476-481. , [C] Hong Kong, China; Hinton, G, Vinyals, O, Dean, J., Distilling the knowledge in a neural network[J/OL] https://arxiv.org/abs/1503.02531, [2015-03-09]","Sun, G.; School of Communication and Information Engineering, China; 电子邮件: sunguangling@shu.edu.cn",,,Press of Shanghai Scientific and Technical Publishers,,,,,2558297,,YKXUD,,Chinese,Yingyong Kexue Xuebao,Article,Final,,Scopus,2-s2.0-85097785678
"Kumar K.N., Vishnu C., Mitra R., Mohan C.K.",57219795577;36538461400;57207571541;55325461200;,Black-box adversarial attacks in autonomous vehicle technology,2020,Proceedings - Applied Imagery Pattern Recognition Workshop,2020-October,,9425267,,,,1,10.1109/AIPR50011.2020.9425267,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106196590&doi=10.1109%2fAIPR50011.2020.9425267&partnerID=40&md5=2b94d919c6270314b867b09763f9089f,"Indian Institute of Technology Hyderabad, India; Southeast Missouri State University, Cape Girardeau, United States","Kumar, K.N., Indian Institute of Technology Hyderabad, India; Vishnu, C., Indian Institute of Technology Hyderabad, India; Mitra, R., Southeast Missouri State University, Cape Girardeau, United States; Mohan, C.K., Indian Institute of Technology Hyderabad, India","Despite the high quality performance of the deep neural network in real-world applications, they are susceptible to minor perturbations of adversarial attacks. This is mostly undetectable to human vision. The impact of such attacks has become extremely detrimental in autonomous vehicles with real-time ""safety""concerns. The black-box adversarial attacks cause drastic misclassification in critical scene elements such as road signs and traffic lights leading the autonomous vehicle to crash into other vehicles or pedestrians. In this paper, we propose a novel query-based attack method called Modified Simple black-box attack (M-SimBA) to overcome the use of a white-box source in transfer based attack method. Also, the issue of late convergence in a Simple black-box attack (SimBA) is addressed by minimizing the loss of the most confused class which is the incorrect class predicted by the model with the highest probability, instead of trying to maximize the loss of the correct class. We evaluate the performance of the proposed approach to the German Traffic Sign Recognition Benchmark (GTSRB) dataset. We show that the proposed model outperforms the existing models like Transfer-based projected gradient descent (T-PGD), SimBA in terms of convergence time, flattening the distribution of confused class probability, and producing adversarial samples with least confidence on the true class. © 2020 IEEE.",Adversarial attacks; Autonomous vehicles; Black-box attacks; Deep learning methods,Accidents; Benchmarking; Deep neural networks; Gradient methods; Pattern recognition; Probability distributions; Traffic signs; Attack methods; Autonomous vehicle technologies; Class probabilities; Convergence time; Misclassifications; Projected gradient; Traffic light; Traffic sign recognition; Autonomous vehicles,,,,,"Wood, M., Robbel, P., Wittmann, D., (2019) Safety First for Automated Driving, , https://www.aptiv.com/docs/default-source/white-papers/safetyfirst-for-automated-driving-aptiv-white-paper.pdf; Deng, Y., Zheng, X., Zhang, T., Chen, C., Lou, G., Kim, M., (2020) An Analysis of Adversarial Attacks and Defenses on Autonomous Driving Models; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations, , http://arxiv.org/abs/1312.6199; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations, , http://arxiv.org/abs/1412.6572; Liu, Y., Chen, X., Liu, C., Song, D., (2016) Delving into Transferable Adversarial Examples and Black-box Attacks; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., Adversarial examples for semantic segmentation and object detection (2017) Proceedings of the IEEE International Conference on Computer Vision, pp. 1369-1378; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP), pp. 39-57; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations, , http://arxiv.org/abs/1312.6199; Cisse, M., Adi, Y., Neverova, N., Keshet, J., (2017) Houdini: Fooling Deep Structured Prediction Models, p. 07; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., Adversarial examples for semantic segmentation and object detection (2017) 2017 IEEE International Conference on Computer Vision (ICCV), pp. 1378-1387; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples; Moosavi-Dezfooli, S.-M., Alhussein Fawzi, O.F., Pascal frossard in Universal adversarial perturbations 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 15-26; Lu, Y., Jia, Y., Wang, J., Li, B., Chai, W., Carin, L., Velipasalar, S., Enhancing cross-task black-box transferability of adversarial examples with dispersion reduction (2020) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 940-949; Jiang, L., Ma, X., Chen, S., Bailey, J., Jiang, Y.-G., Black-box adversarial attacks on video recognition models (2019) Proceedings of the 27th ACM International Conference on Multimedia, pp. 864-872; Sitawarin, C., Bhagoji, A.N., Mosenia, A., Chiang, M., Mittal, P., (2018) Darts: Deceiving Autonomous Cars with Toxic Signs; Huang, Z., Zhang, T., (2019) Black-box Adversarial Attack with Transferable Model-based Embedding; Brendel, W., Rauber, J., Bethge, M., (2017) Decision-based Adversarial Attacks: Reliable Attacks against Black-box Machine Learning Models; Brunner, T., Diehl, F., Le, M.T., Knoll, A., Guessing smart: Biased sampling for efficient black-box adversarial attacks (2019) 2019 IEEE/CVF International Conference on Computer Vision (ICCV), pp. 4957-4965; Rosenberg, I., Shabtai, A., Elovici, Y., Rokach, L., (2018) Query-efficient Black-box Attack against Sequence-based Malware Classifiers; Liu, Y., Moosavi-Dezfooli, S., Frossard, P., A geometry-inspired decision-based attack (2019) 2019 IEEE/CVF International Conference on Computer Vision (ICCV), pp. 4889-4897; Guo, C., Gardner, J., You, Y., Wilson, A.G., Weinberger, K., Simple black-box adversarial attacks (2019) Ser. Proceedings of Machine Learning Research, 97, pp. 2484-2493. , http://proceedings.mlr.press/v97/guo19a.html, K. Chaudhuri and R. Salakhutdinov, Eds.Long Beach, California, USA: PMLR, 09-15 Jun; Stallkamp, J., Schlipsing, M., Salmen, J., Igel, C., The German traffic sign recognition benchmark: A multi-class classification competition (2011) IEEE International Joint Conference on Neural Networks, pp. 1453-1460",,,,Institute of Electrical and Electronics Engineers Inc.,"2020 IEEE Applied Imagery Pattern Recognition Workshop, AIPR 2020",13 October 2020 through 15 October 2020,,168873,21642516,9.78E+12,,,English,Proc. Appl. Imagery Pattern. Recogn. Workshop,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85106196590
"Wang L., Yang K., Wang W., Wang R., Ye A.",55899978500;57224752865;57211314638;57188670585;57218492739;,MGAAttack: Toward More Query-efficient Black-box Attack by Microbial Genetic Algorithm,2020,MM 2020 - Proceedings of the 28th ACM International Conference on Multimedia,,,,2229,2236,,,10.1145/3394171.3413703,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106934914&doi=10.1145%2f3394171.3413703&partnerID=40&md5=76d9a6670a54a2e003dfc2e229b6b213,"Ministry of Education, Wuhan University, Key Laboratory of Aerospace Information Security and Trusted Computing, Wuhan, China; School of Cyber Science and Engineering, Wuhan University, China; Nanyang Technological University, Singapore, Singapore","Wang, L., Ministry of Education, Wuhan University, Key Laboratory of Aerospace Information Security and Trusted Computing, Wuhan, China, School of Cyber Science and Engineering, Wuhan University, China; Yang, K., Ministry of Education, Wuhan University, Key Laboratory of Aerospace Information Security and Trusted Computing, Wuhan, China, School of Cyber Science and Engineering, Wuhan University, China; Wang, W., Ministry of Education, Wuhan University, Key Laboratory of Aerospace Information Security and Trusted Computing, Wuhan, China, School of Cyber Science and Engineering, Wuhan University, China; Wang, R., Nanyang Technological University, Singapore, Singapore; Ye, A., Ministry of Education, Wuhan University, Key Laboratory of Aerospace Information Security and Trusted Computing, Wuhan, China, School of Cyber Science and Engineering, Wuhan University, China","Recent studies have shown that deep neural networks (DNNs) are susceptible to adversarial attacks even in the black-box settings. However, previous studies on creating black-box based adversarial examples by merely solving the traditional continuous problem, which suffer query efficiency issues. To address the efficiency of querying in black-box attack, we propose a novel attack, called MGAAttack, which is a query-efficient and gradient-free black-box attack without obtaining any knowledge of the target model. In our approach, we leverage the advantages of both transfer-based and scored-based methods, two typical techniques in black-box attack, and solve a discretized problem by using a simple yet effective microbial genetic algorithm (MGA). Experimental results show that our approach dramatically reduces the number of queries on CIFAR-10 and ImageNet and significantly outperforms previous work. In the untargeted attack, we can attack a VGG19 classifier with only 16 queries and give an attack success rate more than 99.90% on ImageNet. Our code is available at https://github.com/kangyangWHU/MGAAttack. © 2020 ACM.",black-box adversarial attack; deep neural networks; microbial genetic algorithm,Deep neural networks; Efficiency; Black boxes; Continuous problems; Discretized problems; Query efficiency; Target model; Genetic algorithms,,,,,"Alzantot, M., Sharma, Y., Chakraborty, S., Zhang, H., Hsieh, C.-J., Srivastava, M.B., Genattack: Practical black-box attacks with gradient-free optimization (2019) Proceedings of the Genetic and Evolutionary Computation Conference., pp. 1111-1119; Athalye, A., Carlini, N., Wagner, D., Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples (2018) 35th International Conference on Machine Learning, ICML 2018, 1, pp. 436-448. , 2018; Bahdanau, D., Cho, K., Bengio, Y., (2014) Neural Machine Translation by Jointly Learning to Align and Translate, , (2014); Biggio, B., Corona, I., Maiorca, D., Nelson, B., Srndic, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, pp. 387-402; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (Sp)., pp. 39-57; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security., pp. 15-26; Chollet, F., Xception: Deep learning with depthwise separable convolutions (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition., pp. 1251-1258; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Li, F.-F., Imagenet: A large-scale hierarchical image database (2009) 2009 IEEE Conference on Computer Vision and Pattern Recognition. IEEE, pp. 248-255; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition., pp. 9185-9193; Dong, Y., Pang, T., Su, H., Zhu, J., Evading defenses to transferable adversarial examples by translation-invariant attacks (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition., pp. 4312-4321; Du, J., Zhang, H., Zhou, J.T., Yang, Y., Feng, J., (2019) Queryefficient Meta Attack to Deep Neural Networks, , (2019); Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , (2014); Guo, C., Rana, M., Cissé, M., Van Der Maaten, L., Countering adversarial images using input transformations (2018) International Conference on Learning Representations, ICLR 2018., pp. 1-12; Hansen, N., Ostermeier, A., Completely derandomized self-adaptation in evolution strategies (2001) Evolutionary Computation, 9 (2), pp. 159-195. , 2001; Harvey, I., The microbial genetic algorithm (2009) European Conference on Artificial Life. Springer, pp. 126-133; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition., pp. 770-778; Hinton, G., Deng, L., Yu, D., Dahl, G.E., Mohamed, A.-R., Jaitly, N., Senior, A., Sainath, T.N., Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups (2012) IEEE Signal Processing Magazine, 29 (6), pp. 82-97. , 2012; Huang, Q., Katsman, I., He, H., Gu, Z., Belongie, S., Lim, S.-N., Enhancing adversarial example transferability with an intermediate level attack (2019) Proceedings of the IEEE International Conference on Computer Vision., pp. 4733-4742; Huang, Z., Zhang, T., (2019) Black-Box Adversarial Attack with Transferable Model-based Embedding, , (2019); Ilyas, A., Engstrom, L., Athalye, A., Lin, J., (2018) Blackbox Adversarial Attacks with Limited Queries and Information, , (2018); Ilyas, A., Engstrom, L., Madry, A., (2018) Prior Convictions: Black-box Adversarial Attacks with Bandits and Priors, , (2018); Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images., , (2009); Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , (2016); Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradientbased learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324. , 1998; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , (2017); Meunier, L., Atif, J., Teytaud, O., (2019) Yet Another but More Efficient Black-box Adversarial Attack: Tiling and Evolution Strategies, , (2019); Moon, S., An, G., Song, H.O., (2019) Parsimonious Blackbox Adversarial Attacks Via Efficient Combinatorial Optimization, , (2019); Parkhi, O.M., Vedaldi, A., Zisserman, A., (2015) Deep Face Recognition. (2015).; Redmon, J., Divvala, S., Girshick, R., Farhadi, A., You only look once: Unified, real-time object detection (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 779-788; Russakovsky, O., Deng, J., Su, H., Krause, J., Sanjeev, S., Ma, S., Huang, Z., Bernstein, M., Imagenet large scale visual recognition challenge (2015) International Journal of Computer Vision, 115 (3), pp. 211-252. , 2015; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition, , (2014); Su, J., Vargas, D.V., Sakurai, K., One pixel attack for fooling deep neural networks (2019) IEEE Transactions on Evolutionary Computation, 23 (5), pp. 828-841. , 2019; Suya, F., Chi, J., Evans, D., Tian, Y., (2019) Hybrid Batch Attacks: Finding Black-box Adversarial Examples with Limited Queries, , (2019); Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., Inception-v4, inception-resnet and the impact of residual connections on learning (2017) Thirty-first AAAI Conference on Artificial Intelligence.; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , (2013); Tu, C.-C., Ting, P., Chen, P.-Y., Liu, S., Zhang, H., Yi, J., Hsieh, C.-J., Cheng, S.-M., Autozoom: Autoencoder-based zeroth order optimization method for attacking black-box neural networks (2019) Proceedings of the AAAI Conference on Artificial Intelligence, 33, pp. 742-749; Wang, W., Wang, L., Wang, R., Wang, Z., Ye, A., (2019) Towards A Robust Deep Neural Network in Texts: A Survey, , (2019); Wei, Z., Chen, J., Wei, X., Jiang, L., Chua, T.-S., Zhou, F., Jiang, Y.-G., Heuristic black-box adversarial attacks on video recognition models (2020) AAAI, pp. 12338-12345; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., (2017) Mitigating Adversarial Effects through Randomization, , (2017); Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., Adversarial examples for semantic segmentation and object detection (2017) Proceedings of the IEEE International Conference on Computer Vision, pp. 1369-1378; Xie, C., Zhang, Z., Zhou, Y., Bai, S., Wang, J., Ren, Z., Yuille, A.L., Improving transferability of adversarial examples with input diversity (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2730-2739; Zagoruyko, S., Komodakis, N., (2016) Wide Residual Networks, , (2016)","Wang, R.; Nanyang Technological UniversitySingapore; 电子邮件: wangrun@whu.edu.cn",,ACM SIGMM,"Association for Computing Machinery, Inc","28th ACM International Conference on Multimedia, MM 2020",12 October 2020 through 16 October 2020,,163870,,9.78E+12,,,English,MM - Proc. ACM Int. Conf. Multimed.,Conference Paper,Final,,Scopus,2-s2.0-85106934914
"Zhang J., Sang J., Zhao X., Huang X., Sun Y., Hu Y.",57276924200;27867954600;57193750353;57226088998;9736644400;7407118245;,Adversarial Privacy-preserving Filter,2020,MM 2020 - Proceedings of the 28th ACM International Conference on Multimedia,,,,1423,1431,,5,10.1145/3394171.3413906,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101861075&doi=10.1145%2f3394171.3413906&partnerID=40&md5=6cf19f6c226e71cb622fa698783f0d0c,"Beijing Jiaotong University and Peng Cheng Laboratory, Beijing, China; Peng Cheng Laboratory, ShenZhen, China; Beijing Key Lab. of Multimedia and Intelligent Software Technol Beijing Artif. Intell. Institute, Faculty of Information Technology, Beijing University of Technology, Beijing, China","Zhang, J., Beijing Jiaotong University and Peng Cheng Laboratory, Beijing, China, Peng Cheng Laboratory, ShenZhen, China; Sang, J., Beijing Jiaotong University and Peng Cheng Laboratory, Beijing, China, Peng Cheng Laboratory, ShenZhen, China; Zhao, X., Beijing Jiaotong University and Peng Cheng Laboratory, Beijing, China; Huang, X., Beijing Jiaotong University and Peng Cheng Laboratory, Beijing, China; Sun, Y., Beijing Key Lab. of Multimedia and Intelligent Software Technol Beijing Artif. Intell. Institute, Faculty of Information Technology, Beijing University of Technology, Beijing, China; Hu, Y., Beijing Key Lab. of Multimedia and Intelligent Software Technol Beijing Artif. Intell. Institute, Faculty of Information Technology, Beijing University of Technology, Beijing, China","While widely adopted in practical applications, face recognition has been critically discussed regarding the malicious use of face images and the potential privacy problems, e.g., deceiving payment system and causing personal sabotage. Online photo sharing services unintentionally act as the main repository for malicious crawler and face recognition applications. This work aims to develop a privacy-preserving solution, called Adversarial Privacy-preserving Filter (APF), to protect the online shared face images from being maliciously used. We propose an end-cloud collaborated adversarial attack solution to satisfy requirements of privacy, utility and non-accessibility. Specifically, the solutions consist of three modules: (1) image-specific gradient generation, to extract image-specific gradient in the user end with a compressed probe model; (2) adversarial gradient transfer, to fine-tune the image-specific gradient in the server cloud; and (3) universal adversarial perturbation enhancement, to append image-independent perturbation to derive the final adversarial noise. Extensive experiments on three datasets validate the effectiveness and efficiency of the proposed solution. A prototype application is also released for further evaluation. We hope the end-cloud collaborated attack framework could shed light on addressing the issue of online multimedia sharing privacy-preserving issues from user side. © 2020 ACM.",adversarial example; face recognition; photo sharing; privacy-preserving,Face recognition; Image enhancement; Effectiveness and efficiencies; Face images; Online Photo Sharing; Payment systems; Privacy preserving; Privacy preserving solutions; Privacy problems; PROBE-model; Privacy by design,,,,,"Chen, S., Liu, Y., Gao, X., Han, Z., Mobilefacenets: Efficient cnns for accurate real-Time face verification on mobile devices (2018) Chinese Conference on Biometric Recognition, pp. 428-438. , Springer; Chesney, B., Citron, D., 2019 Deep fakes: A looming challenge for privacy, democracy, and national security (2019) Calif. L. Rev, (107), p. 1753; Deb, D., Zhang, J., Jain, A.K., (2019) 2019 Advfaces: Adversarial Face Synthesis, , arXiv preprint arXiv 1908 05008; Deng, J., Guo, J., Xue, N., Zafeiriou, S., Arcface: Additive angular margin loss for deep face recognition (2019) Proceedings of the Ieee Conference on Computer Vision and Pattern Recognition (CVPR, pp. 4690-4699; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2018) Proceedings of the Ieee Conference on Computer Vision and Pattern Recognition (CVPR, pp. 9185-9193; Dong, Y., Su, H., Wu, B., Li, Z., Liu, W., Zhang, T., Zhu, J., Efficient decision-based black-box adversarial attacks on face recognition (2019) Proceedings of the Ieee Conference on Computer Vision and Pattern Recognition (CVPR, pp. 7714-7722; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Proceedings of the Advances in Neural Information Processing Systems, pp. 2672-2680; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, 2014. , arXiv preprint arXiv 1412.6572; Guo, Y., Zhang, L., Hu, Y., He, X., Gao, J., Msceleb-1m: A dataset and benchmark for large-scale face recognition (2016) Proceedings of the European Conference on Computer Vision (ECCV, pp. 87-102. , Springer; He, K., Zhang, X., Ren, S., Sun, J., Identity mappings in deep residual networks (2016) Proceedings of the European Conference on Computer Vision (ECCV, pp. 630-645. , Springer; Huang, G.B., Mattar, M., Berg, T., Learned-Miller, E., Labeled faces in the wild: A database forstudying face recognition in unconstrained environments (2008) Workshop on Faces in ?Real-Life? Images: Detection, Alignment, and Recognition; Klemperer, P., Liang, Y., Mazurek, M., Sleeper, M., Ur, B., Bauer, L., Faith Cranor, L., Reiter, M., Tag, you can see it! Using tags for access control in photo sharing (2012) Proceedings of the Sigchi Conference on Human Factors in Computing Systems, pp. 377-386; Komkov, S., Petiushko, A., (2019) 2019 AdvHat: Real-world Adversarial Attack on ArcFace Face Id System, , arXiv preprint arXiv 1908 08705; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2016) Proceedings of the International Conference on Learning Representations (ICLR) Workshop; Li, F., Sun, Z., Niu, B., Guo, Y., Liu, Z., 2018 Srim scheme: An impression-management scheme for privacy-Aware photo-sharing users (2018) Engineering, 4 (1), pp. 85-93; Li, Y., Bai, S., Xie, C., Liao, Z., Shen, X., Yuille, A.L., (2019) 2019 Regional Homogeneity: Towards Learning Transferable Universal Adversarial Perturbations against Defenses. ArXiv Preprint ArXiv 1904 00979; Liu, W., Zhiding Yu, Y., Li, M., Raj, B., Song, L., 2017 Sphereface: Deep hypersphere embedding for face recognition Proceedings of the Ieee Conference on Computer Vision and Pattern Recognition (CVPR, pp. 212-220; Liu, Y., Chen, X., Liu, C., Song, D., Delving into Transferable Adversarial Examples and Black-box Attacks (2017) Proceedings of the International Conference on Learning Representations (ICLR; Luo, Y., Boix, X., Roig, G., Poggio, T., Zhao, Q., (2015) 2015 Foveationbased Mechanisms Alleviate Adversarial Examples. ArXiv Preprint ArXiv 1511.06292; Moosavi-Dezfooli, S., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) Proceedings of the Ieee Conference on Computer Vision and Pattern Recognition (CVPR, pp. 1765-1773; Moschoglou, S., Papaioannou, A., Sagonas, C., Deng, J., Kotsia, I., Zafeiriou, S., Agedb: The first manually collected, in-The-wild age database (2017) Proceedings of the Ieee Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pp. 51-59; Poursaeed, O., Katsman, I., Gao, B., Belongie, S., Generative adversarial perturbations (2018) Proceedings of the Ieee Conference on Computer Vision and Pattern Recognition (CVPR, pp. 4422-4431; Ronneberger, O., Fischer, P., Brox, T., U-net: Convolutional networks for biomedical image segmentation (2015) Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 234-241. , Springer; Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., Chen, L., Mobilenetv2: Inverted residuals and linear bottlenecks (2018) Proceedings of the Ieee Conference on Computer Vision and Pattern Recognition (CVPR, pp. 4510-4520; Schroff, F., Kalenichenko, D., Philbin, J., Facenet: A unified embedding for face recognition and clustering (2015) Proceedings of the Ieee Conference on Computer Vision and Pattern Recognition (CVPR, pp. 815-823; Sengupta, S., Chen, J., Castillo, C., Patel, V.M., Chellappa, R., Jacobs, D.W., Frontal to profile face verification in the wild (2016) Proceedings of the Ieee Winter Conference on Applications of Computer Vision (WACV). Ieee, pp. 1-9; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-The-Art face recognition (2016) Proceedings of the 2016 Acm Sigsac Conference on Computer and Communications Security, pp. 1528-1540; Such, J.M., Criado, N., 2016 Resolving multi-party privacy conflicts in social media (2016) Ieee Transactions on Knowledge and Data Engineering, 28 (7), pp. 1851-1863; Sun, W., Zhou, J., Zhu, S., Yan Tang, Y., 2018 Robust privacy-preserving image sharing over online social networks (osns (2018) Acm Transactions on Multimedia Computing, Communications, and Applications (TOMM, (141), pp. 1-22; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., Inception-v4, inception-resnet and the impact of residual connections on learning (2017) Proceedings of the Aaai Conference on Artificial Intelligence; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) Proceedings of the International Conference on Learning Representations (ICLR; Wang, Z., Bovik, A.C., Sheikh, H.R., Simoncelli, E.P., Image quality assessment: From error visibility to structural similarity (2004) Ieee Transactions on Image Processing (TIP, 2004 (134), pp. 600-612; Wang, Z., Simoncelli, E.P., Bovik, A.C., Multiscale structural similarity for image quality assessment (2003) Proceedings of the Asilomar Conference on Signals, Systems & Computers, 2, pp. 1398-1402; Xie, C., Zhang, Z., Zhou, Y., Bai, S., Wang, J., Ren, Z., Yuille, A.L., Improving transferability of adversarial examples with input diversity (2019) Proceedings of the Ieee Conference on Computer Vision and Pattern Recognition (CVPR, pp. 2730-2739; Xu, Y., Price, T., Frahm, J., Monrose, F., Virtual U: Defeating face liveness detection by building virtual models from your public photos (2016) Proceedings of the Usenix Conference on Security Symposium. Usenix Association, pp. 497-512; Yi, D., Lei, Z., Liao, S., Li, S.Z., (2014) Learning Face Representation from Scratch. ArXiv Preprint ArXiv 1411.7923, 2014; Zhang, L., Liu, K., Li, X., Liu, C., Ding, X., Liu, Y., Privacy-friendly photo capturing and sharing system (2016) Proceedings of the 2016 Acm International Joint Conference on Pervasive and Ubiquitous Computing, pp. 524-534",,,ACM SIGMM,"Association for Computing Machinery, Inc","28th ACM International Conference on Multimedia, MM 2020",12 October 2020 through 16 October 2020,,163870,,9.78E+12,,,English,MM - Proc. ACM Int. Conf. Multimed.,Conference Paper,Final,"All Open Access, Bronze, Green",Scopus,2-s2.0-85101861075
"Singla A., Bertino E., Verma D.",57143929800;7102307605;57214983108;,Preparing Network Intrusion Detection Deep Learning Models with Minimal Data Using Adversarial Domain Adaptation,2020,"Proceedings of the 15th ACM Asia Conference on Computer and Communications Security, ASIA CCS 2020",,,,127,140,,9,10.1145/3320269.3384718,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096379810&doi=10.1145%2f3320269.3384718&partnerID=40&md5=215037805aad01b15051d51b61776eba,"Department of Computer Science, Purdue University, West Lafayette, IN, United States; Thomas J. Watson Research Center Ibm, Yorktown Heights, NY, United States","Singla, A., Department of Computer Science, Purdue University, West Lafayette, IN, United States; Bertino, E., Department of Computer Science, Purdue University, West Lafayette, IN, United States; Verma, D., Thomas J. Watson Research Center Ibm, Yorktown Heights, NY, United States","Recent work has shown that deep learning (DL) techniques are highly effective for assisting network intrusion detection systems (NIDS) in identifying malicious attacks on networks. Training DL classification models, however, requires vast amounts of labeled data which is often expensive and time-consuming to collect. Also, DL models trained using data from one type of network may not be able to identify attacks on other types of network or identify new families of attacks discovered over time. In this paper, we propose and evaluate the use of adversarial domain adaptation to address the problem of scarcity of labeled training data in a dataset by transferring knowledge gained from an existing network intrusion detection (NID) dataset. Our approach works for scenarios where the source and target datasets have same or different feature spaces. We demonstrate that our proposed approach can create highly accurate DL classification models even when the number of labeled samples in the target dataset is significantly small. © 2020 ACM.",deep learning; intrusion detection; neural networks; transfer learning,Classification (of information); Intrusion detection; Learning systems; Network security; Classification models; Domain adaptation; Highly accurate; Labeled training data; Learning models; Malicious attack; Network intrusion detection; Network intrusion detection systems; Deep learning,,,,,"NSL-KDD Dataset, , https://www.unb.ca/cic/datasets/nsl.html, [n. d. ]; Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Isard, M., Tensorflow: A system for large-scale machine learning (2016) OSDI, 16, pp. 265-283; Arjovsky, M., Chintala, S., Bottou, L., Wasserstein generative adversarial networks (2017) International Conference on Machine Learning, pp. 214-223; Bousmalis, K., Irpan, A., Wohlhart, P., Bai, Y., Kelcey, M., Kalakrishnan, M., Downs, L., Konolige, K., Using simulation and domain adaptation to improve efficiency of deep robotic grasping (2018) 2018 IEEE International Conference on Robotics and Automation (ICRA). IEEE, pp. 4243-4250; Bousmalis, K., Trigeorgis, G., Silberman, N., Krishnan, D., Erhan, D., Domain separation networks (2016) Advances in Neural Information Processing Systems, pp. 343-351; Cannady, J., Artificial neural networks for misuse detection (1998) National Information Systems Security Conference, 26. , Baltimore; Chollet, F., Keras (2015) GitHub, , https://github.com/fchollet/keras; Dai, W., Xue, G.-R., Yang, Q., Yu, Y., Transferring naive bayes classifiers for text classification (2007) AAAI, 7, pp. 540-545; Deng, J., Zhang, Z., Marchi, E., Schuller, B., Sparse autoencoder-based feature transfer learning for speech emotion recognition (2013) 2013 Humaine Association Conference on Affective Computing and Intelligent Interaction. IEEE, pp. 511-516; Do, C.B., Ng, A.Y., Transfer learning for text classification (2006) Advances in Neural Information Processing Systems, pp. 299-306; Frid-Adar, M., Diamant, I., Klang, E., Amitai, M., Goldberger, J., Greenspan, H., Gan-based synthetic medical image augmentation for increased cnn performance in liver lesion classification (2018) Neurocomputing, 321, pp. 321-331; Frid-Adar, M., Klang, E., Amitai, M., Goldberger, J., Greenspan, H., Synthetic data augmentation using gan for improved liver lesion classification (2018) 2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018). IEEE, pp. 289-293; Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette, F., Marchand, M., Lempitsky, V., Domain-adversarial training of neural networks (2016) The Journal of Machine Learning Research, 17 (1), pp. 2096-2030; Ghifary, M., Bastiaan Kleijn, W., Zhang, M., Balduzzi, D., Domain generalization for object recognition with multi-task autoencoders (2015) Proceedings of the IEEE International Conference on Computer Vision, pp. 2551-2559; Ghifary, M., Bastiaan Kleijn, W., Zhang, M., Balduzzi, D., Li, W., Deep reconstruction-classification networks for unsupervised domain adaptation (2016) European Conference on Computer Vision, pp. 597-613. , Springer; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, pp. 2672-2680; Gretton, A., Borgwardt, K., Rasch, M., Schölkopf, B., Smola, A.J., A kernel method for the two-sample-problem (2007) Advances in Neural Information Processing Systems, pp. 513-520; Hodo, E., Bellekens, X., Hamilton, A., Dubouilh, P.-L., Iorkyase, E., Tachtatzis, C., Atkinson, R., Threat analysis of iot networks using artificial neural network intrusion detection system (2016) Networks, Computers and Communications (ISNCC), 2016 International Symposium On. IEEE, pp. 1-6; Hoffman, J., Tzeng, E., Park, T., Zhu, J.-Y., Isola, P., Saenko, K., Efros, A.A., Darrell, T., (2017) Cycada: Cycle-consistent Adversarial Domain Adaptation; Huang, J.-T., Li, J., Yu, D., Deng, L., Gong, Y., Cross-language knowledge transfer using multilingual deep neural network with shared hidden layers (2013) Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference On. IEEE, pp. 7304-7308; Isola, P., Zhu, J.-Y., Zhou, T., Efros, A.A., Image-toimage translation with conditional adversarial networks (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1125-1134; (2019) IXIA PerfectStorm, , https://www.ixiacom.com/products/perfectstorm; Karras, T., Aila, T., Laine, S., Lehtinen, J., Progressive growing of gans for improved quality, stability, and variation (2018) 6th International Conference on Learning Representations, ICLR 2018, , https://openreview.net/forumid=Hk99zCeAb, Vancouver, BC, Canada, April 30-May 3, 2018, Conference Track Proceedings. OpenReview. net; Kathareios, G., Anghel, A., Mate, A., Clauberg, R., Gusat, M., Catch it if you can: Real-time network anomaly detection with low false alarm rates (2017) Machine Learning and Applications (ICMLA), 2017 16th IEEE International Conference On. IEEE, pp. 924-929; Kingma, D.P., Ba, J., (2014) Adam: A Method for Stochastic Optimization, , http://arxiv.org/abs/1412.6980, CoRR abs/1412. 6980; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images, , Technical Report. Citeseer; (1999) KDD Cup 1999 Data, , http://kdd.ics.uci.edu/databases/kddcup99/task.html, MIT Lincoln Labs; LeCun, Y., (1998) The MNIST Database of Handwritten Digits, , http://yann.lecun.com/exdb/mnist/(1998); Liu, M.-Y., Tuzel, O., Coupled generative adversarial networks (2016) Advances in Neural Information Processing Systems, pp. 469-477; Mahoney, M.V., Chan, P.K., An analysis of the 1999 DARPA/lincoln laboratory evaluation data for network anomaly detection (2003) International Workshop on Recent Advances in Intrusion Detection, pp. 220-237. , Springer; Mariani, G., Scheidegger, F., Istrate, R., Bekas, C., Malossi, C., (2018) Bagan: Data Augmentation with Balancing GAN; McHugh, J., Testing intrusion detection systems: A critique of the 1998 and 1999 DARPA intrusion detection system evaluations as performed by lincoln laboratory (2000) ACM Transactions on Information and System Security (TISSEC), 3 (4), pp. 262-294; Meng, Z., Li, J., Chen, Z., Zhao, Y., Mazalov, V., Gang, Y., Juang, B.-H., Speaker-invariant training via adversarial learning (2018) 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, pp. 5969-5973; Moustafa, N., Slay, J., Unsw-nb15: A comprehensive data set for network intrusion detection systems (unsw-nb15 network data set) (2015) Military Communications and Information Systems Conference (MilCIS), 2015. IEEE, pp. 1-6; Oquab, M., Bottou, L., Laptev, I., Sivic, J., Learning and transferring mid-level image representations using convolutional neural networks (2014) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1717-1724; Palagiri, C., Network-based intrusion detection using neural networks (2002) Department of Computer Science Rensselaer Polytechnic Institute Troy, pp. 12180-13590. , New York; Jialin Pan, S., Yang, Q., A survey on transfer learning (2010) IEEE Transactions on Knowledge and Data Engineering, 22 (10), pp. 1345-1359; Pascual, S., Bonafonte, A., Serrà, J., Segan: Speech enhancement generative adversarial network (2017) Proc. Interspeech, 2017, pp. 3642-3646; Pearson, K., Liii. On lines and planes of closest fit to systems of points in space (1901) The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 2 (11), pp. 559-572; Powell, V., (2015) Principal Component Analysis Explained Visually, , http://setosa.io/ev/principal-component-analysis/; Raina, R., Battle, A., Lee, H., Packer, B., Ng, A.Y., Self-taught learning: Transfer learning from unlabeled data (2007) Proceedings of the 24th International Conference on Machine Learning. ACM, pp. 759-766; Ring, M., Wunderlich, S., Scheuring, D., Landes, D., Hotho, A., A survey of network-based intrusion detection data sets (2019) Computers & Security; Singla, A., Bertino, E., Verma, D., Overcoming the lack of labeled data: Training intrusion detection models using transfer learning (2019) 2019 IEEE International Conference on Smart Computing (SMARTCOMP). IEEE, pp. 69-74; Sun, B., Saenko, K., Deep coral: Correlation alignment for deep domain adaptation (2016) European Conference on Computer Vision, pp. 443-450. , Springer; Taigman, Y., Polyak, A., Wolf, L., (2016) Unsupervised Cross-domain Image Generation; Tavallaee, M., Bagheri, E., Lu, W., Ghorbani, A.A., A detailed analysis of the kdd cup 99 data set (2009) Computational Intelligence for Security and Defense Applications, 2009. CISDA 2009. IEEE Symposium On. IEEE, pp. 1-6; Tuor, A., Kaplan, S., Hutchinson, B., Nichols, N., Robinson, S., Deep learning for unsupervised insider threat detection in structured cybersecurity data streams (2017) Workshops at the Thirty-First AAAI Conference on Artificial Intelligence; Tzeng, E., Hoffman, J., Darrell, T., Saenko, K., Simultaneous deep transfer across domains and tasks (2015) Proceedings of the IEEE International Conference on Computer Vision, pp. 4068-4076; Tzeng, E., Hoffman, J., Saenko, K., Darrell, T., Adversarial discriminative domain adaptation (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 7167-7176; Van Gerven, M., Bohte, S.M., Editorial: Artificial neural networks as models of neural information processing (2017) Front. Comput. Neurosci. 2017, , https://doi.org/10.3389/fncom.2017.00114; Wang, M., Deng, W., Deep visual domain adaptation: A survey (2018) Neurocomputing, 312, pp. 135-153; Wold, S., Esbensen, K., Geladi, P., Principal component analysis (1987) Chemometrics and Intelligent Laboratory Systems, 2 (1-3), pp. 37-52; Yu, L., Zhang, W., Wang, J., Yu, Y., Seqgan: Sequence generative adversarial nets with policy gradient (2017) Thirty-First AAAI Conference on Artificial Intelligence; Zhao, J., Shetty, S., Wei Pan, J., Feature-based transfer learning for network security (2017) MILCOM 2017-2017 IEEE Military Communications Conference (MILCOM). IEEE, pp. 17-22; Zhao, J., Shetty, S., Wei Pan, J., Kamhoua, C., Kwiat, K., Transfer learning for detecting unknown network attacks (2019) EURASIP Journal on Information Security, 2019 (1), p. 1",,,ACM SIGSAC,"Association for Computing Machinery, Inc","15th ACM Asia Conference on Computer and Communications Security, ASIA CCS 2020",5 October 2020 through 9 October 2020,,163813,,9.78E+12,,,English,"Proc. ACM Asia Conf. Comput. Commun. Secur., ASIA CCS",Conference Paper,Final,,Scopus,2-s2.0-85096379810
"Grosz S.A., Chugh T., Jain A.K.",57207568529;56031923100;36071504600;,Fingerprint presentation attack detection: A sensor and material agnostic approach,2020,IJCB 2020 - IEEE/IAPR International Joint Conference on Biometrics,,,9304863,,,,3,10.1109/IJCB48548.2020.9304863,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095479159&doi=10.1109%2fIJCB48548.2020.9304863&partnerID=40&md5=cf812b3069cf3631b87419fbd163a098,"Michigan State University, East Lansing, MI  48824, United States","Grosz, S.A., Michigan State University, East Lansing, MI  48824, United States; Chugh, T., Michigan State University, East Lansing, MI  48824, United States; Jain, A.K., Michigan State University, East Lansing, MI  48824, United States","The vulnerability of automated fingerprint recognition systems to presentation attacks (PAs), i.e., spoof or altered fingers, has been a growing concern, warranting the development of accurate and efficient presentation attack detection (PAD) methods. However, one major limitation of the existing PAD solutions is their poor generalization to new PA materials and fingerprint sensors, not used in training. In this study, we propose a robust PAD solution with improved cross-material and cross-sensor generalization. Specifically, we build on top of any CNN-based architecture trained for fingerprint spoof detection combined with cross-material spoof generalization using a style transfer network wrapper. We also incorporate adversarial representation learning (ARL) in deep neural networks (DNN) to learn sensor and material invariant representations for PAD. Experimental results on LivDet 2015 and 2017 public domain datasets exhibit the effectiveness of the proposed approach. © 2020 IEEE.",,Biometrics; Deep neural networks; Attack detection; CNN-based architecture; Fingerprint recognition systems; Fingerprint sensors; Invariant representation; Public domains; Spoof detection; Transfer network; Palmprint recognition,,,,,"Auksorius, E., Boccara, A.C., Internal fingerprint imaging with visible light full-field optical coherence tomography (2016) Clinical and Translational Biophotonics, pp. TTh1B-4. , 2. Optical Society of America; Baldisserra, D., Franco, A., Maio, D., Maltoni, D., Fake fingerprint detection by odor analysis (2006) International Conference on Biometrics, pp. 265-272. , 1. Springer; Bengio, Y., Courville, A., Vincent, P., Representation learning: A review and new perspectives (2013) IEEE Transactions on Pattern Analysis and Machine Intelligence, 35 (8), pp. 1798-1828. , 2; Cao, K., Jain, A.K., (2016) Hacking Mobile Phones Using 2d Printed Fingerprints, , https://www.youtube.com/watch?v=fZJI_BrMZXU&feature=youtu.be, 1; Cheng, Y., Larin, K.V., Artificial fingerprint recognition by using optical coherence tomography with autocorrelation analysis (2006) Applied Optics, 45 (36), pp. 9238-9245. , 2; Chugh, T., Cao, K., Jain, A.K., Fingerprint spoof buster: Use of minutiae-centered patches (2018) IEEE Transactions on Information Forensics and Security, 13 (9), pp. 2190-2202. , 1, 2, 4, 6; Chugh, T., Jain, A.K., (2018) Fingerprint Presentation Attack Detection: Generalization and Efficiency, , 2; Chugh, T., Jain, A.K., (2019) Fingerprint Spoof Generalization, , 2, 5, 6, 7, 8; Chugh, T., Jain, A.K., (2019) Oct Fingerprints: Resilience to Presentation Attacks., , 2; Csurka, G., (2017) Domain Adaptation for Visual Applications: A Comprehensive Survey, , 3; Ding, Y., Ross, A., An ensemble of one-class svms for fingerprint spoof detection across different fabrication materials (2016) 2016 IEEE International Workshop on Information Forensics and Security (WIFS), pp. 1-6. , 2; Edwards, H., Storkey, A., (2015) Censoring Representations with An Adversary, , 3; Engelsma, J.J., Arora, S.S., Jain, A.K., Paulter, N.G., Universal 3d wearable fingerprint targets: Advancing fingerprint reader evaluations (2018) IEEE Transactions on Information Forensics and Security, 13 (6), pp. 1564-1578. , 1; Engelsma, J.J., Cao, K., Jain, A.K., Raspireader: Open source fingerprint reader (2018) IEEE Transactions on Pattern Analysis and Machine Intelligence, 41 (10), pp. 2511-2524. , 1; Engelsma, J.J., Jain, A.K., Generalizing fingerprint spoof detector: Learning a one-class classifier (2019) 2019 International Conference on Biometrics (ICB), , 2; Evans, N., (2019) Handbook of Biometric Anti-spoofing: Presentation Attack Detection, , 1. Springer; Gajawada, R., Popli, A., Chugh, T., Namboodiri, A., Jain, A.K., Universal material translator: Towards spoof fingerprint generalization (2019) 2019 International Conference on Biometrics (ICB), , 2; Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette, F., Marchand, M., Lempitsky, V., Domainadversarial training of neural networks (2016) The Journal of Machine Learning Research, 17 (1), pp. 2030-2096. , 3; Ghiani, L., Hadid, A., Marcialis, G.L., Roli, F., Fingerprint liveness detection using binarized statistical image features (2013) 2013 IEEE Sixth International Conference on Biometrics: Theory, Applications and Systems (BTAS), pp. 1-6. , 2; Ghiani, L., Marcialis, G.L., Roli, F., Fingerprint liveness detection by local phase quantization (2012) Proceedings of the 21st International Conference on Pattern Recognition, pp. 537-540. , 2; Ghiani, L., Yambay, D., Mura, V., Tocco, S., Marcialis, G.L., Roli, F., Schuckcrs, S., Livdet 2013 fingerprint liveness detection competition 2013 (2013) 2013 International Conference on Biometrics (ICB), pp. 1-6. , 1; González-Soler, L.J., Gomez-Barrero, M., Chang, L., Pérez-Suárez, A., Busch, C., (2019) Fingerprint Presentation Attack Detection Based on Local Features Encoding for Unknown Attacks, , 2; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, pp. 2672-2680. , 3; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778. , 6, 7; Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H., (2017) Mobilenets: Efficient Convolutional Neural Networks for Mobile Vision Applications, , 4, 7, 8; Information Technology-Biometric Presentation Attack Detection-Part 1: Framework, , https://www.iso.org/standard/53227.html.1, International Standards Organization iso/iec 30107-1 2016; Khutlang, R., Khanyile, N.P., Makinana, S., Nelwamondo, F.V., High resolution feature extraction from optical coherence tomography acquired internal fingerprint (2016) 2016 17th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/ Distributed Computing (SNPD), pp. 637-641. , 2. IEEE; Lapsley, P.D., Lee, J.A., Pare, D.F., Jr., Hoffman, N., (1998) Antifraud Biometric Scanner That Accurately Detects Blood Flow, , Apr 7; Maaten L, V.D., Hinton, G., Visualizing data using t-sne (2008) Journal of Machine Learning Research, 9, pp. 2579-2605. , 6 (Nov); Maltoni, D., Maio, D., Jain, A.K., Prabhakar, S., (2009) Handbook of Fingerprint Recognition, , 1. Springer Science & Business Media, 2nd edition; Marasco, E., Ross, A., A survey on antispoofing schemes for fingerprint recognition systems (2014) ACM Computing Surveys, 47 (2), pp. 1-36. , 1; Marasco, E., Sansone, C., On the robustness of fingerprint liveness detection algorithms against new materials used for spoofing (2011) BIOSIGNALS, 8, pp. 553-555. , 2; Marasco, E., Sansone, C., Combining perspiration-and morphology-based static features for fingerprint liveness detection (2012) Pattern Recognition Letters, 33 (9), pp. 1148-1156. , 2; Marcialis, G.L., Lewicke, A., Tan, B., Coli, P., Grimberg, D., Congiu, A., Tidu, A., Schuckers, S., First international fingerprint liveness detection competition-livdet 2009 (2009) International Conference on Image Analysis and Processing, pp. 12-23. , 1. Springer; Marcialis, G.L., Roli, F., Tidu, A., Analysis of fingerprint pores for vitality detection (2010) 2010 20th International Conference on Pattern Recognition, pp. 1289-1292. , 2; Matsumoto, T., Matsumoto, H., Yamada, K., Hoshino, S., Impact of artificial"" gummy"" fingers on fingerprint systems (2002) Optical Security and Counterfeit Deterrence Techniques IV, 4677, pp. 275-289. , 1; Mura, V., Ghiani, L., Marcialis, G.L., Roli, F., Yambay, D.A., Schuckers, S.A., Livdet 2015 fingerprint liveness detection competition 2015 (2015) 2015 International Conference on Biometrics Theory, Applications, and Systems, , 1; Mura, V., Orrù, G., Casula, R., Sibiriu, A., Loi, G., Tuveri, P., Ghiani, L., Marcialis, G.L., Livdet 2017 fingerprint liveness detection competition 2017 (2018) 2018 International Conference on Biometrics (ICB), pp. 297-302. , 1; Nogueira, R.F., De Lotufo Alencar, R., Machado, R.C., Fingerprint liveness detection using convolutional neural networks (2016) IEEE Transactions on Information Forensics and Security, 11 (6), pp. 1206-1213. , 2; IARPA-BAA-16-04, , https://www.iarpa.gov/index.php/research-programs/odin/odin-baa, ODNI, IARPA. 1; Orrù, G., Casula, R., Tuveri, P., Bazzoni, C., Dessalvi, G., Micheletto, M., Ghiani, L., Marcialis, G.L., (2019) Livdet in Action-fingerprint Liveness Detection Competition 2019, , 1; Pala, F., Bhanu, B., Deep triplet embedding representations for liveness detection (2017) Deep Learning for Biometrics, pp. 287-307. , 2. Springer; Rattani, A., Scheirer, W.J., Ross, A., Open set fingerprint spoof detection across, Novel fabrication materials (2015) IEEE Transactions on Information Forensics and Security, 10 (11), pp. 2447-2460. , 2; Roy, P.C., Boddeti, V.N., Mitigating information leakage in image representations: A maximum entropy approach (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2586-2594. , 4; Sousedik, C., Busch, C., Quality of fingerprint scans captured using optical coherence tomography (2014) IEEE International Joint Conference on Biometrics, pp. 1-8. , 2. IEEE; Tan, B., Lewicke, A., Yambay, D., Schuckers, S., The effect of environmental conditions and, Novel spoofing methods on fingerprint anti-spoofing algorithms (2010) 2010 IEEE International Workshop on Information Forensics and Security, pp. 1-6. , 2; Tolosana, R., Gomez-Barrero, M., Busch, C., Ortega-Garcia, J., Biometric presentation attack detection: Beyond the visible spectrum (2019) IEEE Transactions on Information Forensics and Security, 15, pp. 1261-1275. , 2; Tzeng, E., Hoffman, J., Saenko, K., Darrell, T., Adversarial discriminative domain adaptation (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 7167-7176. , 3; Wang, M., Deng, W., Deep visual domain adaptation: A survey (2018) Neurocomputing, 312, pp. 135-153. , 3; Xie, Q., Dai, Z., Du, Y., Hovy, E., Neubig, G., Controllable invariance through adversarial feature learning (2017) Advances in Neural Information Processing Systems, pp. 585-596. , 3; Yambay, D., Ghiani, L., Denti, P., Marcialis, G.L., Roli, F., Schuckers, S., Livdet 2011-fingerprint liveness detection competition 2011 (2012) 2012 5th IAPR International Conference on Biometrics (ICB), pp. 208-215. , 1; Yoon, S., Feng, J., Jain, A.K., Altered fingerprints: Analysis and detection (2012) IEEE Transactions on Pattern Analysis and Machine Intelligence, 34 (3), pp. 451-464. , 1; Zhang, B.H., Lemoine, B., Mitchell, M., Mitigating unwanted biases with adversarial learning (2018) Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society, pp. 335-340. , 3",,,,Institute of Electrical and Electronics Engineers Inc.,"2020 IEEE/IAPR International Joint Conference on Biometrics, IJCB 2020",28 September 2020 through 1 October 2020,,166343,,9.78E+12,,,English,IJCB - IEEE/IAPR Int. Jt. Conf. Biom.,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85095479159
"Tang J., Wen H., Wang K.",57192395903;57193576489;57216775922;,Revisiting Adversarially Learned Injection Attacks against Recommender Systems,2020,RecSys 2020 - 14th ACM Conference on Recommender Systems,,,,318,327,,7,10.1145/3383313.3412243,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092713653&doi=10.1145%2f3383313.3412243&partnerID=40&md5=50e4092edcdc6562ca7cd8d72c5e36ca,"Simon Fraser University, Canada; Cornell Tech, Cornell University, United States","Tang, J., Simon Fraser University, Canada; Wen, H., Cornell Tech, Cornell University, United States; Wang, K., Simon Fraser University, Canada","Recommender systems play an important role in modern information and e-commerce applications. While increasing research is dedicated to improving the relevance and diversity of the recommendations, the potential risks of state-of-the-art recommendation models are under-explored, that is, these models could be subject to attacks from malicious third parties, through injecting fake user interactions to achieve their purposes. This paper revisits the adversarially-learned injection attack problem, where the injected fake user 'behaviors' are learned locally by the attackers with their own model - one that is potentially different from the model under attack, but shares similar properties to allow attack transfer. We found that most existing works in literature suffer from two major limitations: (1) they do not solve the optimization problem precisely, making the attack less harmful than it could be, (2) they assume perfect knowledge for the attack, causing the lack of understanding for realistic attack capabilities. We demonstrate that the exact solution for generating fake users as an optimization problem could lead to a much larger impact. Our experiments on a real-world dataset reveal important properties of the attack, including attack transferability and its limitations. These findings can inspire useful defensive methods against this possible existing attack. © 2020 ACM.",Adversarial Machine Learning; Recommender System; Security and Privacy,Behavioral research; Optimization; Recommender systems; Attack capability; E-Commerce applications; Exact solution; Optimization problems; Potential risks; State of the art; Third parties; User interaction; Electronic commerce,,,,,"Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Isard, M., Tensorflow: A System for Large-scale Machine Learning, , [n. d. ]; Bao, J., Zheng, Y., Mokbel, M.F., Location-based and preferenceaware recommendation using sparse geo-social networking data (2012) Proceedings of the 20th International Conference on Advances in Geographic Information Systems; Günes Baydin, A., Pearlmutter, B.A., Andreyevich Radul, A., Mark Siskind, J., Automatic differentiation in machine learning: A survey (2017) The Journal of Machine Learning Research, 18 (1), pp. 5595-5637; Biggio, B., Fumera, G., Roli, F., Security evaluation of pattern classifiers under attack (2013) IEEE Transactions on Knowledge and Data Engineering, 26 (4), pp. 984-996; Burke, R., Mobasher, B., Bhaumik, R., (2005) Limited Knowledge Shilling Attacks in Collaborative Filtering Systems; Burke, R., O'Mahony, M.P., Hurley, N.J., Robust collaborative recommendation (2015) Recommender Systems Handbook, pp. 961-995. , Springer; Castillo, C., Davison, B.D., Adversarial web search (2011) Foundations and TrendsR in Information Retrieval, 4 (5), pp. 377-486; Chen, Y., Chen, B., He, X., Gao, C., Li, Y., Lou, J.-G., Wang, Y., Opt: Learn to regularize recommender models in finer levels (2019) ACM SIGKDD International Conference on Knowledge Discovery and Data Mining; Cheng, H.-T., Koc, L., Harmsen, J., Shaked, T., Chandra, T., Aradhye, H., Anderson, G., Ispir, M., Wide & deep learning for recommender systems (2016) Proceedings of the 1st Workshop on Deep Learning for Recommender Systems. ACM, pp. 7-10; Cho, E., Myers, S.A., Leskovec, J., Friendship and mobility: User movement in location-based social networks (2011) ACM SIGKDD International Conference on Knowledge Discovery and Data Mining., pp. 1082-1090; Christakopoulou, K., Banerjee, A., Adversarial attacks on an oblivious recommender (2019) Proceedings of the 13th ACM Conference on Recommender Systems. ACM, pp. 322-330; Colson, B., Marcotte, P., Savard, G., An overview of bilevel optimization (2007) Annals of Operations Research, 153 (1), pp. 235-256; Fang, M., Zhenqiang Gong, N., Liu, J., Influence function based data poisoning attacks to top-n recommender systems (2020) Proceedings of the Web Conference 2020., pp. 3019-3025; Fang, M., Yang, G., Zhenqiang Gong, N., Liu, J., Poisoning attacks to graph-based recommender systems (2018) Proceedings of the 34th Annual Computer Security Applications Conference. ACM, pp. 381-392; Finn, C., Abbeel, P., Levine, S., Model-agnostic metalearning for fast adaptation of deep networks (2017) Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. Org, pp. 1126-1135; Franceschi, L., Frasconi, P., Salzo, S., Grazzi, R., Pontil, M., (2018) Bilevel Programming for Hyperparameter Optimization and Metalearning; Goodfellow, I., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Grefenstette, E., Amos, B., Yarats, D., Mon Htut, P., Molchanov, A., Meier, F., Kiela, D., Chintala, S., (2019) Generalized Inner Loop Meta-Learning; He, X., Liao, L., Zhang, H., Nie, L., Hu, X., Chua, T.-S., Neural collaborative filtering (2017) International Conference on World Wide Web. ACM, pp. 173-182; Hsieh, C.-K., Yang, L., Cui, Y., Lin, T.-Y., Belongie, S., Estrin, D., Collaborative metric learning (2017) International Conference on World Wide Web. ACM, pp. 193-201; Hu, Y., Koren, Y., Volinsky, C., Collaborative filtering for implicit feedback datasets (2008) International Conference on Data Mining. IEEE; Kingma, D., Ba, J., (2014) Adam: A Method for Stochastic Optimization; Koren, Y., Bell, R., Volinsky, C., Matrix factorization techniques for recommender systems (2009) Computer, 42, p. 8; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World; Lam, S.K., Riedl, J., Shilling recommender systems for fun and profit (2004) International Conference on World Wide Web. ACM; Li, B., Wang, Y., Singh, A., Vorobeychik, Y., Data poisoning attacks on factorization-based collaborative filtering (2016) Advances in Neural Information Processing Systems., pp. 1885-1893; Liang, D., Krishnan, R.G., Hoffman, M.D., Jebara, T., Variational autoencoders for collaborative filtering (2018) Proceedings of the 2018 World Wide Web Conference on World Wide Web., pp. 689-698; Mehta, B., Hofmann, T., A survey of attack-resistant collaborative filtering algorithms (2008) IEEE Data Eng. Bull, 31 (2), pp. 14-22; Mei, S., Zhu, X., (2015) Using Machine Teaching to Identify Optimal Training-Set Attacks on Machine Learners; Miao, C., Li, Q., Su, L., Huai, M., Jiang, W., Gao, J., Attack under disguise: An intelligent data poisoning attack mechanism in crowdsourcing (2018) International Conference on World Wide Web. International World Wide Web Conferences Steering Committee, pp. 13-22; Muñoz-González, L., Biggio, B., Demontis, A., Paudice, A., Wongrassamee, V., Lupu, E.C., Roli, F., Towards poisoning of deep learning algorithms with back-gradient optimization (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security., pp. 27-38; Pan, R., Zhou, Y., Cao, B., Liu, N.N., Lukose, R., Scholz, M., Yang, Q., One-class collaborative filtering (2008) International Conference on Data Mining. IEEE, pp. 502-511; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security. ACM, pp. 506-519; Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Antiga, L., Pytorch: An imperative style, high-performance deep learning library (2019) Advances in Neural Information Processing Systems., pp. 8024-8035; Rajeswaran, A., Finn, C., Kakade, S.M., Levine, S., Meta-learning with implicit gradients (2019) Advances in Neural Information Processing Systems., pp. 113-124; Rendle, S., Freudenthaler, C., Gantner, Z., Schmidt-Thieme, L., Bpr: Bayesian personalized ranking from implicit feedback (2009) Conference on Uncertainty in Artificial Intelligence, pp. 452-461. , AUAI Press; Sarwar, B., Karypis, G., Konstan, J., Riedl, J., Item-based collaborative filtering recommendation algorithms (2001) International Conference on World Wide Web. ACM, pp. 285-295; Sedhain, S., Krishna Menon, A., Sanner, S., Xie, L., Autorec: Autoencoders meet collaborative filtering (2015) International Conference on World Wide Web. ACM, pp. 111-112; Steinhardt, J., Wei, P.K.W, Liang, P.S., Certified defenses for data poisoning attacks (2017) Advances in Neural Information Processing Systems., pp. 3517-3529; Tang, J., Wang, K., Personalized top-n sequential recommendation via convolutional sequence embedding (2018) International Conference on Web Search and Data Mining. IEEE, pp. 565-573; Zhu, Z., Wang, J., Caverlee, J., Improving top-k recommendation via jointcollaborative autoencoders (2019) The World Wide Web Conference., pp. 3482-3483; Zügner, D., Akbarnejad, A., Günnemann, S., (2018) Adversarial Attacks on Classification Models for Graphs",,,"ACM Special Interest Group on Artificial Intelligence (SIGAI);ACM Special Interest Group on Computer-Human Interaction (SIGCHI);ACM Special Interest Group on Hypertext, Hypermedia, and Web (SIGWEB);ACM Special Interest Group on Information Retrieval (SIGIR);ACM Special Interest Group on Knowledge Discovery in Data (SIGKDD);Special Interest Group on Economics and Computation (SIGecom)","Association for Computing Machinery, Inc","14th ACM Conference on Recommender Systems, RecSys 2020",22 September 2020 through 26 September 2020,,163195,,9.78E+12,,,English,RecSys - ACM Conf. Recomm. Syst.,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85092713653
"Byra M., Styczynski G., Szmigielski C., Kalinowski P., Michalowski L., Paluszkiewicz R., Ziarkiewicz-Wroblewska B., Zieniewicz K., Nowicki A.",56414988400;6602523216;6508277122;23473323700;56764490600;56251293600;6603594205;7004549325;56214353800;,Adversarial attacks on deep learning models for fatty liver disease classification by modification of ultrasound image reconstruction method,2020,"IEEE International Ultrasonics Symposium, IUS",2020-September,,9251568,,,,,10.1109/IUS46767.2020.9251568,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097873243&doi=10.1109%2fIUS46767.2020.9251568&partnerID=40&md5=538bae09e01f69d12495795e551d98ac,"Department of Ultrasound, Institute of Fundamental Technological Research, Polish Academy of Sciences, Warsaw, Poland; Department of Internal Medicine, Hypertension and Vascular Diseases, Medical University of Warsaw, Poland; Department of General, Transplant and Liver Surgery, Medical University of Warsaw, Poland; Department of Pathology, Center for Biostructure Research, Medical University of Warsaw, Poland","Byra, M., Department of Ultrasound, Institute of Fundamental Technological Research, Polish Academy of Sciences, Warsaw, Poland; Styczynski, G., Department of Internal Medicine, Hypertension and Vascular Diseases, Medical University of Warsaw, Poland; Szmigielski, C., Department of Internal Medicine, Hypertension and Vascular Diseases, Medical University of Warsaw, Poland; Kalinowski, P., Department of General, Transplant and Liver Surgery, Medical University of Warsaw, Poland; Michalowski, L., Department of Pathology, Center for Biostructure Research, Medical University of Warsaw, Poland; Paluszkiewicz, R., Department of General, Transplant and Liver Surgery, Medical University of Warsaw, Poland; Ziarkiewicz-Wroblewska, B., Department of Pathology, Center for Biostructure Research, Medical University of Warsaw, Poland; Zieniewicz, K., Department of General, Transplant and Liver Surgery, Medical University of Warsaw, Poland; Nowicki, A., Department of Ultrasound, Institute of Fundamental Technological Research, Polish Academy of Sciences, Warsaw, Poland","Convolutional neural networks (CNNs) have achieved remarkable success in medical image analysis tasks. In ultrasound (US) imaging, CNNs have been applied to object classification, image reconstruction and tissue characterization. However, CNNs can be vulnerable to adversarial attacks, even small perturbations applied to input data may significantly affect model performance and result in wrong output. In this work, we devise a novel adversarial attack, specific to ultrasound (US) imaging. US images are reconstructed based on radio-frequency signals. Since the appearance of US images depends on the applied image reconstruction method, we explore the possibility of fooling deep learning model by perturbing US B-mode image reconstruction method. We apply zeroth order optimization to find small perturbations of image reconstruction parameters, related to attenuation compensation and amplitude compression, which can result in wrong output. We illustrate our approach using a deep learning model developed for fatty liver disease diagnosis, where the proposed adversarial attack achieved success rate of 48%. © 2020 IEEE.",Adversarial attacks; Deep learning; Fatty liver; Transfer learning; Ultrasound imaging,Convolutional neural networks; Deep learning; Diagnosis; Diseases; Image classification; Learning systems; Medical imaging; Ultrasonics; Amplitude compression; Attenuation compensation; Image reconstruction methods; Object classification; Radiofrequency signals; Reconstruction parameters; Small perturbations; Tissue characterization; Image reconstruction,,,,,"Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Akhtar, N., Mian, A., Threat of adversarial attacks on deep learning in computer vision: A survey (2018) Ieee Access, 6, pp. 14410-14430; Qiu, S., Liu, Q., Zhou, S., Wu, C., Review of artificial intelligence adversarial attack and defense technologies (2019) Applied Sciences, 9 (5), p. 909; Byra, M., Wan, L., Wong, J.H., Du, J., Shah, S.B., Andre, M.P., Chang, E.Y., Quantitative ultrasound and b-mode image texture features correlate with collagen and myelin content in human ulnar nerve fascicles (2019) Ultrasound in Medicine &Biology, 45 (7), pp. 1830-1840; Byra, M., Sznajder, T., Korzinek, D., Piotrzkowska-Wroblewska, H., Dobruch-Sobczak, K., Nowicki, A., Marasek, K., Impact of ultrasound image reconstruction method on breast lesion classification with deep learning (2019) Iberian Conference on Pattern Recognition and Image Analysis. Springer, pp. 41-52; Gómez-Flores, W., Hernández-López, J., Assessment of the invariance and discriminant power of morphological features under geometric transformations for breast tumor classification (2020) Computer Methods and Programs in Biomedicine, 185, p. 105173; Finlayson, S.G., Chung, H.W., Kohane, I.S., Beam, A.L., (2018) Adversarial Attacks against Medical Deep Learning Systems; Beeman, S., Garbow, J., (2018) Imaging and Metabolism; Wong, V.W.-S., Adams, L.A., De Lédinghen, V., Wong, G.L.-H., Sookoian, S., Noninvasive biomarkers in nafld and nash-current progress and future promise (2018) Nature Reviews Gastroenterology &Hepatology, 15 (8), pp. 461-478; Byra, M., Styczynski, G., Szmigielski, C., Kalinowski, P., Michalowski, L., Paluszkiewicz, R., Ziarkiewicz-Wróblewska, B., Nowicki, A., Transfer learning with deep convolutional neural network for liver steatosis assessment in ultrasound images (2018) International Journal of Computer Assisted Radiology and Surgery, 13 (12), pp. 1895-1903; Han, A., Byra, M., Heba, E., Andre, M.P., Erdman, J.W., Jr., Loomba, R., Sirlin, C.B., O'Brien, W.D., Jr., Noninvasive diagnosis of nonalcoholic fatty liver disease and quantification of liver fat with radiofrequency ultrasound data using one-dimensional convolutional neural networks (2020) Radiology, 295 (2), pp. 342-350; Cao, W., An, X., Cong, L., Lyu, C., Zhou, Q., Guo, R., Application of deep learning in quantitative analysis of 2-dimensional ultrasound imaging of nonalcoholic fatty liver disease (2020) Journal of Ultrasound in Medicine, 39 (1), pp. 51-59; Han, A., Zhang, Y.N., Boehringer, A.S., Andre, M.P., Erdman, J.W., Loomba, R., Sirlin, C.B., O'Brien, W.D., Inter-platform reproducibility of ultrasonic attenuation and backscatter coefficients in assessing nafld (2019) European Radiology, 29 (9), pp. 4699-4708; Han, A., Zhang, Y.N., Boehringer, A.S., Montes, V., Andre, M.P., Erdman, J.W., Jr., Loomba, R., O'Brien, W.D., Jr., Assessment of hepatic steatosis in nonalcoholic fatty liver disease by using quantitative us (2020) Radiology, 295 (1), pp. 106-113; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Fei-Fei, L., ImageNet large scale visual recognition challenge (2015) International Journal of Computer Vision (IJCV), 115 (3), pp. 211-252; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., Inception-v4, inception-resnet and the impact of residual connections on learning (2017) Thirty-First Aaai Conference on Artificial Intelligence; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) Proceedings of the 10th Acm Workshop on Artificial Intelligence and Security, pp. 15-26; Liu, S., Chen, P.-Y., Chen, X., Hong, M., Signsgd via zeroth-order oracle (2018) International Conference on Learning Representations; Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Isard, M., Tensorflow: A system for largescale machine learning (2016) 12th FUSENIXg Symposium on Operating Systems Design and Implementation (FOSDIg 16), pp. 265-283","Byra, M.; Department of Ultrasound, Poland; 电子邮件: byra.michal@gmail.com",,"Daxsonics Ultrasound;et al.;Fujifilm VisualSonics, Inc;Polytec;us4us Ltd.;Verasonics",IEEE Computer Society,"2020 IEEE International Ultrasonics Symposium, IUS 2020",7 September 2020 through 11 September 2020,,165031,19485719,9.78E+12,,,English,"IEEE Int. Ultrason. Symp., IUS",Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85097873243
"Liao Y., Zhuang W., Huang L., Liu N.",57227984000;57228354300;56566977100;55040727400;,Improve the Robustness of Deep Learning Models against Adversarial Attacks in Judicial Field,2020,"Proceedings - 8th International Conference on Digital Home, ICDH 2020",,,9457269,197,202,,,10.1109/ICDH51081.2020.00041,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113314498&doi=10.1109%2fICDH51081.2020.00041&partnerID=40&md5=97c968839e7f5403074965a0bac075a6,"Sun Yat-sen University, School of Data and Computer Science, China; Guangdong Key Laboratory of Information Security Technology, China","Liao, Y., Sun Yat-sen University, School of Data and Computer Science, China; Zhuang, W., Sun Yat-sen University, School of Data and Computer Science, China; Huang, L., Sun Yat-sen University, School of Data and Computer Science, China, Guangdong Key Laboratory of Information Security Technology, China; Liu, N., Sun Yat-sen University, School of Data and Computer Science, China, Guangdong Key Laboratory of Information Security Technology, China","With the rapid development of deep neural networks (DNNs), they have been applied in various domains including crowd counting, object detection and digital forensic. Consequently, DNN-based forensic process plays an essential role in judicial field, which will simplify the trial procedure in real world as well as cut down the workload of criminal case judgment. Apart from manipulating the visual forensic evidence (i.e., digital images) by existing editing softwares, malicious adversarial attacks can also pose a series threat for DNN-based trial system. In general, by adding some imperceptible perturbations to generate the adversarial forensic evidence, DNN-based trial system may output totally wrong results. To this end, we propose an adversarial fine-tuned training (AFT) method to improve the robustness of deep learning models for defensing against black-box adversarial attacks in judicial process (e.g. digital forensic). Concretely, we utilize both query-based attackers and transfer-based enemies to generate a set of adversarial examples at first, and then mix up both clean and perturbed data as training set to specific fine-tuned layers of models. Base on this training manner, the generated models not only can improve the robustness to resist adversarial examples, but also reduce the computational cost since only parts of parameters need to be retrained. Extensive experiments on both two pre-trained vanilla models and three defensive models demonstrate the efficacy of our proposed method to tackle the adversarial attacks and potential value in digital court system. © 2020 IEEE.",adversarial attack; deep learning; digital forensic; judicial; robustness; trial,Computer crime; Deep neural networks; Digital devices; Digital forensics; Electronic crime countermeasures; Forensic engineering; Learning systems; Object detection; Computational costs; Court systems; Criminal case judgments; Forensic evidence; Forensic process; Judicial process; Learning models; Potential values; Deep learning,,,,,"Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2014) ArXiv Preprint arXiv:1409 1556; Li, S., Zhang, H., Ye, L., Guo, X., Fang, B., Evaluating the rationality of judicial decision with lstm-based case modeling. In (2018) 2018 IEEE Third International Conference on Data Science in Cyberspace (DSC, pp. 392-397; Elnaggar, A., Gebendorfer, C., Glaser, I., Matthes, F., Multi-Task deep learning for legal document translation, summarization and multi-label classification. In Proceedings of the 2018 Artificial Intelligence and Cloud Computing Conference, 2018, pp. 9-15; Perez-Rosas, V., Abouelenien, M., Mihalcea, R., Burzo, M., Deception detection using real-life trial data. In (2015) Proceedings of the 2015 ACM on International Conference on Multimodal Interaction, pp. 59-66; Kang, H., Kang, H., Prediction of crime occurrence from multi-modal data using deep learning (2017) PloS One, 12, p. 4; Deeks, A., The judicial demand for explainable artificial intelligence (2019) Columbia Law Review, 119 (7), pp. 1829-1850; Wei, F., Qin, H., Ye, S., Zhao, H., Empirical study of deep learning for text classification in legal document review. In 2018 IEEE International Conference on Big Data (Big Data, 2018, pp. 3317-3320; Fernandes, K., Cardoso, J.S., Schmidt Astrup, B., A deep learning approach for the forensic evaluation of sexual assault (2018) Pattern Analysis and Applications, 21 (3), pp. 629-640; Udaya Sameer, V., Naskar, R., Musthyala, N., Kokkalla, K., Deep learning based counter-forensic image classification for camera model identification. In (2017) International Workshop on Digital Watermarking, pp. 52-64. , Springer; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2013) ArXiv Preprint arXiv:1312 6199; Aditya, K., Grzonkowski, S., An Lekhac, N., Enabling trust in deep learning models: A digital forensics case study. In (2018) 2018 17th IEEE International Conference on Trust, Security and Privacy in Computing and Communications/12th IEEE International Conference on Big Data Science and Engineering TrustCom/BigDataSE, pp. 1250-1255; Nitin Bhagoji, A., He, W., Li, B., Song, D., Practical black-box attacks on deep neural networks using efficient query mechanisms. In (2018) European Conference on Computer Vision, pp. 158-174. , Springer; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2017) ArXiv Preprint arXiv:1706 06083; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., Mitigating adversarial effects through randomization (2017) ArXiv Preprint ArXiv 1711 01991; Tramer, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2017) ArXiv Preprint arXiv:1705 07204; Xie, C., Wu, Y., Van Der Maaten, L., Yuille, A.L., He, K., Feature denoising for improving adversarial robustness. In (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 501-509; Ilyas, A., Engstrom, L., Athalye, A., Lin, J., Black-box adversarial attacks with limited queries and information (2018) ArXiv Preprint ArXiv 1804 08598; Dong, Y., Pang, T., Su, H., Zhu, J., Evading defenses to transferable adversarial examples by translationinvariant attacks. In (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4312-4321; Ren, S., He, K., Girshick, R., Sun, J., Faster r-cnn: Towards real-Time object detection with region proposal networks: Towards (2015) Advances in Neural Information Processing Systems, pp. 91-99; Liu, N., Long, Y., Zou, C., Niu, Q., Pan, L., Wu, H., Adcrowdnet: An attention-injective deformable convolutional network for crowd understanding. In (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3225-3234; Zampoglou, M., Markatopoulou, F., Mercier, G., Touska, D., Apostolidis, E., Papadopoulos, S., Cozien, R., Kompatsiaris, I., Detecting tampered videos with multimedia forensics and deep learning. In (2019) International Conference on Multimedia Modeling, pp. 374-386. , Springer; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum. In (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 9185-9193; Xie, C., Zhang, Z., Zhou, Y., Bai, S., Wang, J., Ren, Z., Yuille, A.L., Improving transferability of adversarial examples with input diversity. In (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2730-2739; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision. In (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., Inception-v4, inception-resnet and the impact of residual connections on learning. In (2017) Thirty-first AAAI Conference on Artificial Intelligence; Tu, C., Ting, P., Chen, P., Liu, S., Zhang, H., Yi, J., Hsieh, C., Cheng, S., Autozoom: Autoencoder-based zeroth order optimization method for attacking black-box neural networks. In (2019) Proceedings of the AAAI Conference on Artificial Intelligence, 33, pp. 742-749","Liu, N.; Sun Yat-sen University, China; 电子邮件: liuning2@mail.sysu.edu.cn",,,Institute of Electrical and Electronics Engineers Inc.,"8th International Conference on Digital Home, ICDH 2020",20 September 2020 through 22 September 2020,,170941,,9.78E+12,,,English,"Proc. - Int. Conf. Digit. Home, ICDH",Conference Paper,Final,,Scopus,2-s2.0-85113314498
"Mangaokar N., Pu J., Bhattacharya P., Reddy C.K., Viswanath B.",57220022457;57219173573;55954244800;12752116500;35793888500;,Jekyll: Attacking Medical Image Diagnostics using Deep Generative Models,2020,"Proceedings - 5th IEEE European Symposium on Security and Privacy, Euro S and P 2020",,,9230370,139,157,,2,10.1109/EuroSP48549.2020.00017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096549146&doi=10.1109%2fEuroSP48549.2020.00017&partnerID=40&md5=4f76b7f5d932a127e42cc5f27ff5cec1,"Virginia Tech, United States; University of Virginia, United States","Mangaokar, N., Virginia Tech, United States; Pu, J., Virginia Tech, United States; Bhattacharya, P., University of Virginia, United States; Reddy, C.K., Virginia Tech, United States; Viswanath, B., Virginia Tech, United States","Advances in deep neural networks (DNNs) have shown tremendous promise in the medical domain. However, the deep learning tools that are helping the domain, can also be used against it. Given the prevalence of fraud in the healthcare domain, it is important to consider the adversarial use of DNNs in manipulating sensitive data that is crucial to patient healthcare. In this work, we present the design and implementation of a DNN-based image translation attack on biomedical imagery. More specifically, we propose Jekyll, a neural style transfer framework that takes as input a biomedical image of a patient and translates it to a new image that indicates an attacker-chosen disease condition. The potential for fraudulent claims based on such generated 'fake' medical images is significant, and we demonstrate successful attacks on both X-rays and retinal fundus image modalities. We show that these attacks manage to mislead both medical professionals and algorithmic detection schemes. Lastly, we also investigate defensive measures based on machine learning to detect images generated by Jekyll. © 2020 IEEE.",attacks; deep learning; defenses; generative models; medical image diagnostics,Deep learning; Deep neural networks; Diagnosis; Health care; Privacy by design; Biomedical imagery; Biomedical images; Defensive measures; Design and implementations; Healthcare domains; Image translation; Medical professionals; Retinal fundus images; Medical imaging,,,,,"Brundage, M., Avin, S., Clark, J., Toner, H., Eckersley, P., Garfinkel, B., Dafoe, A., Amodei, D., The malicious use of artificial intelligence: Forecasting, prevention, and mitigation (1802) CoRR Abs/, 7228, p. 2018; OSullivan, D., (2019) When Seeing Is No Longer Believing, , https://www.cnn.com/interactive/2019/01/business/pentagons-race-Against-deepfakes/; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Proc. Of Nips; Karras, T., Aila, T., Laine, S., Lehtinen, J., Progressive growing of gans for improved quality, stability, and variation Proc. Of Iclr, 2018; Karras, T., Laine, S., Aila, T., A style-based generator architecture for generative adversarial networks Proc. Of Cvpr, 2018; Vondrick, C., Pirsiavash, H., Torralba, A., Generating videos with scene dynamics Proc. Of NeurIPS, 2016; Christopher, N., (2020) We?ve Just Seen the First Use of Deepfakes in An Indian Election Campaign, , https://www.vice.com/enin/article/jgedjb/the-first-useof-deepfakes-in-indian-election-by-bjp; Finlayson, S.G., Bowers, J.D., Ito, J., Zittrain, J.L., Beam, A.L., Kohane, I.S., Adversarial attacks on medical machine learning Science, 363 (2019), pp. 1287-1289; Al-Mawali, A., Idikula, J., Pinto, A.D., Fraud and misconduct in clinical research: A step to improve ethical practice in research Journal of Contemporary Medical Sciences, 4, p. 2018; Morris, L., Combating fraud in health care: An essential component of any cost containment strategy (2009) Health Affairs, 28, pp. 1351-1356; Rashidian, A., Joudaki, H., Vian, T., No evidence of the effect of the interventions to combat health care fraud and abuse: A systematic review of literature (2012) PloS One, 7; Bauder, R.A., Khoshgoftaar, T.M., Medicare fraud detection using machine learning methods Proc. Of Icmla, 2017; Herland, M., Khoshgoftaar, T.M., Bauder, R.A., Big data fraud detection using multiple medicare data sources Journal of Big Data, 5 (2018), p. 29; Beek, C., Mcafee Researchers Find Poor Security Exposes Medical Data to Cybercriminals, , https://www.mcafee.com/blogs/other-blogs/other-blogs/mcafeelabs/mcafee-researchers-find-poor-security-exposes-medical-datato-cybercriminals/, Mar 2018; (2018) Verizon Protected Health Information Data Breach Report, , https://enterprise.verizon.com/resources/reports/protected.health.information.data.breach.report.pdf; Mirsky, Y., Mahler, T., Shelef, I., Elovici, Y., Ct-gan: Malicious tampering of 3d medical imagery using deep learning Proc. Of Usenix Security Symposium, 2019; Rajpurkar, P., Irvin, J., Zhu, K., Yang, B., Mehta, H., Duan, T., Ding, D., Shpanskaya, K., Chexnet: Radiologist-level pneumonia detection on chest x-rays with deep learning CoRR abs/1711, 5225, p. 2017; Osborne, C., Ibm-Takes-on-Alzheimers-disease-with-machinelearning (2019), https://www.zdnet.com/article/ibm-Takes-on-Alzheimers-disease-with-machine-learning/; Jo, T., Nho, K., Saykin, A.J., Deep learning in alzheimer?s disease: Diagnostic classification and prognostic prediction using neuroimaging data Frontiers in Aging Neuroscience, 11 (2019), p. 220; Rushanan, M., Foo Kune, D., Swanson, C.M., Rubin, A.D., SoK: Security and Privacy in Implantable Medical Devices and Body Area Networks (2014) Proc. Of, , IEEE S&P; Sawyer, B., Cox, C., How does health spending in the U.S. compare to other countries? (2018), https://www.healthsystemtracker.org/chart-collection/health-spending-u-s-compare-countries/; Wennberg, J.E., OConnor, A.M., Collins, E.D., Weinstein, J.N., Extending the p4p agenda, part 1: How medicare can improve patient decision making and reduce unnecessary care (2007) Health Affairs, 26, pp. 1564-1574; Joudaki, H., Rashidian, A., Minaei-Bidgoli, B., Mahmoodi, M., Geraili, B., Nasiri, M., Arab, M., Using data mining to detect health care fraud and abuse: A review of literature (2015) Global Journal of Health Science, 7, p. 194; Barlett, D.L., Steele, J.B., (2006) Critical Condition: How Health Care in America Became Big Business-And Bad Medicine. Broadway; Reddy, C.K., Aggarwal, C.C., (2015) Healthcare Data Analytics, , Chapman and Hall/CRC; Gulshan, V., Peng, L., Coram, M., Stumpe, M.C., Wu, D., Narayanaswamy, A., Venugopalan, S., Cuadros, J., Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs Jama, 316 (2016), pp. 2402-2410; Simon, G., Principles of chest x-ray diagnosis (1972) American Journal of Physical Medicine & Rehabilitation, 51, p. 42; Artificial Intelligence That Reads Chest X-rays Is Approved by Fda, , https://www.ucsf.edu/news/2019/09/415406/artificial-intelligence-reads-chest-x-rays-Approved-fda, Nov 2019; Metz, C., (2019) India Fights Diabetic Blindness with Help from A.i, , https://www.nytimes.com/2019/03/10/technology/artificial-intelligence-eye-hospital-india.html; Snow, J., (2019) The Algorithm Will See You Now: How Ai Is Helping Doctors Diagnose and Treat Patients, , https://www.pbs.org/wgbh/nova/article/howai-is-helping-doctors-diagnose-And-Treat-patients/; Siwicki, B., Johns Hopkins Researchers Use Deep Learning to Combat Pancreatic Cancer, 2018. , https://www.healthcareitnews.com/news/johns-hopkinsresearchers-use-deep-learning-combat-pancreatic-cancer; Wang, D., Khosla, A., Gargeya, R., Irshad, H., Beck, A.H., Deep learning for identifying metastatic breast cancer CoRR abs/1606, 5718, p. 2016; Esteva, A., Kuprel, B., Novoa, R.A., Ko, J., Swetter, S.M., Blau, H.M., Thrun, S., Dermatologist-level classification of skin cancer with deep neural networks Nature, 542 (2017), pp. 115-118; Hannun, A.Y., Rajpurkar, P., Haghpanahi, M., Tison, G.H., Bourn, C., Turakhia, M.P., Ng, A.Y., Cardiologist-level arrhythmia detection and classification in ambulatory electrocardiograms using a deep neural network Nature Medicine, 25 (2019), p. 65; Van Grinsven, M.J., Van Ginneken, B., Hoyng, C.B., Theelen, T., Sanchez, C.I., Fast convolutional neural network training using selective data sampling: Application to hemorrhage detection in color fundus images Ieee Transactions on Medical Imaging, 35 (2016), pp. 1273-1284; Rajalakshmi, R., Subashini, R., Anjana, R.M., Mohan, V., Automated diabetic retinopathy detection in smartphone-based fundus photography using artificial intelligence Eye, 32 (2018), pp. 1138-1144; Ling, X., Ji, S., Zou, J., Wang, J., Wu, C., Li, B., Wang, T., Deepsec: A uniform platform for security analysis of deep learning model Proc. Of Ieee S&p, 2019; Yuan, X., He, P., Zhu, Q., Li, X., Adversarial examples: Attacks and defenses for deep learning Ieee Transactions on Neural Networks and Learning Systems, 30 (2019), pp. 2805-2824; Goodfellow, I.J., Bulatov, Y., Ibarz, J., Arnoud, S., Shet, V., Multi-digit number recognition from street view imagery using deep convolutional neural networks (2014) Proc. Of Iclr; Juuti, M., Sun, B., Mori, T., Asokan, N., Stay on-Topic: Generating context-specific fake restaurant reviews Proc. Of Esorics, 2018; Yao, Y., Viswanath, B., Cryan, J., Zheng, H., Zhao, B.Y., Automated crowdturfing attacks and defenses in online review systems Proc. Of Ccs, 2017; Radford, A., Metz, L., Chintala, S., Unsupervised representation learning with deep convolutional generative adversarial networks (2015) Proc. Of Iclr; Das, A., Verma, R., Automated email generation for targeted attacks using natural language (1908) CoRR Abs/, 6893, p. 2019; Yuan, X., Chen, Y., Zhao, Y., Long, Y., Liu, X., Chen, K., Zhang, S., Gunter, C.A., Commandersong: A systematic approach for practical adversarial voice recognition Proc. Of Usenix Security, 2018; Iter, D., Huang, J., Jermann, M., Generating adversarial examples for speech recognition Stanford Technical Report, 2017; Hitaj, B., Ateniese, G., Perez-Cruz, F., Deep models under the gan: Information leakage from collaborative deep learning Proc. Of Ccs, 2017; Nasr, M., Bahramali, A., Houmansadr, A., Deepcorr: Strong flow correlation attacks on tor using deep learning Proc. Of Ccs, 2018; Sun, Y., Edmundson, A., Vanbever, L., Li, O., Rexford, J., Chiang, M., Mittal, P., Raptor: Routing attacks on privacy intor (2015) Proc. Of Usenix Security; Yan, Q., Wang, M., Huang, W., Luo, X., Yu, F.R., Automatically synthesizing dos attack traces using generative adversarial networks Ijmlc, 10 (2019), pp. 3387-3396; Kohli, N., Yadav, D., Vatsa, M., Singh, R., Noore, A., Synthetic iris presentation attack using idcgan Proc. Of Ijcb, 2017; Choplin, R.H., Boehme, J.M., Maynard, C.D., Picture archiving and communication systems: An overview (1992) RadioGraphics, 12, pp. 127-129; Wang, X., Peng, Y., Lu, L., Lu, Z., Bagheri, M., Summers, R., Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases Proc. Of Cvpr, 2017; Marcus, D.S., Wang, T.H., Parker, J., Csernansky, J.G., Morris, J.C., Buckner, R.L., Open access series of imaging studies (oasis): Cross-sectional mri data in young, diddle aged, non-demented, and demented older adults (2007) J. Cognitive Neuroscience, 12, pp. 2677-2684; Yan, K., Wang, X., Lu, L., Summers, R.M., Deeplesion: Automated mining of large-scale lesion annotations and universal lesion detection with deep learning Journal of Medical Imaging, 5 (2018), p. 036501; Iii Armato, S.G., McLennan, G., Bidaut, L., McNitt-Gray, M.F., Meyer, C.R., Reeves, A.P., Clarke, L.P., Data from LIDCIDRI.The cancer imaging archive (2015), p. 7937. , http://doi.org/10; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) Proc. Of Iclr; Qamber, S., Waheed, Z., Akram, M.U., Personal identification system based on vascular pattern of human retina (2012) Proc. Of Cibec; Brock, A., Donahue, J., Simonyan, K., Large scale GAN training for high fidelity natural image synthesis Proc. Of Iclr, 2019; Frid-Adar, M., Klang, E., Amitai, M., Goldberger, J., Greenspan, H., Synthetic data augmentation using gan for improved liver lesion classification Proc. Oft Ieee Isbi, 2018; Shin, H.-C., Tenenholtz, N.A., Rogers, J.K., Schwarz, C.G., Senjem, M.L., Gunter, J.L., Andriole, K.P., Michalski, M., Medical image synthesis for data augmentation and anonymization using generative adversarial networks Proc. Of Iwssmi, 2018; Frid-Adar, M., Diamant, I., Klang, E., Amitai, M., Goldberger, J., Greenspan, H., Gan-based synthetic medical image augmentation for increased cnn performance in liver lesion classification Neurocomputing, 321 (2018), pp. 321-331; Madani, A., Moradi, M., Karargyris, A., Syeda-Mahmood, T., Chest x-ray generation and data augmentation for cardiovascular abnormality classification Proc. Of Spie Medical Imaging, 2018; Schlegl, T., Seeböck, P., Waldstein, S.M., Schmidt-Erfurth, U., Langs, G., Unsupervised anomaly detection with generative adversarial networks to guide marker discovery Proc. Of Ipmi, 2017; Son, J., Park, S.J., Jung, K.-H., Retinal vessel segmentation in fundoscopic images with generative adversarial networks CoRR abs/1706, 9318, p. 2017; Baumgartner, C.F., Koch, L.M., Can Tezcan, K., Xi Ang, J., Konukoglu, E., Visual feature attribution using wasserstein gans Proc. Of Cvpr, 2018; Yi, X., Walia, E., Babyn, P., Generative adversarial network in medical imaging: A review Medical Image Analysis, 58 (2019), p. 101552; Xue, Y., Xu, T., Zhang, H., Long, L.R., Huang, X., Segan: Adversarial network with multi-scale l 1 loss for medical image segmentation Neuroinformatics, 16 (2018), pp. 383-392; Moeskops, P., Veta, M., Lafarge, M.W., Eppenhof, K.A., Pluim, J.P., Adversarial training and dilated convolutions for brain mri segmentation Proc. Of Miccai, 2017; Yang, D., Xu, D., Zhou, S.K., Georgescu, B., Chen, M., Grbic, S., Metaxas, D., Comaniciu, D., Automatic liver segmentation using an adversarial image-To-image network Proc. Of Miccai, 2017; Li, Z., Wang, Y., Yu, J., Brain tumor segmentation using an adversarial network Proc. Of International Miccai Brainlesion Workshop, 2017; Jin, D., Xu, Z., Tang, Y., Harrison, A.P., Mollura, D.J., CTrealistic lung nodule simulation from 3D conditional generative adversarial networks for robust lung segmentation Proc. Of Miccai, 2018; Isola, P., Zhu, J.-Y., Zhou, T., Efros, A.A., Image-To-image translation with conditional adversarial networks Proc. Of Cvpr, 2017; Zhu, J.-Y., Park, T., Isola, P., Efros, A.A., Unpaired image-Toimage translation using cycle-consistent adversarial networks Proc. Of Iccv, p. 2017; Hu, X., (2018) CycleGAN-Tensorflow, , https://github.com/xhujoy/CycleGAN-Tensorflow; Huang, G., Liu, Z., Maaten Der, L.Van, Weinberger, K.Q., Densely connected convolutional networks Proc. Of Cvpr, 2017; Choi, Y., Choi, M., Kim, M., Ha, J.-W., Kim, S., Choo, J., Star-GAN: Unified generative adversarial networks for multi-domain image-To-image translation Proc. Of Cvpr, 2018; Lin, T.-Y., Goyal, P., Girshick, R., He, K., Dollar, P., Focal loss for dense object detection Proc. Of Iccv, p. 2017; Borji, A., Pros and cons of gan evaluation measures Computer Vision and Image Understanding, 179 (2019), pp. 41-65; (2018), https://www.aoa.org/patients-And-public/eye-Andvision-problems/glossary-of-eye-And-vision-conditions/diabeticretinopathy, AOA American optometric association; Costa, P., Galdran, A., Meyer, M., Abramoff, M., Niemejer, M., Mendonca, A., Campilho, A., Towards adversarial retinal image synthesis CoRR abs/1701, 8974, p. 2017; (2018) Orobix Retina Blood Vessel Segmentation with a Convolutional Neural Network, , https://github.com/orobix/retina-unet; Staal, J., Abramoff, M., Niemeijer, M., Viergever, M., Van Ginneken, B., Ridge based vessel segmentation in color images of the retina (2004) Ieee Transactions on Medical Imaging, 23, pp. 501-509; Li, H., Li, B., Tan, S., Huang, J., Detection of deep network generated images using disparities in color components (1808) CoRR Abs/, 7276, p. 2018; Afchar, D., Nozick, V., Yamagishi, J., Echizen, I., Mesonet: A compact facial video forgery detection network Proc. Of Wifs, 2018",,,,Institute of Electrical and Electronics Engineers Inc.,"5th IEEE European Symposium on Security and Privacy, Euro S and P 2020",7 September 2020 through 11 September 2020,,164634,,9.78E+12,,,English,"Proc. - IEEE Eur. Symp. Secur. Priv., Euro S P",Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85096549146
"Gao D., Zhuo C.",57201317922;17436666200;,Private knowledge transfer via model distillation with generative adversarial networks,2020,Frontiers in Artificial Intelligence and Applications,325,,,1794,1801,,,10.3233/FAIA200294,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091773665&doi=10.3233%2fFAIA200294&partnerID=40&md5=5b1cfc93a805708e2654af3b0beb659c,"Zhejiang University, China","Gao, D., Zhejiang University, China; Zhuo, C., Zhejiang University, China","The deployment of deep learning applications has to address the growing privacy concerns when using private and sensitive data for training. A conventional deep learning model is prone to privacy attacks that can recover the sensitive information of individuals from either model parameters or accesses to the target model. Recently, differential privacy that offers provable privacy guarantees has been proposed to train neural networks in a privacy-preserving manner to protect training data. However, many approaches tend to provide the worst case privacy guarantees for model publishing, inevitably impairing the accuracy of the trained models. In this paper, we present a novel private knowledge transfer strategy, where the private teacher trained on sensitive data is not publicly accessible but teaches a student to be publicly released. In particular, a three-player (teacher-student-discriminator) learning framework is proposed to achieve trade-off between utility and privacy, where the student acquires the distilled knowledge from the teacher and is trained with the discriminator to generate similar outputs as the teacher. We then integrate a differential privacy protection mechanism into the learning procedure, which enables a rigorous privacy budget for the training. The framework eventually allows student to be trained with only unlabelled public data and very few epochs, and hence prevents the exposure of sensitive training data, while ensuring model utility with a modest privacy budget. The experiments on MNIST, SVHN and CIFAR-10 datasets show that our students obtain the accuracy losses w.r.t teachers of 0.89%, 2.29%, 5.16%, respectively with the privacy bounds of (1.93, 10-5), (5.02, 10-6), (8.81, 10-6). When compared with the existing works [15, 20], the proposed work can achieve 5-82% accuracy loss improvement. © 2020 The authors and IOS Press.",,Budget control; Deep learning; Distillation; Distilleries; Economic and social effects; Knowledge management; Students; Adversarial networks; Differential privacies; Knowledge transfer; Learning frameworks; Learning procedures; Privacy preserving; Publicly accessible; Sensitive informations; Data privacy,,,,,"Abadi, M., Chu, A., Goodfellow, I., Brendan McMahan, H., Mironov, I., Talwar, K., Zhang, L., Deep learning with differential privacy (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 308-318. , ACM; Dwork, C., Differential privacy (2011) Encyclopedia of Cryptography and Security, pp. 338-340; Dwork, C., McSherry, F., Nissim, K., Smith, A., Calibrating noise to sensitivity in private data analysis (2006) Theory of Cryptography Conference, pp. 265-284. , Springer; Fredrikson, M., Jha, S., Ristenpart, T., Model inversion attacks that exploit confidence information and basic countermeasures (2015) Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security, pp. 1322-1333. , ACM; Isola, P., Zhu, J.-Y., Zhou, T., Efros, A.A., Imageto-image translation with conditional adversarial networks (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1125-1134; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images, , Technical report, Citeseer; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proceedings of the IEEE, 86 (11), pp. 2278-2324; Lopez-Paz, D., Bottou, L., Schölkopf, B., Vapnik, V., (2015) Unifying Distillation and Privileged Information; Maddison, C.J., Tarlow, D., Minka, T., A sampling (2014) Advances in Neural Information Processing Systems, pp. 3086-3094; Brendan McMahan, H., Andrew, G., (2018) A General Approach to Adding Differential Privacy to Iterative Training Procedures; Brendan McMahan, H., Ramage, D., Talwar, K., Zhang, L., (2018) Learning Differentially Private Recurrent Language Models; Mironov, I., Rényi differential privacy (2017) 2017 IEEE 30th Computer Security Foundations Symposium (CSF), pp. 263-275. , IEEE; Mironov, I., Talwar, K., Zhang, L., (2019) R\'Enyi Differential Privacy of the Sampled Gaussian Mechanism; Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., Ng, A.Y., (2011) Reading Digits in Natural Images with Unsupervised Feature Learning; Papernot, N., Abadi, M., Erlingsson, U., Goodfellow, I., Talwar, K., (2016) Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data; Papernot, N., Song, S., Mironov, I., Raghunathan, A., Talwar, K., Erlingsson, U., (2018) Scalable Private Learning with Pate; Shokri, R., Shmatikov, V., Privacy-preserving deep learning (2015) Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security, pp. 1310-1321. , ACM; Shokri, R., Stronati, M., Song, C., Shmatikov, V., Membership inference attacks against machine learning models (2017) 2017 IEEE Symposium on Security and Privacy (SP), pp. 3-18. , IEEE; Tramèr, F., Zhang, F., Juels, A., Reiter, M.K., Ristenpart, T., Stealing machine learning models via prediction apis (2016) 25th {USENIX} Security Symposium ({USENIX} Security 16), pp. 601-618; Wang, J., Bao, W., Sun, L., Zhu, X., Cao, B., Yu Philip, S., Private model compression via knowledge distillation (2019) Proceedings of the AAAI Conference on Artificial Intelligence, 33, pp. 1190-1197; Wang, X., Zhang, R., Sun, Y., Qi, J., Kdgan: Knowledge distillation with generative adversarial networks (2018) Advances in Neural Information Processing Systems, pp. 775-786; Xu, Z., Hsu, Y.-C., Huang, J., (2017) Training Shallow and Thin Networks for Acceleration Via Knowledge Distillation with Conditional Adversarial Networks; Yu, L., Zhang, W., Wang, J., Yu, Y., Seqgan: Sequence generative adversarial nets with policy gradient (2017) Thirty-First AAAI Conference on Artificial Intelligence; Yu, L., Liu, L., Pu, C., Emre Gursoy, M., Truex, S., (2019) Differentially Private Model Publishing for Deep Learning; Zhang, Y., Gan, Z., Fan, K., Chen, Z., Henao, R., Shen, D., Carin, L., Adversarial feature matching for text generation (2017) Proceedings of the 34th International Conference on Machine Learning, 70, pp. 4006-4015. , JMLR. Org",,De Giacomo G.Catala A.Dilkina B.Milano M.Barro S.Bugarin A.Lang J.,Accenture;Artificial Intelligence;et al.;Hewlett Packard;iecisa IBM;Intel,IOS Press BV,"24th European Conference on Artificial Intelligence, ECAI 2020, including 10th Conference on Prestigious Applications of Artificial Intelligence, PAIS 2020",29 August 2020 through 8 September 2020,,162625,9226389,9.78E+12,,,English,Front. Artif. Intell. Appl.,Conference Paper,Final,,Scopus,2-s2.0-85091773665
"Zhang Y., Song Y., Liang J., Bai K., Yang Q.",57208497710;57216616056;57214441373;57201719836;57201354715;,Two Sides of the Same Coin: White-box and Black-box Attacks for Transfer Learning,2020,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,,,2989,2997,,2,10.1145/3394486.3403349,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090421960&doi=10.1145%2f3394486.3403349&partnerID=40&md5=12f0ad072dbc7ed96213119231b7d935,"Hong Kong University of Science and Technology, Hong Kong; Hong Kong University of Science and Technology, Peng Cheng Laboratory, Hong Kong; Tencent, Guangzhou, China","Zhang, Y., Hong Kong University of Science and Technology, Hong Kong; Song, Y., Hong Kong University of Science and Technology, Peng Cheng Laboratory, Hong Kong; Liang, J., Tencent, Guangzhou, China; Bai, K., Tencent, Guangzhou, China; Yang, Q., Hong Kong University of Science and Technology, Hong Kong","Transfer learning has become a common practice for training deep learning models with limited labeled data in a target domain. On the other hand, deep models are vulnerable to adversarial attacks. Though transfer learning has been widely applied, its effect on model robustness is unclear. To figure out this problem, we conduct extensive empirical evaluations to show that fine-tuning effectively enhances model robustness under white-box FGSM attacks. We also propose a black-box attack method for transfer learning models which attacks the target model with the adversarial examples produced by its source model. To systematically measure the effect of both white-box and black-box attacks, we propose a new metric to evaluate how transferable are the adversarial examples produced by a source model to a target model. Empirical results show that the adversarial examples are more transferable when fine-tuning is used than they are when the two networks are trained independently. © 2020 ACM.",adversarial attacks; neural networks; transfer learning,Data mining; Deep learning; Transfer learning; Attack methods; Empirical evaluations; Fine tuning; Learning models; Model robustness; Source modeling; Target domain; Target model; Learning systems,,,,,"Chen, P., Zhang, H., Sharma, Y., Yi, J., Hsieh, C., Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 15-26; Chrabaszcz, P., Loshchilov, I., Hutter, F., (2017) A Downsampled Variant of Imagenet As An Alternative to the Cifar Datasets, , (2017); Coates, A., Ng, A., Lee, H., An analysis of single-layer networks in unsupervised feature learning (2011) Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics, pp. 215-223; Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette, F., Marchand, M., Lempitsky, V., Domain-adversarial training of neural networks (2016) The Journal of Machine Learning Research, 17 (1), pp. 2030-2096. , (2016); Girshick, R., Donahue, J., Darrell, T., Malik, J., Rich feature hierarchies for accurate object detection and semantic segmentation (2014) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 580-587; Goodfellow, I., Shlens, J., Szegedy, C., (2015) Explaining and Harnessing Adversarial Examples, , http://arxiv.org/abs/1412.6572, (2015); Hendrycks, D., Lee, K., Mazeika, M., Using pre-training can improve model robustness and uncertainty (2019) International Conference on Machine Learning, pp. 2712-2721; Hull, J.J., A database for handwritten text recognition research (1994) IEEE Transactions on Pattern Analysis and Machine Intelligence, 16 (5), pp. 550-554. , (1994); Karpathy, A., Toderici, G., Shetty, S., Leung, T., Sukthankar, R., Fei-Fei, L., Large-scale video classification with convolutional neural networks (2014) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1725-1732; Krizhevsky, A., Hinton, G., Learning multiple layers of features from tiny images (2009) Technical Report. Citeseer; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradientbased learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324. , (1998); Liu, Y., Chen, X., Liu, C., Song, D., (2017) Delving into Transferable Adversarial Examples and Black-box Attacks, , https://openreview.net/forum?id=Sys6GJqxl, (2017); Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2018) Towards Deep Learning Models Resistant to Adversarial Attacks, , https://openreview.net/forum?id=rJzIBfZAb, (2018); Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., Ng, A.Y., (2011) Reading Digits in Natural Images with Unsupervised Feature Learning, , (2011); Oquab, M., Bottou, L., Laptev, I., Sivic, J., Learning and transferring mid-level image representations using convolutional neural networks (2014) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1717-1724; Jialin Pan, S., Yang, Q., A survey on transfer learning (2010) IEEE Transactions on Knowledge and Data Engineering, 22 (10), pp. 1345-1359. , (2010); Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Fei-Fei, L., Imagenet large scale visual recognition challenge (2015) International Journal of Computer Vision, 115 (3), pp. 211-252. , (2015); Schmidt, L., Santurkar, S., Tsipras, D., Talwar, K., Madry, A., Adversarially robust generalization requires more data (2018) Advances in Neural Information Processing Systems, pp. 5014-5026; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2014) Intriguing Properties of Neural Networks, , http://arxiv.org/abs/1312.6199, (2014); Venugopalan, S., Rohrbach, M., Donahue, J., Mooney, R., Darrell, T., Saenko, K., Sequence to sequence-video to text (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4534-4542; Venugopalan, S., Xu, H., Donahue, J., Rohrbach, M., Mooney, R., Saenko, K., Translating videos to natural language using deep recurrent neural networks (2015) Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 1494-1504; Vinyals, O., Toshev, A., Bengio, S., Erhan, D., Show and tell: A neural image caption generator (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3156-3164; Weiss, K., Khoshgoftaar, T.M., Wang, D., A survey of transfer learning (2016) Journal of Big Data, 3 (1), pp. 1-40. , (2016); Yosinski, J., Clune, J., Bengio, Y., Lipson, H., How transferable are features in deep neural networks? (2014) Advances in Neural Information Processing Systems, pp. 3320-3328; Yuan, X., He, P., Zhu, Q., Li, X., Adversarial examples: Attacks and defenses for deep learning (2019) IEEE Transactions on Neural Networks and Learning Systems, 30 (9), pp. 2805-2824. , (2019); Zagoruyko, S., Komodakis, N., (2016) Wide Residual Networks, , (2016)",,,ACM SIGKDD;ACM SIGMOD,Association for Computing Machinery,"26th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD 2020",23 August 2020 through 27 August 2020,,162480,,9.78E+12,,,English,Proc. ACM SIGKDD Int. Conf. Knowl. Discov. Data Min.,Conference Paper,Final,"All Open Access, Bronze, Green",Scopus,2-s2.0-85090421960
"Li Y., Xu G., Li W.",57220752151;57207162460;57210919995;,FA: A Fast Method to Attack Real-time Object Detection Systems,2020,"2020 IEEE/CIC International Conference on Communications in China, ICCC 2020",,,9238807,1268,1273,,1,10.1109/ICCC49849.2020.9238807,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097568584&doi=10.1109%2fICCC49849.2020.9238807&partnerID=40&md5=ccecbcc2a9d9757bd238784393da5d61,"School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China; Institute of Electronic Information and Network Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China","Li, Y., School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China, Institute of Electronic Information and Network Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China; Xu, G., Institute of Electronic Information and Network Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China; Li, W., Institute of Electronic Information and Network Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China","With the development of deep learning, image and video processing plays an important role in the age of 5G communication. However, deep neural networks are vulnerable: subtle perturbations can lead to incorrect classification results. Nowadays, adversarial attacks on artificial intelligence models have seen increasing interest. In this study, we propose a new method named FA to generate adversarial examples of object detection models. Based on the generative adversarial network (GAN), we combine the classification and location information to make the generated image look as real as possible. Experimental results on the PASCAL VOC dataset show that our method efficiently and quickly generates the image. Then, we test the transferability of adversarial samples on different datasets and object detection models such as YOLOv4, which also achieve certain transfer performance. Our work provides a basis for further exploring the defects of deep learning and improving the robustness of the systems. © 2020 IEEE.",adversarial samples; GAN; information security and privacy; object detection,Classification (of information); Deep learning; Deep neural networks; Object detection; Object recognition; Real time systems; Video signal processing; Adversarial networks; Classification results; Fast methods; Image and video processing; Location information; Object detection systems; Real time; Transfer performance; 5G mobile communication systems,,,,,"LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), pp. 436-444; Szegedy, C., (2013) Intriguing Properties of Neural Networks, , arXiv preprint arXiv:1312.6199; Kaziakhmedov, E., Real-world attack on MTCNN face detection system 2019 International Multi-Conference on Engineering, Computer and Information Sciences (SIBIRCON). 2019: IEEE; Jiang, L., Black-box adversarial attacks on video recognition models (2019) Proceedings of the 27th ACM International Conference on Multimedia; Chen, S., Shapeshifter: Robust physical adversarial attack on faster r-cnn object detector (2018) European Conference on Machine Learning; Goodfellow, I., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv: Machine Learning; Xie, C., Adversarial examples for semantic segmentation and object detection (2017) International Conference on Computer Vision; Ren, S., Faster R-CNN: Towards real-time object detection with region proposal networks (2015) Neural Information Processing Systems; Bochkovskiy, A., Wang, C., Liao, H.M., (2020) YOLOv4: Optimal Speed and Accuracy of Object Detection, , arXiv preprint arXiv:2004.10934; Papernot, N., The limitations of deep learning in adversarial settings (2016) Ieee European Symposium on Security and Privacy; Su, J., Vargas, D.V., Sakurai, K., One pixel attack for fooling deep neural networks IEEE Transactions on Evolutionary Computation, 2019, 23 (5), pp. 828-841; Wei, X., (2018) Transferable Adversarial Attacks for Image and Video Object Detection, , arXiv: Computer Vision and Pattern Recognition; Wang, D., Daedalus: Breaking non-maximum suppression in object detection via adversarial examples (2019) ArXiv: Computer Vision and Pattern Recognition; Liu, X., DPatch: An adversarial patch attack on object detectors (2018) ArXiv: Computer Vision and Pattern Recognition; Xiao, C., Generating adversarial examples with adversarial networks (2018) ArXiv: Cryptography and Security; Liu, A., Perceptual-sensitive gan for generating adversarial patches (2019) National Conference on Artificial Intelligence; Everingham, M., The pascal visual object classes (voc) challenge (2010) International Journal of Computer Vision, 88 (2), pp. 303-338; Liao, Q., Category-wise attack: Transferable adversarial examples for anchor free object detection (2020) ArXiv: Computer Vision and Pattern Recognition","Xu, G.; Institute of Electronic Information and Network Engineering, China; 电子邮件: xugl@cqupt.edu.cn",,,Institute of Electrical and Electronics Engineers Inc.,"2020 IEEE/CIC International Conference on Communications in China, ICCC 2020",9 August 2020 through 11 August 2020,,164893,,9.78E+12,,,English,"IEEE/CIC Int. Conf. Commun. China, ICCC",Conference Paper,Final,,Scopus,2-s2.0-85097568584
"Yu L., Wang X., Wang X., Zeng Z.",57219315353;57219314009;55736896100;57218664561;,Improving robustness of deep transfer model by double transfer learning,2020,"12th International Conference on Advanced Computational Intelligence, ICACI 2020",,,9177827,356,363,,,10.1109/ICACI49185.2020.9177827,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092144437&doi=10.1109%2fICACI49185.2020.9177827&partnerID=40&md5=536bcf9060afbc6d99d4ee655e0cef07,"Huazhong University of Science and Technology, School of Artificial Intelligence and Automation, Wuhan, China","Yu, L., Huazhong University of Science and Technology, School of Artificial Intelligence and Automation, Wuhan, China; Wang, X., Huazhong University of Science and Technology, School of Artificial Intelligence and Automation, Wuhan, China; Wang, X., Huazhong University of Science and Technology, School of Artificial Intelligence and Automation, Wuhan, China; Zeng, Z., Huazhong University of Science and Technology, School of Artificial Intelligence and Automation, Wuhan, China","In recent years, deep learning models have been widely adopted for transfer learning tasks. The deep models, however, were shown to be easily attacked by adversarial examples, which is generated from original samples with the carefully designed small perturbations. Thus, the transfer learning models based on deep networks will also face this problem. Because of the particularity of transfer learning tasks, using the conventional adversarial training to improve the robustness of deep transfer models is very difficult. In this paper, we propose a novel Double Transfer Learning with Adversarial Training (DTLAT) method to enhance the robustness of deep transfer learning models. Our intuition is using the instances of the source domain and target domain to help with adversarial training. At the same time, we design a reverse transfer learning method to weaken the effect of attack methods and improve the performance of deep transfer models of target domain. We regard the adversarial examples from some kind of attack method, like FGSM, as an adversarial domain while try to improve the generalization ability on other attacks method. Experiments demonstrate that DTLAT exceed many other methods about improving the robustness of the deep transfer model on several benchmark datasets. © 2020 IEEE.",Adversarial examples; Adversariat training; Deep transfer model; Robustness; Transfer learning,Deep learning; Intelligent computing; Learning systems; Attack methods; Benchmark datasets; Generalization ability; Learning models; Original sample; Small perturbations; Transfer learning methods; Transfer models; Transfer learning,,,,,"Daume, H., III, Marcu, D., Domain adaptation for statistical classifiers (2006) Journal of Artificial Intelligence Research, 26 (1), pp. 101-126; Pan, S.J., Yang, Q., A survey on transfer learning (2010) IEEE Transactions on Knowledge and Data Engineering, 22 (10), pp. 1345-1359; Tzeng, E., Hoffman, J., Saenko, K., Darrell, T., Adversarial discriminative domain adaptation (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 7167-7176; Yosinski, J., Clune, J., Bengio, Y., Lipson, H., How transferable are features in deep neural networks? (2014) Advances in Neural Information Processing Systems, pp. 3320-3328; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) Proceedings of the International Conference on Learning Representations; Yuan, X., He, P., Zhu, Q., Li, X., Adversarial examples: Attacks and defenses for deep learning (2019) IEEE Transactions on Neural Networks and Learning Systems, 30 (9), pp. 2805-2824; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy, pp. 39-57; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) IEEE European Symposium on Security and Privacy, pp. 372-387; Tan, B., Zhang, Y., Pan, S.J., Yang, Q., Learning transferable features with deep adaptation networks (2017) AAAI Conference on Artificial Intelligence; Long, M., Yue, C., Wang, J., Jordan, M.I., (2015) The Limitations of Deep Learning in Adversarial Settings; Long, M., Wang, J., Jordan, M.I., Deep transfer learning with joint adaptation networks (2017) Proceedings of the 34th International Conference on Machine Learning, 70, pp. 2208-2217; Oquab, M., Bottou, L., Laptev, I., Sivic, J., Learning and transferring mid-level image representations using convolutional neural networks (2014) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1717-1724; Long, M., Wang, J., Jordan, M.I., Unsupervised domain adaptation with residual transfer networks (2016) Advances in Neural Information Processing Systems, pp. 136-144; Goodfellow, I.J., Pouget-Abadie, J., Mirza, M., Bing, X., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems., pp. 2672-2680; Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette, F., Marchand, M., Lempitsky, V., Domain-adversarial training of neural networks (2016) Journal of Machine Learning Research, 17 (1), pp. 1-35; Cao, Z., Long, M., Wang, J., Jordan, M.I., Partial transfer learning with selective adversarial networks (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2724-2732; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) Proceedings of the International Conference on Learning Representations; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World; Tram'Er, F., Kurakin, A., Papernot, N., Goodfellow, I., Ensemble adversarial training: Attacks and defenses (2018) Proceedings of the International Conference on Learning Representations; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) Proceedings of the International Conference on Learning Representations; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 9185-9193; Meng, D., Chen, H., (2017) Magnet: A Two-pronged Defense against Adversarial Examples; Song, C., He, K., Wang, L., Hopcroft, J., Improving the generalization of adversarial training with domain adaptation (2019) Proceedings of the International Conference on Learning Representations; Borgwardt, K.M., Arthur, G., Rasch, M.J., Hans-Peter, K., Bernhard, S., Smola, A.J., Integrating structured biological data by kernel maximum mean discrepancy (2006) Bioinformatics, 22 (14), pp. e49-e57; Sun, B., Feng, J., Saenko, K., Return of frustratingly easy domain adaptation (2016) AAAI Conference on Artificial Intelligence; Sun, B., Saenko, K., Deep coral: Correlation alignment for deep domain adaptation (2016) European Conference on Computer Vision, pp. 443-450; Satpal, S., Sarawagi, S., Domain adaptation of conditional probability models via feature subsetting (2007) Proceedings of the European Conference on Principles of Data Mining and Knowledge Discovery, pp. 224-235; Gong, B., Shi, Y., Sha, F., Grauman, K., Geodesic flow kernel for unsupervised domain adaptation (2012) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2066-2073; Zhang, L., Yang, J., Zhang, D., Domain class consistency based transfer learning for image classification across domains (2017) Information Sciences, 418, pp. 242-257; Shu, Y., Cao, Z., Long, M., Wang, J., Transferable curriculum for weakly-supervised domain adaptation (2019) AAAI Conference on Artificial Intelligence; Long, M., Cao, Z., Wang, J., Jordan, M.I., Conditional adversarial domain adaptation (2018) Advances in Neural Information Processing Systems, pp. 1640-1650; Pei, Z., Cao, Z., Long, M., Wang, J., Multi-adversarial domain adaptation (2018) AAAI Conference on Artificial Intelligence; Long, M., Wang, J., Ding, G., Sun, J., Yu, P., Transfer feature learning with joint distribution adaptation (2013) Proceedings of the IEEE International Conference on Computer Vision, pp. 2200-2207; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradientbased learning applied to document recognition (1998) Proceedings of the IEEE, 86 (11), pp. 2278-2324; Bousmalis, K., Trigeorgis, G., Silberman, N., Krishnan, D., Erhan, D., Domain separation networks (2016) Advances in Neural Information Processing Systems, pp. 343-351","Yu, L.; Huazhong University of Science and Technology, China; 电子邮件: m201772624@hust.edu.cn
Wang, X.; Huazhong University of Science and Technology, China; 电子邮件: wangxingda@hust.edu.cn",,City University of Hongkong (CityU);Dali University,Institute of Electrical and Electronics Engineers Inc.,"12th International Conference on Advanced Computational Intelligence, ICACI 2020",14 August 2020 through 16 August 2020,,162652,,9.78E+12,,,English,"Int. Conf. Adv. Comput. Intell., ICACI",Conference Paper,Final,,Scopus,2-s2.0-85092144437
"Siddique A., Browne W.N., Grimshaw G.M.",57209066743;17433255300;7004267866;,Learning classifier systems: Appreciating the lateralized approach,2020,GECCO 2020 Companion - Proceedings of the 2020 Genetic and Evolutionary Computation Conference Companion,,,,1807,1815,,2,10.1145/3377929.3398101,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089753700&doi=10.1145%2f3377929.3398101&partnerID=40&md5=dd172563f8711785a8bc30b724a7eb8f,"School of Engineering and Computer Science, Victoria University of Wellington, New Zealand; School of Psychology, Victoria University of Wellington, New Zealand","Siddique, A., School of Engineering and Computer Science, Victoria University of Wellington, New Zealand; Browne, W.N., School of Engineering and Computer Science, Victoria University of Wellington, New Zealand; Grimshaw, G.M., School of Psychology, Victoria University of Wellington, New Zealand","Biological nervous systems can learn knowledge from simple and small-scale problems and then apply it to resolve more complex and large-scale problems in similar and related domains. However, the rudimentary attempts to apply this transfer learning in artificial intelligence systems have struggled. This is maybe due to the homogeneous nature of their knowledge representation. It is believed that it is the lateral asymmetry of the brain, enabling modular learning at different levels of abstraction, which facilitates transfer between tasks. Learning classifier systems (LCSs) are a rule-based evolutionary computation technique that automatically clusters inputs into environmental niches, which makes it an ideal candidate for implementing lateralization. Recently LCSs based systems have applied lateralization and modular learning at different levels of abstraction to solve complex problems in Boolean, computer vision, and navigation domains. This paper aims to bring these three separate implementations together for the first time to understand the methodology of lateralization and appreciate its benefits. The experimental results demonstrate that the LCSs based lateralized systems outperformed state-of-the-art homogeneous systems in solving complex problems. The advances arise from the ability to consider input at both the constituent level and holistic level simultaneously, such that the most appropriate viewpoint controls the system. © 2020 ACM.",Adversarial attacks; Boolean problems; Lateralization; Learning classifier systems; Modular learning; Non-markov mazes,Calculations; Clustering algorithms; Knowledge representation; Transfer learning; Artificial intelligence systems; Evolutionary computation techniques; Homogeneous system; Large-scale problem; Lateral asymmetry; Learning classifier system; Levels of abstraction; Viewpoint control; Learning systems,,,,,"Akhtar, N., Mian, A., Threat of adversarial attacks on deep learning in computer vision: A survey (2018) IEEE Access, 6, pp. 14410-14430. , 2018; Alexander, A.S., Nitz, D.A., Retrosplenial cortex maps the conjunction of internal and external spaces (2015) Nature Neuroscience, 18 (8), pp. 1143-1151. , 2015; Alvarez, I.M., Browne, W.N., Zhang, M., Human-inspired scaling in learning classifier systems: Case study on the n-bit multiplexer problem set (2016) Proceedings of the Genetic and Evolutionary Computation Conference, pp. 429-436. , ACM; Banich, M.T., Compton, R., (2010) Cognitive Neuroscience, , Nelson Education; Bernadó-Mansilla, E., Garrell-Guiu, J.M., Accuracy-based learning classifier systems: Models, analysis and applications to classification tasks (2003) Evolutionary Computation, 11 (3), pp. 209-238. , 2003; Butz, M.V., (2002) Anticipatory Learning Classifier Systems, 4. , Springer Science & Business Media; Butz, M.V., (2006) Rule-based Evolutionary Online Learning Systems, , Springer; Butz, M.V., Stolzmann, W., An algorithmic description of acs2 (2001) International Workshop on Learning Classifier Systems, pp. 211-229. , Springer; Chan, Y., Chou, T., Chen, H., Yeh, Y., Lavallee, J.P., Liang, K., Chang, K., Towards a neural circuit model of verbal humor processing: An fmri study of the neural substrates of incongruity detection and resolution (2013) Neuroimage, 66, pp. 169-176. , 2013; Chandra, S., (2020) Implementation of Papers on Adversarial Examples, , https://github.com/sarathknv/adversarial-examples-pytorch/tree/master, [Online; accessed Feb 02, 2020]; Corballis, M.C., The evolution of lateralized brain circuits (2017) Frontiers in Psychology, 8, p. 1021. , 2017; Dharmaretnam, M., Rogers, L.J., Hemispheric specialization and dual processing in strongly versus weakly lateralized chicks (2005) Behavioural Brain Research, 162 (1), pp. 62-70. , 2005; Faust, M., Kenett, Y.N., Rigidity, chaos and integration: Hemispheric interaction and individual differences in metaphor comprehension (2014) Frontiers in Human Neuroscience, 8. , 2014; Finger, S., (2001) Origins of Neuroscience: A History of Explorations into Brain Function, , Oxford University Press, USA; Flevaris, A.V., Robertson, L.C., Spatial frequency selection and integration of global and local information in visual processing: A selective review and tribute to shlomo bentin (2016) Neuropsychologia, 83, pp. 192-200. , 2016; Frässle, S., Michel Paulus, F., Krach, S., Robert Schweinberger, S., Enno Stephan, K., Jansen, A., Mechanisms of hemispheric lateralization: Asymmetric interhemispheric recruitment in the face perception network (2016) Neuroimage, 124, pp. 977-988. , 2016; Gaddes, W.H., (2013) Learning Disabilities and Brain Function: A Neuropsychological Approach, , Springer Science & Business Media; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , 2014, arXiv preprint arXiv:1412.6572; Grimshaw, G.M., Anne Séguin, J., Godfrey, H.K., Once more with feeling: The effects of emotional prosody on hemispheric specialisation for linguistic processing (2009) Journal of Neurolinguistics, 22 (4), pp. 313-326. , 2009; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Hickok, G., Poeppel, D., Neural basis of speech perception (2016) Neurobiology of Language, pp. 299-310. , Elsevier; Holland, J.H., Reitman, J.S., Cognitive systems based on adaptive algorithms reprinted in: Evolutionary computation (1998) The Fossil Record, , 1998 IEEE Press, New York; Iandola, F.N., Han, S., Moskewicz, M.W., Ashraf, K., Dally, W.J., Keutzer, K., (2016) SqueezeNet: AlexNet-level Accuracy with 50x Fewer Parameters and< 0.5 MB Model Size; Iqbal, M., Browne, W.N., Zhang, M., Extracting and using building blocks of knowledge in learning classifier systems (2012) Proceedings of the 14th Annual Conference on Genetic and Evolutionary Computation.ACM, pp. 863-870; Iqbal, M., Browne, W.N., Zhang, M., Reusing building blocks of extracted knowledge to solve complex, large-scale boolean problems (2014) IEEE Transactions on Evolutionary Computation, 18 (4), pp. 465-480. , https://doi.org/10.1109/TEVC.2013.2281537, 2014, Aug; (2020) KaggleCats, , https://www.kaggle.com/crawford/cat-dataset, kaggleCats Online; accessed Feb 02, 2020]; Krichmar, J.L., The neuromodulatory system: A framework for survival and adaptive behavior in a challenging world (2008) Adaptive Behavior, 16 (6), pp. 385-399. , 2008; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , 2016, arXiv preprint arXiv:1607.02533; Luca Lanzi, P., An analysis of the memory mechanism of xcsm (1998) Genetic Programming, 98, pp. 643-651. , 1998; Romanovich Luria, A., (2012) Higher Cortical Functions in Man, , Springer Science & Business Media; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , 2017, arXiv preprint arXiv:1706.06083; Moosavi-Dezfooli, S., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Nitz, D.A., Spaces within spaces: Rat parietal cortex neurons register position across three reference frames (2012) Nature Neuroscience, 15 (10), pp. 1365-1367. , 2012; (2020) C++ Library for Machine Learning, , http://dlib.net/files/data/, open source Online; accessed Feb 02, 2020]; (2020) C++ Library for XCS, , http://xcslib.sourceforge.net/, open source. Online; accessed March 26, 2020]; Robertson, L.C., Delis, D.C., Part-whole processing in unilateral brain-damaged patients: Dysfunction of hierarchical organization (1986) Neuropsychologia, 24 (3), pp. 363-370. , 1986; Robertson, L.C., Ivry, R., Hemispheric asymmetries: Attention to visual and auditory primitives (2000) Current Directions in Psychological Science, 9 (2), pp. 59-63. , 2000; Robertson, L.C., Lamb, M.R., Neuropsychological contributions to theories of part/whole organization (1991) Cognitive Psychology, 23 (2), pp. 299-330. , 1991; Rogers, L.J., Zucca, P., Vallortigara, G., Advantages of having a lateralized brain (2004) Proceedings of the Royal Society of London B: Biological Sciences, 271, pp. S420-S422. , 2004; Shanahan, M., Nikiforou, K., Creswell, A., Kaplanis, C., Barrett, D., Garnelo, M., An explicitly relational neural network architecture (2019) CoRR, p. 10307. , http://arxiv.org/abs/1905, 2019. abs/1905. 10307, arXiv: 1905.10307; Siddique, A., Browne, W.N., Grimshaw, G.M., Lateralized learning for robustness against adversarial attacks in a visual classification system Proceedings of the 22nd Annual Conference on Genetic and Evolutionary Computation, , 2020, ACM,-will appear; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition, , 2014, arXiv preprint arXiv:1409.1556; Stark, D.E., Margulies, D.S., Shehzad, Z.E., Reiss, P., Clare Kelly, A.M., Uddin, L.Q., Gee, D.G., Xavier Castellanos, F., Regional variation in interhemispheric coordination of intrinsic hemodynamic fluctuations (2008) Journal of Neuroscience, 28 (51), pp. 13754-13764. , 2008; Sutton, R.S., Barto, A.G., (1998) Reinforcement Learning: An Introduction, 1. , MIT press Cambridge; Urbanowicz, R.J., Browne, W.N., (2017) Introduction to Learning Classifier Systems, , Springer; Urbanowicz, R.J., Moore, J.H., Learning classifier systems: A complete introduction, review, and roadmap (2009) Journal of Artificial Evolution and Applications 2009, p. 1. , 2009; Wilson, S.W., Classifier fitness based on accuracy (1995) Evolutionary Computation, 3 (2), pp. 149-175. , 1995; Yelle, S.K., Grimshaw, G.M., Hemispheric specialization for linguistic processing of sung speech (2009) Perceptual and Motor Skills, 108 (1), pp. 219-228. , 2009; Zatuchna, Z.V., Bagnall, A., Learning mazes with aliasing states: An lcs algorithm with associative perception (2009) Adaptive Behavior, 17 (1), pp. 28-57. , 2009",,,ACM SIGEVO,"Association for Computing Machinery, Inc","2020 Genetic and Evolutionary Computation Conference, GECCO 2020",8 July 2020 through 12 July 2020,,161684,,9.78E+12,,,English,GECCO Companion - Proc. Genet. Evolut. Comput. Conf. Companion,Conference Paper,Final,,Scopus,2-s2.0-85089753700
"Duncan K., Komendantskaya E., Stewart R., Lones M.",57207793268;19640466600;53164860300;6603865966;,Relative Robustness of Quantized Neural Networks Against Adversarial Attacks,2020,Proceedings of the International Joint Conference on Neural Networks,,,9207596,,,,4,10.1109/IJCNN48605.2020.9207596,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093850024&doi=10.1109%2fIJCNN48605.2020.9207596&partnerID=40&md5=26bd0e0ad5b146cbb5e5613006b5cfbc,"Heriot-Watt University, Department of Computer Science, Edinburgh, United Kingdom","Duncan, K., Heriot-Watt University, Department of Computer Science, Edinburgh, United Kingdom; Komendantskaya, E., Heriot-Watt University, Department of Computer Science, Edinburgh, United Kingdom; Stewart, R., Heriot-Watt University, Department of Computer Science, Edinburgh, United Kingdom; Lones, M., Heriot-Watt University, Department of Computer Science, Edinburgh, United Kingdom","Neural networks are increasingly being moved to edge computing devices and smart sensors, to reduce latency and save bandwidth. Neural network compression such as quantization is necessary to fit trained neural networks into these resource constrained devices. At the same time, their use in safety-critical applications raises the need to verify properties of neural networks. Adversarial perturbations have potential to be used as an attack mechanism on neural networks, leading to ""obviously wrong"" misclassification. SMT solvers have been proposed to formally prove robustness guarantees against such adversarial perturbations. We investigate how well these robustness guarantees are preserved when the precision of a neural network is quantized. We also evaluate how effectively adversarial attacks transfer to quantized neural networks. Our results show that quantized neural networks are generally robust relative to their full precision counterpart (98.6%-99.7%), and the transfer of adversarial attacks decreases to as low as 52.05% when the subtlety of perturbation increases. These results show that quantization introduces resilience against transfer of adversarial attacks whilst causing negligible loss of robustness. © 2020 IEEE.",adversarial attack; neural network; verification,Safety engineering; Attack mechanism; Computing devices; Misclassifications; Network compression; Resourceconstrained devices; Safety critical applications; Smt solvers; Trained neural networks; Neural networks,,,,,"Abadi, M., (2015) TensorFlow: Large-scale Machine Learning on Heterogeneous Systems, , https://www.tensorflow.org/; Bacchus, P., Stewart, R., Komendantskaya, E., Accuracy, training time and hardware efficiency trade-offs for quantized neural networks on FPGAS (2020) Applied Reconfigurable Computing. Architectures, Tools, and Applications -16th Int. Symp., Proc., 1283, pp. 121-135. , Springer; Bagnall, A., Stewart, G., Certifying the true error: Machine learning in coq with verified generalization guarantees (2019) The 33rd Aaai Conf. on AI, the 31st Innovative Applications of Ai Conf., the 9th Aaai Symp. on Educational Advances in AI., pp. 2662-2669; Bernhard, R., Moëllic, P., Dutertre, J., Impact of low-bitwidth quantization on the adversarial robustness for embedded neural networks (2019) Int. Conf. on Cyberworlds., pp. 308-315. , IEEE; Cheng, C.H., Nührenberg, G., Huang, C.H., Ruess, H., Verification of binarized neural networks via inter-neuron factoring (2018) Working Conf. on Verified Software: Theories, Tools, and Experiments., pp. 279-290. , Springer; Chollet, F., (2015) Keras: Deep Learning Library for Theano and Tensorflow., 7 (8), p. T1. , https://keras.io/k, URL; Courbariaux, M., Bengio, Y., Binarynet: Training deep neural networks with weights and activations constrained to +1 or -1 (2016) CoRR, , abs/1602.02830; Deng, L., The mnist database of handwritten digit images for machine learning research [best of the web] (2012) Ieee Signal Processing Magazine, 29, pp. 141-142; Ding, X., Zhang, Y., Liu, T., Duan, J., Deep learning for event-driven stock prediction (2015) 24th Int. Joint Conf on Ai; Engstrom, L., Tsipras, D., Schmidt, L., Madry, A., A rotation and a translation suffice: Fooling cnns with simple transformations (2017) CoRR, , abs/1712.02779; Galloway, A., Taylor, G.W., Moussa, M., Attacking binarized neural networks (2018) 6th Int. Conf. on Learning Representations, Conf. Track Proc. OpenReview.net; Goodfellow, I., Generative adversarial nets (2014) Advances in Neural Information Processing Systems., pp. 2672-2680; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) 3rd Int. Conf. on Learning Representations, Conf. Track Proc.; Guo, C., Rana, M., Cissé, M., Van Der Maaten, L., Countering adversarial images using input transformations (2018) 6th Int, Conf. on Learning Representations, Conf. Track Proc.; Huang, X., Kwiatkowska, M., Wang, S., Wu, M., Safety verification of deep neural networks (2017) Int. Conf. on Computer Aided Verification., pp. 3-29. , Springer; Hubara, I., Courbariaux, M., Soudry, D., El-Yaniv, R., Bengio, Y., Quantized neural networks: Training neural networks with low precision weights and activations (2017) The Journal of Machine Learning Research, 18 (1), pp. 6869-6898; Katz, G., Barrett, C., Dill, D.L., Julian, K., Kochenderfer, M.J., Reluplex: An efficient SMT solver for verifying deep neural networks (2017) International Conference on Computer Aided Verification., pp. 97-117. , Springer; Katz, G., The marabou framework for verification and analysis of deep neural networks (2019) Cav 2019, Part I. Lncs, 1561, pp. 443-452. , Springer; Khalid, F., Qusecnets: Quantization-based defense mechanism for securing deep neural network against adversarial attacks (2019) 25th Ieee Int. Symp. on On-Line Testing and Robust System Design., pp. 182-187. , IEEE; Lane, N.D., Georgiev, P., Can deep learning revolutionize mobile sensing? (2015) Proc. of the 16th Int Workshop on Mobile Computing Systems and Applications., pp. 117-122. , ACM; Lin, J., Gan, C., Han, S., Defensive quantization: When efficiency meets robustness (2019) 7th Int. Conf. on Learning Representations; Ma, X., Li, B., Wang, Y., Erfani, S.M., Wijewickrema, S.N.R., Schoenebeck, G., Song, D., Bailey, J., Characterizing adversarial subspaces using local intrinsic dimensionality (2018) 6th Int. Conf. on Learning Representations, Conf. Track Proc.; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., On detecting adversarial perturbations (2017) 5th International Conference on Learning Representations, Iclr 2017, Conference Track Proceedings; Miotto, R., Wang, F., Wang, S., Jiang, X., Dudley, J.T., Deep learning for healthcare: Review, opportunities and challenges (2017) Briefings in Bioinformatics, 19 (6), pp. 1236-1246; Moosavi-Dezfooli, S.M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) Proc. of the Ieee Conf. on Computer Vision and Pattern Recognition., pp. 1765-1773; Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proc. of the Ieee Conf. on Computer Vision and Pattern Recognition., pp. 2574-2582; Narodytska, N., Kasiviswanathan, S., Ryzhyk, L., Sagiv, M., Walsh, T., Verifying properties of binarized deep neural networks (2018) 32nd Aaai Conf. on Ai; Prakash, A., Moran, N., Garber, S., DiLillo, A., Storer, J.A., Protecting jpeg images against adversarial attacks (2018) 2018 Data Compression Conf., pp. 137-146. , IEEE; Radu, V., Kaszyk, K., Wen, Y., Turner, J., Cano, J., Crowley, E.J., Franke, B., O'Boyle, M., Performance aware convolutional neural network channel pruning for embedded GPUs (2019) Ieee Int. Symp. on Workload Characterization., pp. 24-34. , IEEE; Rakin, A.S., Yi, J., Gong, B., Fan, D., Defend deep neural networks against adversarial examples via fixed and dynamic quantized activation functions (2018) CoRR, , abs/1807.06714; Samangouei, P., Kabkab, M., Chellappa, R., Defense-gan: Protecting classifiers against adversarial attacks using generative models (2018) 6th Int. Conf. on Learning Representations, Conf. Track Proc. OpenReview.net; Singh, G., Gehr, T., Püschel, M., Vechev, M.T., An abstract domain for certifying neural networks (2019) Pacmpl 3(POPL), pp. 411-4130; Su, J., Accuracy to throughput trade-offs for reduced precision neural networks on reconfigurable logic (2018) Applied Reconfigurable Computing Architectures, Tools, and Applications -14th Int. Symp., Proceedings., pp. 29-42; Su, J., Vargas, D.V., Sakurai, K., One pixel attack for fooling deep neural networks (2019) Ieee Trans. Evolutionary Computation, 23 (5), pp. 828-841; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R., Intriguing properties of neural networks (2014) 2nd Int. Conf. on Learning Representations, Conf. Track Proc.; Tramèr, F., Papernot, N., Goodfellow, I.J., Boneh, D., McDaniel, P.D., The space of transferable adversarial examples (2017) CoRR; Umuroglu, Y., Fraser, N.J., Gambardella, G., Blott, M., Leong, P.H.W., Jahre, M., Vissers, K.A., Finn: A framework for fast scalable binarized neural network inference (2017) Proceedings of the 2017 ACM/SIGDA Int. Symp. on Field-Programmable Gate Arrays., pp. 65-74; Wang, E., Davis, J.J., Zhao, R., Ng, H.C., Niu, X., Luk, W., Cheung, P.Y., Constantinides, G.A., Deep neural network approximation for custom hardware: Where we've been, where we're going (2019) Acm Computing Surveys (CSUR), 52 (2), p. 40; Wicker, M., Huang, X., Kwiatkowska, M., Feature-guided black-box safety testing of deep neural networks (2018) Int. Conf. on Tools and Algorithms for the Construction and Analysis of Systems., pp. 408-426. , Springer",,,IEEE Computational Intelligence Society (CIS),Institute of Electrical and Electronics Engineers Inc.,"2020 International Joint Conference on Neural Networks, IJCNN 2020",19 July 2020 through 24 July 2020,,163566,,9.78E+12,85OFA,,English,Proc Int Jt Conf Neural Networks,Conference Paper,Final,,Scopus,2-s2.0-85093850024
"Khalid F., Ali H., Hanif M.A., Rehman S., Ahmed R., Shafique M.",57197711927;57211394542;57194855888;7005331385;57213088796;17435669500;,FaDec: A Fast Decision-based Attack for Adversarial Machine Learning,2020,Proceedings of the International Joint Conference on Neural Networks,,,9207635,,,,3,10.1109/IJCNN48605.2020.9207635,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093827773&doi=10.1109%2fIJCNN48605.2020.9207635&partnerID=40&md5=ce193394f9ccfaea82a9f1f8c268dea5,"Technische Universität Wien (TU Wien), Vienna, Austria; National University of Sciences and Technology (NUST), Islamabad, Pakistan","Khalid, F., Technische Universität Wien (TU Wien), Vienna, Austria; Ali, H., National University of Sciences and Technology (NUST), Islamabad, Pakistan; Hanif, M.A., Technische Universität Wien (TU Wien), Vienna, Austria; Rehman, S., Technische Universität Wien (TU Wien), Vienna, Austria; Ahmed, R., National University of Sciences and Technology (NUST), Islamabad, Pakistan; Shafique, M., Technische Universität Wien (TU Wien), Vienna, Austria","Due to the excessive use of cloud-based machine learning (ML) services, the smart cyber-physical systems (CPS) are increasingly becoming vulnerable to black-box attacks on their ML modules. Traditionally, the black-box attacks are either transfer attacks requiring model stealing, or score/decision-based gradient estimation attacks requiring a large number of queries. In practical scenarios, especially for cloud-based ML services and timing-constrained CPS use-cases, every query incurs a huge cost, thereby rendering state-of-the-art decision-based attacks ineffective in such settings. Towards this, we propose a novel methodology for automatically generating an extremely fast and imperceptible decision-based attack called FaDec. It follows two main steps: (1) fast estimation of the classification boundary by combining the half-interval search-based algorithm with gradient sign estimation to reduce the number of queries; and (2) adversarial noise optimization to ensure the imperceptibility. For illustration, we evaluate FaDec on the image recognition and traffic sign detection using multiple state-of-the-art DNNs trained on CIFAR-10 and the German Traffic Sign Recognition Benchmarks (GTSRB) datasets. The experimental analysis shows that the proposed FaDec attack is 16x faster compared to the state-of-the-art decision-based attacks, and generates an attack image with better imperceptibility for a much lesser number of iterations, thereby making our attack more powerful in practical scenarios. We open-sourced the complete code and results of our methodology at https://github.com/fklodhi/FaDec. © 2020 IEEE.",,Embedded systems; Image recognition; Machine learning; Traffic signs; Classification boundary; Cyber-physical systems (CPS); Experimental analysis; Gradient estimation; Number of iterations; Search-based algorithms; Traffic sign detection; Traffic sign recognition; Neural networks,,,,,"Hanif, M.A., Robust machine learning systems: Reliability and security for deep neural networks (2018) Ieee Iolts, pp. 257-260; Khalid, F., Security for machine learning-based systems: Attacks and challenges during training and inference (2018) Ieee Fit, pp. 327-332; Shafique, M., An overview of next-generation architectures for machine learning: Roadmap, opportunities and challenges in the iot era (2018) Ieee Date, pp. 827-832; Madry, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks; Kurakin, A., (2016) Adversarial Examples in the Physical World; Moosavi-Dezfooli, S.-M., Deepfool: A simple and accurate method to fool deep neural networks (2016) Ieee Cvpr, pp. 2574-2582; Papernot, N., The limitations of deep learning in adversarial settings (2016) Ieee EuroS& P, pp. 372-387; Carlini, N., Towards evaluating the robustness of neural networks (2017) Ieee S& P, pp. 39-57; Khalid, F., Trisec: Training data-unaware imperceptible security attacks on deep neural networks (2019) Ieee Iolts, pp. 188-193; Shafique, M., Robust machine learning systems: Challenges, current trends, perspectives, and the road ahead (2020) Ieee D& T, 37 (2), pp. 30-57; Zhang, J.J., Building robust machine learning systems: Current progress, research challenges, and opportunities (2019) ACM/IEEE Dac, pp. 1-4; Marchisio, A., Deep learning for edge computing: Current trends, cross-layer optimizations, and open research challenges (2019) Ieee ISVLSI., pp. 553-559. , IEEE; Goodfellow, I., (2018) Gradient Masking Causes Clever to Overestimate Adversarial Perturbation Size; Papernot, N., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Ieee S& P, pp. 582-597; Khalid, F., Qusecnets: Quantization-based defense mechanism for securing deep neural network against adversarial attacks (2019) Ieee Iolts, pp. 182-187; Ali, H., Sscnets: Robustifying dnns using secure selective convolutional filters (2020) Ieee D& T, 37 (2), pp. 58-65; Lu, J., Issaranon, T., Forsyth, D., Safetynet: Detecting and rejecting adversarial examples robustly (2017) Ieee Iccv, pp. 446-454; Nitin Bhagoji, A., Practical black-box attacks on deep neural networks using efficient query mechanisms (2018) Ieee Eccv, pp. 154-169; Papernot, N., Practical black-box attacks against machine learning (2017) Acm Asia Ccs, pp. 506-519; Gao, J., Black-box generation of adversarial text sequences to evade deep learning classifiers (2018) Ieee Spw, pp. 50-56; Chen, P.-Y., Recent progress in zeroth order optimization and its applications to adversarial robustness in data mining and machine learning (2019) Acm Sigkdd, pp. 3233-3234; Shukla, S.N., (2019) Black-box Adversarial Attacks with Bayesian Optimization; Guo, C., (2019) Simple Black-box Adversarial Attacks; Zhao, P., On the design of black-box adversarial examples by leveraging gradient-free optimization and operator splitting method (2019) Ieee Iccv, pp. 121-130; Improving black-box adversarial attacks with a transfer-based prior (2019) NuerIPS, pp. 10932-10942. , C. et al; Suya, F., Chi, J., Evans, D., Tian, Y., (2019) Hybrid Batch Attacks: Finding Black-box Adversarial Examples with Limited Queries; Narodytska, N.A., (2016) Simple Black-box Adversarial Perturbations for Deep Networks; Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) Acm Aisec, pp. 15-26. , C. et al; Huang, L., Adversarial machine learning (2011) Acm Workshop on Security and Artificial Intelligence, pp. 43-58; Tramèr, F., (2017) Ensemble Adversarial Training: Attacks and Defenses; Brendel, W., (2017) Decision-based Adversarial Attacks: Reliable Attacks Against Black-box Machine Learning Models; Dong, Y., (2019) Efficient Decision-based Black-box Adversarial Attacks on Face Recognition; Chen, J., (2019) Boundary Attack++: Query-efficient Decision-based Adversarial Attack; Cheng, M., (2018) Query-efficient Hard-label Black-box Attack: An Optimization-based Approach; Khalid, F., (2019) RED-Attack: Resource Efficient Decision Based Attack for Machine Learning; Papernot, N., (2016) Cleverhans v1. 0.0: An Adversarial Machine Learning Library, 10; (2017) Foolbox v0. 8.0: A Python Toolbox to Benchmark the Robustness of Machine Learning Models, 5. , R. et al; Lee Rodgers, J., Thirteen ways to look at the correlation coefficient (1988) The American Statistician, 42 (1), pp. 59-66; Wang, Z., Image quality assessment: From error visibility to structural similarity (2004) Ieee Tip, 13 (4), pp. 600-612",,,IEEE Computational Intelligence Society (CIS),Institute of Electrical and Electronics Engineers Inc.,"2020 International Joint Conference on Neural Networks, IJCNN 2020",19 July 2020 through 24 July 2020,,163566,,9.78E+12,85OFA,,English,Proc Int Jt Conf Neural Networks,Conference Paper,Final,,Scopus,2-s2.0-85093827773
"Zhang Y., Yan J.",57212311005;55556549900;,Semi-Supervised Domain-Adversarial Training for Intrusion Detection against False Data Injection in the Smart Grid,2020,Proceedings of the International Joint Conference on Neural Networks,,,9207525,,,,2,10.1109/IJCNN48605.2020.9207525,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093827047&doi=10.1109%2fIJCNN48605.2020.9207525&partnerID=40&md5=161f063a9d165b9e93331202b61e6473,"Concordia University, Department of Computer Science and Software Engineering (CSSE), Montréal, QC  H3G 1M8, Canada; Concordia University, Concordia Institute for Information Systems Engineering (CIISE), Montréal, QC  H3G 1M8, Canada","Zhang, Y., Concordia University, Department of Computer Science and Software Engineering (CSSE), Montréal, QC  H3G 1M8, Canada; Yan, J., Concordia University, Concordia Institute for Information Systems Engineering (CIISE), Montréal, QC  H3G 1M8, Canada","The smart grid faces with increasingly sophisticated cyber-physical threats, against which machine learning (ML)-based intrusion detection systems have become a powerful and promising solution to smart grid security monitoring. However, many ML algorithms presume that training and testing data follow the same or similar data distributions, which may not hold in the dynamic time-varying systems like the smart grid. As operating points may change dramatically over time, the resulting data distribution shifts could lead to degraded detection performance and delayed incidence responses. To address this challenge, this paper proposes a semi-supervised framework based on domain-adversarial training to transfer the knowledge of known attack incidences to detect returning threats at different hours and load patterns. Using normal operation data of the ISO New England grids, the proposed framework leverages adversarial training to adapt learned models against new attacks launched at different times of the day. Effectiveness of the proposed detection framework is evaluated against the well-studied false data injection attacks synthesized on the IEEE 30-bus system, and the results demonstrated the superiority of the framework against persistent threats recurring in the highly dynamic smart grid. © 2020 IEEE.",Adversarial training; domain adaptation; false data injection; intrusion detection; smart grid security; transfer learning,Chemical detection; Electric power transmission networks; Network security; Neural networks; Smart power grids; Time varying systems; Cyber-physical threats; Data distribution; Detection framework; Detection performance; False data injection; False data injection attacks; Intrusion Detection Systems; Training and testing; Intrusion detection,,,,,"Alom, M.Z., Taha, T.M., Network intrusion detection for cyber security on neuromorphic computing system (2017) 2017 International Joint Conference on Neural Networks (IJCNN), pp. 3830-3837. , May; Yousefi-Azar, M., Varadharajan, V., Hamey, L., Tupakula, U., Autoencoder-based feature learning for cyber security applications (2017) 2017 International Joint Conference on Neural Networks (IJCNN), pp. 3854-3861. , May; He, H., Yan, J., Cyber-physical attacks and defences in the smart grid: A survey (2016) Iet Cyber-Physical Systems: Theories & Applications, 1 (1), pp. 13-27; (2015) Business Blackout: The Insurance Implications of a Cyber Attack on the Us Power Grid, , Lloyd's and the University of Cambridge Centre for Risk Studies, Tech. Rep; (2019) Cyber-Attack Against Ukrainian Critical Infrastructure, , https://www.iso-ne.com/isoexpress/web/reports/load-And-demand/-/tree/dmnd-five-minute-sys, The Industrial Control Systems Cyber Emergency Response Team (ICS-CERT), Tech. Rep; Buczak, A., Guven, E., A survey of data mining and machine learning methods for cyber security intrusion detection (2016) Ieee Communications Surveys & Tutorials, 18 (2), pp. 1153-1176; Ozay, M., Esnaola, I., Yarman Vural, F., Kulkarni, S., Poor, H., Machine learning methods for attack detection in the smart grid (2016) Ieee Transactions on Neural Networks and Learning Systems, 27 (8), pp. 1773-1786. , Aug; Yan, J., Tang, B., He, H., Detection of false data attacks in smart grid with supervised learning (2016) 2016 International Joint Conference on Neural Networks (IJCNN), pp. 1395-1402. , July; Quionero-Candela, J., Sugiyama, M., Schwaighofer, A., Lawrence, N., (2009) Dataset Shift in Machine Learning; Weiss, K., Khoshgoftaar, T.M., Wang, D., A survey of transfer learning (2016) Journal of Big Data, 3 (1), p. 9. , May; Taghiyarrenani, Z., Fanian, A., Mahdavi, E., Mirzaei, A., Farsi, H., Transfer learning based intrusion detection (2018) 2018 8th International Conference on Computer and Knowledge Engineering (ICCKE), pp. 92-97. , Oct; Ahmadi, R., Macredie, R.D., Tucker, A., Intrusion detection using transfer learning in machine learning classifiers between non-cloud and cloud datasets (2018) Intelligent Data Engineering and Automated Learning (IDEAL), pp. 556-566; Zhang, Y., Yan, J., Domain-Adversarial transfer learning for robust intrusion detection in the smart grid (2019) 2019 Ieee International Conference on Communications, Control, and Computing Technologies for Smart Grids (SmartGridComm)., pp. 1-6. , IEEE; Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette, F., Marchand, M., Lempitsky, V., Domain-Adversarial training of neural networks (2016) Journal of Machine Learning Research, 17 (1), pp. 2096-3030. , Jan; Liu, Y., Ning, P., Reiter, M.K., False data injection attacks against state estimation in electric power grids (2011) Acm Trans. Inf. Syst. Secur., 14 (1), pp. 131-1333. , Jun; Pan, S., Yang, Q., A survey on transfer learning (2010) Ieee Transactions on Knowledge and Data Engineering, 22 (10), pp. 1345-1359. , Oct; Fang, Z., Lu, J., Liu, F., Zhang, G., Unsupervised domain adaptation with sphere retracting transformation (2019) 2019 International Joint Conference on Neural Networks (IJCNN), pp. 1-8. , July; Li, L., He, H., Li, J., Yang, G., Adversarial domain adaptation via category transfer (2019) 2019 International Joint Conference on Neural Networks (IJCNN), pp. 1-8. , July; Li, L., Zhang, Z., Semi-supervised domain adaptation by covariance matching (2018) Ieee Transactions on Pattern Analysis and Machine Intelligence; Pereira, L.A., Da Silva Torres, R., Semi-supervised transfer subspace for domain adaptation (2018) Pattern Recognition, 75, pp. 235-249; Wang, W., Wang, H., Zhang, C., Gao, Y., Fredholm multiple kernel learning for semi-supervised domain adaptation (2017) Thirty-First Aaai Conference on Artificial Intelligence; Bergamo, A., Torresani, L., Exploiting weakly-labeled web images to improve object classification: A domain adaptation approach (2010) Advances in Neural Information Processing Systems, pp. 181-189; Duan, L., Xu, D., Tsang, I., (2012) Learning with Augmented Features for Heterogeneous Domain Adaptation; Saenko, K., Kulis, B., Fritz, M., Darrell, T., Adapting visual category models to new domains (2010) European Conference on Computer Vision., pp. 213-226. , Springer; Bartos, K., Sofka, M., Robust representation for domain adaptation in network security (2015) Joint European Conference on Machine Learning and Knowledge Discovery in Databases., pp. 116-132. , Springer; Zhao, J., Shetty, S., Pan, J., Feature-based transfer learning for network security (2017) 2017 Ieee Military Communications Conference (MILCOM), pp. 17-22. , Oct; Nahmias, D., Cohen, A., Nissim, N., Elovici, Y., Trustsign: Trusted malware signature generation in private clouds using deep feature transfer learning (2019) 2019 International Joint Conference on Neural Networks (IJCNN), pp. 1-8. , July; Goodfellow, I., Bengio, Y., Courville, A., (2016) Deep Learning., , http://www.deeplearningbook.org, MIT Press; Rumelhart, D.E., Hinton, G.E., Williams, R.J., (1986) Parallel Distributed Processing: Explorations in the Microstructure of Cognition, 1, pp. 318-362. , D. Rumelhart, J. McClelland, and C. PDP Research Group, Eds. Cambridge, MA, USA: MIT Press, ch. Learning Internal Representations by Error Propagation; Brieman, L., Random forests (2001) Machine Learning, 45 (1), pp. 5-32; Liang, G., Weller, S.R., Zhao, J., Luo, F., Dong, Z.Y., The 2015 Ukraine blackout: Implications for false data injection attacks (2016) Ieee Transactions on Power Systems, 32 (4), pp. 3317-3318; Abur, A., Gomez-Exposito, A., (2004) Power System State Estimation: Theory and Implementation, 24. , 01; Ieee 30-bus System, , https://icseg.iti.illinois.edu/ieee-30-bus-system/, I. C. for a Smarter Electric Grid (ICSEG)., [Online]; (2019) Iso New England -energy, Load, and Demand Reports, , https://www.iso-ne.com/isoexpress/web/reports/load-And-demand/-/tree/dmnd-five-minute-sys, ISO New England, Tech. Rep; Sasaki, Y., (2007) The Truth of the F-measure, , Teach Tutor Mater, 01; McCulloch, W.S., Pitts, W., A logical calculus of the ideas immanent in nervous activity (1943) The Bulletin of Mathematical Biophysics, 5 (4), pp. 115-133; Cortes, C., Vapnik, V., Support-vector networks (1995) Machine Learning, 20 (3), pp. 273-297. , https://doi.org/10.1023/A:1022627411411, Sep, [Online]; Breiman, L., (2017) Classification and Regression Trees., , Routledge; Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Duchesnay, E., Scikit-learn: Machine learning in python (2011) Journal of Machine Learning Research, 12, pp. 2825-2830",,,IEEE Computational Intelligence Society (CIS),Institute of Electrical and Electronics Engineers Inc.,"2020 International Joint Conference on Neural Networks, IJCNN 2020",19 July 2020 through 24 July 2020,,163566,,9.78E+12,85OFA,,English,Proc Int Jt Conf Neural Networks,Conference Paper,Final,,Scopus,2-s2.0-85093827047
"Raju R.S., Lipasti M.",57219418594;6701315461;,BlurNet: Defense by Filtering the Feature Maps,2020,"Proceedings - 50th Annual IEEE/IFIP International Conference on Dependable Systems and Networks, DSN-W 2020",,,9151833,38,46,,1,10.1109/DSN-W50199.2020.00016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092671670&doi=10.1109%2fDSN-W50199.2020.00016&partnerID=40&md5=ffab5ca87dc0c064d384da88013a553a,"University of Wisconsin-Madison, Department of Electrical Engineering, Madison, WI, United States","Raju, R.S., University of Wisconsin-Madison, Department of Electrical Engineering, Madison, WI, United States; Lipasti, M., University of Wisconsin-Madison, Department of Electrical Engineering, Madison, WI, United States","Recently, the field of adversarial machine learning has been garnering attention by showing that state-of-the-art deep neural networks are vulnerable to adversarial examples, stemming from small perturbations being added to the input image. Adversarial examples are generated by a malicious adversary by obtaining access to the model parameters, such as gradient information, to alter the input or by attacking a substitute model and transferring those malicious examples over to attack the victim model. Specifically, one of these attack algorithms, Robust Physical Perturbations (RP2), generates adversarial images of stop signs with black and white stickers to achieve high targeted misclassification rates against standard-architecture traffic sign classifiers. In this paper, we propose BlurNet, a defense against the RP2 attack. First, we motivate the defense with a frequency analysis of the first layer feature maps of the network on the LISA dataset, which shows that high frequency noise is introduced into the input image by the RP2 algorithm. To remove the high frequency noise, we introduce a depthwise convolution layer of standard blur kernels after the first layer. We perform a blackbox transfer attack to show that low-pass filtering the feature maps is more beneficial than filtering the input. We then present various regularization schemes to incorporate this low-pass filtering behavior into the training regime of the network and perform white-box attacks. We conclude with an adaptive attack evaluation to show that the success rate of the attack drops from 90% to 20% with total variation regularization, one of the proposed defenses. © 2020 IEEE.",Adversarial Defense; Adversarial Robustness,Deep neural networks; Network security; Traffic signs; Gradient informations; High-frequency noise; Malicious adversaries; Misclassification rates; Regularization schemes; Small perturbations; Standard architecture; Total variation regularization; Low pass filters,,,,,"Trivedi Andreas Mgelmose, M.M., Moeslund, T.B., Vision based traffic sign detection and analysis for intelligent driver assistance systems: Perspectives and survey (2012) Ieee Transactions on Intelligent Transportation Systems, , abs/1711.01991; Athalye, A., Carlini, N., Wagner, D.A., Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples (2018) CoRR, , abs/1802.00420; Cao, X., Zhenqiang Gong, N., Mitigating evasion attacks to deep neural networks via region-based classification (2017) CoRR, , abs/1709.05583; Carlini, N., Athalye, A., Papernot, N., Brendel, W., Rauber, J., Tsipras, D., Goodfellow, I.J., Kurakin, A., On evaluating adversarial robustness (2019) CoRR, , abs/1902.06705; Carlini, N., Wagner, D.A., Towards evaluating the robustness of neural networks (2016) CoRR, , abs/1608.04644; Carlini, N., Wagner, D.A., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) CoRR, , abs/1705.07263; Chollet, F., Xception: Deep learning with depthwise separable convolutions (2016) CoRR, , abs/1610.02357; Cohen, J.M., Rosenfeld, E., Zico Kolter, J., Certified adversarial robustness via randomized smoothing (2019) CoRR, , abs/1902.02918; Dhillon, G.S., Azizzadenesheli, K., Lipton, Z.C., Bernstein, J., Kossaifi, J., Khanna, A., Anandkumar, A., Stochastic activation pruning for robust adversarial defense (2018) CoRR, , abs/1803.01442; Karolina Dziugaite, G., Ghahramani, Z., Roy, D.M., A study of the effect of JPG compression on adversarial images (2016) CoRR, , abs/1608.00853; Evtimov, I., Eykholt, K., Fernandes, E., Kohno, T., Li, B., Prakash, A., Rahmati, A., Song, D., Robust physical-world attacks on machine learning models (2017) CoRR, , abs/1707.08945; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations; Graves, A., Mohamed, A., Hinton, G.E., Speech recognition with deep recurrent neural networks (2013) CoRR, , abs/1303.5778; Guo, C., Rana, M., Cissé, M., Van Der Maaten, L., Countering adversarial images using input transformations (2017) CoRR, , abs/1711.00117; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Proceedings of the 25th International Conference on Neural Information Processing Systems-Volume 1, NIPS'12, pp. 1097-1105. , USA,. Curran Associates Inc; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial examples in the physical world (2016) CoRR, , abs/1607.02533; Li, X., Li, F., Adversarial examples detection in deep networks with convolutional filter statistics (2016) CoRR, , abs/1612.07767; Liang, B., Li, H., Su, M., Li, X., Shi, W., Wang, X., Detecting adversarial examples in deep networks with adaptive noise reduction (2017) CoRR, , abs/1705.08378; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2017) CoRR, , abs/1706.06083; Papernot, N., Faghri, F., Carlini, N., Goodfellow, I., Feinman, R., Kurakin, A., Xie, C., Long, R., (2018) Technical Report on the Cleverhans v2.1.0 Adversarial Examples Library; Papernot, N., McDaniel, P.D., Goodfellow, I.J., Transferability in machine learning: From phenomena to black-box attacks using adversarial samples (2016) CoRR, , abs/1605.07277; Papernot, N., McDaniel, P.D., Goodfellow, I.J., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against deep learning systems using adversarial examples (2016) CoRR, , abs/1602.02697; Papernot, N., McDaniel, P.D., Sinha, A., Wellman, M.P., Towards the science of security and privacy in machine learning (2016) CoRR, , abs/1611.03814; Reichel, L., Ye, Q., Simple square smoothing regularization operators (2009) Electronic Transactions on Numerical Analysis, 33, pp. 63-83; Rudin, L.I., Osher, S., Fatemi, E., Nonlinear total variation based noise removal algorithms (1992) Proceedings of the Eleventh Annual International Conference of the Center for Nonlinear Studies on Experimental Mathematics : Computational Issues in Nonlinear Science: Computational Issues in Nonlinear Science, pp. 259-268. , New York, NY, USA,. Elsevier North-Holland, Inc; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-The-art face recognition (2016) Proceedings of the 2016 Acm Sigsac Conference on Computer and Communications Security, pp. 1528-1540; Sharma, Y., Weiguang Ding, G., Brubaker, M.A., On the effectiveness of low frequency perturbations (2019) CoRR, , abs/1903.00073; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations; Tramer, F., Carlini, N., Brendel, W., Madry, A., (2020) On Adaptive Attacks to Adversarial Example Defenses; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A.L., Mitigating adversarial effects through randomization (2017) CoRR, , abs/1711.01991; Xie, C., Wu, Y., Van Der Maaten, L., Yuille, A.L., He, K., Feature denoising for improving adversarial robustness (2018) CoRR, , abs/1812.03411; Xu, W., Evans, D., Qi, Y., (2017) Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks; Zantedeschi, V., Nicolae, M., Rawat, A., Efficient defenses against adversarial attacks (2017) CoRR, , abs/1707.06728",,,,Institute of Electrical and Electronics Engineers Inc.,"50th Annual IEEE/IFIP International Conference on Dependable Systems and Networks, DSN-W 2020",29 June 2020 through 2 July 2020,,162093,,9.78E+12,,,English,"Proc. - Annu. IEEE/IFIP Int. Conf. Dependable Syst. Networks, DSN-W",Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85092671670
"Ebrahimi M., Samtani S., Chai Y., Chen H.",56208183900;57188838077;57196466678;8871373800;,Detecting cyber threats in non-english hacker forums: An adversarial cross-lingual knowledge transfer approach,2020,"Proceedings - 2020 IEEE Symposium on Security and Privacy Workshops, SPW 2020",,,9283883,20,26,,1,10.1109/SPW50608.2020.00021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099724665&doi=10.1109%2fSPW50608.2020.00021&partnerID=40&md5=35e58fc5f754397c8c0c42271fd79fae,"Artificial Intelligence Lab, Information Systems, University of Arizona, Department of Management, Tucson, AZ, United States; Indiana University, Department of Operations and Decision Technologies, Bloomington, IN, United States; Tsinghua University, Beijing, China","Ebrahimi, M., Artificial Intelligence Lab, Information Systems, University of Arizona, Department of Management, Tucson, AZ, United States; Samtani, S., Indiana University, Department of Operations and Decision Technologies, Bloomington, IN, United States; Chai, Y., Tsinghua University, Beijing, China; Chen, H., Artificial Intelligence Lab, Information Systems, University of Arizona, Department of Management, Tucson, AZ, United States","The regularity of devastating cyber-attacks has made cybersecurity a grand societal challenge. Many cybersecurity professionals are closely examining the international Dark Web to proactively pinpoint potential cyber threats. Despite its potential, the Dark Web contains hundreds of thousands of non-English posts. While machine translation is the prevailing approach to process non-English text, applying MT on hacker forum text results in mistranslations. In this study, we draw upon Long-Short Term Memory (LSTM), Cross-Lingual Knowledge Transfer (CLKT), and Generative Adversarial Networks (GANs) principles to design a novel Adversarial CLKT (A-CLKT) approach. A-CLKT operates on untranslated text to retain the original semantics of the language and leverages the collective knowledge about cyber threats across languages to create a language invariant representation without any manual feature engineering or external resources. Three experiments demonstrate how A-CLKT outperforms state-of-the-art machine learning, deep learning, and CLKT algorithms in identifying cyber-threats in French and Russian forums. © 2020 IEEE.",Adversarial learning; Cross-lingual knowledge transfer; Generative adversarial networks; Hacker forums; Long short-term memory,Computer aided language translation; Deep learning; Knowledge management; Network security; Personal computing; Privacy by design; Semantics; Adversarial networks; Cyber security; External resources; Feature engineerings; Invariant representation; Knowledge transfer; Machine translations; State of the art; Long short-term memory,,,,,"Chen, H., (2012) Dark Web: Exploring and Data Mining the Dark Side of the Web, , New York: Springer; Du, P.-Y., Identifying, collecting, and presenting hacker community data: Forums, irc, carding shops, and dnms (2018) IEEE International Conference on Intelligence and Security Informatics (ISI), , Miami, FL; Nunes, E., Darknet and deepnet mining for proactive cybersecurity threat intelligence (2016) IEEE Conference on Intelligence and Security Informatics (ISI), pp. 7-12. , Tucson, AZ; Arnold, N., Dark-net ecosystem cyber-threat intelligence (cti) tool (2019) IEEE International Conference on Intelligence and Security Informatics (ISI), pp. 92-97; Li, W., Chen, H., Nunamaker, J.F., Jr., Identifying and profiling key sellers in cyber carding community: Azsecure text mining system (2016) Journal of Management Information Systems, 33 (4), pp. 1059-1086; Tavabi, N., Goyal, P., Almukaynizi, M., Shakarian, P., Lerman, K., Darkembed: Exploit prediction with neural language models (2018) Thirty-Second AAAI Conference on Artificial Intelligence; Schäfer, M., Fuchs, M., Strohmeier, M., Engel, M., Liechti, M., Lenders, V., Blackwidow: Monitoring the dark web for cyber security information (2019) International Conference on Cyber Conflict (CyCon), 900, pp. 1-21; Grisham, J., Samtani, S., Patton, M., Chen, H., Identifying mobile malware and key threat actors in online hacker forums for proactive cyber threat intelligence (2017) IEEE International Conference on Intelligence and Security Informatics (ISI), pp. 13-18. , Beijing, China; Li, W., Chen, H., Identifying top sellers in underground economy using deep learning-based sentiment analysis (2014) Intelligence and Security Informatics Conference (JISIC), 2014 IEEE Joint, pp. 64-67; Samtani, S., Chinn, R., Chen, H., Nunamaker, J.F., Jr., Exploring emerging hacker assets and key hackers for proactive cyber threat intelligence (2017) Journal of Management Information Systems, 34 (4), pp. 1023-1053; Samtani, S., Chinn, R., Chen, H., Exploring hacker assets in underground forums (2015) IEEE International Conference on Intelligence and Security Informatics (ISI), pp. 31-36. , Baltimore, MD; Weiss, K., Khoshgoftaar, T.M., Wang, D., A survey of transfer learning (2016) Journal of Big Data, 3 (1), p. 9; Abdalla, M., Hirst, G., Cross-lingual sentiment analysis without (good) translation (2017) The 8th International Joint Conference on Natural Language Processing (IJCNLP), pp. 506-515. , Taiwan; Li, N., Zhai, S., Zhang, Z., Liu, B., Structural correspondence learning for cross-lingual sentiment classification with one-to-many mappings (2017) AAAI Conference on Artificial Intelligence, pp. 3490-3496. , San Francisco; Wang, M., Deng, W., Deep visual domain adaptation: A survey (2018) Neurocomputing; Goodfellow, I., Generative adversarial nets (2014) Advances in Neural Information Processing Systems (NeurIPS), pp. 2672-2680. , Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger, Eds. Curran Associates, Inc; Johnson, R., Zhang, T., Supervised and semisupervised text categorization using lstm for region embeddings (2016) International Conference on Machine Learning (ICML), 48, pp. 526-534. , New York, NY; Goodfellow, I., Bengio, Y., Courville, A., Bengio, Y., (2016) Deep Learning, 1. , MIT Press Cambridge; Goldberg, Y., Neural network methods for natural language processing (2017) Synthesis Lectures on Human Language Technologies, 10 (1), pp. 1-309; Ebrahimi, M., Surdeanu, M., Samtani, S., Chen, H., Detecting cyber threats in non-english dark net markets: A cross-lingual transfer learning approach (2018) IEEE International Conference on Intelligence and Security Informatics (ISI), pp. 85-90; Hastie, T., Tibshirani, R., Friedman, J., (2017) The Elements of Statistical Learning, , Springer series in statistics New York","Chai, Y.; Department of Management Science and Engineering, China; 电子邮件: chaiyd14@mails.tsinghua.edu.cn",,,Institute of Electrical and Electronics Engineers Inc.,"2020 IEEE Symposium on Security and Privacy Workshops, SPW 2020",21-May-20,,165937,,9.78E+12,,,English,"Proc. - IEEE Symp. Secur. Priv. Workshops, SPW",Conference Paper,Final,"All Open Access, Bronze",Scopus,2-s2.0-85099724665
"Schuster R., Schuster T., Meri Y., Shmatikov V.",57190396604;57205163573;57219173049;6603350413;,Humpty dumpty: Controlling word meanings via corpus poisoning,2020,Proceedings - IEEE Symposium on Security and Privacy,2020-May,,9152608,1295,1313,,6,10.1109/SP40000.2020.00115,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091583087&doi=10.1109%2fSP40000.2020.00115&partnerID=40&md5=2e0b683c2c22766201869a2f12be27e7,"Tel Aviv University, Israel; CSAIL, MIT; Cornell Tech","Schuster, R., Tel Aviv University, Israel; Schuster, T., CSAIL, MIT; Meri, Y.; Shmatikov, V., Cornell Tech","Word embeddings, i.e., low-dimensional vector representations such as GloVe and SGNS, encode word ""meaning""in the sense that distances between words' vectors correspond to their semantic proximity. This enables transfer learning of semantics for a variety of natural language processing tasks.Word embeddings are typically trained on large public corpora such as Wikipedia or Twitter. We demonstrate that an attacker who can modify the corpus on which the embedding is trained can control the ""meaning""of new and existing words by changing their locations in the embedding space. We develop an explicit expression over corpus features that serves as a proxy for distance between words and establish a causative relationship between its values and embedding distances. We then show how to use this relationship for two adversarial objectives: (1) make a word a top-ranked neighbor of another word, and (2) move a word from one semantic cluster to another.An attack on the embedding can affect diverse downstream tasks, demonstrating for the first time the power of data poisoning in transfer learning scenarios. We use this attack to manipulate query expansion in information retrieval systems such as resume search, make certain names more or less visible to named entity recognition models, and cause new words to be translated to a particular target word regardless of the language. Finally, we show how the attacker can generate linguistically likely corpus modifications, thus fooling defenses that attempt to filter implausible sentences from the corpus using a language model. © 2020 IEEE.",,Information retrieval systems; Natural language processing systems; Search engines; Semantics; Transfer learning; Language model; Learning scenarios; Low dimensional; Named entity recognition; NAtural language processing; Query expansion; Semantic clusters; Word meaning; Embeddings,,,,,"Agerri, R., Rigau, G., Robust multilingual named entity recognition with shallow semi-supervised features (2016) Artificial Intelligence; Akbik, A., Blythe, D., Vollgraf, R., Contextual string embeddings for sequence labeling (2018) Coling; Akhtar, N., Mian, A., Threat of adversarial attacks on deep learning in computer vision: A survey (2018) Ieee Access; Alzantot, M., Sharma, Y., Elgohary, A., Ho, B.-J., Srivastava, M., Chang, K.-W., Generating natural language adversarial examples (2018) Emnlp; Antoniak, M., Mimno, D., Evaluating the stability of embeddingbased word similarities (2018) Tacl; (2019), https://archive.org/download/archiveteam-twitter-stream-2018-10, Twitter stream, oct 2018, accessed: May; Arora, S., Li, Y., Liang, Y., Ma, T., Risteski, A., (2015) Random Walks on Context Spaces: Towards An Explanation of the Mysteries of Semantic Word Embeddings; Arora, S., Li, Y., Liang, Y., Ma, T., Risteski, A., A latent variable model approach to PMI-based word embeddings (2016) Tacl; Artetxe, M., Labaka, G., Agirre, E., Learning bilingual word embeddings with (almost) no bilingual data (2017) Acl; Belinkov, Y., Bisk, Y., Synthetic and natural noise both break neural machine translation (2018) Iclr; Bojcheski, A., Günnemann, S., (2018) Adversarial Attacks on Node Embeddings; Bolukbasi, T., Chang, K.-W., Zou, J.Y., Saligrama, V., Kalai, A.T., Man is to computer programmer as woman is to homemaker? debiasing word embeddings (2016) Nips; Brunet, M.-E., Alkalay-Houlihan, C., Anderson, A., Zemel, R., Understanding the origins of bias in word embeddings (2019) Icml; Chen, D., Fisch, A., Weston, J., Bordes, A., Reading Wikipedia to answer open-domain questions (2017) Acl; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) AISec; Chen, X., Liu, C., Li, B., Lu, K., Song, D., (2017) Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning; Cherry, C., Guo, H., The unreasonable effectiveness of word representations for twitter named entity recognition (2015) NAACL-HLT; Conneau, A., Lample, G., Ranzato, M., Denoyer, L., Jégou, H., Word translation without parallel data (2018) Iclr; (2019), https://cupy.chainer.org/, accessed: May; Devlin, J., Chang, M.-W., Lee, K., Toutanova, K., BERT: Pretraining of deep bidirectional transformers for language understanding (2019) NAACL-HLT; Diaz, F., Mitra, B., Craswell, N., Query expansion with locallytrained word embeddings (2016) Acl; Ebrahimi, J., Rao, A., Lowd, D., Dou, D., Hotflip: White-box adversarial examples for text classification (2018) NAACL-HLT; Efthimiadis, E.N., Query expansion (1996) Arist; (2019) Elastic Search Guide: Lucene's Practical Scoring Function, , https://www.elastic.co/guide/en/elasticsearch/guide/current/practical-scoring-function.html, accessed: May; (2019), https://www.elastic.co/, accessed: May; Ethayarajh, K., Duvenaud, D., Hirst, G., Towards understanding linear word analogies (2019) Acl; Firth, J.R., A synopsis of linguistic theory, 1930-1955 (1957) Studies in Linguistic Analysis; Gabrilovich, E., Markovitch, S., Computing semantic relatedness using Wikipedia-based explicit semantic analysis (2007) Ijcai; Gao, J., Lanchantin, J., Soffa, M.L., Qi, Y., Black-box generation of adversarial text sequences to evade deep learning classifiers (2018) Ieee Security and Privacy Workshops (SPW); Ginter, F., Hajic, J., Luotolahti, J., Straka, M., Zeman, D., (2017) CoNLL 2017 Shared Task-automatically Annotated Raw Texts and Word Embeddings, , LINDAT/CLARIN digital library at Charles University; Hashimoto, T.B., Alvarez-Melis, D., Jaakkola, T.S., Word embeddings as metric recovery in semantic spaces (2016) Tacl; Hellrich, J., Hahn, U., Bad company - neighborhoods in neural embedding spaces considered harmful (2016) Coling; Ilyas, A., Engstrom, L., Athalye, A., Lin, J., (2018) Black-box Adversarial Attacks with Limited Queries and Information; Jia, R., Liang, P., Adversarial examples for evaluating reading comprehension systems (2017) Emnlp; Kamath, S., Grau, B., Ma, Y., A study of word embeddings for biomedical question answering (2017) Symp. sur L'Ingénierie de L'Information Médicale; Krause, A., Golovin, D., (2014) Submodular Function Maximization; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2017) Iclr; Kuzi, S., Shtok, A., Kurland, O., Query expansion using word embeddings (2016) Cikm; Levy, O., Goldberg, Y., Linguistic regularities in sparse and explicit word representations (2014) CoNLL; Levy, O., Goldberg, Y., Neural word embedding as implicit matrix factorization (2014) Nips; Levy, O., Goldberg, Y., Dagan, I., Improving distributional similarity with lessons learned from word embeddings (2015) Tacl; Li, B., Wang, Y., Singh, A., Vorobeychik, Y., Data poisoning attacks on factorization-based collaborative filtering (2016) Nips; Li, C., Sun, A., Datta, A., Twevent: Segment-based event detection from tweets (2012) Cikm; Li, C., Weng, J., He, Q., Yao, Y., Datta, A., Sun, A., Lee, B.-S., Twiner: Named entity recognition in targeted twitter stream (2012) Sigir; Liang, B., Li, H., Su, M., Bian, P., Li, X., Shi, W., Deep text classification can be fooled (2018) Ijcai; Liu, X., Zhang, S., Wei, F., Zhou, M., Recognizing named entities in tweets (2011) Acl; Liu, Y., Ma, S., Aafer, Y., Lee, W.-C., Zhai, J., Wang, W., Zhang, X., (2017) Trojaning Attack on Neural Networks, , Purdue e-Pubs:17-002; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) Iclr; Mikolov, T., Chen, K., Corrado, G., Dean, J., (2013) Efficient Estimation of Word Representations in Vector Space; Mikolov, T., Le, Q.V., Sutskever, I., (2013) Exploiting Similarities among Languages for Machine Translation; Mikolov, T., Sutskever, I., Chen, K., Corrado, G.S., Dean, J., Distributed representations of words and phrases and their compositionality (2013) Nips; Nemhauser, G.L., Wolsey, L.A., Best algorithms for approximating the maximum of a submodular set function (1978) Mathematics of Operations Research; Nikfarjam, A., Sarker, A., O'Connor, K., Ginn, R., Gonzalez, G., Pharmacovigilance from social media: Mining adverse drug reaction mentions using sequence labeling with word embedding cluster features (2015) Jamia; Pennington, J., Socher, R., Manning, C.D., Glove: Global vectors for word representation (2014) Emnlp; Pennington, J., Socher, R., Manning, C.D., Glove source code (2014), https://github.com/stanfordnlp/GloVe, accessed: June 2018; Peters, M., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., Zettlemoyer, L., Deep contextualized word representations (2018) Naaclhlt; Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., Language models are unsupervised multitask learners (2019) OpenAI Blog; Ritter, A., Clark, S., Mausam, Etzioni, O., Named entity recognition in tweets: An experimental study (2011) Emnlp; Ritter, A., Mausam, Etzioni, O., Clark, S., Open domain event extraction from Twitter (2012) Kdd; Roy, D., Paul, D., Mitra, M., Garain, U., (2016) Using Word Embeddings for Automatic Query Expansion; Samanta, S., Mehta, S., (2017) Towards Crafting Text Adversarial Samples; Sato, M., Suzuki, J., Shindo, H., Matsumoto, Y., Interpretable adversarial perturbation in input embedding space for text (2018) Ijcai; Schuster, R., Schuster, T., Meri, Y., Shmatikov, V., (2020) Humpty Dumpty: Controlling Word Meanings Via Corpus Poisoning; Schuster, T., Ram, O., Barzilay, R., Globerson, A., Cross-lingual alignment of contextual word embeddings, with applications to zeroshot dependency parsing (2019) NAACL-HLT; Shafahi, A., Huang, W.R., Najibi, M., Suciu, O., Studer, C., Dumitras, T., Goldstein, T., Poison frogs! targeted clean-label poisoning attacks on neural networks (2018) Nips; Smith, S.L., Turban, D.H., Hamblin, S., Hammerla, N.Y., Offline bilingual word vectors, orthogonal transformations and the inverted softmax (2017) Iclr; Steinhardt, J., Koh, P.W.W., Liang, P.S., Certified defenses for data poisoning attacks (2017) Nips; Sun, M., Tang, J., Li, H., Li, B., Xiao, C., Chen, Y., Song, D., (2018) Data Poisoning Attack against Unsupervised Node Embedding Methods; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks; Turney, P.D., Pantel, P., From frequency to meaning: Vector space models of semantics (2010) Jair; Voorhees, E.M., Query expansion using lexical-semantic relations (1994) Sigir; Wallace, E., Feng, S., Kandpal, N., Gardner, M., Singh, S., Universal adversarial triggers for attacking and analyzing nlp (2019) Emnlp; Wang, W., Tang, B., Wang, R., Wang, L., Ye, A., (2019) A Survey on Adversarial Attacks and Defenses in Text; Wu, M., (2019) Tweets Preprocessing Script, , https://gist.github.com/tokestermw/cb87a97113da12acb388, accessed: May; Xing, C., Wang, D., Liu, C., Lin, Y., Normalized word embedding and orthogonal transform for bilingual word translation (2015) Naaclhlt; Yang, C., Wu, Q., Li, H., Chen, Y., (2017) Generative Poisoning Attack Method against Neural Networks; (2019) Flair Tutorial 7: Training a Model, , https://github.com/zalandoresearch/flair/blob/master/resources/docs/TUTORIAL_7_TRAINING_A_MODEL.md, Zalando Research, accessed: May; Yang, C., Wu, Q., Li, H., Chen, Y., (2019) DFlair Tutorial 7: Training a Model, , https://github.com/zalandoresearch/flair/blob/master/resources/docs/TUTORIAL_7_TRAINING_A_MODEL.md, accessed: May; Yang, C., Wu, Q., Li, H., Chen, Y., (2019) Flair Tutorial 7: Training a Model, , https://github.com/zalandoresearch/flair, accessed: May",,,,Institute of Electrical and Electronics Engineers Inc.,"41st IEEE Symposium on Security and Privacy, SP 2020",18 May 2020 through 21 May 2020,,162113,10816011,9.78E+12,,,English,Proc. IEEE Symp. Secur. Privacy,Conference Paper,Final,"All Open Access, Bronze, Green",Scopus,2-s2.0-85091583087
"Yan C., Shin H., Bolton C., Xu W., Kim Y., Fu K.",57200512381;57188676854;57188761807;36242752200;54784526900;18434230000;,SoK: A minimalist approach to formalizing analog sensor security,2020,Proceedings - IEEE Symposium on Security and Privacy,2020-May,,9152711,233,248,,9,10.1109/SP40000.2020.00026,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091577331&doi=10.1109%2fSP40000.2020.00026&partnerID=40&md5=e4d9d06d974497b4d8ca19eb1c1c2091,"Zhejiang University, China; KAIST; University of Michigan, United States","Yan, C., Zhejiang University, China; Shin, H., KAIST; Bolton, C., University of Michigan, United States; Xu, W., Zhejiang University, China; Kim, Y., KAIST; Fu, K., University of Michigan, United States","Over the last six years, several papers demonstrated how intentional analog interference based on acoustics, RF, lasers, and other physical modalities could induce faults, influence, or even control the output of sensors. Damage to the availability and integrity of sensor output carries significant risks to safety-critical systems that make automated decisions based on trusted sensor measurement. Established signal processing models use transfer functions to express reliability and dependability characteristics of sensors, but existing models do not provide a deliberate way to express and capture security properties meaningfully.Our work begins to fill this gap by systematizing knowledge of analog attacks against sensor circuitry and defenses. Our primary contribution is a simple sensor security model such that sensor engineers can better express analog security properties of sensor circuitry without needing to learn significantly new notation. Our model introduces transfer functions and a vector of adversarial noise to represent adversarial capabilities at each stage of a sensor's signal conditioning chain. The primary goals of the systematization are (1) to enable more meaningful quantification of risk for the design and evaluation of past and future sensors, (2) to better predict new attack vectors, and (3) to establish defensive design patterns that make sensors more resistant to analog attacks. © 2020 IEEE.",,Risk assessment; Safety engineering; Signal processing; Availability and integrities; Design and evaluations; Primary contribution; Safety critical systems; Security properties; Sensor circuitry; Sensor measurements; Sensor securities; Transfer functions,,,,,"(1992) Copa Airlines Plane Crashes, , http://www.airsafe.com/events/airlines/copa.html; Frankel, T.C., (2018) Sensor Cited As Potential Factor in Boeing Crashing Draws Scrutiny, , https://www:washingtonpost:com/business/economy/sensor-cited-as-potential-factor-in-boeing-crashes-draws-scrutiny/2019/03/17/5ecf0b0e-4682-11e9-aaf8-4512a6fe3439story:html; (2016) A Tragic Loss, , https://www.tesla.com/blog/tragic-loss; Stewart, J., (2018) Why Tesla's Autopilot Can't See a Stopped Firetruck, , https://www:wired:com/story/tesla-autopilot-why-crash-radar; Cole, B., (2014) The Design Challenges of a Trillion Sensor World, , https://www.embedded.com/electronics-blogs/cole-bin/4433743/Thedesign-challenges-of-a-trillion-sensor-world; Koscher, K., Czeskis, A., Roesner, F., Patel, S., Kohno, T., Checkoway, S., McCoy, D., Shacham, H., Experimental security analysis of a modern automobile (2010) Proceedings of the 31st Ieee Symposium on Security and Privacy (SP), pp. 447-462; Checkoway, S., McCoy, D., Kantor, B., Anderson, D., Shacham, H., Savage, S., Koscher, K., Kohno, T., Comprehensive experimental analyses of automotive attack surfaces (2011) Proceedings of the 20th Usenix Security Symposium, pp. 447-462. , USENIX Association; Cho, K.-T., Shin, K.G., Fingerprinting electronic control units for vehicle intrusion detection (2016) Proceedings of the 25th Usenix Security Symposium, pp. 911-927. , USENIX Association; Cho, K.-T., Shin, K.G., Viden: Attacker identification on in-vehicle networks (2017) Proceedings of the 2017 Acm Conference on Computer and Communications Security (CCS), pp. 1109-1123; Xu, W., Trappe, W., Zhang, Y., Wood, T., The feasibility of launching and detecting jamming attacks in wireless networks (2005) Proceedings of the 6th Acm International Symposium on Mobile Ad Hoc Networking and Computing (MobiHoc), pp. 46-57; Xu, W., Ma, K., Trappe, W., Zhang, Y., Jamming sensor networks: Attack and defense strategies (2006) Ieee Network, 20 (3), pp. 41-47; Law, Y.W., Palaniswami, M., Hoesel, L.V., Doumen, J., Hartel, P., Havinga, P., Energy-efficient link-layer jamming attacks against wireless sensor network MAC protocols (2009) Acm Transactions on Sensor Networks (TOSN), 5 (1), p. 6; Roufa, I., Miller, R., Hossen, M., Taylor, T., Oh, S., Xu, W., Gruteser, M., Seskar, I., Security and privacy vulnerabilities of in-car wireless networks: A tire pressure monitoring system case study (2010) Proceedings of the 19th Usenix Security Symposium; Rouf, I., Mustafa, H., Xu, M., Xu, W., Miller, R., Gruteser, M., Neighborhood watch: Security and privacy analysis of automatic meter reading systems (2012) Proceedings of the 2012 Acm Conference on Computer and Communications Security (CCS), pp. 462-473; Bojinov, H., Michalevsky, Y., Nakibly, G., Boneh, D., (2014) Mobile Device Identification Via Sensor Fingerprinting; Dey, S., Roy, N., Xu, W., Choudhury, R.R., Nelakuditi, S., Accelprint: Imperfections of accelerometers make smartphones trackable (2014) Proceedings of the Network and Distributed System Security Symposium (NDSS); Zhou, X., Ji, X., Yan, C., Deng, J., Xu, W., Nauth: Secure face-to-face device authentication via nonlinearity (2019) Proceedings of the 2019 Ieee Conference on Computer Communications (INFOCOM), pp. 2080-2088; Zhang, J., Beresford, A.R., Sheret, I., Sensorid: Sensor calibration fingerprinting for smartphones (2019) Proceedings of the 40th Ieee Symposium on Security and Privacy (SP); Marquardt, P., Verma, A., Carter, H., Traynor, P., (sp)iphone: Decoding vibrations from nearby keyboards using mobile phone accelerometers (2011) Proceedings of the 18th Acm Conference on Computer and Communications Security (CCS), pp. 551-562; Cai, L., Chen, H., Touchlogger: Inferring keystrokes on touch screen from smartphone motion (2011) Proceedings of the 6th Usenix Workshop on Hot Topics in Security (HotSec), pp. 1-9; Miluzzo, E., Varshavsky, A., Balakrishnan, S., Choudhury, R.R., Tapprints: Your finger taps have fingerprints (2012) Proceedings of the 10th International Conference on Mobile Systems, Applications, and Services, pp. 323-336; Michalevsky, Y., Boneh, D., Nakibly, G., Gyrophone: Recognizing speech from gyroscope signals (2014) Proceedings of the 23rd Usenix Security Symposium, pp. 1053-1067; Spreitzer, R., Pin skimming: Exploiting the ambient-light sensor in mobile devices (2014) Proceedings of the 4th Acm Workshop on Security and Privacy in Smartphones & Mobile Devices, pp. 51-62; Sikder, A.K., Aksu, H., Uluagac, A.S., 6thsense: A context-aware sensor-based attack detector for smart devices (2017) Proceedings of the 26th Usenix Security Symposium, pp. 397-414; Petracca, G., Reineh, A.-A., Sun, Y., Grossklags, J., Jaeger, T., Aware: Preventing abuse of privacy-sensitive sensors via operation bindings (2017) Proceedings of the 26th Usenix Security Symposium, pp. 379-396; Kwong, A., Xu, W., Fu, K., Hard drive of hearing: Disks that eavesdrop with a synthesized microphone (2019) Proceedings of the 40th Ieee Symposium on Security and Privacy (SP), p. 15. , IEEE, May; Uluagac, A.S., Subramanian, V., Beyah, R., Sensory channel threats to cyber physical systems: A wake-up call (2014) Proceedings of the 2014 Ieee Conference on Communications and Network Security, pp. 301-309. , Oct; Jia, Y.J., Chen, Q.A., Wang, S., Rahmati, A., Fernandes, E., Mao, Z.M., Prakash, A., Unviersity, S.J., Contexlot: Towards providing contextual integrity to appified IoT platforms (2017) Proceedings of the Network and Distributed System Security Symposium (NDSS); Kumar, D., Paccagnella, R., Murley, P., Hennenfent, E., Mason, J., Bates, A., Bailey, M., Skill squatting attacks on amazon alexa (2018) Proceedings of the 27th Usenix Security Symposium, pp. 33-47; Zhang, N., Mi, X., Feng, X., Wang, X., Tian, Y., Qian, F., Dangerous skills: Understanding and mitigating security risks of voice-controlled third-party functions on virtual personal assistant systems (2019) Proceedings of the 40th Ieee Symposium on Security and Privacy (SP), pp. 1-16; Sousedik, C., Busch, C., Presentation attack detection methods for fingerprint recognition systems: A survey (2014) Iet Biometrics, 3 (4), pp. 219-233; Roy, A., Memon, N., Ross, A., Masterprint: Exploring the vulnerability of partial fingerprint-based authentication systems (2017) Ieee Transactions on Information Forensics and Security (TIFS), 12 (9), pp. 2013-2025; Zhang, Z., Yi, D., Lei, Z., Li, S.Z., Face liveness detection by learning multispectral reflectance distributions (2011) Proceedings of the 2011 International Conference on Automatic Face and Gesture Recognition, pp. 436-441; (2017) How Bkav Tricked Iphone X's Face Id with a Mask, , https://youtu:be/i4YQRLQVixM, B. Coporation; Congress, C.C., (2017) Hacking the Samsung Galaxy s8 Irisscanner, , https://media:ccc:de/v/biometrie-s8-iris-en#t=0; Carlini, N., Mishra, P., Vaidya, T., Zhang, Y., Sherr, M., Shields, C., Wagner, D., Zhou, W., Hidden voice commands (2016) Proceedings of the 25th Usenix Security Symposium, pp. 513-530; Carlini, N., Wagner, D., Audio adversarial examples: Targeted attacks on speech-to-text (2018) Proceedings of the 2018 Ieee Security and Privacy Workshops, pp. 1-7. , May; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-The-art face recognition (2016) Proceedings of the 2016 Acm Conference on Computer and Communications Security (CCS), pp. 1528-1540; Yuan, X., Chen, Y., Zhao, Y., Long, Y., Liu, X., Chen, K., Zhang, S., Gunter, C.A., Commandersong: A systematic approach for practical adversarial voice recognition (2018) Proceedings of the 27th Usenix Security Symposium, pp. 49-64; Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Xiao, C., Prakash, A., Song, D., Robust physical-world attacks on deep learning visual classification (2018) Proceedings of the 2018 Ieee Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1625-1634; Fu, K., Xu, W., Risks of trusting the physics of sensors (2018) Communications of the Acm, 61 (2), pp. 20-23; Son, Y., Shin, H., Kim, D., Park, Y.-S., Noh, J., Choi, K., Choi, J., Kim, Y., Rocking drones with intentional sound noise on gyroscopic sensors (2015) Proceedings of the 24th Usenix Security Symposium, pp. 881-896; Tu, Y., Lin, Z., Lee, I., Hei, X., Injected and delivered: Fabricating implicit control over actuation systems by spoofing inertial sensors (2018) Proceedings of the 27th Usenix Security Symposium. Usenix Association, pp. 1545-1562; Wang, Z., Wang, K., Yang, B., Li, S., Pan, A., (2017) Sonic Gun to Smart Devices, , Black Hat USA; Shin, H., Kim, D., Kwon, Y., Kim, Y., Illusion and dazzle: Adversarial optical channel exploits against lidars for automotive applications (2017) Proceedings of the 19th International Conference on Cryptographic Hardware and Embedded Systems (CHES), pp. 445-467. , Springer; Petit, J., Stottelaar, B., Feiri, M., Kargl, F., Remote attacks on automated vehicles sensors: Experiments on camera and lidar (2015) Black Hat Europe; Foo Kune, D., Backes, J., Clark, S.S., Kramer, D., Reynolds, M., Fu, K., Kim, Y., Xu, W., Ghost talk: Mitigating EMI signal injection attacks against analog sensors (2013) Proceedings of the 34th Ieee Symposium on Security and Privacy (SP), pp. 145-159; Kasmi, C., Esteves, J.L., IEMI threats for information security: Remote command injection on modern smartphones (2015) Ieee Transactions on Electromagnetic Compatibility, 57 (6), pp. 1752-1755; Giechaskiel, I., Rasmussen, K.B., (2019) Sok: Taxonomy and Challenges of Out-of-band Signal Injection Attacks and Defenses; Sikder, A.K., Petracca, G., Aksu, H., Jaeger, T., Uluagac, A.S., (2018) A Survey on Sensor-based Threats to Internet-of-things (IoT) Devices and Applications; Giechaskiel, I., Zhang, Y., Rasmussen, K.B., (2019) A Framework for Evaluating Security in the Presence of Signal Injection Attacks; (2019) List of Sensors, , https://en:wikipedia:org/wiki/Listofsensors; Wilson, J.S., (2004) Sensor Technology Handbook, , Elsevier; Grandke, T., Ko, W.H., (1989) Sensors a Comprehensive Survey 1: Fundamentals and General Aspects, , VCH, New York; Eargle, J., (2012) The Microphone Book: From Mono to Stereo to Surround-A Guide to Microphone Design and Application, , CRC Press; Engelsma, J.J., Arora, S.S., Jain, A.K., Paulter, N.G., Universal 3D wearable fingerprint targets: Advancing fingerprint reader evaluations (2018) Ieee Transactions on Information Forensics and Security (TIFS), 13 (6), pp. 1564-1578; Koch, E.-C., Review on pyrotechnic aerial infrared decoys (2001) Propellants, Explosives, Pyrotechnics, 26 (1), pp. 3-11; Sharma, K., Paradakar, M., The melamine adulteration scandal (2010) Food Security, 2 (1), pp. 97-107. , Mar; Trippel, T., Weisse, O., Xu, W., Honeyman, P., Fu, K., WALNUT: Waging doubt on the integrity of MEMS accelerometers with acoustic injection attacks (2017) Proceedings of the 2nd Ieee European Symposium on Security and Privacy (EuroS&P), pp. 3-18; Nise, N.S., (2007) Control Systems Engineering, , John Wiley & Sons; Fraden, J., (2004) Handbook of Modern Sensors: Physics, Designs, and Applications, , Springer Science & Business Media; Ono, K., Cho, H., Matsuo, T., Transfer functions of acoustic emission sensors (2008) Journal of Acoustic Emission, 26, pp. 72-91; Cochrun, B., Grabel, A., A method for the determination of the transfer function of electronic circuits (1973) Ieee Transactions on Circuit Theory, 20 (1), pp. 16-20; Ogata, K., Yang, Y., (2002) Modern Control Engineering, , Prentice-Hall; Parr, E.A., (2013) Logic Designer's Handbook: Circuits and Systems, , Elsevier; Sinclair, I., Dunton, J., (2007) Electronic and Electrical Servicing, Second Edition: Consumer and Commercial Electronics, 2nd Ed, , Newton, MA, USA: Newnes; Tuzlukov, V., (2002) Signal Processing Noise, , CRC Press; Xu, W., Yan, C., Jia, W., Ji, X., Liu, J., Analyzing and enhancing the security of ultrasonic sensors for autonomous vehicles (2018) Ieee Internet of Things Journal, 5 (6), pp. 5015-5029. , Dec; Wilson, M.J., Ford, S.R., Rinaldo, P.L., (2006) The Arrl Handbook for Radio Communications 2007, , Amer Radio Relay League; Yan, C., Xu, W., Liu, J., Can you trust autonomous vehicles: Contactless attacks against sensors of self-driving vehicle (2016) Def Con; Joffe, E.B., Lock, K.-S., (2011) Grounds for Grounding: A Circuit to System Handbook, , John Wiley & Sons; Rasmussen, K.B., Castelluccia, C., Heydt-Benjamin, T.S., Capkun, S., Proximity-based access control for implantable medical devices (2009) Proceedings of the 16th Acm Conference on Computer and Communications Security (CCS), pp. 410-419; Hu, Y.-C., Perrig, A., Johnson, D.B., Wormhole attacks in wireless networks (2006) Ieee Journal on Selected Areas in Communications, 24 (2), pp. 370-380; Esteves, J.L., Kasmi, C., (2018) Remote and Silent Voice Command Injection on a Smartphone through Conducted IEMI: Threats of Smart Iemi for Information Security, , Wireless Security Lab, French Network and Information Security Agency (ANSSI), Tech. Rep; Selvaraj, J., Dayanikli, G.Y., Gaunkar, N.P., Ware, D., Gerdes, R.M., Mina, M., Electromagnetic induction attacks against embedded systems (2018) Proceedings of the 2018 on Asia Conference on Computer and Communications Security (AsiaCCS), pp. 499-510; Selvaraj, J., (2018) Intentional Electromagnetic Interference Attack on Sensors and Actuators, , Ph.D. dissertation, Iowa State University; Ware, D.A., (2017) Effects of Intentional Electromagnetic Interference on Analog to Digital Converter Measurements of Sensor Outputs and General Purpose Input Output Pins, , Master's thesis, Utah State University; Attenuation of Sound Waves, , https://www:nde-ed:org/EducationResources/CommunityCollege/Ultrasonics/Physics/attenuation:htm, NDT Resource Center; Canada, H., (1991) Guidelines for the Safe Use of Ultrasound: Part II-industrial and Commercial Applications Safety Code 24; Yan, C., Zhang, G., Ji, X., Zhang, T., Zhang, T., Xu, W., The feasibility of injecting inaudible voice commands to voice assistants (2019) Ieee Transactions on Dependable and Secure Computing (TDSC); Yan, C., Fu, K., Xu, W., On Cuba, diplomats, ultrasound, and intermodulation distortion (2019) Computers in Biology and Medicine, 104, pp. 250-266; Bjørnø, L., Introduction to nonlinear acoustics (2010) Physics Procedia, 3 (1), pp. 5-16; Hamilton, M.F., Blackstock, D.T., (1998) Nonlinear Acoustics, 1. , Academic press San Diego; Castro, S., Dean, R., Roth, G., Flowers, G.T., Grantham, B., Influence of acoustic noise on the dynamic performance of MEMS gyroscopes (2007) Proceedings of the Asme 2007 International Mechanical Engineering Congress and Exposition. American Society of Mechanical Engineers, pp. 1825-1831; Giri, D., Tesche, F., Classification of intentional electromagnetic environments (IEME) (2004) Ieee Transactions on Electromagnetic Compatibility, 46 (3), pp. 322-328; Bolton, C., Rampazzi, S., Li, C., Kwong, A., Xu, W., Fu, K., Blue note: How intentional acoustic interference damages availability and integrity in hard disk drives and operating systems (2018) Proceedings of the 39th Ieee Symposium on Security and Privacy (SP), pp. 1048-1062. , May; Park, Y., Son, Y., Shin, H., Kim, D., Kim, Y., This ain't your dose: Sensor spoofing attack on medical infusion pump (2016) Proceedings of the 10th Usenix Workshop on Offensive Technologies (WOOT); Smillie, G., 2-analogue modulation principles (1999) Analogue and Digital Communication Techniques, G. Smillie, Ed. Oxford: Butterworth-Heinemann, pp. 15-45; Horowitz, P., Hill, W., (1989) The Art of Electronics, , Cambridge Univ. Press; Zhang, G., Yan, C., Ji, X., Zhang, T., Zhang, T., Xu, W., DolphinAttack: Inaudible voice commands (2017) Proceedings of the 2017 Acm Conference on Computer and Communications Security (CCS); Roy, N., Shen, S., Hassanieh, H., Choudhury, R.R., Inaudible voice commands: The long-range attack and defense (2018) Proceedings of the 15th Usenix Symposium on Networked Systems Design and Implementation (NSDI), pp. 547-560. , USENIX Association; Song, L., Mittal, P., (2017) Inaudible Voice Commands; (2018) System-level Esd Protection Guide, , Texas Instruments Texas Instruments, Tech. Rep; Rostamzadeh, C., Canavero, F., Kashefi, F., Darbandi, M., Effectiveness of multilayer ceramic capacitors for electrostatic discharge protection (2012) Compliance Magazine; Chauhan, R., (2014) A Platform for False Data Injection in Frequency Modulated Continuous Wave Radar, , Master's thesis, Utah State University; Shoukry, Y., Martin, P., Tabuada, P., Srivastava, M., Non-invasive spoofing attacks for anti-lock braking systems (2013) Proceedings of the 15th International Workshop on Cryptographic Hardware and Embedded Systems (CHES), pp. 55-72. , Springer; Sakr, Y.S., (2015) Security and Privacy in Cyber-physical Systems: Physical Attacks and Countermeasures, , Ph.D. dissertation, UCLA; Davidson, D., Wu, H., Jellinek, R., Ristenpart, T., Singh, V., Controlling UAVs with sensor input spoofing attacks (2016) Proceedings of the 10th Usenix Workshop on Offensive Technologies (WOOT); Nashimoto, S., Suzuki, D., Sugawara, T., Sakiyama, K., Sensor con-fusion: Defeating kalman filter in signal injection attack (2018) Proceedings of the 2018 on Asia Conference on Computer and Communications Security (AsiaCCS), pp. 511-524; Roy, N., Hassanieh, H., Roy Choudhury, R., Backdoor: Making microphones hear inaudible sounds (2017) Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services (MobiSys), pp. 2-14; Shen, H., Zhang, W., Fang, H., Ma, Z., Yu, N., Jamsys: Coverage optimization of a microphone jamming system based on ultrasounds (2019) Ieee Access, 7, pp. 67483-67496; Chen, Y., Li, H., Nagels, S., Li, Z., Lopes, P., Zhao, B.Y., Zheng, H., (2019) Understanding the Effectiveness of Ultrasonic Microphone Jammer; Maruyama, S., Wakabayashi, S., Mori, T., Tap 'n ghost: A compilation of novel attack techniques against smartphone touchscreens (2019) Proceedings of the 40th Ieee Symposium on Security and Privacy (SP), pp. 628-645; Shannon, C.E., Communication in the presence of noise (1998) Proceedings of the Institute of Radio Engineers, 86 (2), pp. 447-457; Oppenheim, A.V., Schafer, R.W., (2009) Discrete-Time Signal Processing, 3rd Ed, , Upper Saddle River, NJ, USA: Prentice Hall Press; Shoukry, Y., Martin, P., Yona, Y., Diggavi, S., Srivastava, M., PyCRA: Physical challenge-response authentication for active sensors under spoofing attacks (2015) Proceedings of the 2015 Acm Conference on Computer and Communications Security (CCS), pp. 1004-1015; Muniraj, D., Farhood, M., Detection and mitigation of actuator attacks on small unmanned aircraft systems (2019) Control Engineering Practice, 83, pp. 188-202; Shin, H., Son, Y., Park, Y., Kwon, Y., Kim, Y., Sampling race: Bypassing timing-based analog active sensor spoofing detection on analog-digital systems (2016) Proceedings of the 10th Usenix Workshop on Offensive Technologies (WOOT); Fischler, M.A., Bolles, R.C., Random sample consensus: A paradigm for model fitting with applications to image analysis and automated cartography (1981) Communications of the Acm, 24 (6), pp. 381-395; Lucas, B.D., Kanade, T., An iterative image registration technique with an application to stereo vision (1981) Proceedings of the 7th International Joint Conference on Artificial Intelligence, , Morgan Kaufmann Publishers Inc; Pace, P.E., (2009) Detecting and Classifying Low Probability of Intercept Radar, , Artech House; Tu, Y., Rampazzi, S., Hao, B., Rodriguez, A., Fu, K., Hei, X., (2019) Trick or Heat? Attack on Amplification Circuits to Abuse Critical Temperature Control Systems","Yan, C.; Zhejiang UniversityChina; 电子邮件: yanchen@zju.edu.cn
Xu, W.; Zhejiang UniversityChina; 电子邮件: wyxu@zju.edu.cn
Shin, H.; KAIST电子邮件: h.c.shin@kaist.ac.kr
Kim, Y.; KAIST电子邮件: yongdaek@kaist.ac.kr
Bolton, C.; University of MichiganUnited States; 电子邮件: mcbolto@umich.edu
Fu, K.; University of MichiganUnited States; 电子邮件: kevinfu@umich.edu",,,Institute of Electrical and Electronics Engineers Inc.,"41st IEEE Symposium on Security and Privacy, SP 2020",18 May 2020 through 21 May 2020,,162113,10816011,9.78E+12,,,English,Proc. IEEE Symp. Secur. Privacy,Conference Paper,Final,"All Open Access, Bronze",Scopus,2-s2.0-85091577331
"Abdelkader A., Curry M.J., Fowl L., Goldstein T., Schwarzschild A., Shu M., Studer C., Zhu C.",23007519300;57212527170;57211071247;14055829100;57218453716;57218455191;22036392500;57217437192;,Headless Horseman: Adversarial Attacks on Transfer Learning Models,2020,"ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings",2020-May,,9053181,3087,3091,,,10.1109/ICASSP40776.2020.9053181,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089238589&doi=10.1109%2fICASSP40776.2020.9053181&partnerID=40&md5=7eb0ab4ffac45ae0372b7e6257d35673,"University of Maryland, Dept. of Computer Science, United States; University of Maryland, Dept. of Mathematics, United States; Cornell Tech","Abdelkader, A., University of Maryland, Dept. of Computer Science, United States; Curry, M.J., University of Maryland, Dept. of Computer Science, United States; Fowl, L., University of Maryland, Dept. of Mathematics, United States; Goldstein, T., University of Maryland, Dept. of Computer Science, United States; Schwarzschild, A., University of Maryland, Dept. of Mathematics, United States; Shu, M., University of Maryland, Dept. of Computer Science, United States; Studer, C., Cornell Tech; Zhu, C., University of Maryland, Dept. of Computer Science, United States","Transfer learning facilitates the training of task-specific classifiers using pre-trained models as feature extractors. We present a family of transferable adversarial attacks against such classifiers, generated without access to the classification head; we call these headless attacks. We first demonstrate successful transfer attacks against a victim network using only its feature extractor. This motivates the introduction of a label-blind adversarial attack. This transfer attack method does not require any information about the class-label space of the victim. Our attack lowers the accuracy of a ResNet18 trained on CIFAR10 by over 40%. © 2020 IEEE.",adversarial; attack; implicit regularization; synthetic labels; Transfer Learning,Audio signal processing; Learning systems; Speech communication; Attack methods; Class labels; Feature extractor; Transfer learning,,,,,"He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826; Yosinski, J., Clune, J., Bengio, Y., Lipson, H., How transferable are features in deep neural networks? (2014) Advances in Neural Information Processing Systems, pp. 3320-3328; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security. ACM, pp. 506-519; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Deng, J., Dong, W., Socher, R., Li, L., Li, K., Fei-Fei, L., Imagenet: A large-scale hierarchical image database (2009) 2009 IEEE Conference on Computer Vision and Pattern Recognition. Ieee, pp. 248-255; Bengio, Y., Deep learning of representations for unsupervised and transfer learning Proceedings of ICML Workshop on Unsupervised and Transfer Learning, pp. 17-36. , Isabelle Guyon, Gideon Dror, Vincent Lemaire, Graham Taylor, and Daniel Silver, Eds., Bellevue, Washington, USA, 02 Jul 2012 27 of Proceedings of Machine Learning Research PMLR; Mao, J., Jain, A.K., Artificial neural networks for feature extraction and multivariate data projection (1995) IEEE Transactions on Neural Networks, 6 (2), pp. 296-317; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Machine Learning at Scale; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks; Moosavi-Dezfooli, S., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP), , May; Papernot, N., McDaniel, P.D., Goodfellow, I.J., Transferability in machine learning: From phenomena to black-box attacks using adversarial samples (2016) CoRR, , Abs/1605. 07277; Ilyas, A., Engstrom, L., Madry, A., (2018) Prior Convictions: Black-box Adversarial Attacks with Bandits and Priors; Nitin Bhagoji, A., He, W., Li, B., Song, D., (2017) Exploring the Space of Black-box Attacks on Deep Neural Networks; Demontis, A., Melis, M., Pintor, M., Jagielski, M., Biggio, B., Oprea, A., Nita-Rotaru, C., Roli, F., Why do adversarial attacks transfer? Explaining transferability of evasion and poisoning attacks (2019) 28th FUSENIXg Security Symposium (FUSENIXg Security 19), pp. 321-338; Wang, B., Yao, Y., Viswanath, B., Zheng, H., Zhao, B.Y., With great training comes great vulnerability: Practical attacks against transfer learning (2018) 27th USENIX Security Symposium (USENIX Security 18), pp. 1281-1297. , Baltimore, MD, Aug. USENIX Association; Uday Prabhu, V., Whaley, J., On Grey-box Adversarial Attacks and Transfer Learning, , https://unify.id/wpcontent/uploads/2018/03/greyboxattack.pdf; Krizhevsky, A., Nair, V., Hinton, G., (2014) The cifar-10 Dataset, 55. , http://www.cs.toronto.edu/kriz/cifar.html; Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., Chen, L., Mobilenetv2: Inverted residuals and linear bottlenecks (2018) 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, , Jun; Hu, J., Shen, L., Sun, G., Squeeze-and-excitation networks (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 7132-7141",,,"The Institute of Electrical and Electronics Engineers, Signal Processing Society",Institute of Electrical and Electronics Engineers Inc.,"2020 IEEE International Conference on Acoustics, Speech, and Signal Processing, ICASSP 2020",4 May 2020 through 8 May 2020,,161907,15206149,9.78E+12,IPROD,,English,ICASSP IEEE Int Conf Acoust Speech Signal Process Proc,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85089238589
"Ye G., Tang Z., Fang D., Zhu Z., Feng Y., Xu P., Chen X., Han J., Wang Z.",57193613039;15822992800;8975043000;57200340512;55387599700;56672326500;8317069000;14522692900;35111811300;,Using Generative Adversarial Networks to Break and Protect Text Captchas,2020,ACM Transactions on Privacy and Security,23,2,7,,,,6,10.1145/3378446,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085590553&doi=10.1145%2f3378446&partnerID=40&md5=3aba184ec410d3be9f38fd4c5a9ef18e,"Northwest University, China; Peking University, China; University of Warwick, United Kingdom; University of Leeds, United Kingdom","Ye, G., Northwest University, China; Tang, Z., Northwest University, China; Fang, D., Northwest University, China; Zhu, Z., Peking University, China; Feng, Y., Peking University, China; Xu, P., Northwest University, China; Chen, X., Northwest University, China; Han, J., University of Warwick, United Kingdom; Wang, Z., University of Leeds, United Kingdom","Text-based CAPTCHAs remains a popular scheme for distinguishing between a legitimate human user and an automated program. This article presents a novel genetic text captcha solver based on the generative adversarial network. As a departure from prior text captcha solvers that require a labor-intensive and time-consuming process to construct, our scheme needs significantly fewer real captchas but yields better performance in solving captchas. Our approach works by first learning a synthesizer to automatically generate synthetic captchas to construct a base solver. It then improves and fine-tunes the base solver using a small number of labeled real captchas. As a result, our attack requires only a small set of manually labeled captchas, which reduces the cost of launching an attack on a captcha scheme. We evaluate our scheme by applying it to 33 captcha schemes, of which 11 are currently used by 32 of the top-50 popular websites. Experimental results demonstrate that our scheme significantly outperforms four prior captcha solvers and can solve captcha schemes where others fail. As a countermeasure, we propose to add imperceptible perturbations onto a captcha image. We demonstrate that our countermeasure can greatly reduce the success rate of the attack. © 2020 ACM.",authentication; generative adversarial networks; security; Text captchas; transfer learning,Adversarial networks; CAPTCHAs; Human users; Labor intensive; Electronic mail filters,,,,,"Algwil, A., Ciresan, D.C., Liu, B., Yan, J., A security analysis of automated Chinese turing tests (2016) Proceedings of the 32nd Annual Conference on Computer Security Applications., pp. 520-532; Arjovsky, M., Chintala, S., Bottou, L., Wasserstein generative adversarial networks (2017) Proceedings of the International Conference on Machine Learning., pp. 214-223; Athanasopoulos, E., Antonatos, S., Enhanced CAPTCHAs: Using animation to tell humans and computers apart (2006) Proceedings of the Ifip International Conference on Communications and Multimedia Security., pp. 97-108; Audet, C., Dennis, J.E., Jr., Mesh adaptive direct search algorithms for constrained optimization (2006) Siam J. Optimiz., 17 (1), pp. 188-217. , 2006; Barreno, M., Nelson, B., Sears, R., Joseph, A.D., Tygar, J.D., Can machine learning be secure? (2006) Proceedings of the Acm Symposium on Information, Computer and Communications Security., pp. 16-25; Bigham, J.P., Cavender, A.C., Evaluating existing audio CAPTCHAs and an interface optimized for non-visual use (2009) Proceedings of the Sigchi Conference on Human Factors in Computing Systems., pp. 1829-1838; Bursztein, E., (2012) How We Broke the NuCaptcha Video Scheme and What We Proposed to Fix It, , https://elie.net/blog/security/how-we-broke-the-nucaptcha-video-scheme-and-what-we-propose-to-fix-it, Retrieved from; Bursztein, E., Aigrain, J., Moscicki, A., Mitchell, J.C., The end is nigh: Generic solving of text-based CAPTCHAs (2014) Proceedings of the Usenix Workshop on Offensive Technologies (WOOT'14); Bursztein, E., Bethard, S., Decaptcha: Breaking 75% of eBay audio CAPTCHAs (2009) Proceedings of the Usenix Conference on Offensive Technologies., p. 8; Bursztein, E., Martin, M., Mitchell, J., Text-based CAPTCHA strengths and weaknesses (2011) Proceedings of the Conference on Computer and Communications Security (CCS'11)., pp. 125-138; Bursztein, E., Moscicki, A., Fabry, C., Bethard, S., Mitchell, J.C., Dan, J., Easy does it: More usable CAPTCHAs (2014) Proceedings of the Acm Conference on Human Factors in Computing Systems., pp. 2637-2646; Chellapilla, K., Larson, K., Simard, P.Y., Czerwinski, M., Computers beat humans at single character recognition in reading based human interaction proofs (HIPs) (2005) Proceedings of the Conference on Email & Anti-Spam; Chew, M., Tygar, J.D., Image recognition captchas (2004) Proceedings of the International Conference on Information Security., pp. 268-279. , Springer; Elson, J., Douceur, J.R., Howell, J., Saul, J., Asirra: A CAPTCHA that exploits interest-aligned manual image categorization (2007) Proceedings of the Acm Conference on Computer and Communications Security (CCS'07)., pp. 366-374; Fuglede, B., Topsoe, F., Jensen-Shannon divergence and Hilbert space embedding (2004) Proceedings of the International Symposium on Information Theory (ISIT'04)., p. 31. , IEEE; Gao, H., Tang, M., Liu, Y., Zhang, P., Liu, X., Research on the security of Microsoft's two-layer captcha (2017) Ieee Trans. Info. Forensics Secur., 12 (7), pp. 1671-1685. , 2017; Gao, H., Wei, W., Wang, X., Liu, X., Yan, J., The robustness of hollow CAPTCHAs (2013) Proceedings of the Acm Sigsac Conference on Computer & Communications Security., pp. 1075-1086; Gao, H., Yan, J., Cao, F., Zhang, Z., Lei, L., Tang, M., Zhang, P., Li, J., A simple generic attack on text captchas (2016) Proceedings of the Network and Distributed Systems Symposium (NDSS'16); Gao, S., (2014) An Evolutionary Study of Dynamic Cognitive Game CAPTCHAs: Automated Attacks and Defenses., , Dissertations Theses Gradworks. University of Alabama, Birminghan; George, D., Lehrach, W., Kansky, K., Lazaro-Gredilla, M., Laan, C., Marthi, B., Lou, X., Wang, H., A generative vision model that trains with high data efficiency and breaks text-based CAPTCHAs (2017) Science, 358 (6368), p. eaag2612. , 2017; Gold, C., Holub, A., Sollich, P., Bayesian approach to feature selection and parameter tuning for support vector machine classifiers (2005) Neural Netw., 18 (5), pp. 693-701. , 2005; Golle, P., Machine learning attacks against the Asirra CAPTCHA (2008) Comput. Commun. Secur., 2008, pp. 535-542. , 2008; Goodfellow, I.J., Bulatov, Y., Ibarz, J., Arnoud, S., Shet, V., Multi-digit number recognition from street view imagery using deep convolutional neural networks (2014) Proceedings of the International Conference on Learning Representations (ICLR'14); Goodfellow, I.J., Pougetabadie, J., Mirza, M., Xu, B., Wardefarley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial networks (2014) Adv. Neural Info. Process. Syst., 3, pp. 2672-2680. , 2014; Goodfellow, I.J., Shlens, J., Szegedy, C., Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) Proceedings of the International Conference on Machine Learning (ICML'15)., pp. 1-10; Goodfellow, I.J., Warde-Farley, D., Mirza, M., Courville, A., Bengio, Y., (2013) Maxout Networks, , arXiv preprint arXiv:1302.4389; Gossweiler, R., Kamvar, M., Baluja, S., What's up CAPTCHA?: A CAPTCHA based on image orientation (2009) Proceedings of the International Conference on World Wide Web (WWW'09)., pp. 841-850; Greg, M., Malik, J., Recognizing objects in adversarial cultter: Breaking a visual CAPTCHA (2003) Proceedings of the Ieee Computer Society Conferene on Computer Vision and Pattern Recognition; He, K., Gkioxari, G., Dollar, P., Girshick, R., Mask R-CNN (2017) Proceedings of the Ieee International Conference on Computer Vision (ICCV'17)., pp. 2980-2988; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the Ieee Conference on Computer Vision and Pattern Recognition., pp. 770-778; Hecht-Nielsen, R., (1989) Theory of the Backpropagation Neural Network., pp. 593-605. , Harcourt Brace & Co; Hernandezcastro, C.J., Ribagorda, A., Saez, Y., Side-channel attack on labeling CAPTCHAs (2009) Comput. Sci., , ArXiv Preprint ArXiv:0908.1185; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I.P., Tygar, J.D., Adversarial machine learning (2011) Ieee Internet Comput., 15 (5), pp. 4-6. , 2011; Isola, P., (2017) Pix2Pix: Image-to-Image Translation with COnditional Adversarial Networks, , https://github.com/phillipi/pix2pix, Retrieved from; Isola, P., Zhu, J.-Y., Zhou, T., Efros, A.A., Image-to-Image translation with conditional adversarial networks [C] (2017) Proceedings of the Ieee Conference on Computer Vision and Pattern Recognition., pp. 1125-1134; Wilkins, J., (2010) Strong Captcha Guidelines v1. 2 [J]., 10, p. 8. , 2010; Jiang, Z., Zhao, J., Li, X.-Y., Han, J., Xi, W., Rejecting the attack: Source authentication for wi-fi management frames using csi information (2013) Proceedings of the Ieee INFOCOM., pp. 2544-2552; Kingma, D.P., Ba, J., Adam: A method for stochastic optimization [C] (2015) Proceedings of the International Conference on Learning Representations; Krol, K., Parkin, S., Sasse, M.A., Better the devil you know: A user study of two CAPTCHAs and a possible replacement technology (2016) Proceedings of the Ndss Workshop on Usable Security; Lea, C., Vidal, R., Reiter, A., Hager, G.D., Temporal convolutional networks: A unified approach to action segmentation (2016) Proceedings of the European Conference on Computer Vision., pp. 47-54; Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. Ieee, 86 (11), pp. 2278-2324. , 1998; Li, J., Monroe, W., Shi, T., Jean, S., Ritter, A., Jurafsky, D., Adversarial learning for neural dialogue generation (2017) Proceedings of the Conference on EmpiricalMethods in Natural Language Processing., pp. 2157-2169; Liang, B., Li, H., Su, M., Li, X., Shi, W., XiaoFeng Wang., Detecting adversarial image examples in deep neural networks with adaptive noise reduction (2019) Ieee Trans. Depend. Secure Comput., p. 1. , 2019; Lin, M., Chen, Q., Yan, S., (2013) Network in Network, , arXiv preprint arXiv:1312.4400; McEwan, E.K., (2008) Root Words, Roots and Affixes., , http://www.readingrockets.org/article/root-words-roots-and-affixes, Retrieved from; Meutzner, H., Kolossa, D., Reducing the cost of breaking audio CAPTCHAs by active and semisupervised learning (2014) Proceedings of the International Conference on Machine Learning and Applications., pp. 67-73; Miyato, T., Maeda, S., Koyama, M., Nakae, K., Ishii, S., Distributional smoothing by virtual adversarial examples (2015) Proceedings of the International Conference on Learning Representations (Poster); Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D., Riedmiller, M., (2013) Playing Atari with Deep Reinforcement Learning, , ArXiv Preprint ArXiv:1312.5602; Mohamed, M., Sachdeva, N., Georgescu, M., Gao, S., Saxena, N., Zhang, C., Kumaraguru, P., Chen, W.B., A three-way investigation of a game-CAPTCHA:automated attacks, relay attacks and usability (2014) Proceedings of the Acm Symposium on Information, Computer and Communications Security., pp. 195-206; Mohameda, M., Gaob, S., Sachdevac, N., Saxena, N., Zhangd, C., Kumaraguruc, P., Van Oorschote, P.C., On the security and usability of dynamic cognitive game CAPTCHAs (2017) J. Comput. Secur., 25 (3), pp. 205-230. , 2017; Osadchy, M., Hernandez-Castro, J., Gibson, S., Dunkelman, O., Perez-Cabo, D., No bot expects the DeepCAPTCHA! introducing immutable adversarial examples, with applications to CAPTCHA generation (2017) Ieee Transactions on Information Forensics and Security, 12 (11), pp. 2640-2653. , 2017; Pan, S.J., Yang, Q., A survey on transfer learning (2010) Ieee Trans. Knowl. Data Eng., 22 (10), pp. 1345-1359. , 2010; Rosenberg, I., Shabtai, A., Rokach, L., Elovici, Y., (2017) Generic Black-box End-to-end Attack Against RNNs and Other Api Calls Based Malware Classifiers, , arXiv preprint arXiv:1707.05970; Rubenking, N.J., (2013) Are You a Human., , https://www.areyouahuman.com, Retrieved from; Schlaikjer, A., (2007) A Dual-use Speech CAPTCHA: Aiding Visually Impaired Web Users while Providing Transcriptions of Audio Streams, , LTI-CMU Technical Report, 07-014; (2010) NuCaptcha, , www.nucaptcha.com, NuData Security Retrieved from; Shahzad, M., Liu, A.X., Samuel, A., Behavior based human authentication on touch screen devices using gestures and signatures (2017) Ieee Trans. Mobile Comput., 16 (10), pp. 2726-2741. , 2017; Shi, C., Xu, X., Ji, S., Bu, K., Chen, J., Beyah, R.A., Wang, T., (2019) Adversarial CAPTCHAs, , http://arxiv.org/abs/1901.01107, Retrieved from; Shrivastava, A., Pfister, T., Tuzel, O., Susskind, J., Wang, W., Webb, R., Learning from simulated and unsupervised images through adversarial training (2017) Proceedings of the Ieee Conference on Computer Vision and Pattern Recognition (CVPR'17); Simonyan, K., Zisserman, A., (2014) Proceedings of the International Conference on Learning Representations; Sivakorn, S., Polakis, I., Keromytis, A.D., I am robot: (Deep) learning to break semantic image CAPTCHAs (2016) Proceedings of the Ieee European Symposium on Security and Privacy., pp. 388-403; Stark, F., Hazirbas, C., Triebel, R., Cremers, D., CAPTCHA recognition with active deep learning (2015) Proceedings of the German Conference on Pattern Recognition Workshop; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) Proceedings of the Ieee Conference on Computer Vision and Pattern Recognition., pp. 1-9; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the Ieee Conference on Computer Vision and Pattern Recognition (CVPR'16)., pp. 2818-2826; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) Proceedings of the International Conference on Learning Representations (ICLR); Tam, J., Simsa, J., Hyde, S., Von Ahn, L., Breaking audio CAPTCHAs (2008) Proceedings of the Conference on Neural Information Processing Systems., pp. 1625-1632; Von Ahn, L., Blum, M., Hopper, N.J., Langford, J., (2003) CAPTCHA: Using Hard Ai Problems for Security., pp. 294-311. , Springer, Berlin; Von Ahn, L., Blum, M., Langford, J., Telling humans and computers apart automatically (2004) Commun. Acm, 47 (2), pp. 56-60. , 2004; Xie, C., Zhang, Z., Zhou, Y., Bai, S., Wang, J., Ren, Z., Yuille, A.L., Improving transferability of adversarial examples with input diversity (2019) Proceedings of the Ieee Conference on Computer Vision and Pattern Recognition (CVPR'19); Xu, W., Qi, Y., Evans, D., Automatically evading classifiers: A case study on PDF malware classifiers (2016) Proceedings of the Network and Distributed System Security Symposium; Xu, Y., Reynaga, G., Chiasson, S., Frahm, J.-M., Monrose, F., Van Oorschot, P.C., Security analysis and related usability of motion-based captchas: Decoding codewords inmotion (2014) Ieee Trans. Depend. Secure Comput., 11 (5), pp. 480-493. , 2014; Yan, J., El Ahmad, A.S., Breaking visual CAPTCHAs with Naive pattern recognition algorithms (2007) Proceedings of the Computer Security Applications Conference (ACSAC'07). Twenty-Third Annual., pp. 279-291; Yan, J., El Ahmad, A.S., A low-cost attack on a Microsoft captcha (2008) Proceedings of the Acm Conference on Computer and Communications Security (CCS'08), pp. 543-554. , Alexandria, Virginia, Usa, October; Ye, G., Tang, Z., Fang, D., Zhu, Z., Feng, Y., Xu, P., Chen, X., Wang, Z., Yet another text captcha solver: A generative adversarial network based approach (2018) Proceedings of the Acm Sigsac Conference on Computer and Communications Security., pp. 332-348. , ACM; Yosinski, J., Clune, J., Bengio, Y., Lipson, H., How transferable are features in deep neural networks? (2014) Advances in Neural Information Processing Systems., pp. 3320-3328. , MIT Press; Yu, L., Zhang, W., Wang, J., Yu, Y., SeqGAN: Sequence generative adversarial nets with policy gradient (2016) Proceedings of the Thirty-First Association for the Advancement of Artificial Intelligence., pp. 2852-2858; Zhu, J.-Y., Park, T., Isola, P., Efros, A.A., (2017) Unpaired Image-to-image Translation Using Cycleconsistent Adversarial Networks, , arXiv preprint arXiv:1703.10593","Tang, Z.; Northwest UniversityChina; 电子邮件: zytang@nwu.edu.cn",,,Association for Computing Machinery,,,,,24712566,,,,English,ACM Trans. Priv. Secur.,Article,Final,"All Open Access, Green",Scopus,2-s2.0-85085590553
"Anand D., Tank D., Tibrewal H., Sethi A.",57201792526;57217028088;56716193900;12775689700;,Self-Supervision vs. Transfer Learning: Robust Biomedical Image Analysis Against Adversarial Attacks,2020,Proceedings - International Symposium on Biomedical Imaging,2020-April,,9098369,1159,1163,,4,10.1109/ISBI45749.2020.9098369,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085861707&doi=10.1109%2fISBI45749.2020.9098369&partnerID=40&md5=ba4d25761938c306d0f4ea8cef094637,"IIT Bombay, Department of Electrical Engineering, India","Anand, D.; Tank, D.; Tibrewal, H., IIT Bombay, Department of Electrical Engineering, India; Sethi, A., IIT Bombay, Department of Electrical Engineering, India","Deep neural networks are being increasingly used for disease diagnosis and lesion localization on biomedical images. However, training deep neural networks not only requires large sets of expensive ground truth (image labels or pixel annotations); they are also susceptible to adversarial attacks. Transfer learning alleviates the former problem to some extent, wherein the lower layers of a neural network are pre-trained on a large labeled dataset from a different domain (e.g., ImageNet), while only the upper layers are fine-tuned on the target domain (e.g., chest X-rays). An alternative to transfer learning is self-supervised learning, in which a supervised task is created using the unlabeled images from the target domain itself to pre-train the lower layers. In this work, we show that self-supervised learning combined with adversarial training offers additional advantages over transfer learning as well as vanilla self-supervised learning. In particular, the process of adversarial training itself acts as data augmentation for self-supervision. This adversarial data augmentation leads to both a reduction in the amount of supervised data required for comparable accuracy, as well as natural robustness to adversarial attacks. We support our claims using experiments on the two modalities and tasks - classification of chest X-rays, and segmentation of MRI images. © 2020 IEEE.",annotation cost; deep learning; l-{\infty} adversarial attack; radiology; Self-supervision; transfer learning,Deep learning; Deep neural networks; Diagnosis; Image segmentation; Large dataset; Magnetic resonance imaging; Medical imaging; Multilayer neural networks; Supervised learning; X rays; Biomedical image analysis; Biomedical images; Chest x-rays; Data augmentation; Different domains; Disease diagnosis; Labeled dataset; Target domain; Transfer learning,,,,,"Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classi-cation with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Yosinski, J., Clune, J., Bengio, Y., Lipson, H., How transferable are features in deep neural networks (2014) Advances in Neural Information Process-ing Systems, pp. 3320-3328; Bengio, Y., Deep learning of representations for unsupervised and transfer learning (2012) Proceedings of ICML Workshop on Unsupervised and Transfer Learning, pp. 17-36; Liu, Y., Gadepalli, K., Norouzi, M., Dahl, G.E., Kohlberger, T., Boyko, A., Venugopalan, S., Corrado, G.S., (2017) Detecting Cancer Metastases on Gigapixel Pathology Images, , arXiv preprint arXiv: 1703.02442; Rajpurkar, P., Irvin, J., Zhu, K., Yang, B., Mehta, H., Duan, T., Ding, D., Shpanskaya, K., (2017) Chexnet: Radiologist-level Pneumonia Detection on Chest X-rays with Deep Learning, , arXiv preprint arXiv: 1711.05225; Lin, T., Dolĺar, P., Girshick, R., He, K., Hariharan, B., Belongie, S., Feature pyramid networks for object detection (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2117-2125; Doersch, C., Gupta, A., Efros, A.A., Unsupervised visual representation learning by context prediction (2015) Proceedings of the IEEE International Con-ference on Computer Vision, pp. 1422-1430; Noroozi, M., Favaro, P., Unsupervised learning of visual representations by solving jigsaw puzzles (2016) European Conference on Computer Vision. Springer, pp. 69-84; Ji, X., Henriques, J.F., Vedaldi, A., (2018) Invariant Information Distillation for Unsupervised Image Segmentation and Clustering, , arXiv preprint arXiv: 1807.06653; Hénaff, O.J., Razavi, A., Doersch, C., Eslami, S.M., Oord Den A.Van, (2019) Data-ef-cient Image Recognition with Contrastive Predictive Coding, , arXiv preprint arXiv: 1905.09272; Chen, L., Bentley, P., Mori, K., Misawa, K., Fujiwara, M., Rueckert, D., Selfsupervised learning for medical image analysis using image context restoration (2019) Medical Image Analysis, 58, p. 101539; Tajbakhsh, N., Hu, Y., Cao, J., Yan, X., Xiao, Y., Lu, Y., Liang, J., Ding, X., (2019) Surrogate Supervision for Medical Image Analysis: Effective Deep Learning from Limited Quantities of Labeled Data, , arXiv preprint arXiv: 1901.08707; Bai, W., Chen, C., Tarroni, G., Duan, J., Guitton, F., Petersen, S.E., Guo, Y., Rueckert, D., (2019) Selfsupervised Learning for Cardiac Mr Image Segmentation by Anatomical Position Prediction, , arXiv preprint arXiv: 1907.02757; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., Adversarial examples for semantic segmentation and object detection (2017) Pro-ceedings of the IEEE International Conference on Com-puter Vision, pp. 1369-1378; Arnab, A., Miksik, O., Torr, P.H.S., On the robustness of semantic segmentation models to adversarial attacks (2018) Proceedings of the IEEE Con-ference on Computer Vision and Pattern Recognition, pp. 888-897; Hendrycks, D., Mazeika, M., Kadavath, S., Song, D., (2019) Using Self-supervised Learning Can Improve Model Robustness and Uncertainty, , arXiv preprint arXiv: 1906.12340; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , arXiv preprint arXiv: 1706.06083; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint arXiv: 1412.6572; Ronneberger, O., Fischer, P., Brox, T., U-net: Convolutional networks for biomedical image segmentation (2015) International Conference on Med-ical Image Computing and Computer-assisted Interven-tion. Springer, pp. 234-241; Kermany, D., Zhang, K., Goldbaum, M., Labeled optical coherence tomography (oct) and chest x-ray images for classi-cation (2018) Mendeley Data, 2; Petitjean, C., Zuluaga, M.A., Bai, W., Dacher, J., Grosgeorge, D., Caudron, O., Jr., Ruan, S., Chen, H., Right ventricle segmentation from cardiac mri: A collation study (2015) Medical Image Analysis, 19 (1), pp. 187-202; Pizer, S.M., Johnston, R.E., Ericksen, J.P., Yankaskas, B.C., Muller, K.E., Contrastlimited adaptive histogram equalization: Speed and effectiveness (1990) [1990] Proceedings of the First Confer-ence on Visualization in Biomedical Computing. IEEE, pp. 337-345",,,EMB;IEEE;IEEE Signal Processing Society,IEEE Computer Society,"17th IEEE International Symposium on Biomedical Imaging, ISBI 2020",3 April 2020 through 7 April 2020,,160183,19457928,9.78E+12,,,English,IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recogn.,Conference Paper,Final,,Scopus,2-s2.0-85085861707
"Wang L., Cho W., Yoon K.-J.",57203128728;57214453147;55932200600;,Deceiving Image-to-Image Translation Networks for Autonomous Driving with Adversarial Perturbations,2020,IEEE Robotics and Automation Letters,5,2,8962221,1421,1428,,8,10.1109/LRA.2020.2967289,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079610239&doi=10.1109%2fLRA.2020.2967289&partnerID=40&md5=eb8f913da523a3e4f2f3420177b434df,"Visual Intelligence Lab., Department of Mechanical Engineering, KAIST, Daejeon, 34141, South Korea","Wang, L., Visual Intelligence Lab., Department of Mechanical Engineering, KAIST, Daejeon, 34141, South Korea; Cho, W., Visual Intelligence Lab., Department of Mechanical Engineering, KAIST, Daejeon, 34141, South Korea; Yoon, K.-J., Visual Intelligence Lab., Department of Mechanical Engineering, KAIST, Daejeon, 34141, South Korea","Deep neural networks (DNNs) have achieved impressive performance on handling computer vision problems. However, it has been found that DNNs are vulnerable to adversarial examples. For such reason, adversarial perturbations have been recently studied in several respects. However, most previous works have focused on image classification tasks, and it has never been studied regarding adversarial perturbations on Image-to-image (Im2Im) translation tasks, showing great success in handling paired and/or unpaired mapping problems in the field of autonomous driving and robotics. This letter examines different types of adversarial perturbations that can fool Im2Im frameworks for autonomous driving purposes. We propose both quasi-physical and digital adversarial perturbations that can make Im2Im models yield unexpected results. We then empirically analyze these perturbations and show that they generalize well under both paired for image synthesis and unpaired settings for style transfer. We also validate that there exist some perturbation thresholds over which the Im2Im mapping is disrupted or impossible. The existence of these perturbations reveals that there exist crucial weaknesses in Im2Im models. Lastly, we show that our methods illustrate how perturbations affect the quality of outputs, pioneering the improvement of the robustness of current SOTA networks for autonomous driving. © 2016 IEEE.",adversarial attack; autonomous driving; Im2Im,Deep neural networks; Mapping; adversarial attack; Autonomous driving; Computer vision problems; Im2Im; Image synthesis; Image translation; Mapping problem; Autonomous vehicles,,,,,"Athalye, A., Logan, E., Andrew, I., Kevin, K., Sutskever, I., (2017) Synthesizing Robust Adversarial Examples; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Proc. IEEE Symp. Secur. Privacy, pp. 39-57; Chen, S.-T., Cornelius, C., Martin, J., Chau, D.H.P., ShapeShifter: Robust Physical Adversarial Attack on Faster R-CNN Object Detector (2018) Proc. Joint Eur. Conf. Mach. Learn. Knowl. Discovery Database, pp. 52-68; Cordts, M., The cityscapes dataset for semantic urban scene understanding (2016) Proc. IEEE Conf. Comput. Vision Pattern Recognit., pp. 3213-3223; Engstrom, L., Tran, B., Tsipras, D., Schmidt, L., Madry, A., (2017) A Rotation and A Translation Suffice: Fooling Cnns with Simple Transformations; Eykholt, K., Robust physical-world attacks on deep learning visual classification (2018) Proc. IEEE Conf. Comput. Vision Pattern Recognit., pp. 1625-1634; Fabbri, C., Sharma, J., D-GAN: Autonomous driving using generative adversarial networks (2018); Ghafoorian, M., Nugteren, C., Baka, N., Booij, O., Hofmann, M., El-GAN: Embedding loss driven generative adversarial networks for lane detection (2018) Proc. Eur. Conf. Comput. Vision; Metzen, J.H., Kumar, M.C., Brox, T., Fischer, V., Universal adversarial perturbations against semantic image segmentation (2017) Proc. IEEE Conf. Comput. Vision Pattern Recognit., pp. 2755-2764; Huang, X., Liu, M.-Y., Belongie, S., Kautz, J., Multimodal unsupervised image-to-image translation (2018) Proc. Eur. Conf. Comput. Vision, pp. 172-189; Isola, P., Zhu, J.-Y., Zhou, T., Efros, A.A., Image-to-image translation with conditional adversarial networks (2017) Proc. IEEE Conf. Comput. Vision Pattern Recognit., pp. 5967-5976; Jaderberg, M., Simonyan, K., Zisserman, A., Spatial transformer networks (2015) Proc. Adv. Neural Inf. Process. Syst., pp. 2017-2025; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Proc. Adv. Neural Inf. Process. Syst., pp. 1097-1105; Kuang, B., Using generative adversarial networks to enhance simulated robotics data (2018); Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World; Liu, M.-Y., Breuel, T., Kautz, J., Unsupervised image-to-image translation networks (2017) Proc. Adv. Neural Inf. Process. Syst., pp. 700-708; Ma, X., (2019) Understanding Adversarial Attacks on Deep Learning Based Medical Image Analysis Systems; Ma, X., (2017) Adversarial Generation of Real-time Feedback with Neural Networks for Simulation-based Training; Metzen, J.H., Universal adversarial perturbations against semantic image segmentation (2017) Proc. IEEE Int. Conf. Comput. Vision; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) Proc. IEEE Conf. Comput. Vision Pattern Recognit., pp. 86-94; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proc. IEEE Conf. Comput. Vision Pattern Recognit., pp. 2574-2582; Morrison, D., Corke, P., Leitner, J., (2018) Closing the Loop for Robotic Grasping: A Real-time, Generative Grasp Synthesis Approach; Mohammad Mostafavi, S., Wang, I.L., Ho, Y.-S., Yoon, K.-J., Eventbased high dynamic range image and very high frame rate video generation using conditional generative adversarial networks (2019) Proc. IEEE Conf. Comput. Vision Pattern Recognit., pp. 10081-10090; Papernot, N., (2016) Practical Black-box Attacks against Deep Learning Systems Using Adversarial Examples; Poursaeed, O., Katsman, I., Gao, B., Belongie, S., Generative adversarial perturbations (2018) Proc. IEEE Conf. Comput. Vision Pattern Recognit., pp. 4422-4431; Rahmatizadeh, R., Abolghasemi, P., Bölöni, L., Levine, S., Visionbased multi-task manipulation for inexpensive robots using end-to-end learning from demonstration (2018) Proc. IEEE Int. Conf. Robot. Autom., pp. 3758-3765; Soufi, N., Valdenegro-Toro, M., (2019) Data Augmentation with Symbolicto-real Image Translation GANs for Traffic Sign Recognition; Uricar, M., Krizek, P., Hurych, D., Sobh, I., Yogamani, S., Denny, P., (2019) Yes, We GAN: Applying Adversarial Techniques for Autonomous Driving, 2019 (15), pp. 481-4817; Xiao, C., (2018) Spatially Transformed Adversarial Examples; Yang, L., Liang, X., Wang, T., Xing, E., Real-to-virtual domain unification for end-to-end autonomous driving (2018) Proc. Eur. Conf. Comput. Vision, pp. 530-545; Zhang, R., Isola, P., Efros, A.A., Shechtman, E., Wang, O., The unreasonable effectiveness of deep features as a perceptual metric (2018) Proc. IEEE Conf. Comput. Vision Pattern Recognit., pp. 586-595; Zhu, J.-Y., Unpaired image-to-image translation using cycleconsistent adversarial networks (2017) Proc. IEEE Int. Conf. Comput. Vision; Zou, Y., Yu, Z., Kumar, B.V.K.V., Wang, J., Unsupervised domain adaptation for semantic segmentation via class-balanced self-training (2018) Proc. Eur. Conf. Comput. Vision, pp. 289-305","Yoon, K.-J.; Visual Intelligence Lab., South Korea; 电子邮件: kjyoon@kaist.ac.kr",,,Institute of Electrical and Electronics Engineers Inc.,,,,,23773766,,,,English,IEEE Robot. Autom.,Article,Final,"All Open Access, Green",Scopus,2-s2.0-85079610239
"Wang X., Hou R., Zhao B., Yuan F., Zhang J., Meng D., Qian X.",57208887494;55684325200;57189067805;55614646000;57195319967;55308382800;57194286286;,DNNGuard: An elastic heterogeneous DNN accelerator architecture against adversarial attacks,2020,International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS,,,,19,34,,5,10.1145/3373376.3378532,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082383275&doi=10.1145%2f3373376.3378532&partnerID=40&md5=6608781c0976cc54e6ff128f24d69586,"State Key Laboratory of Information Security, Institute of Information Engineering, CAS, School of Cyber Security, University of Chinese Academy of Sciences, China; State Key Laboratory of Information Security, Institute of Information Engineering, CAS, China; Hubei University of Arts and Science, China; University of Southern California, United States","Wang, X., State Key Laboratory of Information Security, Institute of Information Engineering, CAS, School of Cyber Security, University of Chinese Academy of Sciences, China; Hou, R., State Key Laboratory of Information Security, Institute of Information Engineering, CAS, China; Zhao, B., State Key Laboratory of Information Security, Institute of Information Engineering, CAS, China; Yuan, F., State Key Laboratory of Information Security, Institute of Information Engineering, CAS, China; Zhang, J., Hubei University of Arts and Science, China; Meng, D., State Key Laboratory of Information Security, Institute of Information Engineering, CAS, China; Qian, X., University of Southern California, United States","Recent studies show that Deep Neural Networks (DNN) are vulnerable to adversarial samples that are generated by perturbing correctly classified inputs to cause the misclassification of DNN models. This can potentially lead to disastrous consequences, especially in security-sensitive applications such as unmanned vehicles, finance and healthcare. Existing adversarial defense methods require a variety of computing units to effectively detect the adversarial samples. However, deploying adversary sample defense methods in existing DNN accelerators leads to many key issues in terms of cost, computational efficiency and information security. Moreover, existing DNN accelerators cannot provide effective support for special computation required in the defense methods. To address these new challenges, this paper proposes DNNGuard, an elastic heterogeneous DNN accelerator architecture that can efficiently orchestrate the simultaneous execution of original (target) DNN networks and the detect algorithm or network that detects adversary sample attacks. The architecture tightly couples the DNN accelerator with the CPU core into one chip for efficient data transfer and information protection. An elastic DNN accelerator is designed to run the target network and detection network simultaneously. Besides the capability to execute two networks at the same time, DNNGuard also supports the non-DNN computing and allows the special layer of the neural network to be effectively supported by the CPU core. To reduce off-chip traffic and improve resources utilization, we propose a dynamical resource scheduling mechanism. To build a general implementation framework, we propose an extended AI instruction set for neural networks synchronization, task scheduling and efficient data interaction. We implement DNNGuard based on RISC-V and NVDLA, and evaluate its performance impacts with six target networks and three typical detection networks. Experiment results show that DNNGuard can effectively validate the legitimacy of the input samples in parallel with the target DNN model, achieving an average 1.42× speedup compared with the state-of-the-art accelerators. © 2020 Association for Computing Machinery.",Adversarial sample; Detection network; DNN accelerator; Heterogeneous architecture,Acceleration; Computational efficiency; Data transfer; Multilayer neural networks; Network architecture; Network security; Unmanned vehicles; Accelerator architectures; Detection networks; Heterogeneous architectures; Information protection; Misclassifications; Resource-scheduling; Resources utilizations; Sensitive application; Deep neural networks,,,,,"Anderson, P., He, X., Buehler, C., Teney, D., Johnson, M., Gould, S., Zhang, L., Bottom-up and top-down attention for image captioning and visual question answering (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 6077-6086; Norcliffe-Brown, W., Vafeias, S., Parisot, S., Learning conditioned graph structures for interpretable visual question answering (2018) Advances in Neural Information Processing Systems, pp. 8334-8343; Graves, A., Fernández, S., Gomez, F., Schmidhuber, J., Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural networks (2006) Proceedings of the 23rd International Conference on Machine Learning, pp. 369-376; Hinton, G., Deng, L., Yu, D., Dahl, G., Mohamed, A.-R., Jaitly, N., Senior, A., Kingsbury, B., Deep neural networks for acoustic modeling in speech recognition (2012) IEEE Signal Processing Magazine, 29; Kim, Y., (2014) Convolutional Neural Networks for Sentence Classification; Devlin, J., Chang, M.-W., Lee, K., Toutanova, K., (2018) Bert: Pre-Training of Deep Bidirectional Transformers for Language Understanding; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2016) 2016 IEEE European Symposium on Security and Privacy (EuroS&P), pp. 372-387; Su, J., Vargas, D.V., Sakurai, K., One pixel attack for fooling deep neural networks (2019) IEEE Transactions on Evolutionary Computation; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP), pp. 39-57; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1765-1773; Cheng, S., Dong, Y., Pang, T., Su, H., Zhu, J., (2019) Improving Black-Box Adversarial Attacks with a Transfer-Based Prior; Gu, T., Dolan-Gavitt, B., Garg, S., (2017) Badnets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain; (2016) Ios-Siri-Apple, , https://www.apple.com/ios/siri; (2016) Cortana-Your Intelligent Virtual and Personal Assistant - Microsoft, , https://www.microsoft.com/en-us/windows/cortana; Xu, W., Evans, D., Qi, Y., Feature squeezing: Detecting adversarial examples in deep neural networks (2018) Network and Distributed System Security Symposium; Meng, D., Chen, H., Magnet: A two-pronged defense against adversarial examples (2017) Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pp. 135-147; Lu, J., Issaranon, T., Forsyth, D., SafeTyNet: Detecting and rejecting adversarial examples robustly (2017) Proceedings of the IEEE International Conference on Computer Vision, pp. 446-454; Jouppi, N.P., Young, C., Patil, N., Patterson, D., Agrawal, G., Bajwa, R., Bates, S., Borchers, A., In-datacenter performance analysis of a tensor processing unit (2017) 2017 ACM/IEEE 44th Annual International Symposium on Computer Architecture (ISCA), pp. 1-12; Chen, Y.-H., Krishna, T., Emer, J.S., Sze, V., Eyeriss: An energy-efficient reconfigurable accelerator for deep convolutional neural networks (2016) IEEE Journal of Solid-State Circuits, 52 (1), pp. 127-138; Hu, X., Liang, L., Deng, L., Li, S., Xie, X., Ji, Y., Ding, Y., Xie, Y., (2019) Neural Network Model Extraction Attacks in Edge Devices by Hearing Architectural Hints; Erraqabi, A., Baratin, A., Bengio, Y., Lacoste-Julien, S., (2018) A3t: Adversarially Augmented Adversarial Training; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., (2017) On Detecting Adversarial Perturbations; Li, X., Li, F., Adversarial examples detection in deep networks with convolutional filter statistics (2017) Proceedings of the IEEE International Conference on Computer Vision, pp. 5764-5772; Raghunathan, A., Steinhardt, J., Liang, P., Certified defenses against adversarial examples (2018) International Conference on Learning Representations; Liao, F., Liang, M., Dong, Y., Pang, T., Hu, X., Zhu, J., Defense against adversarial attacks using high-level representation guided denoiser (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1778-1787; Chen, L., Ding, H., Li, Q., Zhu, J., Huang, H., Chang, Y., Li, H., (2018) Adversarial Feature Genome: A Data Driven Adversarial Examples Recognition Method; Ma, S., Liu, Y., Tao, G., Lee, W.-C., Zhang, X., NIC: Detecting adversarial samples with neural network invariant checking (2019) NDSS; Li, D., Baral, R., Li, T., Wang, H., Li, Q., Xu, S., (2018) Hashtran-Dnn: A Framework for Enhancing Robustness of Deep Neural Networks against Adversarial Malware Samples; Wang, J., Dong, G., Sun, J., Wang, X., Zhang, P., Adversarial sample detection for deep neural network through model mutation testing (2019) Proceedings of the 41st International Conference on Software Engineering, pp. 1245-1256. , IEEE Press; Wong, E., Zico Kolter, J., Provable defenses against adversarial examples via the convex outer adversarial polytope (2018) Proceedings of the 35th International Conference on Machine Learning; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts; Wu, S., Sang, J., Xu, K., Zhang, J., Sun, Y., Jing, L., Yu, J., (2018) Attention, Please! Adversarial Defense Via Attention Rectification and Preservation; Song, Y., Kim, T., Nowozin, S., Ermon, S., Kushman, N., PixelDefend: Leveraging generative models to understand and defend against adversarial examples (2018) International Conference on Learning Representations; Tao, G., Ma, S., Liu, Y., Zhang, X., Attacks meet interpretability: Attribute-steered detection of adversarial samples (2018) Advances in Neural Information Processing Systems, pp. 7717-7728; Bradshaw, J., de G Matthews, A.G., Ghahramani, Z., (2017) Adversarial Examples, Uncertainty, and Transfer Testing Robustness in Gaussian Process Hybrid Deep Networks; Hwang, U., Park, J., Jang, H., Yoon, S., Cho, N.I., (2019) Puvae: A Variational Autoencoder to Purify Adversarial Examples; Jia, X., Wei, X., Cao, X., Foroosh, H., ComDefend: An efficient image compression model to defend adversarial examples (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 6084-6092; Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., (2017) On the (Statistical) Detection of Adversarial Examples; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts; Sahay, R., Mahfuz, R., Gamal, A.E., (2019) A Computationally Efficient Method for Defending Adversarial Deep Learning Attacks; Sitawarin, C., Wagner, D., (2019) Defending against Adversarial Examples with K-Nearest Neighbor; Goibert, M., Dohmatob, E., (2019) Adversarial Robustness Via Adversarial Label-Smoothing; Ding, Y., Wang, L., Zhang, H., Yi, J., Fan, D., Gong, B., Defending against adversarial attacks using random forest (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops; Mustafa, A., Khan, S.H., Hayat, M., Shen, J., Shao, L., (2019) Image Super-Resolution as a Defense against Adversarial Attacks; Kou, C., Lee, H.K., Ng, T.K., Chang, E.-C., (2019) Enhancing Transformation-Based Defenses Using a Distribution Classifier; Liu, J., Zhang, W., Zhang, Y., Hou, D., Liu, Y., Zha, H., Yu, N., Detection based defense against adversarial examples from the steganalysis point of view (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4825-4834; Li, Y., Xie, L., Zhang, Y., Zhang, R., Wang, Y., Tian, Q., (2019) Defending Adversarial Attacks by Correcting Logits; Borkar, T., Heide, F., Karam, L., (2019) Defending against Adversarial Attacks through Resilient Feature Regeneration; Aigrain, J., Detyniecki, M., (2019) Detecting Adversarial Examples and Other Misclassifications in Neural Networks by Introspection; Qin, Y., Frosst, N., Sabour, S., Raffel, C., Cottrell, G., Hinton, G., (2019) Detecting and Diagnosing Adversarial Images with Class-Conditional Capsule Reconstructions; Theagarajan, R., Chen, M., Bhanu, B., Zhang, J., Shield-nets: Defending against adversarial attacks using probabilistic adversarial robustness (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 6988-6996; Hwang, U., Park, J., Jang, H., Yoon, S., Cho, N.I., (2019) Puvae: A Variational Autoencoder to Purify Adversarial Examples; Li, P., Yi, J., Zhou, B., Zhang, L., (2019) Improving the Robustness of Deep Neural Networks Via Adversarial Training with Triplet Loss; He, Z., Rakin, A.S., Fan, D., Parametric noise injection: Trainable randomness to improve deep neural network robustness against adversarial attack (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 588-597; Zhang, H., Wang, J., (2019) Defense against Adversarial Attacks Using Feature Scattering-Based Adversarial Training; Azizimazreah, A., Chen, L., Shortcut mining: Exploiting cross-layer shortcut reuse in dcnn accelerators (2019) 2019 IEEE International Symposium on High Performance Computer Architecture (HPCA), pp. 94-105; Sharma, H., Park, J., Mahajan, D., Amaro, E., Kim, J.K., Shao, C., Mishra, A., Esmaeilzadeh, H., From high-level deep neural models to FPGAS (2016) The 49th Annual IEEE/ACM International Symposium on Microarchitecture, p. 17. , IEEE Press; Liu, S., Du, Z., Tao, J., Han, D., Luo, T., Xie, Y., Chen, Y., Chen, T., Cambricon: An instruction set architecture for neural networks (2016) ACM SIGARCH Computer Architecture News, 44, pp. 393-405. , IEEE Press; Sharma, H., Park, J., Suda, N., Lai, L., Chau, B., Chandra, V., Esmaeilzadeh, H., Bit fusion: Bit-level dynamically composable architecture for accelerating deep neural networks (2018) Proceedings of the 45th Annual International Symposium on Computer Architecture, pp. 764-775. , IEEE Press; (2018) Hardware Architectural Specification, , http://nvdla.org/hw/v1/hwarch.html; (2018) Unit Description, , http://nvdla.org/hw/v1/ias/unit_description.html#tab-sdp-supported-use-scenarios; (2018) Nvdla Primer, , http://nvdla.org/primer.html; (2018) Nvdla-Hw, , https://github.com/nvdla/hw; Waterman, A., Lee, Y., Patterson, D.A., Asanovi, K., (2014) The Risc-V Instruction Set Manual. 1: User-Level Isa, Version 2.0, , Technical report, CALIFORNIA UNIV BERKELEY DEPT OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES; Redmon, J., Farhadi, A., YOLO9000: Better, faster, stronger (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 7263-7271; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-Scale Image Recognition; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Muralimanohar, N., Balasubramonian, R., Jouppi, N., Optimizing nuca organizations and wiring alternatives for large caches with cacti 6.0 (2007) Proceedings of the 40th Annual IEEE/ACM International Symposium on Microarchitecture, pp. 3-14. , IEEE Computer Society; Rouhani, B.D., Samragh, M., Javaheripi, M., Javidi, T., Koushanfar, F., DeepFense: Online accelerated defense against adversarial deep learning (2018) 2018 IEEE/ACM International Conference on Computer-Aided Design (ICCAD), pp. 1-8; Sotgiu, A., Demontis, A., Melis, M., Biggio, B., Fumera, G., Feng, X., Roli, F., (2019) Deep Neural Rejection against Adversarial Examples; Hua, Y., Ge, S., Gao, X., Jin, X., Zeng, D., Defending against adversarial examples via soft decision trees embedding (2019) Proceedings of the 27th ACM International Conference on Multimedia, pp. 2106-2114; Samangouei, P., Kabkab, M., Chellappa, R., (2018) Defensegan: Protecting Classifiers against Adversarial Attacks Using Generative Models; Samajdar, A., Zhu, Y., Whatmough, P., Mattina, M., Krishna, T., (2018) Scale-Sim: Systolic Cnn Accelerator; Hua, W., Zhang, Z., Edward Suh, G., Reverse engineering convolutional neural networks through side-channel information leaks (2018) 2018 55th ACM/ESDA/IEEE Design Automation Conference (DAC), pp. 1-6; Meng, D., Hou, R., Shi, G., Tu, B., Yu, A., Zhu, Z., Jia, X., Liu, P., Security-first architecture: Deploying physically isolated active security processors for safeguarding the future of computing (2018) Cybersecurity, 1 (1), p. 2; Kwon, H., Samajdar, A., Krishna, T., Maeri: Enabling flexible dataflow mapping over dnn accelerators via reconfigurable interconnects (2018) ACM SIGPLAN Notices, 53, pp. 461-475; Ding, C., Liao, S., Wang, Y., Li, Z., Liu, N., Zhuo, Y., Wang, C., Yuan, G., C IR CNN: Accelerating and compressing deep neural networks using block-circulant weight matrices (2017) Proceedings of the 50th Annual IEEE/ACM International Symposium on Microarchitecture, pp. 395-408; Zhao, Y., Du, Z., Guo, Q., Liu, S., Li, L., Xu, Z., Chen, T., Chen, Y., CambricON-F: Machine learning computers with fractal von neumann architecture (2019) Proceedings of the 46th International Symposium on Computer Architecture, pp. 788-801; Cheng, S., Dong, Y., Pang, T., Su, H., Zhu, J., (2019) Improving Black-Box Adversarial Attacks with a Transfer-Based Prior; Duan, Y., Zhao, Z., Bu, L., Song, F., (2019) Things You May Not Know about Adversarial Example: A Black-Box Adversarial Image Attack; Borkar, T., Heide, F., Karam, L., (2019) Defending against Adversarial Attacks through Resilient Feature Regeneration","Hou, R.; State Key Laboratory of Information Security, China; 电子邮件: hourui@iie.ac.cn",,ACM SIGARCH;ACM SIGOPS;ACM SIGPLAN,Association for Computing Machinery,"25th International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS 2020",16 March 2020 through 20 March 2020,,158436,,9.78E+12,85MCA,,English,Int Conf Archit Support Program Lang Oper Syst ASPLOS,Conference Paper,Final,"All Open Access, Bronze",Scopus,2-s2.0-85082383275
[无可用作者姓名],[无可用的作者 ID],"18th Annual IEEE International Conference on Pervasive Computing and Communications, PerCom 2020",2020,"18th Annual IEEE International Conference on Pervasive Computing and Communications, PerCom 2020",,,,,,308,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088710957&partnerID=40&md5=f8d7d0d27358852fbb81cb6b1d067deb,,,"The proceedings contain 35 papers. The topics discussed include: deployment of APIs on android mobile devices and microcontrollers; digitally mapping the human behaviorome; ExhaleSense: detecting high fidelity forced exhalations to estimate lung obstruction on smartphones; towards energy positive sensing using kinetic energy harvesters; predicting machine errors based on adaptive sensor data drifts in a real world industrial setup; activity recommendation: optimizing life in the long term; my journey from research to product; an analysis of adversarial attacks and defenses on autonomous driving models; speaker counting model based on transfer learning from SincNet bottleneck layer; and let opportunistic crowdsensors work together for resource-efficient, quality-aware observations.",,,,,,,,,,,Institute of Electrical and Electronics Engineers Inc.,"18th Annual IEEE International Conference on Pervasive Computing and Communications, PerCom 2020",23 March 2020 through 27 March 2020,,161543,,9.78E+12,,,English,"Annu. IEEE Int. Conf. Pervasive Comput. Commun., PerCom",Conference Review,Final,,Scopus,2-s2.0-85088710957
"Cosgrove C., Yuille A.L.",57216955277;7006372632;,"Adversarial examples for edge detection: They exist, and they transfer",2020,"Proceedings - 2020 IEEE Winter Conference on Applications of Computer Vision, WACV 2020",,,9093304,1059,1068,,1,10.1109/WACV45572.2020.9093304,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085511406&doi=10.1109%2fWACV45572.2020.9093304&partnerID=40&md5=3dc28424a77610e152cdfb873fc25da5,"Johns Hopkins University, Department of Computer Science, Baltimore, MD  21218, United States","Cosgrove, C., Johns Hopkins University, Department of Computer Science, Baltimore, MD  21218, United States; Yuille, A.L., Johns Hopkins University, Department of Computer Science, Baltimore, MD  21218, United States","Convolutional neural networks have recently advanced the state of the art in many tasks including edge and object boundary detection. However, in this paper, we demonstrate that these edge detectors inherit a troubling property of neural networks: they can be fooled by adversarial examples. We show that adding small perturbations to an image causes HED [42], a CNN-based edge detection model, to fail to locate edges, to detect nonexistent edges, and even to hallucinate arbitrary configurations of edges. More importantly, we find that these adversarial examples blindly transfer to other CNN-based vision models. In particular, attacks on edge detection result in significant drops in accuracy in models trained to perform unrelated, high-level tasks like image classification and semantic segmentation. © 2020 IEEE.",,Computer vision; Convolutional neural networks; Image segmentation; Semantics; Detection models; Edge detectors; Object boundaries; Semantic segmentation; Small perturbations; State of the art; Vision model; Object detection,,,,,"Alzantot, M., Sharma, Y., Elgohary, A., Ho, B.-J., Srivastava, M., Chang, K.-W., Generating natural language adversarial examples (2018) Conference on Empirical Methods in Natural Language Processing; Arbelaez, P., Maire, M., Fowlkes, C., Malik, J., Contour detection and hierarchical image segmentation (2011) IEEE Trans. Pattern Anal. Mach. Intell., 33 (5), pp. 898-916. , May; Baluja, S., Fischer, I., (2017) Adversarial Transformation Networks: Learning to Generate Adversarial Examples; Belongie, S., Mori, G., Malik, J., Matching with shape contexts (2006) Statistics and Analysis of Shapes, pp. 81-105. , Springer; Bertasius, G., Shi, J., Torresani, L., Deepedge: A multiscale bifurcated deep network for top-down contour detection (2015) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , June; Canny, J., A computational approach to edge detection (1986) IEEE Transactions on Pattern Analysis and Machine Intelligence, (6), pp. 679-698; Chen, L.-C., Zhu, Y., Papandreou, G., Schroff, F., Adam, H., Encoder-decoder with atrous separable convolution for semantic image segmentation (2018) ECCV; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., Imagenet: A large-scale hierarchical image database (2009) Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pp. 248-255. , Ieee; Dollár, P., Zitnick, C.L., Structured forests for fast edge detection (2013) Proceedings of the IEEE International Conference on Computer Vision, pp. 1841-1848; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2018) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , June; Everingham, M., Van Gool, L., Williams, C.K.I., Winn, J., Zisserman, A., The PASCAL Visual Object Classes Challenge 2012 (VOC2012) Results, , http://www.pascalnetwork.org/challenges/VOC/voc2012/workshop/index.html; Fischer, V., Kumar, M.C., Metzen, J.H., Brox, T., Adversarial examples for semantic image segmentation (2018) International Conference on Learning Representations Workshop; Geirhos, R., Rubisch, P., Michaelis, C., Bethge, M., Wichmann, F.A., Brendel, W., Imagenet-trained cnns are biased towards texture; Increasing shape bias improves accuracy and robustness (2019) International Conference on Learning Representations; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , CoRR, abs/1412. 6572; Guo, C., Rana, M., Cisse, M., Maaten Der L.Van, Countering adversarial images using input transformations (2018) International Conference on Learning Representations Workshop; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Heng, W., Zhou, S., Jiang, T., (2018) Harmonic Adversarial Attack Method, , CoRR, abs/1807. 10590; Horn, B.K., (1973) The Binford-horn Line-finder.; Huang, Q., Gu, Z., Katsman, I., He, H., Pawakapan, P., Lin, Z., Belongie, S.J., Lim, S., (2018) Intermediate Level Adversarial Attack for Enhanced Transferability, , CoRR, abs/1811. 08458; Huang, X., Belongie, S., Arbitrary style transfer in realtime with adaptive instance normalization (2017) The IEEE International Conference on Computer Vision (ICCV), , Oct; Hubel, D.H., Wiesel, T.N., Receptive fields, binocular interaction and functional architecture in the cat's visual cortex (1962) The Journal of Physiology, 160 (1), pp. 106-154; Kittler, J., On the accuracy of the sobel edge detector (1983) Image and Vision Computing, 1 (1), pp. 37-42; Konishi, S., Yuille, A.L., Coughlan, J.M., Zhu, S.C., Statistical edge detection: Learning and evaluating edge cues (2003) IEEE Transactions on Pattern Analysis and Machine Intelligence, 25 (1), pp. 57-74; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2017) International Conference on Learning Representations; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2017) International Conference on Learning Representations; Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Dollár, P., Zitnick, C.L., Microsoft coco: Common objects in context (2014) European Conference on Computer Vision, pp. 740-755. , Springer; Liu, Y., Lew, M.S., Learning relaxed deep supervision for better edge detection (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 231-240; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) International Conference on Learning Representations; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) 2016 IEEE Symposium on Security and Privacy (SP), pp. 582-597. , IEEE; Poursaeed, O., Katsman, I., Gao, B., Belongie, S., Generative adversarial perturbations (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4422-4431; Premachandran, V., Bonev, B., Yuille, A.L., (2015) Pascal Boundaries: A Class-agnostic Semantic Boundary Dataset; Scharstein, D., Szeliski, R., A taxonomy and evaluation of dense two-frame stereo correspondence algorithms (2002) International Journal of Computer Vision, 47 (1), pp. 7-42. , Apr; Shapley, R., Tolhurst, D., Edge detectors in human vision (1973) The Journal of Physiology, 229 (1), pp. 165-183; Shen, W., Wang, X., Wang, Y., Bai, X., Zhang, Z., Deepcontour: A deep convolutional feature learned by positivesharing loss for contour detection (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3982-3991; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations; Wang, Z., Bovik, A.C., Sheikh, H.R., Simoncelli, E.P., Image quality assessment: From error visibility to structural similarity (2004) IEEE Transactions on Image Processing, 13 (4), pp. 600-612; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., Adversarial examples for semantic segmentation and object detection (2017) The IEEE International Conference on Computer Vision (ICCV), , Oct; Xie, C., Zhang, Z., Zhou, Y., Bai, S., Wang, J., Ren, Z., Yuille, A., Improving transferability of adversarial examples with input diversity (2019) Computer Vision and Pattern Recognition. IEEE; Xie, S., Tu, Z., Holistically-nested edge detection (2015) Proceedings of the 2015 IEEE International Conference on Computer Vision (ICCV), ICCV '15, pp. 1395-1403. , Washington, DC, USA. IEEE Computer Society; Yosinski, J., Clune, J., Bengio, Y., Lipson, H., How transferable are features in deep neural networks? (2014) Advances in Neural Information Processing Systems, pp. 3320-3328; Zhu, L.L., Lin, C., Huang, H., Chen, Y., Yuille, A., Unsupervised structure learning: Hierarchical recursive composition, suspicious coincidence and competitive exclusion (2008) European Conference on Computer Vision, pp. 759-773. , Springer",,,CVF;IEEE Computer Society,Institute of Electrical and Electronics Engineers Inc.,"2020 IEEE/CVF Winter Conference on Applications of Computer Vision, WACV 2020",1 March 2020 through 5 March 2020,,159803,,9.78E+12,,,English,"Proc. - IEEE Winter Conf. Appl. Comput. Vis., WACV",Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85085511406
"Chien T., Kalita J.",57207102809;57203217689;,Adversarial analysis of natural language inference systems,2020,"Proceedings - 14th IEEE International Conference on Semantic Computing, ICSC 2020",,,9031510,1,8,,1,10.1109/ICSC.2020.00008,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083433876&doi=10.1109%2fICSC.2020.00008&partnerID=40&md5=bc1903576b3073ed7188d1cc35ca10c9,"University of California, Berkeley, United States; University of Colorado, Colorado Springs, United States","Chien, T., University of California, Berkeley, United States; Kalita, J., University of Colorado, Colorado Springs, United States","The release of large natural language inference (NLI) datasets like SNLI and MNLI have led to rapid development and improvement of completely neural systems for the task. Most recently, heavily pre-trained, Transformer-based models like BERT and MT-DNN have reached near-human performance on these datasets. However, these standard datasets have been shown to contain many annotation artifacts, allowing models to shortcut understanding using simple fallible heuristics, and still perform well on the test set. So it is no surprise that many adversarial (challenge) datasets have been created that cause models trained on standard datasets to fail dramatically. Although extra training on this data generally improves model performance on just that type of data, transferring that learning to unseen examples is still partial at best. This work evaluates the failures of state-of-the-art models on existing adversarial datasets that test different linguistic phenomena, and find that even though the models perform similarly on MNLI, they differ greatly in their robustness to these attacks. In particular, we find syntax-related attacks to be particularly effective across all models, so we provide a fine-grained analysis and comparison of model performance on those examples. We draw conclusions about the value of model size and multi-task learning (beyond comparing their standard test set performance), and provide suggestions for more effective training data. © 2020 IEEE.",,Large dataset; Multi-task learning; Semantics; Transfer learning; Comparison of models; Fine-grained analysis; Human performance; Linguistic phenomena; Model performance; Natural languages; Neural systems; State of the art; Learning systems,,,,,"McCoy, T., Pavlick, E., Linzen, T., Right for the wrong reasons: Diagnosing syntactic heuristics in natural language inference (2019) Proceedings of the 57th Conference of the Association for Computational Linguistics., pp. 3428-3448. , Florence, Italy: Association for Computational Linguistics, Jul; Glockner, M., Shwartz, V., Goldberg, Y., Breaking NLI systems with sentences that require simple lexical inferences (2018) Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pp. 650-655. , Melbourne, Australia: Association for Computational Linguistics, Jul; Naik, A., Ravichander, A., Sadeh, N., Rose, C., Neubig, G., (2018) Stress Test Evaluation for Natural Language Inference, , Jun., arXiv: 1806. 00692; Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, L., Polosukhin, I., (2017) Attention Is All You Need, , Jun., arXiv: 1706. 03762; Devlin, J., Chang, M.-W., Lee, K., Toutanova, K., (2018) BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, , Oct., arXiv: 1810. 04805; Liu, X., He, P., Chen, W., Gao, J., (2019) Multi-Task Deep Neural Networks for Natural Language Understanding, , Jan., arXiv: 1901. 11504; Belinkov, Y., Glass, J., Analysis methods in neural language processing: A survey (2019) Transactions of the Association for Computational Linguistics, 7, pp. 49-72. , Apr; Liu, N.F., Schwartz, R., Smith, N.A., (2019) Inoculation by Fine-Tuning: A Method for Analyzing Challenge Datasets, , Apr., arXiv: 1904. 02668; Nie, Y., Wang, Y., Bansal, M., (2018) Analyzing Compositionality-Sensitivity of NLI Models, , Nov., arXiv: 1811. 07033; Gururangan, S., Swayamdipta, S., Levy, O., Schwartz, R., Bowman, S.R., Smith, N.A., (2018) Annotation Artifacts in Natural Language Inference Data, , Mar., arXiv: 1803. 02324; Wang, A., Singh, A., Michael, J., Hill, F., Levy, O., Bowman, S.R., (2018) GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding, , Apr., arXiv: 1804. 07461; Chen, Q., Zhu, X., Ling, Z., Wei, S., Jiang, H., Inkpen, D., (2016) Enhanced LSTM for Natural Language Inference, , Sep., arXiv: 1609. 06038; Goldberg, Y., (2019) Assessing BERT's Syntactic Abilities, , Jan., arXiv: 1901. 05287; Jawahar, G., Sagot, B., Seddah, D., What does BERT learn about the structure of language? (2019) Proceedings of the 57th Conference of the Association for Computational Linguistics, pp. 3651-3657. , Florence, Italy: Association for Computational Linguistics, Jul; Bowman, S.R., Gauthier, J., Rastogi, A., Gupta, R., Manning, C.D., Potts, C., (2016) A Fast Unified Model for Parsing and Sentence Understanding, , Mar., arXiv: 1603. 06021; Nie, Y., Bansal, M., Shortcut-stacked sentence encoders for multi-domain inference (2017) Proceedings of the 2nd Workshop on Evaluating Vector Space Representations for NLP. Copenhagen, Denmark: Association for Computational Linguistics, pp. 41-45. , Sep; Evans, R., Saxton, D., Amos, D., Kohli, P., Grefenstette, E., (2018) Can Neural Networks Understand Logical Entailment?, , Feb., arXiv: 1802. 08535; Minervini, P., Riedel, S., (2018) Adversarially Regularising Neural NLI Models to Integrate Logical Background Knowledge, , Aug., arXiv: 1808. 08609; Hu, Z., Ma, X., Liu, Z., Hovy, E., Xing, E., Harnessing deep neural networks with logic rules (2016) Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 2410-2420. , Berlin, Germany: Association for Computational Linguistics, Aug; Wang, H., Poon, H., Deep probabilistic logic: A unifying framework for indirect supervision (2018) Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 1891-1902. , Brussels, Belgium: Association for Computational Linguistics, Oct; Ferreira, F., Henderson, J.M., Recovery from misanalyses of garden-path sentences (1991) Journal of Memory and Language, 30 (6), pp. 725-745. , Dec; Osterhout, L., Holcomb, P.J., Swinney, D.A., Brain potentials elicited by garden-path sentences: Evidence of the application of verb information during parsing (1994) Journal of Experimental Psychology: Learning, Memory, and Cognition, 20 (4), pp. 786-803",,,,Institute of Electrical and Electronics Engineers Inc.,"14th IEEE International Conference on Semantic Computing, ICSC 2020",3 February 2020 through 5 February 2020,,158497,,9.78E+12,,,English,"Proc. - IEEE Int. Conf. Semant. Comput., ICSC",Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85083433876
"Zhao X., Stamm M.C.",57192545235;34870520200;,The effect of class definitions on the transferability of adversarial attacks against forensic CNNs,2020,IS and T International Symposium on Electronic Imaging Science and Technology,2020,4,119,,,,,10.2352/ISSN.2470-1173.2020.4.MWSF-119,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094879511&doi=10.2352%2fISSN.2470-1173.2020.4.MWSF-119&partnerID=40&md5=735e6220d1fad0565ec85d499a213205,"Drexel University, Philadelphia, PA, United States","Zhao, X., Drexel University, Philadelphia, PA, United States; Stamm, M.C., Drexel University, Philadelphia, PA, United States","In recent years, convolutional neural networks (CNNs) have been widely used by researchers to perform forensic tasks such as image tampering detection. At the same time, adversarial attacks have been developed that are capable of fooling CNN-based classifiers. Understanding the transferability of adversarial attacks, i.e. an attacks ability to attack a different CNN than the one it was trained against, has important implications for designing CNNs that are resistant to attacks. While attacks on object recognition CNNs are believed to be transferrable, recent work by Barni et al. has shown that attacks on forensic CNNs have difficulty transferring to other CNN architectures or CNNs trained using different datasets. In this paper, we demonstrate that adversarial attacks on forensic CNNs are even less transferrable than previously thought even between virtually identical CNN architectures! We show that several common adversarial attacks against CNNs trained to identify image manipulation fail to transfer to CNNs whose only difference is in the class definitions (i.e. the same CNN architectures trained using the same data). We note that all formulations of class definitions contain the unaltered class. This has important implications for the future design of forensic CNNs that are robust to adversarial and anti-forensic attacks. © 2020, Society for Imaging Science and Technology.",,Architecture; Convolutional neural networks; Network architecture; Object recognition; Anti-Forensics; Future designs; Image manipulation; Image tampering; Digital forensics,,,,,"Stamm, M. C., Wu, M., Liu, K. J. R., Information forensics: An overview of the first decade (2013) IEEE Access, 1, pp. 167-200; Kirchner, M., Fast and reliable resampling detection by spectral analysis of fixed linear predictor residue (2008) Proceedings of the 10th ACM workshop on Multimedia and security, pp. 11-20; Stamm, M. C., Liu, K. R., Forensic detection of image manipulation using statistical intrinsic fingerprints (2010) IEEE Transactions on Information Forensics and Security, 5 (3), pp. 492-506; Amerini, I., Ballan, L., Caldelli, R., Del Bimbo, A., Serra, G., A sift-based forensic method for copymove attack detection and transformation recovery (2011) IEEE Transactions on Information Forensics and Security, 6 (3), pp. 1099-1110. , Sep; Fridrich, J., Soukal, D., Lukáš, J., Detection of copy-move forgery in digital images (2003) Proceedings of Digital Forensic Research Workshop, , Citeseer; Bayram, S., Sencar, H. T., Memon, N., An efficient and robust method for detecting copy-move forgery (2009) 2009 IEEE International Conference on Acoustics, Speech and Signal Processing, pp. 1053-1056. , IEEE; Pan, X., Lyu, S., Region duplication detection using image feature matching (2010) IEEE Transactions on Information Forensics and Security, 5 (4), pp. 857-867. , Dec; Mayer, O., Stamm, M. C., Accurate and efficient image forgery detection using lateral chromatic aberration (2018) IEEE Transactions on Information Forensics and Security, 13 (7), pp. 1762-1777. , July; Bayar, B., Stamm, M. C., Constrained convolutional neural networks: A new approach towards general purpose image manipulation detection (2018) IEEE Transactions on Information Forensics and Security, 13 (11), pp. 2691-2706. , Nov; Bianchi, T., Piva, A., Image forgery localization via block-grained analysis of jpeg artifacts (2012) IEEE Transactions on Information Forensics and Security, 7 (3), pp. 1003-1017; Chen, M., Fridrich, J., Lukáš, J., Goljan, M., Imaging sensor noise as digital x-ray for revealing forgeries (2007) International Workshop on Information Hiding, pp. 342-358. , Springer, Berlin, Heidelberg; Cozzolino, D., Poggi, G., Verdoliva, L., Splicebuster: A new blind image splicing detector (2015) 2015 IEEE International Workshop on Information Forensics and Security, pp. 1-6. , IEEE; Farid, H., Exposing digital forgeries from jpeg ghosts (2009) IEEE transactions on information forensics and security, 4 (1), pp. 154-160; Ferrara, P., Fontani, M., Bianchi, T., De Rosa, A., Piva, A., Barni, M., Unsupervised fusion for forgery localization exploiting background information (2015) 2015 IEEE International Conference on Multimedia Expo Workshops, pp. 1-6. , June; Li, H., Luo, W., Qiu, X., Huang, J., Identification of various image operations using residual-based features (2018) IEEE Transactions on Circuits and Systems for Video Technology, 28 (1), pp. 31-45. , Jan; Mayer, O., Stamm, M. C., Forensic similarity for digital images (2020) IEEE Transactions on Information Forensics and Security, 15, pp. 1331-1346; Bondi, L., Lameri, S., Gera, D., Bestagini, P., Delp, E. J., Tubaro, S., Tampering detection and localization through clustering of camera-based cnn features (2017) Conference on Computer Vision and Pattern Recognition Workshops, pp. 1855-1864. , IEEE, July; Li, B., Zhang, H., Luo, H., Tan, S., Detecting double jpeg compression and its related anti-forensic operations with cnn (2019) Multimedia Tools and Applications, , 01; Tuama, A., Comby, F., Chaumont, M., Camera model identification with the use of deep convolutional neural networks (2016) Information Forensics and Security (WIFS). IEEE, pp. 1-6; Cozzolino, D., Verdoliva, L., Noiseprint: a cnn-based camera model fingerprint (2019) IEEE Transactions on Information Forensics and Security, 15, pp. 144-159; Bondi, L., Baroffio, L., Gera, D., Bestagini, P., Delp, E. J., Tubaro, S., First steps toward camera model identification with convolutional neural networks (2017) IEEE Signal Processing Letters, 24 (3), pp. 259-263. , March; Sharma, S., Subramanyam, A. V., Jain, M., Mehrish, A., Emmanuel, S., Anti-forensic technique for median filtering using l1-l2 tv model (2016) 2016 IEEE International Workshop on Information Forensics and Security, pp. 1-6. , Dec; Fontani, M., Barni, M., Hiding traces of median filtering in digital images (2012) Signal Processing Conference, Proceedings of the 20th European, pp. 1239-1243. , IEEE; Kirchner, M., Bohme, R., Hiding traces of resampling in digital images (2008) IEEE Transactions on Information Forensics and Security, 3 (4), pp. 582-592; Cao, G., Zhao, Y., Ni, R., Tian, H., Anti-forensics of contrast enhancement in digital images (2010) Proceedings of the 12th ACM Workshop on Multimedia and Security, pp. 25-34; Stamm, M. C., Liu, K. J. R., Anti-forensics of digital image compression (2011) IEEE Transactions on Information Forensics and Security, 6 (3), pp. 1050-1065. , Sep; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) The IEEE Conference on Computer Vision and Pattern Recognition, , June; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in neural information processing systems, pp. 2672-2680; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z. B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519. , Association for Computing Machinery; Goodfellow, I. J., Shlens, J., Szegedy, C., (2014) Explaining and harnessing adversarial examples, , arXiv preprint arXiv:1412.6572; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy, pp. 39-57. , May; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndić, N., Laskov, P., Giacinto, G., Roli, F., (2013) Evasion attacks against machine learning at test time, pp. 387-402; Biggio, B., Nelson, B., Laskov, P., (2012) Poisoning attacks against support vector machines; Chen, C., Zhao, X., Stamm, M. C., Mislgan: An anti-forensic camera model falsification framework using a generative adversarial network (2018) 2018 25th IEEE International Conference on Image Processing, pp. 535-539. , Oct; Huang, S., Papernot, N., Goodfellow, I., Duan, Y., Abbeel, P., (2017) Adversarial attacks on neural network policies, , arXiv preprint arXiv:1702.02284; Gera, D., Wang, Y., Bondi, L., Bestagini, P., Tubaro, S., Delp, E. J., A counter-forensic method for cnn-based camera model identification (2017) Computer Vision and Pattern Recognition Workshops, pp. 1840-1847. , IEEE, July; Chen, C., Zhao, X., Stamm, M. C., Generative adversarial attacks against deep-learning-based camera model identification (2019) IEEE Transactions on Information Forensics and Security; Kim, D., Jang, H. U., Mun, S. M., Choi, S., Lee, H. K., Median filtered image restoration and anti-forensics using adversarial networks (2018) IEEE Signal Processing Letters, 25 (2), pp. 278-282. , Feb; Liu, Y., Chen, X., Liu, C., Song, D., (2016) Delving into transferable adversarial examples and black-box attacks; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in machine learning: from phenomena to black-box attacks using adversarial samples, , arXiv preprint arXiv:1605.07277; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z. B., Swami, A., The limitations of deep learning in adversarial settings (2016) 2016 IEEE European Symposium on Security and Privacy (EuroS&P), pp. 372-387. , IEEE; Barni, M., Stamm, M. C., Tondi, B., Adversarial multimedia forensics: Overview and challenges ahead (2018) 2018 26th European Signal Processing Conference, pp. 962-966. , IEEE; Barni, M., Kallas, K., Nowroozi, E., Tondi, B., (2019) On the transferability of adversarial examples against cnn-based image forensics, pp. 8286-8290; Zhan, Y., Chen, Y., Zhang, Q., Kang, X., Image forensics based on transfer learning and convolutional neural network Proceedings of the 5th ACM Workshop on Information Hiding and Multimedia Security, ser. IH&MMSec’17, pp. 165-170; Boroumand, M., Fridrich, J., Deep learning for detecting processing history of images (2018) Electronic Imaging, 2018 (7), pp. 213-1; Boroumand, M., Chen, M., Fridrich, J., Deep residual network for steganalysis of digital images (2018) IEEE Transactions on Information Forensics and Security, 14 (5), pp. 1181-1193; Huang, G., Liu, Z., Van Der Maaten, L., Weinberger, K. Q., Densely connected convolutional networks (2017) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 4700-4708; Simonyan, K., Zisserman, A., (2014) Very deep convolutional networks for large-scale image recognition, , arXiv preprint arXiv:1409.1556; Gloe, T., Böhme, R., The dresden image database for benchmarking digital image forensics (2010) Journal of Digital Forensic Practice, 3 (2-4), pp. 150-159",,Adnan M. A.M.Nasir D. N.D.Gaurav G.,Reconnaissance,Society for Imaging Science and Technology,"2020 Media Watermarking, Security, and Forensics Conference, MWSF 2020",26 January 2020 through 30 January 2020,,163996,24701173,,,,English,IS T Intl. Symposium Electronic Imaging Science Technol.,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85094879511
"Tang X., Li Y., Sun Y., Yao H., Mitra P., Wang S.",57202640721;57202365760;57204767647;57196217415;35582720000;57001918800;,Transferring robustness for graph neural network against poisoning attacks,2020,WSDM 2020 - Proceedings of the 13th International Conference on Web Search and Data Mining,,,,600,608,,30,10.1145/3336191.3371851,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079555588&doi=10.1145%2f3336191.3371851&partnerID=40&md5=b1af016f94b81e5a471d64178bd80175,"Pennsylvania State University, United States; University of Central Florida, United States","Tang, X., Pennsylvania State University, United States; Li, Y., University of Central Florida, United States; Sun, Y., Pennsylvania State University, United States; Yao, H., Pennsylvania State University, United States; Mitra, P., Pennsylvania State University, United States; Wang, S., Pennsylvania State University, United States","Graph neural networks (GNNs) are widely used in many applications. However, their robustness against adversarial attacks is criticized. Prior studies show that using unnoticeable modifications on graph topology or nodal features can significantly reduce the performances of GNNs. It is very challenging to design robust graph neural networks against poisoning attack and several efforts have been taken. Existing work aims at reducing the negative impact from adversarial edges only with the poisoned graph, which is sub-optimal since they fail to discriminate adversarial edges from normal ones. On the other hand, clean graphs from similar domains as the target poisoned graph are usually available in the real world. By perturbing these clean graphs, we create supervised knowledge to train the ability to detect adversarial edges so that the robustness of GNNs is elevated. However, such potential for clean graphs is neglected by existing work. To this end, we investigate a novel problem of improving the robustness of GNNs against poisoning attacks by exploring clean graphs. Specifically, we propose PA-GNN, which relies on a penalized aggregation mechanism that directly restrict the negative impact of adversarial edges by assigning them lower attention coefficients. To optimize PA-GNN for a poisoned graph, we design a meta-optimization algorithm that trains PA-GNN to penalize perturbations using clean graphs and their adversarial counterparts, and transfers such ability to improve the robustness of PA-GNN on the poisoned graph. Experimental results on four real-world datasets demonstrate the robustness of PA-GNN against poisoning attacks on graphs. © 2020 Copyright held by the owner/author(s).",Adversarial defense; Robust graph neural networks,Data mining; Graphic methods; Information retrieval; Optimization; Topology; Websites; Adversarial defense; Aggregation mechanism; Graph neural networks; Graph topology; Meta-optimization; Poisoning attacks; Real-world datasets; Robust graphs; Graph algorithms,,,,,"Akoglu, L., Tong, H., Koutra, D., Graph based anomaly detection and description: A survey (2015) Data Mining and Knowledge Discovery, 29 (3), pp. 626-688. , 2015; Bojchevski, A., Günnemann, S., Adversarial attacks on node embeddings via graph poisoning (2019) ICML; Bruna, J., Zaremba, W., Szlam, A., LeCun, Y., (2013) Spectral Networks and Locally Connected Networks on Graphs, , 2013; Chen, J., Wu, Y., Xu, X., Chen, Y., Zheng, H., Xuan, Q., (2018) Fast Gradient Attack on Network Embedding, , 2018; Cheng, M., Le, T., Chen, P.-Y., Yi, J., Zhang, H., Hsieh, C.-J., (2018) Query-Efficient Hard-Label Black-Box Attack: An Optimization-Based Approach, , 2018; Dai, H., Li, H., Tian, T., Huang, X., Wang, L., Zhu, J., Song, L., Adversarial attack on graph structured data (2018) ICML, , 2018; Defferrard, M., Bresson, X., Vandergheynst, P., Convolutional neural networks on graphs with fast localized spectral filtering (2016) Advances in Neural Information Processing Systems, pp. 3844-3852; Ding, K., Li, J., Bhanushali, R., Liu, H., Deep anomaly detection on attributed networks (2019) SDM; Ding, K., Li, Y., Li, J., Liu, C., Liu, H., (2019) Graph Neural Networks with High-Order Feature Interactions, , 2019; Fan, W., Ma, Y., Li, Q., He, Y., Zhao, E., Tang, J., Yin, D., Graph neural networks for social recommendation (2019) The World Wide Web Conference, pp. 417-426; Finn, C., Abbeel, P., Levine, S., Model-agnostic meta-learning for fast adaptation of deep networks (2017) ICML; Gao, H., Wang, Z., Ji, S., Large-scale learnable graph convolutional networks (2018) KDD; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , 2014; Hamilton, W., Ying, Z., Leskovec, J., Inductive representation learning on large graphs (2017) NeurIPS; Henaff, M., Bruna, J., LeCun, Y., (2015) Deep Convolutional Networks on Graph-Structured Data, , 2015; Hochreiter, S., Steven Younger, A., Conwell, P.R., Learning to learn using gradient descent (2001) ICANN, pp. 87-94. , Springer; Huang, C., Wu, X., Zhang, X., Zhang, C., Zhao, J., Yin, D., Chawla, N.V., Online purchase prediction via multi-scale modeling of behavior dynamics (2019) KDD, pp. 2613-2622; Jin, M., Chang, H., Zhu, W., Sojoudi, S., (2019) Power up! Robust Graph Convolutional Network against Evasion Attacks Based on Graph Powering, , 2019; Kipf, T.N., Welling, M., (2016) Semi-Supervised Classification with Graph Convolutional Networks, , 2016; Lee, J., Kim, H., Lee, J., Yoon, S., Transfer learning for deep learning on graph-structured data (2017) AAAI; Li, R., Li, L., Wu, X., Zhou, Y., Wang, W., Click feedback-aware query recommendation using adversarial examples (2019) The World Wide Web Conference, pp. 2978-2984; Li, R., Wang, S., Zhu, F., Huang, J., Adaptive graph convolutional neural networks (2018) AAAI; Li, Y., Bai, S., Xie, C., Liao, Z., Shen, X., Yuille, A.L., (2019) Regional Homogeneity: Towards Learning Transferable Universal Adversarial Perturbations against Defenses, , 2019; Li, Y., Bai, S., Zhou, Y., Xie, C., Zhang, Z., Yuille, A., (2018) Learning Transferable Adversarial Examples Via Ghost Networks, , 2018; Li, Y., Li, L., Wang, L., Zhang, T., Gong, B., Nat-Tack: Learning the distributions of adversarial examples for an improved black-box attack on deep neural networks (2019) ICML, , 2019; Ma, Y., Wang, S., Aggarwal, C.C., Tang, J., Graph convolutional networks with eigenpooling (2019) KDD; Ma, Y., Wang, S., Aggarwal, C.C., Yin, D., Tang, J., Multi-dimensional Graph Convolutional Networks (2019) SDM; Ma, Y., Wang, S., Wu, L., Tang, J., (2019) Attacking Graph Convolutional Networks Via Rewiring, , 2019; Monti, F., Boscaini, D., Masci, J., Rodola, E., Svoboda, J., Bronstein, M.M., Geometric deep learning on graphs and manifolds using mixture model cnns (2017) CVPR; Niepert, M., Ahmed, M., Kutzkov, K., Learning convolutional neural networks for graphs (2016) ICML; Pennington, J., Socher, R., Manning, C., Glove: Global vectors for word representation (2014) EMNLP; Santoro, A., Bartunov, S., Botvinick, M., Wierstra, D., Lillicrap, T., Meta-learning with memory-augmented neural networks (2016) ICML; Sen, P., Namata, G., Bilgic, M., Getoor, L., Galligher, B., Eliassi-Rad, T., Collective classification in network data (2008) AI Magazine, 29 (3), p. 93. , 2008; Shu, K., Wang, S., Tang, J., Wang, Y., Liu, H., CrossFire: Cross media joint friend and item recommendations (2018) WSDM; Sun, Y., Wang, S., Tang, X., Hsieh, T.-Y., Honavar, V., (2019) Node Injection Attacks on Graphs Via Reinforcement Learning, , 2019; Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, L., Polosukhin, I., Attention is all you need (2017) Advances in Neural Information Processing Systems, pp. 5998-6008; Veličković, P., Cucurull, G., Casanova, A., Romero, A., Lio, P., Bengio, Y., (2017) Graph Attention Networks, , 2017; Vinyals, O., Blundell, C., Lillicrap, T., Wierstra, D., Matching networks for one shot learning (2016) Advances in Neural Information Processing Systems, pp. 3630-3638; Wu, F., Zhang, T., De Souza, A.H., Jr., Fifty, C., Yu, T., Weinberger, K.Q., (2019) Simplifying Graph Convolutional Networks, , 2019; Wu, H., Wang, C., Tyshetskiy, Y., Docherty, A., Lu, K., Zhu, L., Adversarial examples on graph data: Deep insights into attack and defense (2019) IJCAI; Wu, Z., Pan, S., Chen, F., Long, G., Zhang, C., Yu, P.S., (2019) A Comprehensive Survey on Graph Neural Networks, , 2019; Xu, H., Ma, Y., Liu, H., Deb, D., Liu, H., Tang, J., Jain, A., (2019) Adversarial Attacks and Defenses in Images, Graphs and Text: A Review, , 2019; Xu, K., Chen, H., Liu, S., Chen, P.-Y., Weng, T.-W., Hong, M., Lin, X., (2019) Topology Attack and Defense for Graph Neural Networks: An Optimization Perspective, , 2019; Yao, H., Liu, Y., Wei, Y., Tang, X., Li, Z., Learning from multiple cities: A meta-learning approach for spatial-temporal prediction (2019) The World Wide Web Conference, pp. 2181-2191; Yao, H., Wei, Y., Huang, J., Li, Z., Hierarchically Structured Meta-learning (2019) ICML, pp. 7045-7054; Yao, H., Zhang, C., Wei, Y., Jiang, M., Wang, S., Huang, J., Chawla, N.V., Li, Z., (2019) Graph Few-Shot Learning Via Knowledge Transfer, , 2019; Zhang, J., Shi, X., Xie, J., Ma, H., King, I., Yeung, D.-Y., (2018) Gaan: Gated Attention Networks for Learning on Large and Spatiotemporal Graphs, , 2018; Zhu, D., Zhang, Z., Cui, P., Zhu, W., Robust graph convolutional networks against adversarial attacks (2019) KDD; Zügner, D., Akbarnejad, A., Günnemann, S., Adversarial attacks on neural networks for graph data (2018) KDD; Zügner, D., Günnemann, S., Certifiable robustness and robust training for graph convolutional networks (2019) KDD; Zügner, D., Günnemann, S., Adversarial attacks on graph neural networks via meta learning (2019) ICLR","Wang, S.; Pennsylvania State UniversityUnited States; 电子邮件: szw494@psu.edu",,ACM SIGIR;ACM SIGKDD;ACM SIGMOD;ACM SIGWEB,"Association for Computing Machinery, Inc","13th ACM International Conference on Web Search and Data Mining, WSDM 2020",3 February 2020 through 7 February 2020,,157225,,9.78E+12,,,English,WSDM - Proc. Int. Conf. Web Search Data Min.,Conference Paper,Final,"All Open Access, Bronze, Green",Scopus,2-s2.0-85079555588
"Zhao J., Hu Q., Liu G., Ma X., Chen F., Hassan M.M.",57212349809;57207466832;57203062038;36930770600;57211734196;57201949986;,AFA: Adversarial fingerprinting authentication for deep neural networks,2020,Computer Communications,150,,,488,497,,8,10.1016/j.comcom.2019.12.016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076471262&doi=10.1016%2fj.comcom.2019.12.016&partnerID=40&md5=3fd8178c465a6a1c217b23a6e91b7b79,"School of Computer Science and Information Engineering, Hubei University, Wuhan, 430062, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, 430074, China; College of Computer Science and Technology, Qingdao University, Qingdao, 266071, China; College of Computer and Information Sciences, King Saud University, Riyadh, 11543, Saudi Arabia","Zhao, J., School of Computer Science and Information Engineering, Hubei University, Wuhan, 430062, China; Hu, Q., School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, 430074, China; Liu, G., School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, 430074, China; Ma, X., School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, 430074, China; Chen, F., College of Computer Science and Technology, Qingdao University, Qingdao, 266071, China; Hassan, M.M., College of Computer and Information Sciences, King Saud University, Riyadh, 11543, Saudi Arabia","With the vigorous development of deep learning, sharing trained deep neural network (DNN) models has become a common trend in various fields. An urgent problem is to protect the intellectual property (IP) rights of the model owners and detect IP infringement. DNN watermarking technology, which embeds signature information into the protected model and tries to extract it from the plagiarism model, has been the main approach of IP verification. However, the existing DNN watermarking methods have to be robust to various removal attacks since their watermarks are single in form or limited in quantity. Meanwhile, the process of adding watermarks to the DNN models will affect their original prediction abilities. Moreover, if the model has been distributed before embedding the watermarks, its IP cannot be correctly recognized and protected. To this end, we propose AFA, a new DNN fingerprinting technology aiming at extracting the inherent features of the model itself instead of embedding fixed watermarks. The features we selected as model fingerprints are a set of specially-crafted adversarial examples called Adversarial-Marks, which can transfer much better to the models that are derived from the original model than to other irrelative models. We also design a new IP verification scheme to identify a remote model's ownership. Experimental results show that our mechanism works well for common image classification models, and it can be easily adapted to other deep neural networks. © 2019 Elsevier B.V.",5G mobile services; Adversarial examples; DNN fingerprinting; IP verification,Embeddings; Intellectual property; Internet protocols; Watermarking; Adversarial examples; Classification models; DNN fingerprinting; Fingerprinting technologies; Mobile service; Removal attacks; Signature information; Watermarking methods; Deep neural networks,,,,,"Lecun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), p. 436; Chen, M., Shi, X., Zhang, Y., Wu, D., Guizani, M., Deep features learning for medical image analysis with convolutional autoencoder neural network (2017) IEEE Trans. Big Data; Chen, M., Hao, Y., Label-less learning for emotion cognition (2019) IEEE Trans. Neural Netw. Learn. Syst.; Jiang, H., Cai, C., Ma, X., Yang, Y., Liu, J., Smart home based on wifi sensing: A survey (2018) IEEE Access, 6, pp. 13317-13325; Chen, M., Zhang, Y., Qiu, M., Guizani, N., Hao, Y., Spha: Smart personal health advisor based on deep analytics (2018) IEEE Commun. Mag., 56 (3), pp. 164-169; Manning, C., Surdeanu, M., Bauer, J., Finkel, J., Bethard, S., McClosky, D., The stanford corenlp natural language processing toolkit (2014), Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations; Maimó, L.F., Gómez, Á.L.P., Clemente, F.J.G., Pérez, M.G., Pérez, G.M., A self-adaptive deep learning-based system for anomaly detection in 5g networks (2018) IEEE Access, 6, pp. 7700-7712; Ribeiro, M., Grolinger, K., Capretz, M.A., Mlaas: Machine learning as a service (2015), 2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA); Wang, C., Liu, G., Huang, H., Feng, W., Peng, K., Wang, L., Miasec: Enabling data indistinguishability against membership inference attacks in mlaas (2019) IEEE Trans. Sustain. Comput.; Uchida, Y., Nagai, Y., Sakazawa, S., Satoh, S., Embedding watermarks into deep neural networks Proceedings of the 2017 ACM on International Conference on Multimedia Retrieval; Rouhani, B.D., Samragh, M., Javidi, T., Koushanfar, F., Curtail: Characterizing and thwarting adversarial deep learning (2017), arXiv preprint; Merrer, E.L., Perez, P., Trédan, G., Adversarial frontier stitching for remote neural network watermarking (2017), arXiv preprint; Goodfellow, I., Bengio, Y., Courville, A., Deep Learning (2016), MIT press; Robbins, H., Monro, S., A stochastic approximation method (1951) Ann. Math. Stat., 22 (3), pp. 400-407; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2013), arXiv preprint; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2014), arXiv preprint; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2016), arXiv preprint; Athalye, A., Engstrom, L., Ilyas, A., Kwok, K., Synthesizing robust adversarial examples (2017), arXiv preprint; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Baluja, S., Fischer, I., Learning to attack: Adversarial transformation networks (2018) AAAI; Poursaeed, O., Katsman, I., Gao, B., Belongie, S., Generative adversarial perturbations (2018), Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Xiao, C., Li, B., Zhu, J.-Y., He, W., Liu, M., Song, D., Generating adversarial examples with adversarial networks (2018), arXiv preprint; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017), Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security; Bhagoji, A.N., He, W., Li, B., Song, D., Practical black-box attacks on deep neural networks using efficient query mechanisms (2018) European Conference on Computer Vision, , Springer; Guo, C., Frank, J.S., Weinberger, K.Q., Low frequency adversarial perturbation (2018), arXiv preprint; Naseer, M., Khan, S.H., Rahman, S., Porikli, F., Distorting neural representations to generate highly transferable adversarial examples (2018), arXiv preprint; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2014), arXiv preprint; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks 2017 IEEE Symposium on Security and Privacy (SP); Li, Y., Bai, S., Zhou, Y., Xie, C., Zhang, Z., Yuille, A., Learning transferable adversarial examples via ghost networks (2018), arXiv preprint; Krizhevsky, A., Hinton, G., Learning Multiple Layers of Features from Tiny Images: Tech. Rep. (2009), Citeseer; Chollet, F., Keras (2015), https://github.com/fchollet/keras, URL; Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G.S., Devin, M., Tensorflow: Large-scale machine learning on heterogeneous distributed systems (2016), arXiv preprint; Rouhani, B.D., Chen, H., Koushanfar, F., Deepsigns: A generic watermarking framework for ip protection of deep learning models (2018), arXiv preprint; Pittaras, N., Markatopoulou, F., Mezaris, V., Patras, I., Comparison of fine-tuning and extension strategies for deep convolutional neural networks (2017) International Conference on Multimedia Modeling, , Springer; Adi, Y., Baum, C., Cisse, M., Pinkas, B., Keshet, J., Turning your weakness into a strength: Watermarking deep neural networks by backdooring (2018) Usenix Security Symposium; Zhang, J., Gu, Z., Jang, J., Wu, H., Stoecklin, M.P., Huang, H., Molloy, I., Protecting intellectual property of deep neural networks with watermarking, in: Proceedings of the 2018 on Asia Conference on Computer and Communications Security, ACM (2018)","Liu, G.; School of Electronic Information and Communications, China; 电子邮件: liugaoyang@hust.edu.cn",,,Elsevier B.V.,,,,,1403664,,COCOD,,English,Comput Commun,Article,Final,,Scopus,2-s2.0-85076471262
"Hu G., Yang Q.",57001925900;57195665626;,PrivNet: Safeguarding private attributes in transfer learning for recommendation,2020,Findings of the Association for Computational Linguistics Findings of ACL: EMNLP 2020,,,,4506,4516,,1,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115639371&partnerID=40&md5=4048ef20cbae06c32265f8b9480719c3,"HKUST, Hong Kong, Hong Kong","Hu, G., HKUST, Hong Kong, Hong Kong; Yang, Q., HKUST, Hong Kong, Hong Kong","Transfer learning is an effective technique to improve a target recommender system with the knowledge from a source domain. Existing research focuses on the recommendation performance of the target domain while ignores the privacy leakage of the source domain. The transferred knowledge, however, may unintendedly leak private information of the source domain. For example, an attacker can accurately infer user demographics from their historical purchase provided by a source domain data owner. This paper addresses the above privacy-preserving issue by learning a privacy-aware neural representation by improving target performance while protecting source privacy. The key idea is to simulate the attacks during the training for protecting unseen users’ privacy in the future, modeled by an adversarial game, so that the transfer learning model becomes robust to attacks. Experiments show that the proposed PrivNet model can successfully disentangle the knowledge benefitting the transfer from leaking the privacy. © 2020 Association for Computational Linguistics",,Computational linguistics; IMPROVE-A; Neural representations; Privacy aware; Privacy leakages; Privacy preserving; Private information; Recommendation performance; Research focus; Target domain; Transfer learning; Learning systems,,,,,"Bassily, R., Smith, A., Local, private, efficient protocols for succinct histograms (2015) ACM STOC; Beigi, G., Mosallanezhad, A., Guo, R., Alvari, H., Privacy-aware recommendation with private-attribute protection using adversarial learning (2020) ACM WSDM; Cantador, Iván, Fernández-Tobías, Ignacio, Berkovsky, Shlomo, Cremonesi, Paolo, Cross-domain recommender systems (2015) Recommender systems handbook, pp. 919-959; Chen, Chong, Zhang, Min, Wang, Chenyang, Ma, Weizhi, Li, Minming, Liu, Yiqun, Ma, Shaoping, An efficient adaptive transfer neural network for social-aware recommendation (2019) ACM SIGIR; Chen, F., Dong, Z., Li, Z., He, X., (2018) Federated meta-learning for recommendation, , arXiv:1802.07876; Cheng, H., Koc, L., Harmsen, J., Shaked, T., Wide & deep learning for recommender systems (2016) ACM RecSys Workshop; Dwork, C., McSherry, F., Nissim, K., Smith, A., Calibrating noise to sensitivity in private data analysis (2006) Theory of Cryptography; Elkahky, A., Song, Y., He, X., A multi-view deep learning approach for cross domain user modeling in recommendation systems (2015) WWW; Fawcett, T., (2006) An introduction to roc analysis, , Pattern recognition letters; Gao, C., Chen, X., Feng, F., Zhao, K., Cross-domain recommendation without sharing user-relevant data (2019) WWW; Gao, Chen, He, Xiangnan, Gan, Dahua, Chen, Xiangning, Feng, Fuli, Li, Yong, Chua, Tat-Seng, Jin, Depeng, Neural multi-task recommendation from multi-behavior data (2019) IEEE ICDE; Gao, W., Tian, Y., Huang, T., Yang, Q., Vlogging: A survey of videoblogging technology on the web (2010) ACM Computing Surveys; Goodfellow, I., Pouget, J., Mirza, M., Xu, B., Generative adversarial nets (2014) NIPS; Harper, F., Konstan, J., The movielens datasets: History and context (2016), ACM TIST; He, X., Liao, L., Zhang, H., Nie, L., Neural collaborative filtering (2017) WWW; Hu, G., Zhang, Y., Yang, Q., Conet: Collaborative cross networks for cross-domain recommendation (2018) ACM CIKM; Hu, Guangneng, Zhang, Yu, Yang, Qiang, Transfer meets hybrid: a synthetic approach for cross-domain collaborative filtering with text (2019) The World Wide Web Conference, pp. 2822-2829; Huang, H., Zhang, Q., Gong, Y., Huang, X., Hashtag recommendation using end-to-end memory networks with hierarchical attention (2016) COLING; Huang, Y., Lin, S., Transferring user interests across websites with unstructured text for cold-start recommendation (2016) EMNLP; Jia, J., Gong, N., Attriguard: A practical defense against attribute inference attacks via adversarial machine learning (2018) USENIX Security; Li, B., Yang, Q., Xue, X., Can movies and books collaborate? cross-domain collaborative filtering for sparsity reduction (2009) IJCAI; Liu, B., Wei, Y., Zhang, Y., Yan, Z., Yang, Q., Transferable contextual bandit for cross-domain recommendation (2018) AAAI; Ma, Muyang, Ren, Pengjie, Lin, Yujie, Chen, Zhumin, Ma, Jun, de Rijke, Maarten, Pi-net: A parallel information-sharing network for shared-account cross-domain sequential recommendations (2019) ACM SIGIR; Ma, Y., Zong, L., Yang, Y., Su, J., News2vec: News network embedding with subnode information (2019) EMNLP; Man, Tong, Shen, Huawei, Jin, Xiaolong, Cheng, Xueqi, Cross-domain recommendation: an embedding and mapping approach (2017) IJCAI; McSherry, F., Mironov, I., Differentially private recommender systems: Building privacy into the netflix prize contenders (2009) ACM SIGKDD; Meng, X., Wang, S., Shu, K., Li, J., Personalized privacy-preserving social recommendation (2018) AAAI; Misra, Ishan, Shrivastava, Abhinav, Gupta, Abhinav, Hebert, Martial, Cross-stitch networks for multi-task learning (2016) IEEE CVPR; Nikolaenko, V., Ioannidis, S., Weinsberg, U., Joye, M., Privacy-preserving matrix factorization (2013) ACM CCS; Oquab, Maxime, Bottou, Leon, Laptev, Ivan, Sivic, Josef, Learning and transferring mid-level image representations using convolutional neural networks (2014) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 1717-1724; Pan, R., Zhou, Y., Cao, B., Liu, N., One-class collaborative filtering (2008) IEEE ICDM; Pan, Sinno Jialin, Yang, Qiang, A survey on transfer learning (2009) IEEE Transactions on knowledge and data engineering, 22 (10), pp. 1345-1359; Pan, W., Xiang, E., Liu, N., Yang, Q., Transfer learning in collaborative filtering for sparsity reduction (2010) AAAI; Polat, H., Du, W., Privacy-preserving collaborative filtering using randomized perturbation techniques (2003) IEEE ICDM; Ramakrishnan, N., Keller, B., Mirza, B., Grama, A., Karypis, G., Privacy risks in recommender systems (2001) IEEE Internet Computing; Ravfogel, Shauli, Elazar, Yanai, Gonen, Hila, Twiton, Michael, Goldberg, Yoav, Null it out: Guarding protected attributes by iterative nullspace projection (2020) ACL; Rendle, S., Freudenthaler, C., Gantner, Z., Schmidt-Thieme, L., Bpr: Bayesian personalized ranking from implicit feedback (2009) UAI; Resheff, Yehezkel, Elazar, Yanai, Shahar, Moni, Shalom, Oren, Privacy and fairness in recommender systems via adversarial training of user representations (2019) Proceedings of the 8th International Conference on Pattern Recognition Applications and Methods; Rosenberg, Andrew, Hirschberg, Julia, V-measure: A conditional entropy-based external cluster evaluation measure (2007) EMNLP; Singh, Ajit P, Gordon, Geoffrey J, Relational learning via collective matrix factorization (2008) SIGKDD; Wan, M., Ni, J., Misra, R., McAuley, J., Addressing marketing bias in product recommendations (2020) ACM WSDM; Wang, H., Zhang, F., Xie, X., Guo, M., D-kn: Deep knowledge-aware network for news recommendation (2018) WWW; Wang, J., Tang, Q., Arriaga, A., Ryan, P., Novel collaborative filtering recommender friendly to privacy protection (2019) IJCAI; Wang, J., Zhou, Z., Differentially private learning with small public data (2020) AAAI; Wang, Y., Gu, Q., Brown, D., Differentially private hypothesis transfer learning (2018) ECMLPKDD; Weinsberg, U., Bhagat, S., Ioannidis, S., Taft, N., Blurme: Inferring and obfuscating user gender based on ratings (2012) ACM RecSys; Yang, Carl, Bai, Lanxiao, Zhang, Chao, Yuan, Quan, Han, Jiawei, Bridging collaborative filtering and semi-supervised learning: a neural approach for poi recommendation (2017) ACM SIGKDD; Yang, Chunfeng, Yan, Huan, Yu, Donghan, Li, Yong, Chiu, Dah Ming, Multi-site user behavior modeling and its application in video recommendation (2017) ACM SIGIR; Yang, D., Qu, B., Cudré, P., Privacy-preserving social media data publishing for personalized ranking-based recommendation (2019) IEEE TKDE; Yang, Q., Liu, Y., Chen, T., Tong, Y., Federated machine learning: Concept and applications (2019), ACM TIST; Yosinski, Jason, Clune, Jeff, Bengio, Yoshua, Lipson, Hod, How transferable are features in deep neural networks? (2014) Advances in neural information processing systems, pp. 3320-3328; Yuan, Feng, Yao, Lina, Benatallah, Boualem, Darec: Deep domain adaptation for cross-domain recommendation via transferring rating patterns (2019) IJCAI; Zhang, Fuzheng, Yuan, Nicholas Jing, Lian, Defu, Xie, Xing, Ma, Wei-Ying, Collaborative knowledge base embedding for recommender systems (2016) ACM SIGKDD; Zhang, Yu, Yang, Qiang, (2017) A survey on multitask learning, , arXiv preprint arXiv:1707.08114; Zhao, X., Guo, Y., He, Y., Jiang, H., We know what you want to buy: a demographic-based system for product recommendation on microblogs (2014) ACM SIGKDD; Zhou, G., Zhu, X., Song, C., Fan, Y., Deep interest network for click-through rate prediction (2018) ACM SIGKDD",,,,Association for Computational Linguistics (ACL),"Findings of the Association for Computational Linguistics, ACL 2020: EMNLP 2020",16 November 2020 through 20 November 2020,,172733,,9.78E+12,,,English,Findings Assoc. Comp. Linguist. Findings ACL: EMNLP,Conference Paper,Final,,Scopus,2-s2.0-85115639371
"Inkawhich N., Liang K.J., Wang B., Inkawhich M., Carin L., Chen Y.",57194798606;57202922615;55552239200;57219545534;7004561693;9737381600;,Perturbing across the feature hierarchy to improve standard and strict blackbox attack transferability,2020,Advances in Neural Information Processing Systems,2020-December,,,,,,2,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108434978&partnerID=40&md5=7195b1767d9698b4330833f81ff2f794,"Duke University, United States","Inkawhich, N., Duke University, United States; Liang, K.J., Duke University, United States; Wang, B., Duke University, United States; Inkawhich, M., Duke University, United States; Carin, L., Duke University, United States; Chen, Y., Duke University, United States","We consider the blackbox transfer-based targeted adversarial attack threat model in the realm of deep neural network (DNN) image classifiers. Rather than focusing on crossing decision boundaries at the output layer of the source model, our method perturbs representations throughout the extracted feature hierarchy to resemble other classes. We design a flexible attack framework that allows for multilayer perturbations and demonstrates state-of-the-art targeted transfer performance between ImageNet DNNs. We also show the superiority of our feature space methods under a relaxation of the common assumption that the source and target models are trained on the same dataset and label space, in some instances achieving a 10× increase in targeted success rate relative to other blackbox transfer methods. Finally, we analyze why the proposed methods outperform existing attack strategies and show an extension of the method in the case when limited queries to the blackbox model are allowed. © 2020 Neural information processing systems foundation. All rights reserved.",,Attack strategies; Decision boundary; Feature hierarchies; Image Classifiers; Source modeling; State of the art; Transfer method; Transfer performance; Deep neural networks,,,,,"(2018) Restricted-Use Microdata, , https://www.census.gov/topics/research/guidance/restricted-use-microdata.html, US Census Bureau; Carlini, Nicholas, Wagner, David A., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy; Cheng, Shuyu, Dong, Yinpeng, Pang, Tianyu, Su, Hang, Zhu, Jun, Improving black-box adversarial attacks with a transfer-based prior (2019) NeurIPS; Deng, Jia, Dong, Wei, Socher, Richard, Li, Li-Jia, Li, Kai, Li, Fei-Fei, Imagenet: A large-scale hierarchical image database (2009) CVPR; Dong, Yinpeng, Liao, Fangzhou, Pang, Tianyu, Su, Hang, Zhu, Jun, Hu, Xiaolin, Li, Jianguo, Boosting adversarial attacks with momentum (2018) CVPR; Dong, Yinpeng, Pang, Tianyu, Su, Hang, Zhu, Jun, Evading defenses to transferable adversarial examples by translation-invariant attacks (2019) CVPR; Goodfellow, Ian J., Shlens, Jonathon, Szegedy, Christian, Explaining and harnessing adversarial examples (2015) ICLR; Graepel, Thore, Candela, Joaquin Quiñonero, Borchert, Thomas, Herbrich, Ralf, Web-scale Bayesian click-through rate prediction for sponsored search advertising in Microsoft’s bing search engine (2010) ICML; He, Kaiming, Zhang, Xiangyu, Ren, Shaoqing, Sun, Jian, Deep residual learning for image recognition (2016) CVPR; Huang, Gao, Liu, Zhuang, van der Maaten, Laurens, Weinberger, Kilian Q., Densely connected convolutional networks (2017) CVPR; Huang, Qian, Katsman, Isay, Gu, Zeqi, He, Horace, Belongie, Serge J., Lim, Ser-Nam, Enhancing adversarial example transferability with an intermediate level attack (2019) ICCV; Ilyas, Andrew, Engstrom, Logan, Athalye, Anish, Lin, Jessy, Black-box adversarial attacks with limited queries and information (2018) ICML; Inkawhich, Nathan, Wen, Wei, Li, Hai, Chen, Yiran, Feature space perturbations yield more transferable adversarial examples (2019) CVPR; Inkawhich, Nathan, Liang, Kevin J, Carin, Lawrence, Chen, Yiran, Transferable perturbations of deep feature distributions (2020) ICLR; Kurakin, Alexey, Goodfellow, Ian J., Bengio, Samy, Adversarial machine learning at scale (2017) ICLR; Liang, Kevin J, Heilmann, Geert, Gregory, Christopher, Diallo, Souleymane O., Carlson, David, Spell, Gregory P., Sigman, John B., Carin, Lawrence, Automatic Threat Recognition of Prohibited Items at Aviation Checkpoint with X-ray Imaging: A Deep Learning Approach (2018) SPIE Anomaly Detection and Imaging with X-Rays (ADIX) III; Liu, Yanpei, Chen, Xinyun, Liu, Chang, Song, Dawn, Delving into transferable adversarial examples and black-box attacks (2017) ICLR; Lu, Yantao, Jia, Yunhan, Wang, Jianyu, Li, Bai, Chai, Weiheng, Carin, Lawrence, Velipasalar, Senem, Enhancing cross-task black-box transferability of adversarial examples with dispersion reduction (2020) CVPR; Madry, Aleksander, Makelov, Aleksandar, Schmidt, Ludwig, Tsipras, Dimitris, Vladu, Adrian, Towards deep learning models resistant to adversarial attacks (2018) ICLR; Miller, George A, (1998) WordNet: An Electronic Lexical Database, , MIT press; Moosavi-Dezfooli, Seyed-Mohsen, Fawzi, Alhussein, Frossard, Pascal, Deepfool: A simple and accurate method to fool deep neural networks (2016) CVPR; Nguyen, Anh Mai, Yosinski, Jason, Clune, Jeff, Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) CVPR; Papernot, Nicolas, McDaniel, Patrick D., Goodfellow, Ian J., (2016) Transferability in machine learning: from phenomena to black-box attacks using adversarial samples, , arXiv, abs/1605.07277; Papernot, Nicolas, McDaniel, Patrick D., Goodfellow, Ian J., Jha, Somesh, Berkay Celik, Z., Swami, Ananthram, Practical black-box attacks against machine learning (2017) AsiaCCS; Ribli, Dezsö, Horváth, Anna, Unger, Zsuzsa, Pollner, Péter, Csabai, István, Detecting and Classifying Lesions in Mammograms with Deep Learning (2018) Scientific reports, 8. , Nature Publishing Group; Rozsa, Andras, Günther, Manuel, Boult, Terrance E., LOTS about attacking deep features (2017) IJCB; Sandler, Mark, Howard, Andrew G., Zhu, Menglong, Zhmoginov, Andrey, Chen, Liang-Chieh, Mobilenetv2: Inverted residuals and linear bottlenecks (2018) CVPR; Sharma, Yash, Ding, Gavin Weiguang, Brubaker, Marcus A., On the effectiveness of low frequency perturbations (2019) IJCAI; Sigman, John B., Spell, Gregory P., Liang, Kevin J, Carin, Lawrence, Background Adaptive Faster R-CNN for Semi-supervised Convolutional Object Detection of Threats in X-ray Images (2020) SPIE Anomaly Detection and Imaging with X-Rays (ADIX) V; Simonyan, Karen, Zisserman, Andrew, Very deep convolutional networks for large-scale image recognition (2015) ICLR; Sun, Chen, Shrivastava, Abhinav, Singh, Saurabh, Gupta, Abhinav, Revisiting Unreasonable Effectiveness of Data in Deep Learning Era (2017) ICCV; Szegedy, Christian, Zaremba, Wojciech, Sutskever, Ilya, Bruna, Joan, Erhan, Dumitru, Goodfellow, Ian J., Fergus, Rob, Intriguing properties of neural networks (2014) ICLR; Tramèr, Florian, Papernot, Nicolas, Goodfellow, Ian J., Boneh, Dan, McDaniel, Patrick D., (2017) The space of transferable adversarial examples, , arXiv, abs/1704.03453; Tramèr, Florian, Kurakin, Alexey, Papernot, Nicolas, Goodfellow, Ian J., Boneh, Dan, McDaniel, Patrick D., Ensemble adversarial training: Attacks and defenses (2018) ICLR; Uesato, Jonathan, O’Donoghue, Brendan, Kohli, Pushmeet, van den Oord, Aäron, Adversarial risk and the dangers of evaluating against weak attacks (2018) ICML; Wu, Dongxian, Wang, Yisen, Xia, Shu-Tao, Bailey, James, Ma, Xingjun, Skip connections matter: On the transferability of adversarial examples generated with resnets (2020) ICLR; Xie, Cihang, Zhang, Zhishuai, Zhou, Yuyin, Bai, Song, Wang, Jianyu, Ren, Zhou, Yuille, Alan L., Improving transferability of adversarial examples with input diversity (2019) CVPR; Zhou, Wen, Hou, Xin, Chen, Yongjun, Tang, Mengyun, Huang, Xiangqi, Gan, Xiang, Yang, Yong, Transferable adversarial perturbations (2018) ECCV","Inkawhich, N.; Duke UniversityUnited States; 电子邮件: nathan.inkawhich@duke.edu",,Apple;et al.;Microsoft;PDT Partners;Sony;Tenstorrent,Neural information processing systems foundation,"34th Conference on Neural Information Processing Systems, NeurIPS 2020",6 December 2020 through 12 December 2020,,169463,10495258,,,,English,Adv. neural inf. proces. syst.,Conference Paper,Final,,Scopus,2-s2.0-85108434978
"You Y., Chen T., Sui Y., Chen T., Wang Z., Shen Y.",57219687830;57221072108;57222257500;56355432100;56288839400;56683396900;,Graph contrastive learning with augmentations,2020,Advances in Neural Information Processing Systems,2020-December,,,,,,42,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108428369&partnerID=40&md5=42cc07a29e9f8519b9399a2d16a9fa24,"Texas A&M University, United States; University of Texas, Austin, United States; University of Science and Technology of China, China; Google Research, Brain Team","You, Y., Texas A&M University, United States; Chen, T., University of Texas, Austin, United States; Sui, Y., University of Science and Technology of China, China; Chen, T., Google Research, Brain Team; Wang, Z., University of Texas, Austin, United States; Shen, Y., Texas A&M University, United States","Generalizable, transferrable, and robust representation learning on graph-structured data remains a challenge for current graph neural networks (GNNs). Unlike what has been developed for convolutional neural networks (CNNs) for image data, self-supervised learning and pre-training are less explored for GNNs. In this paper, we propose a graph contrastive learning (GraphCL) framework for learning unsupervised representations of graph data. We first design four types of graph augmentations to incorporate various priors. We then systematically study the impact of various combinations of graph augmentations on multiple datasets, in four different settings: semi-supervised, unsupervised, and transfer learning as well as adversarial attacks. The results show that, even without tuning augmentation extents nor using sophisticated GNN architectures, our GraphCL framework can produce graph representations of similar or better generalizability, transferrability, and robustness compared to state-of-the-art methods. We also investigate the impact of parameterized graph augmentation extents and patterns, and observe further performance gains in preliminary experiments. Our codes are available at: https://github.com/Shen-Lab/GraphCL. © 2020 Neural information processing systems foundation. All rights reserved.",,Convolutional neural networks; Semi-supervised learning; Transfer learning; Graph augmentation; Graph neural networks; Graph representation; Graph structured data; Multiple data sets; Parameterized graphs; Representations of graphs; State-of-the-art methods; Graph structures,,,,,"Kipf, Thomas N, Welling, Max, (2016) Semi-supervised classification with graph convolutional networks, , arXiv_preprint_arXiv:1609.02907; Velickovic, Petar, Cucurull, Guillem, Casanova, Arantxa, Romero, Adriana, Lio, Pietro, Bengio, Yoshua, (2017) Graph attention networks, , arXiv_preprint_arXiv:1710.10903; Xu, Keyulu, Hu, Weihua, Leskovec, Jure, Jegelka, Stefanie, (2018) How powerful are graph neural networks?, , arXiv_preprint_arXiv:1810.00826; You, Yuning, Chen, Tianlong, Wang, Zhangyang, Shen, Yang, L2-gcn: Layer-wise and learned efficient training of graph convolutional networks (2020) Proceedings_of_the_IEEE/CVF_Conference_on_Computer Vision_and_Pattern_Recognition, pp. 2127-2135; Liu, Meng, Gao, Hongyang, Ji, Shuiwang, Towards deeper graph neural networks (2020) Proceedings_of_the 26th_ACM_SIGKDD_International_Conference_on_Knowledge_Discovery_&_Data_Mining, pp. 338-348; Zou, Difan, Hu, Ziniu, Wang, Yewen, Jiang, Song, Sun, Yizhou, Gu, Quanquan, Layer-dependent importance sampling for training deep and large graph convolutional networks (2019) Advances_in_Neural Information_Processing_Systems, pp. 11249-11259; Zhang, Muhan, Chen, Yixin, Link prediction based on graph neural networks (2018) Advances_in_Neural Information_Processing_Systems, pp. 5165-5175; Ying, Zhitao, You, Jiaxuan, Morris, Christopher, Ren, Xiang, Hamilton, Will, Leskovec, Jure, Hierarchical graph representation learning with differentiable pooling (2018) Advances_in_Neural_Information_Processing Systems, pp. 4800-4810; Hu, Weihua, Liu, Bowen, Gomes, Joseph, Zitnik, Marinka, Liang, Percy, Pande, Vijay, Leskovec, Jure, (2019) Pre-training graph neural networks, , arXiv_preprint_arXiv:1905.12265; Erhan, Dumitru, Manzagol, Pierre-Antoine, Bengio, Yoshua, Bengio, Samy, Vincent, Pascal, The difficulty of training deep architectures and the effect of unsupervised pre-training (2009) Artificial_Intelligence_and Statistics, pp. 153-160; Glorot, Xavier, Bengio, Yoshua, Understanding the difficulty of training deep feedforward neural networks (2010) Proceedings_of_the_thirteenth_international_conference_on_artificial_intelligence_and_statistics, pp. 249-256; Dwivedi, Vijay Prakash, Joshi, Chaitanya K, Laurent, Thomas, Bengio, Yoshua, Bresson, Xavier, (2020) Benchmarking graph neural networks, , arXiv_preprint_arXiv:2003.00982; Li, Qimai, Han, Zhichao, Wu, Xiao-Ming, Deeper insights into graph convolutional networks for semi-supervised learning (2018) Thirty-Second_AAAI_Conference_on_Artificial_Intelligence; Oono, Kenta, Suzuki, Taiji, (2019) Graph neural networks exponentially lose expressive power for node classification, , arXiv_preprint_cs.LG/1905.10947; Zitnik, Marinka, Leskovec, Jure, Prioritizing network communities (2018) Nature_communications, 9 (1), pp. 1-9; Goyal, Priya, Mahajan, Dhruv, Gupta, Abhinav, Misra, Ishan, (2019) Scaling and benchmarking self-supervised visual representation learning, , arXiv_preprint_arXiv:1905.01235; Kolesnikov, Alexander, Zhai, Xiaohua, Beyer, Lucas, (2019) Revisiting self-supervised visual representation learning, , arXiv_preprint_arXiv:1901.09005; Chen, Ting, Kornblith, Simon, Norouzi, Mohammad, Hinton, Geoffrey, (2020) A simple framework for contrastive learning of visual representations, , arXiv_preprint_arXiv:2002.05709; Hu, Weihua, Fey, Matthias, Zitnik, Marinka, Dong, Yuxiao, Ren, Hongyu, Liu, Bowen, Catasta, Michele, Leskovec, Jure, (2020) Open graph benchmark: Datasets for machine learning on graphs, , arXiv_preprint arXiv:2005.00687; Velickovic, Petar, Fedus, William, Hamilton, William L, Liò, Pietro, Bengio, Yoshua, Devon Hjelm, R, (2018) Deep graph infomax, , arXiv_preprint_arXiv:1809.10341; Sun, Fan-Yun, Hoffmann, Jordan, Tang, Jian, (2019) Infograph: Unsupervised and semi-supervised graph-level representation learning via mutual information maximization, , arXiv_preprint_arXiv:1908.01000; Kipf, Thomas N, Welling, Max, (2016) Variational graph auto-encoders, , arXiv_preprint_arXiv:1611.07308; Hamilton, Will, Ying, Zhitao, Leskovec, Jure, Inductive representation learning on large graphs (2017) Advances_in_neural_information_processing_systems, pp. 1024-1034; Ribeiro, Leonardo FR, Saverese, Pedro HP, Figueiredo, Daniel R, struc2vec: Learning node representations from structural identity (2017) Proceedings_of_the_23rd_ACM_SIGKDD_International_Conference_on Knowledge_Discovery_and_Data_Mining, pp. 385-394; Wu, Zhirong, Xiong, Yuanjun, Yu, Stella X, Lin, Dahua, Unsupervised feature learning via nonparametric instance discrimination (2018) Proceedings_of_the_IEEE_Conference_on_Computer_Vision_and Pattern_Recognition, pp. 3733-3742; Ye, Mang, Zhang, Xu, Yuen, Pong C, Chang, Shih-Fu, Unsupervised embedding learning via invariant and spreading instance feature (2019) Proceedings_of_the_IEEE_Conference_on_Computer_Vision_and_Pattern Recognition, pp. 6210-6219; Ji, Xu, Henriques, João F, Vedaldi, Andrea, Invariant information clustering for unsupervised image classification and segmentation (2019) Proceedings_of_the_IEEE_International_Conference_on_Computer_Vision, pp. 9865-9874; He, Kaiming, Fan, Haoqi, Wu, Yuxin, Xie, Saining, Girshick, Ross, Momentum contrast for unsupervised visual representation learning (2020) Proceedings_of_the_IEEE/CVF_Conference_on_Computer_Vision_and Pattern_Recognition, pp. 9729-9738; Noroozi, Mehdi, Favaro, Paolo, Unsupervised learning of visual representations by solving jigsaw puzzles (2016) European_Conference_on_Computer_Vision, pp. 69-84. , Springer; Carlucci, Fabio M, D’Innocente, Antonio, Bucci, Silvia, Caputo, Barbara, Tommasi, Tatiana, Domain generalization by solving jigsaw puzzles (2019) Proceedings_of_the_IEEE_Conference_on_Computer_Vision and_Pattern_Recognition, pp. 2229-2238; Trinh, Trieu H, Luong, Minh-Thang, Le, Quoc V, (2019) Selfie: Self-supervised pretraining for image embedding, , arXiv_preprint_arXiv:1906.02940; Chen, Tianlong, Liu, Sijia, Chang, Shiyu, Cheng, Yu, Amini, Lisa, Wang, Zhangyang, (2020) Adversarial robustness: From self-supervised pre-training to fine-tuning, , arXiv_preprint_arXiv:2003.12862; Herzig, Roei, Bar, Amir, Xu, Huijuan, Chechik, Gal, Darrell, Trevor, Globerson, Amir, (2019) Learning canonical representations for scene graph to image generation, , arXiv_preprint_arXiv:1912.07414; You, Yuning, Chen, Tianlong, Wang, Zhangyang, Shen, Yang, (2020) When does self-supervision help graph convolutional networks?, , arXiv_preprint_arXiv:2006.09136; Jin, Wei, Derr, Tyler, Liu, Haochen, Wang, Yiqi, Wang, Suhang, Liu, Zitao, Tang, Jiliang, (2020) Self-supervised learning on graphs: Deep insights and new direction, , arXiv_preprint_arXiv:2006.10141; Zhu, Qikui, Du, Bo, Yan, Pingkun, (2020) Self-supervised training of graph convolutional networks, , arXiv preprint_arXiv:2006.02380; Zhang, Jiawei, Zhang, Haopeng, Sun, Li, Xia, Congying, (2020) Graph-bert: Only attention is needed for learning graph representations, , arXiv_preprint_arXiv:2001.05140; Hu, Ziniu, Dong, Yuxiao, Wang, Kuansan, Chang, Kai-Wei, Sun, Yizhou, Gpt-gnn: Generative pretraining of graph neural networks (2020) Proceedings_of_the_26th_ACM_SIGKDD_International_Conference on_Knowledge_Discovery_&_Data_Mining, pp. 1857-1867; Liu, Xiao, Zhang, Fanjin, Hou, Zhenyu, Wang, Zhaoyu, Mian, Li, Zhang, Jing, Tang, Jie, (2020) Self-supervised learning: Generative or contrastive, , arXiv_preprint_arXiv:2006.08218; Verma, Vikas, Qu, Meng, Lamb, Alex, Bengio, Yoshua, Kannala, Juho, Tang, Jian, (2019) Graphmix: Regularized training of graph neural networks for semi-supervised learning, , arXiv_preprint_arXiv:1909.11715; Ding, Ming, Tang, Jie, Zhang, Jie, Semi-supervised learning on graphs with generative adversarial nets (2018) Proceedings_of_the_27th_ACM_International_Conference_on_Information_and_Knowledge_Management, pp. 913-922; Deng, Zhijie, Dong, Yinpeng, Zhu, Jun, (2019) Batch virtual adversarial training for graph convolutional networks, , arXiv_preprint_arXiv:1902.09192; Feng, Fuli, He, Xiangnan, Tang, Jie, Chua, Tat-Seng, Graph adversarial training: Dynamically regularizing based on graph structure (2019) IEEE_Transactions_on_Knowledge_and_Data_Engineering; Rosenstein, Michael T, Marx, Zvika, Kaelbling, Leslie Pack, Dietterich, Thomas G, To transfer or not to transfer (2005) NIPS_2005_workshop_on_transfer_learning, 898, pp. 1-4; Becker, Suzanna, Hinton, Geoffrey E, Self-organizing neural network that discovers surfaces in random-dot stereograms (1992) Nature, 355 (6356), pp. 161-163; Belghazi, Mohamed Ishmael, Baratin, Aristide, Rajeswar, Sai, Ozair, Sherjil, Bengio, Yoshua, Courville, Aaron, Devon Hjelm, R, (2018) Mine: mutual information neural estimation, , arXiv_preprint_arXiv:1801.04062; Devon Hjelm, R, Fedorov, Alex, Lavoie-Marchildon, Samuel, Grewal, Karan, Bachman, Phil, Trischler, Adam, Bengio, Yoshua, (2018) Learning deep representations by mutual information estimation and maximization, , arXiv_preprint_arXiv:1808.06670; Peng, Zhen, Dong, Yixiang, Luo, Minnan, Wu, Xiao-Ming, Zheng, Qinghua, (2020) Self-supervised graph representation learning via global context prediction, , arXiv_preprint_arXiv:2003.01604; Xie, Qizhe, Dai, Zihang, Hovy, Eduard, Luong, Minh-Thang, Le, Quoc V, (2019) Unsupervised data augmentation, , arXiv_preprint_arXiv:1904.12848; Berthelot, David, Carlini, Nicholas, Goodfellow, Ian, Papernot, Nicolas, Oliver, Avital, Raffel, Colin A, Mixmatch: A holistic approach to semi-supervised learning (2019) Advances_in_Neural_Information_Processing Systems, pp. 5050-5060; Sohn, Kihyuk, Improved deep metric learning with multi-class n-pair loss objective (2016) Advances_in_neural information_processing_systems, pp. 1857-1865; van den Oord, Aaron, Li, Yazhe, Vinyals, Oriol, (2018) Representation learning with contrastive predictive coding, , arXiv_preprint_arXiv:1807.03748; Chen, Ting, Sun, Yizhou, Shi, Yue, Hong, Liangjie, On sampling strategies for neural network-based collaborative filtering (2017) Proceedings_of_the_23rd_ACM_SIGKDD_International_Conference_on_Knowledge Discovery_and_Data_Mining, pp. 767-776; Velickovic, Petar, Fedus, William, Hamilton, William L, Liò, Pietro, Bengio, Yoshua, Devon Hjelm, R, Deep graph infomax (2019) ICLR_(Poster); Ren, Yuxiang, Liu, Bo, Huang, Chao, Dai, Peng, Bo, Liefeng, Zhang, Jiawei, (2019) Heterogeneous deep graph infomax, , arXiv_preprint_arXiv:1911.08538; Park, Chanyoung, Kim, Donghyun, Han, Jiawei, Yu, Hwanjo, Unsupervised attributed multiplex network embedding (2020) AAAI, pp. 5371-5378; Peng, Zhen, Huang, Wenbing, Luo, Minnan, Zheng, Qinghua, Rong, Yu, Xu, Tingyang, Huang, Junzhou, Graph representation learning via graphical mutual information maximization (2020) Proceedings_of_The_Web Conference_2020, pp. 259-270; Hassani, Kaveh, Khasahmadi, Amir Hosein, (2020) Contrastive multi-view representation learning on graphs, , arXiv_preprint_arXiv:2006.05582; Qiu, Jiezhong, Chen, Qibin, Dong, Yuxiao, Zhang, Jing, Yang, Hongxia, Ding, Ming, Wang, Kuansan, Tang, Jie, Gcc: Graph contrastive coding for graph neural network pre-training (2020) Proceedings_of_the_26th ACM_SIGKDD_International_Conference_on_Knowledge_Discovery_&_Data_Mining, pp. 1150-1160; Dai, Hanjun, Li, Hui, Tian, Tian, Huang, Xin, Wang, Lin, Zhu, Jun, Song, Le, (2018) Adversarial attack on graph structured data, , arXiv_preprint_arXiv:1806.02371; Zügner, Daniel, Akbarnejad, Amir, Günnemann, Stephan, Adversarial attacks on neural networks for graph data (2018) Proceedings_of_the_24th_ACM_SIGKDD_International_Conference_on_Knowledge_Discovery &_Data_Mining, pp. 2847-2856; Gilmer, Justin, Schoenholz, Samuel S, Riley, Patrick F, Vinyals, Oriol, Dahl, George E, Neural message passing for quantum chemistry (2017) Proceedings_of_the_34th_International_Conference_on_Machine Learning, 70, pp. 1263-1272. , Volume_, pages JMLR. org; Chen, Ting, Bian, Song, Sun, Yizhou, (2019) Are powerful graph neural nets necessary? a dissection on graph classification, , arXiv_preprint_arXiv:1905.04579; Morris, Christopher, Kriege, Nils M., Bause, Franka, Kersting, Kristian, Mutzel, Petra, Neumann, Marion, Tudataset: A collection of benchmark datasets for learning with graphs (2020) ICML_2020_Workshop_on Graph_Representation_Learning_and_Beyond_(GRL+_2020); Narayanan, Annamalai, Chandramohan, Mahinthan, Venkatesan, Rajasekar, Chen, Lihui, Liu, Yang, Jaiswal, Shantanu, (2017) graph2vec: Learning distributed representations of graphs, , arXiv_preprint_arXiv:1707.05005; Grover, Aditya, Leskovec, Jure, node2vec: Scalable feature learning for networks (2016) Proceedings_of_the 22nd_ACM_SIGKDD_international_conference_on_Knowledge_discovery_and_data_mining, pp. 855-864; Adhikari, Bijaya, Zhang, Yao, Ramakrishnan, Naren, Prakash, B Aditya, Sub2vec: Feature learning for subgraphs (2018) Pacific-Asia_Conference_on_Knowledge_Discovery_and_Data_Mining, pp. 170-182. , Springer; Dai, Hanjun, Dai, Bo, Song, Le, Discriminative embeddings of latent variable models for structured data (2016) International_conference_on_machine_learning, pp. 2702-2711","You, Y.; Texas A&M UniversityUnited States; 电子邮件: yuning.you@tamu.edu
Chen, T.; University of TexasUnited States; 电子邮件: tianlong.chen@utexas.edu",,Apple;et al.;Microsoft;PDT Partners;Sony;Tenstorrent,Neural information processing systems foundation,"34th Conference on Neural Information Processing Systems, NeurIPS 2020",6 December 2020 through 12 December 2020,,169463,10495258,,,,English,Adv. neural inf. proces. syst.,Conference Paper,Final,,Scopus,2-s2.0-85108428369
"Kim M., Tack J., Hwang S.J.",57217525456;57219758567;36445099200;,Adversarial self-supervised contrastive learning,2020,Advances in Neural Information Processing Systems,2020-December,,,,,,5,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108417078&partnerID=40&md5=5730eb8485aee1e44fa99ebd4e48a1c0,KAIST; AITRICS,"Kim, M., KAIST; Tack, J., KAIST; Hwang, S.J., KAIST, AITRICS","Existing adversarial learning approaches mostly use class labels to generate adversarial samples that lead to incorrect predictions, which are then used to augment the training of the model for improved robustness. While some recent works propose semi-supervised adversarial learning methods that utilize unlabeled data, they still require class labels. However, do we really need class labels at all, for adversarially robust training of deep neural networks? In this paper, we propose a novel adversarial attack for unlabeled data, which makes the model confuse the instance-level identities of the perturbed data samples. Further, we present a self-supervised contrastive learning framework to adversarially train a robust neural network without labeled data, which aims to maximize the similarity between a random augmentation of a data sample and its instance-wise adversarial perturbation. We validate our method, Robust Contrastive Learning (RoCL), on multiple benchmark datasets, on which it obtains comparable robust accuracy over state-of-the-art supervised adversarial learning methods, and significantly improved robustness against the black box and unseen types of attacks. Moreover, with further joint fine-tuning with supervised adversarial loss, RoCL obtains even higher robust accuracy over using self-supervised learning alone. Notably, RoCL also demonstrate impressive results in robust transfer learning. © 2020 Neural information processing systems foundation. All rights reserved.",,Deep learning; Deep neural networks; Neural networks; Semi-supervised learning; Transfer learning; Adversarial learning; Benchmark datasets; Class labels; Learning frameworks; Robust trainings; Semi-supervised; State of the art; Unlabeled data; Learning systems,,,,,"Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing properties of neural networks, , arXiv preprint arXiv:1312.6199; Zhang, H., Yu, Y., Jiao, J., Xing, E. P., Ghaoui, L. E., Jordan, M. I., Theoretically principled trade-off between robustness and accuracy (2019) Proceedings of the 36th International Conference on Machine Learning; Tramèr, F., Boneh, D., Adversarial training and robustness for multiple perturbations (2019) Advances in Neural Information Processing Systems, pp. 5858-5868; Madaan, D., Shin, J., Hwang, S. J., Adversarial neural pruning with latent vulnerability suppression (2020) Proceedings of the 37th International Conference on Machine Learning; Zheng, S., Song, Y., Leung, T., Goodfellow, I., Improving the robustness of deep neural networks via stability training (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4480-4488; Hendrycks, D., Dietterich, T., Benchmarking neural network robustness to common corruptions and perturbations (2019) International Conference on Learning Representations; Yin, D., Lopes, R. G., Shlens, J., Cubuk, E. D., Gilmer, J., A fourier perspective on model robustness in computer vision (2019) Advances in Neural Information Processing Systems, pp. 13255-13265; Goodfellow, I. J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) International Conference on Learning Representations; Gidaris, S., Singh, P., Komodakis, N., Unsupervised representation learning by predicting image rotations (2018) International Conference on Learning Representations; Noroozi, M., Favaro, P., Unsupervised learning of visual representations by solving jigsaw puzzles (2016) European Conference on Computer Vision, pp. 69-84. , Springer; Chen, T., Kornblith, S., Norouzi, M., Hinton, G., A simple framework for contrastive learning of visual representations (2020) Proceedings of the 37th International Conference on Machine Learning; He, K., Fan, H., Wu, Y., Xie, S., Girshick, R., Momentum contrast for unsupervised visual representation learning (2020) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Wu, Z., Xiong, Y., Yu, S. X., Lin, D., Unsupervised feature learning via non-parametric instance discrimination (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3733-3742; Tian, Y., Krishnan, D., Isola, P., Contrastive multiview coding (2020) European Conference on Computer Vision; Carmon, Y., Raghunathan, A., Schmidt, L., Duchi, J. C., Liang, P. S., Unlabeled data improves adversarial robustness (2019) Advances in Neural Information Processing Systems, pp. 11190-11201; Stanforth, R., Fawzi, A., Kohli, P., Are labels required for improving adversarial robustness? (2019) Advances in Neural Information Processing Systems; Chen, T., Liu, S., Chang, S., Cheng, Y., Amini, L., Wang, Z., Adversarial robustness: From self-supervised pre-training to fine-tuning (2020) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: a simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial examples in the physical world, , arXiv preprint arXiv:1607.02533; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE symposium on security and privacy (sp), pp. 39-57. , IEEE; Athalye, A., Carlini, N., Wagner, D., Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples (2018) Proceedings of the 35th International Conference on Machine Learning; Ilyas, A., Santurkar, S., Tsipras, D., Engstrom, L., Tran, B., Madry, A., Adversarial examples are not bugs, they are features (2019) Advances in Neural Information Processing Systems, pp. 125-136; Li, B., Chen, C., Wang, W., Carin, L., Certified adversarial robustness with additive noise (2019) Advances in Neural Information Processing Systems, pp. 9459-9469; Cohen, J., Rosenfeld, E., Kolter, Z., Certified adversarial robustness via randomized smoothing (2019) Proceedings of the 36th International Conference on Machine Learning, pp. 1310-1320; Salman, H., Li, J., Razenshteyn, I., Zhang, P., Zhang, H., Bubeck, S., Yang, G., Provably robust deep learning via adversarially trained smoothed classifiers (2019) Advances in Neural Information Processing Systems, pp. 11289-11300; Dosovitskiy, A., Fischer, P., Springenberg, J. T., Riedmiller, M., Brox, T., Discriminative unsupervised feature learning with exemplar convolutional neural networks (2015) IEEE transactions on pattern analysis and machine intelligence, 38 (9), pp. 1734-1747; Doersch, C., Gupta, A., Efros, A. A., Unsupervised visual representation learning by context prediction (2015) Proceedings of the IEEE International Conference on Computer Vision, pp. 1422-1430; Zhang, R., Isola, P., Efros, A. A., Colorful image colorization (2016) European Conference on Computer Vision, pp. 649-666. , Springer; Pathak, D., Krahenbuhl, P., Donahue, J., Darrell, T., Efros, A. A., Context encoders: Feature learning by inpainting (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2536-2544; Tian, Y., Sun, C., Poole, B., Krishnan, D., Schmid, C., Isola, P., What makes for good views for contrastive learning (2020) Advances in Neural Information Processing Systems; Khosla, P., Teterwak, P., Wang, C., Sarna, A., Tian, Y., Isola, P., Maschinot, A., Krishnan, D., Supervised contrastive learning (2020) Advances in Neural Information Processing Systems; Hendrycks, D., Mazeika, M., Kadavath, S., Song, D., Using self-supervised learning can improve model robustness and uncertainty (2019) Advances in Neural Information Processing Systems, pp. 15637-15648; Naseer, M., Khan, S., Hayat, M., Khan, F. S., Porikli, F., A self-supervised approach for adversarial robustness (2020) IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), , June; Chen, K., Zhou, H., Chen, Y., Mao, X., Li, Y., He, Y., Xue, H., Yu, N., (2019) Self-supervised adversarial training, , arXiv preprint arXiv:1911.06470; Bachman, P., Hjelm, R. D., Buchwalter, W., Learning representations by maximizing mutual information across views (2019) Advances in Neural Information Processing Systems, pp. 15509-15519; Kolesnikov, A., Zhai, X., Beyer, L., Revisiting self-supervised visual representation learning (2019) CoRR, , abs/1901.09005; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Krizhevsky, A., Hinton, G., Learning multiple layers of features from tiny images (2009) Citeseer; Hendrycks, D., Lee, K., Mazeika, M., Using pre-training can improve model robustness and uncertainty (2019) Proceedings of the 36th International Conference on Machine Learning; Shafahi, A., Saadatpanah, P., Zhu, C., Ghiasi, A., Studer, C., Jacobs, D., Goldstein, T., Adversarially robust transfer learning (2020) International Conference on Learning Representations; Zagoruyko, S., Komodakis, N., (2016) Wide residual networks, , arXiv preprint arXiv:1605.07146; You, Y., Gitman, I., Ginsburg, B., (2017) Large batch training of convolutional networks, , arXiv preprint arXiv:1708.03888; Goyal, P., Dollár, P., Girshick, R., Noordhuis, P., Wesolowski, L., Kyrola, A., Tulloch, A., He, K., (2017) Accurate, large minibatch sgd: Training imagenet in 1 hour, , arXiv preprint arXiv:1706.02677; Loshchilov, I., Hutter, F., (2016) Sgdr: Stochastic gradient descent with warm restarts, , arXiv preprint arXiv:1608.03983; Ioffe, S., Szegedy, C., Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015), 37, pp. 448-456. , PMLR (F. Bach and D. Blei, eds), of Proceedings of Machine Learning Research, (Lille, France), 07–09 Jul; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9; Krizhevsky, A., (2012) Learning multiple layers of features from tiny images, , University of Toronto, 05",,,Apple;et al.;Microsoft;PDT Partners;Sony;Tenstorrent,Neural information processing systems foundation,"34th Conference on Neural Information Processing Systems, NeurIPS 2020",6 December 2020 through 12 December 2020,,169463,10495258,,,,English,Adv. neural inf. proces. syst.,Conference Paper,Final,,Scopus,2-s2.0-85108417078
"Saadatpanah P., Shafahi A., Goldstein T.",57195739383;55734962700;14055829100;,Adversarial attacks on copyright detection systems,2020,"37th International Conference on Machine Learning, ICML 2020",PartF168147-11,,,8277,8285,,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105289465&partnerID=40&md5=3a3fa974a33d7efe39543050281f4776,"University of Maryland, College Park, MD, United States","Saadatpanah, P., University of Maryland, College Park, MD, United States; Shafahi, A., University of Maryland, College Park, MD, United States; Goldstein, T., University of Maryland, College Park, MD, United States","It is well-known that many machine learning models are susceptible to adversarial attacks, in which an attacker evades a classifier by making small perturbations to inputs. This paper discusses how industrial copyright detection tools, which serve a central role on the web, are susceptible to adversarial attacks. As proof of concept, we describe a well-known music identification method and implement this system in the form of a neural net. We then attack this system using simple gradient methods and show that it is easily broken with white-box attacks. By scaling these perturbations up, we can create transfer attacks on industrial systems, such as the AudioTag copyright detector and YouTube's Content ID system, using perturbations that are audible but significantly smaller than a random baseline. Our goal is to raise awareness of the threats posed by adversarial examples in this space and to highlight the importance of hardening copyright detection systems to attacks. Copyright © 2020 by the Authors. All rights reserved.",,Gradient methods; Detection system; Detection tools; Industrial systems; Machine learning models; Music identification; Proof of concept; Small perturbations; White box; Machine learning,,,,,"Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Isard, M., Tensorflow: A system for large-scale machine learning (2016) 12th fUSENIXg Symposium on Operating Systems Design and Implementation (fOSDIg 16), pp. 265-283; Alzantot, M., Balaji, B., Srivastava, M., (2018) Did you hear that? adversarial examples against automatic speech recognition, , arXiv preprint arXiv:1801.00554; Athalye, A., Engstrom, L., Ilyas, A., Kwok, K., (2017) Synthesizing robust adversarial examples, , arXiv preprint arXiv:1707.07397; (2009) Audiotag-free music recognition robot, , https://audiotag.info/, Audio Tag; Carlini, N., Wagner, D., Audio adversarial examples: Targeted attacks on speech-to-text (2018) 2018 IEEE Security and Privacy Workshops (SPW), pp. 1-7. , IEEE; Cohen, J. M., Rosenfeld, E., Kolter, J. Z., (2019) Certified adversarial robustness via randomized smoothing, , arXiv preprint arXiv:1902.02918; Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Xiao, C., Prakash, A., Song, D., (2017) Robust physical-world attacks on deep learning models, , arXiv preprint arXiv:1707.08945; Fischer, V., Kumar, M. C., Metzen, J. H., Brox, T., (2017) Adversarial examples for semantic image segmentation, , arXiv preprint arXiv:1703.01101; Goldstein, T., Studer, C., Baraniuk, R., (2014) A field guide to forward-backward splitting with a fasta implementation, , arXiv preprint arXiv:1411.3406; Goodfellow, I. J., Shlens, J., Szegedy, C., (2014) Explaining and harnessing adversarial examples, , arXiv preprint arXiv:1412.6572; (2019) How content id works-youtube help, , https://support.google.com/youtube/answer/2797370?hl=en, Google; Kingma, D. P., Ba, J., (2014) Adam: A method for stochastic optimization, , arXiv preprint arXiv:1412.6980; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial examples in the physical world, , arXiv preprint arXiv:1607.02533; Li, Y., Wang, D., Tang, L., Robust and secure image fingerprinting learned by neural network (2019) IEEE Transactions on Circuits and Systems for Video Technology, pp. 1-1. , ISSN 1051-8215; Lu, J., Sibai, H., Fabry, E., Forsyth, D., (2017) No need to worry about adversarial examples in object detection in autonomous vehicles, , arXiv preprint arXiv:1707.03501, a; Lu, J., Sibai, H., Fabry, E., Forsyth, D., (2017) Standard detectors aren't (currently) fooled by physical adversarial stop signs, , arXiv preprint arXiv:1710.03337, b; Manara, C., (2018) Protecting what we love about the internet: our efforts to stop online piracy, , https://www.blog.google/outreachinitiatives/public-policy/protectingwhat-we-love-about-internet-ourefforts-stop-online-piracy/, [Accessed: 05/21/2019]; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: a simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2574-2582; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 1765-1773; Qin, Y., Carlini, N., Goodfellow, I., Cottrell, G., Raffel, C., (2019) Imperceptible, robust, and targeted adversarial examples for automatic speech recognition, , arXiv preprint arXiv:1903.10346; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Bernstein, M., Imagenet large scale visual recognition challenge (2015) International journal of computer vision, 115 (3), pp. 211-252; Saviaga, C., Toxtli, C., (2018) Deepiracy: Video piracy detection system by using longest common subsequence and deep learning, , https://medium.com/hciwvu/piracy-detection-using-longestcommon-subsequence-and-neuralnetworks-a6f689a541a6, [Accessed: 05/21/2019]; Shafahi, A., Najibi, M., Xu, Z., Dickerson, J., Davis, L. S., Goldstein, T., (2018) Universal adversarial training, , arXiv preprint arXiv:1811.11304; Shafahi, A., Najibi, M., Ghiasi, A., Xu, Z., Dickerson, J., Studer, C., Davis, L. S., Goldstein, T., (2019) Adversarial training for free!, , arXiv preprint arXiv:1904.12843; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing properties of neural networks, , arXiv preprint arXiv:1312.6199; Taori, R., Kamsetty, A., Chu, B., Vemuri, N., (2018) Targeted adversarial examples for black box audio systems, , arXiv preprint arXiv:1805.07820; (2019) Experimental security research of tesla autopilot, , Tencent; Wang, A., An industrial strength audio search algorithm (2003) Ismir, pp. 7-13. , Washington, DC, 2003; Wang, D., Li, C., Wen, S., Nepal, S., Xiang, Y., (2019) Daedalus: Breaking non-maximum suppression in object detection via adversarial examples, , arXiv preprint arXiv:1902.02067; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., Adversarial examples for semantic segmentation and object detection (2017) Proceedings of the IEEE International Conference on Computer Vision, pp. 1369-1378; Yakura, H., Sakuma, J., (2018) Robust audio adversarial example for a physical attack, , arXiv preprint arXiv:1810.11793; Yasaswi, J., Purini, S., Jawahar, C. V., Plagiarism detection in programming assignments using deep features (2017) 2017 4th IAPR Asian Conference on Pattern Recognition (ACPR), pp. 652-657. , Nov","Saadatpanah, P.; University of MarylandUnited States; 电子邮件: parsa@cs.umd.edu",Daume H.Singh A.,,International Machine Learning Society (IMLS),"37th International Conference on Machine Learning, ICML 2020",13 July 2020 through 18 July 2020,,168147,,9.78E+12,,,English,"Int. Conf. Machin. Learn., ICML",Conference Paper,Final,,Scopus,2-s2.0-85105289465
"Yang H., Zhang J., Dong H., Inkawhich N., Gardner A., Touchet A., Wilkes W., Berry H., Li H.",57203286881;57207799161;57221154048;57194798606;57225315832;57221157880;57204096853;57190768870;57204886743;,DVERGE: Diversifying vulnerabilities for enhanced robust generation of ensembles,2020,Advances in Neural Information Processing Systems,2020-December,,,,,,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104224908&partnerID=40&md5=6b7236705a1a9bf0e313421532492ff2,"Department of Electrical and Computer Engineering, Duke University, United States; Radiance Technologies","Yang, H., Department of Electrical and Computer Engineering, Duke University, United States; Zhang, J., Department of Electrical and Computer Engineering, Duke University, United States; Dong, H., Department of Electrical and Computer Engineering, Duke University, United States; Inkawhich, N., Department of Electrical and Computer Engineering, Duke University, United States; Gardner, A., Radiance Technologies; Touchet, A., Radiance Technologies; Wilkes, W., Radiance Technologies; Berry, H., Radiance Technologies; Li, H., Department of Electrical and Computer Engineering, Duke University, United States","Recent research finds CNN models for image classification demonstrate overlapped adversarial vulnerabilities: adversarial attacks can mislead CNN models with small perturbations, which can effectively transfer between different models trained on the same dataset. Adversarial training, as a general robustness improvement technique, eliminates the vulnerability in a single model by forcing it to learn robust features. The process is hard, often requires models with large capacity, and suffers from significant loss on clean data accuracy. Alternatively, ensemble methods are proposed to induce sub-models with diverse outputs against a transfer adversarial example, making the ensemble robust against transfer attacks even if each sub-model is individually non-robust. Only small clean accuracy drop is observed in the process. However, previous ensemble training methods are not efficacious in inducing such diversity and thus ineffective on reaching robust ensemble. We propose DVERGE, which isolates the adversarial vulnerability in each sub-model by distilling non-robust features, and diversifies the adversarial vulnerability to induce diverse outputs against a transfer attack. The novel diversity metric and training procedure enables DVERGE to achieve higher robustness against transfer attacks comparing to previous ensemble methods, and enables the improved robustness when more sub-models are added to the ensemble. The code of this work is available at https://github.com/zjysteven/DVERGE. © 2020 Neural information processing systems foundation. All rights reserved.",,Diversity metrics; Ensemble methods; Improvement technique; Recent researches; Robust generation; Small perturbations; Training methods; Training procedures; Classification (of information),,,,,"Goodfellow, Ian J, Shlens, Jonathon, Szegedy, Christian, (2014) Explaining and harnessing adversarial examples, , arXiv preprint arXiv:1412.6572; Carlini, Nicholas, Wagner, David, Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium on, pp. 39-57. , IEEE; Madry, Aleksander, Makelov, Aleksandar, Schmidt, Ludwig, Tsipras, Dimitris, Vladu, Adrian, Towards deep learning models resistant to adversarial attacks (2018) International Conference on Learning Representations; Papernot, Nicolas, McDaniel, Patrick, Goodfellow, Ian, (2016) Transferability in machine learning: from phenomena to black-box attacks using adversarial samples, , arXiv preprint arXiv:1605.07277; Ilyas, Andrew, Santurkar, Shibani, Tsipras, Dimitris, Engstrom, Logan, Tran, Brandon, Madry, Aleksander, Adversarial examples are not bugs, they are features (2019) Advances in Neural Information Processing Systems, pp. 125-136; Inkawhich, Nathan, Liang, Kevin, Carin, Lawrence, Chen, Yiran, Transferable perturbations of deep feature distributions (2020) International Conference on Learning Representations; Li, Yixuan, Yosinski, Jason, Clune, Jeff, Lipson, Hod, Hopcroft, John E, Convergent learning: Do different neural networks learn the same representations? (2015) FE@ NIPS, pp. 196-212; Tsipras, Dimitris, Santurkar, Shibani, Engstrom, Logan, Turner, Alexander, Madry, Aleksander, (2018) Robustness may be at odds with accuracy, , arXiv preprint arXiv:1805.12152; Breiman, Leo, Bagging predictors (1996) Machine learning, 24 (2), pp. 123-140; Dietterich, Thomas G, Ensemble methods in machine learning (2000) International workshop on multiple classifier systems, pp. 1-15. , Springer; Bagnall, Alexander, Bunescu, Razvan, Stewart, Gordon, (2017) Training ensembles to detect adversarial examples, , arXiv preprint arXiv:1712.04006; Pang, Tianyu, Xu, Kun, Du, Chao, Chen, Ning, Zhu, Jun, (2019) Improving adversarial robustness via promoting ensemble diversity, , arXiv preprint arXiv:1901.08846; Kariyappa, Sanjay, Qureshi, Moinuddin K, (2019) Improving adversarial robustness of ensembles with diversity training, , arXiv preprint arXiv:1901.09981; Tramer, Florian, Carlini, Nicholas, Brendel, Wieland, Madry, Aleksander, (2020) On adaptive attacks to adversarial example defenses, , arXiv preprint arXiv:2002.08347; Papernot, Nicolas, McDaniel, Patrick, Jha, Somesh, Fredrikson, Matt, Berkay Celik, Z, Swami, Ananthram, The limitations of deep learning in adversarial settings (2016) 2016 IEEE European symposium on security and privacy (EuroS&P), pp. 372-387. , IEEE; Dong, Yinpeng, Liao, Fangzhou, Pang, Tianyu, Hu, Xiaolin, Zhu, Jun, (2017) Discovering adversarial examples with momentum, , arXiv preprint arXiv:1710.06081; Zheng, Tianhang, Chen, Changyou, Ren, Kui, Distributionally adversarial attack (2019) Proceedings of the AAAI Conference on Artificial Intelligence, 33, pp. 2253-2260; Hansen, Lars Kai, Salamon, Peter, Neural network ensembles (1990) IEEE transactions on pattern analysis and machine intelligence, 12 (10), pp. 993-1001; Kuncheva, Ludmila I, Whitaker, Christopher J, Measures of diversity in classifier ensembles and their relationship with the ensemble accuracy (2003) Machine learning, 51 (2), pp. 181-207; Lakshminarayanan, Balaji, Pritzel, Alexander, Blundell, Charles, Simple and scalable predictive uncertainty estimation using deep ensembles (2017) Advances in neural information processing systems, pp. 6402-6413; Sinha, Samarth, Bharadhwaj, Homanga, Goyal, Anirudh, Larochelle, Hugo, Garg, Animesh, Shkurti, Florian, (2020) Dibs: Diversity inducing information bottleneck in model ensembles, , arXiv preprint arXiv:2003.04514; Wen, Yeming, Tran, Dustin, Ba, Jimmy, (2020) Batchensemble: an alternative approach to efficient ensemble and lifelong learning, , arXiv preprint arXiv:2002.06715; Dusenberry, Michael W, Jerfel, Ghassen, Wen, Yeming, Ma, Yi-an, Snoek, Jasper, Heller, Katherine, Lakshminarayanan, Balaji, Tran, Dustin, (2020) Efficient and scalable bayesian neural nets with rank-1 factors, , arXiv preprint arXiv:2005.07186; Tramèr, Florian, Papernot, Nicolas, Goodfellow, Ian, Boneh, Dan, McDaniel, Patrick, (2017) The space of transferable adversarial examples, , arXiv preprint arXiv:1704.03453; Xie, Cihang, Yuille, Alan, Intriguing properties of adversarial training at scale (2020) International Conference on Learning Representations; Tramèr, Florian, Kurakin, Alexey, Papernot, Nicolas, Goodfellow, Ian, Boneh, Dan, McDaniel, Patrick, (2017) Ensemble adversarial training: Attacks and defenses, , arXiv preprint arXiv:1705.07204; He, Kaiming, Zhang, Xiangyu, Ren, Shaoqing, Sun, Jian, Deep residual learning for image recognition (2016) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770-778; Krizhevsky, Alex, Hinton, Geoffrey, (2009) Learning multiple layers of features from tiny images, , Technical report, Citeseer; Dong, Yinpeng, Liao, Fangzhou, Pang, Tianyu, Su, Hang, Zhu, Jun, Hu, Xiaolin, Li, Jianguo, Boosting adversarial attacks with momentum (2018) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 9185-9193; Xie, Cihang, Zhang, Zhishuai, Zhou, Yuyin, Bai, Song, Wang, Jianyu, Ren, Zhou, Yuille, Alan L, Improving transferability of adversarial examples with input diversity (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2730-2739; Wu, Dongxian, Wang, Yisen, Xia, Shu-Tao, Bailey, James, Ma, Xingjun, (2020) Skip connections matter: On the transferability of adversarial examples generated with resnets, , arXiv preprint arXiv:2002.05990; Hamon, Ronan, Junklewitz, Henrik, Sanchez, Ignacio, (2020) Robustness and explainability of artificial intelligence; Strubell, Emma, Verga, Patrick, Andor, Daniel, Weiss, David, McCallum, Andrew, (2018) Linguistically-informed self-attention for semantic role labeling, , arXiv preprint arXiv:1804.08199; Danks, David, (2020) How adversarial attacks could destabilize military ai systems, , https://spectrum.ieee.org/automaton/artificial-intelligence/embedded-ai/adversarial-attacks-and-ai-systems, [Online; accessed 2-June-2020]; Oh, Seong Joon, Schiele, Bernt, Fritz, Mario, Towards reverse-engineering black-box neural networks (2019) Explainable AI: Interpreting, Explaining and Visualizing Deep Learning, pp. 121-144. , Springer; Tramèr, Florian, Zhang, Fan, Juels, Ari, Reiter, Michael K, Ristenpart, Thomas, Stealing machine learning models via prediction apis (2016) 25th {USENIX} Security Symposium ({USENIX} Security 16), pp. 601-618; Kingma, Diederik P, Ba, Jimmy, (2014) Adam: A method for stochastic optimization, , arXiv preprint arXiv:1412.6980; Paszke, Adam, Gross, Sam, Chintala, Soumith, Chanan, Gregory, Yang, Edward, DeVito, Zachary, Lin, Zeming, Lerer, Adam, Automatic differentiation in pytorch (2017) NIPS-W; Ding, Gavin Weiguang, Wang, Luyu, Jin, Xiaomeng, (2019) AdverTorch v0.1: An adversarial robustness toolbox based on pytorch, , arXiv preprint arXiv:1902.07623; Athalye, Anish, Carlini, Nicholas, Wagner, David, (2018) Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples, , arXiv preprint arXiv:1802.00420; Carlini, Nicholas, Athalye, Anish, Papernot, Nicolas, Brendel, Wieland, Rauber, Jonas, Tsipras, Dimitris, Goodfellow, Ian, Kurakin, Alexey, (2019) On evaluating adversarial robustness, , arXiv preprint arXiv:1902.06705","Yang, H.; Department of Electrical and Computer Engineering, United States; 电子邮件: huanrui.yang@duke.edu
Zhang, J.; Department of Electrical and Computer Engineering, United States; 电子邮件: jz288@duke.edu
Dong, H.; Department of Electrical and Computer Engineering, United States; 电子邮件: hongliang.dong@duke.edu",,Apple;et al.;Microsoft;PDT Partners;Sony;Tenstorrent,Neural information processing systems foundation,"34th Conference on Neural Information Processing Systems, NeurIPS 2020",6 December 2020 through 12 December 2020,,169463,10495258,,,,English,Adv. neural inf. proces. syst.,Conference Paper,Final,,Scopus,2-s2.0-85104224908
"Che Z., Borji A., Zhai G., Ling S., Li J., Callet P.L.",57022192800;23395793600;15847120000;57193346540;51461432900;57203923621;,A new ensemble adversarial attack powered by long-term gradient memories,2020,AAAI 2020 - 34th AAAI Conference on Artificial Intelligence,,,,3405,3413,,1,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103164179&partnerID=40&md5=2ddfe29b7c58c6b230bdc227bff78eb4,"Shanghai Jiao Tong University, Shanghai, China; MarkableAI Inc., Brooklyn, NY  11201, United States; Université de Nantes, Nantes, France; Alibaba Group, Hangzhou, China","Che, Z., Shanghai Jiao Tong University, Shanghai, China; Borji, A., MarkableAI Inc., Brooklyn, NY  11201, United States; Zhai, G., Shanghai Jiao Tong University, Shanghai, China; Ling, S., Université de Nantes, Nantes, France; Li, J., Alibaba Group, Hangzhou, China; Callet, P.L., Université de Nantes, Nantes, France","Deep neural networks are vulnerable to adversarial attacks. More importantly, some adversarial examples crafted against an ensemble of pre-trained source models can transfer to other new target models, thus pose a security threat to blackbox applications (when the attackers have no access to the target models). Despite adopting diverse architectures and parameters, source and target models often share similar decision boundaries. Therefore, if an adversary is capable of fooling several source models concurrently, it can potentially capture intrinsic transferable adversarial information that may allow it to fool a broad class of other black-box target models. Current ensemble attacks, however, only consider a limited number of source models to craft an adversary, and obtain poor transferability. In this paper, we propose a novel black-box attack, dubbed Serial-Mini-Batch- Ensemble-Attack (SMBEA). SMBEA divides a large number of pre-trained source models into several mini-batches. For each single batch, we design 3 new ensemble strategies to improve the intra-batch transferability. Besides, we propose a new algorithm that recursively accumulates the ""long-term""gradient memories of the previous batch to the following batch. This way, the learned adversarial information can be preserved and the inter-batch transferability can be improved. Experiments indicate that our method outperforms state-ofthe- art ensemble attacks over multiple pixel-to-pixel vision tasks including image translation and salient region prediction. Our method successfully fools two online black-box saliency prediction systems including DeepGaze-II (Kummerer 2017) and SALICON (Huang et al. 2017). Finally, we also contribute a new repository to promote the research on adversarial attack and defense over pixel-to-pixel tasks: https://github.com/CZHQuality/AAA-Pix2pix. © 2020, Association for the Advancement of Artificial Intelligence.",,Deep neural networks; Online systems; Pixels; Decision boundary; Ensemble strategies; Image translation; Number of sources; Prediction systems; Salient regions; Security threats; Source models; Artificial intelligence,,,,,"Alletto, S., Palazzi, A., Solera, F., Calderara, S., Cucchiara, R., Dr(eye)ve: A dataset for attention-based tasks with applications to autonomous and assisted driving (2016) CVPRw; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017), SP; Che, Z., Borji, A., Zhai, G., Min, X., Guo, G., Callet, P., How is gaze influenced by image transformations? dataset and model (2019), TIP; Cordts, M., Omran, M., The cityscapes dataset for semantic urban scene understanding (2016) CVPR; Cornia, M., Baraldi, L., Serra, G., Predicting human eye fixations via an lstm-based saliency attentive model (2018), TIP; Dai, J., Qi, H., Xiong, Y., Li, Y., Zhang, G., Hu, H., Wei, Y., Deformable convolutional networks (2017) ICCV; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2018) CVPR; Dong, Y., Su, H., Wu, B., Li, Z., Liu, W., Zhang, T., Efficient decision-based black-box adversarial attacks on face recognition (2019) CVPR; Dosovitskiy, A., Brox, T., Generating images with perceptual similarity metrics based on deep networks (2016) NeurIPS; Duchi, J., Hazan, E., Singer, Y., Adaptive subgradient methods for online learning and stochastic optimization (2011) JMLR; Goodfellow, I., Shlens, J., Szegedy, C., Goodfellow, I., Explaining and harnessing adversarial examples (2015) ICLR; Huang, X., Shen, C., Boix, X., Zhao, Q., (2017) Online saliency prediction system SALICON, , http://salicon.net/demo/; Jiang, M., Huang, S., Duan, J., Zhao, Q., Salicon: Saliency in context (2015) CVPR; Kingma, D. P., Ba, J., Adam: A method for stochastic optimization (2015) ICLR; Kummerer, M., (2017) Online saliency prediction system Deepgaze-II, , https://deepgaze.bethgelab.org/; Kurakin, A., Goodfellow, I., Bengio, S., Bengio, S., Adversarial examples in the physical world (2016) ICLRw; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) ICLR; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) ICLR; Mopuri, K. R., Ganeshan, A., Radhakrishnan, V. B., Generalizable data-free objective for crafting universal adversarial perturbations (2018) TPAMI; Pan, J., Canton, C., McGuinness, K., Connor, N., Torres, J., Sayrol, E., Nieto, X., Salgan: Visual saliency prediction with generative adversarial networks (2017), CoRR:1701.01081; Papernot, N., Goodfollow, I., Sheatsley, R., Feinman, R., Mc-Daniel, P., (2016) cleverhans v2. 0.0: An adversarial machine learning library, , a arXiv preprint; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) SP; Papernot, N., Practical black-box attacks against machine learning (2017) ACM ACCCS; Qian, N., On the momentum term in gradient descent learning algorithms (1999) Neural networks; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M. K., Accessorize to a crime: Real and stealthy attacks on state-of-theart face recognition (2016) ACM SIGSAC; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I. J., Fergus, R., Intriguing properties of neural networks (2014) ICLR; Tieleman, T., Hinton, G., Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude (2012), COURSERA: Neural networks for machine learning; Tylecek, R., Spatial pattern templates for recognition of objects with regular structure (2013) GCPR; Wang, T. C., Liu, M. Y., Zhu, J. Y., Tao, A., Kautz, J., Catanzaro, B., High-resolution image synthesis and semantic manipulation with conditional gans (2018) CVPR; Wei, X., Liang, S., Chen, N., Cao, X., Transferable adversarial attacks for image and video object detection (2019) IJCAI; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Yuille, A., Adversarial examples for semantic segmentation and object detection (2017) ICCV, , L. X; Yang, S., Hsu, Y., (2017) Full speed region sensorless drive of permanent-magnet machine combining saliency-based and backemf-based drive, , TIE; Yu, F., Koltun, V., Multi-scale context aggregation by dilated convolutions (2016) ICLR; Zhao, Z., Dheeru, D., Sameer, S., Generating natural adversarial examples (2018) ICLR","Zhai, G.; Shanghai Jiao Tong UniversityChina",,Association for the Advancement of Artificial Intelligence,AAAI press,"34th AAAI Conference on Artificial Intelligence, AAAI 2020",7 February 2020 through 12 February 2020,,166426,,9.78E+12,,,English,AAAI - AAAI Conf. Artif. Intell.,Conference Paper,Final,,Scopus,2-s2.0-85103164179
"Wallace E., Stern M., Song D.",57207856436;57200274220;57226844538;,Imitation attacks and defenses for black-box machine translation systems,2020,"EMNLP 2020 - 2020 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference",,,,5531,5546,,5,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103065267&partnerID=40&md5=f48dec57e345428207b76d91e5b7fc93,"UC Berkeley, United States","Wallace, E., UC Berkeley, United States; Stern, M., UC Berkeley, United States; Song, D., UC Berkeley, United States","Adversaries may look to steal or attack black-box NLP systems, either for financial gain or to exploit model errors. One setting of particular interest is machine translation (MT), where models have high commercial value and errors can be costly. We investigate possible exploitations of black-box MT systems and explore a preliminary defense against such threats. We first show that MT systems can be stolen by querying them with monolingual sentences and training models to imitate their outputs. Using simulated experiments, we demonstrate that MT model stealing is possible even when imitation models have different input data or architectures than their target models. Applying these ideas, we train imitation models that reach within 0.6 BLEU of three production MT systems on both high-resource and low-resource language pairs. We then leverage the similarity of our imitation models to transfer adversarial examples to the production systems. We use gradient-based attacks that expose inputs which lead to semantically-incorrect translations, dropped content, and vulgar model outputs. To mitigate these vulnerabilities, we propose a defense that modifies translation outputs in order to misdirect the optimization of imitation models. This defense degrades the adversary's BLEU score and attack success rate at some cost in the defender's BLEU and inference speed. © 2020 Association for Computational Linguistics",,Computational linguistics; Computer aided language translation; Black boxes; Financial gains; Imitation models; Machine translation models; Machine translation systems; Machine translations; Model errors; NLP systems; Simulated experiments; Training model; Network security,,,,,"Alabdulmohsin, Ibrahim M, Gao, Xin, Zhang, Xiangliang, Adding robustness to support vector machines against adversarial reverse engineering (2014) CIKM; Alvarez-Melis, David, Jaakkola, Tommi S, A causal framework for explaining the predictions of black-box sequence-to-sequence models (2017) EMNLP; Cettolo, Mauro, Niehues, Jan, Stuker, Sebastian, Bentivogli, Luisa, Federico, Marcello, Report on the 11th IWSLT evaluation campaign (2014) IWSLT; Chandrasekaran, Varun, Chaudhari, K, Giacomelli, Irene, Jha, Somesh, Yan, Songbai, Exploring connections between active learning and model extraction (2020) USENIX Security Symposium; Chaturvedi, Akshay, Abijith, KP, Garain, Utpal, (2019) Exploring the robustness of NMT systems to nonsensical inputs, , arXiv preprint 1908.01165; Chen, Xinyun, Wang, Wenxiao, Bender, Chris, Ding, Yiming, Jia, Ruoxi, Li, Bo, Song, Dawn, (2019) REFIT: A unified watermark removal framework for deep learning systems with limited data, , arXiv preprint arXiv:1911.07205; Cheng, Minhao, Yi, Jinfeng, Zhang, Huan, Chen, Pin-Yu, Hsieh, Cho-Jui, Seq2Sick: Evaluating the robustness of sequence-to-sequence models with adversarial examples (2020) AAAI; Ebrahimi, Javid, Lowd, Daniel, Dou, Dejing, On adversarial examples for character-level neural machine translation (2018) COLING; Fan, Angela, Lewis, Mike, Dauphin, Yann, Hierarchical neural story generation (2018) ACL; Furlanello, Tommaso, Lipton, Zachary C, Tschannen, Michael, Itti, Laurent, Anandkumar, Anima, Born again neural networks (2018) ICML; Ghazvininejad, Marjan, Levy, Omer, Liu, Yinhan, Zettlemoyer, Luke, Constant-time machine translation with conditional masked language models (2019) EMNLP; Goodfellow, Ian J., Shlens, Jonathon, Szegedy, Christian, Explaining and harnessing adversarial examples (2015) ICLR; Guzmán, Francisco, Chen, Peng-Jen, Ott, Myle, Pino, Juan, Lample, Guillaume, Koehn, Philipp, Chaudhary, Vishrav, Ranzato, Marc'Aurelio, The FLoRes evaluation datasets for low-resource machine translation: Nepali-English and Sinhala-English (2019) EMNLP; Hern, Alex, Facebook translates “good morning” into “attack them”, leading to arrest (2018), The Guardian; Hinton, Geoffrey, Vinyals, Oriol, Dean, Jeff, Distilling the knowledge in a neural network (2014) NIPS Deep Learning Workshop; Hisamoto, Sorami, Post, Matt, Duh, Kevin, (2020) Membership inference attacks on sequence-to-sequence models: Is my data in your machine translation system?; Holtzman, Ari, Buys, Jan, Du, Li, Forbes, Maxwell, Choi, Yejin, The curious case of neural text degeneration (2020) ICLR; Huang, Po-Sen, Stanforth, Robert, Welbl, Johannes, Dyer, Chris, Yogatama, Dani, Gowal, Sven, Dvijotham, Krishnamurthy, Kohli, Pushmeet, Achieving verified robustness to symbol substitutions via interval bound propagation (2019) EMNLP; Jia, Robin, Raghunathan, Aditi, Göksel, Kerem, Liang, Percy, Certified robustness to adversarial word substitutions (2019) EMNLP; Johnson, Melvin, (2020) A scalable approach to reducing gender bias in Google Translate, , Google Blog; Juuti, Mika, Szyller, Sebastian, Marchal, Samuel, Asokan, N, PRADA: protecting against DNN model stealing attacks (2019) IEEE EuroS&P; Kim, Yoon, Rush, Alexander M, Sequence-level knowledge distillation (2016) EMNLP; Kim, Young Jin, Junczys-Dowmunt, Marcin, Hassan, Hany, Aji, Alham Fikri, Heafield, Kenneth, Grundkiewicz, Roman, Bogoychev, Nikolay, From research to production and back: Ludicrously fast neural machine translation (2019) Workshop on Neural Generation and Translation; Klar, Rebecca, (2019) Google under fire for mistranslating chinese amid hong kong protests, , The Hill; Krishna, Kalpesh, Tomar, Gaurav Singh, Parikh, Ankur P, Papernot, Nicolas, Iyyer, Mohit, Thieves on sesame street! Model extraction of BERT-based APIs (2020) ICLR; Kudo, Taku, Richardson, John, SentencePiece: A simple and language independent subword tokenizer and detokenizer for neural text processing (2018) EMNLP Demo Track; Lee, Taesung, Edwards, Benjamin, Molloy, Ian, Su, Dong, Defending against machine learning model stealing attacks using deceptive perturbations (2019) IEEE Security and Privacy Workshops; Liu, Yanpei, Chen, Xinyun, Liu, Chang, Song, Dawn, Delving into transferable adversarial examples and black-box attacks (2017) ICLR; Lowd, Daniel, Meek, Christopher, Adversarial learning (2005) KDD; Michel, Paul, Li, Xian, Neubig, Graham, Pino, Juan Miguel, On evaluation of adversarial perturbations for sequence-to-sequence models (2019) NAACL; Miller, George A, WordNet: a lexical database for English (1995) Communications of the ACM; Mobahi, Hossein, Farajtabar, Mehrdad, Bartlett, Peter L, Self-distillation amplifies regularization in Hilbert space (2020) NeurIPS; Moosavi-Dezfooli, Seyed-Mohsen, Fawzi, Alhussein, Fawzi, Omar, Frossard, Pascal, Universal adversarial perturbations (2017) CVPR; Orekondy, Tribhuvanesh, Schiele, Bernt, Fritz, Mario, Knockoff nets: Stealing functionality of black-box models (2019) CVPR; Orekondy, Tribhuvanesh, Schiele, Bernt, Fritz, Mario, Prediction poisoning: Towards defenses against dnn model stealing attacks (2020) ICLR; Ott, Myle, Edunov, Sergey, Baevski, Alexei, Fan, Angela, Gross, Sam, Ng, Nathan, Grangier, David, Auli, Michael, fairseq: A fast, extensible toolkit for sequence modeling (2019) NAACL Demo Track; Pal, Soham, Gupta, Yash, Shukla, Aditya, Kanade, Aditya, Shevade, Shirish, Ganapathy, Vinod, (2019) A framework for the extraction of deep neural networks by leveraging public data, , arXiv preprint arXiv:1905.09165; Papernot, Nicolas, McDaniel, Patrick, Goodfellow, Ian, (2016) Transferability in machine learning: from phenomena to black-box attacks using adversarial samples, , arXiv preprint arXiv:1605.07277; Papineni, Kishore, Roukos, Salim, Ward, Todd, Zhu, Wei-Jing, BLEU: a method for automatic evaluation of machine translation (2002) ACL; Post, Matt, A call for clarity in reporting BLEU scores (2018) WMT; Sennrich, Rico, Haddow, Barry, Birch, Alexandra, Improving neural machine translation models with monolingual data (2016) ACL; Singhal, Amit, Microsoft's Bing uses Google search results-and denies it (2011), Google Blog; Stanovsky, Gabriel, Smith, Noah A, Zettlemoyer, Luke, Evaluating gender bias in machine translation (2019) ACL; Stern, Mitchell, Chan, William, Kiros, Jamie, Uszkoreit, Jakob, Insertion transformer: Flexible sequence generation via insertion operations (2019) ICML; Szegedy, Christian, Zaremba, Wojciech, Sutskever, Ilya, Bruna, Joan, Erhan, Dumitru, Goodfellow, Ian J., Fergus, Rob, Intriguing properties of neural networks (2014) ICLR; Szyller, Sebastian, Atli, Buse Gul, Marchal, Samuel, Asokan, N, (2019) DAWN: Dynamic adversarial watermarking of neural networks, , arXiv preprint arXiv:1906.00830; Tan, Xu, Ren, Yi, He, Di, Qin, Tao, Liu, Tie-Yan, Multilingual neural machine translation with knowledge distillation (2019) ICLR; Tramèr, Florian, Zhang, Fan, Juels, Ari, Reiter, Michael K, Ristenpart, Thomas, Stealing machine learning models via prediction APIs (2016) USENIX Security Symposium; Vaswani, Ashish, Shazeer, Noam, Parmar, Niki, Uszkoreit, Jakob, Jones, Llion, Gomez, Aidan N, Kaiser, Łukasz, Polosukhin, Illia, Attention is all you need (2017) NeurIPS; Vijayakumar, Ashwin K, Cogswell, Michael, Selvaraju, Ramprasath R, Sun, Qing, Lee, Stefan, Crandall, David, Batra, Dhruv, Diverse beam search: Decoding diverse solutions from neural sequence models (2018) AAAI; Wallace, Eric, Feng, Shi, Kandpal, Nikhil, Gardner, Matt, Singh, Sameer, Universal adversarial triggers for attacking and analyzing NLP (2019) EMNLP; Wang, Chenglong, Bunel, Rudy, Dvijotham, Krishnamurthy, Huang, Po-Sen, Grefenstette, Edward, Kohli, Pushmeet, Knowing when to stop: Evaluation and verification of conformity to output-size specifications (2019) CVPR; Zhang, Jialong, Gu, Zhongshu, Jang, Jiyong, Wu, Hui, Stoecklin, Marc Ph, Huang, Heqing, Molloy, Ian, Protecting intellectual property of deep neural networks with watermarking (2018) ACM ASIACCS; Zhou, Chunting, Neubig, Graham, Gu, Jiatao, Understanding knowledge distillation in non-autoregressive machine translation (2020) ICLR",,,Amazon Science;Apple;Baidu;Bloomberg Engineering;et al.;Google Research,Association for Computational Linguistics (ACL),"2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020",16 November 2020 through 20 November 2020,,172724,,9.78E+12,,,English,"EMNLP - Conf. Empir. Methods Nat. Lang. Process., Proc. Conf.",Conference Paper,Final,,Scopus,2-s2.0-85103065267
"Rathgeb C., Drozdowski P., Busch C.",34870479500;57197761292;7101767185;,Detection of makeup presentation attacks based on deep face representations,2020,Proceedings - International Conference on Pattern Recognition,,,9413347,3443,3450,,1,10.1109/ICPR48806.2021.9413347,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102671467&doi=10.1109%2fICPR48806.2021.9413347&partnerID=40&md5=c6dd072e49efc6fab178cc3b7842fe50,"Da/Sec - Biometrics and Internet Security Research Group, Hochschule Darmstadt, Germany","Rathgeb, C., Da/Sec - Biometrics and Internet Security Research Group, Hochschule Darmstadt, Germany; Drozdowski, P., Da/Sec - Biometrics and Internet Security Research Group, Hochschule Darmstadt, Germany; Busch, C., Da/Sec - Biometrics and Internet Security Research Group, Hochschule Darmstadt, Germany","Facial cosmetics have the ability to substantially alter the facial appearance, which can negatively affect the decisions of a face recognition. In addition, it was recently shown that the application of makeup can be abused to launch so-called makeup presentation attacks. In such attacks, the attacker might apply heavy makeup in order to achieve the facial appearance of a target subject for the purpose of impersonation. In this work, we assess the vulnerability of a COTS face recognition system to makeup presentation attacks employing the publicly available Makeup Induced Face Spoofing (MIFS) database. It is shown that makeup presentation attacks might seriously impact the security of the face recognition system. Further, we propose an attack detection scheme which distinguishes makeup presentation attacks from genuine authentication attempts by analysing differences in deep face representations obtained from potential makeup presentation attacks and corresponding target face images. The proposed detection system employs a machine learning-based classifier, which is trained with synthetically generated makeup presentation attacks utilizing a generative adversarial network for facial makeup transfer in conjunction with image warping. Experimental evaluations conducted using the MIFS database reveal a detection equal error rate of 0.7% for the task of separating genuine authentication attempts from makeup presentation attacks. © 2020 IEEE",Biometrics; Deep face representation; Face recognition; Makeup attack detection; Presentation attack detection,Authentication; Turing machines; Adversarial networks; Attack detection; Detection system; Equal error rate; Experimental evaluation; Face recognition systems; Face representations; Facial appearance; Face recognition,,,,,"Marcel, S., Nixon, M.S., Fierrez, J., Evans, N., (2019) Handbook of Biometric Anti-Spoofing: Presentation Attack Detection; Galbally, J., Marcel, S., Fierrez, J., Biometric antispoofing methods: A survey in face recognition (2014) IEEE Access, 2, pp. 1530-1552. , December; Raghavendra, R., Busch, C., Presentation attack detection methods for face recognition systems: A comprehensive survey (2017) Computing Surveys (CSUR), 50 (1), pp. 1-37. , March; Steiner, H., Kolb, A., Jung, N., Reliable face anti-spoofing using multispectral SWIR imaging (2016) International Conference on Biometrics (ICB), pp. 1-8. , IEEE, June; Chen, C., Dantcheva, A., Swearingen, T., Ross, A., Spoofing faces using makeup: An investigative study (2017) International Conference on Identity, Security and Behavior Analysis (ISBA), pp. 1-8. , IEEE, February; Dantcheva, A., Chen, C., Ross, A., Can facial cosmetics affect the matching accuracy of face recognition systems? (2012) International Conference on Biometrics: Theory, Applications and Systems (BTAS), pp. 391-398. , IEEE, September; Rathgeb, C., Dantcheva, A., Busch, C., Impact and detection of facial beautification in face recognition: An overview (2019) IEEE Access, 7, pp. 152667-152678. , October; (2018) Socio-Economic Contribution of the European Cosmetics Industry, , https://www.ft.com/content/4721ed6a-f797-11e5-96db-fc683b5e52db, May last accessed: October 14, 2020; Whipp, L., (2016) Changing Face of Cosmetics Alters $63bn US Beauty Market, , https://www.ft.com/content/4721ed6a-f797-11e5-96db-fc683b5e52db, April last accessed: October 14, 2020; Ericson, L., Overview of the odin program on presentation attack detection (2018) International Face Performance Conference (IFPC); (2017) Information Technology - Biometric Presentation Attack Detection - Part 3: Testing and Reporting, , ISO/IEC JTC 1/SC 37 Biometrics, ISO/IEC 30107-3. September; Eckert, M., Kose, N., Dugelay, J.-L., Facial cosmetics database and impact analysis on automatic face recognition (2013) International Workshop on Multimedia Signal Processing (MMSP), pp. 434-439. , IEEE, September; Wang, T.Y., Kumar, A., Recognizing human faces under disguise and makeup (2016) International Conference on Identity, Security and Behavior Analysis (ISBA), pp. 1-7. , IEEE, February; Ueda, S., Koyama, T., Influence of make-up on facial recognition (2010) Perception, 39 (2), pp. 260-264. , February; Moeini, A., Moeini, H., Ayatollahi, F., Faez, K., Makeup-invariant face recognition by 3D face: Modeling and dual-tree complex wavelet transform from women's 2D real-world images (2014) International Conference on Pattern Recognition (ICPR), pp. 1710-1715. , IEEE, August; Kose, N., Apvrille, L., Dugelay, J.-L., Facial makeup detection technique based on texture and shape analysis (2015) International Conference and Workshops on Automatic Face and Gesture Recognition (FG), 1, pp. 1-7. , IEEE, May; Chen, C., Dantcheva, A., Ross, A., An ensemble of patch-based subspaces for makeup-robust face recognition (2016) Information Fusion, 32, pp. 80-92. , November; Feng, R., Prabhakaran, B., Quantifying the makeup effect in female faces and its applications for age estimation (2012) International Symposium on Multimedia (ISM), pp. 108-115. , IEEE, December; Chen, C., Dantcheva, A., Ross, A., Automatic facial makeup detection with application in face recognition (2013) International Conference on Biometrics (ICB), pp. 1-8. , IEEE, June; Guo, G., Wen, L., Yan, S., Face authentication with makeup changes (2014) Transactions on Circuits and Systems for Video Technology (TCSVT), 24 (5), pp. 814-825. , August; Wang, S., Fu, Y., Face behind makeup (2016) Conference on Artificial Intelligence, pp. 58-64. , AAAI, February; Zhu, Z., Lu, Y., Chiang, C., Generating adversarial examples by makeup attacks on face recognition (2019) International Conference on Image Processing (ICIP), pp. 2516-2520. , IEEE, September; Kotwal, K., Mostaani, Z., Marcel, S., Detection of age-induced makeup attacks on face recognition systems using multi-layer deep features (2019) Transactions on Biometrics, Behavior, and Identity Science (TBIOM), pp. 1-11. , October; Rathgeb, C., Drozdowski, P., Fischer, D., Busch, C., Vulnerability assessment and detection of makeup presentation attacks (2020) International Workshop on Biometrics and Forensics (IWBF), , IEEE, April; Boulkenafet, Z., Komulainen, J., Akhtar, Z., Benlamoudi, A., Samai, D., A competition on generalized software-based face presentation attack detection in mobile scenarios (2017) International Joint Conference on Biometrics (IJCB), pp. 688-696. , IEEE, October; Scherhag, U., Rathgeb, C., Merkle, J., Busch, C., Deep face representations for differential morphing attack detection IEEE Transactions on Information Forensics and Security, p. 2020; Rathgeb, C., Satnoianu, C.-I., Haryanto, N.E., Bernardo, K., Busch, C., Differential detection of facial retouching: A multi-biometric approach (2020) IEEE Access, 8, pp. 106373-106385. , June; Glasbey, C.A., Mardia, K.V., A review of image-warping methods (1998) Journal of Applied Statistics, 25 (2), pp. 155-171. , April; Chang, H., Lu, J., Yu, F., Finkelstein, A., PairedCyclegan: Asymmetric style transfer for applying and removing makeup (2018) International Conference on Computer Vision and Pattern Recognition (CVPR), , IEEE, June; Li, T., Qian, R., Dong, C., Liu, S., Yan, Q., Zhu, W., Lin, L., Beautygan: Instance-level facial makeup transfer with deep generative adversarial network (2018) International Conference on Multimedia (MM), pp. 645-653. , ACM, October; King, D.E., Dlib-mL: A machine learning toolkit (2009) Journal of Machine Learning Research (JMLR), 10, pp. 1755-1758. , December; Sandberg, D., Face Recognition Using Tensorflow, , https://github.com/davidsandberg/facenet, last accessed: October 14, 2020; Schroff, F., Kalenichenko, D., Philbin, J., FaceNet: A unified embedding for face recognition and clustering (2015) Conference on Computer Vision and Pattern Recognition (CVPR), pp. 815-823. , IEEE, June; Deng, J., Guo, J., Xue, N., Zafeiriou, S., ArcFace: Additive angular margin loss for deep face recognition (2019) Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4690-4699. , IEEE, June; Zhang, H., BeautyGAN: Instance-Level Facial Makeup Transfer with Deep Generative Adversarial Network, , https://github.com/Honlan/BeautyGAN, last accessed: October 14, 2020; Pedregosa, F., Scikit-learn: Machine learning in Python (2011) Journal of Machine Learning Research (JMLR), 12, pp. 2825-2830. , October; Phillips, P.J., Flynn, P.J., Scruggs, T., Bowyer, K.W., Chang, J., Hoffman, K., Marques, J., Worek, W., Overview of the face recognition grand challenge (2005) Conference on Computer Vision and Pattern Recognition (CVPR), 1, pp. 947-954. , IEEE, June; Liu, Z., Luo, P., Wang, X., Tang, X., Deep learning face attributes in the wild (2015) International Conference on Computer Vision (ICCV), pp. 3730-3738. , IEEE, December; Hernandez-Ortega, J., Galbally, J., Fiérrez, J., Haraksim, R., Beslay, L., Faceqnet: Quality assessment for face recognition based on deep learning (2019) International Conference on Biometrics (ICB), , IEEE, June; Phillips, J., Wechsler, H., Huang, J., Rauss, P., The FERET database and evaluation procedure for face recognition algorithms (1998) Image and Vision Computing Journal (IMAVIS), 16 (5), pp. 295-306. , April; (2006) Information Technology - Biometric Performance Testing and Reporting - Part 1: Principles and Framework, , ISO/IEC JTC1 SC37 Biometrics, ISO/IEC 19795-1: April 2006; Scherhag, U., Nautsch, A., Rathgeb, C., Gomez-Barrero, M., Veldhuis, R.N.J., Biometric systems under morphing attacks: Assessment of morphing techniques and vulnerability reporting (2017) International Conference of the Biometrics Special Interest Group (BIOSIG), pp. 1-7. , IEEE, September; Ahonen, T., Hadid, A., Pietikäinen, M., Face recognition with local binary patterns (2004) European Conf. On Computer Vision (ECCV'04), pp. 469-481. , Berlin, Heidelberg: Springer Berlin Heidelberg; Scherhag, U., Rathgeb, C., Busch, C., Towards detection of morphed face images in electronic travel documents (2018) 13th IAPR Workshop on Document Analysis Systems (DAS), pp. 1-6",,,,Institute of Electrical and Electronics Engineers Inc.,"25th International Conference on Pattern Recognition, ICPR 2020",10 January 2021 through 15 January 2021,,169954,10514651,9.78E+12,PICRE,,English,Proc. Int. Conf. Pattern Recognit.,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85102671467
"Liu J., Tian Y., Zhang R., Sun Y., Wang C.",55705849900;57225875444;57219462075;57222496869;57222496827;,A two-stage generative adversarial networks with semantic content constraints for adversarial example generation,2020,IEEE Access,8,,,205766,205777,,3,10.1109/ACCESS.2020.3037329,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101842449&doi=10.1109%2fACCESS.2020.3037329&partnerID=40&md5=d763cccddae89726e1d3af9c51a15c3b,"Beijing University of Posts and Telecommunications, Beijing, 100876, China; State Grid Information and Telecommunication Branch, Beijing, 100761, China","Liu, J., Beijing University of Posts and Telecommunications, Beijing, 100876, China; Tian, Y., Beijing University of Posts and Telecommunications, Beijing, 100876, China; Zhang, R., Beijing University of Posts and Telecommunications, Beijing, 100876, China; Sun, Y., Beijing University of Posts and Telecommunications, Beijing, 100876, China; Wang, C., State Grid Information and Telecommunication Branch, Beijing, 100761, China","Deep neural networks (DNNs) have achieved great success in various applications due to their strong expressive power. However, recent studies have shown that DNNs are vulnerable to adversarial examples, and these manipulated instances can mislead DNN into making false predictions. The existing methods of generating adversarial examples include pixel-level perturbation or spatial transformation of images, which cannot consider concurrently with the semantic quality of adversarial examples or success rate of attack. These methods are computationally bulky and slow to generate the adversarial examples. To solve this kind of issue, a two-stage generative adversarial networks (TSGAN) with semantic content constraints is proposed in this paper. The first-stage uses the original example dataset to train generator G, which can help the generator learn the distribution of real examples. Then, the example semantic quality constraint loss function, the adversarial loss function and the distance loss function are adopted in the second-stage, so that the generator G can continue to learn to search the distribution of the adversarial examples, and train the new generator Gadv. The adversarial examples generated by generator Gadv are better fit the distribution of real examples, and have targeted black-box attack capability. The experiments show that the adversarial examples generated by TSGAN can achieve the success rate of attack at 98.40% in target model, 29.40% success rate in defense-oriented model. And 77.58% success rate is obtained in the transfer test attack. The results show that the adversarial examples generated by the proposed model, which has a highly attack success rate and more difficult to defense. Meanwhile, the improved adversarial examples have stronger transfer ability than the existing models. The proposed model can effectively reduce the expression of target category features of the adversarial examples, and the generated adversarial examples have better semantic quality than others. © 2020 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.",Adversarial example attack; Generative adversarial networks; Semantic content,Deep neural networks; Network security; Semantic Web; Adversarial networks; Attack capability; Expressive power; Loss functions; Real example; Semantic content; Semantic qualities; Spatial transformation; Semantics,,,,,"Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) Proc. Int. Conf. Learn. Represent. (ICLR), pp. 1-10. , Banff, AB, Canada; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial examples in the physical world (2017) Proc. Int. Conf. Learn. Represent. (ICLR), pp. 1-14. , Toulon, France; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on State-of-the-Art face recognition (2016) Proc. ACM SIGSAC Conf. Comput. Commun. Secur., pp. 1528-1540. , Vienna, Austria, Oct; Lu, J., Sibai, H., Fabry, E., (2017) Adversarial Examples That Fool Detectors, , http://arxiv.org/abs/1712.02494, Online; Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Xiao, C., Prakash, A., Song, D., Robust physical-world attacks on deep learning visual classification (2018) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., pp. 1625-1634. , Salt Lake City, UT, USA, Jun; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Proc. ICONIP, pp. 2672-2680. , Montreal, QC, Canada; Gu, S., Rigazio, L., Towards deep neural network architectures robust to adversarial examples (2015) Proc. Int. Conf. Learn. Represent. (ICLR), pp. 1-9. , San Diego, CA, USA; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) Proc. Int. Conf. Learn. Represent. (ICLR), pp. 1-11. , San Diego, CA, USA; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2018) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., pp. 9185-9193. , Salt Lake City, UT, USA, Jun; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Proc. IEEE Symp. Secur. Privacy (SP), pp. 39-57. , San Jose, CA, USA, May; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 2574-2582. , Las Vegas, NV, USA, Jun; Baluja, S., Fischer, I., (2017) Adversarial Transformation Networks: Learning to Generate Adversarial Examples, , http://arxiv.org/abs/1703.09387, Online; Bose, A.J., Aarabi, P., Adversarial attacks on face detectors using neural net based constrained optimization (2018) Proc. IEEE 20th Int. Workshop Multimedia Signal Process. (MMSP), pp. 1-6. , Vancouver, BC, Canada, Aug; Zhao, Z., Dua, D., Singh, S., Generating natural adversarial examples (2018) Proc. Int. Conf. Learn. Represent. (ICLR), pp. 1-15. , Vancouver, BC, Canada; Xiao, C., Li, B., Zhu, J.-Y., He, W., Liu, M., Song, D., Generating adversarial examples with adversarial networks (2018) Proc. 27th Int. Joint Conf. Artif. Intell., pp. 3905-3911. , Stockholm, Sweden, Jul; Jandial, S., Mangla, P., Varshney, S., Balasubramanian, V., AdvGAN++: Harnessing latent layers for adversary generation (2019) Proc. IEEE/CVF Int. Conf. Comput. Vis. Workshop (ICCVW), pp. 2045-2048. , Seoul, Republic of Korea, Oct; Song, Y., Kushman, N., Shu, R., Ermon, S., Constructing unrestricted adversarial examples with generative models (2018) Proc. NeurIPS, pp. 8312-8323. , Montreal, QC, Canada; Wang, X., He, K., Song, C., Wang, L., Hopcroft, J.E., (2019) AT-GAN: An Adversarial Generator Model for Non-Constrained Adversarial Examples, , http://arxiv.org/abs/1904.07793, Online; Chen, F., Shang, Y., Hu, J., Xu, B., Few features attack to fool machine learning models through mask-based GAN Proc. Int. Joint Conf. Neural Netw. (IJCNN), pp. 1-7. , Glasgow, U.K., Jul. 2020; Zhao, G., Zhang, M., Liu, J., Wen, J.-R., (2019) Unsupervised Adversarial Attacks on Deep Feature-Based Retrieval with GAN, , http://arxiv.org/abs/1907.05793, Online; Jiang, L., Qiao, K., Qin, R., Wang, L., Yu, W., Chen, J., Bu, H., Yan, B., Cycle-consistent adversarial GAN: The integration of adversarial attack and defense (2020) Secur. Commun. Netw., 2020, pp. 1-9. , Feb; Lin, Z., Shi, Y., Xue, Z., (2018) IDSGAN: Generative Adversarial Networks for Attack Generation against Intrusion Detection, , http://arxiv.org/abs/1809.02077, Online; Gatys, L.A., Ecker, A.S., Bethge, M., Image style transfer using convolutional neural networks (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 2414-2423. , Jun; Gatys, L.A., Ecker, A.S., Bethge, M., (2015) A Neural Algorithm of Artistic Style, , http://arxiv.org/abs/1508.06576, Online; Johnson, J., Alahi, A., Fei-Fei, L., Perceptual losses for real-time style transfer and super-resolution (2016) Proc. Eur. Conf. Comput. Vis. Cham, pp. 694-711. , Switzerland: Springer; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-Scale Image Recognition, , http://arxiv.org/abs/1409.1556, Online; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) Proc. Int. Conf. Learn. Represent. (ICLR), pp. 1-14. , San Diego, CA, USA; Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., Courville, A.C., Improved training of Wasserstein GANs (2017) Proc. Adv. Neural Inf. Process. Syst., pp. 5767-5777; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2323. , Nov; Krizhevsky, A., Learning multiple layers of features from tiny images (2009) Tech. Rep. TR 2009, pp. 3-16; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 770-778. , Las Vegas, NV, USA, Jun; Kingma, D.P., Ba, J.L., ADaM: A method for stochastic optimization (2015) Proc. Int. Conf. Learn. Represent. (ICLR), pp. 1-15. , San Diego, CA, USA; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) Proc. Int. Conf. Learn. Represent. (ICLR), pp. 1-28. , Vancouver, BC, Canada; Dowson, D.C., Landau, B.V., The Fréchet distance between multivariate normal distributions (1982) J. Multivariate Anal., 12 (3), pp. 450-455. , Sep; Wang, Z., Bovik, A.C., Sheikh, H.R., Simoncelli, E.P., Image quality assessment: From error visibility to structural similarity (2004) IEEE Trans. Image Process., 13 (4), pp. 600-612. , Apr; Chowdhary, C.L., Patel, P.V., Kathrotia, K.J., Attique, M., Perumal, K., Ijaz, M.F., Analytical study of hybrid techniques for image encryption and decryption (2020) Sensors, 20 (18), p. 5162. , Sep","Zhang, R.; Beijing University of Posts and TelecommunicationsChina; 电子邮件: zhangru@bupt.edu.cn",,,Institute of Electrical and Electronics Engineers Inc.,,,,,21693536,,,,English,IEEE Access,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85101842449
"Lim J., Price T., Monrose F., Frahm J.-M.",57219590600;7202062119;8943339800;15622959600;,Revisiting the Threat Space for Vision-Based Keystroke Inference Attacks,2020,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),12539 LNCS,,,449,461,,,10.1007/978-3-030-68238-5_33,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101373919&doi=10.1007%2f978-3-030-68238-5_33&partnerID=40&md5=66786da318be7f0203e5b80810dafe28,"Department of Computer Science, The University of North Carolina at Chapel Hill, Chapel Hill, NC  27514, United States","Lim, J., Department of Computer Science, The University of North Carolina at Chapel Hill, Chapel Hill, NC  27514, United States; Price, T., Department of Computer Science, The University of North Carolina at Chapel Hill, Chapel Hill, NC  27514, United States; Monrose, F., Department of Computer Science, The University of North Carolina at Chapel Hill, Chapel Hill, NC  27514, United States; Frahm, J.-M., Department of Computer Science, The University of North Carolina at Chapel Hill, Chapel Hill, NC  27514, United States","A vision-based keystroke inference attack is a side-channel attack in which an attacker uses an optical device to record users on their mobile devices and infer their keystrokes. The threat space for these attacks has been studied in the past, but we argue that the defining characteristics for this threat space, namely the strength of the attacker, are outdated. Previous works do not study adversaries with vision systems that have been trained with deep neural networks because these models require large amounts of training data and curating such a dataset is expensive. To address this, we create a large-scale synthetic dataset to simulate the attack scenario for a keystroke inference attack. We show that first pre-training on synthetic data, followed by adopting transfer learning techniques on real-life data, increases the performance of our deep learning models. This indicates that these models are able to learn rich, meaningful representations from our synthetic data and that training on the synthetic data can help overcome the issue of having small, real-life datasets for vision-based key stroke inference attacks. For this work, we focus on single keypress classification where the input is a frame of a keypress and the output is a predicted key. We are able to get an accuracy of 95.6% after pre-training a CNN on our synthetic data and training on a small set of real-life data in an adversarial domain adaptation framework. © 2020, Springer Nature Switzerland AG.",Domain adaptation; Side-channel attack; Synthetic data,Computer vision; Deep learning; Deep neural networks; Large dataset; Learning systems; Transfer learning; Attack scenarios; Domain adaptation; Inference attacks; Learning models; Learning techniques; Real life data; Real life datasets; Synthetic data; Side channel attack,,,,,"Backes, M., Dürmuth, M., Unruh, D., Compromising reflections-or-how to read LCD monitors around the corner (2008) 2008 IEEE Symposium on Security and Privacy, SP 2008, Pp. 158–169. IEEE; Backes, M., Chen, T., Duermuth, M., Lensch, H.P.A., Welk, M., Tempest in a teapot: Compromising reflections revisited (2009) 2009 30Th IEEE Symposium on Security and Privacy, Pp. 315–327. IEEE; Balzarotti, D., Cova, M., Vigna, G., ClearShot: Eavesdropping on keyboard input from video (2008) 2008 IEEE Symposium on Security and Privacy, SP 2008, Pp. 170–183. IEEE; Bousmalis, K., Silberman, N., Dohan, D., Erhan, D., Krishnan, D., Unsupervised pixel-level domain adaptation with generative adversarial networks (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3722-3731. , , pp; Chen, Y., Li, T., Zhang, R., Zhang, Y., Hedgpeth, T., EyeTell: Video-assisted touchscreen keystroke inference from eye movements (2018) 2018 IEEE Symposium on Security and Privacy (SP), pp. 144-160. , , pp. , IEEE; Chen, Y., Li, W., Chen, X., van Gool, L., Learning semantic segmentation from synthetic data: A geometrically guided input-output adaptation approach (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1841-1850. , , pp; Chu, B., Madhavan, V., Beijbom, O., Hoffman, J., Darrell, T.: Best practices for fine-tuning visual classifiers to new domains. In: Hua, G., Jégou, H. (eds.) ECCV 2016. LNCS, vol. 9915, pp. 435–442. Springer, Cham (2016). https://doi.org/10. 1007/978-3-319-49409-8 34; Cordts, M., The cityscapes dataset for semantic urban scene understanding (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., (2009) Imagenet: A Large-Scale Hierarchical Image Database; Dosovitskiy, A., FlowNet: Learning optical flow with convolutional networks (2015) IEEE International Conference on Computer Vision (ICCV), , http://lmb.informatik.uni-freiburg.de/Publications/2015/DFIB15; Hoffman, J., (2018) Cycada: Cycle-Consistent Adversarial Domain Adaptation, , https://openreview.net/forum?id=SktLlGbRZ; Kuhn, M.G., (2002) Compromising Emanations: Eavesdropping Risks of Computer Displays, , Ph.D. thesis; Lin, T.-Y., et al.: Microsoft COCO: common objects in context. In: Fleet, D., Pajdla, T., Schiele, B., Tuytelaars, T. (eds.) ECCV 2014. LNCS, vol. 8693, pp. 740–755. Springer, Cham (2014). https://doi.org/10.1007/978-3-319-10602-1 48; Oquab, M., Bottou, L., Laptev, I., Sivic, J., Learning and transferring mid-level image representations using convolutional neural networks (2014) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1717-1724. , , pp; Peng, X., Usman, B., Saito, K., Kaushik, N., Hoffman, J., Saenko, K., (2018) Syn2real: A New Benchmark for Synthetic-To-Real Visual Domain Adaptation. Arxiv Preprint Arxiv, 1806, p. 09755; Raguram, R., White, A.M., Goswami, D., Monrose, F., Frahm, J.-M., (2011) Proceedings of the 18Th ACM Conference on Computer and Communications Security, pp. 527-536. , iSpy: automatic reconstruction of typed input from compromising reflections. In, pp. , ACM; Richter, S.R., Vineet, V., Roth, S., Koltun, V.: Playing for data: ground truth from computer games. In: Leibe, B., Matas, J., Sebe, N., Welling, M. (eds.) ECCV 2016. LNCS, vol. 9906, pp. 102–118. Springer, Cham (2016). https://doi.org/10. 1007/978-3-319-46475-6 7; Ros, G., Sellart, L., Materzynska, J., Vazquez, D., Lopez, A.M., The SYNTHIA dataset: A large collection of synthetic images for semantic segmentation of urban scenes (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3234-3243. , , pp; Shrivastava, A., Pfister, T., Tuzel, O., Susskind, J., Wang, W., Webb, R., Learning from simulated and unsupervised images through adversarial training (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2107-2116. , , pp; Shukla, D., Kumar, R., Serwadda, A., Phoha, V.V., Beware, your hands reveal your secrets! In (2014) Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security, pp. 904-917. , , pp. , ACM; Sun, J., Jin, X., Chen, Y., Zhang, J., Zhang, Y., Zhang, R., Visible: Video-assisted keystroke inference from tablet backside motion (2016) NDSS; Tzeng, E., Hoffman, J., Saenko, K., Darrell, T., Adversarial discriminative domain adaptation (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 7167-7176. , , pp; Wood, E., Baltrušaitis, T., Morency, L.-P., Robinson, P., Bulling, A., Learning an appearance-based gaze estimator from one million synthesised images (2016) Proceedings of the Ninth Biennial ACM Symposium on Eye Tracking Research & Applications, Pp. 131–138. ACM; Xu, Y., Heinly, J., White, A.M., Monrose, F., Frahm, J.-M., Seeing double: Reconstructing obscured typed input from repeated compromising reflections (2013) Proceedings of the 2013 ACM SIGSAC Conference on Computer & Communications Security, Pp. 1063–1074. ACM; Ye, G., (2017) Cracking Android Pattern Lock in Five Attempts; Yue, Q., Ling, Z., Fu, X., Liu, B., Ren, K., Zhao, W., Blind recognition of touched keys on mobile devices (2014) Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security, pp. 1403-1414. , , pp. , ACM","Lim, J.; Department of Computer Science, United States; 电子邮件: jlim13@cs.unc.edu",Bartoli A.Fusiello A.,,Springer Science and Business Media Deutschland GmbH,"Workshops held at the 16th European Conference on Computer Vision, ECCV 2020",23 August 2020 through 28 August 2020,,253939,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85101373919
"Gong X., Hu G., Hospedales T., Yang Y.",57222091491;55925786500;23990799300;56335750200;,Adversarial Robustness of Open-Set Recognition: Face Recognition and Person Re-identification,2020,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),12535 LNCS,,,135,151,,1,10.1007/978-3-030-66415-2_9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101364383&doi=10.1007%2f978-3-030-66415-2_9&partnerID=40&md5=727fbf6ba568560b096d86ca762eb51b,"Nanjing University, Nanjing, China; AnyVision, Belfast, United Kingdom; Edinburgh University, Edinburgh, United Kingdom","Gong, X., Nanjing University, Nanjing, China; Hu, G., AnyVision, Belfast, United Kingdom; Hospedales, T., Edinburgh University, Edinburgh, United Kingdom; Yang, Y., Edinburgh University, Edinburgh, United Kingdom","Recent studies show that DNNs are vulnerable to adversarial attacks, in which carefully chosen imperceptible modifications to the inputs lead to incorrect predictions. However most existing attacks focus on closed-set classification, and adversarial attack of open-set recognition has been less investigated. In this paper, we systematically investigate the adversarial robustness of widely used open-set recognition models, namely person re-identification (ReID) and face recognition (FR) models. Specifically, we compare two categories of black-box attacks: transfer-based extensions of standard closed-set attacks and several direct random-search based attacks proposed here. Extensive experiments demonstrate that ReID and FR models are also vulnerable to adversarial attack, and highlight a potential AI trustworthiness problem for these socially important applications. © 2020, Springer Nature Switzerland AG.",Adversarial attack; Face recognition; Open-world classification; Person re-identification,Computer vision; Black boxes; Closed set; Closed-set classifications; Person re identifications; Random searches; Recognition models; Face recognition,,,,,"Bai, S., Li, Y., Zhou, Y., Li, Q., Torr, P.H.S., (2019) Metric Attack and Defense for Person Re-Identification; Cao, K., Rong, Y., Li, C., Tang, X., Loy, C.C., Pose-robust face recognition via deep residual equivariant mapping (2018) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 5187-5196. , , pp; Carlini, N., Wagner, D.A., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP), pp. 39-57. , , pp; Chen, P.Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.J., ZOO: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) Proceedings of the 10Th ACM Workshop on Artificial Intelligence and Security, pp. 15-26. , , pp; Chen, S., Liu, Y., Gao, X., Han, Z.: MobileFaceNets: efficient CNNs for accurate real-time face verification on mobile devices. In: Zhou, J., et al. (eds.) CCBR 2018. LNCS, vol. 10996, pp. 428–438. Springer, Cham (2018). https://doi.org/10.1007/978-3-319-97909-0 46; Cissé, M., Adi, Y., Neverova, N., Keshet, J., Houdini: Fooling deep structured prediction models (2017) Corr Abs/1707, p. 05373; Deb, D., Zhang, J., Jain, A.K., AdvFaces: Adversarial face synthesis (2019) Corr Abs/1908, p. 05008; Deng, J., Guo, J., Xue, N., Zafeiriou, S., ArcFace: additive angular margin loss for deep face recognition (2019) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4690-4699. , , pp; Ding, W., Wei, X., Hong, X., Ji, R., Gong, Y., Universal adversarial perturbations against person re-identification (2019) Corr Abs/1910, p. 14184; Gafni, O., Wolf, L., Taigman, Y., Live face de-identification in video (2019) IEEE/CVF International Conference on Computer Vision (ICCV), pp. 9377-9386. , , pp. , 2019; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) 3Rd International Conference on Learning Representations (ICLR; Goswami, G., Ratha, N.K., Agarwal, A., Singh, R., Vatsa, M., Unravelling robustness of deep learning based face recognition against adversarial attacks (2018) Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, pp. 6829-6836. , , pp; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 770-778. , , pp; Huang, G.B., Ramesh, M., Berg, T., Learned-Miller, E., (2007) Labeled Faces in the Wild: A Database for Studying Face Recognition in Unconstrained Environments, , Technical report; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial examples in the physical world (2017) 5Th International Conference on Learning Representations (ICLR; Li, D., Chen, X., Zhang, Z., Huang, K., Learning deep context-aware features over body and latent parts for person re-identification (2017) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 7398-7407. , , pp; Li, X., Wu, A., Zheng, W.-S.: Adversarial open-world person re-identification. In: Ferrari, V., Hebert, M., Sminchisescu, C., Weiss, Y. (eds.) ECCV 2018. LNCS, vol. 11206, pp. 287–303. Springer, Cham (2018). https://doi.org/10.1007/978-3-030-01216-8 18; Liu, W., Wen, Y., Yu, Z., Li, M., Raj, B., Song, L., SphereFace: deep hypersphere embedding for face recognition (2017) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 6738-6746. , , pp; Liu, Y., Li, H., Wang, X., Rethinking feature discrimination and polymerization for large-scale recognition (2017) Corr Abs/1710, p. 00870; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) 6Th International Conference on Learning Representations (ICLR; Moosavi-Dezfooli, S., Fawzi, A., Frossard, P., DeepFool: A simple and accurate method to fool deep neural networks (2016) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2574-2582. , , pp; Papernot, N., McDaniel, P.D., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) IEEE European Symposium on Security and Privacy (EuroS&P; Sarkar, S., Bansal, A., Mahbub, U., Chellappa, R., UPSET and ANGRI: Breaking high performance image classifiers (2017) Corr Abs/1707, p. 01159; Schroff, F., Kalenichenko, D., Philbin, J., FaceNet: A unified embedding for face recognition and clustering (2015) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 815-823. , , pp; Shen, Y., Xiao, T., Li, H., Yi, S., Wang, X., End-to-end deep Kronecker-product matching for person re-identification (2018) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 6886-6895. , , pp; Si, J., Zhang, H., Li, C., Kuen, J., Kong, X., Kot, A.C., Wang, G., Dual attention matching network for context-aware feature sequence based person re-identification (2018) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 5363-5372. , , pp; Song, C., Huang, Y., Ouyang, W., Wang, L., Mask-guided contrastive attention model for person re-identification (2018) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1179-1188. , , pp; Su, J., Vargas, D.V., Sakurai, K., One pixel attack for fooling deep neural networks (2019) IEEE Trans. Evol. Comput., 23 (5), pp. 828-841; Sun, Y., Wang, X., Tang, X., Deep learning face representation from predicting 10, 000 classes (2014) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1891-1898. , , pp; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R., Intriguing properties of neural networks (2014) 2Nd International Conference on Learning Representations (ICLR; Taigman, Y., Yang, M., Ranzato, M., Wolf, L., DeepFace: closing the gap to human-level performance in face verification (2014) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1701-1708. , , pp; Tang, D., Wang, X., Zhang, K., Query-free attacks on industry-grade face recognition systems under resource constraints (2018) Corr Abs/1802, p. 09900; Varior, R.R., Haloi, M., Wang, G.: Gated Siamese convolutional neural network architecture for human re-identification. In: Leibe, B., Matas, J., Sebe, N., Welling, M. (eds.) ECCV 2016. LNCS, vol. 9912, pp. 791–808. Springer, Cham (2016). https://doi.org/10.1007/978-3-319-46484-8 48; Wang, F., Xiang, X., Cheng, J., Yuille, A.L., Normface: L2 hypersphere embedding for face verification (2017) Proceedings of the 2017 ACM on Multimedia Conference, pp. 1041-1049. , , pp; Wang, H., Wang, Y., Zhou, Z., Ji, X., Gong, D., Zhou, J., Li, Z., Liu, W., Cos-Face: large margin cosine loss for deep face recognition (2018) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 5265-5274. , , pp; Wang, Z., Zheng, S., Song, M., Wang, Q., Rahimpour, A., Qi, H., AdvPattern: Physical-world attacks on deep person re-identification via adversarially trans-formable patterns (2019) 2019 IEEE/CVF International Conference on Computer Vision (ICCV), pp. 8340-8349. , , pp; Wei, L., Zhang, S., Gao, W., Tian, Q., Person transfer GAN to bridge domain gap for person re-identification (2018) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 79-88. , , pp; Yi, D., Lei, Z., Liao, S., Li, S.Z., Learning face representation from scratch (2014) Corr Abs/1411, p. 7923; Yu, T., Li, D., Yang, Y., Hospedales, T.M., Xiang, T., Robust person re-identification by modelling feature uncertainty (2019) IEEE/CVF International Conference on Computer Vision (ICCV), pp. 552-561. , , pp; Zhang, X., AlignedReID: Surpassing human-level performance in person re-identification (2017) Corr Abs/1711, p. 08184; Zhang, Z., Lan, C., Zeng, W., Chen, Z., Densely semantically aligned person re-identification (2019) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 667-676. , , pp; Zhao, L., Li, X., Zhuang, Y., Wang, J., Deeply-learned part-aligned representations for person re-identification (2017) IEEE International Conference on Computer Vision (ICCV), pp. 3239-3248. , , pp; Zheng, L., Shen, L., Tian, L., Wang, S., Wang, J., Tian, Q., Scalable person re-identification: A benchmark (2015) IEEE International Conference on Computer Vision (ICCV), pp. 1116-1124. , , pp; Zhou, E., Cao, Z., Yin, Q., Naive-deep face recognition: Touching the limit of LFW benchmark or not? (2015) Corr Abs/1501, p. 04690; Zhou, K., Xiang, T., Torchreid: A library for deep learning person re-identification in Pytorch (2019) Corr Abs/1910, p. 10093; Zhou, K., Yang, Y., Cavallaro, A., Xiang, T., Omni-scale feature learning for person re-identification (2019) IEEE/CVF International Conference on Computer Vision (ICCV), pp. 3701-3711. , , pp; Zhu, Z., Luo, P., Wang, X., Tang, X., Recover canonical-view faces in the wild with deep neural networks (2014) Corr Abs/1404, p. 3543","Gong, X.; Nanjing UniversityChina; 电子邮件: gongxiao2020@hotmail.com",Bartoli A.Fusiello A.,,Springer Science and Business Media Deutschland GmbH,"Workshops held at the 16th European Conference on Computer Vision, ECCV 2020",23 August 2020 through 28 August 2020,,253939,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,,Scopus,2-s2.0-85101364383
"Li Q., Guo Y., Chen H.",57219474497;57194152792;57189043754;,Practical no-box adversarial attacks against DNNs,2020,Advances in Neural Information Processing Systems,2020-December,,,,,,1,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099890820&partnerID=40&md5=09590a790cae98167f920e9514e46f32,"ByteDance AI Lab.; University of California, Davis, United States","Li, Q., ByteDance AI Lab.; Guo, Y., ByteDance AI Lab.; Chen, H., University of California, Davis, United States","The study of adversarial vulnerabilities of deep neural networks (DNNs) has progressed rapidly. Existing attacks require either internal access (to the architecture, parameters, or training set of the victim model) or external access (to query the model). However, both the access may be infeasible or expensive in many scenarios. We investigate no-box adversarial examples, where the attacker can neither access the model information or the training set nor query the model. Instead, the attacker can only gather a small number of examples from the same problem domain as that of the victim model. Such a stronger threat model greatly expands the applicability of adversarial attacks. We propose three mechanisms for training with a very small dataset (on the order of tens of examples) and find that prototypical reconstruction is the most effective. Our experiments show that adversarial examples crafted on prototypical auto-encoding models transfer well to a variety of image classification and face verification models. On a commercial celebrity recognition system held by clarifai.com, our approach significantly diminishes the average prediction accuracy of the system to only 15.40%, which is on par with the attack that transfers adversarial examples from a pre-trained Arcface model. Our code is publicly available at: https://github.com/qizhangli/nobox-attacks. © 2020 Neural information processing systems foundation. All rights reserved.",,Encoding models; Face Verification; Internal access; Model informations; Prediction accuracy; Problem domain; Recognition systems; Threat modeling; Deep neural networks,,,,,"Athalye, Anish, Carlini, Nicholas, Wagner, David, Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples (2018) ICML; Brendel, Wieland, Rauber, Jonas, Bethge, Matthias, Decision-based adversarial attacks: Reliable attacks against black-box machine learning models (2018) ICLR; Carlini, Nicholas, Wagner, David, Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy (SP); Chen, Jianbo, Jordan, Michael I, Wainwright, Martin J, (2019) Hopskipjumpattack: A query-efficient decision-based attack, , arXiv preprint arXiv:1904.02144; Chen, Pin-Yu, Zhang, Huan, Sharma, Yash, Yi, Jinfeng, Hsieh, Cho-Jui, Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 15-26. , ACM; Cheng, Minhao, Le, Thong, Chen, Pin-Yu, Yi, Jinfeng, Zhang, Huan, Hsieh, Cho-Jui, Query-efficient hard-label black-box attack: An optimization-based approach (2019) ICLR; Deng, Jiankang, Guo, Jia, Xue, Niannan, Zafeiriou, Stefanos, Arcface: Additive angular margin loss for deep face recognition (2019) CVPR; Doersch, Carl, Gupta, Abhinav, Efros, Alexei A, Unsupervised visual representation learning by context prediction (2015) ICCV; Dong, Yinpeng, Su, Hang, Wu, Baoyuan, Li, Zhifeng, Liu, Wei, Zhang, Tong, Zhu, Jun, Efficient decision-based black-box adversarial attacks on face recognition (2019) CVPR; Dosovitskiy, Alexey, Springenberg, Jost Tobias, Riedmiller, Martin, Brox, Thomas, Discriminative unsupervised feature learning with convolutional neural networks (2014) NeurIPS; Gidaris, Spyros, Singh, Praveer, Komodakis, Nikos, (2018) Unsupervised representation learning by predicting image rotations, , arXiv preprint arXiv:1803.07728; Goodfellow, Ian J, Shlens, Jonathon, Szegedy, Christian, Explaining and harnessing adversarial examples (2015) ICLR; Guo, Chuan, Gardner, Jacob R, You, Yurong, Wilson, Andrew G, Weinberger, Kilian Q, Simple black-box adversarial attacks (2019) ICML; Guo, Yiwen, Li, Qizhang, Chen, Hao, Backpropagating linearly improves transferability of adversarial examples (2020) NeurIPS; He, Kaiming, Zhang, Xiangyu, Ren, Shaoqing, Sun, Jian, Deep residual learning for image recognition (2016) CVPR; Hu, Jie, Shen, Li, Sun, Gang, Squeeze-and-excitation networks (2018) CVPR; Huang, Gao, Liu, Zhuang, Van Der Maaten, Laurens, Weinberger, Kilian Q, Densely connected convolutional networks (2017) CVPR; Huang, Gary B., Ramesh, Manu, Berg, Tamara, Learned-Miller, Erik, (2007) Labeled faces in the wild: A database for studying face recognition in unconstrained environments, , Technical Report 07-49, University of Massachusetts, Amherst, October; Huang, Qian, Katsman, Isay, He, Horace, Gu, Zeqi, Belongie, Serge, Lim, Ser-Nam, Enhancing adversarial example transferability with an intermediate level attack (2019) ICCV; Ilyas, Andrew, Engstrom, Logan, Athalye, Anish, Lin, Jessy, Black-box adversarial attacks with limited queries and information (2018) ICML; Ilyas, Andrew, Engstrom, Logan, Madry, Aleksander, Prior convictions: Black-box adversarial attacks with bandits and priors (2019) ICLR; Inkawhich, Nathan, Wen, Wei, Li, Hai Helen, Chen, Yiran, Feature space perturbations yield more transferable adversarial examples (2019) CVPR; Ioffe, Sergey, Szegedy, Christian, Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015) ICML; Kingma, Diederik P, Ba, Jimmy, (2014) Adam: A method for stochastic optimization, , arXiv preprint arXiv:1412.6980; Kos, Jernej, Fischer, Ian, Song, Dawn, Adversarial examples for generative models (2018) IEEE security and privacy workshops, pp. 36-42; Kurakin, Alexey, Goodfellow, Ian, Bengio, Samy, Adversarial machine learning at scale (2017), ICLR, [27] Qizhang Li, Yiwen Guo, and Hao Chen. Yet another intermediate-leve attack ECCV, 2020; Liu, Chenxi, Zoph, Barret, Neumann, Maxim, Shlens, Jonathon, Hua, Wei, Li, Li-Jia, Fei-Fei, Li, Murphy, Kevin, Progressive neural architecture search (2018) ECCV; Madry, Aleksander, Makelov, Aleksandar, Schmidt, Ludwig, Tsipras, Dimitris, Vladu, Adrian, Towards deep learning models resistant to adversarial attacks (2018) ICLR; Moosavi-Dezfooli, Seyed-Mohsen, Fawzi, Alhussein, Frossard, Pascal, DeepFool: a simple and accurate method to fool deep neural networks (2016) CVPR; Narodytska, Nina, Kasiviswanathan, Shiva, Simple black-box adversarial attacks on deep neural networks (2017) CVPR Workshop; Noroozi, Mehdi, Favaro, Paolo, Unsupervised learning of visual representations by solving jigsaw puzzles (2016) ECCV; Papernot, Nicolas, McDaniel, Patrick, Goodfellow, Ian, (2016) Transferability in machine learning: from phenomena to black-box attacks using adversarial samples, , arXiv preprint arXiv:1605.07277; Papernot, Nicolas, McDaniel, Patrick, Goodfellow, Ian, Jha, Somesh, Berkay Celik, Z, Swami, Ananthram, Practical black-box attacks against machine learning (2017) Asia Conference on Computer and Communications Security; Papernot, Nicolas, McDaniel, Patrick, Jha, Somesh, Fredrikson, Matt, Berkay Celik, Z, Swami, Ananthram, The limitations of deep learning in adversarial settings (2016) Euro S&P; Paszke, Adam, Gross, Sam, Massa, Francisco, Lerer, Adam, Bradbury, James, Chanan, Gregory, Killeen, Trevor, Antiga, Luca, Pytorch: An imperative style, high-performance deep learning library (2019) NeurIPS; Ruiz, Nataniel, Sclaroff, Stan, (2020) Disrupting deepfakes: Adversarial attacks against conditional image translation networks and facial manipulation systems, , arXiv preprint arXiv:2003.01279; Russakovsky, Olga, Deng, Jia, Su, Hao, Krause, Jonathan, Satheesh, Sanjeev, Ma, Sean, Huang, Zhiheng, Fei-Fei, Li, Imagenet large scale visual recognition challenge (2015) IJCV; Sandler, Mark, Howard, Andrew, Zhu, Menglong, Zhmoginov, Andrey, Chen, Liang-Chieh, Mobilenetv2: Inverted residuals and linear bottlenecks (2018) CVPR; Schroff, Florian, Kalenichenko, Dmitry, Philbin, James, Facenet: A unified embedding for face recognition and clustering (2015) CVPR; Shaham, Tamar Rott, Dekel, Tali, Michaeli, Tomer, Singan: Learning a generative model from a single natural image (2019) ICCV; Simonyan, Karen, Zisserman, Andrew, Very deep convolutional networks for large-scale image recognition (2015) ICLR; Srivastava, Nitish, Hinton, Geoffrey, Krizhevsky, Alex, Sutskever, Ilya, Salakhutdinov, Ruslan, Dropout: a simple way to prevent neural networks from overfitting (2014) The Journal of Machine Learning Research, 15 (1), pp. 1929-1958; Szegedy, Christian, Ioffe, Sergey, Vanhoucke, Vincent, Alemi, Alexander A, Inception-v4, inceptionresnet and the impact of residual connections on learning (2017) AAAI; Szegedy, Christian, Vanhoucke, Vincent, Ioffe, Sergey, Shlens, Jon, Wojna, Zbigniew, Rethinking the inception architecture for computer vision (2016) CVPR; Szegedy, Christian, Zaremba, Wojciech, Sutskever, Ilya, Bruna, Joan, Erhan, Dumitru, Goodfellow, Ian, Fergus, Rob, Intriguing properties of neural networks (2014) ICLR; Tabacof, Pedro, Tavares, Julia, Valle, Eduardo, (2016) Adversarial images for variational autoencoders, , arXiv preprint arXiv:1612.00155; Tlusty, Tal, Michaeli, Tomer, Dekel, Tali, Zelnik-Manor, Lihi, Modifying non-local variations across multiple views (2018) CVPR; Tramèr, Florian, Zhang, Fan, Juels, Ari, Reiter, Michael K, Ristenpart, Thomas, Stealing machine learning models via prediction apis (2016) USENIX} Security; Tu, Chun-Chen, Ting, Paishun, Chen, Pin-Yu, Liu, Sijia, Zhang, Huan, Yi, Jinfeng, Hsieh, Cho-Jui, Cheng, Shin-Ming, Autozoom: Autoencoder-based zeroth order optimization method for attacking black-box neural networks (2019) AAAI; Ulyanov, Dmitry, Vedaldi, Andrea, Lempitsky, Victor, Deep image prior (2018) CVPR; Wang, Hao, Wang, Yitong, Zhou, Zheng, Ji, Xing, Gong, Dihong, Zhou, Jingchao, Li, Zhifeng, Liu, Wei, Cosface: Large margin cosine loss for deep face recognition (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 5265-5274; Xie, Cihang, Zhang, Zhishuai, Zhou, Yuyin, Bai, Song, Wang, Jianyu, Ren, Zhou, Yuille, Alan L, Improving transferability of adversarial examples with input diversity (2019) CVPR; Yan, Ziang, Guo, Yiwen, Zhang, Changshui, Subspace attack: Exploiting promising subspaces for query-efficient black-box attacks (2019) NeurIPS; Yi, Dong, Lei, Zhen, Liao, Shengcai, Li, Stan Z, (2014) Learning face representation from scratch, , arXiv preprint arXiv:1411.7923; Zagoruyko, Sergey, Komodakis, Nikos, Wide residual networks (2016) BMVC; Zhang, Chiyuan, Bengio, Samy, Hardt, Moritz, Recht, Benjamin, Vinyals, Oriol, Understanding deep learning requires rethinking generalization (2017) ICLR; Zhang, Kaipeng, Zhang, Zhanpeng, Li, Zhifeng, Qiao, Yu, Joint face detection and alignment using multitask cascaded convolutional networks (2016) IEEE Signal Processing Letters, 23 (10), pp. 1499-1503; Zhang, Richard, Isola, Phillip, Efros, Alexei A, Colorful image colorization (2016) ECCV, , Springer; Zhou, Mingyi, Wu, Jing, Liu, Yipeng, Liu, Shuaicheng, Zhu, Ce, Dast: Data-free substitute training for adversarial attacks (2020) CVPR; Zhou, Wen, Hou, Xin, Chen, Yongjun, Tang, Mengyun, Huang, Xiangqi, Gan, Xiang, Yang, Yong, Transferable adversarial perturbations (2018) ECCV; Zhu, Jun-Yan, Park, Taesung, Isola, Phillip, Efros, Alexei A, Unpaired image-to-image translation using cycle-consistent adversarial networks (2017) ICCV","Li, Q.; ByteDance AI Lab.电子邮件: liqizhang@bytedance.com",,Apple;et al.;Microsoft;PDT Partners;Sony;Tenstorrent,Neural information processing systems foundation,"34th Conference on Neural Information Processing Systems, NeurIPS 2020",6 December 2020 through 12 December 2020,,169463,10495258,,,,English,Adv. neural inf. proces. syst.,Conference Paper,Final,,Scopus,2-s2.0-85099890820
"Rathgeb C., Drozdowski P., Busch C.",34870479500;57197761292;7101767185;,Makeup Presentation Attacks: Review and Detection Performance Benchmark,2020,IEEE Access,8,,9293285,224958,224973,,5,10.1109/ACCESS.2020.3044723,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098571987&doi=10.1109%2fACCESS.2020.3044723&partnerID=40&md5=fa380cf36e17652c023811df2d582664,"Da/sec - Biometrics and Internet-Security Research Group, Hochschule Darmstadt, Darmstadt, Germany","Rathgeb, C., Da/sec - Biometrics and Internet-Security Research Group, Hochschule Darmstadt, Darmstadt, Germany; Drozdowski, P., Da/sec - Biometrics and Internet-Security Research Group, Hochschule Darmstadt, Darmstadt, Germany; Busch, C., Da/sec - Biometrics and Internet-Security Research Group, Hochschule Darmstadt, Darmstadt, Germany","The application of facial cosmetics may cause substantial alterations in the facial appearance, which can degrade the performance of facial biometrics systems. Additionally, it was recently demonstrated that makeup can be abused to launch so-called makeup presentation attacks. More precisely, an attacker might apply heavy makeup to obtain the facial appearance of a target subject with the aim of impersonation or to conceal their own identity. We provide a comprehensive survey of works related to the topic of makeup presentation attack detection, along with a critical discussion. Subsequently, we assess the vulnerability of a commercial off-the-shelf and an open-source face recognition system against makeup presentation attacks. Specifically, we focus on makeup presentation attacks with the aim of impersonation employing the publicly available Makeup Induced Face Spoofing (MIFS) and Disguised Faces in the Wild (DFW) databases. It is shown that makeup presentation attacks might seriously impact the security of face recognition systems. Further, we propose different image pair-based, i.e. differential, attack detection schemes which analyse differences in feature representations obtained from potential makeup presentation attacks and corresponding target face images. The proposed detection systems employ various types of feature extractors including texture descriptors, facial landmarks, and deep (face) representations. To distinguish makeup presentation attacks from genuine, i.e. bona fide presentations, machine learning-based classifiers are used. The classifiers are trained with a large number of synthetically generated makeup presentation attacks utilising a generative adversarial network for facial makeup transfer in conjunction with image warping. Experimental evaluations conducted using the MIFS database and a subset of the DFW database reveal that deep face representations achieve competitive detection equal error rates of 0.7% and 1.8%, respectively. © 2013 IEEE.",Biometrics; face recognition; makeup; makeup attack detection; presentation attack detection,Benchmarking; Database systems; Feature extraction; Open systems; Textures; Adversarial networks; Critical discussions; Detection performance; Experimental evaluation; Face recognition systems; Face representations; Feature representation; Texture descriptors; Face recognition,,,,,"Jain, A.K., Nandakumar, K., Ross, A., 50 years of biometric research: Accomplishments, challenges, and opportunities (2016) Pattern Recognit. Lett., 79, pp. 80-105. , Aug; Jain, A.K., Flynn, P., Ross, A., (2008) Handbook of Biometrics, , New York, NY, USA: Springer, Jul; Ratha, N.K., Connell, J.H., Bolle, R.M., Enhancing security and privacy in biometrics-based authentication systems (2001) IBM Syst. J., 40 (3), pp. 614-634; Marcel, S., Nixon, M.S., Fierrez, J., Evans, N., (2019) Handbook of Bio-metric Anti-Spoofing: Presentation Attack Detection, , Cham, Switzerland: Springer; Hadid, A., Evans, N., Marcel, S., Fierrez, J., Biometrics systems under spoofing attack: An evaluation methodology and lessons learned (2015) IEEE Signal Process. Mag., 32 (5), pp. 20-30. , Sep; https://www.blackhat.com/html/bh-usa-09/bh-usa-09-archives.html, (2009). Black Hat USA. Accessed: Oct. 2020; https://nvd.nist.gov/, National Institute of Standards and Technology. (2020). National Vulnerability Database. Accessed: Oct. 2020; http://www.tabularasaeuproject.org/, (2016). EU-FP7 Trusted Biometrics Under Spoofing Attacks (TABULA RASA). Accessed: Oct. 2020; https://www.iarpa.gov/index.php/research-programs/odin, (2016). IARPA Odin. Accessed: Oct. 2020; Galbally, J., Marcel, S., Fierrez, J., Biometric antispoofing methods: A survey in face recognition (2014) IEEE Access, 2, pp. 1530-1552. , Dec; Raghavendra, R., Busch, C., Presentation attack detection methods for face recognition systems: A comprehensive survey (2017) Comput. Surv., 50 (1), pp. 1-37. , Mar; Information Security, Cybersecurity and Privacy Protection, Informa-tion Technology Security Techniques Security Evaluation of Biometrics, Standard ISO/IEC JTC1 SC27, ISO/IEC 19792, International Organization for Standardization and International Electrotechnical Committee, Aug. 2009; Information Technology Biometric Presentation Attack Detection Part 1: Framework, Standard ISO/IEC JTC1 SC37 Biometrics, ISO/IEC 30107-1, International Organization for Standardization and International Electrotechnical Committee, 2016; Information Technology Criteria and Methodology for Security Evalua-tion of Biometric Systems Part 1: Framework, Standard ISO/IEC FDIS 19989-1, ISO/IEC JTC1 SC27 Information Security, Cybersecurity and Privacy Protection, International Organization for Standardization and International Electrotechnical Committee, 2020; Dantcheva, A., Chen, C., Ross, A., Can facial cosmetics affect the matching accuracy of face recognition systems? (2012) Proc. IEEE 5th Int. Conf. Biometrics Theory, Appl. Syst. (BTAS), pp. 391-398. , Sep; Rathgeb, C., Dantcheva, A., Busch, C., Impact and detection of facial beautification in face recognition: An overview (2019) IEEE Access, 7, pp. 152667-152678. , Oct; Harvey, A., (2010) Computer Vision Dazzle Camoufiage, , https://cvdazzle.com/, Accessed: Oct. 2020; Chen, C., Dantcheva, A., Swearingen, T., Ross, A., Spoofing faces using makeup: An investigative study (2017) Proc. IEEE Int. Conf. Identity, Secur. Behav. Anal. (ISBA), pp. 1-8. , Feb; http://www.tabularasa-euproject.org/events/tabularasa-Spoofing-challenge, (2013). TABULA RASA Spoofing Challenge in Conjunction With the 6th International Conference of Biometrics (ICB 2013). Accessed: Oct. 2020; Wang, T.Y., Kumar, A., Recognizing human faces under disguise and makeup (2016) Proc. IEEE Int. Conf. IdentitySecur. Behav. Anal. (ISBA), pp. 1-7. , Feb; Singh, M., Singh, R., Vatsa, M., Ratha, N.K., Chellappa, R., Recognizing disguised faces in the wild (2019) IEEE Trans. Biometrics, Behav., Identity Sci., 1 (2), pp. 97-108. , Apr; Singh, M., Chawla, M., Singh, R., Vatsa, M., Chellappa, R., Disguised faces in the wild 2019 (2019) Proc. IEEE/CVF Int. Conf. Comput. Vis. Workshop (ICCVW), pp. 542-550. , Oct; Kotwal, K., Mostaani, Z., Marcel, S., Detection of age-induced makeup attacks on face recognition systems using multi-layer deep features (2019) Trans. Biometrics, Behav., Identity Sci., 2 (1), pp. 15-25. , Oct; Liu, Y., Stehouwer, J., Jourabloo, A., Liu, X., Deep tree learning for zero-shot face anti-Spoofing (2019) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 4675-4684. , Jun; Rathgeb, C., Drozdowski, P., Fischer, D., Busch, C., Vulnerability assessment and detection of makeup presentation attacks (2020) Proc. Int. Workshop Biometrics Forensics (IWBF), pp. 1-6. , Apr; Rathgeb, C., Drozdowski, P., Busch, C., (2020) Detection of Makeup Presentation Attacks Based on Deep Face Representations, , http://arxiv.org/abs/2006.05074; Arab, M.A., Azadi Moghadam, P., Hussein, M., Abd-Almageed, W., Hefeeda, M., Revealing true identity: Detecting makeup attacks in facebased biometric systems (2020) Proc. 28th Acm Int. Conf. Multimedia, pp. 3568-3576. , Oct; https://www.ft.com/content/4721ed6a-f797-11e5-96db-fc683b5e52db, Cosmetics Europe. (May 2018). Socio-Economic Contribution of the European Cosmetics Industry. Accessed: Oct. 2020; Whipp, L., Changing Face of Cosmetics Alters $63bn Us Beauty Market, , https://www.ft.com/content/4721ed6a-f797-11e5-96db-fc683b5e52db, Accessed: Oct. 2020. Apr. 2016; Ericson, L., Overview of the odin program on presentation attack detection (2018) Proc. Int. Face Perform. Conf. (IFPC); Information Technology Biometric Presentation Attack Detection Part 3: Testing and Reporting, Standard ISO/IEC JTC1 SC37 Biometrics, ISO/IEC 30107-3, International Organization for Standardization and International Electrotechnical Committee, Sep. 2017; http://antitza.com/makeup-datasets.html, (2017). Makeup Induced Face Spoofing (MIFS). Accessed: Oct. 2020; http://iab-rubric.org/DFW/2019Competition.html, (2019). Disguised Faces in theWild (DFW). Accessed: Oct. 2020; Liu, A., Wan, J., Escalera, S., Escalante, H.J., Tan, Z., Yuan, Q., Wang, K., Li, S.Z., Multi-modal face anti-Spoofing attack detection challenge at CVPR2019 (2019) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. Workshops (CVPRW), pp. 1601-1610. , Jun; Eckert, M.-L., Kose, N., Dugelay, J.-L., Facial cosmetics database and impact analysis on automatic face recognition (2013) Proc. IEEE 15th Int. Workshop Multimedia Signal Process. (MMSP), pp. 434-439. , Sep; Ueda, S., Koyama, T., Influence of make-up on facial recognition (2010) Perception, 39 (2), pp. 260-264. , Feb; Moeini, A., Moeini, H., Ayatollahi, F., Faez, K., Makeup-invariant face recognition by 3D face: Modeling and dual-tree complex wavelet transform from Women's 2D real-world images (2014) Proc. 22nd Int. Conf. Pattern Recognit. (ICPR), pp. 1710-1715. , Aug; Kose, N., Apvrille, L., Dugelay, J.-L., Facial makeup detection technique based on texture and shape analysis (2015) Proc. 11th IEEE Int. Conf. Workshops Autom. Face Gesture Recognit. (FG), 1, pp. 1-7. , May; Chen, C., Dantcheva, A., Ross, A., An ensemble of patch-based subspaces for makeup-robust face recognition (2016) Inf. Fusion, 32, pp. 80-92. , Nov; Zhang, K., Chang, Y.-L., Hsu, W., Deep disguised faces recognition (2018) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. Workshops (CVPRW), pp. 32-324. , Jun; Kohli, N., Yadav, D., Noore, A., Face verification with disguise variations via deep disguise recognizer (2018) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. Workshops (CVPRW), pp. 17-24. , Jun; Feng, R., Prabhakaran, B., Quantifying the makeup effect in female faces and its applications for age estimation (2012) Proc. IEEE Int. Symp. Multimedia (ISM), pp. 108-115. , Dec; Chen, C., Dantcheva, A., Ross, A., Automatic facial makeup detection with application in face recognition (2013) Proc. Int. Conf. Biometrics (ICB), pp. 1-8. , Jun; Guo, G., Wen, L., Yan, S., Face authentication with makeup changes (2014) IEEE Trans. Circuits Syst. Video Technol., 24 (5), pp. 814-825. , May; Wang, S., Fu, Y., Face behind makeup (2016) Proc. Conf. Artif. Intell., pp. 58-64. , Feb; Zhu, Z.-A., Lu, Y.-Z., Chiang, C.-K., Generating adversarial examples by makeup attacks on face recognition (2019) Proc. IEEE Int. Conf. Image Process. (ICIP), pp. 2516-2520. , Sep; https://www4.comp.polyu.edu.hk/csajaykr/DMFaces.htm, (2016). The Hong Kong Polytechnic University Disguise and Makeup Faces Database (DMFaces). Accessed: Oct. 2020; https://www.idiap.ch/dataset/aim, (2016). Age Induced Makeup (AIM). Accessed: Oct. 2020; http://cvlab.cse.msu.edu/siwm-spoof-in-The-wild-with-multiple-attacks-database.html, (2019). Spoofing in the Wild With Multiple Attacks Database (SiW-M). Accessed: Nov. 2020; Scherhag, U., Rathgeb, C., Merkle, J., Busch, C., Deep face representations for differential morphing attack detection (2020) IEEE Trans. Inf. Forensics Security, 15, pp. 3625-3639; Rathgeb, C., Satnoianu, C.-I., Haryanto, N.E., Bernardo, K., Busch, C., Differential detection of facial retouching: A multi-biometric approach (2020) IEEE Access, 8, pp. 106373-106385. , Jun; Scherhag, U., Rathgeb, C., Busch, C., Towards detection of morphed face images in electronic travel documents (2018) Proc. 13th Iapr Int. Workshop Document Anal. Syst. (DAS), pp. 187-192. , Apr; Glasbey, C.A., Mardia, K.V., A review of image-warping methods (1998) J. Appl. Statist., 25 (2), pp. 155-171. , Apr; Chang, H., Lu, J., Yu, F., Finkelstein, A., PairedCycleGAN: Asymmetric style transfer for applying and removing makeup (2018) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 40-48. , Jun; Li, T., Qian, R., Dong, C., Liu, S., Yan, Q., Zhu, W., Lin, L., BeautyGAN: Instance-level facial makeup transfer with deep generative adversarial network (2018) Proc. Int. Conf. Multimedia (MM), pp. 645-653. , Oct; King, D.E., Dlib-ml: A machine learning toolkit (2009) J. Mach. Learn. Res., 10, pp. 1755-1758. , Dec; Kazemi, V., Sullivan, J., One millisecond face alignment with an ensemble of regression trees (2014) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 1867-1874. , Jun; Ren, S., Cao, X., Wei, Y., Sun, J., Face alignment at 3000 FPS via regressing local binary features (2014) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 1685-1692. , Jun; Parkhi, O.M., Vedaldi, A., Zisserman, A., Deep face recognition (2015) Proc. Brit. Mach. Vis. Conf. (BMVC), pp. 1-6. , Sep; Deng, J., Guo, J., Xue, N., Zafeiriou, S., ArcFace: Additive angular margin loss for deep face recognition (2019) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 4690-4699. , Jun; Huang, G., Liu, Z., Maaten Der, L.Van, Weinberger, K.Q., Densely connected convolutional networks (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 2261-2269. , Jul; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 770-778. , Jun; Ahonen, T., Hadid, A., Pietikäinen, M., Face recognition with local binary patterns (2004) Proc. Eur. Conf. Comput. Vis. (ECCV). Berlin, pp. 469-481. , Germany: Springer, May; Kannala, J., Rahtu, E., BSIF: Binarized statistical image features (2012) Proc. Int. Conf. Pattern Recognit. (ICPR), pp. 1363-1366. , Nov; Zhang, H., (2020) BeautyGAN: Instance-Level Facial Makeup Transfer with Deep Generative Adversarial Network, , https://github.com/Honlan/BeautyGAN, Accessed: Oct; Pedregosa, F., Varoquaux, G., Thirion, B., Dubourg, V., Passos, A., Pedregosa, V., Gramfort, A., Perrot, M., Scikit-learn: Machine learning in python (2011) J. Mach. Learn. Res., 12 (85), pp. 2825-2830. , Nov; Liu, Z., Luo, P., Wang, X., Tang, X., Deep learning face attributes in the wild (2015) Proc. IEEE Int. Conf. Comput. Vis. (ICCV), pp. 3730-3738. , Dec; Hernandez-Ortega, J., Galbally, J., Fiérrez, J., Haraksim, R., Beslay, L., FaceQnet: Quality assessment for face recognition based on deep learning (2019) Proc. Int. Conf. Biometrics (ICB), pp. 1-8. , Jun; Phillips, P.J., Flynn, P.J., Scruggs, T., Bowyer, K.W., Chang, J., Hoffman, K., Marques, J., Worek, W., Overviewof the face recognition grand challenge (2005) Proc. Conf. Comput. Vis. Pattern Recognit. (CVPR), 1, pp. 947-954. , Jun; Information Technology Biometric Performance Testing and Reporting Part 1: Principles and Framework, Standard ISO/IEC JTC1 SC37 Biometrics, ISO/IEC 19795-1:2006, International Organization for Standardization and International Electrotechnical Committee, Apr. 2006; Scherhag, U., Nautsch, A., Rathgeb, C., Gomez-Barrero, M., Veldhuis, R.N.J., Spreeuwers, L., Schils, M., Busch, C., Biometric systems under morphing attacks: Assessment of morphing techniques and vulnerability reporting (2017) Proc. Int. Conf. Biometrics Special Interest Group (BIOSIG), pp. 1-7. , Sep; Best practice technical guidelines for automated border control ABC systems (2015) Eur. Agency Manage. Oper. Cooperation External Borders Member States Eur. Union, Brussels, Belgium, Tech. Rep. TT-02-16-152-EN-N, , Sep. Research Development Unit; Feng, Y., Wu, F., Shao, X., Wang, Y., Zhou, X., Joint 3D face reconstruction and dense alignment with position map regression network (2018) Proc. Eur. Conf. Comput. Vis. (ECCV). Cham, pp. 534-551. , Switzerland: Springer, Sep; Galbally, J., Marcel, S., Fierrez, J., Image quality assessment for fake biometric detection: Application to iris, fingerprint, and face recognition (2014) IEEE Trans. Image Process., 23 (2), pp. 710-724. , Feb; Mittal, A., Moorthy, A.K., Bovik, A.C., No-reference image quality assessment in the spatial domain (2012) IEEE Trans. Image Process., 21 (12), pp. 4695-4708. , Dec; Maaten Der, L.Van, Hinton, G., Visualizing data using t-SNE (2008) J. Mach. Learn. Res., 9, pp. 2579-2605. , Nov; https://www.csmonitor.com/1996/1107/110796.feat._lm.1.html, The Christian Science Monitor. (1996). In Associate, ' Whoopi Shatters Glass Ceiling. Accessed: Oct. 2020; https://www.nist.gov/itl/iad/image-group/resources/biometrics-evaluations, National Institute of Standards and Technology. Biometric Evalua-tions Homepage. Accessed: Oct. 2020; Drozdowski, P., Rathgeb, C., Dantcheva, A., Damer, N., Busch, C., Demographic bias in biometrics: A survey on an emerging challenge (2020) IEEE Trans. Technol. Soc., 1 (2), pp. 89-103. , Jun","Rathgeb, C.; Da/sec - Biometrics and Internet-Security Research Group, Germany; 电子邮件: christian.rathgeb@h-da.de",,,Institute of Electrical and Electronics Engineers Inc.,,,,,21693536,,,,English,IEEE Access,Review,Final,"All Open Access, Gold",Scopus,2-s2.0-85098571987
"Yang P., Chen J., Hsieh C.-J., Wang J.-L., Jordan M.I.",57216280377;57201908340;24502954900;35239020400;57209168184;,ML-LOO: Detecting adversarial examples with feature attribution,2020,AAAI 2020 - 34th AAAI Conference on Artificial Intelligence,,,,6639,6647,,10,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098440942&partnerID=40&md5=6a22d740323e1de21b76f6c986be6201,"University of California, Davis, United States; University of California, Berkeley, United States; University of California, Los Angeles, United States","Yang, P., University of California, Davis, United States; Chen, J., University of California, Berkeley, United States; Hsieh, C.-J., University of California, Los Angeles, United States; Wang, J.-L., University of California, Davis, United States; Jordan, M.I., University of California, Berkeley, United States","Deep neural networks obtain state-of-the-art performance on a series of tasks. However, they are easily fooled by adding a small adversarial perturbation to the input. The perturbation is often imperceptible to humans on image data. We observe a significant difference in feature attributions between adversarially crafted examples and original examples. Based on this observation, we introduce a new framework to detect adversarial examples through thresholding a scale estimate of feature attribution scores. Furthermore, we extend our method to include multi-layer feature attributions in order to tackle attacks that have mixed confidence levels. As demonstrated in extensive experiments, our method achieves superior performances in distinguishing adversarial examples from popular attack methods on a variety of real data sets compared to state-of-the-art detection methods. In particular, our method is able to detect adversarial examples of mixed confidence levels, and transfer between different attacking methods. We also show that our method achieves competitive performance even when the attacker has complete access to the detector. Copyright © 2020, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,Deep neural networks; Machine learning; Attack methods; Competitive performance; Confidence levels; Detection methods; Real data sets; State of the art; State-of-the-art performance; Thresholding; Feature extraction,,,,,"Athalye, A., Carlini, N., Wagner, D., Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples (2018) ICML, pp. 274-283; Bach, S., Binder, A., Montavon, G., Klauschen, F., Müller, K.-R., Samek, W., On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation (2015) PloS One, 10 (7), p. e0130140; Bhagoji, A. N., Cullina, D., Sitawarin, C., Mittal, P., Enhancing robustness of machine learning systems via data transformations (2018) CISS, pp. 1-5. , and, IEEE; Brendel, W., Rauber, J., Bethge, M., Decision-based adversarial attacks: Reliable attacks against black-box machine learning models (2018) ICLR; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) AISec, pp. 3-14. , a ACM; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE SP, pp. 39-57. , b IEEE; Chalasani, P., Jha, S., Sadagopan, A., Wu, X., (2018) Adversarial learning and explainability in structured datasets, , arXiv preprint arXiv:1810.06583; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) AISec, pp. 15-26. , ACM; Chen, J., Song, L., Wainwright, M. J., Jordan, M. I., Lshapley and C-shapley: Efficient model interpretation for structured data (2019) ICLR; Chollet, F., (2015) Keras, , https://github.com/fchollet/keras; Datta, A., Sen, S., Zick, Y., Algorithmic transparency via quantitative input influence: Theory and experiments with learning systems (2016) IEEE SP, pp. 598-617. , IEEE; Dvijotham, K., Gowal, S., Stanforth, R., Arandjelovic, R., O’Donoghue, B., Uesato, J., Kohli, P., (2018) Training verified learners with learned verifiers, , arXiv preprint arXiv:1805.10265; Fawzi, A., Fawzi, O., Frossard, P., Analysis of classifiers’ robustness to adversarial perturbations (2018) Machine Learning, 107 (3), pp. 481-508; Feinman, R., Curtin, R. R., Shintre, S., Gardner, A. B., (2017) Detecting adversarial samples from artifacts, , arXiv preprint arXiv:1703.00410; Ghorbani, A., Abid, A., Zou, J., (2017) Interpretation of neural networks is fragile, , arXiv preprint arXiv:1710.10547; Gong, Z., Wang, W., Ku, W.-S., (2017) Adversarial and clean data are not twins, , arXiv preprint arXiv:1704.04960; Goodfellow, I., Papernot, N., Huang, S., Duan, Y., Abbeel, P., (2017) Attacking machine learning with adversarial examples, , https://blog.openai.com/adversarial-example-research/; Goodfellow, I. J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR; Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., (2017) On the (statistical) detection of adversarial examples, , arXiv preprint arXiv:1702.06280; He, K., Zhang, X., Ren, S., Sun, J., Identity mappings in deep residual networks (2016) ECCV, pp. 630-645. , Springer; Hendrycks, D., Gimpel, K., Early methods for detecting adversarial images (2017) ICLR; Huang, G., Liu, Z., Van Der Maaten, L., Weinberger, K. Q., Densely connected convolutional networks (2017) CVPR, pp. 4700-4708; Ilyas, A., Engstrom, L., Athalye, A., Lin, J., Black-box adversarial attacks with limited queries and information (2018) ICML, pp. 2142-2151; Ilyas, A., Engstrom, L., Madry, A., Prior convictions: Black-box adversarial attacks with bandits and priors (2019) ICLR; Kingma, D. P., Ba, J., Adam: A method for stochastic optimization (2014) ICLR; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2017) ICLR; Lecuyer, M., Atlidakis, V., Geambasu, R., Hsu, D., Jana, S., Certified robustness to adversarial examples with differential privacy (2019) IEEE SP; Lee, K., Lee, K., Lee, H., Shin, J., A simple unified framework for detecting out-of-distribution samples and adversarial attacks (2018) NeurIPS, pp. 7167-7177; Li, X., Li, F., Adversarial examples detection in deep networks with convolutional filter statistics (2017) ICCV, pp. 5764-5772; Li, J., Monroe, W., Jurafsky, D., (2016) Understanding neural networks through representation erasure, , arXiv preprint arXiv:1612.08220; Liu, X., Hsieh, C.-J., Rob-gan: Generator, discriminator, and adversarial attacker (2019) CVPR; Liu, X., Cheng, M., Zhang, H., Hsieh, C.-J., Towards robust neural networks via random self-ensemble (2018) ECCV, pp. 369-385; Liu, X., Li, Y., Wu, C., Hsieh, C.-J., Adv-bnn: Improved adversarial defense through robust bayesian neural network (2019) ICLR; Lu, P.-H., Chen, P.-Y., Yu, C.-M., (2018) On the limitation of local intrinsic dimensionality for characterizing the subspaces of adversarial examples, , arXiv preprint arXiv:1803.09638; Lundberg, S. M., Lee, S.-I., A unified approach to interpreting model predictions (2017) NeurIPS, pp. 4765-4774; Ma, X., Li, B., Wang, Y., Erfani, S. M., Wijewickrema, S., Schoenebeck, G., Houle, M. E., Bailey, J., Characterizing adversarial subspaces using local intrinsic dimensionality (2018) ICLR; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) ICLR; Metzen, J. H., Genewein, T., Fischer, V., Bischoff, B., On detecting adversarial perturbations (2017) ICLR; Miyato, T., Maeda, S.-I., Koyama, M., Nakae, K., Ishii, S., Distributional smoothing with virtual adversarial training (2016) ICLR; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deep-fool: a simple and accurate method to fool deep neural networks (2016) CVPR, pp. 2574-2582; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z. B., Swami, A., The limitations of deep learning in adversarial settings (2016) EuroS&P, pp. 372-387. , a IEEE; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) IEEE SP, pp. 582-597. , b IEEE; Ribeiro, M. T., Singh, S., Guestrin, C., Why should I trust you?: Explaining the predictions of any classifier (2016) SIGKDD, pp. 1135-1144. , ACM; Royston, J., Algorithm as 177: Expected normal order statistics (exact and approximate) (1982) Journal of the royal statistical society. Series C (Applied statistics), 31 (2), pp. 161-165; Schmidt, L., Santurkar, S., Tsipras, D., Talwar, K., Madry, A., Adversarially robust generalization requires more data (2018) NeurIPS, pp. 5019-5031; Shrikumar, A., Greenside, P., Kundaje, A., Learning important features through propagating activation differences (2017) ICML, 70, pp. 3145-3153. , of PMLR, PMLR; Simonyan, K., Vedaldi, A., Zisserman, A., (2013) Deep inside convolutional networks: Visualising image classification models and saliency maps, , arXiv preprint arXiv:1312.6034; Song, Y., Kim, T., Nowozin, S., Ermon, S., Kushman, N., Pixeldefend: Leveraging generative models to understand and defend against adversarial examples (2018) ICLR; Sundararajan, M., Taly, A., Yan, Q., Axiomatic attribution for deep networks (2017) ICML, pp. 3319-3328; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) ICLR; Tanay, T., Griffin, L., (2016) A boundary tilting persepective on the phenomenon of adversarial examples, , arXiv preprint arXiv:1608.07690; Tao, G., Ma, S., Liu, Y., Zhang, X., Attacks meet interpretability: Attribute-steered detection of adversarial samples (2018) NeurIPS, pp. 7728-7739; Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2018) ICLR; Tsipras, D., Santurkar, S., Engstrom, L., Turner, A., Madry, A., (2018) There is no free lunch in adversarial robustness (but there are unexpected benefits), , arXiv preprint arXiv:1805.12152; Wong, E., Kolter, J. Z., Provable defenses against adversarial examples via the convex outer adversarial polytope (2018) ICML; Xu, W., Evans, D., Qi, Y., Feature squeezing: Detecting adversarial examples in deep neural networks (2018) NDSS; Yeh, C.-K., Hsieh, C.-Y., Suggala, A. S., Inouye, D., Ravikumar, P., (2019) How sensitive are sensitivity-based explanations?, , arXiv preprint arXiv:1901.09392; Zeiler, M. D., Fergus, R., Visualizing and understanding convolutional networks (2014) ECCV, pp. 818-833. , Springer; Zhang, C., Ye, Z., Wang, Y., Yang, Z., Detecting adversarial perturbations with saliency (2018) ICSIP, pp. 271-275. , IEEE",,,Association for the Advancement of Artificial Intelligence,AAAI press,"34th AAAI Conference on Artificial Intelligence, AAAI 2020",7 February 2020 through 12 February 2020,,166426,,9.78E+12,,,English,AAAI - AAAI Conf. Artif. Intell.,Conference Paper,Final,,Scopus,2-s2.0-85098440942
"Che Z., Borji A., Zhai G., Ling S., Li J., Min X., Guo G., Callet P.L.",57022192800;23395793600;15847120000;57193346540;51461432900;56030205300;7402768270;57203923621;,SMGEA: A New Ensemble Adversarial Attack Powered by Long-Term Gradient Memories,2020,IEEE Transactions on Neural Networks and Learning Systems,,,,,,,1,10.1109/TNNLS.2020.3039295,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097952631&doi=10.1109%2fTNNLS.2020.3039295&partnerID=40&md5=c5dcebc9e0e09b4a5dc53e039fa00c44,"Shanghai Key Laboratory of Digital Media Processing and Transmissions, Institute of Image Communication and Network Engineering, Shanghai Jiao Tong University, Shanghai 200240, China.; MarkableAI Inc., Brooklyn, NY 11201 USA.; Shanghai Key Laboratory of Digital Media Processing and Transmissions, Institute of Image Communication and Network Engineering, Shanghai Jiao Tong University, Shanghai 200240, China (e-mail: zhaiguangtao@sjtu.edu.cn); Suiyi Ling and Patrick Le Callet are with the&#x00C9;quipe Image, Perception et Interaction, Laboratoire des Sciences du Num&#x00E9;rique de Nantes, Universit&#x00E9; de Nantes, 44035 Nantes, France.; Alibaba Group, Beijing 100020, China.; Institute of Deep Learning, Baidu Research, Beijing 100085, China, and also with the National Engineering Laboratory for Deep Learning Technology and Application, Beijing 100085, China.","Che, Z., Shanghai Key Laboratory of Digital Media Processing and Transmissions, Institute of Image Communication and Network Engineering, Shanghai Jiao Tong University, Shanghai 200240, China.; Borji, A., MarkableAI Inc., Brooklyn, NY 11201 USA.; Zhai, G., Shanghai Key Laboratory of Digital Media Processing and Transmissions, Institute of Image Communication and Network Engineering, Shanghai Jiao Tong University, Shanghai 200240, China (e-mail: zhaiguangtao@sjtu.edu.cn); Ling, S., Suiyi Ling and Patrick Le Callet are with the&#x00C9;quipe Image, Perception et Interaction, Laboratoire des Sciences du Num&#x00E9;rique de Nantes, Universit&#x00E9; de Nantes, 44035 Nantes, France.; Li, J., Alibaba Group, Beijing 100020, China.; Min, X., Shanghai Key Laboratory of Digital Media Processing and Transmissions, Institute of Image Communication and Network Engineering, Shanghai Jiao Tong University, Shanghai 200240, China.; Guo, G., Institute of Deep Learning, Baidu Research, Beijing 100085, China, and also with the National Engineering Laboratory for Deep Learning Technology and Application, Beijing 100085, China.; Callet, P.L., Suiyi Ling and Patrick Le Callet are with the&#x00C9;quipe Image, Perception et Interaction, Laboratoire des Sciences du Num&#x00E9;rique de Nantes, Universit&#x00E9; de Nantes, 44035 Nantes, France.","Deep neural networks are vulnerable to adversarial attacks. More importantly, some adversarial examples crafted against an ensemble of source models transfer to other target models and, thus, pose a security threat to black-box applications (when attackers have no access to the target models). Current transfer-based ensemble attacks, however, only consider a limited number of source models to craft an adversarial example and, thus, obtain poor transferability. Besides, recent query-based black-box attacks, which require numerous queries to the target model, not only come under suspicion by the target model but also cause expensive query cost. In this article, we propose a novel transfer-based black-box attack, dubbed serial-minigroup-ensemble-attack (SMGEA). Concretely, SMGEA first divides a large number of pretrained white-box source models into several ``minigroups.'' For each minigroup, we design three new ensemble strategies to improve the intragroup transferability. Moreover, we propose a new algorithm that recursively accumulates the ``long-term'' gradient memories of the previous minigroup to the subsequent minigroup. This way, the learned adversarial information can be preserved, and the intergroup transferability can be improved. Experiments indicate that SMGEA not only achieves state-of-the-art black-box attack ability over several data sets but also deceives two online black-box saliency prediction systems in real world, i.e., DeepGaze-II (https://deepgaze.bethgelab.org/) and SALICON (http://salicon.net/demo/). Finally, we contribute a new code repository to promote research on adversarial attack and defense over ubiquitous pixel-to-pixel computer vision tasks. We share our code together with the pretrained substitute model zoo at https://github.com/CZHQuality/AAA-Pix2pix. IEEE",Adversarial attack; gradient descent.,HTTP; Online systems; Pixels; Current transfer; Ensemble strategies; Number of sources; Prediction systems; Security threats; Source models; State of the art; Target model; Deep neural networks,,,,,,,,,Institute of Electrical and Electronics Engineers Inc.,,,,,2162237X,,,,English,IEEE Trans. Neural Networks Learn. Sys.,Article,Article in Press,,Scopus,2-s2.0-85097952631
"Li Y., Bai S., Xie C., Liao Z., Shen X., Yuille A.",57211277832;57206839797;57200616617;57219508381;7402721428;7006372632;,Regional Homogeneity: Towards Learning Transferable Universal Adversarial Perturbations Against Defenses,2020,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),12356 LNCS,,,795,813,,2,10.1007/978-3-030-58621-8_46,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097640375&doi=10.1007%2f978-3-030-58621-8_46&partnerID=40&md5=9b850162fd9ef26ee441a1e530c2215a,"Johns Hopkins University, Baltimore, United States; University of Oxford, Oxford, United Kingdom; Kuaishou Technology, Palo Alto, United States; ByteDance Research, Mountain View, United States","Li, Y., Johns Hopkins University, Baltimore, United States; Bai, S., University of Oxford, Oxford, United Kingdom; Xie, C., Johns Hopkins University, Baltimore, United States; Liao, Z., Kuaishou Technology, Palo Alto, United States; Shen, X., ByteDance Research, Mountain View, United States; Yuille, A., Johns Hopkins University, Baltimore, United States","This paper focuses on learning transferable adversarial examples specifically against defense models (models to defense adversarial attacks). In particular, we show that a simple universal perturbation can fool a series of state-of-the-art defenses. Adversarial examples generated by existing attacks are generally hard to transfer to defense models. We observe the property of regional homogeneity in adversarial perturbations and suggest that the defenses are less robust to regionally homogeneous perturbations. Therefore, we propose an effective transforming paradigm and a customized gradient transformer module to transform existing perturbations into regionally homogeneous ones. Without explicitly forcing the perturbations to be universal, we observe that a well-trained gradient transformer module tends to output input-independent gradients (hence universal) benefiting from the under-fitting phenomenon. Thorough experiments demonstrate that our work significantly outperforms the prior art attacking algorithms (either image-dependent or universal ones) by an average improvement of 14.0% when attacking 9 defenses in the transfer-based attack setting. In addition to the cross-model transferability, we also verify that regionally homogeneous perturbations can well transfer across different vision tasks (attacking with the semantic segmentation task and testing on the object detection task). The code is available here: https://github.com/LiYingwei/Regional-Homogeneity. © 2020, Springer Nature Switzerland AG.",Transferable adversarial example; Universal attack,Image enhancement; Network security; Object detection; Semantics; Well testing; Cross model; Prior arts; Regional homogeneity; Semantic segmentation; State of the art; Computer vision,,,,,"Akhtar, N., Liu, J., Mian, A., Defense against universal adversarial perturbations (2018) CVPR; Ba, J.L., Kiros, J.R., Hinton, G.E., (2016) Layer Normalization; Bai, S., Li, Y., Zhou, Y., Li, Q., Torr, P.H., (2019) Metric Attack and Defense for Person Re-Identification; Baluja, S., Fischer, I., (2018) Learning to Attack: Adversarial Transformation Networks, , AAAI; Bhagoji, A.N., He, W., Li, B., Song, D., Practical black-box attacks on deep neural networks using efficient query mechanisms (2018) ECCV 2018. LNCS, 11216, pp. 158-174. , Ferrari, V., Hebert, M., Sminchisescu, C., Weiss, Y. (eds.), pp., Springer, Cham, https://doi.org/10.1007/978-3-030-01258-8 10; Bishop, C.M., The bias-variance decomposition (2006) Pattern Recognition and Machine Learning, pp. 147-152. , pp., Springer, Heidelberg; Borkar, T., Heide, F., Karam, L., Defending against universal attacks through selective feature regeneration (2020) CVPR; Brendel, W., Rauber, J., Bethge, M., (2018) Decision-Based Adversarial Attacks: Reliable Attacks against Black-Box Machine Learning Models, , ICLR; Cao, Y., Adversarial sensor attack on lidar-based perception in autonomous driving (2019) ACM SIGSAC CCS; Chen, L.-C., Zhu, Y., Papandreou, G., Schroff, F., Adam, H., Encoder-decoder with Atrous separable convolution for semantic image segmentation (2018) ECCV 2018. LNCS, 11211, pp. 833-851. , Ferrari, V., Hebert, M., Sminchisescu, C., Weiss, Y. (eds.), pp., Springer, Cham, https://doi.org/10.1007/978-3-030-01234-2 49; Chen, P.Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.J., ZOO: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) Proceedings of the 10Th ACM Workshop on Artificial Intelligence and Security; Chen, X., Liu, C., Li, B., Lu, K., Song, D., (2017) Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning; Chollet, F., Xception: Deep learning with depthwise separable convolutions (2017) ICCV; Das, N., SHIELD: Fast, practical defense and vaccination for deep learning using JPEG compression (2018) KDD. ACM; Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L., (2009) Imagenet: A Large-Scale Hierarchical Image Database, , CVPR; Dong, Y., (2018) Boosting Adversarial Attacks with Momentum, , CVPR; Dong, Y., Pang, T., Su, H., Zhu, J., Evading defenses to transferable adversarial examples by translation-invariant attacks (2019) CVPR; Dziugaite, G.K., Ghahramani, Z., Roy, D.M., (2016) A Study of the Effect of JPG Compression on Adversarial Images; Everingham, M., Eslami, S.A., van Gool, L., Williams, C.K., Winn, J., Zisserman, A., The pascal visual object classes challenge: A retrospective (2015) IJCV, 111 (1), pp. 98-136; Eykholt, K., (2018) Robust Physical-World Attacks on Deep Learning Visual Classification, , CVPR; Gao, L., Zhang, Q., Song, J., Liu, X., Shen, H.T., (2020) Patch-Wise Attack for Fooling Deep Neural Network; Goodfellow, I., Bengio, Y., Courville, A., (2016) Deep Learning, , MIT Press, Cambridge; Goodfellow, I.J., Shlens, J., Szegedy, C., (2015) Explaining and Harnessing Adversarial Examples, , ICLR; Goyal, P., (2017) Accurate, Large Minibatch SGD: Training Imagenet in 1 Hour; Guo, C., Frank, J.S., Weinberger, K.Q., (2018) Low Frequency Adversarial Perturbation; Guo, C., Rana, M., Cissé, M., van der Maaten, L., (2018) Countering Adversarial Images Using Input Transformations, , ICLR; Haykin, S.S., Finite sample-size considerations (2009) Neural Networks and Learning Machines, pp. 82-86. , vol. 3, pp.,. Pearson Upper Saddle River; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) CVPR; Hendrik Metzen, J., Chaithanya Kumar, M., Brox, T., Fischer, V., Universal adversarial perturbations against semantic image segmentation (2017) ICCV; Huang, L., (2020) Universal Physical Camouflage Attacks on Object Detectors, , CVPR; Ioffe, S., Szegedy, C., (2015) Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift, , ICML; Jia, R., Konstantakopoulos, I.C., Li, B., Spanos, C., Poisoning attacks on data-driven utility learning in games (2018) ACC; Jin, W., Li, Y., Xu, H., Wang, Y., Tang, J., (2020) Adversarial Attacks and Defenses on Graphs: A Review and Empirical Study; Jin, W., Ma, Y., Liu, X., Tang, X., Wang, S., Tang, J., (2020) Graph Structure Learning for Robust Graph Neural Networks; Kannan, H., Kurakin, A., Goodfellow, I., (2018) Adversarial Logit Pairing; Khrulkov, V., Oseledets, I., Art of singular vectors and universal adversarial perturbations (2018) CVPR; Kingma, D.P., Ba, J., (2014) Adam: A Method for Stochastic Optimization; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2017) ICLR Workshop; Kurakin, A., (2018) Adversarial Attacks and Defences Competition; Li, Y., Bai, S., Zhou, Y., Xie, C., Zhang, Z., Yuille, A., Learning transferable adversarial examples via ghost networks (2020) AAAI; Li, Y., et al.: Volumetric medical image segmentation: a 3D deep coarse-to-fine framework and its adversarial examples. In: Lu, L., Wang, X., Carneiro, G., Yang, L. (eds.) Deep Learning and Convolutional Neural Networks for Medical Imaging and Clinical Informatics. ACVPR, pp. 69–91. Springer, Cham (2019). https://doi. org/10.1007/978-3-030-13969-8 4; Liao, F., Liang, M., Dong, Y., Pang, T., Hu, X., Zhu, J., Defense against adversarial attacks using high-level representation guided denoiser (2018) CVPR; Lin, T.-Y., et al.: Microsoft COCO: common objects in context. In: Fleet, D., Pajdla, T., Schiele, B., Tuytelaars, T. (eds.) ECCV 2014. LNCS, vol. 8693, pp. 740–755. Springer, Cham (2014). https://doi.org/10.1007/978-3-319-10602-1 48; Liu, L., Deep neural network ensembles against deception: Ensemble diversity, accuracy and robustness (2019) 2019 IEEE 16Th International Conference on Mobile Ad Hoc and Sensor Systems (MASS), pp. 274-282. , pp., IEEE; Liu, X., Cheng, M., Zhang, H., Hsieh, C.-J.: Towards robust neural networks via random self-ensemble. In: Ferrari, V., Hebert, M., Sminchisescu, C., Weiss, Y. (eds.) ECCV 2018. LNCS, vol. 11211, pp. 381–397. Springer, Cham (2018). https://doi. org/10.1007/978-3-030-01234-2 23; Liu, Y., Chen, X., Liu, C., Song, D., (2017) Delving into Transferable Adversarial Examples and Black-Box Attacks, , ICLR; Ma, X., (2018) Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality, , ICLR; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2018) Towards Deep Learning Models Resistant to Adversarial Attacks, , ICLR; Mao, X., Chen, Y., Li, Y., He, Y., Xue, H., (2020) GAP++: Learning to Generate Target-Conditioned Adversarial Examples; Moosavi-Dezfooli, S.M., Fawzi, A., Fawzi, O., Frossard, P., (2017) Universal Adversarial Perturbations, , CVPR; Mopuri, K.R., Garg, U., Babu, R.V., Fast feature fool: A data independent approach to universal adversarial perturbations (2017) BMVC; Naseer, M.M., Khan, S.H., Khan, M.H., Khan, F.S., Porikli, F., Cross-domain transferability of adversarial perturbations (2019) Advances in Neural Information Processing Systems, pp. 12905-12915. , pp; Poursaeed, O., Jiang, T., Yang, H., Belongie, S., Lim, S.N., (2019) Fine-Grained Synthesis of Unrestricted Adversarial Examples; Poursaeed, O., Katsman, I., Gao, B., Belongie, S., (2017) Generative Adversarial Perturbations, , CVPR; Qiu, H., Xiao, C., Yang, L., Yan, X., Lee, H., Li, B., (2019) Semanticadv: Generating Adversarial Examples via Attribute-Conditional Image Editing; Ren, S., He, K., Girshick, R., Sun, J., (2015) Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks, , NeurIPS; Roth, H.R., et al.: DeepOrgan: multi-level deep convolutional networks for automated pancreas segmentation. In: Navab, N., Hornegger, J., Wells, W.M., Frangi, A.F. (eds.) MICCAI 2015. LNCS, vol. 9349, pp. 556–564. Springer, Cham (2015). https://doi.org/10.1007/978-3-319-24553-9 68; Ruder, S., (2017) An Overview of Multi-Task Learning in Deep Neural Networks; Rudin, L.I., Osher, S., Fatemi, E., Nonlinear total variation based noise removal algorithms (1992) Physica D Nonlinear Phenomena, 60 (1-4), pp. 259-268; Shafahi, A., Najibi, M., Xu, Z., Dickerson, J., Davis, L.S., Goldstein, T., Universal adversarial training (2020) AAAI; Simonyan, K., Zisserman, A., (2015) Very Deep Convolutional Networks for Large-Scale Image Recognition, , ICLR; Sun, M., (2018) Data Poisoning Attack against Unsupervised Node Embedding Methods; Sun, Y., Wang, S., Tang, X., Hsieh, T.Y., Honavar, V., Adversarial attacks on graph neural networks via node injections: A hierarchical reinforcement learning approach (2020) Proceedings of the Web Conference 2020, pp. 673-683. , pp; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., Inception-v4, Inception-ResNet and the impact of residual connections on learning (2017) AAAI; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) CVPR; Szegedy, C., (2014) Intriguing Properties of Neural Networks, , ICLR; Tang, X., Li, Y., Sun, Y., Yao, H., Mitra, P., Wang, S., Transferring robustness for graph neural network against poisoning attacks (2020) Proceedings of the 13Th International Conference on Web Search and Data Mining, pp. 600-608. , pp; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., (2018) Ensemble Adversarial Training: Attacks and Defenses, , ICLR; Ulyanov, D., Vedaldi, A., Lempitsky, V., (2016) Instance Normalization: The Missing Ingredient for Fast Stylization; Wu, Y., He, K., Group normalization (2018) ECCV 2018. LNCS, 11217, pp. 3-19. , https://doi.org/10.1007/978-3-030-01261-81, Ferrari, V., Hebert, M., Sminchisescu, C., Weiss, Y. (eds.), pp., Springer, Cham; Xiao, C., Zhong, P., Zheng, C., (2020) Enhancing Adversarial Defense by K-Winners-Take-All, , ICLR; Xiao, C., Li, B., Zhu, J.Y., He, W., Liu, M., Song, D., (2018) Generating Adversarial Examples with Adversarial Networks, p. IJCAI; Xie, C., Tan, M., Gong, B., Yuille, A., Le, Q.V., (2020) Smooth Adversarial Training; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., (2018) Mitigating Adversarial Effects through Randomization, , ICLR; Xie, C., Wu, Y., Maaten, L.V.D., Yuille, A.L., He, K., Feature denoising for improving adversarial robustness (2019) CVPR; Xie, C., Yuille, A., (2020) Intriguing Properties of Adversarial Training at Scale, , ICLR; Xie, C., Zhang, Z., Zhou, Y., Bai, S., Wang, J., Ren, Z., Yuille, A.L., Improving transferability of adversarial examples with input diversity (2019) CVPR; Yang, C., Kortylewski, A., Xie, C., Cao, Y., Yuille, A., (2020) Patchattack: A Black-Box Texture-Based Attack with Reinforcement Learning; Zhang, Z., Zhu, X., Li, Y., Chen, X., Guo, Y., (2020) Adversarial Attacks on Monocular Depth Estimation; Zhou, W., (2018) Transferable Adversarial Perturbations, pp. 471-486. , https://doi.org/10.1007/978-3-030-01264-928, Ferrari, V., Hebert, M., Sminchisescu, C., Weiss, Y. (eds.) Computer Vision – ECCV 2018. LNCS, vol. 11218, pp.,. Springer, Cham","Li, Y.; Johns Hopkins UniversityUnited States; 电子邮件: yingwei.li@jhu.edu",Vedaldi A.Bischof H.Brox T.Frahm J.,,Springer Science and Business Media Deutschland GmbH,"16th European Conference on Computer Vision, ECCV 2020",23 August 2020 through 28 August 2020,,249299,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85097640375
[无可用作者姓名],[无可用的作者 ID],"3rd International Conference on Dynamic Data Driven Application Systems, DDDAS 2020",2020,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),12312 LNCS,,,,,358,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097402504&partnerID=40&md5=c63e82dbd3d5e5ffc442424986abfa40,,,"The proceedings contain 43 papers. The special focus in this conference is on Dynamic Data Driven Application Systems. The topics include: A DDDAS Protocol for Real-Time Large-Scale UAS Flight Coordination; data-Driven State Awareness for Fly-by-Feel Aerial Vehicles via Adaptive Time Series and Gaussian Process Regression Models; preface; predictive Digital Twins: Where Dynamic Data-Driven Learning Meets Physics-Based Modeling; Integrated Planning, Decision-Making, and Weather Modeling for UAS Navigating Complex Weather; Microgrid Operational Planning Using Deviation Clustering Within a DDDAS Framework; dynamic Data-Driven Self-healing Application for Phasor Measurement Unit Networks; interpretable Deep Attention Model for Multivariate Time Series Prediction in Building Energy Systems; overcoming Stealthy Adversarial Attacks on Power Grid Load Predictions Through Dynamic Data Repair; Uncertainty Analysis of Self-healed Composites with Machine Learning as Part of DDDAS; active Search Methods to Predict Material Failure Under Intermittent Loading in the Serebrinksy-Ortiz Fatigue Model; dynamic Data-Driven Distribution Tracking of Nanoparticle Morphology; machine Learning Algorithms for Improved Thermospheric Density Modeling; Dynamic Transfer Learning from Physics-Based Simulated SAR Imagery for Automatic Target Recognition; Dynamic Data-Driven Application Systems for NASA’s Science Mission Directorate; uncertainty Estimation for Semantic Segmentation of Hyperspectral Imagery; Spectral Super Resolution with DCT Decomposition and Deep Residual Learning; active Scene Classification via Dynamically Learning Prototypical Views; informative Ensemble Kalman Learning for Neural Structure; reachability Analysis Based Tracking: Applications to Non-cooperative Space Object Tracking; sparse Regression and Adaptive Feature Generation for the Discovery of Dynamical Systems; improving Prediction Confidence in Learning-Enabled Autonomous Systems; towards Provably Correct Probabilistic Flight Systems; data-Based Defense-in-Depth of Critical Systems.",,,,,,,,,Darema F.Blasch E.Ravela S.Aved A.,,Springer Science and Business Media Deutschland GmbH,"3rd International Conference on Dynamic Data Driven Application Systems, DDDAS 2020",2 October 2020 through 4 October 2020,,251319,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Review,Final,,Scopus,2-s2.0-85097402504
"Guo Q., Xie X., Juefei-Xu F., Ma L., Li Z., Xue W., Feng W., Liu Y.",57191163500;55268560900;54911989900;55479591700;57216832412;57194779872;56471162500;56911879800;,SPARK: Spatial-Aware Online Incremental Attack Against Visual Tracking,2020,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),12370 LNCS,,,202,219,,3,10.1007/978-3-030-58595-2_13,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097372295&doi=10.1007%2f978-3-030-58595-2_13&partnerID=40&md5=bc0cff7675b122799448188fe852b506,"College of Intelligence and Computing, Tianjin University, Tianjin, China; Nanyang Technological University, Singapore, Singapore; Alibaba Group, San Mateo, United States; Kyushu University, Fukuoka, Japan; Tianjin University of Technology, Tianjin, China","Guo, Q., College of Intelligence and Computing, Tianjin University, Tianjin, China, Nanyang Technological University, Singapore, Singapore; Xie, X., Nanyang Technological University, Singapore, Singapore; Juefei-Xu, F., Alibaba Group, San Mateo, United States; Ma, L., Kyushu University, Fukuoka, Japan; Li, Z., College of Intelligence and Computing, Tianjin University, Tianjin, China; Xue, W., Tianjin University of Technology, Tianjin, China; Feng, W., College of Intelligence and Computing, Tianjin University, Tianjin, China; Liu, Y., Nanyang Technological University, Singapore, Singapore","Adversarial attacks of deep neural networks have been intensively studied on image, audio, and natural language classification tasks. Nevertheless, as a typical while important real-world application, the adversarial attacks of online video tracking that traces an object’s moving trajectory instead of its category are rarely explored. In this paper, we identify a new task for the adversarial attack to visual tracking: online generating imperceptible perturbations that mislead trackers along with an incorrect (Untargeted Attack, UA) or specified trajectory (Targeted Attack, TA). To this end, we first propose a spatial-aware basic attack by adapting existing attack methods, i.e., FGSM, BIM, and C&W, and comprehensively analyze the attacking performance. We identify that online object tracking poses two new challenges: 1) it is difficult to generate imperceptible perturbations that can transfer across frames, and 2) real-time trackers require the attack to satisfy a certain level of efficiency. To address these challenges, we further propose the spatial-aware online inc remental attac k (a.k.a. SPARK) that performs spatial-temporal sparse incremental perturbations online and makes the adversarial attack less perceptible. In addition, as an optimization-based method, SPARK quickly converges to very small losses within several iterations by considering historical incremental perturbations, making it much more efficient than basic attacks. The in-depth evaluation of the state-of-the-art trackers (i.e., SiamRPN++ with AlexNet, MobileNetv2, and ResNet-50, and SiamDW) on OTB100, VOT2018, UAV123, and LaSOT demonstrates the effectiveness and transferability of SPARK in misleading the trackers under both UA and TA with minor perturbations. © 2020, Springer Nature Switzerland AG.",Adversarial attack; Online incremental attack; Visual object tracking,Computer vision; Deep neural networks; Classification tasks; Depth evaluations; Natural languages; Online object tracking; Optimization based methods; Real-time tracker; Spatial temporals; Specified trajectories; Object tracking,,,,,"Bertinetto, L., Valmadre, J., Henriques, J.F., Vedaldi, A., Torr, P.H.S., (2016) Fully-Convolutional Siamese Networks for Object Tracking; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy (SP), pp. 39-57. , 2017; Carlini, N., Wagner, D., (2018) Audio Adversarial Examples: Targeted Attacks on Speech-To-Text.; Chen, Z., Guo, Q., Wan, L., Feng, W., Background-suppressed correlation filters for visual tracking (2018) ICME, pp. 1-6; Cisse, M., Adi, Y., Neverova, N., Keshet, J., (2017) Houdini: Fooling Deep Structured Prediction Models; Dai, K., Dong Wang, H.L., Sun, C., Li, J., Visual tracking via adaptive spatially-regularized correlation filters (2019) CVPR, pp. 4665-4674; Danelljan, M., Bhat, G., Khan, F.S., Felsberg, M., ECO: Efficient convolution operators for tracking (2017) CVPR, pp. 6931-6939; Dong, X., Shen, J., Triplet loss in siamese network for object tracking (2018) ECCV 2018. LNCS, 11217, pp. 472-488. , https://doi.org/10.1007/978-3-030-01261-828, Ferrari, V., Hebert, M., Sminchisescu, C., Weiss, Y. (eds.) , Springer, Cham; Dong, Y., (2018) Boosting Adversarial Attacks with Momentum, pp. 9185-9193. , CVPR; Du, X., Xie, X., Li, Y., Ma, L., Liu, Y., Zhao, J., DeepStellar: Model-based quantitative analysis of stateful deep learning systems (2019) ESEC/FSE, pp. 477-487; Fan, H., LaSOT: A high-quality benchmark for large-scale single object tracking (2019) CVPR, pp. 5369-5378; Fan, H., Ling, H., Siamese cascaded region proposal networks for real-time visual tracking (2019) CVPR, pp. 7944-7953; Feng, W., Han, R., Guo, Q., Zhu, J., Wang, S., Dynamic saliency-aware regularization for correlation filter-based object tracking (2019) IEEE TIP, 28 (7), pp. 3232-3245; Gao, J., Lanchantin, J., Soffa, M.L., Qi, Y., Black-box generation of adversarial text sequences to evade deep learning classifiers (2018) SPW, pp. 50-56; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples.; Guo, Q., Feng, W., Zhou, C., Huang, R., Wan, L., Wang, S., Learning dynamic Siamese network for visual object tracking (2017) ICCV, pp. 1781-1789; Guo, Q., Feng, W., Zhou, C., Pun, C., Wu, B., Structure-regularized compressive tracking with online data-driven sampling (2017) IEEE TIP, 26 (12), pp. 5692-5705; Guo, Q., Han, R., Feng, W., Chen, Z., Wan, L., Selective spatial regularization by reinforcement learned decision making for object tracking (2020) IEEE TIP, 29, pp. 2999-3013; He, A., Luo, C., Tian, X., Zeng, W., A twofold Siamese network for real-time object tracking (2018) CVPR, pp. 4834-4843; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) CVPR, pp. 770-778; Held, D., Thrun, S., Savarese, S., Learning to track at 100 FPS with deep regression networks (2016) ECCV 2016. LNCS, 9905, pp. 749-765. , https://doi.org/10.1007/978-3-319-46448-045, Leibe, B., Matas, J., Sebe, N., Welling, M. (eds.) , Springer, Cham; Howard, A.G., (2017) Mobilenets: Efficient Convolutional Neural Networks for Mobile Vision Applications. Arxiv Preprint Arxiv, 1704, p. 04861; Jin, D., Jin, Z., Zhou, J.T., Szolovits, P., (2019) Is Bert Really Robust? Natural Language Attack on Text Classification and Entailment; Kristan, M., et al.: The sixth visual object tracking VOT2018 challenge results. In: Leal-Taixé, L., Roth, S. (eds.) ECCV 2018. LNCS, vol. 11129, pp. 3–53. Springer, Cham (2019). https://doi.org/10.1007/978-3-030-11009-3 1; Kristan, M., The seventh visual object tracking vot2019 challenge results (2019) ICCVW, pp. 2206-2241; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) NIPS, pp. 1097-1105; Kurakin, A., Goodfellow, I., Bengio, S., (2017) Adversarial Examples in the Physical World. ICLR (Workshop; Li, B., Wu, W., Wang, Q., Zhang, F., Xing, J., Yan, J., SiamRPN++: Evolution of Siamese visual tracking with very deep networks (2019) CVPR, pp. 4282-4291; Li, B., Wu, W., Zhu, Z., Yan, J., Hu, X., High performance visual tracking with Siamese region proposal network (2018) CVPR, pp. 8971-8980; Li, Y., Tian, D., Chang, M.C., Bian, X., Lyu, S., Robust adversarial perturbation on deep proposal-based models (2018) BMVC, pp. 1-11; Lin, Y.C., Hong, Z.W., Liao, Y.H., Shi, M.L., Liu, M.Y., Sun, M., Tactics of adversarial attack on deep reinforcement learning agents (2017) IJCAI, pp. 3756-3762; Ling, X., DEEPSEC: A uniform platform for security analysis of deep learning model (2019) IEEE Symposium on Security and Privacy (SP), pp. 673-690; Liu, W., SSD: Single shot multibox detector (2016) ECCV 2016. LNCS, 9905, pp. 21-37. , https://doi.org/10.1007/978-3-319-46448-02, In: Leibe, B., Matas, J., Sebe, N., Welling, M. (eds.), vol., pp. , . Springer, Cham (, ); Lukežič, A., Vojíř, T., Čehovin, L., Matas, J., Kristan, M., Discriminative correlation filter with channel and spatial reliability (2017) CVPR, pp. 4847-4856; Ma, L., (2018) Deepgauge: Multi-Granularity Testing Criteria for Deep Learning Systems, pp. 120-131. , ASE; Metzen, J.H., Kumar, M.C., Brox, T., Fischer, V., Universal adversarial perturbations against semantic image segmentation (2017) ICCV, pp. 2774-2783; Moosavi-Dezfooli, S.M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) CVPR, pp. 86-94; Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P., DeepFool: A simple and accurate method to fool deep neural networks (2016) CVPR, pp. 2574-2582; Mueller, M., Smith, N., Ghanem, B., A benchmark and simulator for UAV tracking (2016) ECCV 2016. LNCS, 9905, pp. 445-461. , https://doi.org/10.1007/978-3-319-46448-027, Leibe, B., Matas, J., Sebe, N., Welling, M. (eds.), Springer, Cham; Müller, M., Bibi, A., Giancola, S., Alsubaihi, S., Ghanem, B., TrackingNet: A large-scale dataset and benchmark for object tracking in the wild (2018) ECCV 2018. LNCS, 11205, pp. 310-327. , Ferrari, V., Hebert, M., Sminchisescu, C., Weiss, Y. (eds.), Springer, Cham, https://doi.org/10.1007/978-3-030-01246-5 19; Nam, H., Han, B., Learning multi-domain convolutional neural networks for visual tracking (2016) CVPR, pp. 4293-4302; Papernot, N., McDaniel, P.D., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) IEEE European Symposium on Security and Privacy (Euros P), pp. 372-387; Qin, Y., Carlini, N., Goodfellow, I., Cottrell, G., Raffel, C., (2019) Imperceptible, Robust, and Targeted Adversarial Examples for Automatic Speech Recognition. Arxiv, 1903, p. 10346; Ren, S., Deng, Y., He, K., Che, W., Generating natural language adversarial examples through probability weighted word saliency (2019) ACL, pp. 1085-1097; Song, Y., (2018) Vital: Visual Tracking via Adversarial Learning, pp. 8990-8999. , CVPR; Sun, J., Stealthy and efficient adversarial attacks against deep reinforcement learning (2020) AAAI, pp. 5883-5891; Sun, Y., Sun, C., Wang, D., Lu, H., He, Y., Roi pooled correlation filters for visual tracking (2019) CVPR, pp. 5776-5784; Szegedy, C., (2013) Intriguing Properties of Neural Networks. Arxiv, 1312, p. 6199; Wang, Q., Zhang, L., Bertinetto, L., Hu, W., Torr, P.H., Fast online object tracking and segmentation: A unifying approach (2019) CVPR, pp. 1328-1338; Wang, X., Li, C., Luo, B., Tang, J., SINT++: Robust visual tracking via adversarial positive instance generation (2018) CVPR, pp. 4864-4873; Wei, X., Liang, S., Chen, N., Cao, X., Transferable adversarial attacks for image and video object detection (2019) IJCAI, pp. 954-960; Wei, X., Zhu, J., Yuan, S., Su, H., Sparse adversarial perturbations for videos (2019) AAAI, pp. 8973-8980; Wiyatno, R.R., Xu, A., (2019) Physical Adversarial Textures that Fool Visual Object Tracking. Arxiv, 1904, p. 11042; Wu, Y., Lim, J., Yang, M.H., Object tracking benchmark (2015) IEEE TPAMI, 37 (9), pp. 1834-1848; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A.L., Adversarial examples for semantic segmentation and object detection (2017) ICCV, pp. 1378-1387; Xie, X., DeepHunter: A coverage-guided fuzz testing framework for deep neural networks (2019) ISSTA, pp. 146-157. , In; Zhang, H., Zhou, H., Miao, N., Li, L., Generating fluent adversarial examples for natural languages (2019) ACL, pp. 5564-5569; Zhang, P., Guo, Q., Feng, W., Fast and object-adaptive spatial regularization for correlation filters based tracking (2019) Neurocomputing, 337, pp. 129-143; Zhang, Y., Wang, L., Qi, J., Wang, D., Feng, M., Lu, H., Structured Siamese network for real-time visual tracking (2018) ECCV 2018. LNCS, 11213, pp. 355-370. , https://doi.org/10.1007/978-3-030-01240-322, Ferrari, V., Hebert, M., Sminchisescu, C., Weiss, Y. (eds.) , Springer, Cham; Zhang, Z., Peng, H., Deeper and wider Siamese networks for real-time visual tracking (2019) CVPR, pp. 4586-4595; Zhao, Y., Zhu, H., Liang, R., Shen, Q., Zhang, S., Chen, K., Seeing isn’t believing: Practical adversarial attack against object detectors (2019) CCS, pp. 1989-2004; Zhu, Z., Wang, Q., Li, B., Wu, W., Yan, J., Hu, W., Distractor-aware Siamese networks for visual object tracking (2018) ECCV 2018. LNCS, 11213, pp. 103-119. , Ferrari, V., Hebert, M., Sminchisescu, C., Weiss, Y. (eds.) , Springer, Cham, https://doi.org/10.1007/978-3-030-01240-3 7","Feng, W.; College of Intelligence and Computing, China; 电子邮件: tsingqguo@gmail.com",Vedaldi A.Bischof H.Brox T.Frahm J.,,Springer Science and Business Media Deutschland GmbH,"16th European Conference on Computer Vision, ECCV 2020",23 August 2020 through 28 August 2020,,249299,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85097372295
"Zhou X., Canady R., Li Y., Koutsoukos X., Gokhale A.",57190391397;57215315800;57214961724;6603632868;7103339463;,Overcoming Stealthy Adversarial Attacks on Power Grid Load Predictions Through Dynamic Data Repair,2020,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),12312 LNCS,,,102,109,,,10.1007/978-3-030-61725-7_14,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097367165&doi=10.1007%2f978-3-030-61725-7_14&partnerID=40&md5=0b184bb4b6b11d27b4dd56f8516cc16e,"Department of EECS, Vanderbilt University, Nashville, TN  37235, United States","Zhou, X., Department of EECS, Vanderbilt University, Nashville, TN  37235, United States; Canady, R., Department of EECS, Vanderbilt University, Nashville, TN  37235, United States; Li, Y., Department of EECS, Vanderbilt University, Nashville, TN  37235, United States; Koutsoukos, X., Department of EECS, Vanderbilt University, Nashville, TN  37235, United States; Gokhale, A., Department of EECS, Vanderbilt University, Nashville, TN  37235, United States","For power distribution networks with connected smart meters, current advances in machine learning enable the service provider to utilize data flows from smart meters for load forecasting using deep neural networks. However, recent research shows that current machine learning algorithms for power systems can be vulnerable to adversarial attacks, which are small designed perturbations crafted on normal inputs that can greatly affect the overall performance of the predictor. Even with only a partial compromise of the network, an attacker could intercept and adversarially modify data from some smart meters in a limited range to make the load predictor deviate from normal prediction results. In this paper, we leverage the dynamic data-driven applications systems (DDDAS) paradigm and propose a novel data repair framework to defend against these kinds of adversarial attacks. This framework complements the predictor with a self-representative auto-encoder and works in an iterative manner. The auto-encoder is used to detect and reconstruct the likely adversarial part in the input data. Different reconstruction results come up given different sensitivity levels in detection. As new data flows in each iterative time step, the service provider continuously checks the error of the previous prediction step and dynamically trades off between different detection sensitivity levels to seek an overall stable data reconstruction. Case studies on power network load forecast regression demonstrate the vulnerability of current machine learning algorithms and correspondingly the effectiveness of our defense framework. © 2020, Springer Nature Switzerland AG.",Adversarial attacks; Dynamic data repair; Load forecasting; Power systems,Data transfer; Deep learning; Deep neural networks; Electric network analysis; Electric power plant loads; Electric power transmission networks; Forecasting; Internet service providers; Iterative methods; Learning systems; Network security; Signal encoding; Smart meters; Data reconstruction; Detection sensitivity; Load forecasting; Load predictions; Power distribution network; Power networks; Recent researches; Service provider; Learning algorithms,,,,,"(2015) Feeders, , https://github.com/gridlab-d/Taxonomy, Accessed October 2019; Athalye, A., Carlini, N., Wagner, D., Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples; Blasch, E., Bernstein, D., Rangaswamy, M., Introduction to dynamic data driven applications systems (2018) Handbook of Dynamic Data Driven Applications Systems, pp. 1-25. , https://doi.org/10.1007/978-3-319-95504-91, Blasch, E., Ravela, S., Aved, A. (eds.) , Springer, Cham; Broll, B., Whitaker, J., DeepForge: An open source (2017) Collaborative Environment for Reproducible Deep Learning; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) Proceedings of the 10Th ACM Workshop on Artificial Intelligence and Security, pp. 3-14. , ACM; Chen, Y., Tan, Y., Zhang, B., Exploiting vulnerabilities of load forecasting through adversarial attacks (2019) Proceedings of the Tenth ACM International Conference on Future Energy Systems, pp. 1-11. , ACM; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and Harnessing Adversarial Examples; Schneider, K.P., Chen, Y., Chassin, D.P., Pratt, R.G., Engel, D.W., Thompson, S.E., (2008) Modern Grid Initiative Distribution Taxonomy Final Report, , Technical report. Pacific Northwest National Laboratory; Sevlian, R., Rajagopal, R., A scaling law for short term load forecasting on varying levels of aggregation (2018) Int. J. Electr. Power Energy Syst., 98, pp. 350-361; Szegedy, C., (2013) Intriguing Properties of Neural Networks. Arxiv Preprint Arxiv, 1312, p. 6199; Vorobeychik, Y., Kantarcioglu, M., Adversarial machine learning (2018) Synth. Lect. Artif. Intell. Mach. Learn., 12 (3), pp. 1-169; Zhang, H., Yu, Y., Jiao, J., Xing, E.P., Ghaoui, L.E., Jordan, M.I., (2019) Theoretically Principled Trade-Off between Robustness and Accuracy. Arxiv Preprint Arxiv, 1901, p. 08573; Zhou, X., Evaluating resilience of grid load predictions under stealthy adversarial attacks (2019) 2019 Resilience Week (RWS), 1, pp. 206-212. , IEEE","Zhou, X.; Department of EECS, United States; 电子邮件: xingyu.zhou@vanderbilt.edu",Darema F.Blasch E.Ravela S.Aved A.,,Springer Science and Business Media Deutschland GmbH,"3rd International Conference on Dynamic Data Driven Application Systems, DDDAS 2020",2 October 2020 through 4 October 2020,,251319,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,,Scopus,2-s2.0-85097367165
[无可用作者姓名],[无可用的作者 ID],"7th National Conference on Computer Vision, Pattern Recognition, Image Processing, and Graphics, NCVPRIPG 2019",2020,Communications in Computer and Information Science,1249,,,,,628,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097306523&partnerID=40&md5=5db10814e11e6467512863b6bf65fbfa,,,"The proceedings contain 58 papers. The special focus in this conference is on Computer Vision, Pattern Recognition, Image Processing, and Graphics. The topics include: Deep Learn Bananas: A Transfer Learning for Banana Variety Classification; a Framework for Lane Prediction Based on Vehicle Detection and Tracking; detector-SegMentor Network for Skin Lesion Localization and Segmentation; choroid Disease Classification Using Convolutional Neural Network; hyper Vision Net: Kidney Tumor Segmentation Using Coordinate Convolutional Layer and Attention Unit; texture Classification by Local Rajan Transform Based Descriptor; domain Decomposition Based Preconditioned Solver for Bundle Adjustment; deep Dictionary Learning for Inpainting; A Robust Pose Transformational GAN for Pose Guided Person Image Synthesis; structure Preserving Image Inpainting Using Edge Priors with Contextual Attention; preface; fast Stereo Depth Estimation in Smartphone Devices with Narrow Baseline; exploring Temporal Differences in 3D Convolutional Neural Networks; PoshakNet: Framework for Matching Dresses from Real-Life Photos Using GAN and Siamese Network; unsupervised Domain Adaptation for Remote Sensing Images Using Metric Learning and Correlation Alignment; computationally Efficient Super-Resolution Approach for Real-World Images; Accurate Damage Dimension Estimation in AI Driven Vehicle Inspection System; a Deep Learning Based Framework for Distracted Driver Detection; RECAL: Reuse of Established CNN Classifier Apropos Unsupervised Learning Paradigm; Pose Estimation of UAVs Using Stereovision; U-RME: Underwater Refined Motion Estimation in Hazy, Cluttered and Dynamic Environments; emphasizing Similar Feature Representations to Defend Against Adversarial Attacks; single Storage Semi-Global Matching for Real Time Depth Processing; iSalGAN - An Improvised Saliency GAN; putting Jewellery and Accessories on a 3D Face Model Generated from 2D Image.",,,,,,,,,Babu R.V.Prasanna M.Namboodiri V.P.,,Springer Science and Business Media Deutschland GmbH,"7th National Conference on Computer Vision, Pattern Recognition, Image Processing, and Graphics, NCVPRIPG 2019",22 December 2019 through 24 December 2019,,251849,18650929,9.79E+12,,,English,Commun. Comput. Info. Sci.,Conference Review,Final,,Scopus,2-s2.0-85097306523
"Ding Y., Liu W., Qin Y., Wang Y.",56389883500;57218922991;57220773319;56177361800;,Smart Watchdog: A Lightweight Defending Mechanism Against Adversarial Transfer Learning,2020,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),12487 LNCS,,,540,549,,,10.1007/978-3-030-62460-6_48,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097184535&doi=10.1007%2f978-3-030-62460-6_48&partnerID=40&md5=11d9c513a1d0ddf64808a2a069f28688,"Guangxi Key Laboratory of Cryptography and Information Security, School of Computer Science and Information Security, Guilin University of Electronic Technology, Guilin, 541004, China; Cyberspace Security Research Center, Peng Cheng Laboratory, Shenzhen, 518055, China; School of Mathematics and Computational Sciences, Guilin University of Electronic Technology, Guilin, 541004, China","Ding, Y., Guangxi Key Laboratory of Cryptography and Information Security, School of Computer Science and Information Security, Guilin University of Electronic Technology, Guilin, 541004, China, Cyberspace Security Research Center, Peng Cheng Laboratory, Shenzhen, 518055, China; Liu, W., Guangxi Key Laboratory of Cryptography and Information Security, School of Computer Science and Information Security, Guilin University of Electronic Technology, Guilin, 541004, China; Qin, Y., School of Mathematics and Computational Sciences, Guilin University of Electronic Technology, Guilin, 541004, China; Wang, Y., Guangxi Key Laboratory of Cryptography and Information Security, School of Computer Science and Information Security, Guilin University of Electronic Technology, Guilin, 541004, China","Most traffic sign recognition tasks rely on artificial neural network. As a kind of transfer learning method, knowledge distillation has improved the robustness of neural network models to a certain extent and saved time for model training. However, the weights of the original model (teacher model) and the new model (student model) are similar. The adversarial examples of the teacher model are easy to transfer and can successfully attack the student model. In order to solve this problem, this paper proposes a lightweight defense mechanism to reduce the similarity between the weight of the student model and the weight of the teacher model, and the dropout-randomization method is applied in the input layer of the student model to reduce the input probability of the adversarial examples. Moreover, we evaluate the precision and the recall of the improved model, the results show that the robustness of the model is significantly improved under the Carlini-Wagner (CW) attack and Project Gradient Descent (PGD) attack. © 2020, Springer Nature Switzerland AG.",Dropout; Knowledge distillation; Transfer learning; Weight,Distillation; Gradient methods; Neural networks; Pattern recognition; Security of data; Students; Traffic signs; Transfer learning; Wearable computers; Defense mechanism; Gradient descent; Model training; Neural network model; Original model; Student Modeling; Traffic sign recognition; Transfer learning methods; Learning systems,,,,,"Berger, M., Forechi, A., de Souza, A.F., de Oliveira Neto, J., Veronese, L., Badue, C., Traffic sign recognition with VG-RAM weightless neural networks (2012) 2012 12Th International Conference on Intelligent Systems Design and Applications (ISDA), pp. 315-319. , IEEE; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP), pp. 39-57. , May; Goutte, C., Gaussier, E., A probabilistic interpretation of precision, recall and F-Score, with implication for evaluation (2005) ECIR 2005. LNCS, 3408, pp. 345-359. , https://doi.org/10.1007/978-3-540-31865-125, Losada, D.E., Fernández-Luna, J.M. (eds.), Springer, Heidelberg; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; He, W., Wei, J., Chen, X., Carlini, N., Song, D., Adversarial example defenses: Ensembles of weak defenses are not strong (2017) Proceedings of the 11Th USENIX Conference on Offensive Technologies, pp. 15-15; Hua, Y., Ge, S., Li, C., Luo, Z., Jin, X., Distilling deep neural networks for robust classification with soft decision trees (2018) 2018 14Th IEEE International Conference on Signal Processing (ICSP), pp. 1128-1132. , IEEE; Huang, G.-B., Saratchandran, P., Sundararajan, N., A generalized growing and pruning RBF (GGAP-RBF) neural network for function approximation (2005) IEEE Trans. Neural Netw., 16 (1), pp. 57-67; Huang, Z., Yuanlong, Y., Jason, G., Liu, H., An efficient method for traffic sign recognition based on extreme learning machine (2016) IEEE Trans. Cybern., 47 (4), pp. 920-933; El Jelali, S., Lyhyaoui, A., Figueirasvidal, A.R., Designing model based classifiers by emphasizing soft targets (2009) Fundamenta Informaticae, 96 (4), pp. 419-433; Ketkar, N., (2017) Introduction to Keras. Deep Learning with Python, pp. 97-111. , Springer, Berlin; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Luo, J., Wu, J., Lin, W., Thinet: A filter level pruning method for deep neural network compression (2017) Proceedings of the IEEE International Conference on Computer Vision, pp. 5068-5076; Luo, X., Chang, X., Ban, X., Regression and classification using extreme learning machine based on l1 − norm and l2 − norm (2016) Neurocomputing, 174, pp. 179-186; Pan, W., Zhong, E., Yang, Q., (2012) Transfer Learning for Text Mining. Mining Text Data, pp. 223-257. , Springer, Berlin; Qureshi, K.N., Abdullah, A.H., A survey on intelligent transportation systems (2013) Middle-East J. Sci. Res., 15 (5), pp. 629-642; Raina, R., Battle, A., Lee, H., Packer, B., Ng, A.Y., Self-taught learning: Transfer learning from unlabeled data (2007) Proceedings of the 24Th International Conference on Machine Learning, pp. 759-766; Tan, Q., Yu, G., Domeniconi, C., Wang, J., Zhang, Z., Incomplete multi-view weak-label learning (2018) IJCAI, pp. 2703-2709; Tang, Z., Wang, D., Zhang, Z., Recurrent neural network training with dark knowledge transfer (2016) 2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 5900-5904. , IEEE; Tokui, S., Oono, K., Hido, S., Clayton, J., Chainer: A next-generation open source framework for deep learning (2015) Proceedings of Workshop on Machine Learning Systems (Learningsys) in the Twenty-Ninth Annual Conference on Neural Information Processing Systems (NIPS), 5, pp. 1-6; Weiss, K., Khoshgoftaar, T.M., Wang, D.D., A survey of transfer learning (2016) J. Big Data, 3 (1), pp. 1-40. , https://doi.org/10.1186/s40537-016-0043-6; Yosinski, J., Clune, J., Bengio, Y., Lipson, H., (2014) How Transferable are Features in Deep Neural Networks? In: Advances in Neural Information Processing Systems, pp. 3320-3328; Zhou, W., Transferable adversarial perturbations (2018) Proceedings of the European Conference on Computer Vision (ECCV), pp. 452-467","Liu, W.; Guangxi Key Laboratory of Cryptography and Information Security, China; 电子邮件: 1466002758@qq.com",Chen X.Yan H.Yan Q.Zhang X.,,Springer Science and Business Media Deutschland GmbH,"3rd International Conference on Machine Learning for Cyber Security, ML4CS 2020",8 October 2020 through 10 October 2020,,251659,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,,Scopus,2-s2.0-85097184535
[无可用作者姓名],[无可用的作者 ID],"1st International Conference on Security and Privacy in Digital Economy, SPDE 2020",2020,Communications in Computer and Information Science,1268 CCIS,,,,,749,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096519309&partnerID=40&md5=d095d7e19dc6b577e3dd2ec61543664f,,,"The proceedings contain 49 papers. The special focus in this conference is on Security and Privacy in Digital Economy. The topics include: Local Differential Privacy for Data Streams; a Personalized Preservation Mechanism Satisfying Local Differential Privacy in Location-Based Services; Location-Aware Privacy Preserving Scheme in SDN-Enabled Fog Computing; PLFG: A Privacy Attack Method Based on Gradients for Federated Learning; a Survey of Game Theoretical Privacy Preservation for Data Sharing and Publishing; network Anomaly Detection Using Federated Learning and Transfer Learning; variational Autoencoder Based Enhanced Behavior Characteristics Classification for Social Robot Detection; A Decentralized Weighted Vote Traffic Congestion Detection Framework for ITS; CVNNs-IDS: Complex-Valued Neural Network Based In-Vehicle Intrusion Detection System; trusted Link-Separation Multipath Selection for Software-Defined Wireless Sensor Networks in Adversarial Environments; intrusion Detection Scheme for Autonomous Driving Vehicles; Hyperparameter Optimization of ICS Intrusion Detection Classifier Based on Improved Hybrid Algorithm; bitcoin-Based Anti-collusion Fair Payments for Outsourcing Computations in Cloud Computing; Rational Delegation of Computation Based on Reputation and Contract Theory in the UC Framework; A PBFT Consensus Scheme with Reputation Value Voting Based on Dynamic Clustering; multi-user Dynamic Symmetric Searchable Encryption for Attribute-Value Type Database in Cloud Storage; revocable Attribute-Based Encryption Scheme with Arithmetic Span Program for Cloud-Assisted IoT; A Multi-data Collaborative Encryption in Concealed Data Aggregation for WSNs; multi-owner Encrypted Ranked Keyword Search Using Machine Learning Techniques; detection of Various Speech Forgery Operations Based on Recurrent Neural Network; Secure Radio Frequency DCS Watermark-Aided Physical Layer Authentication Design for NB-IoT Systems; Robust, Imperceptible and End-to-End Audio Steganography Based on CNN.",,,,,,,,,Yu S.Mueller P.Qian J.,,Springer Science and Business Media Deutschland GmbH,"1st International Conference on Security and Privacy in Digital Economy, SPDE 2020",30 October 2020 through 1 November 2020,,250659,18650929,9.79E+12,,,English,Commun. Comput. Info. Sci.,Conference Review,Final,,Scopus,2-s2.0-85096519309
"Goldblum M., Fowl L., Feizi S., Goldstein T.",57211069935;57211071247;27067628400;14055829100;,Adversarially robust distillation,2020,AAAI 2020 - 34th AAAI Conference on Artificial Intelligence,,,,3996,4003,,7,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095545483&partnerID=40&md5=417d2d237bb10835463d5e2f1fa35342,"University of Maryland, 4176 Campus Drive, College Park, MD  20742, United States","Goldblum, M., University of Maryland, 4176 Campus Drive, College Park, MD  20742, United States; Fowl, L., University of Maryland, 4176 Campus Drive, College Park, MD  20742, United States; Feizi, S., University of Maryland, 4176 Campus Drive, College Park, MD  20742, United States; Goldstein, T., University of Maryland, 4176 Campus Drive, College Park, MD  20742, United States","Knowledge distillation is effective for producing small, highperformance neural networks for classification, but these small networks are vulnerable to adversarial attacks. This paper studies how adversarial robustness transfers from teacher to student during knowledge distillation. We find that a large amount of robustness may be inherited by the student even when distilled on only clean images. Second, we introduce Adversarially Robust Distillation (ARD) for distilling robustness onto student networks. In addition to producing small models with high test accuracy like conventional distillation, ARD also passes the superior robustness of large networks onto the student. In our experiments, we find that ARD student models decisively outperform adversarially trained networks of identical architecture in terms of robust accuracy, surpassing state-of-the-art methods on standard robustness benchmarks. Finally, we adapt recent fast adversarial training methods to ARD for accelerated robust distillation. © 2020, Association for the Advancement of Artificial Intelligence.",,Artificial intelligence; Distillation; Students; Highperformance; Large networks; Small networks; State-of-the-art methods; Student Models; Student network; Test accuracy; Training methods; Distilleries,,,,,"Bridle, J. S., Probabilistic interpretation of feedforward classification network outputs, with relationships to statistical pattern recognition (1990) Neurocomputing, pp. 227-236. , Springer; Carlini, N., Wagner, D., (2016) Defensive distillation is not robust to adversarial examples, , arXiv preprint arXiv:1607.04311; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP), pp. 39-57. , IEEE; Chen, W.-C., Chang, C.-C., Lu, C.-Y., Lee, C.-R., (2018) Knowledge distillation with feature maps for image classification, , arXiv preprint arXiv:1812.00660; Courbariaux, M., Hubara, I., Soudry, D., El-Yaniv, R., Bengio, Y., (2016) Binarized neural networks: Training deep neural networks with weights and activations constrained to+ 1 or-1, , arXiv preprint arXiv:1602.02830; Cubuk, E. D., Zoph, B., Mane, D., Vasudevan, V., Le, Q. V., (2018) Autoaugment: Learning augmentation policies from data, , arXiv preprint arXiv:1805.09501; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 9185-9193; Dziugaite, G. K., Ghahramani, Z., Roy, D. M., (2016) A study of the effect of jpg compression on adversarial images, , arXiv preprint arXiv:1608.00853; Goldblum, M., Fowl, L., Goldstein, T., (2019) Adversarially robust few-shot learning: A meta-learning approach, , arXiv preprint arXiv:1910.00982; Goodfellow, I. J., Shlens, J., Szegedy, C., (2014) Explaining and harnessing adversarial examples, , arXiv preprint arXiv:1412.6572; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770-778; Hinton, G., Vinyals, O., Dean, J., (2015) Distilling the knowledge in a neural network, , arXiv preprint arXiv:1503.02531; Kannan, H., Kurakin, A., Goodfellow, I., (2018) Adversarial logit pairing, , arXiv preprint arXiv:1803.06373; Lee, J.-G., Jun, S., Cho, Y.-W., Lee, H., Kim, G. B., Seo, J. B., Kim, N., Deep learning in medical imaging: General overview (2017) Korean journal of radiology, 18 (4), pp. 570-584; Li, H., Kadav, A., Durdanovic, I., Samet, H., Graf, H. P., (2016) Pruning filters for efficient convnets, , arXiv preprint arXiv:1608.08710; Lin, J., Gan, C., Han, S., (2019) Defensive quantization: When efficiency meets robustness, , arXiv preprint arXiv:1904.08444; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards deep learning models resistant to adversarial attacks, , arXiv preprint arXiv:1706.06083; Miyato, T., Maeda, S.-i., Ishii, S., Koyama, M., Virtual adversarial training: A regularization method for supervised and semi-supervised learning (2018) IEEE transactions on pattern analysis and machine intelligence; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2574-2582; Mustafa, A., Khan, S. H., Hayat, M., Shen, J., Shao, L., (2019) Image super-resolution as a defense against adversarial attacks, , arXiv preprint arXiv:1901.01677; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) 2016 IEEE Symposium on Security and Privacy (SP), pp. 582-597. , IEEE; Prakash, A., Moran, N., Garber, S., DiLillo, A., Storer, J., Deflecting adversarial attacks with pixel deflection (2018) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 8571-8580; Saadatpanah, P., Shafahi, A., Goldstein, T., (2019) Adversarial attacks on copyright detection systems, , arXiv preprint arXiv:1906.07153; Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., Chen, L.-C., Mobilenetv2: Inverted residuals and linear bottlenecks (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4510-4520; Santana, E., Hotz, G., (2016) Learning a driving simulator, , arXiv preprint arXiv:1608.01230; Sehwag, V., Wange, S., Mittal, P., Jana, S., (2019) Towards compact and robust deep neural networks, , arXiv preprint arXiv:1906.06110; Shafahi, A., Najibi, M., Ghiasi, A., Xu, Z., Dickerson, J., Studer, C., Davis, L. S., Goldstein, T., (2019) Adversarial training for free!, , arXiv preprint arXiv:1904.12843; Shaham, U., Yamada, Y., Negahban, S., Understanding adversarial training: Increasing local stability of supervised models through robust optimization (2018) Neurocomputing, 307, pp. 195-204; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing properties of neural networks, , arXiv preprint arXiv:1312.6199; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., andWojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2818-2826; Tai, C., Xiao, T., Zhang, Y., Wang, X., (2015) Convolutional neural networks with low-rank regularization, , arXiv preprint arXiv:1511.06067; Wijayanto, A. W., Jin, C. J., Madhawa, K., Murata, T., Robustness of compressed convolutional neural networks (2018) 2018 IEEE International Conference on Big Data (Big Data), pp. 4829-4836. , IEEE; Xie, C., Wu, Y., van der Maaten, L., Yuille, A., He, K., (2018) Feature denoising for improving adversarial robustness, , arXiv preprint arXiv:1812.03411; Zagoruyko, S., Komodakis, N., (2016) Wide residual networks, , arXiv preprint arXiv:1605.07146; Zhang, D., Zhang, T., Lu, Y., Zhu, Z., Dong, B., (2019) You only propagate once: Painless adversarial training using maximal principle, , arXiv preprint arXiv:1905.00877; Zhang, H., Yu, Y., Jiao, J., Xing, E. P., El Ghaoui, L., Jordan, M. I., (2019) Theoretically principled trade-off between robustness and accuracy, , arXiv preprint arXiv: 1901.08573; Zhao, Y., Shumailov, I., Mullins, R., Anderson, R., (2018) To compress or not to compress: Understanding the interactions between adversarial attacks and neural network compression, , arXiv preprint arXiv:1810.00208","Goldblum, M.; University of Maryland, 4176 Campus Drive, United States; 电子邮件: goldblum@umd.edu",,Association for the Advancement of Artificial Intelligence,AAAI press,"34th AAAI Conference on Artificial Intelligence, AAAI 2020",7 February 2020 through 12 February 2020,,166426,,9.78E+12,,,English,AAAI - AAAI Conf. Artif. Intell.,Conference Paper,Final,,Scopus,2-s2.0-85095545483
"Subramani N., Rao D.",57195955065;57205540813;,Learning efficient representations for fake speech detection,2020,AAAI 2020 - 34th AAAI Conference on Artificial Intelligence,,,,5859,5866,,2,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095305655&partnerID=40&md5=ed4f5039a1f3a38c236b661fd2fad6bb,"AI Foundation, San Francisco, CA, United States","Subramani, N., AI Foundation, San Francisco, CA, United States; Rao, D., AI Foundation, San Francisco, CA, United States","Synthetic speech or “fake speech” which matches personal vocal traits has become better and cheaper due to advances in deep learning-based speech synthesis and voice conversion approaches. This increased accessibility of synthetic speech systems and the growing misuse of them highlights the critical need to build countermeasures. Furthermore, new synthesis models evolve all the time and the efficacy of previously trained detection models on these unseen attack vectors is poor. In this paper, we focus on: 1) How can we build highly accurate, yet parameter and sample-efficient models for fake speech detection? 2) How can we rapidly adapt detection models to new sources of fake speech? We present four parameter-efficient convolutional architectures for fake speech detection with best detection F1 scores of around 97 points on a large dataset of fake and bonafide speech. We show how the fake speech detection task naturally lends itself to a novel multi-task problem further improving F1 scores for a mere 0.5% increase in model parameters. Our multi-task setting also helps in data-sparse situations, commonplace in adversarial settings. We investigate an alternative approach to the data-sparsity problem using transfer learning and show that it is possible to meet purely supervised detection performance for unseen attack vectors with as little as 6.25% of the training data. This is the first known application of transfer learning in adversarial settings for speech. Finally, we show how well our transfer learning approach adapts in an instance-efficient way to new attack vectors using the Real-Time Voice Cloning toolkit. We exceed the purely supervised detection performance (99.18 F1) with as little as 6.25% of the data. © 2020, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,Clone cells; Deep learning; Large dataset; Speech synthesis; Transfer learning; Data sparsity problems; Detection models; Detection performance; Model parameters; Speech detection; Synthesis models; Synthetic speech; Voice conversion; Speech recognition,,,,,"Akuzawa, K., Iwasawa, Y., Matsuo, Y., (2018) Expressive speech synthesis via modeling expressions with variational autoencoder, , arXiv preprint arXiv:1804.02135; Arik, S., Chen, J., Peng, K., Ping, W., Zhou, Y., Neural voice cloning with a few samples (2018) Advances in Neural Information Processing Systems, pp. 10019-10029; Chettri, B., Mishra, S., Sturm, B. L., Benetos, E., Analysing the predictions of a cnn-based replay spoofing detection system (2018) 2018 IEEE Spoken Language Technology Workshop (SLT), pp. 92-97. , IEEE; Cozzolino, D., Thies, J., Rössler, A., Riess, C., Nießner, M., Verdoliva, L., (2018) Forensictransfer: Weakly-supervised domain adaptation for forgery detection, , arXiv preprint arXiv:1812.02510; Gibiansky, A., Arik, S., Diamos, G., Miller, J., Peng, K., Ping, W., Raiman, J., Zhou, Y., Deep voice 2: Multi-speaker neural text-to-speech (2017) Advances in neural information processing systems, pp. 2962-2970; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770-778; Jemine, C., (2019) Master thesis: Automatic multispeaker voice cloning; Jin, Z., Mysore, G. J., Diverdi, S., Lu, J., Finkelstein, A., Voco: Text-based insertion and replacement in audio narration (2017) ACM Transactions on Graphics (TOG), 36 (4), p. 96; Kingma, D. P., Ba, J., (2014) Adam: A method for stochastic optimization, , arXiv preprint arXiv:1412.6980; Lin, M., Chen, Q., Yan, S., (2013) Network in network, , arXiv preprint arXiv:1312.4400; Nachmani, E., Polyak, A., Taigman, Y., Wolf, L., (2018) Fitting new speakers based on a short untranscribed sample, , arXiv preprint arXiv:1802.06984; Oord, A. v. d., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A., Kalchbrenner, N., Kavukcuoglu, K., (2016) Wavenet: A generative model for raw audio, , arXiv preprint arXiv:1609.03499; Pan, S. J., Yang, Q., A survey on transfer learning (2009) IEEE Transactions on knowledge and data engineering, 22 (10), pp. 1345-1359; Piczak, K. J., Environmental sound classification with convolutional neural networks (2015) 2015 IEEE 25th International Workshop on Machine Learning for Signal Processing (MLSP), pp. 1-6. , IEEE; Ping, W., Peng, K., Gibiansky, A., Arik, S. O., Kannan, A., Narang, S., Raiman, J., Miller, J., (2017) Deep voice 3: Scaling text-to-speech with convolutional sequence learning, , arXiv preprint arXiv:1710.07654; Rössler, A., Cozzolino, D., Verdoliva, L., Riess, C., Thies, J., Nießner, M., (2018) Faceforensics: A large-scale video dataset for forgery detection in human faces, , arXiv preprint arXiv:1803.09179; Salamon, J., Bello, J. P., Deep convolutional neural networks and data augmentation for environmental sound classification (2017) IEEE Signal Processing Letters, 24 (3), pp. 279-283; Skerry-Ryan, R., Battenberg, E., Xiao, Y., Wang, Y., Stanton, D., Shor, J., Weiss, R. J., Saurous, R. A., (2018) Towards end-to-end prosody transfer for expressive speech synthesis with tacotron, , arXiv preprint arXiv:1803.09047; Todisco, M., Wang, X., Vestman, V., Sahidullah, M., Delgado, H., Nautsch, A., Yamagishi, J., Lee, K. A., (2019) Asvspoof 2019: Future horizons in spoofed and fake audio detection, , arXiv preprint arXiv:1904.05441; Wang, Y., Skerry-Ryan, R., Stanton, D., Wu, Y., Weiss, R. J., Jaitly, N., Yang, Z., Bengio, S., (2017) Tacotron: Towards end-to-end speech synthesis, , arXiv preprint arXiv:1703.10135; Wang, Y., Stanton, D., Zhang, Y., Skerry-Ryan, R., Battenberg, E., Shor, J., Xiao, Y., Saurous, R. A., (2018) Style tokens: Unsupervised style modeling, control and transfer in end-to-end speech synthesis, , arXiv preprint arXiv:1803.09017; Wu, X., He, R., Sun, Z., Tan, T., A light cnn for deep face representation with noisy labels (2018) IEEE Transactions on Information Forensics and Security, 13 (11), pp. 2884-2896; Yosinski, J., Clune, J., Bengio, Y., Lipson, H., How transferable are features in deep neural networks? (2014) Advances in neural information processing systems, pp. 3320-3328; Zhang, Y., Yang, Q., (2017) A survey on multi-task learning, , arXiv preprint arXiv:1707.08114","Rao, D.; AI FoundationUnited States; 电子邮件: delip@aifoundation.com",,Association for the Advancement of Artificial Intelligence,AAAI press,"34th AAAI Conference on Artificial Intelligence, AAAI 2020",7 February 2020 through 12 February 2020,,166426,,9.78E+12,,,English,AAAI - AAAI Conf. Artif. Intell.,Conference Paper,Final,,Scopus,2-s2.0-85095305655
"Shi Y., Han Y., Tian Q.",57204978397;55489219500;57209993060;,Polishing decision-based adversarial noise with a customized sampling,2020,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,,,9157197,1027,1035,,5,10.1109/CVPR42600.2020.00111,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094840254&doi=10.1109%2fCVPR42600.2020.00111&partnerID=40&md5=f10ca26183610b85c5034e0655855e62,"College of Intelligence and Computing, Tianjin University, Tianjin, China; Tianjin Key Lab of Machine Learning, Tianjin University, Tianjin, China; Noah's Ark Lab, Huawei Technologies, China","Shi, Y., College of Intelligence and Computing, Tianjin University, Tianjin, China, Tianjin Key Lab of Machine Learning, Tianjin University, Tianjin, China; Han, Y., College of Intelligence and Computing, Tianjin University, Tianjin, China, Tianjin Key Lab of Machine Learning, Tianjin University, Tianjin, China; Tian, Q., Noah's Ark Lab, Huawei Technologies, China","As an effective black-box adversarial attack, decision-based methods polish adversarial noise by querying the target model. Among them, boundary attack is widely applied due to its powerful noise compression capability, especially when combined with transfer-based methods. Boundary attack splits the noise compression into several independent sampling processes, repeating each query with a constant sampling setting. In this paper, we demonstrate the advantage of using current noise and historical queries to customize the variance and mean of sampling in boundary attack to polish adversarial noise. We further reveal the relationship between the initial noise and the compressed noise in boundary attack. We propose Customized Adversarial Boundary (CAB) attack that uses the current noise to model the sensitivity of each pixel and polish adversarial noise of each image with a customized sampling setting. On the one hand, CAB uses current noise as a prior belief to customize the multivariate normal distribution. On the other hand, CAB keeps the new samplings away from historical failed queries to avoid similar mistakes. Experimental results measured on several image classification datasets emphasizes the validity of our method. © 2020 IEEE",,Classification (of information); Normal distribution; Classification datasets; Current noise; Decision-based; Historical queries; Multi-variate normal distributions; Noise compression; Sampling process; Target model; Pattern recognition,,,,,"Brendel, W., Rauber, J., Kurakin, A., Papernot, N., Veliqi, B., Mohanty, S.P., Laurent, F., Yu, Y., Adversarial vision challenge (2020) The NeurIPS'18 Competition, pp. 129-153. , Springer; Brunner, T., Diehl, F., Le, M.T., Knoll, A., Guessing smart: Biased sampling for efficient black-box adversarial attacks (2019) ICCV, pp. 4958-4966; Carlini, N., Wagner, D.A., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP), pp. 39-57; Chen, J., Jordan, M.I., Wainwright, M.J., HopskipJumpattack: A query-efficient decision-based attack (2019) ICLR; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 15-26; Cheng, M., Le, T., Chen, P.-Y., Yi, J., Zhang, H., Hsieh, C.-J., Query-efficient hard-label black-box attack: An optimization-based approach (2019) ICLR; Cheng, S., Dong, Y., Pang, T., Su, H., Zhu, J., Improving black-box adversarial attacks with a transfer-based prior (2019) NeurIPS, pp. 10932-10942; Dong, Y., Liao, F., Pang, T., Su, H., Hu, X., Li, J., Zhu, J., Boosting adversarial attacks with momentum (2018) CVPR; Dong, Y., Pang, T., Su, H., Zhu, J., Evading defenses to transferable adversarial examples by translation-invariant attacks (2019) CVPR; Dong, Y., Su, H., Wu, B., Li, Z., Liu, W., Zhang, T., Zhu, J., Efficient decision-based black-box adversarial attacks on face recognition (2019) CVPR; Fawzi, A., Fawzi, O., Frossard, P., Analysis of classifiers robustness to adversarial perturbations (2018) Machine Learning, 107 (3), pp. 481-508; Finlay, C., Pooladian, A.-A., Oberman, A., The logbarrier adversarial attack: Making effective use of decision boundary information (2019) ICCV, pp. 4862-4870; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) CVPR, pp. 770-778; Hu, J., Shen, L., Sun, G., Squeeze-and-excitation networks (2018) CVPR, pp. 7132-7141; Huang, G., Liu, Z., Weinberger, K.Q., Densely connected convolutional networks (2017) CVPR, pp. 2261-2269; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images, , Technical report; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2017) ICLR Workshop; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proceedings of the IEEE, 86 (11), pp. 2278-2324; Liu, L., Cheng, M., Hsieh, C.-J., Tao, D., (2018) Stochastic Zeroth-Order Optimization Via Variance Reduction Method, , arXiv preprint; Liu, Y., Chen, X., Liu, C.C., Song, D.X., Delving into transferable adversarial examples and black-box attacks (2017) ICLR; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) CVPR, pp. 427-436; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2016) EuroS&P, pp. 372-387; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Bernstein, M., Imagenet large scale visual recognition challenge (2015) International Journal of Computer Vision, 115 (3), pp. 211-252; Shi, Y., Wang, S., Han, Y., Curls & whey: Boosting black-box adversarial attacks (2019) CVPR; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) ICLR; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., Inception-v4, inception-resnet and the impact of residual connections on learning (2017) AAAI, p. 12; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) CVPR, pp. 2818-2826; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R., Intriguing properties of neural networks (2013) ICLR; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P.D., Ensemble adversarial training: Attacks and defenses (2018) ICLR; Tu, C.-C., Ting, P., Chen, P.-Y., Liu, S., Zhang, H., Yi, J., Hsieh, C.-J., Cheng, S.-M., AutoZoom: Autoencoder-based zeroth order optimization method for attacking black-box neural networks (2019) AAAI, pp. 742-749; Brendel, J.R.W., Bethge, M., Decision-based adversarial attacks: Reliable attacks against black-box machine learning models (2018) ICLR; Wu, L., Zhu, Z., Tai, C., (2018) Understanding and Enhancing the Transferability of Adversarial Examples, , arXiv preprint; Zoph, B., Vasudevan, V., Shlens, J., Le, Q.V., Learning transferable architectures for scalable image recognition (2018) CVPR, pp. 8697-8710","Han, Y.; College of Intelligence and Computing, China; 电子邮件: yahong@tju.edu.cn",,,IEEE Computer Society,"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2020",14 June 2020 through 19 June 2020,,162261,10636919,,PIVRE,,English,Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit,Conference Paper,Final,,Scopus,2-s2.0-85094840254
"Wu W., Su Y., Chen X., Zhao S., King I., Lyu M.R., Tai Y.-W.",57209642543;56717004400;57002419400;56024272800;7102275781;7006811415;7201915847;,Boosting the transferability of adversarial samples via attention,2020,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,,,9156604,1158,1167,,8,10.1109/CVPR42600.2020.00124,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094807683&doi=10.1109%2fCVPR42600.2020.00124&partnerID=40&md5=046c4cc5224e49a4a6a48d9be6907bbd,"Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong; Tencent","Wu, W., Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong; Su, Y., Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong; Chen, X., Tencent; Zhao, S., Tencent; King, I., Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong; Lyu, M.R., Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong; Tai, Y.-W., Tencent","The widespread deployment of deep models necessitates the assessment of model vulnerability in practice, especially for safety- and security-sensitive domains such as autonomous driving and medical diagnosis. Transfer-based attacks against image classifiers thus elicit mounting interest, where attackers are required to craft adversarial images based on local proxy models without the feedback information from remote target ones. However, under such a challenging but practical setup, the synthesized adversarial samples often achieve limited success due to overfitting to the local model employed. In this work, we propose a novel mechanism to alleviate the overfitting issue. It computes model attention over extracted features to regularize the search of adversarial examples, which prioritizes the corruption of critical features that are likely to be adopted by diverse architectures. Consequently, it can promote the transferability of resultant adversarial instances. Extensive experiments on ImageNet classifiers confirm the effectiveness of our strategy and its superiority to state-of-the-art benchmarks in both white-box and black-box settings. ©2020 IEEE.",,Classification (of information); Diagnosis; Autonomous driving; Black boxes; Critical features; Feed back information; Image Classifiers; Overfitting; Safety and securities; State of the art; Image classification,,,,,"Athalye, A., Carlini, N., Wagner, D., Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples (2018) International Conference on Machine Learning (ICML), , 3; Bhagoji, A.N., He, W., Li, B., Song, D., Practical black-box attacks on deep neural networks using efficient query mechanisms (2018) The European Conference on Computer Vision (ECCV), pp. 158-174. , Springer, 3; Biggio, B., Roli, F., Wild patterns: Ten years after the rise of adversarial machine learning (2018) Pattern Recognition, 84, pp. 317-331. , 1, 2, 3; Carlini, N., Athalye, A., Papernot, N., Brendel, W., Rauber, J., Tsipras, D., Goodfellow, I., Madry, A., (2019) On Evaluating Adversarial Robustness, , 5; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy (SP), , 1, 3, 6; Chen, P.-Y., Sharma, Y., Zhang, H., Yi, J., Hsieh, C.-J., EAD: Elastic-net attacks to deep neural networks via adversarial examples (2018) The Thirty-Second AAAI Conference on Artificial Intelligence, , 3; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2018) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 9185-9193. , 1; Dong, Y., Pang, T., Su, H., Zhu, J., Evading defenses to transferable adversarial examples by translation-invariant attacks (2019) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , 1, 3, 8; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations (ICLR), , 1, 3, 4, 6; Guo, C., Gardner, J., You, Y., Wilson, A.G., Weinberger, K., Simple black-box adversarial attacks (2019) International Conference on Machine Learning (ICML), , 3; Guo, C., Rana, M., Cisse, M., Van Der Maaten, L., Countering adversarial images using input transformations (2018) International Conference on Learning Representations (ICLR), , 3; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) IEEE International Conference on Computer Vision (ICCV), pp. 770-778. , 2, 5; He, K., Zhang, X., Ren, S., Sun, J., Identity mappings in deep residual networks (2016) The European Conference on Computer Vision (ECCV), pp. 630-645. , Springer, 2, 5; He, W., Wei, J., Chen, X., Carlini, N., Song, D., Adversarial example defense: Ensembles of weak defenses are not strong (2017) 11th USENIX Workshop on Offensive Technologies (WOOT 17), , 3; Hinton, G.E., Learning multiple layers of representation (2007) Trends in Cognitive Sciences, , 4; Ilyas, A., Engstrom, L., Athalye, A., Lin, J., Black-box adversarial attacks with limited queries and information (2018) International Conference on Machine Learning (ICML), pp. 2142-2151. , 1; Kingma, D.P., Ba, J., ADaM: A method for stochastic optimization (2015) International Conference on Learning Representations (ICLR), , 3; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2017) ICLR Workshop, 3, p. 6; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2017) International Conference on Learning Representations (ICLR), , 6; Kurakin, A., Goodfellow, I., Bengio, S., Dong, Y., Liao, F., Liang, M., Pang, T., Xie, C., Adversarial attacks and defences competition (2018) The NIPS’17 Competition: Building Intelligent Systems, , 1, 3, 5; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) International Conference on Learning Representations (ICLR), 1, p. 3; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) International Conference on Learning Representations (ICLR), 3, p. 6; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1765-1773. , 3; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) The Asia Conference on Computer and Communications Security (ASIA CCS), , ACM, 3; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2016) The IEEE European Symposium on Security and Privacy (EuroS&P), pp. 372-387. , 3, 6; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) IEEE Symposium on Security and Privacy (SP), pp. 582-597. , 3; Pouyanfar, S., Sadiq, S., Yan, Y., Tian, H., Tao, Y., Reyes, M.P., Shyu, M.-L., Iyengar, S.S., A survey on deep learning: Algorithms, techniques, and applications (2018) ACM Computing Surveys (CSUR), , 1; Rauber, J., Brendel, W., Bethge, M., Foolbox: A python toolbox to benchmark the robustness of machine learning models (2017) ICML Workshop, , 6; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Fei-Fei, L., ImageNet large scale visual recognition challenge (2015) International Journal of Computer Vision, , 5; Selvaraju, R.R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., Batra, D., Grad-cam: Visual explanations from deep networks via gradient-based localization (2017) IEEE International Conference on Computer Vision (ICCV), 2, p. 4; Razavian, A.S., Azizpour, H., Sullivan, J., Carlsson, S., CNN features off-the-shelf: An astounding baseline for recognition (2014) CVPR Workshop, , 4; Sharma, Y., Le, T.-D., Alzantot, M., (2018) CAAD 2018: Generating Transferable Adversarial Examples, , arXiv preprint 3; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) International Conference on Learning Representations (ICLR), , 2; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., Inception-v4, Inception-ResNet and the impact of residual connections on learning (2017) The Thirty-First AAAI Conference on Artificial Intelligence, , 5; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) IEEE International Conference on Computer Vision (ICCV), 2, p. 5; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations (ICLR), 1, p. 3; Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2018) International Conference on Learning Representations (ICLR), 3, p. 6; Wu, W., Xu, H., Zhong, S., Lyu, M.R., King, I., Deep validation: Toward detecting real-world corner cases for deep neural networks (2019) International Conference on Dependable Systems and Networks (DSN), pp. 125-137. , IEEE, 3; Xie, C., Zhang, Z., Zhou, Y., Bai, S., Wang, J., Ren, Z., Yuille, A.L., Improving transferability of adversarial examples with input diversity (2019) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , 1, 3; Xu, W., Evans, D., Qi, Y., Feature squeezing: Detecting adversarial examples in deep neural networks (2018) The Network and Distributed System Security Symposium (NDSS), , 3; Zhou, W., Hou, X., Chen, Y., Tang, M., Huang, X., Gan, X., Yang, Y., Transferable adversarial perturbations (2018) The European Conference on Computer Vision (ECCV), , 1, 3, 5, 6, 7, 8","Su, Y.; Department of Computer Science and Engineering, Hong Kong; 电子邮件: yxsu@cse.cuhk.edu.hk",,,IEEE Computer Society,"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2020",14 June 2020 through 19 June 2020,,162261,10636919,,PIVRE,,English,Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit,Conference Paper,Final,,Scopus,2-s2.0-85094807683
"Duan R., Ma X., Wang Y., Bailey J., Qin A.K., Yang Y.",57219707779;57195682647;57188869413;7404350735;7004084538;57215201658;,Adversarial camouflage: Hiding physical-world attacks with natural styles,2020,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,,,9157568,997,1005,,24,10.1109/CVPR42600.2020.00108,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094732841&doi=10.1109%2fCVPR42600.2020.00108&partnerID=40&md5=f3773a154fc8d03441b0d8b78e346041,"Swinburne University of Technology, Australia; University of Melbourne, Australia; Shanghai Jiao Tong University, China","Duan, R., Swinburne University of Technology, Australia; Ma, X., University of Melbourne, Australia; Wang, Y., Shanghai Jiao Tong University, China; Bailey, J., University of Melbourne, Australia; Qin, A.K., Swinburne University of Technology, Australia; Yang, Y., Swinburne University of Technology, Australia","Deep neural networks (DNNs) are known to be vulnerable to adversarial examples. Existing works have mostly focused on either digital adversarial examples created via small and imperceptible perturbations, or physical-world adversarial examples created with large and less realistic distortions that are easily identified by human observers. In this paper, we propose a novel approach, called Adversarial Camouflage (AdvCam), to craft and camouflage physicalworld adversarial examples into natural styles that appear legitimate to human observers. Specifically, AdvCam transfers large adversarial perturbations into customized styles, which are then ""hidden""on-target object or off-target background. Experimental evaluation shows that, in both digital and physical-world scenarios, adversarial examples crafted by AdvCam are well camouflaged and highly stealthy, while remaining effective in fooling state-of-the-art DNN image classifiers. Hence, AdvCam is a flexible approach that can help craft stealthy attacks to evaluate the robustness of DNNs. AdvCam can also be used to protect private information from being detected by deep learning systems. © 2020 IEEE.",,Deep neural networks; Learning systems; Pattern recognition; Petroleum reservoir evaluation; Experimental evaluation; Human observers; Image Classifiers; Physical world; Private information; State of the art; Target background; Target object; Deep learning,,,,,"Athalye, A., Engstrom, L., Ilyas, A., Kwok, K., Synthesizing robust adversarial examples (2017) ICLR; Bai, Y., Feng, Y., Wang, Y., Dai, T., Xia, S., Jiang, Y., Hilbert-based generative defense for adversarial examples (2019) ICCV; Brown, T.B., Mané, D., Roy, A., Abadi, M., Gilmer, J., Adversarial patch (2017) NIPS Workshop; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE S&P; Champandard, A.J., Semantic style transfer and turning two-bit doodles into fine artworks (2016) ICLR; Chen, C., Seff, A., Kornhauser, A., Xiao, J., Deepdriving: Learning affordance for direct perception in autonomous driving (2015) ICCV; Chen, P., Sharma, Y., Zhang, H., Yi, J., Hsieh, C., Ead: Elastic-net attacks to deep neural networks via adversarial examples (2018) AAAI; Dong, Y., Su, H., Wu, B., Li, Z., Liu, W., Zhang, T., Zhu, J., Efficient decision-based blackbox adversarial attacks on face recognition (2019) CVPR, pp. 7714-7722; Efros, A.A., Freeman, W.T., Image quilting for texture synthesis and transfer (2001) PACMCGIT; Evtimov, I., Eykholt, K., Fernandes, E., Kohno, T., Li, B., Prakash, A., Rahmati, A., Song, D., Robust physical-world attacks on deep learning models (2018) CVPR; Gatys, L.A., Ecker, A.S., Bethge, M., Image style transfer using convolutional neural networks (2016) CVPR; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2014) ICLR; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) CVPR; Hosseini, H., Poovendran, R., Semantic adversarial examples (2018) CVPR Workshop; Jiang, L., Ma, X., Chen, S., Bailey, J., Jiang, Y., Black-box adversarial attacks on video recognition models (2019) ACM MM; Karayev, S., Trentacoste, M., Han, H., Agarwala, A., Darrell, T., Hertzmann, A., Winnemoeller, H., (2013) Recognizing Image Style.; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2016) ICLR; Derek Liu, H., Tao, M., Li, C., Nowrouzezahrai, D., Jacobson, A., Beyond pixel normballs: Parametric adversaries using an analytically differentiable renderer (2018) ICLR; Luan, F., Paris, S., Shechtman, E., Bala, K., Deep photo style transfer (2017) CVPR; Ma, X., Li, B., Wang, Y., Erfani, S.M., Wijewickrema, S., Schoenebeck, G., Song, D., Bailey, J., Characterizing adversarial subspaces using local intrinsic dimensionality (2018) ICLR; Ma, X., Niu, Y., Gu, L., Wang, Y., Zhao, Y., Bailey, J., Lu, F., (2019) Understanding Adversarial Attacks on Deep Learning Based Medical Image Analysis Systems.; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) ICLR; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) CCS; Song, Y., Shu, R., Kushman, N., Ermon, S., Constructing unrestricted adversarial examples with generative models (2018) NIPS; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2013) ICLR; Wang, Y., Deng, X., Pu, S., Huang, Z., (2017) Residual Convolutional Ctc Networks for Automatic Speech Recognition.; Wang, Y., Ma, X., Bailey, J., Yi, J., Zhou, B., Gu, Q., On the convergence and robustness of adversarial training (2019) ICML; Wang, Y., Zou, D., Yi, J., Bailey, J., Ma, X., Gu, Q., Improving adversarial robustness requires revisiting misclassified examples (2020) ICLR; Wu, D., Wang, Y., Xia, S., Bailey, J., Ma, X., Skip connections matter: On the transferability of adversarial examples generated with resnets (2020) ICLR; Xiao, C., Li, B., Zhu, J., He, W., Liu, M., Song, D., Generating adversarial examples with adversarial networks (2018) IJCAI; Xie, C., Zhang, Z., Zhou, Y., Bai, S., Wang, J., Ren, Z., Yuille, A.L., Improving transferability of adversarial examples with input diversity (2019) CVPR; Xu, K., Zhang, G., Liu, S., Fan, Q., Sun, M., Chen, H., Chen, P., Lin, X., (2019) Adversarial T-shirt! Evading Person Detectors in A Physical World.; Zeng, M., Wang, Y., Luo, Y., Dirichlet latent variable hierarchical recurrent encoder-decoder in dialogue generation (2019) EMNLP; Zeng, X., Liu, C., Wang, Y., Qiu, W., Xie, L., Tai, Y., Tang, C., Yuille, A.L., Adversarial attacks beyond the image space (2019) CVPR; Zhang, Y., Foroosh, H., David, P., Gong, B., Camou: Learning physical vehicle camouflages to adversarially attack detectors in the wild (2019) ICLR","Ma, X.; University of MelbourneAustralia; 电子邮件: xingjun.ma@unimelb.edu.au",,,IEEE Computer Society,"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2020",14 June 2020 through 19 June 2020,,162261,10636919,,PIVRE,,English,Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85094732841
"Lu Y., Jia Y., Wang J., Li B., Chai W., Carin L., Velipasalar S.",57192556936;57219508246;57142698500;57205290558;57219612376;7004561693;55884798200;,Enhancing cross-task black-box transferability of adversarial examples with dispersion reduction,2020,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,,,9157043,937,946,,8,10.1109/CVPR42600.2020.00102,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094207043&doi=10.1109%2fCVPR42600.2020.00102&partnerID=40&md5=3fcefba3134fedb0024d5be4b14f65a7,"Syracuse University, United States; Bytedance AI Lab; Baidu USA, United States; Duke University, United States","Lu, Y., Syracuse University, United States; Jia, Y., Bytedance AI Lab; Wang, J., Baidu USA, United States; Li, B., Duke University, United States; Chai, W., Syracuse University, United States; Carin, L., Duke University, United States; Velipasalar, S., Syracuse University, United States","Neural networks are known to be vulnerable to carefully crafted adversarial examples, and these malicious samples often transfer, i.e., they remain adversarial even against other models. Although significant effort has been devoted to the transferability across models, surprisingly little attention has been paid to cross-task transferability, which represents the real-world cybercriminal's situation, where an ensemble of different defense/detection mechanisms need to be evaded all at once. We investigate the transferability of adversarial examples across a wide range of real-world computer vision tasks, including image classification, object detection, semantic segmentation, explicit content detection, and text detection. Our proposed attack minimizes the “dispersion” of the internal feature map, overcoming the limitations of existing attacks, that require task-specific loss functions and/or probing a target model. We conduct evaluation on open-source detection and segmentation models, as well as four different computer vision tasks provided by Google Cloud Vision (GCV) APIs. We demonstrate that our approach outperforms existing attacks by degrading performance of multiple CV tasks by a large margin with only modest perturbations. © 2020 IEEE.",,Dispersions; Image segmentation; Object detection; Petroleum reservoir evaluation; Semantics; Text processing; Content detection; Internal features; Large margins; Open sources; Segmentation models; Semantic segmentation; Specific loss function; Text detection; Computer vision,,,,,"Github Repository for Our Code, , https://github.com/erbloo/dr_cvpr20.2; Github Repository for Our Evaluation Data, , https://github.com/erbloo/dr_images_cvpr20.6; Google Cloud Vision, 2. , Link; Robust reading challenge on COCO-Text Link, 7, p. 8. , ICDAR2017; (2017) Link, 8. , ImageNet Challenge; Keras applications Link., 8; NSFW data scraper Link., 7, p. 8; Brendel, W., Rauber, J., Bethge, M., (2017) Decision-Based Adversarial Attacks: Reliable Attacks against Black-Box Machine Learning Models, , arXiv preprint 3; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP), pp. 39-57. , IEEE, 1, 3; Chen, L.-C., Papandreou, G., Schroff, F., Adam, H., Rethinking atrous convolution for semantic image segmentation (2017) CoRR, , abs/1706.05587, 4; Chen, L.-C., Zhu, Y., Papandreou, G., Schroff, F., Adam, H., (2018) Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation, , 4; Dong, Y., Liao, F., Pang, T., Hu, X., Zhu, J., Discovering adversarial examples with momentum (2017) CoRR, , abs/1710.06081, 5; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 9185-9193. , 1, 2, 3, 5, 7; Dong, Y., Pang, T., Su, H., Zhu, J., Evading defenses to transferable adversarial examples by translation-invariant attacks (2019) Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2, p. 5; Dong, Y., Pang, T., Su, H., Zhu, J., Evading defenses to transferable adversarial examples by translation-invariant attacks (2019) Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 3, p. 5; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint 2, 3, 4; He, K., Gkioxari, G., Dollár, P., Ross, B., Mask r-cnn (2017) 2017 IEEE International Conference on Computer Vision (ICCV), pp. 2980-2988. , 4; Ilyas, A., Engstrom, L., Athalye, A., Lin, J., (2018) Black-Box Adversarial Attacks with Limited Queries and Information, , arXiv preprint 3; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Machine Learning at Scale, , arXiv preprint 3; Lee, H., Grosse, R., Ranganath, R., Ng, A.Y., Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations (2009) Proceedings of the 26th Annual International Conference on Machine Learning, pp. 609-616. , ACM, 2; Lin, T.-Y., Goyal, P., Girshick, R.B., He, K., Dollár, P., Focal loss for dense object detection (2017) 2017 IEEE International Conference on Computer Vision (ICCV), pp. 2999-3007. , Oct 4; Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S.E., Fu, C.-Y., Berg, A.C., SSD: Single shot multibox detector (2015) CoRR, p. 4. , abs/1512.02325; Liu, Y., Chen, X., Liu, C., Song, D., (2016) Delving into Transferable Adversarial Examples and Black-Box Attacks, , arXiv preprint 1, 2; Long, J., Shelhamer, E., Darrell, T., Fully convolutional networks for semantic segmentation (2014) CoRR, p. 4. , abs/1411.4038; Luo, Y., Boix, X., Roig, G., Poggio, T.A., Zhao, Q., (2015) Foveation-Based Mechanisms Alleviate Adversarial Examples, , arXiv preprint 8; Mack, C.A., (2007) NIST,SEMATECH E-Handbook of Statistical Methods, 4; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, 3, p. 5; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-Box Attacks Using Adversarial Samples, , arXiv preprint 2; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519. , ACM, 2; Redmon, J., Farhadi, A., (2018) Yolov3: An Incremental Improvement, , arXiv, 4; Ren, S., He, K., Girshick, R., Sun, J., Faster R-CNN: Towards real-time object detection with region proposal networks (2015) Advances in Neural Information Processing Systems, 28, pp. 91-99. , C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors, Curran Associates, Inc, 4; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540. , ACM, 2; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint 1, 2; Uesato, J., O'Donoghue, B., van den Oord, A., Kohli, P., (2018) Adversarial Risk and the Dangers of Evaluating against Weak Attacks, , arXiv preprint 3; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., Adversarial examples for semantic segmentation and object detection (2017) Proceedings of the IEEE International Conference on Computer Vision, pp. 1369-1378. , 2; Xie, C., Zhang, Z., Wang, J., Zhou, Y., Ren, Z., Yuille, A., (2018) Improving Transferability of Adversarial Examples with Input Diversity, , arXiv preprint 1, 2, 3, 5, 7; Xie, C., Zhang, Z., Wang, J., Zhou, Y., Ren, Z., Yuille, A.L., (2018) Improving Transferability of Adversarial Examples with Input Diversity, , CoRR, abs/1803.06978, 5; Zhou, W., Hou, X., Chen, Y., Tang, M., Huang, X., Gan, X., Yang, Y., Transferable adversarial perturbations (2018) Proceedings of the European Conference on Computer Vision (ECCV), pp. 452-467. , 2",,,,IEEE Computer Society,"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2020",14 June 2020 through 19 June 2020,,162261,10636919,,PIVRE,,English,Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85094207043
"Hamdi A., Rojas S., Thabet A., Ghanem B.",57219482068;57219484835;54788625000;24331436200;,AdvPC: Transferable Adversarial Perturbations on 3D Point Clouds,2020,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),12357 LNCS,,,241,257,,5,10.1007/978-3-030-58610-2_15,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093089308&doi=10.1007%2f978-3-030-58610-2_15&partnerID=40&md5=5fd763d89331798a96df854f49788e8b,"King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia","Hamdi, A., King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia; Rojas, S., King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia; Thabet, A., King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia; Ghanem, B., King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia","Deep neural networks are vulnerable to adversarial attacks, in which imperceptible perturbations to their input lead to erroneous network predictions. This phenomenon has been extensively studied in the image domain, and has only recently been extended to 3D point clouds. In this work, we present novel data-driven adversarial attacks against 3D point cloud networks. We aim to address the following problems in current 3D point cloud adversarial attacks: they do not transfer well between different networks, and they are easy to defend against via simple statistical methods. To this extent, we develop a new point cloud attack (dubbed AdvPC) that exploits the input data distribution by adding an adversarial loss, after Auto-Encoder reconstruction, to the objective it optimizes. AdvPC leads to perturbations that are resilient against current defenses, while remaining highly transferable compared to state-of-the-art attacks. We test AdvPC using four popular point cloud networks: PointNet, PointNet++ (MSG and SSG), and DGCNN. Our proposed attack increases the attack success rate by up to 40% for those transferred to unseen networks (transferability), while maintaining a high success rate on the attacked network. AdvPC also increases the ability to break defenses by up to 38% as compared to other baselines on the ModelNet40 dataset. The code is available at https://github.com/ajhamdi/AdvPC. © 2020, Springer Nature Switzerland AG.",,Deep neural networks; 3D point cloud; Auto encoders; Data driven; Following problem; Image domain; Input datas; Network prediction; State of the art; Computer vision,,,,,"Achlioptas, P., Diamanti, O., Mitliagkas, I., Guibas, L., (2018) Learning Representations and Generative Models for 3D Point Clouds; Alcorn, M.A., Strike (With) a pose: Neural networks are easily fooled by strange poses of familiar objects (2019) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Cao, Y., Adversarial objects against lidar-based autonomous driving systems (2019) Corr Abs/1907, p. 05418; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy (SP); Engelmann, F., Kontogianni, T., Hermans, A., Leibe, B., Exploring spatial context for 3D semantic segmentation of point clouds (2017) 2017 IEEE International Conference on Computer Vision Workshops (ICCVW), pp. 716-724. , October; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations (ICLR; Hamdi, A., Ghanem, B., Towards analyzing semantic robustness of deep neural networks (2019) Corr, , abs/1904.04621; Hamdi, A., Muller, M., Ghanem, B., SADA: Semantic adversarial diagnostic attacks for autonomous applications (2020) AAAI Conference on Artificial Intelligence; Huang, Q., Wang, W., Neumann, U., Recurrent slice networks for 3D segmentation of point clouds (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2626-2635; Kingma, D.P., Ba, J., Adam: A method for stochastic optimization (2014) Corr, , abs/1412.6980; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial machine learning at scale (2016) Corr, , abs/1611.01236; Landrieu, L., Boussaha, M., (2019) Point Cloud over Segmentation with Graph-Structured Deep Metric Learning, pp. 7440-7449; Landrieu, L., Simonovsky, M., Large-scale point cloud semantic segmentation with superpoint graphs (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4558-4567; Li, J., Chen, B.M., Hee Lee, G., SO-Net: Self-organizing network for point cloud analysis (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 9397-9406; Li, Y., Bu, R., Sun, M., Wu, W., Di, X., Chen, B., PointCNN: Convolution on x-transformed points (2018) Advances in Neural Information Processing Systems (NIPS), pp. 820-830; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) International Conference on Learning Representations (ICLR; Moosavi-Dezfooli, S.M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P., DeepFool: A simple and accurate method to fool deep neural networks (2016) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Naseer, M.M., Khan, S.H., Khan, M.H., Shahbaz Khan, F., Porikli, F., Cross-domain transferability of adversarial perturbations (2019) Advances in Neural Information Processing Systems (Neurips), pp. 12905-12915; Poursaeed, O., Katsman, I., Gao, B., Belongie, S., Generative adversarial perturbations (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4422-4431; Qi, C.R., Su, H., Mo, K., Guibas, L.J., PointNet: Deep learning on point sets for 3D classification and segmentation (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 652-660; Qi, C.R., Yi, L., Su, H., Guibas, L.J., PointNet++: Deep hierarchical feature learning on point sets in a metric space (2017) Advances in Neural Information Processing Systems (NIPS), pp. 5099-5108; Szegedy, C., Intriguing properties of neural networks (2013) Corr, , abs/1312.6199; Tatarchenko, M., Park, J., Koltun, V., Zhou, Q.Y., Tangent convolutions for dense prediction in 3D (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 3887-3896; Tsai, T., Yang, K., Ho, T.Y., Jin, Y., Robust adversarial objects against deep learning models (2020) AAAI Conference on Artificial Intelligence; Tu, C.C., Autozoom: Autoencoder-based zeroth order optimization method for attacking black-box neural networks (2019) Proceedings of the AAAI Conference on Artificial Intelligence, 33, pp. 742-749; Tu, J., Physically realizable adversarial examples for lidar object detection (2020) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 13716-13725; Wang, W., Yu, R., Huang, Q., Neumann, U., SGPN: Similarity group proposal network for 3D point cloud instance segmentation (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2569-2578; Wang, Y., Sun, Y., Liu, Z., Sarma, S.E., Bronstein, M.M., Solomon, J.M., Dynamic graph CNN for learning on point clouds (2019) ACM Trans. Graph. (TOG), 38 (1-12); Wu, Z., 3D shapenets: A deep representation for volumetric shapes (2015) 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1912-1920; Xiang, C., Qi, C.R., Li, B., Generating 3D adversarial point clouds (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 9136-9144; Xiao, C., Yang, D., Li, B., Deng, J., Liu, M., MeshAdv: Adversarial meshes for visual recognition (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 6898-6907; Ye, X., Li, J., Huang, H., Du, L., Zhang, X., 3D recurrent neural networks with context fusion for point cloud semantic segmentation (2018) ECCV 2018. LNCS, 11211, pp. 415-430. , https://doi.org/10.1007/978-3-030-01234-225, Ferrari, V., Hebert, M., Sminchisescu, C., Weiss, Y. (eds.), Springer, Cham; Yu, L., Li, X., Fu, C.W., Cohen-Or, D., Heng, P.A., PU-Net: Point cloud upsampling network (2018) Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Zeng, X., Adversarial attacks beyond the image space (2019) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Zhao, Z., Dua, D., Singh, S., Generating natural adversarial examples (2018) International Conference on Learning Representations (ICLR; Zheng, T., Chen, C., Yuan, J., Li, B., Ren, K., PointCloud saliency maps (2019) The IEEE International Conference on Computer Vision (ICCV); Zhou, H., Chen, K., Zhang, W., Fang, H., Zhou, W., Yu, N., DUP-Net: Denoiser and upsampler network for 3d adversarial point clouds defense (2019) The IEEE International Conference on Computer Vision (ICCV)","Hamdi, A.; King Abdullah University of Science and Technology (KAUST)Saudi Arabia; 电子邮件: abdullah.hamdi@kaust.edu.sa",Vedaldi A.Bischof H.Brox T.Frahm J.-M.,,Springer Science and Business Media Deutschland GmbH,"16th European Conference on Computer Vision, ECCV 2020",23 August 2020 through 28 August 2020,,249299,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85093089308
"Zhou S., Yang Z., Xiang J., Cao Y., Yang M., Zhang Y.",57217606571;55286289300;57219257979;36668327500;55703330900;55286715500;,An ever-evolving game: Evaluation of real-world attacks and defenses in ethereum ecosystem,2020,Proceedings of the 29th USENIX Security Symposium,,,,2793,2809,,7,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091930121&partnerID=40&md5=300039106f6d43907f8e10417087ee95,"Fudan University, China; Johns Hopkins University, United States","Zhou, S., Fudan University, China; Yang, Z., Fudan University, China; Xiang, J., Fudan University, China; Cao, Y., Johns Hopkins University, United States; Yang, M., Fudan University, China; Zhang, Y., Fudan University, China","Smart contract security has drawn much attention due to many severe incidents with huge ether and token losses. As a consequence, researchers have proposed to detect smart contract vulnerabilities via code analysis. However, code analysis only shows what contracts can be attacked, but not what have been attacked, and more importantly, what attacks have been prevented in the real world. In this paper, we present the first comprehensive measurement study to analyze real-world attacks and defenses adopted in the wild based on the transaction logs produced by uninstrumented Ethereum Virtual Machine (EVM). Specifically, our study decouples two important factors of an adversarial transaction-i.e., (i) an adversarial action exploiting the vulnerable contract and (ii) an adversarial consequence like ether or token transfers resulted from the action-for the analysis of attacks and defenses. The results of our study reveal a huge volume of attacks beyond what have been studied in the literature, e.g., those targeting new vulnerability types like airdrop hunting and those targeting zero-day variants of known vulnerabilities. Besides successful attacks, our study also shows attempted attacks that are prevented due to the deployments of defenses. As the nature of cyber-security, those defenses have also been evaded, mainly due to incomplete defense deployments. To summarize it, we believe that this is an ever-evolving game between adversaries obtaining illegal profits and defenders shielding their own contracts. © 2020 by The USENIX Association. All Rights Reserved.",,Ethers; Network security; Code analysis; Comprehensive measurement; Cyber security; Real-world; Real-world attack; Transaction log; Ethereum,,,,,"(2016), https://etherscan.io/address/0x304a554a310C7e546dfe434669C62820b7D83490, TheDarkDAO contract; (2016), https://etherscan.io/address/0xbf4ed7b27f1d666546e30d74d50d173d20bca754, WithdrawDAO contract; (2017), https://etherscan.io/address/0x3abe5285ED57c8b028D62D30c456cA9eb3E74105, ChooseWHGReturnAddress contract; (2017), https://consensys.github.io/smart-contract-best-practices/known_attacks/, Ethereum known attacks; (2017), https://github.com/trailofbits/manticore, Manticore; (2017) Parity wallet multi-sig library vulnerability, , https://www.parity.io/security-alert-2/; (2018) Analyzing the first token harvest event in blockchain, , https://paper.seebug.org/646/; (2018), https://etherscan.io/address/0xa62142888aba8370742be823c1782d17a0389da1, FoMo3Dlong contract; (2018), https://github.com/ConsenSys/mythril, Mythril; (2018) A redundant SafeMath implementation to make your contract unsafe!, , https://blog.peckshield.com/2018/08/14/unsafemath/; (2019), https://www.coingecko.com, CoinGecko; (2019) Ethereum in bigquery: a public dataset for smart contract analytics, , https://cloud.google.com/blog/products/data-analytics/ethereum-bigquery-public-dataset-smart-contract-analytics; (2019), https://etherscan.io, Etherscan; (2019), https://en.wikipedia.org/wiki/Fleiss%27_kappa, Fleiss kappa; (2019) Fuzzing, , https://en.wikipedia.org/wiki/Fuzzing; (2019), https://github.com/christoftorres/HoneyBadger/tree/master/results/evaluation, HoneyBadger dataset; (2019), https://llvm.org/docs/LangRef.html#introduction, LLVM IR; (2019) OpenZeppelin contracts is a library for secure smart contract development, , https://github.com/OpenZeppelin/openzeppelin-contracts; (2019), https://en.wikipedia.org/wiki/Replay_attack, Replay attack; (2019) Solidity programming language: Error handling, , https://solidity.readthedocs.io/en/v0.5.11/control-structures.html?highlight=require#errorhandling-assert-require-revert-and-exceptions; Bhargavan, Karthikeyan, Delignat-Lavaud, Antoine, Fournet, Cédric, Gollamudi, Anitha, Gonthier, Georges, Kobeissi, Nadim, Kulatova, Natalia, Swamy, Nikhil, Formal verification of smart contracts: Short paper (2016) Proceedings_of_the_2016_ACM_Workshop_on Programming_Languages_and_Analysis_for_Security; Breindenbach, Lorenz, Daian, Phil, Tramèr, Florian, Juels, Ari, Enter the hydra: Towards principled bug bounties and exploit-resistant smart contracts (2018) 27th_{USENIX} Security_Symposium_({USENIX}_Security_18), pp. 1335-1352; Brent, Lexi, Jurisevic, Anton, Kong, Michael, Liu, Eric, Gauthier, Francois, Gramoli, Vincent, Holz, Ralph, Scholz, Bernhard, (2018) Vandal: A scalable security analysis framework for smart contracts, , arXiv_preprint_arXiv:1809.03981; Buterin, Vitalik, (2016) DAO fork, , https://blog.ethereum.org/2016/07/20/hard-fork-completed/; Chen, Ting, Li, Xiaoqi, Luo, Xiapu, Zhang, Xiaosong, Under-optimized smart contracts devour your money (2017) 2017 IEEE_24th_International_Conference_on_Software_Analysis, Evolution_and_Reengineering_(SANER); Delmolino, Kevin, Arnett, Mitchell, Kosba, Ahmed, Miller, Andrew, Shi, Elaine, Step by step towards creating a safe smart contract: Lessons and insights from a cryptocurrency lab (2016) International_Conference_on_Financial_Cryptography and_Data_Security, pp. 79-94. , Springer; Grech, Neville, Kong, Michael, Jurisevic, Anton, Brent, Lexi, Scholz, Bernhard, Smaragdakis, Yannis, Madmax: Surviving out-of-gas conditions in ethereum smart contracts (2018) The_ACM_SIGPLAN_conference_on_Systems, Programming,_Languages_and_Applications:_Software_for Humanity_(OOPSLA'18); Jiang, Bo, Liu, Ye, Chan, WK, Contractfuzzer: Fuzzing smart contracts for vulnerability detection (2018) Proceedings_of the_33rd_ACM/IEEE_International_Conference_on_Automated Software_Engineering_(ASE'18); Kalra, Sukrit, Goel, Seep, Dhawan, Mohan, Sharma, Subodh, Zeus: Analyzing safety of smart contracts (2018) 25th Annual_Network_and_Distributed_System_Security_Symposium (NDSS'18); Krupp, Johannes, Rossow, Christian, teether: Gnawing at ethereum to automatically exploit smart contracts (2018) 27th USENIX_Security_Symposium_(USENIX_Security'18); Luu, Loi, Chu, Duc-Hiep, Olickel, Hrishi, Saxena, Prateek, Hobor, Aquinas, Making smart contracts smarter (2016) Proceedings_of_the_2016_ACM_SIGSAC_Conference_on Computer_and_Communications_Security_(CCS'16); Mueller, Bernhard, Smashing ethereum smart contracts for fun and real profit (2018) 9th_Annual_HITB_Security_Conference (HITBSecConf); Nikolić, Ivica, Kolluri, Aashish, Sergey, Ilya, Saxena, Prateek, Hobor, Aquinas, Finding the greedy, prodigal, and suicidal contracts at scale (2018) Proceedings_of_the_34th_Annual_Computer Security_Applications_Conference_(ACSAC'18); Palladino, Santiago, (2017) The parity wallet hack explained, , https://blog.openzeppelin.com/on-the-paritywallet-multisig-hack-405a8c12e8f7/; Perez, Daniel, Livshits, Benjamin, (2019) Smart contract vulnerabilities: Does anyone care?, , arXiv_preprint_arXiv:1902.06710; Rodler, Michael, Li, Wenting, Karame, Ghassan O, Davi, Lucas, Sereum: Protecting existing smart contracts against re-entrancy attacks (2019) 26th_Annual_Network_and_Distributed System_Security_Symposium_(NDSS'19); Sherbachev, Alex, (2018) Hacking the hackers: Honeypots on ethereum network, , https://hackernoon.com/hacking-the-hackers-honeypots-on-ethereum-network-5baa35a13577; Sherbuck, Alex, (2018) Dissecting an ethereum honeypot, , https://medium.com/coinmonks/dissecting-an-ethereum-honey-pot-7102d7def5e0; Tikhomirov, Sergei, Voskresenskaya, Ekaterina, Ivanitskiy, Ivan, Takhaviev, Ramil, Marchenko, Evgeny, Alexandrov, Yaroslav, Smartcheck: Static analysis of ethereum smart contracts (2018) 2018_IEEE/ACM_1st_International_Workshop_on Emerging_Trends_in_Software_Engineering_for_Blockchain (WETSEB'18); Torres, Christof Ferreira, Steichen, Mathis, The art of the scam: Demystifying honeypots in ethereum smart contracts (2019) 28th_USENIX_Security_Symposium_(USENIX_Security'19); Tsankov, Petar, Dan, Andrei, Drachsler-Cohen, Dana, Gervais, Arthur, Buenzli, Florian, Vechev, Martin, Securify: Practical security analysis of smart contracts (2018) Proceedings of_the_2018_ACM_SIGSAC_Conference_on_Computer_and Communications_Security_(CCS'18); Vessenes, Peter, (2016) Deconstructing TheDAO attack: A brief code tour, , https://vessenes.com/deconstructing-thedaoattack-a-brief-code-tour/; Zhou, Yi, Kumar, Deepak, Bakshi, Surya, Mason, Joshua, Miller, Andrew, Bailey, Michael, Erays: reverse engineering ethereum's opaque smart contracts (2018) 27th_USENIX_Security Symposium_(USENIX_Security'18)",,,ByteDance;et al.;Facebook;Microsoft;Salesforce;USENIX Association,USENIX Association,29th USENIX Security Symposium,12 August 2020 through 14 August 2020,,162471,,9.78E+12,,,English,Proc. USENIX Secur. Symp.,Conference Paper,Final,,Scopus,2-s2.0-85091930121
"Wang G., Lai J., Liang W., Wang G.",57201954806;57216303737;57219541547;56609497900;,Smoothing adversarial domain attack and p-memory reconsolidation for cross-domain person re-identification,2020,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,,,9156972,10565,10574,,18,10.1109/CVPR42600.2020.01058,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091062268&doi=10.1109%2fCVPR42600.2020.01058&partnerID=40&md5=a28ab7deb8d8d1c229673eabd6f36531,"School of Data and Computer Science, Sun Yat-sen University, China; Guangdong Key Laboratory of Information Security Technology; Key Laboratory of Machine Intelligence and Advanced Computing, Ministry of Education","Wang, G., School of Data and Computer Science, Sun Yat-sen University, China; Lai, J., School of Data and Computer Science, Sun Yat-sen University, China, Guangdong Key Laboratory of Information Security Technology, Key Laboratory of Machine Intelligence and Advanced Computing, Ministry of Education; Liang, W., School of Data and Computer Science, Sun Yat-sen University, China; Wang, G., School of Data and Computer Science, Sun Yat-sen University, China","Most of the existing person re-identification (re-ID) methods achieve promising accuracy in a supervised manner, but they assume the identity labels of the target domain is available. This greatly limits the scalability of person re-ID in real-world scenarios. Therefore, the current person re-ID community focuses on the cross-domain person re-ID that aims to transfer the knowledge from a labeled source domain to an unlabeled target domain and exploits the specific knowledge from the data distribution of the target domain to further improve the performance. To reduce the gap between the source and target domains, we propose a Smoothing Adversarial Domain Attack (SADA) approach that guides the source domain images to align the target domain images by using a trained camera classifier. To stabilize a memory trace of cross-domain knowledge transfer after its initial acquisition from the source domain, we propose a p-Memory Reconsolidation (pMR) method that re-consolidates the source knowledge with a small probability p during the self-training of the target domain. With both SADA and pMR, the proposed method significantly improves the cross-domain person re-ID. Extensive experiments on Market-1501 and DukeMTMC-reID benchmarks show that our pMR-SADA outperforms all of the state-of-the-arts by a large margin. © 2020 IEEE",,Knowledge management; Data distribution; Identity labels; Large margins; Person re identifications; Re-consolidation; Real-world scenario; Specific knowledge; State of the art; Pattern recognition,,,,,"Aljundi, R., Chakravarty, P., Tuytelaars, T., Expert gate: Lifelong learning with a network of experts (2017) CVPR, pp. 3366-3375. , 3; Baxter, J., A model of inductive bias learning (2000) Journal of Artificial Intelligence Research, 12, pp. 149-198. , 2; Chen, W., Chen, X., Zhang, J., Huang, K., Beyond triplet loss: A deep quadruplet network for person re-identification (2017) CVPR, pp. 403-412. , 2; Chen, Y., Zhu, X., Gong, S., Instance-guided context rendering for cross-domain person re-identification (2019) ICCV, pp. 232-242. , 1, 2, 6, 7; Cheng, D., Gong, Y., Zhou, S., Wang, J., Zheng, N., Person re-identification by multi-channel parts-based cnn with improved triplet loss function (2016) CVPR, pp. 1335-1344. , 2; Deng, W., Zheng, L., Ye, Q., Kang, G., Yang, Y., Jiao, J., Image-image domain adaptation with preserved self-similarity and domain-dissimilarity for person re-identification (2018) CVPR, pp. 994-1003. , 1, 2, 7, 8; Ding, S., Lin, L., Wang, G.R., Chao, H., Deep feature learning with relative distance comparison for person re-identification (2015) Pattern Recognition, 48 (10), pp. 2993-3003. , 2; Fan, H., Zheng, L., Yan, C., Yang, Y., Unsupervised person re-identification: Clustering and fine-tuning (2018) ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM), 14 (4), p. 83. , 1, 2, 6, 7; Fang, P., Zhou, J., Roy, S.K., Petersson, L., Harandi, M., Bilinear attention networks for person retrieval (2019) ICCV, pp. 8030-8039. , 2; Fu, Y., Wei, Y., Zhou, Y., Shi, H., Huang, G., Wang, X., Yao, Z., Huang, T., Horizontal pyramid matching for person re-identification (2019) AAAI, 33, pp. 8295-8302. , 2; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) CVPR, pp. 770-778. , 2; Hermans, A., Beyer, L., Leibe, B., (2017) In Defense of the Triplet Loss for Person Re-Identification, , arXiv preprint 4; Jung, H., Ju, J., Jung, M., Kim, J., (2016) Less-Forgetting Learning in Deep Neural Networks, , arXiv preprint 3; Kirkpatrick, J., Pascanu, R., Rabinowitz, N., Veness, J., Desjardins, G., Rusu, A.A., Milan, K., Grabska-Barwinska, A., Overcoming catastrophic forgetting in neural networks (2017) Proceedings of the National Academy of Sciences, 114 (13), pp. 3521-3526. , 3; Kodirov, E., Xiang, T., Gong, S., Dictionary learning with iterative laplacian regularisation for unsupervised person re-identification (2015) BMVC, 3, p. 8. , 6, 7; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint 3; Li, W., Zhu, X., Gong, S., Harmonious attention network for person re-identification (2018) CVPR, pp. 2285-2294. , 2; Li, Y.J., Lin, C.C., Lin, Y.B., Wang, Y.F., Cross-dataset person re-identification via unsupervised pose disentanglement and adaptation (2019) ICCV, pp. 7919-7929. , 1, 2, 6, 7; Liang, W., Wang, G., Lai, J., Zhu, J., (2018) M2m-Gan: Many-to-Many Generative Adversarial Transfer Learning for Person Re-Identification, , arXiv preprint 1, 2; Liao, S., Hu, Y., Zhu, X., Li, S.Z., Person re-identification by local maximal occurrence representation and metric learning (2015) CVPR, pp. 2197-2206. , 6, 7; Lin, L., Wang, G.R., Zuo, W., Feng, X., Zhang, L., Cross-domain visual matching via generalized similarity measure and feature learning (2016) IEEE TPAMI, 39 (6), pp. 1089-1102. , 2; Lin, S., Li, H., Li, C.T., Kot, A.C., (2018) Multi-Task Mid-Level Feature Alignment Network for Unsupervised Cross-Dataset Person Re-Identification, , arXiv preprint 2; Lin, Y., Dong, X., Zheng, L., Yan, Y., Yang, Y., A bottom-up clustering approach to unsupervised person re-identification (2019) AAAI, 33, pp. 8738-8745. , 2; Lisanti, G., Masi, L., Bagdanov, A.D., Del Bimbo, A., Person re-identification by iterative re-weighted sparse ranking (2014) IEEE TPAMI, 37 (8), pp. 1629-1642. , 6, 7; Liu, J., Zha, Z.J., Chen, D., Hong, R., Wang, M., Adaptive transfer network for cross-domain person re-identification (2019) CVPR, pp. 7202-7211. , 2, 6, 7; Lopez-Paz, D., Ranzato, M., Gradient episodic memory for continual learning (2017) NeurIPS, pp. 6467-6476. , 2, 3; Peng, P., Xiang, T., Wang, Y., Pontil, M., Gong, S., Huang, T., Tian, Y., Unsupervised cross-dataset transfer learning for person re-identification (2016) CVPR, pp. 1306-1315. , 6, 7; Qi, L., Wang, L., Huo, J., Zhou, L., Shi, Y., Gao, Y., A novel unsupervised camera-aware domain adaptation framework for person re-identification (2019) ICCV, pp. 8080-8089. , 2, 6, 7; Rusu, A.A., Rabinowitz, N.C., Desjardins, G., Soyer, H., Kirkpatrick, J., Kavukcuoglu, K., Pascanu, R., Had-Sell, R., (2016) Progressive Neural Networks, , arXiv preprint 3; Ruvolo, P., Eaton, E., Ella: An efficient lifelong learning algorithm (2013) ICML, pp. 507-515. , 2; Song, L., Wang, C., Zhang, L., Du, B., Zhang, Q., Huang, C., Wang, X., (2018) Unsupervised Domain Adaptive Re-Identification: Theory and Practice, , arXiv preprint 2; Su, C., Li, J., Zhang, S., Xing, J., Gao, W., Tian, Q., Pose-driven deep convolutional model for person re-identification (2017) ICCV, pp. 3960-3969. , 2; Sun, Y., Zheng, L., Yang, Y., Tian, Q., Wang, S., Beyond part models: Person retrieval with refined part pooling (and a strong convolutional baseline) (2018) ECCV, pp. 480-496. , 2; Wang, C., Zhang, Q., Huang, C., Liu, W., Wang, X., MANCS: A multi-task attentional network with curriculum sampling for person re-identification (2018) ECCV, pp. 365-381. , 2; Wang, G., Yuan, Y., Chen, X., Li, J., Zhou, X., Learning discriminative features with multiple granularities for person re-identification (2018) 2018 ACM Multimedia Conference on Multimedia Conference, pp. 274-282. , ACM, 2; Wang, G.C., Lai, J., Huang, P., Xie, X., Spatial-temporal person re-identification (2019) AAAI, pp. 8933-8940. , 2; Wang, G.C., Lai, J., Xie, X., P2SNEt: Can an image match a video for person re-identification in an end-to-end way? (2018) IEEE TCSVT, 28, pp. 2777-2787. , 2; Wang, G.C., Lai, J., Xie, Z., Xie, X., (2019) Discovering Underlying Person Structure Pattern with Relative Local Distance for Person Re-Identification, , arXiv preprint 2; Wang, G.R., Lin, L., Ding, S., Li, Y., Wang, Q., Dari: Distance metric and representation integration for person verification (2016) AAAI, , 2; Wang, G.R., Luo, P., Wang, X., Lin, L., Kalman normalization: Normalizing internal representations across network layers (2018) NeurIPS, pp. 21-31. , etc. 2; Wang, G.R., Wang, G.C., Zhang, X., Lai, J., Lin, L., (2019) Weakly Supervised Person Re-Identification: Cost-Effective Learning with a New Benchmark, , arXiv preprint 2; Wang, G.R., Wang, K., Lin, L., Adaptively connected neural networks (2019) CVPR, pp. 1781-1790. , 2; Wang, J., Zhu, X., Gong, S., Li, W., Transferable joint attribute-identity deep learning for unsupervised person re-identification (2018) CVPR, pp. 2275-2284. , 6, 7; Wei, L., Zhang, S., Gao, W., Tian, Q., Person transfer gan to bridge domain gap for person re-identification (2018) CVPR, pp. 79-88. , 1, 2; Wu, A., Zheng, W.S., Lai, J.H., Unsupervised person re-identification by camera-aware similarity consistency learning (2019) ICCV, pp. 6922-6931. , 6, 7; Yi, D., Lei, Z., Liao, S., Li, S.Z., Deep metric learning for person re-identification (2014) ICPR, pp. 34-39. , IEEE, 2; Yu, H.X., Wu, A., Zheng, W.S., Cross-view asymmetric metric learning for unsupervised person re-identification (2017) ICCV, pp. 994-1002. , 6, 7; Yu, H.X., Zheng, W.S., Wu, A., Guo, X., Gong, S., Lai, J.H., Unsupervised person re-identification by soft multilabel learning (2019) CVPR, pp. 2148-2157. , 6, 7; Zhao, H., Tian, M., Sun, S., Shao, J., Yan, J., Yi, S., Wang, X., Tang, X., Spindle Net: Person re-identification with human body region guided feature decomposition and fusion (2017) CVPR, pp. 1077-1085. , 2; Zhao, L., Li, X., Zhuang, Y., Wang, J., Deeply-learned part-aligned representations for person re-identification (2017) ICCV, pp. 3219-3228. , 2; Zheng, L., Bie, Z., Sun, Y., Wang, J., Su, C., Wang, S., Tian, Q., Mars: A video benchmark for large-scale person re-identification (2016) ECCV, pp. 868-884. , Springer, 2; Zheng, L., Shen, L., Tian, L., Wang, S., Wang, J., Tian, Q., Scalable person re-identification: A benchmark (2015) ICCV, pp. 1116-1124. , 1, 6, 7; Zheng, Z., Zheng, L., Yang, Y., Unlabeled samples generated by gan improve the person re-identification baseline in vitro (2017) ICCV, , 6; Zhong, Z., Zheng, L., Luo, Z., Li, S., Yang, Y., Invariance matters: Exemplar memory for domain adaptive person re-identification (2019) CVPR, pp. 598-607. , 6, 7; Zhou, S., Wang, F., Huang, Z., Wang, J., Discriminative feature learning with consistent attention regularization for person re-identification (2019) ICCV, pp. 8040-8049. , 2; Zhuo, J., Chen, Z., Lai, J., Wang, G.C., (2018) Occluded Person Re-Identification, , arXiv preprint 2","Lai, J.; School of Data and Computer Science, China; 电子邮件: liangwq8@mail2.sysu.edu.cn",,,IEEE Computer Society,"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2020",14 June 2020 through 19 June 2020,,162261,10636919,,PIVRE,,English,Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit,Conference Paper,Final,,Scopus,2-s2.0-85091062268
"Li M., Deng C., Li T., Yan J., Gao X., Huang H.",57219706957;57208019993;57219704300;36026971200;7403873424;57221180537;,Towards Transferable Targeted Attack,2020,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,,,9156367,638,646,,7,10.1109/CVPR42600.2020.00072,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090405641&doi=10.1109%2fCVPR42600.2020.00072&partnerID=40&md5=d76ae6a07e71ea11f42ae097206788de,"School of Electronic Engineering, Xidian University, Xi'an, 710071, China; Department of Electrical and Computer Engineering, University of PittsburghPA  15260, United States; Department of CSE, MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University, China; JD Finance America Corporation, Mountain View, CA  94043, United States","Li, M., School of Electronic Engineering, Xidian University, Xi'an, 710071, China; Deng, C., School of Electronic Engineering, Xidian University, Xi'an, 710071, China; Li, T., School of Electronic Engineering, Xidian University, Xi'an, 710071, China; Yan, J., Department of CSE, MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University, China; Gao, X., School of Electronic Engineering, Xidian University, Xi'an, 710071, China; Huang, H., Department of Electrical and Computer Engineering, University of PittsburghPA  15260, United States, JD Finance America Corporation, Mountain View, CA  94043, United States","An intriguing property of adversarial examples is their transferability, which suggests that black-box attacks are feasible in real-world applications. Previous works mostly study the transferability on non-targeted setting. However, recent studies show that targeted adversarial examples are more difficult to transfer than non-targeted ones. In this paper, we find there exist two defects that lead to the difficulty in generating transferable examples. First, the magnitude of gradient is decreasing during iterative attack, causing excessive consistency between two successive noises in accumulation of momentum, which is termed as noise curing. Second, it is not enough for targeted adversarial examples to just get close to target class without moving away from true class. To overcome the above problems, we propose a novel targeted attack approach to effectively generate more transferable adversarial examples. Specifically, we first introduce the Poincare distance as the similarity metric to make the magnitude of gradient self-adaptive during iterative attack to alleviate noise curing. Furthermore, we regularize the targeted attack process with metric learning to take adversarial examples away from true label and gain more transferable targeted adversarial examples. Experiments on ImageNet validate the superiority of our approach achieving 8% higher attack success rate over other state-of-the-art methods on average in black-box targeted attack. © 2020 IEEE.",,Curing; Iterative methods; Black boxes; Metric learning; Non-targeted; Poincare; Real-world; Similarity metrics; State-of-the-art methods; Target class; Pattern recognition,,,,,"Bi, Y., Fan, B., Wu, F., Beyond mahalanobis metric: Cayley-klein metric learning (2015) In CVPR, pp. 2339-2347; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Srndic, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) In ECML-PKDD, pp. 387-402. , Springer; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) In ACM Workshop on AISec, pp. 3-14. , ACM; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) In S&P, pp. 39-57. , IEEE; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2018) In CVPR, pp. 9185-9193; Dong, Y., Pang, T., Su, H., Zhu, J., Evading defenses to transferable adversarial examples by translation-invariant attacks (2019) In CVPR, pp. 4312-4321; Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Xiao, C., Prakash, A., Song, D., Robust physical-world attacks on deep learning visual classification (2018) In CVPR, pp. 1625-1634; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2014) In ICLR; He, K., Zhang, X., Ren, S., Sun, J., Identity mappings in deep residual networks (2016) In ECCV, pp. 630-645. , Springer; Hoffer, E., Ailon, N., Deep metric learning using triplet network (2015) In SIMBAD, pp. 84-92. , Springer; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2017) In ICLR; Li, C., Gao, S., Deng, C., De, Xie, Liu, W., Cross-modal learning with adversarial samples (2019) In NeurIPS; Li, J., Schmidt, F., Kolter, Z., Adversarial camera stickers: A physical camera-based attack on deep learning systems (2019) In ICML, pp. 3896-3904; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and blackbox attacks (2017) In ICLR; Mathieu, E., Lan, C.L., Maddison, C.J., Tomioka, R., Teh, Y.W., (2019) Hierarchical Representations with Poincare Variational Auto-encoders, , 1901.06033; Nickel, M., Kiela, D., Poincare embeddings for learning hierarchical representations (2017) In NeurIPS, pp. 6338-6347; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples, , 1605.07277; Pattanaik, A., Tang, Z., Liu, S., Bommannan, G., Chowdhary, G., Robust deep reinforcement learning with adversarial attacks (2018) In AAMAS, pp. 2040-2042. , IFAAMAS; Schroff, F., Kalenichenko, D., Philbin, J., Facenet: A unified embedding for face recognition and clustering (2015) In CVPR, pp. 815-823; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., Inception-v4, inception-resnet and the impact of residual connections on learning (2017) In AAAI; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) In CVPR, pp. 2818-2826; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , 1312.6199; Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses, , 1705.07204; Xie, C., Zhang, Z., Zhou, Y., Bai, S., Wang, J., Ren, Z., Yuille, A.L., Improving transferability of adversarial examples with input diversity (2019) In CVPR, pp. 2730-2739; Yang, E., Liu, T., Deng, C., Tao, D., Adversarial examples for hamming space search (2018) IEEE Trans. Cybern.; Yuan, X., He, P., Zhu, Q., Li, X., Adversarial examples: Attacks and defenses for deep learning (2019) IEEE Trans. Neural Netw. Learn. Syst.","Deng, C.; School of Electronic Engineering, China; 电子邮件: chdeng@mail.xidian.edu.cn",,,IEEE Computer Society,"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2020",14 June 2020 through 19 June 2020,,162261,10636919,,PIVRE,,English,Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit,Conference Paper,Final,,Scopus,2-s2.0-85090405641
"Suya F., Chi J., Evans D., Tian Y.",57211192308;57205496174;57216599304;57207140400;,Hybrid batch attacks: Finding black-box adversarial examples with limited queries,2020,Proceedings of the 29th USENIX Security Symposium,,,,1327,1344,,16,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090276677&partnerID=40&md5=77790aa2ecc08afefadbb7629c2e4f69,"University of Virginia, United States","Suya, F., University of Virginia, United States; Chi, J., University of Virginia, United States; Evans, D., University of Virginia, United States; Tian, Y., University of Virginia, United States","We study adversarial examples in a black-box setting where the adversary only has API access to the target model and each query is expensive. Prior work on black-box adversarial examples follows one of two main strategies: (1) transfer attacks use white-box attacks on local models to find candidate adversarial examples that transfer to the target model, and (2) optimization-based attacks use queries to the target model and apply optimization techniques to search for adversarial examples. We propose hybrid attacks that combine both strategies, using candidate adversarial examples from local models as starting points for optimization-based attacks and using labels learned in optimization-based attacks to tune local models for finding transfer candidates. We empirically demonstrate on the MNIST, CIFAR10, and ImageNet datasets that our hybrid attack strategy reduces cost and improves success rates. We also introduce a seed prioritization strategy which enables attackers to focus their resources on the most promising seeds. Combining hybrid attacks with our seed prioritization strategy enables batch attacks that can reliably find adversarial examples with only a handful of queries. © 2020 by The USENIX Association. All Rights Reserved.",,Attack strategies; Black boxes; Local model; Optimization techniques; Prioritization; Target model; White box; Image enhancement,,,,,"Al-Dujaili, Abdullah, O'Reilly, Una-May, (2019) There are no bit parts for sign bits in black-box attacks, , arXiv:1902.06894; Alzantot, Moustafa, Sharma, Yash, Chakraborty, Supriyo, Srivastava, Mani, GenAttack: Practical black-box attacks with gradient-free optimization (2019) The Genetic and Evolutionary Computation Conference; Balduzzi, David, Frean, Marcus, Leary, Lennox, Lewis, JP, Ma, Kurt Wan-Duo, McWilliams, Brian, The shattered gradients problem: If resnets are the answer, then what is the question? (2017) International Conference on Machine Learning; Bhagoji, Arjun Nitin, He, Warren, Li, Bo, Song, Dawn, Exploring the space of black-box attacks on deep neural networks (2019) European Conference on Computer Vision; Brendel, Wieland, Rauber, Jonas, Bethge, Matthias, Decision-based adversarial attacks: Reliable attacks against black-box machine learning models (2018) International Conference on Learning Representations; Brunner, Thomas, Diehl, Frederik, Le, Michael Truong, Knoll, Alois, (2018) Guessing smart: Biased sampling for efficient black-box adversarial attacks, , arXiv:1812.09803; Carlini, Nicholas, Erlingsson, Ulfar, Papernot, Nicolas, (2018) Prototypical examples in deep learning: Metrics, characteristics, and utility, , https://openreview.net/forum?id=r1xyx3R9tQ; Carlini, Nicholas, Wagner, David, Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy; Chen, Jianbo, Jordan, Michael I, (2019) Boundary attack++: Query-efficient decision-based adversarial attack, , arXiv:1904.02144; Chen, Pin-Yu, Zhang, Huan, Sharma, Yash, Yi, Jinfeng, Hsieh, Cho-Jui, ZOO: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) 10th ACM Workshop on Artificial Intelligence and Security; Chen, Steven, Carlini, Nicholas, Wagner, David, (2019) Stateful detection of black-box adversarial attacks, , arXiv:1907.05587; Cheng, Minhao, Le, Thong, Chen, Pin-Yu, Yi, Jinfeng, Zhang, Huan, Hsieh, Cho-Jui, Query-efficient hard-label black-box attack: An optimization-based approach (2019) International Conference on Learning Representations; Cheng, Shuyu, Dong, Yinpeng, Pang, Tianyu, Su, Hang, Zhu, Jun, (2019) Improving black-box adversarial attacks with a transfer-based prior, , arXiv:1906.06919; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., ImageNet: A Large-Scale Hierarchical Image Database (2009) IEEE Conference on Computer Vision and Pattern Recognition; Dong, Yinpeng, Liao, Fangzhou, Pang, Tianyu, Su, Hang, Zhu, Jun, Hu, Xiaolin, Li, Jianguo, Boosting adversarial attacks with momentum (2018) IEEE Conference on Computer Vision and Pattern Recognition; Dong, Yinpeng, Pang, Tianyu, Su, Hang, Zhu, Jun, Evading defenses to transferable adversarial examples by translation-invariant attacks (2019) IEEE Conference on Computer Vision and Pattern Recognition; Goodfellow, Ian J, Shlens, Jonathon, Szegedy, Christian, Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations; Guo, Chuan, Gardner, Jacob R, You, Yurong, Wilson, Andrew Gordon, Weinberger, Kilian Q, Simple black-box adversarial attacks (2019) International Conference on Machine Learning; He, Kaiming, Zhang, Xiangyu, Ren, Shaoqing, Sun, Jian, Deep residual learning for image recognition (2016) IEEE Conference on Computer Vision and Pattern Recognition; Huang, Gao, Liu, Zhuang, Van Der Maaten, Laurens, Weinberger, Kilian Q, Densely connected convolutional networks (2017) IEEE Conference on Computer Vision and Pattern Recognition; Ilyas, Andrew, Engstrom, Logan, Athalye, Anish, Lin, Jessy, Black-box adversarial attacks with limited queries and information (2018) International Conference on Machine Learning, , July; Ilyas, Andrew, Engstrom, Logan, Madry, Aleksander, Prior convictions: Black-box adversarial attacks with bandits and priors (2019) International Conference on Learning Representations; Krizhevsky, Alex, Hinton, Geoffrey, (2009) Learning multiple layers of features from tiny images, , Technical Report; Kurakin, Alexey, Goodfellow, Ian, Bengio, Samy, Adversarial examples in the physical world (2016) ICLR Workshop; LeCun, Yann, (1998) The MNIST database of handwritten digits, , http://yann.lecun.com/exdb/mnist/; LeCun, Yann, Bottou, Léon, Bengio, Yoshua, Haffner, Patrick, Gradient-based learning applied to document recognition (1998) Proceedings of the IEEE, 86 (11), pp. 2278-2324; Li, Pengcheng, Yi, Jinfeng, Zhang, Lijun, Query-efficient black-box attack by active learning (2018) IEEE International Conference on Data Mining; Li, Yandong, Li, Lijun, Wang, Liqiang, Zhang, Tong, Gong, Boqing, Nattack: Learning the distributions of adversarial examples for an improved black-box attack on deep neural networks (2019) International Conference on Machine Learning; Liu, Yanpei, Chen, Xinyun, Liu, Chang, Song, Dawn, Delving into transferable adversarial examples and black-box attacks (2017) International Conference on Learning Representations; Madry, Aleksander, (2017) CIFAR10 adversarial examples challenge, , https://github.com/MadryLab/cifar10_challenge, July; Madry, Aleksander, (2017) MNIST adversarial examples challenge, , https://github.com/MadryLab/mnist_challenge, June; Madry, Aleksander, Makelov, Aleksandar, Schmidt, Ludwig, Tsipras, Dimitris, Vladu, Adrian, Towards deep learning models resistant to adversarial attacks (2018) International Conference on Learning Representations; Moon, Seungyong, An, Gaon, Song, Hyun Oh, Parsimonious black-box adversarial attacks via efficient combinatorial optimization (2019) International Conference on Machine Learning; Narodytska, Nina, Kasiviswanathan, Shiva Prasad, Simple black-box adversarial perturbations for deep networks (2017) CVPR Workshop; Papernot, Nicolas, McDaniel, Patrick, Goodfellow, Ian, (2016) Transferability in machine learning: from phenomena to black-box attacks using adversarial samples, , arXiv:1605.07277; Papernot, Nicolas, McDaniel, Patrick, Goodfellow, Ian, Jha, Somesh, Berkay Celik, Z, Swami, Ananthram, Practical black-box attacks against machine learning (2017) ACM Asia Conference on Computer and Communications Security; Simonyan, Karen, Zisserman, Andrew, Very deep convolutional networks for large-scale image recognition (2015) International Conference on Learning Representations; Suya, Fnu, Tian, Yuan, Evans, David, Papotti, Paolo, Query-limited black-box attacks to classifiers (2017) NIPS Workshop in Machine Learning and Computer Security; Szegedy, Christian, Zaremba, Wojciech, Sutskever, Ilya, Bruna, Joan, Erhan, Dumitru, Goodfellow, Ian, Fergus, Rob, Intriguing properties of neural networks (2014) International Conference on Learning Representations; Taori, Rohan, Kamsetty, Amog, Chu, Brenton, Vemuri, Nikita, (2018) Targeted adversarial examples for black box audio systems, , arXiv:1805.07820; Tramèr, Florian, Kurakin, Alexey, Papernot, Nicolas, Goodfellow, Ian, Boneh, Dan, McDaniel, Patrick, Ensemble adversarial training: Attacks and defenses (2018) International Conference on Learning Representations; Tsipras, Dimitris, Santurkar, Shibani, Engstrom, Logan, Turner, Alexander, Madry, Aleksander, Robustness may be at odds with accuracy (2019) International Conference on Learning Representations; Tu, Chun-Chen, Ting, Paishun, Chen, Pin-Yu, Liu, Sijia, Zhang, Huan, Yi, Hsieh Cho-Jui, Jinfeng, Cheng, Shin-Ming, Autozoom: Autoencoder-based zeroth order optimization method for attacking black-box neural networks (2018) AAAI Conference on Artificial Intelligence; Wierstra, Daan, Schaul, Tom, Peters, Jan, Schmidhuber, Juergen, Natural evolution strategies (2008) IEEE Congress on Evolutionary Computation; Xie, Cihang, Zhang, Zhishuai, Wang, Jianyu, Zhou, Yuyin, Ren, Zhou, Yuille, Alan, Improving transferability of adversarial examples with input diversity (2019) IEEE Conference on Computer Vision and Pattern Recognition",,,ByteDance;et al.;Facebook;Microsoft;Salesforce;USENIX Association,USENIX Association,29th USENIX Security Symposium,12 August 2020 through 14 August 2020,,162471,,9.78E+12,,,English,Proc. USENIX Secur. Symp.,Conference Paper,Final,,Scopus,2-s2.0-85090276677
[无可用作者姓名],[无可用的作者 ID],"13th International Conference on Knowledge Science, Engineering and Management, KSEM 2020",2020,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),12275 LNAI,,,,,985,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090093089&partnerID=40&md5=a8e4e1299d6d61058f0b29a566f633a0,,,"The proceedings contain 85 papers. The special focus in this conference is on Knowledge Science, Engineering and Management. The topics include: Robust Sequence Embedding for Recommendation; deep Generative Recommendation with Maximizing Reciprocal Rank; spatio-Temporal Attentive Network for Session-Based Recommendation; category-Level Adversarial Network for Cross-Domain Sentiment Classification; seeds Selection for Influence Maximization Based on Device-to-Device Social Knowledge by Reinforcement Learning; CIFEF: Combining Implicit and Explicit Features for Friendship Inference in Location-Based Social Networks; a Knowledge Enhanced Ensemble Learning Model for Mental Disorder Detection on Social Media; constrained Viral Marketing in Social Networks; a Multi-source Self-adaptive Transfer Learning Model for Mining Social Links; an Incremental Learning Network Model Based on Random Sample Distribution Fitting; multi-hop Syntactic Graph Convolutional Networks for Aspect-Based Sentiment Classification; a Matching-Integration-Verification Model for Multiple-Choice Reading Comprehension; how to Interact and Change? Abstractive Dialogue Summarization with Dialogue Act Weight and Topic Change Info; Chinese Text Classification via Bidirectional Lattice LSTM; MG-BERT: A Multi-glosses BERT Model for Word Sense Disambiguation; top Personalized Reviews Set Selection Based on Subject Aspect Modeling; SCX-SD: Semi-supervised Method for Contextual Sarcasm Detection; end-to-End Multi-task Learning for Allusion Detection in Ancient Chinese Poems; defense of Word-Level Adversarial Attacks via Random Substitution Encoding; document-Improved Hierarchical Modular Attention for Event Detection; parameter Optimization and Weights Assessment for Evidential Artificial Immune Recognition System; fine-Tuned Transformer Model for Sentiment Analysis; An Algorithm for Emotion Evaluation and Analysis Based on CBOW; predicting Crowdsourcing Worker Performance with Knowledge Tracing; watermarking Neural Network with Compensation Mechanism; information Diffusion Prediction with Personalized Graph Neural Networks.",,,,,,,,,Li G.Shen H.T.Yuan Y.Wang X.Liu H.Zhao X.,,Springer,"13th International Conference on Knowledge Science, Engineering and Management, KSEM 2020",28 August 2020 through 30 August 2020,,243999,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Review,Final,,Scopus,2-s2.0-85090093089
"Gupta R., Sharma A., Kumar A.",57220802732;57220907172;57210413959;,Super-Resolution using GANs for Medical Imaging,2020,Procedia Computer Science,173,,,28,35,,2,10.1016/j.procs.2020.06.005,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089996978&doi=10.1016%2fj.procs.2020.06.005&partnerID=40&md5=cbdfd16ec62d031b5b782fb9261ea6f8,"Department of Computer Science, Maharaja Agrasen Institute of Technology, Rohini, Sector 22, PSP Area, Delhi, 110086, India","Gupta, R., Department of Computer Science, Maharaja Agrasen Institute of Technology, Rohini, Sector 22, PSP Area, Delhi, 110086, India; Sharma, A., Department of Computer Science, Maharaja Agrasen Institute of Technology, Rohini, Sector 22, PSP Area, Delhi, 110086, India; Kumar, A., Department of Computer Science, Maharaja Agrasen Institute of Technology, Rohini, Sector 22, PSP Area, Delhi, 110086, India","Generative Adversarial Models (GANs) have been quite popular and are currently and active area of research. They can be used for generative new data and study adversarial samples and attacks. We have used the similar approach to apply super-resolution to medical images. In Radiology MRI is a commonly used method to produce medical imaging but the limitations of lab equipment and health hazard of being in an MRI radiation environment to obtain good quality scans lead to lower quality scans and also it takes a lot of time to get a high-resolution data. This problem can be solved by using super-resolution using deep learning as a post-processing step to improve the resolution of the scans. Super-resolution is a process of generating higher resolution images from lower resolution data. For this, we are proposing a generative adversarial network architecture which is a dual neural network designed to generate lifelike images. In this deep learning algorithm, two neural networks compete with each other to improve alternatively. Given a training set, this technique learns to generate new data with the same statistics as the training set. To apply this technique to our problem statement we are using generator as the network to improve the resolution and discriminator as a network to train generator better. We used transfer learning in our generative neural network and training our discriminator from scratch and using the perceptual loss [1] to train our network. This will help in improving the performance of the network. We are using Lung MRI scans of tuberculosis with a set of 216 MRI samples containing around 60-130 channels each and each channel having 512x512 dimensions. © 2020 The Authors. Published by Elsevier B.V.",Artificial Intelligence; Computer Vision; Deep Learning; Generative Adversarial Network; Magnetic resonance imaging; Super resolution; Transfer Learning,Deep learning; Discriminators; Health hazards; Intelligent computing; Learning algorithms; Magnetic resonance imaging; Medical imaging; Network architecture; Optical resolving power; Transfer learning; Dual neural networks; High resolution data; Higher resolution images; Lower resolution; Post processing; Problem statement; Radiation environments; Super resolution; Neural networks,,,,,"Johnson, J., Alahi, A., Fei-Fei, L., (2016) Perceptual Losses for Real-Time Style Transfer and Super-Resolution. Computer Vision-ECCV 2016 Lecture Notes in Computer Science, pp. 694-711; Yang, X., Zhant, S., Hu, C., Liang, Z., Xie, D., Super-resolution of medical image using representation learning (2016) 2016 8th International Conference on Wireless Communications & Signal Processing (WCSP); Lyu, Q., You, C., Hongming, S., Wang, G., (2018) Super-resolution Mri Through Deep Learning, , https://arxiv.org/abs/1810.06776, October 16. Retrieved November 25, 2019; You, C., Li, G., Zhang, Y., Zhang, X., Shan, H., Li, M., Wang, G., CT Super-resolution GAN Constrained by the Identical, Residual, and Cycle Learning Ensemble (GAN-CIRCLE) (2019) Ieee Transactions on Medical Imaging, pp. 1-2; Shende, P., Pawar, M., Kakde, S., A Brief Review on: MRI Images Reconstruction using GAN (2019) 2019 International Conference on Communication and Signal Processing (ICCSP); Chen, Y., Xie, Y., Zhou, Z., Shi, F., Christodoulou, A.G., Li, D., Brain MRI super resolution using 3D deep densely connected neural networks (2018) 2018 Ieee 15th International Symposium on Biomedical Imaging (ISBI 2018); Pham, C.-H., Ducournau, A., Fablet, R., Rousseau, F., Brain MRI super-resolution using deep 3D convolutional networks (2017) 2017 Ieee 14th International Symposium on Biomedical Imaging (ISBI 2017); Ronneberger, O., Fischer, P., Brox, T., U-Net: Convolutional Networks for Biomedical Image Segmentation (2015) Lecture Notes in Com-puter Science Medical Image Computing and Computer-Assisted Intervention-MICCAI 2015, pp. 234-241; He, K., Zhang, X., Ren, S., Sun, J., Deep Residual Learning for Image Recognition (2016) 2016 Ieee Conference on Computer Vision and Pattern Recognition (CVPR); Wang, C., Xu, C., Wang, C., Tao, D., Perceptual Adversarial Networks for Image-to-Image Transformation (2018) Ieee Transactions on Image Processing, 27 (8), pp. 4066-4079; Simonyan, K., Zisserman, A., (2015) Very Deep Convolutional Networks for Large-Scale Image Recognition, , https://arxiv.org/abs/1409.1556, April 10. Retrieved November 25, 2019; Smith, L.N., Topin, N., Super-convergence: Very fast training of neural networks using large learning rates (2019) Artificial Intelligence and Machine Learning for Multi-Domain Operations Applications, p. 1100612. , Tien Pham, International Society for Optics and Photonics; Howard, J., Ruder, S., (2018) Universal Language Model Fine-tuning for Text Classification, , arXiv preprint arXiv:1801.06146","Sharma, A.; Department of Computer Science, Rohini, Sector 22, PSP Area, India; 电子邮件: anurag.sharma.2p@gmail.com",Gupta N.Grover P.S.Piuri V.Balas V.E.Liu C.M.,CSIR;DRDO;EIL;et al.;MATIC Networks;TCS,Elsevier B.V.,"1st International Conference on Smart Sustainable Intelligent Computing and Applications, ICITETM 2020",4 February 2020 through 6 February 2020,,161763,18770509,,,,English,Procedia Comput. Sci.,Conference Paper,Final,"All Open Access, Gold",Scopus,2-s2.0-85089996978
"Jin L., Tan F., Jiang S.",57218592089;24544940700;57199661979;,Generative Adversarial Network Technologies and Applications in Computer Vision,2020,Computational Intelligence and Neuroscience,2020,,1459107,,,,7,10.1155/2020/1459107,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089707988&doi=10.1155%2f2020%2f1459107&partnerID=40&md5=18e7737bfd38575e9d2ff01753fce6b7,"College of Information Engineering, Shanghai Maritime University, Shanghai, 201306, China","Jin, L., College of Information Engineering, Shanghai Maritime University, Shanghai, 201306, China; Tan, F., College of Information Engineering, Shanghai Maritime University, Shanghai, 201306, China; Jiang, S., College of Information Engineering, Shanghai Maritime University, Shanghai, 201306, China","Computer vision is one of the hottest research fields in deep learning. The emergence of generative adversarial networks (GANs) provides a new method and model for computer vision. The idea of GANs using the game training method is superior to traditional machine learning algorithms in terms of feature learning and image generation. GANs are widely used not only in image generation and style transfer but also in the text, voice, video processing, and other fields. However, there are still some problems with GANs, such as model collapse and uncontrollable training. This paper deeply reviews the theoretical basis of GANs and surveys some recently developed GAN models, in comparison with traditional GAN models. The applications of GANs in computer vision include data enhancement, domain transfer, high-quality sample generation, and image restoration. The latest research progress of GANs in artificial intelligence (AI) based security attack and defense is introduced. The future development of GANs in computer vision is also discussed at the end of the paper with possible applications of AI in computer vision. © 2020 Lianchao Jin et al.",,"Computer networks; Deep learning; Image enhancement; Image reconstruction; Learning algorithms; Video signal processing; Adversarial networks; Applications of AI; Data enhancement; Domain transfers; Image generations; Sample generations; Security attacks; Video processing; Computer vision; biomimetics; computer; facial expression; human; image processing; vision; Biomimetics; Computers; Facial Expression; Humans; Image Processing, Computer-Assisted; Neural Networks, Computer; Vision, Ocular",,,,,"Pan, Z., Yu, W., Yi, X., Khan, A., Yuan, F., Zheng, Y., Recent progress on generative adversarial networks (GANs): A survey (2019) IEEE Access, 7, pp. 36322-36333. , 2-s2.0-85063950837; Liu, S., Face Aging with Contextual Generative Adversarial Nets, pp. 82-90. , Proceedings of the ACM November 2017 Singapore; Hu, D., Wang, L., Jiang, W., Zheng, S., Li, B., A novel image steganography method via deep convolutional generative adversarial networks (2018) IEEE Access, 6, pp. 38303-38314. , 2-s2.0-85049424715; Odena, A., Olah, C., Shlens, J., Conditional Image Synthesis with Auxiliary Classifier GANs, 70, pp. 2642-2651. , Proceedings of the 34th International Conference Machine Learning (PMLR) 2017 Sydney, Australia https://arxiv.org/abs/1610.09585; Kim, K., Myung, H., Autoencoder-combined generative adversarial networks for synthetic image data generation and detection of jellyfish swarm (2018) IEEE Access, 6, pp. 54207-54214. , 2-s2.0-85054627843; Li, N., Zheng, Z., Zhang, S., Yu, Z., Zheng, H., Zheng, B., The synthesis of unpaired underwater images using a multistyle generative adversarial network (2018) IEEE Access, 6, pp. 54241-54257. , 2-s2.0-85053613290; Arjovsky, M., Bottou, L., (2017) Towards Principled Methods for Training Generative Adversarial Networks, , https://arxiv.org/abs/1701.04862; Mirza, M., Osindero, S., (2014) Conditional Generative Adversarial Nets, pp. 2672-2680. , https://arxiv.org/abs/1411.1784; Weng, Y., Zhou, H., Data augmentation computing model based on generative adversarial network (2019) IEEE Access, 7, pp. 64223-64233. , 2-s2.0-85066751859; Frid-Adar, M., Klang, E., Amitai, M., Goldberger, J., Greenspan, H., Synthetic Data Augmentation Using GAN for Improved Liver Lesion Classification, pp. 289-293. , Proceedings of the 2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018) April 2018 Washington, DC, USA 2-s2.0-85048075788; Liu, H., Yuan, J., Zheng, Y., (2015) Computer Vision Algorithms and Intelligent Vehicle Applications, , Beijing, China Electronic Industry Press; Chen, Y., Wu, J., Cui, M., Automatic Classification and Detection of Oranges Based on Computer Vision, pp. 1551-1556. , Proceedings of the 2018 IEEE 4th International Conference on Computer and Communications (ICCC) December 2018 Chengdu, China 2-s2.0-85070807909; Ma, J., Zhou, Z., Wang, B., An, Z., Hard Ship Detection Via Generative Adversarial Networks, pp. 3961-3965. , Proceedings of the 2019 Chinese Control and Decision Conference (CCDC) June 2019 Nanchang, China 2-s2.0-85073112074; Eskimez, S.E., Koishida, K., Speech Super Resolution Generative Adversarial Network, pp. 3717-3721. , Proceedings of the ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) May 2019 Brighton, UK 2-s2.0-85068990002; Wang, H., Wu, W., Su, Y., Duan, Y., Wang, P., Image Super-resolution Using A Improved Generative Adversarial Network, pp. 312-315. , Proceedings of the 2019 IEEE 9th International Conference on Electronics Information and Emergency Communication (ICEIEC) July 2019 Beijing, China 2-s2.0-85071072253; Lucas, A., López-Tapia, S., Molina, R., Katsaggelos, A.K., Generative adversarial networks and perceptual losses for video super-resolution (2019) IEEE Transactions on Image Processing, 28 (7), pp. 3312-3327. , 2-s2.0-85065998195; Anwar, S., Huynh, C.P., Porikli, F., Image deblurring with a class-specific prior (2019) IEEE Transactions on Pattern Analysis and Machine Intelligence, 41 (9), pp. 2112-2130. , 2-s2.0-85049776152; Li, Y., Liu, D., Li, H., Li, L., Li, Z., Wu, F., Learning a convolutional neural network for image compact-resolution (2019) IEEE Transactions on Image Processing, 28 (3), pp. 1092-1107. , 2-s2.0-85054366205; Shi, T., Yuan, Y., Fan, C., Zou, Z., Shi, Z., Liu, Y., Face-to-parameter Translation for Game Character Auto-creation, , Proceedings of the 2019 IEEE/CVF International Conference on Computer Vision (ICCV) November 2019 Seoul, South Korea; Hong, Y., Hwang, U., Yoo, J., How generative adversarial networks and their variants work: An overview (2017) ACM Computing Surveys, 52 (1). , 2-s2.0-85062420736; Voulodimos, A., Doulamis, N., Doulamis, A., Protopapadakis, E., Deep learning for computer vision: A brief review (2018) Computational Intelligence and Neuroscience, 2018, p. 13. , 7068349 2-s2.0-85042148149; Yamins, D.L.K., Dicarlo, J.J., Using goal-driven deep learning models to understand sensory cortex (2016) Nature Neuroscience, Perspective, 19 (3), pp. 356-365. , 2-s2.0-84975760699; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Generative Adversarial Nets, pp. 2672-2680. , Proceedings of the 2014 Conference on Advances in Neural Information Processing Systems 27 2014 Curran Associates, Inc. Montreal, Canada; Salakhutdinov, R., Hinton, G., Deep Boltzmann machines (2009) Journal of Machine Learning Research, 5 (2), pp. 1967-2006; Jiang, L., Zhang, H., Cai, Z., A novel Bayes model: Hidden naïve Bayes (2009) IEEE Transactions on Knowledge and Data Engineering, 21 (10), pp. 1361-1371. , 2-s2.0-70349337297; Rabiner, L.R., A tutorial on hidden Markov models and selected applications in speech recognition (1989) Proceedings of the IEEE, 77 (2), pp. 267-296. , 2-s2.0-0024610919; Pu, Y., Variational Autoencoder for Deep Learning of Images,labels and Captions, pp. 2352-2360. , Proceedings of the Conference and Workshop on Neural Information Processing Systems December 2016 Barcelona, Spain https://arxiv.org/pdf/1609.08976; Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Li, F.F., ImageNet: A Large-scale Hierarchical Image Database, pp. 248-255. , Proceedings of the 2009 IEEE Conference on Computer Vision and Pattern Recognition June 2009 Miami, FL, USA; Berthelot, D., Schumm, T., Metz, L., (2017) BEGAN: Boundary Equilibrium Generative Adversarial Networks, , http://arxiv.org/abs/1703.10717; Brock, A., Donahue, J., Simonyan, K., (2018) Large Scale GAN Training for High Fidelity Natural Image Synthesis, , http://arxiv.org/abs/1809.11096; Karras, T., Laine, S., Aila, T., A style-based generator architecture for generative adversarial networks (2020) IEEE Transactions on Pattern Analysis and Machine Intelligence, p. 1; Antipov, G., Baccouche, M., Dugelay, J.-L., Face Aging with Conditional Generative Adversarial Networks, , Proceedings of the 2017 IEEE International Conference on Image Processing (ICIP) September 2017 Beijing, China 2-s2.0-85045313026; Lecun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), pp. 436-444. , 2-s2.0-84930630277; Goodfellow, I.J., Generative Adversarial Nets, pp. 2672-2680. , Proceedings of the Neural Information Processing Systems December 2014 Montreal, Quebec; He, D., Chen, W., Wang, L., Liu, T.Y., A Game-theoretic Machine Learning Approach for Revenue Maximization in Sponsored Search, pp. 206-212. , Proceedings of the International Joint Conference on Artificial Intelligence December 2014 Gold Coast, Australia; Goodfellow, I., (2016) Nips 2016 Tutorial: Generative Adversarial Networks, , http://arxiv.org/abs/1701.00160; Wang, K.-F., Chao, G., Duan, Y.-J., Lin, Y.-L., Zheng, X.-H., Wang, F.-Y., Generative adversarial networks: The state of the art and beyond (2013) Acta Automatica Sinica, 43 (3), pp. 321-332; Cao, Y.J., Jia, L.L., Chen, Y.X., Recent advances of generative adversarial networks in computer vision (2018) IEEE Access, 7, p. 1. , 2-s2.0-85058871830; Arjovsky, M., Chintala, S., Bottou, L., (2017) Wasserstein GAN, , https://arxiv.org/abs/1701.07875; Wang, C., Xu, C., Wang, C., Tao, D., Perceptual adversarial networks for image-to-image transformation (2018) IEEE Transactions on Image Processing, 27 (8), pp. 4066-4079. , 2-s2.0-85046801720; Chen, X., Duan, Y., Houthooft, R., Schulman, J., Sutskever, I., Abbeel, P., InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets, pp. 2172-2180. , Proceedings of the Neural Information Processing Systems September 2016 Barcelona, Spain; Mao, X., Li, Q., Xie, H., Lau, R.Y.K., Wang, Z., Smolley, S.P., Least Squares Generative Adversarial Networks, pp. 2813-2821. , Proceedings of the 2017 IEEE International Conference on Computer Vision (ICCV) October 2018 Venice, Italy 2-s2.0-85041908569; Kodali, N., Abernethy, J., Hays, J., Kira, Z., (2018) On Convergence and Stability of GANs, , https://arxiv.org/abs/1705.07215; Shi, Y., Li, Q., Zhu, X.X., BFGAN-building Footprint Extraction from Satellite Images, pp. 1-4. , Proceedings of the 2019 Joint Urban Remote Sensing Event (JURSE) May 2019 Vannes, France 2-s2.0-85072051590; Wang, J., Yang, Z., Zhang, J., Zhang, Q., Chien, W.-T.K., AdaBalGAN: An improved generative adversarial network with imbalanced learning for wafer defective pattern recognition (2019) IEEE Transactions on Semiconductor Manufacturing, 32 (3), pp. 310-319. , 2-s2.0-85069785438; Li, Y., Wang, J., Zhang, X., Cao, Y., FittingGAN: Fitting Image Generation Based on Conditional Generative Adversarial Networks, pp. 741-745. , Proceedings of the 2019 14th International Conference on Computer Science & Education (ICCSE) August 2019 Toronto, Canada 2-s2.0-85073250993; Zhang, H., Xu, T., Li, H., StackGAN++: Realistic image synthesis with stacked generative adversarial networks (2019) IEEE Transactions on Pattern Analysis and Machine Intelligence, 41 (8), pp. 1947-1962. , 2-s2.0-85049955346; Metz, L., Poole, B., Pfau, D., Sohl-Dickstein, (2016) Unrolled Generative Adversarial Networks, , https://arxiv.org/abs/1611.02163; Li, D., Chen, D., Jin, B., Shi, L., Goh, J., Ng, N.S., MAD-GAN: Multivariate anomaly detection for time series data with generative adversarial networks (2019) Artificial Neural Networks and Machine Learning-ICANN 2019: Text and Time Series, , Berlin, Germany Springer 2-s2.0-85072871136; Zhang, H., Xu, T., Li, H., StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks, pp. 5908-5916. , Proceedings of the 2017 IEEE International Conference on Computer Vision (ICCV) October 2017 Venice, Italy 2-s2.0-85040306596; Juefei-Xu, F., Boddeti, V., Savvides, M., (2017) Gang of GANs: Generative Adversarial Networks with Maximum Margin Ranking, , https://arxiv.org/abs/1704.04865; Shen, Y., Gu, J., Tang, X., Zhou, B., (2019) Interpreting the Latent Space of GANs for Semantic Face Editing, , https://arxiv.org/abs/1907.10786; Reed, S., Akata, Z., Mohan, S., Tenka, S., Schiele, B., Lee, H., Learning What and Where to Draw, pp. 217-225. , Proceedings of the 30th International Conference on Neural Inference Processing System 2016 Barcelona, Spain; Reed, S., Akata, Z., Yan, X., Logeswaran, L., Schiele, B., Lee, H., Generative Adversarial Text-to-image Synthesis, pp. 1060-1069. , Proceedings of the 33rd International Conference on Machine Learning June 2016 New York, NY, USA; Chen, X., Duan, Y., Houthooft, R., Schulman, J., Sutskever, I., Abbeel, P., InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets, pp. 2172-2180. , Proceedings of the 2016 Neural Information Processing Systems 2016 Department of Information Technology IMEC, Barcelona, Spain; Frid-Adar, M., Diamant, I., Klang, M.E., Amitai, H.J., Goldberger, J., Greenspan, H., GAN-based synthetic medical image augmentation for increased CNN performance in liver lesion classification (2018) Neurocomputing, 321, pp. 321-331. , 2-s2.0-85054131811; Weng, Y., Zhou, H., Data augmentation computing model based on generative adversarial network (2019) IEEE Access, 7, p. 1. , 2-s2.0-85066751859; Haradal, S., Hayashi, H., Uchida, S., Biosignal Data Augmentation Based on Generative Adversarial Networks, pp. 368-371. , Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society July 2018 Honolulu, HI, USA 2-s2.0-85056652977; Harada, S., Hayashi, H., Uchida, S., Biosignal generation and latent variable analysis with recurrent generative adversarial networks (2019) IEEE Access, 7. , 2-s2.0-85073807712; Mahdizadehaghdam, S., Panahi, A., Krim, H., Sparse Generative Adversarial Network, , Proceedings of the 2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW) October 2019 Seoul, South Korea; Lucas, A., Katsaggelos, A.K., Lopez-Tapuia, S., Molina, R., Generative Adversarial Networks and Perceptual Losses for Video Super-resolution, pp. 51-55. , Proceedings of the 2018 25th IEEE International Conference on Image Processing (ICIP) October 2018 Athens, Greece 2-s2.0-85062918260; Deng, Y., Loy, C.C., Tang, X., Aesthetic-driven Image Enhancement by Adversarial Learning, pp. 870-878. , Proceedings of the 2018 ACM Multimedia Conference on Multimedia Conference October 2018 Seoul, Republic of Korea 2-s2.0-85058218421; Radford, A., Metz, L., Chintala, S., (2015) Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks, , https://arxiv.org/pdf/1511.06434; Fergus, R., Fergus, R., Fergus, R., Fergus, R., Deep Generative Image Models Using A Laplacian Pyramid of Adversarial Networks, pp. 1486-1494. , Proceedings of the International Conference on Neural Information Processing Systems 2015 Montreal, Canada; Zhang, H., Goodfellow, I.J., Metaxas, D., Odena, A., (2018) Self-attention Generative Adversarial Networks, , https://arxiv.org/abs/1805.08318; Dong, C., Loy, C.C., He, K., Tang, X., Learning a deep convolutional network for image super-resolution (2014) Lecture Notes in Computer Science, , Berlin, Germany Springer; Huang, G., Liu, Z., Van Der Maaten, L., Kilian, W., Densely Connected Convolutional Networks, , Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) July 2017 Honolulu, HI, USA 2-s2.0-85035343801; He, K., Zhang, X., Ren, S., Sun, J., Deep Residual Learning for Image Recognition, pp. 770-778. , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Las Vegas, NV, USA June 2016 2-s2.0-84986274465; Gan, Y., Gong, J., Ye, M., Qian, Y., Liu, K., Zhang, S., GANs with multiple constraints for image translation (2018) Complexity, 2018, p. 12. , 4613935 2-s2.0-85059896481; Li, Z., Wang, W., Zhao, Y., Image translation by domain-adversarial training (2018) Computational Intelligence and Neuroscience, 2018, p. 11. , 8974638 2-s2.0-85049863854; Isola, P., Image-to-image Translation with Conditional Adversarial Networks, pp. 5967-5976. , Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) July 2017 Honolulu, HI, USA 2-s2.0-85030759098; Zhu, J.Y., Park, T., Isola, P., Efros, A.A., Unpaired Image-to-image Translation Using Cycle-consistent Adversarial Networks, pp. 2242-2251. , Proceedings of the 2017 IEEE International Conference on Computer Vision (ICCV) October 2017 Venice, Italy 2-s2.0-85041892358; Kim, T., Cha, M., Kim, H., Lee, J.K., Kim, J., Learning to Discover Cross-domain Relations with Generative Adversarial Networks, pp. 1857-1865. , Proceedings of the 34th International Conference on Machine Learning August 2017 Sydney, Australia; Choi, Y., Choi, M., Kim, M., Ha, J.-W., Kim, S., Choo, J., StarGAN: Unified Generative Adversarial Networks for Multi-domain Image-to-image Translation, pp. 8789-8797. , Proceedings of the 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition June 2018 Salt Lake City, UT, USA 2-s2.0-85062854894; Taigman, Y., Polyak, A., Wolf, L., Unsupervised Cross-domain Image Generation, , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) November 2016 Taipei, Taiwan https://arxiv.org/pdf/1611.02200; Cherian, A., Sullivan, A., Sem-GAN: Semantically-consistent Image-to-image Translation, , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) July 2018 Las Vegas, NV, USA https://arxiv.org/abs/1807.04409; Dong, J., Yin, R., Sun, X., Li, Q., Yang, Y., Qin, X., Inpainting of remote sensing SST images with deep convolutional generative adversarial network (2019) IEEE Geoscience and Remote Sensing Letters, 16 (2), pp. 173-177. , 2-s2.0-85054490519; He, C., Zhang, Z., Restoration of Underwater Distorted Image Sequence Based on Generative Adversarial Network, pp. 866-870. , Proceedings of the 2019 IEEE 8th Joint International Information Technology and Artificial Intelligence Conference (ITAIC) May 2019 Chongqing, China 2-s2.0-85071100855; Kupyn, O., Budzan, V., Mykhailych, M., Mishkin, D., Matas, J., DeblurGAN: Blind Motion Deblurring Using Conditional Adversarial Networks, pp. 8183-8192. , Proceedings of the 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition June 2018 Salt Lake City, UT, USA 2-s2.0-85056760291; Kupyn, O., Martyniuk, T., Wu, J., Wang, Z., DeblurGAN-v2: Deblurring (Orders-of-magnitude) Faster and Better, , Proceedings of the 2019 IEEE/CVF International Conference on Computer Vision (ICCV) October 2019 Seoul, South Korea; Huang, R., Zhang, S., Li, T., He, R., Beyond Face Rotation: Global and Local Perception GAN for Photorealistic and Identity Preserving Frontal View Synthesis, pp. 2458-2467. , Proceedings of the 2017 IEEE International Conference on Computer Vision (ICCV) October 2017 Venice, Italy 2-s2.0-85041900166; Yeh, R.A., Chen, C., Lim, T.Y., Schwing, A.G., Hasegawa-Johnson, M., Do, M.N., Semantic Image Inpainting with Deep Generative Models, pp. 6882-6890. , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) July 2017 Honolulu, HI, USA 2-s2.0-85042693344; Pathak, D., Krähenbuhl, P., Donahue, J., Darrell, T., Efros, A.A., Context Encoders: Feature Learning by Inpainting, pp. 2536-2544. , Proceedings of the 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Juny 2016 Las Vegas, NV, USA 2-s2.0-84986294165; Demir, U., Unal, G., Patch-based Image Inpainting with Generative Adversarial Networks, , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) June 2018 Salt Lake City, UT, USA https://arxiv.org/abs/1803.07422; Abadi, M., Andersen, D., (2016) Learning to Protect Communications with Adversarial Neural Cryptography, , https://arxiv.org/abs/1610.06918; Zhang, H., Guo, Y., Li, T., Multifeature named entity recognition in information security based on adversarial learning (2019) Security and Communication Networks, 2019, p. 9. , 6417407 2-s2.0-85062789635; Yin, D., Yang, Q., GANs based density distribution privacy-preservation on mobility data (2018) Security and Communication Networks, 2018, p. 13. , 9203076 2-s2.0-85058896766; Abadi, M., Andersen, D., Learning to Protect Communications with Adversarial Neural Cryptography, 15. , Proceedings of the ICLR 2017 April 2017 Toulon, France; Zenati, H., Foo, C., Lecouat, B., Manek, G., Chandrasekhar, V., (2018) Efficient GAN-based Anomaly Detection, , https://arxiv.org/abs/1802.06222; Feng, J., Cai, Q.-Z., Zhou, Z.-H., (2019) Learning to Confuse: Generating Training Time Adversarial Data with Auto-encoder, , https://arxiv.org/abs/1905.09027","Tan, F.; College of Information Engineering, China; 电子邮件: fxtan@shmtu.edu.cn",,,Hindawi Limited,,,,,16875265,,,32802024,English,Comput. Intell. Neurosci.,Review,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85089707988
[无可用作者姓名],[无可用的作者 ID],"5th International Conference on Information Systems Security and Privacy, ICISSP 2019",2020,Communications in Computer and Information Science,1221 CCIS,,,,,425,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088262301&partnerID=40&md5=989598aeb94f942204f68e9074ed8243,,,"The proceedings contain 19 papers. The special focus in this conference is on Information Systems Security and Privacy. The topics include: Protection of User-Defined Sensitive Attributes on Online Social Networks Against Attribute Inference Attack via Adversarial Data Mining; user Behavioral Biometrics and Machine Learning Towards Improving User Authentication in Smartphones; threat Modeling and Attack Simulations of Connected Vehicles: Proof of Concept; the Security of the Speech Interface: A Modelling Framework and Proposals for New Defence Mechanisms; hypervisor Memory Introspection and Hypervisor Based Malware Honeypot; Guidelines and Tool Support for Building a Cybersecurity Awareness Program for SMEs; analysing the Provenance of IoT Data; improving Interoperability in Multi-domain Enterprise Right Management Applications; fine-Grained Access Control for Querying Over Encrypted Document-Oriented Database; next Generation Information Warfare: Rationales, Scenarios, Threats, and Open Issues; information Technology Consulting Firms’ Readiness for Managing Information Security Incidents; Evaluation of Side-Channel Key-Recovery Attacks on LoRaWAN End-Device; black-Box Attacks via the Speech Interface Using Linguistically Crafted Input; proposal and Performance Evaluation of an Order-Specified Aggregate Authority-Transfer Signature; context-Aware Software-Defined Networking for Automated Incident Response in Industrial Networks; Transparency Enhancing Tools and the GDPR: Do They Match?; user Study of the Effectiveness of a Privacy Policy Summarization Tool.",,,,,,,,,Mori P.Furnell S.Camp O.,,Springer,"5th International Conference on Information Systems Security and Privacy, ICISSP 2019",23 February 2019 through 25 February 2019,,241639,18650929,9.78E+12,,,English,Commun. Comput. Info. Sci.,Conference Review,Final,,Scopus,2-s2.0-85088262301
Szandała T.,57188741703;,Using Convolutional Network Visualisation to Determine the Most Significant Pixels,2020,Advances in Intelligent Systems and Computing,1173 AISC,,,626,632,,,10.1007/978-3-030-48256-5_61,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086181558&doi=10.1007%2f978-3-030-48256-5_61&partnerID=40&md5=f81d30b7d576e8eaa386e9c09e62b9dd,"Wroclaw University of Science and Technology, Wroclaw, Poland","Szandała, T., Wroclaw University of Science and Technology, Wroclaw, Poland","Over the last years, Deep Neural Network models have been recognized as successful in solving many complex problems. However, these methods are mostly focused on the efficiency of final results and rarely provide sufficient evidence and details on factors that contribute to their outcomes This is why a growing demand for analysis techniques appeared. Thanks to visualisation techniques we can if network works as expected or even improve output of given model if possible. Moreover we can use these methods as optimization technique to boost network’s performance but pruning less important neurons. Finally, if we know how a given model works we can prepare a disruption to its work process. This paper shows how we can combine Class Activation Map with feature map to determine a few of the most contributing pixels for given input and modify them to perform an adversarial attack. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2020.","Convolutional networks; Deep learning, adversarial attacks; Deep neural networks; Visualisation",Deep neural networks; Technology transfer; Visualization; Analysis techniques; Complex problems; Convolutional networks; Feature map; Growing demand; Neural network model; Optimization techniques; Work process; Pixels,,,,,"Boureau, Y.-L., Ponce, J., Lecun, Y., A theoretical analysis of feature pooling in visual recognition (2010) Proceedings of the 27Th International Conference on Machine Learning (ICML-10); Szyc, K., An impact of different images color spaces on the efficiency of convolutional neural networks (2019) International Conference on Dependability and Complex Systems, , Springer, Cham; Selvaraju, R.R., Grad-cam: Visual explanations from deep networks via gradient-based localization (2017) Proceedings of the IEEE International Conference on Computer Vision; Springenberg, J.T., (2014) Striving for Simplicity: The All Convolutional Net; Zeiler, M.D., Graham, W.T., Rob, F., Adaptive deconvolutional networks for mid and high level feature learning (2011) ICCV, 1 (2); Chattopadhay, A., Grad-cam ++: Generalized gradient-based visual explanations for deep convolutional networks (2018) 2018 IEEE Winter Conference on Applications of Computer Vision (WACV). IEEE; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-Scale Image Recognition; He, K., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems; Szegedy, C., Going deeper with convolutions (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Yu, W., Yang, K., Bai, Y., Yao, H., Rui, Y., (2014) Visualizing and Comparing Convolutional Neural Networks; Evans, R., Grefenstette, E., Learning explanatory rules from noisy data (2018) J. Artif. Intell. Res., 61, pp. 1-64; Lin, M., Chen, Q., Yan, S., (2013) Network in Network, , arXiv preprint arXiv","Szandała, T.; Wroclaw University of Science and TechnologyPoland; 电子邮件: Tomasz.Szandala@pwr.edu.pl",Zamojski W.Mazurkiewicz J.Sugier J.Walkowiak T.Kacprzyk J.,,Springer,"15th International Conference on Dependability of Computer Systems, DepCoS-RELCOMEX 2020",29 June 2020 through 3 July 2020,,240339,21945357,9.78E+12,,,English,Adv. Intell. Sys. Comput.,Conference Paper,Final,,Scopus,2-s2.0-85086181558
[无可用作者姓名],[无可用的作者 ID],"24th Pacific-Asia Conference on Knowledge Discovery and Data Mining, PAKDD 2020",2020,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),12085 LNAI,,,,,1797,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085769776&partnerID=40&md5=540a6be95ecce33ff8a85409e2919dd5,,,The proceedings contain 135 papers. The special focus in this conference is on Knowledge Discovery and Data Mining. The topics include: Adversarial Autoencoder and Multi-Task Semi-Supervised Learning for Multi-stage Process; data-Free Adversarial Perturbations for Practical Black-Box Attack; secure and Accurate Two-Step Hash Encoding for Privacy-Preserving Record Linkage; assessing Centrality Without Knowing Connections; deep Cost-Sensitive Kernel Machine for Binary Software Vulnerability Detection; TCN-ATT: A Non-recurrent Model for Sequence-Based Malware Detection; dK-Microaggregation: Anonymizing Graphs with Differential Privacy Guarantees; MIRD-Net for Medical Image Segmentation; JPLink: On Linking Jobs to Vocational Interest Types; exploiting the Matching Information in the Support Set for Few Shot Event Classification; chinese Sentence Semantic Matching Based on Multi-Granularity Fusion Model; PEARL: Probabilistic Exact Adaptive Random Forest with Lossy Counting for Data Streams; reliable Aggregation Method for Vector Regression Tasks in Crowdsourcing; balancing Exploration and Exploitation in Self-imitation Learning; mask-Guided Region Attention Network for Person Re-Identification; multi-view Deep Gaussian Process with a Pre-training Acceleration Technique; semantics-Reconstructing Hashing for Cross-Modal Retrieval; connecting the Dots: Hypotheses Generation by Leveraging Semantic Shifts; efficient Database Search via Tensor Distribution Bucketing; SAFE: Similarity-Aware Multi-modal Fake News Detection; Simultaneous ECG Heartbeat Segmentation and Classification with Feature Fusion and Long Term Context Dependencies; phosTransfer: A Deep Transfer Learning Framework for Kinase-Specific Phosphorylation Site Prediction in Hierarchy; mining Dynamic Graph Streams for Predictive Queries Under Resource Constraints; Multi-information Source HIN for Medical Concept Embedding; semi-supervised Learning Approach to Generate Neuroimaging Modalities with Adversarial Training; An Advanced Two-Step DNN-Based Framework for Arrhythmia Detection; canonicalizing Knowledge Bases for Recruitment Domain.,,,,,,,,,Lauw H.W.Lim E.-P.Wong R.C.-W.Ntoulas A.Ng S.-K.Pan S.J.,,Springer,"24th Pacific-Asia Conference on Knowledge Discovery and Data Mining, PAKDD 2020",11 May 2020 through 14 May 2020,,240129,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Review,Final,,Scopus,2-s2.0-85085769776
[无可用作者姓名],[无可用的作者 ID],"19th Joint European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, ECML PKDD 2019",2020,Communications in Computer and Information Science,1168 CCIS,,,,,1413,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083653069&partnerID=40&md5=e70bcd06c1bf0a875016530668890ef7,,,The proceedings contain 116 papers. The special focus in this conference is on Machine Learning and Principles and Practice of Knowledge Discovery in Databases. The topics include: Informativeness-Based Active Learning for Entity Resolution; encoding Hierarchical Classification Codes for Privacy-Preserving Record Linkage Using Bloom Filters; are Network Attacks Outliers? A Study of Space Representations and Unsupervised Algorithms; auto Semi-supervised Outlier Detection for Malicious Authentication Events; Defense-VAE: A Fast and Accurate Defense Against Adversarial Attacks; analyzing and Storing Network Intrusion Detection Data Using Bayesian Coresets: A Preliminary Study in Offline and Streaming Settings; analyzing Soccer Players’ Skill Ratings Over Time Using Tensor-Based Methods; exploring Successful Team Tactics in Soccer Tracking Data; soccer Team Vectors; modeling Evolving User Behavior via Sequential Clustering; tactical Analyses in Professional Tennis; difficulty Classification of Mountainbike Downhill Trails Utilizing Deep Neural Networks; categorizing Online Harassment on Twitter; learning to Detect Online Harassment on Twitter with the Transformer; detection of Harassment on Twitter with Deep Learning Techniques; Gradient Boosting Machine and LSTM Network for Online Harassment Detection and Categorization in Social Media; attention-Based Method for Categorizing Different Types of Online Harassment Language; SPICE: Streaming PCA Fault Identification and Classification Engine in Predictive Maintenance; event-Based Predictive Maintenance on Top of Sensor Data in a Real Industry 4.0 Case Study; forecasting of Product Quality Through Anomaly Detection; recognizing User’s Activity and Transport Mode Detection: Maintaining Low-Power Consumption; data Preprocessing and Dynamic Ensemble Selection for Imbalanced Data Stream Classification; a Study on Imbalanced Data Streams; neural Symbolic Music Genre Transfer Insights.,,,,,,,,,Cellier P.Driessens K.,,Springer,"19th Joint European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, ECML PKDD 2019",16 September 2019 through 20 September 2019,,238889,18650929,9.78E+12,,,English,Commun. Comput. Info. Sci.,Conference Review,Final,,Scopus,2-s2.0-85083653069
"Wang P., Gao H., Shi Z., Yuan Z., Hu J.",56937140100;12790863200;57205678318;57216391795;57216394240;,Simple and Easy: Transfer Learning-Based Attacks to Text CAPTCHA,2020,IEEE Access,8,,9045951,59044,59058,,7,10.1109/ACCESS.2020.2982945,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083394638&doi=10.1109%2fACCESS.2020.2982945&partnerID=40&md5=27306b133830ee6c9c421f1a1c9ca338,"School of Computer Science and Technology, Xidian University, Xi'an, China; School of Cyber Engineering, Xidian University, Xi'an, China","Wang, P., School of Computer Science and Technology, Xidian University, Xi'an, China; Gao, H., School of Computer Science and Technology, Xidian University, Xi'an, China; Shi, Z., School of Computer Science and Technology, Xidian University, Xi'an, China; Yuan, Z., School of Computer Science and Technology, Xidian University, Xi'an, China; Hu, J., School of Cyber Engineering, Xidian University, Xi'an, China","CAPTCHA, or Completely Automated Public Turing Tests to Tell Computers and Humans Apart, is a common mechanism used to protect commercial accounts from malicious computer bots, and the most widely used scheme is text-based CAPTCHA. In recent years, newly emerged deep learning techniques have achieved high accuracy and speed in attacking text-based CAPTCHAs. However, most of the existing attacks have various disadvantages, the attack process made high complexity or manually collecting and labeling a large number of samples to train a deep learning recognition model is time-consuming and expensive. In this paper, we propose a transfer learning-based approach that greatly reduces the attack complexity and the cost of labeling samples, specifically, by pre-training the model with randomly generated samples and fine-tuning the pre-trained model with a small number of real-world samples. To evaluate our attack, we tested 25 online CAPTCHAs achieving success rates ranging from 36.3% to 96.9%. To further explore the effect of the training sample characteristics on the attack accuracy, we elaborately imitate some samples and apply a generative adversarial network to refine the samples, sequentially we use these two kinds of generated samples to pre-train the models, respectively. The experimental results demonstrate that the similarity between randomly generated samples and elaborately imitated samples has a negligible impact on the attack accuracy. Instead, transfer learning is the key factor; it reduces the cost of data preparation while preserving the model's attack accuracy. © 2013 IEEE.",CAPTCHA; deep learning; security; transfer learning,Complex networks; Cost reduction; Deep learning; Electronic mail filters; Learning systems; Adversarial networks; Attack complexity; Data preparation; High complexity; Learning techniques; Learning-based approach; Number of samples; Recognition models; Transfer learning,,,,,"Yan, J., El Ahmad, A.S., Usability of captchas or usability issues in captcha design (2008) Proc ACM 4th Symp. Usable Privacy Secur, pp. 44-52; Gao, H., Tang, M., Liu, Y., Zhang, P., Liu, X., Research on the security of microsoft's two-layer captcha (2017) IEEE Trans. Inf. Forensics Security, 12 (7), pp. 1671-1685. , Mar; Tang, M., Gao, H., Zhang, Y., Liu, Y., Zhang, P., Wang, P., Research on deep learning techniques in breaking text-based CAPTCHAs and designing image-based CAPTCHA (2018) IEEE Trans. Inf. Forensics Security, 13 (10), pp. 2522-2537. , Oct; Yan, J., El Ahmad, S.A., A low-cost attack on a microsoft CAPTCHA (2008) Proc. 15th ACM Conf. Comput. Commun. Secur. (CCS, pp. 543-554; Algwil, A., Ciresan, D., Liu, B., Yan, J., A security analysis of automated Chinese turing tests (2016) Proc. 32nd Annu. Conf. Comput. Secur. Appl. (ACSAC, pp. 520-532; Xu, Y., Reynaga, G., Chiasson, S., Frahm, J.-M., Monrose, F., Van Oorschot, P.C., Security and usability challenges of moving-object CAPTCHAs: Decoding codewords in motion (2012) Proc. USENIX Secur. Symp, pp. 49-64; Gao, H., Wang, W., Qi, J., Wang, X., Liu, X., Yan, J., The robustness of hollow captchas (2013) Proc ACM SIGSAC Conf. Comput. Commun. Secur. (CCS, pp. 1075-1086; Chow, Y.-W., Susilo, W., Thorncharoensri, P., CAPTCHA design and security issues (2019) Advances in Cyber Security: Principles, Techniques, and Applications, pp. 69-92. , Singapore Springer; Ye, G., Tang, Z., Fang, D., Zhu, Z., Feng, Y., Xu, P., Chen, X., Wang, Z., Yet another text captcha solver: A generative adversarial network based approach (2018) Proc ACM SIGSAC Conf. Comput. Commun. Secur, pp. 332-348; Shrivastava, A., P-Ster, T., Tuzel, O., Susskind, J., Wang, W., Webb, R., Learning from simulated and unsupervised images through adversarial training (2017) Proc IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 2107-2116. , Jul; Jialin Pan, S., Yang, Q., A survey on transfer learning (2009) IEEE Trans. Knowl. Data Eng, 22 (10), pp. 1345-1359. , Oct; He, K., Zhang, X., Ren, S., Sun, J., Identity mappings in deep residual networks (2016) Proc. Eur. Conf. Comput. Vis. Cham, Switzerland, pp. 630-645. , Springer; Baird, H.S., Popat, K., Human interactive proofs and document image analysis (2002) Proc. Int. Workshop Document Anal. Syst. Berlin, Germany, pp. 507-518. , Springer; Mori, G., Malik, J., Recognizing objects in adversarial clutter: Breaking a visual CAPTCHA (2003) Proc. Comput. Vis. Pattern Recognit, 1, p. 1. , Jun; Chellapilla, K., Simard, P.Y., Using machine learning to break visual human interaction proofs (hips) (2005) Proc. Adv. Neural Inf. Process. Syst, pp. 265-272; Yan, J., El Ahmad, A.S., Breaking visual CAPTCHAs with Naive pattern recognition algorithms (2007) Proc. 23rd Annu. Comput. Secur. Appl. Conf. (ACSAC, pp. 279-291. , Dec; Bursztein, E., Aigrain, J., Moscicki, A., Mitchell, J.C., The end is nigh: Generic solving of text-based captchas (2014) Proc. 8th USENIX Workshop Offensive Technol. (WOOT, pp. 1-15; Gao, H., Yan, J., Cao, F., Zhang, Z., Lei, L., Tang, M., Zhang, P., Li, J., A simple generic attack on text CAPTCHAs (2016) Proc. Netw. Distrib. Syst. Secur. Symp. (NDSS, pp. 1-14; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Proc. Adv. Neural Inf. Process. Syst, pp. 2672-2680; Le, T.A., Baydin, A.G., Zinkov, R., Wood, F., Using synthetic data to train neural networks is model-based reasoning (2017) Proc. Int. Joint Conf. Neural Netw. (IJCNN), pp. 3514-3521. , May; Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc IEEE, 86 (11), pp. 2278-2324. , Nov; Zhao, B., Weng, H., Ji, S., Chen, J., Wang, T., He, Q., Beyah, R., Towards evaluating the security of real-world deployed image captchas (2018) Proc. 11th ACM Workshop Artif. Intell. Secur. (AISec, pp. 85-96; Wojna, Z., Gorban, A.N., Lee, D.-S., Murphy, K., Yu, Q., Li, Y., Ibarz, J., Attention-based extraction of structured information from street view imagery (2017) Proc. 14th IAPR Int. Conf. Document Anal. Recognit. (ICDAR, 1, pp. 844-850. , Nov; Zi, Y., Gao, H., Cheng, Z., Liu, Y., An end-to-end attack on text captchas (2019) IEEE Trans. Inf. Forensics Security, 15, pp. 753-766. , Jul; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proc IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 2818-2826. , Jun; Hu, J., Shen, L., Sun, G., Squeeze-And-excitation networks (2018) Proc IEEE Conf. Comput. Vis. Pattern Recognit., pp. 7132-7141. , Jun; Hochreiter, S., Schmidhuber, J., (1997) Long Short-Term Memory, 9 (8), pp. 1735-1780. , Cambridge, MA, USA MIT Press; Isola, P., Zhu, J.-Y., Zhou, T., Efros, A.A., Image-To-image translation with conditional adversarial networks (2017) Proc IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 1125-1134. , Jul; Lin, D., Lin, F., Lv, Y., Cai, F., Cao, D., Chinese character CAPTCHA recognition and performance estimation via deep neural network (2018) Neuro-computing, 288, pp. 11-19. , May; He, T., Huang, W., Qiao, Y., Yao, J., Text-Attentional convolutional neural network for scene text detection (2016) IEEE Trans. Image Process, 25 (6), pp. 2529-2541. , Jun; Bursztein, E., Martin, M., Mitchell, J., Text-based CAPTCHA strengths and weaknesses (2011) Proc. 18th ACM Conf. Comput. Commun. Secur. (CCS, pp. 125-138; George, D., Lehrach, W., Kansky, K., Lázaro-Gredilla, M., Laan, C., Marthi, B., Lou, X., Phoenix, D.S., A generative vision model that trains with high data ef-ciency and breaks text-based captchas Science, 358 (6368), p. 2017. , Dec; Stark, F., Hazrbas, C., Triebel, R., Cremers, D., CAPTCHA recognition with active deep learning (2015) Proc. GCPR Workshop New Challenges Neural Comput, 10, p. 94","Gao, H.; School of Computer Science and Technology, China; 电子邮件: hchgao@xidian.edu.cn",,,Institute of Electrical and Electronics Engineers Inc.,,,,,21693536,,,,English,IEEE Access,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85083394638
"Guo J., Gai K., Zhu L., Zhang Z.",57207765399;36655735200;7404201289;24337088400;,An Approach of Secure Two-Way-Pegged Multi-sidechain,2020,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),11945 LNCS,,,551,564,,4,10.1007/978-3-030-38961-1_47,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082140777&doi=10.1007%2f978-3-030-38961-1_47&partnerID=40&md5=54f0ac64e65d435ed8c08f7fa3ba3ba4,"School of Information and Electronics, Beijing Institute of Technology, Beijing, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; School of Computer Science, University of Auckland, Auckland, New Zealand","Guo, J., School of Information and Electronics, Beijing Institute of Technology, Beijing, China; Gai, K., School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; Zhu, L., School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; Zhang, Z., School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China, School of Computer Science, University of Auckland, Auckland, New Zealand","As a temper-resistant ledger, blockchain ensures integrity of transaction information among trust-less participants in peer to peer network. Thus, blockchain has attracted enormous research interests in the past decade due to its prior application in cryptocurrency, financial auditing, supply chain management, etc. However, blockchain scalability limitations has impeded blockchain technology from large scale commercial applications. Since blockchain is low in throughput, blockchain in incapable of handling large scale asset transfer. To tackle this problem, in this paper, we propose a secure multi-sidechain system. The proposed approach can transfer assets simultaneously to increase throughput. In addition, security of assets during transfer was also ensured by implementing firewall property. Detailed adversarial analysis shows this proposed approach can (1) prevent double spending and transaction ordering dependence attacks during asset transfer, (2) protect mainchain from sidechain’s catastrophic failure, (3) apply multi-sidechain model with different functions in each sidechain. © 2020, Springer Nature Switzerland AG.",Blockchain; Global consensus; High throughput; Scalability; Sidechain protocol,Blockchain; Network architecture; Parallel architectures; Scalability; Supply chain management; Catastrophic failures; Commercial applications; Global consensus; High throughput; Research interests; Side-chains; Transaction information; Two ways; Peer to peer networks,,,,,"Nakamoto, S., (2008) Bitcoin: A Peer-To-Peer Electronic Cash System; Morgan, J.P., (2019) The Next Step for Blockchain, , https://www.jpmorgan.com/global/research/blockchain-next-steps; (2019) Libra Write Paper, , https://libra.org/en-US/white-paper/; Liang, X., Shetty, S., Tosh, D., Kamhoua, C., Kwiat, K., Njilla, L., Provchain: A blockchain-based data provenance architecture in cloud environment with enhanced privacy and availability (2017) Proceedings of the 17Th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing, Pp. 468–477. IEEE Press; Xia, Q., Sifah, E., Asamoah, K., Gao, J., Du, X., Guizani, M., MeDShare: Trust-less medical data sharing among cloud service providers via blockchain (2017) IEEE Access, 5, pp. 14757-14767; Gai, K., Qiu, M., Blend arithmetic operations on tensor-based fully homomorphic encryption over real numbers (2017) IEEE Trans. Ind. Inf., 14 (8), pp. 3590-3598; Choudhuri, A., Green, M., Jain, A., Kaptchuk, G., Miers, I., Fairness in an unfair world: Fair multiparty computation from public bulletin boards (2017) Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pp. 719-728. , ACM; Hu, S., Cai, C., Wang, Q., Wang, C., Luo, X., Ren, K., Searching an encrypted cloud meets blockchain: A decentralized, reliable and fair realization (2018) IEEE Conference on Computer Communications (INFOCOM), pp. 792-800. , IEEE; Gai, K., Wu, Y., Zhu, L., Xu, L., Zhang, Y., Permissioned blockchain and edge computing empowered privacy-preserving smart grid networks (2019) IEEE Internet Things J, 15 (6), pp. 3548-3558; Gai, K., Wu, Y., Zhu, L., Qiu, M., Shen, M., Privacy-preserving energy trading using consortium blockchain in smart grid (2019) IEEE Trans. Ind. Inf.; Zhu, L., Wu, Y., Gai, K., Choo, K., Controllable and trustworthy blockchain-based cloud data management (2019) Future Gener. Comput. Syst., 91, pp. 527-535; Karame, G., On the security and scalability of bitcoin’s blockchain (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1861-1862. , ACM; Gai, K., Qiu, M., Zhao, H., Energy-aware task assignment for mobile cyber-enabled applications in heterogeneous cloud computing (2018) J. Parallel Distrib. Comput., 111, pp. 126-135; Kwon, Y., Kim, H., Shin, J., Kim, Y., Bitcoin vs. Bitcoin cash: Coexistence or downfall of bitcoin cash? (2019) Proceedings of the 2019 IEEE Symposium on Security and Privacy, pp. 1290-1306. , IEEE Computer Society; Back, A., (2014) Enabling Blockchain Innovations with Pegged Sidechains, p. 72. , http://www.opensciencereview.com/papers/123/enablingblockchain-innovations-with-pegged-sidechains; Luu, L., Narayanan, V., Zheng, C., Baweja, K., Gilbert, S., Saxena, P., A secure sharding protocol for open blockchains (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 17-30. , ACM; Zamani, M., Movahedi, M., Raykova, M., Rapidchain: Scaling blockchain via full sharding (2018) Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, pp. 931-948. , ACM; Chow, J., (2016) BTC Relay, , https://github.com/ethereum/btcrelay; Teutsch, J., Straka, M., Boneh, D., (2018) Retrofitting a Two-Way Peg between Blockchains, , https://people.cs.uchicago.edu, Technical report; Gazi, P., Kiayias, A., Zindros, D., Proof-of-stake sidechains (2019) Proceedings of the 2019 IEEE Symposium on Security and Privacy, pp. 677-694. , IEEE Computer Society; Poon, J., Dryja, T., (2016) The Bitcoin Lightning Network: Scalable Off-Chain Instant Payments; Dziembowski, S., Faust, S., Hostáková, K., General state channel networks (2018) Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, pp. 949-966. , ACM; Luu, L., Chu, D., Olickel, H., Saxena, P., Hobor, A., Making smart contracts smarter (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 254-269. , ACM","Gai, K.; School of Computer Science and Technology, China; 电子邮件: gaikeke@bit.edu.cn",Wen S.Zomaya A.Yang L.T.,,Springer,"19th International Conference on Algorithms and Architectures for Parallel Processing, ICA3PP 2019",9 December 2019 through 11 December 2019,,238019,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,,Scopus,2-s2.0-85082140777
"Zhang Y., Tian X., Li Y., Wang X., Tao D.",57215822000;16643535600;55329591800;54406086400;7102600334;,Principal Component Adversarial Example,2020,IEEE Transactions on Image Processing,29,,9018372,4804,4815,,9,10.1109/TIP.2020.2975918,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081974650&doi=10.1109%2fTIP.2020.2975918&partnerID=40&md5=c11ca45858444f34152fb2992c60da71,"Department of Electronic Engineering and Information Science, University of Science and Technology of China, Hefei, 230027, China; Department of Computer Science, Stevens Institute of Technology, Hoboken, NJ, United States; UBTECH Sydney Artificial Intelligence Centre, University of Sydney, Sydney, NSW, Australia","Zhang, Y., Department of Electronic Engineering and Information Science, University of Science and Technology of China, Hefei, 230027, China; Tian, X., Department of Electronic Engineering and Information Science, University of Science and Technology of China, Hefei, 230027, China; Li, Y., Department of Electronic Engineering and Information Science, University of Science and Technology of China, Hefei, 230027, China; Wang, X., Department of Computer Science, Stevens Institute of Technology, Hoboken, NJ, United States; Tao, D., UBTECH Sydney Artificial Intelligence Centre, University of Sydney, Sydney, NSW, Australia","Despite having achieved excellent performance on various tasks, deep neural networks have been shown to be susceptible to adversarial examples, i.e., visual inputs crafted with structural imperceptible noise. To explain this phenomenon, previous works implicate the weak capability of the classification models and the difficulty of the classification tasks. These explanations appear to account for some of the empirical observations but lack deep insight into the intrinsic nature of adversarial examples, such as the generation method and transferability. Furthermore, previous works generate adversarial examples completely rely on a specific classifier (model). Consequently, the attack ability of adversarial examples is strongly dependent on the specific classifier. More importantly, adversarial examples cannot be generated without a trained classifier. In this paper, we raise a question: what is the real cause of the generation of adversarial examples? To answer this question, we propose a new concept, called the adversarial region, which explains the existence of adversarial examples as perturbations perpendicular to the tangent plane of the data manifold. This view yields a clear explanation of the transfer property across different models of adversarial examples. Moreover, with the notion of the adversarial region, we propose a novel target-free method to generate adversarial examples via principal component analysis. We verify our adversarial region hypothesis on a synthetic dataset and demonstrate through extensive experiments on real datasets that the adversarial examples generated by our method have competitive or even strong transferability compared with model-dependent adversarial example generating methods. Moreover, our experiment shows that the proposed method is more robust to defensive methods than previous methods. © 1992-2012 IEEE.",adversarial examples; classification; Deep learning; manifold learning,Classification (of information); Deep neural networks; Principal component analysis; adversarial examples; Classification models; Classification tasks; Generating methods; Generation method; Manifold learning; Principal Components; Transfer properties; Deep learning,,,,,"Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Proc. Neural Inf. Process. Syst. (NIPS), pp. 1097-1105; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition, , http://arxiv.org/abs/1409.1556; Szegedy, C., Going deeper with convolutions (2015) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 1-9. , Jun; Li, J., Chang, H., Yang, J., Luo, W., Fu, Y., Visual representation and classification by learning group sparse deep stacking network (2018) IEEE Trans. Image Process., 27 (1), pp. 464-476. , Jan; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 770-778. , Jun; Hinton, G., Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups (2012) IEEE Signal Process. Mag., 29 (6), pp. 82-97. , Nov; Wang, W., Shen, J., Shao, L., Video salient object detection via fully convolutional networks (2018) IEEE Trans. Image Process., 27 (1), pp. 38-49. , Jan; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples, , http://arxiv.org/abs/1605.07277; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , http://arxiv.org/abs/1412.6572; Sabour, S., Cao, Y., Faghri, F., Fleet, D.J., (2015) Adversarial Manipulation of Deep Representations, , http://arxiv.org/abs/1511.05122; Rozsa, A., Rudd, E.M., Boult, T.E., Adversarial diversity and hard positive generation (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. Workshops (CVPRW), pp. 25-32. , Jun; Tabacof, P., Valle, E., Exploring the space of adversarial images (2016) Proc. Int. Joint Conf. Neural Netw. (IJCNN), pp. 426-433. , Jul; Fawzi, A., Fawzi, O., Frossard, P., (2015) Analysis of Classifiers&grave; Robustness to Adversarial Perturbations, , http://arxiv.org/abs/1502.02590; Lyu, C., Huang, K., Liang, N.H., A unified gradient regularization family for adversarial examples (2015) Proc. IEEE Int. Conf. Data Mining, pp. 301-309. , Nov; Gu, S., Rigazio, L., (2014) Towards Deep Neural Network Architectures Robust to Adversarial Examples, , http://arxiv.org/abs/1412.5068; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 427-436. , Jun; Fawzi, A., Moosavi-Dezfooli, M.S., Frossard, P., Robustness of classifiers: From adversarial to random noise (2016) Proc. Neural Inf. Process. Syst. (NIPS), pp. 1632-1640; Moosavi-Dezfooli, M.S., Fawzi, A., Fawzi, O., Frossard, P., Soatto, S., (2017) Analysis of Universal Adversarial Perturbations, , http://arxiv.org/abs/1705.09554; Akhtar, N., Mian, A., Threat of adversarial attacks on deep learning in computer vision: A survey (2018) IEEE Access, 6, pp. 14410-14430; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Proc. IEEE Symp. Secur. Privacy (SP), pp. 39-57. , May; Rozsa, A., Gunther, M., Boult, T.E., Are accuracy and robustness correlated (2016) Proc. 15th IEEE Int. Conf. Mach. Learn. Appl. (ICMLA), pp. 227-232. , Dec; Szegedy, C., (2013) Intriguing Properties of Neural Networks, , http://arxiv.org/abs/1312.6199; Tanay, T., Griffin, L., (2016) A Boundary Tilting Persepective on the Phenomenon of Adversarial Examples, , http://arxiv.org/abs/1608.07690; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Machine Learning at Scale, , http://arxiv.org/abs/1611.01236; Gilmer, J., (2018) Adversarial Spheres, , http://arxiv.org/abs/1801.02774; Song, Y., Kim, T., Nowozin, S., Ermon, S., Kushman, N., (2017) PixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples, , http://arxiv.org/abs/1710.10766; Lee, H., Han, S., Lee, J., (2017) Generative Adversarial Trainer: Defense to Adversarial Perturbations with GAN, , http://arxiv.org/abs/1705.03387; Fawzi, A., Moosavi-Dezfooli, S.M., Frossard, P., The robustness of deep networks: A geometrical perspective (2017) IEEE Signal Process. Mag., 34 (6), pp. 50-62. , Nov; Moosavi-Dezfooli, S.M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 86-94. , Jul; Simard, P., Victorri, B., LeCun, Y., Denker, J., Tangent prop-A formalism for specifying selected invariances in an adaptive network (1992) Proc. Neural Inf. Process. Syst. (NIPS), pp. 895-903; Bengio, Y., Courville, A., Vincent, P., Representation learning: A review and new perspectives (2013) IEEE Trans. Pattern Anal. Mach. Intell., 35 (8), pp. 1798-1828. , Aug; Rifai, S., Dauphin, Y.N., Vincent, P., Bengio, Y., Muller, X., The manifold tangent classifier (2011) Proc. Neural Inf. Process. Syst. (NIPS), pp. 2294-2302; Goodfellow, I., Bengio, Y., Courville, A., (2016) Deep Learning, , Cambridge, MA, USA: MIT Press; Vincent, P., Bengio, Y., Manifold parzen windows (2003) Proc. Neural Inf. Process. Syst. (NIPS), pp. 849-856; Cayton, L., Algorithms for manifold learning Univ. Ca San Diego, 12, pp. 1-17. , San Diego, CA, USA, Tech. Rep. CS2008-0923, 2005; Bakr, G.H., Zien, A., Tsuda, K., Learning to find graph preimages (2004) Proc. Neural Inf. Process. Syst. (NIPS), pp. 449-456; Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., (2017) On the (Statistical) Detection of Adversarial Examples, , http://arxiv.org/abs/1702.06280; Meng, D., Chen, H., MagNet: A two-pronged defense against adversarial examples (2017) Proc. ACM SIGSAC Conf. Comput. Commun. Secur. (CCS), pp. 135-147; Carlini, N., Wagner, D., (2017) MagNet and &grave;Efficient Defenses against Adversarial Attacks&grave; Are Not Robust to Adversarial Examples, , http://arxiv.org/abs/1711.08478; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , http://arxiv.org/abs/1706.06083; Wang, Z., Bovik, A.C., Sheikh, H.R., Simoncelli, E.P., Image quality assessment: From error visibility to structural similarity (2004) IEEE Trans. Image Process., 13 (4), pp. 600-612. , Apr; Jia, Y., Caffe: Convolutional architecture for fast feature embedding (2014) Proc. ACM Int. Conf. Multimedia (MM), pp. 675-678; Russakovsky, O., ImageNet large scale visual recognition challenge (2015) Int. J. Comput. Vis., 115 (3), pp. 211-252. , Apr; Wei, X.S., Luo, J.H., Wu, J., Zhou, Z.H., Selective convolutional descriptor aggregation for fine-grained image retrieval (2017) IEEE Trans. Image Process., 26 (6), pp. 2868-2881. , Jun; Sun, T., Wang, Y., Yang, J., Hu, X., Convolution neural networks with two pathways for image style recognition (2017) IEEE Trans. Image Process., 26 (9), pp. 4102-4113. , Sep; Lebrun, M., An analysis and implementation of the BM3D image denoising method (2012) Image Process. Line, 2, pp. 175-213. , Aug","Zhang, Y.; Department of Electronic Engineering and Information Science, China; 电子邮件: yonggang@mail.ustc.edu.cn",,,Institute of Electrical and Electronics Engineers Inc.,,,,,10577149,,IIPRE,,English,IEEE Trans Image Process,Article,Final,,Scopus,2-s2.0-85081974650
"Hu M., Peng Y., Wei F., Huang Z., Li D., Yang N., Zhou M.",56724917100;55257095800;23995914700;56188479000;57204110845;55746714100;55587890800;,Attention-guided answer distillation for machine reading comprehension,2020,"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, EMNLP 2018",,,,2077,2086,,15,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081716987&partnerID=40&md5=b6d5b71977b70c70064e90422ffc5ee7,"College of Computer, National University of Defense Technology, China; Microsoft Research Asia, China","Hu, M., College of Computer, National University of Defense Technology, China; Peng, Y., College of Computer, National University of Defense Technology, China; Wei, F., Microsoft Research Asia, China; Huang, Z., College of Computer, National University of Defense Technology, China; Li, D., College of Computer, National University of Defense Technology, China; Yang, N., Microsoft Research Asia, China; Zhou, M., Microsoft Research Asia, China","Despite that current reading comprehension systems have achieved significant advancements, their promising performances are often obtained at the cost of making an ensemble of numerous models. Besides, existing approaches are also vulnerable to adversarial attacks. This paper tackles these problems by leveraging knowledge distillation, which aims to transfer knowledge from an ensemble model to a single model. We first demonstrate that vanilla knowledge distillation applied to answer span prediction is effective for reading comprehension systems. We then propose two novel approaches that not only penalize the prediction on confusing answers but also guide the training with alignment information distilled from the ensemble. Experiments show that our best student model has only a slight drop of 0.4% F1 on the SQuAD test set compared to the ensemble teacher, while running 12× faster during inference. It even outperforms the teacher on adversarial SQuAD datasets and NarrativeQA benchmark. © 2018 Association for Computational Linguistics",,Distillation; Knowledge management; Ensemble modeling; Numerous models; Reading comprehension; Single models; Student Modeling; Test sets; Natural language processing systems,,,,,"Bahdanau, D., Cho, K., Bengio, Y., Neural machine translation by jointly learning to align and translate (2015) Proceedings of ICLR; Bai, B., Weston, J., Grangier, D., Collobert, R., Sadamasa, K., Qi, Y., Chapelle, O., Weinberger, K., Learning to rank with (a lot of) word features (2010) Information Retrieval, 13 (3), pp. 291-314; Bowman, S.R., Angeli, G., Potts, C., Manning, C.D., A large annotated corpus for learning natural language inference systems (2015) Proceedings of EMNLP; Bucilu, C., Caruana, R., Niculescu-Mizil, A., Model compression (2006) Proceedings of SIGKDD, pp. 535-541; Chen, D., Fisch, A., Weston, J., Bordes, A., Reading wikipedia to answer open-domain questions (2017) Proceedings of ACL; Clark, C., Gardner, M., Simple and effective multi-paragraph reading comprehension (2018) Proceedings of ACL; Hermann, K.M., Kocisky, T., Grefenstette, E., Espeholt, L., Kay, W., Suleyman, M., Blunsom, P., Teaching machines to read and comprehend (2015) Proceedings of NIPS; Hill, F., Bordes, A., Chopra, S., Weston, J., The goldilocks principle: Reading childrens books with explicit memory representations (2016) Proceedings of ICLR; Hinton, G., Vinyals, O., Dean, J., Distilling the knowledge in a neural network (2014) Proceedings of NIPS Workshop; Hu, M., Peng, Y., Huang, Z., Qiu, X., Wei, F., Zhou, M., Reinforced mnemonic reader for machine reading comprehension (2018) Proceedings of UCAI; Huang, H.-Y., Zhu, C., Shen, Y., Chen, W., FusionNet: Fusing via fully-aware attention with application to machine comprehension (2018) Proceedings of ICLR; Huang, Z., Wang, N., (2017) Like What You Like: Knowledge Distill Via Neuron Selectivity Transfer, , arXiv preprint; Jia, R., Liang, P., Adversarial examples for evaluating reading comprehension systems (2017) Proceedings ofEMNLP; Joshi, M., Choi, E., Weld, D.S., Zettlemoyer, L., Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension (2017) Proceedings of ACL; Kadlec, R., Schmid, M., Bajgar, O., Kleindienst, J., Text understanding with the attention sum reader network (2016) Proceedings of ACL; Kim, Y., Rush, A.M., Sequence-level knowledge distillation (2016) Proceedings of EMNLP; Kočisky, T., Schwarz, J., Blunsom, P., Dyer, C., Hermann, K.M., Melis, G., Grefenstette, E., (2017) The Narrativeqa Reading Comprehension Challenge, , arXiv preprint; Kuncoro, A., Ballesteros, M., Kong, L., Dyer, C., Smith, N.A., Distilling an ensemble of greedy dependency parsers into one mst parser (2016) Proceedings ofEMNLP; Min, S., Zhong, V., Socher, R., Xiong, C., (2018) Efficient and Robust Question Answering from Minimal Context over Documents; Mou, L., Jia, R., Xu, Y., Li, G., Zhang, L., Jin, Z., Distilling word embeddings: An encoding approach (2016) Proceedings ofCIKM, pp. 1977-1980; Nakashole, N., Flauger, R., Knowledge distillation for bilingual dictionary induction (2017) Proceedings of EMNLP, pp. 2487-2496; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) 2076 IEEE Symposium on Security and Privacy (SP), pp. 582-597; Peters, M.E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., Zettlemoyer, L., Deep contextualized word prepresentations (2018) Proceedings of NACCL; Radosavovic, I., Dollár, P., Girshick, R., Gkioxari, G., He, K., (2017) Data Distillation: Towards Omni-Supervised Learning, , arXiv preprint; Rajpurkar, P., Zhang, J., Lopyrev, K., Liang, P., Squad: 100,000+ questions for machine comprehension of text (2016) Proceedings of EMNLP; Romero, A., Ballas, N., Kahou, S.E., Chassang, A., Gatta, C., Bengio, Y., Fitnets: Hints for thin deep nets (2015) Proceedings of ICLR; Seo, M., Kembhavi, A., Farhadi, A., Hajishirzi, H., Bidirectional attention flow for machine comprehension (2017) Proceedings of ICLR; Tay, Y., Tuan, L.A., Hui, S.C., (2018) Multi-Range Reasoning for Machine Comprehension, , arXivpreprintarXiv; Vinyals, O., Fortunate, M., Jaitly, N., Pointer networks (2015) Proceedings of NIPS; Wang, S., Jiang, J., Machine comprehension using match-lstm and answer pointer (2017) Proceedings of ICLR; Wang, W., Yan, M., Wu, C., Multigranularity hierarchical attention fusion networks for reading comprehension and question answering (2018) Proceedings of ACL; Wang, W., Yang, N., Wei, F., Chang, B., Zhou, M., Gated self-matching networks for reading comprehension and question answering (2017) Proceedings of ACL; Wang, Y., Bansal, M., Robust machine comprehension models via adversarial training (2018) Proceedings ofNAACL; Xiong, C., Zhong, V., Socher, R., DCN+: Mixed objective and deep residual coattention for question answering (2018) Proceedings oflCLR; Xu, R., Yang, Y., Cross-lingual distillation for text classification (2017) Proceedings of ACL; Yang, Y., Yih, W.-T., Meek, C., Wikiqa: A challenge dataset for open-domain question answering (2015) Proceedings ofEMNLP; Yu, A.W., Dohan, D., Luong, M.-T., Zhao, R., Chen, K., Norouzi, M., Le, Q.V., QaNet: Combining local convolution with global self-attention for reading comprehension (2018) Proceedings of ICLR; Zagoruyko, S., Komodakis, N., Paying more attention to attention: Improving the performance of convolutional neural networks via attention transfer (2017) Proceedings of ICLR","Hu, M.; College of Computer, China; 电子邮件: huminghao09@nudt.edu.cn",Riloff E.Chiang D.Hockenmaier J.Tsujii J.,Apple;Bloomberg;et al.;Facebook;Google;salesforce,Association for Computational Linguistics,"2018 Conference on Empirical Methods in Natural Language Processing, EMNLP 2018",31 October 2018 through 4 November 2018,,158085,,9.78E+12,,,English,"Proc. Conf. Empir. Methods Nat. Lang. Process., EMNLP",Conference Paper,Final,,Scopus,2-s2.0-85081716987
[无可用作者姓名],[无可用的作者 ID],"20th World Conference on Information Security Applications, WISA 2019",2020,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),11897 LNCS,,,,,382,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079149629&partnerID=40&md5=8cf95b6096774581661a3aacf2d5e69f,,,"The proceedings contain 28 papers. The special focus in this conference is on Information Security Applications. The topics include: Reversible Data Hiding in Homomorphic Encrypted Images Without Preprocessing; model Selection for Data Analysis in Encrypted Domain: Application to Simple Linear Regression; timed-Release Encryption with Master Time Bound Key; secret Sharing on Evolving Multi-level Access Structure; Strengthened PAKE Protocols Secure Against Malicious Private Key Generator; efficient Decentralized Random Commitment Key Generation for Mixnet Shuffle Proof; Catching the Phish: Detecting Phishing Attacks Using Recurrent Neural Networks (RNNs); CAPTCHA Image Generation Using Style Transfer Learning in Deep Neural Network; a New Password Cracking Model with Generative Adversarial Networks; Turn On the Lights: User Behavior in Game Environment Using CPTED; is It Possible to Hide My Key into Deep Neural Network?; RC PUF: A Low-Cost and an Easy-to-Design PUF for Resource-Constrained IoT Devices; on the Automation of Security Testing for IoT Constrained Scenarios; cyber Deception in the Internet of Battlefield Things: Techniques, Instances, and Assessments; Ring-LWE on 8-Bit AVR Embedded Processor; Low-Noise LLC Side-Channel Attack with Perf; Optimized SIKE Round 2 on 64-bit ARM; shedding Light on Dark Korea: An In-Depth Analysis and Profiling of the Dark Web in Korea; An SGX-Based Key Management Framework for Data Centric Networking; QR Code Watermarking for Digital Images; FSF: Code Coverage-Driven Fuzzing for Software-Defined Networking; DroPPPP: A P4 Approach to Mitigating DoS Attacks in SDN; a Secure and Self-tallying E-voting System Based on Blockchain; An Extended CTRT for AES-256; a Blind Ring Signature Based on the Short Integer Solution Problem.",,,,,,,,,You I.,,Springer,"20th World Conference on Information Security Applications, WISA 2019",21 August 2019 through 24 August 2019,,236689,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Review,Final,,Scopus,2-s2.0-85079149629
"Rueckert D., Schnabel J.A.",7004895812;7003492772;,Model-Based and Data-Driven Strategies in Medical Image Computing,2020,Proceedings of the IEEE,108,1,8867900,110,124,,14,10.1109/JPROC.2019.2943836,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077799075&doi=10.1109%2fJPROC.2019.2943836&partnerID=40&md5=236b00b0d10de8ac9e8966aacbb0d028,"Department of Computing, Imperial College London, London, SW72AZ, United Kingdom; School of Biomedical Engineering and Imaging Sciences, King's College London, London, SE17EH, United Kingdom","Rueckert, D., Department of Computing, Imperial College London, London, SW72AZ, United Kingdom; Schnabel, J.A., School of Biomedical Engineering and Imaging Sciences, King's College London, London, SE17EH, United Kingdom","Model-based approaches for image reconstruction, analysis, and interpretation have made significant progress over the past decades. Many of these approaches are based on either mathematical, physical, or biological models. A challenge for these approaches is the modeling of the underlying processes (e.g., the physics of image acquisition or the patho-physiology of a disease) with appropriate levels of detail and realism. With the availability of large amounts of imaging data and machine learning (in particular deep learning) techniques, data-driven approaches have become more widespread for use in different tasks in reconstruction, analysis, and interpretation. These approaches learn statistical models directly from labeled or unlabeled image data and have been shown to be very powerful for extracting clinically useful information from medical imaging. While these data-driven approaches often outperform traditional model-based approaches, their clinical deployment often poses challenges in terms of robustness, generalization ability, and interpretability. In this article, we discuss what developments have motivated the shift from model-based approaches toward data-driven strategies and what potential problems are associated with the move toward purely data-driven approaches, in particular deep learning. We also discuss some of the open challenges for data-driven approaches, e.g., generalization to new unseen data (e.g., transfer learning), robustness to adversarial attacks, and interpretability. Finally, we conclude with a discussion on how these approaches may lead to the development of more closely coupled imaging pipelines that are optimized in an end-to-end fashion. © 2019 IEEE.",Artificial neural networks; biomedical imaging; image analysis; image classification; image processing; image reconstruction; image registration; image segmentation; machine learning,Deep learning; Image analysis; Image classification; Image processing; Image reconstruction; Image registration; Image segmentation; Learning systems; Machine learning; Neural networks; Biomedical imaging; Data-driven approach; Generalization ability; Medical image computing; Model based approach; Potential problems; Traditional models; Transfer learning; Medical imaging,,,,,"Aljabar, P., Heckemann, R., Hammers, A., Hajnal, J., Rueckert, D., Multi-atlas based segmentation of brain images: Atlas selection and its effect on accuracy (2009) NeuroImage, 46 (3), pp. 726-738; Arbabshirani, M.R., Advanced machine learning in action: Identification of intracranial hemorrhage on computed tomography scans of the head with clinical workflow integration (2018) Npj Digit. Med, 1. , Apr; Artaechevarria, X., Munoz-Barrutia, A., Ortiz-De-Solorzano, C., Combination strategies in multi-atlas image segmentation: Application to brain MR data (2009) IEEE Trans. Med. Imag, 28 (8), pp. 1266-1277. , Aug; Ashburner, J., A fast diffeomorphic image registration algorithm (2007) NeuroImage, 38 (1), pp. 95-113; Ashburner, J., Friston, K.J., Voxel-based morphometry-The methods (2000) NeuroImage, 11 (6), pp. 805-821; Ashburner, J., Friston, K.J., Unified Segmentation (2005) Neuro Image, 26 (3), pp. 839-851; Avants, B.B., Epstein, C.L., Grossman, M., Gee, J.C., Symmetric diffeomorphic image registration with cross-correlation: Evaluating automated labeling of elderly and neurodegenerative brain (2008) Med. Image Anal, 12 (1), pp. 26-41; Bai, W., Automated cardiovascular magnetic resonance image analysis with fully convolutional networks (2018) J. Cardiovascular Magn. Reson, 20. , Sep; Baker, B., Gupta, O., Naik, N., Raskar, R., Designing neural network architectures using reinforcement learning (2017) Proc. Int. Conf. Learn. Represent. (ICLR); Baker, R.E., Penã, J.-M., Jayamohan, J., Jérusalem, A., Mechanistic models versus machine learning, a fight worth fighting for the biological community (2018) Biol. Lett, 14 (5); Balakrishnan, G., Zhao, A., Sabuncu, M.R., Guttag, J., Dalca, A.V., An unsupervised learning model for deformable medical image registration (2018) Proc. Comput. Vis. Pattern Recognit. (CVPR), pp. 9252-9260; Bauer, S., Nolte, L.-P., Reyes, M., Fully automatic segmentation of brain tumor images using support vector machine classification in combination with hierarchical conditional random field regularization (2011) Medical Image Computing and Computer-Assisted Intervention-MICCAI, pp. 354-361. , Berlin, Germany: Springer; Baumgartner, C., SonoNet: Real-time detection and localisation of fetal standard scan planes in freehand ultrasound (2017) IEEE Trans. Med. Imag, 36 (11), pp. 2204-2215. , Nov; Beg, M.F., Miller, M.I., Trouvé, A., Younes, L., Computing large deformation metric mappings via geodesic flows of diffeomorphisms (2005) Int. J. Comput. Vis, 61 (2), pp. 139-157; Bello, G.A., Deep-learning cardiac motion analysis for human survival prediction (2019) Nature Mach. Intell, 1, pp. 95-104. , Feb; Bien, N., Deep-learning-assisted diagnosis for knee magnetic resonance imaging: Development and retrospective validation of MRNet (2018) PLOS Med, 15 (11); Bonawitz, K., Towards federated learning at scale: System design (2019) CoRR, , Mar; Bookstein, F.L., (1991) Morphometric Tools Landmark Data: Geometry and Biology, , Cambridge U.K.: Cambridge Univ. Press; Bronstein, M.M., Bronstein, A.M., Michel, F., Paragios, N., Data fusion through cross-modality metric learning using similarity-sensitive hashing (2010) Proc. Comput. Vis. Pattern Recognit. (CVPR), pp. 3594-3601; Çiçek, O., Abdulkadir, A., Lienkamp, S.S., Brox, T., Ronneberger, O., 3D U-Net: Learning dense volumetric segmentation from sparse annotation (2016) Medical Image Computing and Computer-Assisted Intervention-MICCAI, pp. 424-432. , Cham, Switzerland: Springer; Clough, J.R., Öksüz, I., Byrne, N., Schnabel, J.A., King, A.P., Explicit topological priors for deep-learning based image segmentation using persistent homology (2019) Information Processing in Medical Imaging, pp. 16-28. , Cham, Switzerland: Springer; The German National Cohort: Aims, study design and organization (2014) Eur. J. Epidemiol, 29, pp. 371-382. , German National Cohort (GNC) Consortium, May; Cootes, T.F., Edwards, G.J., Taylor, C.J., Active appearance models (1998) Proc. Eur. Conf. Comput. Vis. (ECCV), pp. 484-498; Cootes, T.F., Taylor, C.J., Cooper, D.H., Graham, J., Active shape models-their training and application (1995) Comput. Vis. Image Understand, 61 (1), pp. 38-59; Cortes, C., Vapnik, V., Support-vector networks (1995) Mach. Learn, 20 (3), pp. 273-297; Criminisi, A., Shotton, J., Konukoglu, E., Decision forests: A unified framework for classification, regression, density estimation, manifold learning and semi-supervised learning (2012) Found. Trends Comput. Graph. Vis, 7 (2-3), pp. 81-227. , Feb; Dalca, A.V., Balakrishnan, G., Guttag, J., Sabuncu, M.R., Unsupervised learning for fast probabilistic diffeomorphic registration (2018) Medical Image Computing and Computer Assisted Intervention-MICCAI, pp. 729-738. , Cham, Switzerland: Springer; De Vos, B.D., Berendsen, F.F., Viergever, M.A., Sokooti, H., Staring, M., Išgum, I., A deep learning framework for unsupervised affine and deformable image registration (2018) Med. Image Anal, 52, pp. 128-143. , Feb; De Vos, B.D., Wolterink, J.M., De Jong, P.A., Leiner, T., Viergever, M.A., Isgum, I., ConvNet-based localization of anatomical structures in 3-D medical images (2017) IEEE Trans. Med. Imag, 36 (7), pp. 1470-1481. , Jul; Donoho, D.L., Compressed sensing (2006) IEEE Trans. Inf. Theory, 52 (4), pp. 1289-1306. , Apr; Dosovitskiy, A., FlowNet: Learning optical flow with convolutional networks (2015) Proc. Int. Conf. Comput. Vis. (ICCV), pp. 2758-2766; Dwork, C., Hardt, M., Pitassi, T., Reingold, O., Zemel, R., Fairness through awareness (2012) Proc. Innov. Theor. Comput. Sci. (ITCS), pp. 214-226; Esteva, A., Dermatologist-level classification of skin cancer with deep neural networks (2017) Nature, 542, pp. 115-118. , Feb; Fan, J., Cao, X., Xue, Z., Yap, P.-T., Shen, D., Adversarial similarity network for evaluating image alignment in deep learning based registration (2018) Medical Image Computing and Computer-Assisted Intervention-MICCAI, pp. 739-746. , Cham, Switzerland: Springer; De Fauw, J., Clinically applicable deep learning for diagnosis and referral in retinal disease (2018) Nature Med, 24, pp. 1342-1350. , Aug; Feng, X., Yang, J., Laine, A.F., Angelini, E.D., Discriminative localization in CNNs for weakly-supervised segmentation of pulmonary nodules (2017) Medical Image Computing and Computer-Assisted Intervention-MICCAI, pp. 568-576. , Cham, Switzerland: Springer; Finlayson, S.G., Bowers, J.D., Ito, J., Zittrain, J.L., Beam, A.L., Kohane, I.S., Adversarial attacks on medical machine learning (2019) Science, 363 (6433), pp. 1287-1289; Gaser, C., Nenadic, I., Buchsbaum, B.R., Hazlett, E.A., Buchsbaum, M.S., Deformation-based morphometry and its relation to conventional volumetry of brain lateral ventricles in MRI (2001) NeuroImage, 13 (6), pp. 1140-1145; Ghafoorian, M., Transfer learning for domain adaptation in MRI: Application in brain lesion segmentation (2017) Medical Image Computing and Computer-Assisted Intervention-MICCAI, pp. 516-524. , Cham, Switzerland: Springer; Ghesu, F.C., (2019) Quantifying and Leveraging Classification Uncertainty for Chest Radiograph Assessment, pp. 1-9. , CoRR, vol. abs/1906,07775, Jun; Gilad-Bachrach, R., Dowlin, N., Laine, K., Lauter, K., Naehrig, M., Wernsing, J., CryptoNets: Applying neural networks to encrypted data with high throughput and accuracy (2016) Proc. Int. Conf. Mach. Learn. (ICML), 48, pp. 201-210; Goodfellow, I.J., Generative adversarial nets (2014) Proc. Adv. Neural Inf. Process. Syst. (NIPS), pp. 2672-2680; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) Proc. Int. Conf. Learn. Represent. (ICLR); Grgíc-Hlaca, N., Zafar, M.B., Gummadi, K.P., Weller, A., On fairness, diversity and randomness in algorithmic decision making (2017) CoRR, , Jun; Gunning, D., DARPA's explainable artificial intelligence (XAI) program (2019) Proc. 24th Int. Conf. Intell. User Interfaces (IUI); Hammernik, K., Learning a variational network for reconstruction of accelerated MRI data (2017) Magn. Reson. Med, 79 (6), pp. 3055-3071; Havaei, M., Brain tumor segmentation with deep neural networks (2017) Med. Image Anal, 35, pp. 18-31. , Jan; Heckemann, R.A., Hajnal, J.V., Aljabar, P., Rueckert, D., Hammers, A., Automatic anatomical brain MRI segmentation combining label propagation and decision fusion (2006) Neuro Image, 33 (1), pp. 115-126; Hein, M., Andriushchenko, M., Bitterwolf, J., Why ReLU networks yield high-confidence predictions far away from the training data and how to mitigate the problem (2019) Proc. Comput. Vis. Pattern Recognit. (CVPR), pp. 41-50; Heinrich, M.P., MIND: Modality independent neighbourhood descriptor for multi-modal deformable registration (2012) Med. Image Anal, 16 (7), pp. 1423-1435; Hoffman, J., CyCADA: Cycle-consistent adversarial domain adaptation (2018) Proc. Int. Conf. Mach. Learn. (ICML), pp. 1989-1998; Horn, B.K.P., Schunck, B.G., Determining optical flow (1981) Artif. Intell, 17 (1-3), pp. 185-203. , Aug; Hua, X., Tensor-based morphometry as a neuroimaging biomarker for Alzheimer's disease: An MRI study of 676 AD, MCI, normal subjects (2008) NeuroImage, 43 (3), pp. 458-469; Huizinga, W., A spatio-temporal reference model of the aging brain (2018) NeuroImage, 169, pp. 11-22. , Apr; Irvin, J., (2019) CheXpert: A Large Chest Radiograph Dataset with Uncertainty Labels and Expert Comparison, pp. 1-9. , CoRR, vol. abs/1901.07031, Jan; Jaderberg, M., Simonyan, K., Zisserman, A., Kavukcuoglu, K., Spatial transformer networks (2015) Proc. Adv. Neural Inf. Process. Syst. (NIPS), pp. 2017-2025; Yan, K., Wang, X., Lu, L., Summers, R.M., DeepLesion: Automated mining of large-scale lesion annotations and universal lesion detection with deep learning (2018) J. Med. Imag, 5 (3); Kamnitsas, K., Unsupervised domain adaptation in brain lesion segmentation with adversarial networks (2017) Proc. Inf. Process. Med. Imag. (IPMI), pp. 597-609; Kamnitsas, K., Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation (2017) Med. Image Anal, 36, pp. 61-78. , Feb; Katz, G., Barrett, C., Dill, D.L., Julian, K., Kochenderfer, M.J., Towards proving the adversarial robustness of deep neural networks (2017) Proc. Workshop Formal Verification Auto. Vehicles, pp. 19-26; Klein, A., Evaluation of volume-based and surface-based brain image registration methods (2010) Neuro Image, 51 (1), pp. 214-220; Klöppel, S., Automatic classification of MR scans in Alzheimer's disease (2008) Brain, 131 (3), pp. 681-689; Kohavi, R., A study of cross-validation and bootstrap for accuracy estimation and model selection (1995) Proc. Int. Joint Conf. Artif. Intell. (IJCAI), pp. 1137-1145; Koikkalainen, J., Lötjönen, J., Thurfjell, L., Rueckert, D., Waldemar, G., Soininen, H., Multi-template tensor-based morphometry: Application to analysis of Alzheimer's disease (2011) NeuroImage, 56 (3), pp. 1134-1144; Krebs, J., Delingette, H., Mailhé, B., Ayache, N., Mansi, T., Learning a probabilistic model for diffeomorphic registration (2019) IEEE Trans. Med. Imag, 38 (9), pp. 2165-2176. , Sep; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324. , Nov; Lee, M.C.H., Petersen, K., Pawlowski, N., Glocker, B., Schaap, M., TETRIS: Template transformer networks for image segmentation with shape priors IEEE Trans. Med. Imag., , To be published; Van Leemput, K., Maes, F., Vandermeulen, D., Suetens, P., Automated model-based tissue classification of MR images of the brain (1999) IEEE Trans. Med. Imag, 18 (10), pp. 897-908. , Oct; Leibig, C., Allken, V., Ayhan, M.S., Berens, P., Wahl, S., Leveraging uncertainty information from deep neural networks for disease detection (2017) Sci. Rep, 7. , Dec; Leofante, F., Narodytska, N., Pulina, L., Tacchella, A., (2018) Automated Verification of Neural Networks: Advances, Challenges and Perspectives, pp. 1-8. , CoRR, vol. abs/1805,09938, May; Lin, T.-Y., Microsoft COCO: Common objects in context (2014) Proc. Eur. Conf. Comput. Vis. (ECCV), pp. 740-755; Lindner, C., Thiagarajah, S., Wilkinson, J.M., Wallis, G.A., Cootes, T.F., Development of a fully automatic shape model matching (FASMM) system to derive statistical shape models from radiographs: Application to the accurate capture and global representation of proximal femur shape (2013) Osteoarthritis Cartilage, 21 (10), pp. 1537-1544; Lombaert, H., Grady, L., Pennec, X., Ayache, N., Cheriet, F., Spectral log-demons: Diffeomorphic image registration with very large deformations (2014) Int. J. Comput. Vis, 107 (3), pp. 254-271; Long, J., Shelhamer, E., Darrell, T., Fully convolutional networks for semantic segmentation (2015) Proc. Comput. Vis. Pattern Recognit. (CVPR), pp. 3431-3440; Lorenzi, M., Ayache, N., Frisoni, G.B., Pennec, X., The Alzheimer's disease neuroimaging initiative lcc-demons: A robust and accurate symmetric diffeomorphic registration algorithm (2013) Neuro Image, 81, pp. 470-483. , Nov; Lustig, M., Donoho, D., Pauly, J.M., Sparse MRI: The application of compressed sensing for rapid MR imaging (2007) Magn. Reson. Med, 58 (6), pp. 1182-1195; Maes, F., Collignon, A., Vandermeulen, D., Marchal, G., Suetens, P., Multimodality image registration by maximization of mutual information (1997) IEEE Trans. Med. Imag, 16 (2), pp. 187-198. , Apr; Mahendran, A., Vedaldi, A., Understanding deep image representations by inverting them (2015) Proc. Comput. Vis. Pattern Recognit. (CVPR), pp. 5188-5196; Mansi, T., Pennec, X., Sermesant, M., Delingette, H., Ayache, N., ILogDemons: A demons-based registration algorithm for tracking incompressible elastic biological tissues (2011) Int. J. Comput. Vis, 92 (1), pp. 92-111; McInerney, T., Terzopoulos, D., Deformable models in medical image analysis: A survey (1996) Med. Image Anal, 1 (2), pp. 91-108; Miller, K.L., Multimodal population brain imaging in the UK Biobank prospective epidemiological study (2016) Nature Meurosci, 19, pp. 1523-1536. , Sep; Montillo, A., Shotton, J., Winn, J., Iglesias, J.E., Metaxas, D., Criminisi, A., Entangled decision forests and their application for semantic segmentation of CT images (2011) Proc. Inf. Process. Med. Imag. (IPMI), pp. 184-196; Öksüz, I., Deep learning using k-space based data augmentation for automated cardiac MR motion artefact detection (2018) Medical Image Computing and Computer-Assisted Intervention-MICCAI, pp. 250-258. , Cham, Switzerland: Springer; Oktay Regan, O., Kainz, B., Glocker, B., Rueckert, D., Anatomically constrained neural networks (acnns): Application to cardiac image enhancement and segmentation (2018) IEEE Trans. Med. Imag., 37 (2), pp. 384-395. , Feb; Papiez, B.W., Heinrich, M.P., Fehrenbach, J., Risser, L., Schnabel, J.A., An implicit sliding-motion preserving regularisation via bilateral filtering for deformable image registration (2014) Med. Image Anal, 18 (8), pp. 1299-1311; Petersen, S.E., Imaging in population science: Cardiovascular magnetic resonance in 100, 000 participants of UK Biobank-Rationale, challenges and approaches (2013) J. Cardiovascular Magn. Reson, 15. , May; Qin, C., Joint learning of motion estimation and segmentation for cardiac MR image sequences (2018) Medical Image Computing and Computer-Assisted Intervention-MICCAI, pp. 472-480. , Cham, Switzerland:Springer; Rajchl, M., DeepCut: Object segmentation from bounding box annotations using convolutional neural networks (2017) IEEE Trans. Med. Imag, 36 (2), pp. 674-683. , Feb; Rajpurkar, P., Deep learning for chest radiograph diagnosis: A retrospective comparison of the CheXNeXt algorithm to practicing radiologists (2018) PLoS Med, 15 (11); Ranjan, A., Black, M.J., Optical flow estimation using a spatial pyramid network (2017) Proc. Comput. Vis. Pattern Recognit. (CVPR), pp. 4161-4170; Ravishankar, S., Bresler, Y., MR image reconstruction from highly undersampled k-space data by dictionary learning (2011) IEEE Trans. Med. Imag, 30 (5), pp. 1028-1041. , May; Ronneberger, O., Fischer, P., Brox, T., U-Net: Convolutional networks for biomedical image segmentation (2015) Medical Image Computing and Computer-Assisted Intervention-MICCAI, pp. 234-241. , Cham, Switzerland: Springer; Rueckert, D., Sonoda, L.I., Hayes, C., Hill, D.L.G., Leach, M.O., Hawkes, D.J., Nonrigid registration using free-form deformations: Application to breast MR images (1999) IEEE Trans. Med. Imag., 18 (8), pp. 712-721. , Aug; Russakovsky, O., ImageNet large scale visual recognition challenge (2015) Int. J. Comput. Vis, 115 (3), pp. 211-252. , Dec; Sarwate, A.D., Chaudhuri, K., Signal processing and machine learning with differential privacy: Algorithms and challenges for continuous data (2013) IEEE Signal Process. Mag, 30 (5), pp. 86-94. , Sep; Schlemper, J., Caballero, J., Hajnal, J.V., Price, A.N., Rueckert, D., A deep cascade of convolutional neural networks for dynamic mr image reconstruction (2017) IEEE Trans. Med. Imag, 37 (2), pp. 491-503. , Feb; Schlemper, J., Attention gated networks: Learning to leverage salient regions in medical images (2019) Med. Image Anal, 53, pp. 197-207. , Apr; Sheller, M.J., Reina, G.A., Edwards, B., Martin, J., Bakas, S., Multi-institutional deep learning modeling without sharing patient data: A feasibility study on brain tumor segmentation (2019) Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries, pp. 92-104. , Cham, Switzerland: Springer; Shin, H.-C., Deep convolutional neural networks for computer-aided detection: CNN architectures, dataset characteristics and transfer learning (2016) IEEE Trans. Med. Imag, 35 (5), pp. 1285-1298. , May; Shrikumar, A., Greenside, P., Kundaje, A., Learning important features through propagating activation differences (2017) Proc. Int. Conf. Mach. Learn. (ICML), pp. 3145-3153; Simonyan, K., Vedaldi, A., Zisserman, A., Deep inside convolutional networks: Visualising image classification models and saliency maps (2014) Proc. Int. Conf. Learn. Represent. (ICLR); Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) Proc. Int. Conf. Learn. Represent. (ICLR); Springenberg, J.T., Dosovitskiy, A., Brox, T., Riedmiller, M.A., Striving for simplicity: The all convolutional net (2015) Proc. Int. Conf. Learn. Represent. (ICLR); Studholme, C., Hill, D.L.G., Hawkes, D.J., An overlap invariant entropy measure of 3D medical image alignment (1999) Pattern Recognit, 32 (1), pp. 71-86; Styner, M., Lieberman, J.A., Pantazis, D., Gerig, G., Boundary and medial shape analysis of the hippocampus in schizophrenia (2004) Med. Image Anal, 8 (3), pp. 197-203; Topol, E.J., Individualized medicine from prewomb to tomb (2014) Cell, 157, pp. 241-253. , Mar; Tran, P.V., (2016) A Fully Convolutional Neural Network for Cardiac Segmentation in Short-axis MRI, pp. 1-21. , CoRR, vol. abs/1604.00494, Apr; Vercauteren, T., Pennec, X., Perchant, A., Ayache, N., Diffeomorphic demons: Efficient non-parametric image registration (2009) NeuroImage, 45 (1), pp. S61-S72; Vrooman, H.A., Multi-spectral brain tissue segmentation using automatically trained k-nearest-neighbor classification (2007) Neuro Image, 37 (1), pp. 71-81; Wang, H., Suh, J.W., Das, S.R., Pluta, J.B., Craige, C., Yushkevich, P.A., Multi-atlas segmentation with joint label fusion (2013) IEEE Trans. Pattern Anal. Mach. Intell, 35 (3), pp. 611-623. , Mar; Wang, S., Accelerating magnetic resonance imaging via deep learning (2016) Proc. IEEE Int. Symp. Biomed. Imag. (ISBI), pp. 514-517. , Apr; Warfield, S.K., Kaus, M., Jolesz, F.A., Kikinis, R., Adaptive, template moderated, spatially varying statistical classification (2000) Med. Image Anal, 4 (1), pp. 43-55; Weinzaepfel, P., Revaud, J., Harchaoui, Z., Schmid, C., DeepFlow: Large displacement optical flow with deep matching (2013) Proc. Int. Conf. Comput. Vis. (ICCV), pp. 1385-1392; Weller, A., Transparency: Motivations and challenges (2017) CoRR, , Jun; Wells, W.M., Grimson, W.E.L., Kikinis, R., Jolesz, F.A., Adaptive segmentation of MRI data (1996) IEEE Trans. Med. Imag, 15 (8), pp. 429-442. , Aug; Wells, W.M., Viola, P.A., Atsumi, H., Nakajima, S., Kikinis, R., Multi-modal volume registration by maximization of mutual information (1996) Med. Image Anal, 1 (1), pp. 35-51; Wright, R., LSTM spatial co-transformer networks for registration of 3D fetal US and MR brain images (2018) Proc. Preterm, Perinatal Paediatric Image Anal. Workshop (PIPPI), pp. 149-159; Wu, L., Cheng, J., Li, S., Lei, B., Wang, T., Ni, D., FUIQA: Fetal ultrasound image quality assessment with deep convolutional networks (2017) IEEE Trans. Cybern, 47 (5), pp. 1336-1349. , May; Yang, X., Kwitt, R., Styner, M., Niethammer, M., Quicksilver: Fast predictive image registration-A deep learning approach (2017) NeuroImage, 158, pp. 378-396. , Sep; Zeiler, M.D., Fergus, R., Visualizing and understanding convolutional networks (2014) Proc. Eur. Conf. Comput. Vis. (ECCV), pp. 818-833; Zhang, K., Deng, J., Lu, W., Segmenting human knee cartilage automatically from multi-contrast MR images using support vector machines and discriminative random fields (2011) Proc. Int. Conf. Image Process. (ICIP), pp. 721-724; Zhu, B., Liu, J.Z., Cauley, S.F., Rosen, B.R., Rosen, M.S., Image reconstruction by domain-transform manifold learning (2017) Nature, 555, pp. 487-492. , Mar; Zikic, D., Decision forests for tissue-specific segmentation of high-grade gliomas in multi-channel MR (2012) Medical Image Computing and Computer-Assisted Intervention-MICCAI, pp. 369-376. , Berlin, Germany: Springer","Rueckert, D.; Department of Computing, United Kingdom; 电子邮件: d.rueckert@imperial.ac.uk",,,Institute of Electrical and Electronics Engineers Inc.,,,,,189219,,IEEPA,,English,Proc. IEEE,Article,Final,"All Open Access, Green",Scopus,2-s2.0-85077799075
[无可用作者姓名],[无可用的作者 ID],"6th International Conference on Man-Machine Interactions, ICMMI 2019",2020,Advances in Intelligent Systems and Computing,1061,,,,,258,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075855521&partnerID=40&md5=877f9a604fdf7dc0092b9cd371256880,,,The proceedings contain 24 papers. The special focus in this conference is on International Conference on Man-Machine Interactions. The topics include: FIT2COMIn – Robust Clustering Algorithm for Incomplete Data; GrFCM – Granular Clustering of Granular Data; evaluation of Cosine Similarity Feature for Named Entity Recognition on Tweets; deep Recurrent Neural Networks for Human Activity Recognition During Skiing; recognition of Tennis Shots Using Convolutional Neural Networks Based on Three-Dimensional Data; on Unsupervised and Supervised Discretisation in Mining Stylometric Features; LCR-BLAST—A New Modification of BLAST to Search for Similar Low Complexity Regions in Protein Sequences; risk Susceptibility of Brain Tumor Classification to Adversarial Attacks; prediction of Drug Potency and Latent Relation Analysis in Precision Cancer Treatment; predictions of Age and Mood Based on Changes in Saccades Parameters; VEEP—The System for Motion Tracking in Virtual Reality; using Copula and Quantiles Evolution in Prediction of Multidimensional Distributions for Better Query Selectivity Estimation; Audio-Visual TV Broadcast Signal Segmentation; optimizing Training Data and Hyperparameters of Support Vector Machines Using a Memetic Algorithm; induction of Centre-Based Biclusters in Terms of Boolean Reasoning; issues on Performance of Reactive Programming in the Java Ecosystem with Persistent Data Sources; immersive Virtual Reality for Assisting in Inclusive Architectural Design; spatio-Temporal Filtering for Evoked Potentials Detection; a Review on the Vehicle to Vehicle and Vehicle to Infrastructure Communication; classifying Relation via Piecewise Convolutional Neural Networks with Transfer Learning; ensembles of Active Adaptive Incremental Classifiers; influence of the Applied Outlier Detection Methods on the Quality of Classification.,,,,,,,,,Gruca A.Deorowicz S.Harezlak K.Piotrowska A.Czachorski T.,,Springer,"6th International Conference on Man-Machine Interactions, ICMMI 2019",2 October 2019 through 3 October 2019,,232439,21945357,9.78E+12,,,English,Adv. Intell. Sys. Comput.,Conference Review,Final,,Scopus,2-s2.0-85075855521
[无可用作者姓名],[无可用的作者 ID],AISec 2019 - Proceedings of the 12th ACM Workshop on Artificial Intelligence and Security,2019,Proceedings of the ACM Conference on Computer and Communications Security,,,,,,121,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075855455&partnerID=40&md5=74c0d92186282edca40bd02146feb88d,,,The proceedings contain 10 papers. The topics discussed include: a hybrid approach to privacy-preserving federated learning; HybridAlpha: an efficient approach for privacy-preserving federated learning; robust detection of obfuscated strings in android apps; malware detection on highly imbalanced data through sequence modeling; risk prioritization by leveraging latent vulnerability features in a contested environment; cross-vendor knowledge transfer for managed security services with triplet network; CADENCE: conditional anomaly detection for events using noise-contrastive estimation; making targeted black-box evasion attacks effective and efficient; and interpolated adversarial training: achieving robust neural networks without sacrificing too much accuracy.,,,,,,,,,,ACM SIGSAC,Association for Computing Machinery,"12th ACM Workshop on Artificial Intelligence and Security, AISec 2019, co-located with CCS 2019",15-Nov-19,,154875,15437221,9.78E+12,,,English,Proc ACM Conf Computer Commun Secur,Conference Review,Final,,Scopus,2-s2.0-85075855455
"Aiken J., Scott-Hayward S.",57216272699;54917376600;,Investigating Adversarial Attacks against Network Intrusion Detection Systems in SDNs,2019,"IEEE Conference on Network Function Virtualization and Software Defined Networks, NFV-SDN 2019 - Proceedings",,,9040101,,,,10,10.1109/NFV-SDN47374.2019.9040101,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082997252&doi=10.1109%2fNFV-SDN47374.2019.9040101&partnerID=40&md5=eef19780f6cdd942397ac0fd31f73a0b,"Centre for Secure Information Technologies, Queen's University Belfast, Belfast, BT3 9DT, United Kingdom","Aiken, J., Centre for Secure Information Technologies, Queen's University Belfast, Belfast, BT3 9DT, United Kingdom; Scott-Hayward, S., Centre for Secure Information Technologies, Queen's University Belfast, Belfast, BT3 9DT, United Kingdom","Machine-learning based network intrusion detection systems (ML-NIDS) are increasingly popular in the fight against network attacks. In particular, promising detection results have been demonstrated in conjunction with Software-Defined Networks (SDN), in which the logically centralized control plane provides access to data from across the network. However, research into adversarial attacks against machine learning classifiers has highlighted vulnerabilities in a number of fields. These vulnerabilities raise concerns about the implementation of similar classifiers in anomaly-based NIDSs within SDNs. In this work, we investigate the viability of adversarial attacks against classifiers in this field. We implement an anomaly-based NIDS, Neptune, as a target platform that utilises a number of different machine learning classifiers and traffic flow features. We develop an adversarial test tool, Hydra, to evaluate the impact of adversarial evasion classifier attacks against Neptune with the goal of lowering the detection rate of malicious network traffic. The results demonstrate that with the perturbation of a few features, the detection accuracy of a specific SYN flood Distributed Denial of Service (DDoS) attack by Neptune decreases from 100% to 0% across a number of classifiers. Based on these results, recommendations are made as to how to increase the robustness of classifiers against the demonstrated attacks. © 2019 IEEE.",Adversarial Attacks; Intrusion Detection Systems; Machine Learning; Network Security; Software-Defined Networks,Access control; Denial-of-service attack; Intrusion detection; Learning systems; Machine learning; Network security; Software defined networking; Transfer functions; Adversarial Attacks; Anomaly-based NIDS; Centralized control; Detection accuracy; Detection rates; Distributed denial of service attack; Intrusion Detection Systems; Network intrusion detection systems; Network function virtualization,,,,,"Ahmad, I., Namal, S., Ylianttila, M., Gurtov, A., Security in software defined networks: A survey (2015) IEEE Communications Surveys Tutorials, 17 (4), pp. 2317-2346. , Fourthquarter; Corona, I., Giacinto, G., Roli, F., Adversarial attacks against intrusion detection systems: Taxonomy, solutions and open issues (2013) Information Sciences, 239, pp. 201-225; Kwon, H., Kim, Y., Park, K., Yoon, H., Choi, C., Multi-targeted adversarial example in evasion attack on deep neural network (2018) IEEE Access, 6, pp. 46084-46096; Goodfellow, I., McDaniel, P., Papernot, N., Making machine learning robust against adversarial inputs (2018) Commun. Acm, 61 (7), pp. 56-66. , Jun; Pawar, K., Patil, M., Pattern classification under attack on spam filtering (2015) 2015 Ieee International Conference on Research in Computational Intelligence and Communication Networks (ICRCICN), pp. 197-201. , Nov; Liu, Q., Li, P., Zhao, W., Cai, W., Yu, S., Leung, V.C.M., A survey on security threats and defensive techniques of machine learning: A data driven view (2018) IEEE Access, 6, pp. 12103-12117; Wang, Z., Deep learning-based intrusion detection with adversaries (2018) IEEE Access, 6, pp. 38367-38384; Abaid, Z., Kaafar, M.A., Jha, S., Quantifying the impact of adversarial evasion attacks on machine learning based android malware classifiers 2017 Ieee 16th International Symposium on Network Computing and Applications (NCA), pp. 1-10. , Oct 2017; Liu, X., Lin, Y., Li, H., Zhang, J., Adversarial examples: Attacks on machine learning-based malware visualization detection methods (2018) CoRR, , vol. abs/1808.01546; Biggio, B., Evasion attacks against machine learning at test time (2013) Joint European Conference on Machine Learning and Knowledge Discovery in Databases., pp. 387-402. , Springer; Goodfellow, I.J., Papernot, N., McDaniel, P.D., Cleverhans v2.1.0: An adversarial machine learning library (2018) CoRR, , vol. abs/1610.00768v6; Lee, S., Kim, J., Shin, S., Porras, P., Yegneswaran, V., Athena: A framework for scalable anomaly detection in software-defined networks (2017) 2017 47th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN), pp. 249-260. , June; Abubakar, A., Pranggono, B., Machine learning based intrusion detection system for software defined networks (2017) 2017 Seventh International Conference on Emerging Security Technologies (EST), pp. 138-143. , Sept; Sultana, N., Survey on SDN based network intrusion detection system using machine learning approaches (2018) Peer-to-Peer Networking and Applications, 1, pp. 1-9; Braga, R., Mota, E., Passito, A., Lightweight DDoS flooding attack detection using NOX/OpenFlow (2010) IEEE Local Computer Network Conference, pp. 408-415. , Oct; Mehdi, S.A., Khalid, J., Khayam, S.A., Revisiting traffic anomaly detection using software defined networking (2011) Proceedings of the 14th Int. Conf. on Recent Advances in Intrusion Detection, Ser. RAID'11., pp. 161-180. , Springer-Verlag; Tang, T.A., Mhamdi, L., McLernon, D., Zaidi, S., Ghogho, M., Deep learning approach for network intrusion detection in software defined networking (2016) 2016 Int. Conf. on Wireless Networks and Mobile Communications (WINCOM), pp. 258-263. , Oct; Niyaz, Q., Sun, W., Javaid, A.Y., A deep learning based DDoS detection system in software-defined networking (SDN) (2016) CoRR, , vol. abs/1611.07400; (2019) Faucet SDN Controller., , https://faucet.nz/, faucetsdn. [Online]; (2019) Argus Network Activity., , https://qosient.com/argus/index.shtml, QoSient. [Online]; (1999) Kdd Cup 1999 Data., , http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html, I. University of California. [Online]; McHugh, J., Testing intrusion detection systems: A critique of the 1998 and 1999 DARPA intrusion detection system evaluations as performed by lincoln laboratory (2000) Acm Transactions on Information and System Security (TISSEC), 3 (4), pp. 262-294; Sharafaldin, I., Habibi Lashkari, A., Ghorbani, A., Toward generating a new intrusion detection dataset and intrusion traffic characterization (2018) 4th International Conference on Information Systems Security and Privacy (ICISSP), pp. 108-116. , 01; Manaf Gharaibeh, C.S.U., (2009) DARPA 2009 Intrusion Detection Dataset., , http://www.darpa2009.netsec.colostate.edu, [Online]; (2017) Recursive Feature Elimination (RFE)., , https://scikitlearn.org/stable/modules/generated/sklearn.featureselection.RFE.html, Scikit-Learn. [Online]; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint arXiv:1412.6572; Zhou, L., Liao, M., Yuan, C., Zhang, H., Low-rate DDoS attack detection using expectation of packet size (2017) Security and Communication Networks, 2017",,Horner L.Tutschku K.Granelli F.Sekiya Y.Tacca M.Bhamare D.Parzyjegla H.,Fujitsu;Intel,Institute of Electrical and Electronics Engineers Inc.,"2019 IEEE Conference on Network Function Virtualization and Software Defined Networks, NFV-SDN 2019",12 November 2019 through 14 November 2019,,158707,,9.78E+12,,,English,"IEEE Conf. Netw. Funct. Virtualiz. Softw. Defined Networks, NFV-SDN - Proc.",Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85082997252
"Chacon H., Silva S., Rad P.",57215531892;57208798841;56748978800;,Deep learning poison data attack detection,2019,"Proceedings - International Conference on Tools with Artificial Intelligence, ICTAI",2019-November,,8995262,971,978,,2,10.1109/ICTAI.2019.00137,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081094430&doi=10.1109%2fICTAI.2019.00137&partnerID=40&md5=0b19c60fe5ca3dc9d416155c302d9f54,"Department of Management Sciences and Statistics, University of Texas at San Antonio, San Antonio, TX  78294, United States; Department of Electrical and Computer Engineering, University of Texas at San Antonio, San Antonio, TX  78294, United States; Department of Information Systems and Cyber Security, University of Texas at San Antonio, San Antonio, TX  78294, United States; Secure Ai and Autonomy Laboratory, University of Texas at San Antonio, San Antonio, TX  78294, United States","Chacon, H., Department of Management Sciences and Statistics, University of Texas at San Antonio, San Antonio, TX  78294, United States, Secure Ai and Autonomy Laboratory, University of Texas at San Antonio, San Antonio, TX  78294, United States; Silva, S., Department of Electrical and Computer Engineering, University of Texas at San Antonio, San Antonio, TX  78294, United States, Secure Ai and Autonomy Laboratory, University of Texas at San Antonio, San Antonio, TX  78294, United States; Rad, P., Department of Information Systems and Cyber Security, University of Texas at San Antonio, San Antonio, TX  78294, United States, Secure Ai and Autonomy Laboratory, University of Texas at San Antonio, San Antonio, TX  78294, United States","Deep neural networks are widely used in many walks of life. Techniques such as transfer learning enable neural networks pre-trained on certain tasks to be retrained for a new duty, often with much less data. Users have access to both pre-trained model parameters and model definitions along with testing data but have either limited access to training data or just a subset of it. This is risky for system-critical applications, where adversarial information can be maliciously included during the training phase to attack the system. Determining the existence and level of attack in a model is challenging. In this paper, we present evidence on how adversarially attacking training data increases the boundary of model parameters using as an example of a CNN model and the MNIST data set as a test. This expansion is due to new characteristics of the poisonous data that are added to the training data. Approaching the problem from the feature space learned by the network provides a relation between them and the possible parameters taken by the model on the training phase. An algorithm is proposed to determine if a given network was attacked in the training by comparing the boundaries of parameters distribution on intermediate layers of the model estimated by using the Maximum Entropy Principle and the Variational inference approach. © 2019 IEEE.",Bayesian statistic; Deep learning; Maximum Entropy method; Network attack; Poisoned training data; Variational inference,Deep neural networks; Inference engines; Maximum entropy methods; Statistical tests; Transfer learning; Bayesian statistics; Critical applications; Intermediate layers; Maximum entropy principle; Model parameters; Network attack; Training data; Variational inference; Deep learning,,,,,"Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security. ACM, pp. 506-519; Kendall, A., Gal, Y., (2017) What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?, , http://arxiv.org/abs/1703.04977, CoRR abs/1703. 04977; Silva, S.H., Rad, P., Beebe, N., Choo, K.-K.R., Umapathy, M., Cooperative unmanned aerial vehicles with privacy preserving deep vision for real-time object identification and tracking (2019) Journal of Parallel and Distributed Computing, 131, pp. 147-160; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks; Biggio, B., Roli, F., Wild patterns: Ten years after the rise of adversarial machine learning (2018) Pattern Recognition, 84, pp. 317-331; Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., (2017) On the (Statistical) Detection of Adversarial Examples; Torrey, L., Shavlik, J., Transfer learning (2010) Handbook of Research on Machine Learning Applications and Trends: Algorithms, Methods, and Techniques, pp. 242-264. , IGI Global; Wang, B., Yao, Y., Shan, S., Li, H., Viswanath, B., Zheng, H., Zhao, B.Y., Neural cleanse: Identifying and mitigating backdoor attacks in neural networks (2019) Neural Cleanse: Identifying and Mitigating Backdoor Attacks in Neural Networks, p. 0. , IEEE; Tran, B., Li, J., Madry, A., Spectral signatures in backdoor attacks (2018) Advances in Neural Information Processing Systems, pp. 8000-8010; Cardelli, L., Kwiatkowska, M., Laurenti, L., Patane, A., Robustness guarantees for Bayesian inference with gaussian processes (2019) Proceedings of the AAAI Conference on Artificial Intelligence, 33, pp. 7759-7768; Polson, N.G., Sokolov, V., Deep learning: A Bayesian perspective (2017) Bayesian Analysis, 12 (4), pp. 1275-1304; Gal, Y., (2016) Uncertainty in Deep Learning, , Ph. D. dissertation, PhD thesis, University of Cambridge; Ormerod, J.T., Wand, M.P., Explaining variational approximations (2010) The American Statistician, 64 (2), pp. 140-153; Shridhar, K., Laumann, F., Liwicki, M., (2019) A Comprehensive Guide to Bayesian Convolutional Neural Network with Variational Inference; Kingma, D.P., (2017) Variational Inference & Deep Learning: A New Synthesis; Wainwright, M.J., Jordan, M.I., Graphical models, exponential families, and variational inference (2008) Foundations and Trends® in Machine Learning, 1 (1-2), pp. 1-305; LeCun, Y., (2015) Lenet-5 convolutional neural networks, 20, p. 5. , http://yann.LeCun.com/exdb/lenet; Biggio, B., Nelson, B., Laskov, P., (2012) Poisoning Attacks Against Support Vector Machines; Yang, C., Wu, Q., Li, H., Chen, Y., (2017) Generative Poisoning Attack Method Against Neural Networks; Shafahi, A., Huang, W.R., Najibi, M., Suciu, O., Studer, C., Dumitras, T., Goldstein, T., Poison frogs! targeted clean-label poisoning attacks on neural networks (2018) Advances in Neural Information Processing Systems, pp. 6103-6113; Hendrycks, D., Mazeika, M., Wilson, D., Gimpel, K., Using trusted data to train deep networks on labels corrupted by severe noise (2018) Advances in Neural Information Processing Systems, pp. 10456-10465; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP). IEEE, pp. 39-57; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses; Papernot, N., Goodfellow, I., Sheatsley, R., Feinman, R., McDaniel, P., (2016) Cleverhans v1. 0. 0: An Adversarial Machine Learning Library, 10; Grosse, K., Pfaff, D., Smith, M.T., Backes, M., (2018) The Limitations of Model Uncertainty in Adversarial Settings; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proceedings of the IEEE, 86 (11), pp. 2278-2324; LeCun, Y., Boser, B., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W., Jackel, L.D., Backpropagation applied to handwritten zip code recognition (1989) Neural Computation, 1 (4), pp. 541-551; Goodfellow, I., Bengio, Y., Courville, A., (2016) Deep Learning., , MIT press; Jaynes, E.T., Information theory and statistical mechanics (1957) Physical Review, 106 (4), p. 620; Golan, A., (2017) Foundations of Info-metrics: Modeling, Inference, and Imperfect Information, , Oxford University Press; Kapur, J., (2009) Maximum-Entropy Models in Science and Engineering, , 1st ed. New age international publishers; Henryk, G., (1995) The Method of Maximum Entropy, 29. , World scientific; Mnatsakanov, R., Hakobyan, A., Recovery of distributions via moments (2009) Lecture Notes-Monograph Series, 57, pp. 252-265; Lin, G., Recent developments on the moment problem (2017) Journal of Statistical Distributions and Applications, 4 (5); Blei, D.M., Build, compute, critique, repeat: Data analysis with latent variable models (2014) Annual Review of Statistics and Its Application, 1, pp. 203-232; Cover, T.M., Thomas, J.A., (2012) Elements of Information Theory, , John Wiley & Sons; Shannon, C.E., A mathematical theory of communication (1948) Bell System Technical Journal, pp. 379-423; Cover, T.M., Thomas, J.A., (2005) Elements of Information Theory, , Willey",,,,IEEE Computer Society,"31st IEEE International Conference on Tools with Artificial Intelligence, ICTAI 2019",4 November 2019 through 6 November 2019,,157766,10823409,9.78E+12,PCTIF,,English,Proc. Int. Conf. Tools Artif. Intell. ICTAI,Conference Paper,Final,,Scopus,2-s2.0-85081094430
"Xiao C., Deng R., Li B., Lee T., Edwards B., Yi J., Song D., Liu M., Molloy I.",56379538100;57204286868;57188689924;56122325800;56431268400;36095116600;7402443870;9733562100;23478119000;,AdvIT: Adversarial frames identifier based on temporal consistency in videos,2019,Proceedings of the IEEE International Conference on Computer Vision,2019-October,,9010733,3967,3976,,7,10.1109/ICCV.2019.00407,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081909913&doi=10.1109%2fICCV.2019.00407&partnerID=40&md5=3586174b68e05f81b321f36ff7ff2c39,"University of Michigan, Ann Arbor, United States; Simon Fraser University, Canada; UIUC; IBM Research AI; JD.com; UC Berkeley, United States","Xiao, C., University of Michigan, Ann Arbor, United States; Deng, R., Simon Fraser University, Canada; Li, B., UIUC; Lee, T., IBM Research AI; Edwards, B., IBM Research AI; Yi, J., JD.com; Song, D., UC Berkeley, United States; Liu, M., University of Michigan, Ann Arbor, United States; Molloy, I., IBM Research AI","Deep neural networks (DNNs) have been widely applied in various applications, including autonomous driving and surveillance systems. However, DNNs are found to be vulnerable to adversarial examples, which are carefully crafted inputs aiming to mislead a learner to make incorrect predictions. While several defense and detection approaches are proposed for static image classification, many security-critical tasks use videos as their input and require efficient processing. In this paper, we propose an efficient and effective method advIT to detect adversarial frames within videos against different types of attacks based on temporal consistency property of videos. In particular, we apply optical flow estimation to the target and previous frames to generate pseudo frames and evaluate the consistency of the learner output between these pseudo frames and target. High inconsistency indicates that the target frame is adversarial. We conduct extensive experiments on various learning tasks including video semantic segmentation, human pose estimation, object detection, and action recognition, and demonstrate that we can achieve above 95% adversarial frame detection rate. To consider adaptive attackers, we show that even if an adversary has access to the detector and performs a strong adaptive attack based on the state of the art expectation of transformation method, the detection rate stays almost the same. We also tested the transferability among different optical flow estimators and show that it is hard for attackers to attack one and transfer the perturbation to others. In addition, as efficiency is important in video analysis, we show that advIT can achieve real-time detection in about 0.03 - 0.4 seconds. © 2019 IEEE.",,Computer vision; Deep neural networks; Optical flows; Semantics; Action recognition; Detection approach; Human pose estimations; Optical flow estimation; Real-time detection; Surveillance systems; Temporal consistency; Transformation methods; Object detection,,,,,"(2017) Davis Challenge, , https://davischallenge.org/challenge2017.html; Youtube Video, , https://www.youtube.com/watch?v=vgusHl1Oue0; Andriluka, M., Pishchulin, L., Gehler, P., Schiele, B., 2d human pose estimation: New benchmark and state of the art analysis (2014) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , June; Athalye, A., Carlini, N., Wagner, D., Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples (2018) ICML; Cao, Y., Xiao, C., Cyr, B., Zhou, Y., Park, W., Rampazzi, S., Alfred Chen, Q., Morley Mao, Z., Adversarial sensor attack on lidar-based perception in autonomous driving (2019) CCS; Cao, Y., Xiao, C., Yang, D., Fang, J., Yang, R., Liu, M., Li, B., (2019) Adversarial Objects Against Lidar-based Autonomous Driving Systems; Cao, Z., Hidalgo, G., Simon, T., Wei, S., Sheikh, Y., (2018) OpenPose: Realtime Multi-person 2D Pose Estimation Using Part Affinity Fields; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 3-14. , ACM; Carlini, N., Wagner, D.A., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy, SP 2017, 2017, pp. 39-57. , San Jose, CA, USA, May 22-26; Cisse, M., Adi, Y., Neverova, N., Keshet, J., Houdini: Fooling deep structured prediction models (2017) Advances in Neural Information Processing Systems 30; Das, N., Shanbhogue, M., Chen, S., Hohman, F., Chen, L., Kounavis, M.E., Horng Chau, D., (2017) Keeping the Bad Guys Out: Protecting and Vaccinating Deep Learning with Jpeg Compression; Dosovitskiy, A., Fischer, P., Ilg, E., Hausser, P., Hazirbas, C., Golkov, V., Van Der Smagt, P., Brox, T., Flownet: Learning optical flow with convolutional networks (2015) Proceedings of the IEEE ICCV, pp. 2758-2766; Karolina Dziugaite, G., Ghahramani, Z., Roy, D.M., (2016) A Study of the Effect of Jpg Compression on Adversarial Images; Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Xiao, C., Prakash, A., Song, D., Robust physical-world attacks on deep learning visual classification (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1625-1634; Girshick, R., Fast r-cnn (2015) Proceedings of the IEEE International Conference on Computer Vision, pp. 1440-1448; Girshick, R., Donahue, J., Darrell, T., Malik, J., Rich feature hierarchies for accurate object detection and semantic segmentation (2014) Proceedings of the IEEE CVPR, pp. 580-587; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR; Guo, C., Rana, M., Cisse, M., Van Der Maaten, L., Countering adversarial images using input transformations (2018) ICLR; Ilg, E., Mayer, N., Saikia, T., Keuper, M., Dosovitskiy, A., Brox, T., Flownet 2. 0: Evolution of optical flow estimation with deep networks (2017) IEEE Conference on CVPR, 2, p. 6; Liu, C., (2009) Beyond Pixels: Exploring New Representations and Applications for Motion Analysis, , PhD thesis, Massachusetts Institute of Technology; Long, J., Shelhamer, E., Darrell, T., Fully convolutional networks for semantic segmentation (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3431-3440; Ma, X., Li, B., Wang, Y., Erfani, S.M., Wijewickrema, S., Houle, M.E., Schoenebeck, G., Bailey, J., (2018) Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks; Moosavi-Dezfooli, S., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1765-1773; Newell, A., Yang, K., Deng, J., Stacked hourglass networks for human pose estimation (2016) European Conference on Computer Vision, pp. 483-499. , Springer; Paszke, A., Chaurasia, A., Kim, S., Culurciello, E., (2016) Enet: A Deep Neural Network Architecture for Real-time Semantic Segmentation; Puri, A., Kollarits, R., Haskell, B., Basics of stereoscopic video, new compression results with MPEG-2 and a proposal for MPEG-4 (1997) Sig. Proc. : Image Comm., 10 (1-3), pp. 201-234; Qiu, H., Xiao, C., Yang, L., Yan, X., Lee, H., Li, B., (2019) Semanticadv: Generating Adversarial Examples Via Attribute-conditional Image Editing; Redmon, J., Divvala, S., Girshick, R., Farhadi, A., You only look once: Unified, real-time object detection (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 779-788; Redmon, J., Farhadi, A., (2018) Yolov3: An Incremental Improvement; Ren, S., He, K., Girshick, R., Sun, J., Faster r-cnn: Towards real-time object detection with region proposal networks (2015) Advances in Neural Information Processing Systems, pp. 91-99; Song, D., Eykholt, K., Evtimov, I., Fernan-Des, E., Li, B., Rahmati, A., Tramer, F., Kohno, T., Physical adversarial examples for object detectors (2018) 12th FUSENIXg Workshop on Offensive Technologies (FWOOTg 18); Soomro, K., Roshan Zamir, A., Shah, M., Ucf101: A dataset of 101 human actions classes from videos in the wild (2012) CRCV-TR-12-01; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2018) ICLR; Tsipras, D., Santurkar, S., Engstrom, L., Turner, A., Madry, A., Robustness may be at odds with accuracy) (2018) ICLR 2019; Wei, X., Zhu, J., Su, H., Sparse adversarial perturbations for videos (2018) AAAI 2019; Xiao, C., Deng, R., Li, B., Yu, F., Song, D., Characterizing adversarial examples based on spatial consistency information for semantic segmentation (2018) Proceedings of the (ECCV), pp. 217-234; Xiao, C., Li, B., Zhu, J., He, W., Liu, M., Song, D., Generating adversarial examples with adversarial networks (2018) IJCAI; Xiao, C., Pan, X., He, W., Peng, J., Sun, M., Yi, J., Li, B., Song, D., (2019) Characterizing Attacks on Deep Reinforcement Learning; Xiao, C., Yang, D., Li, B., Deng, J., Liu, M., Meshadv: Adversarial meshes for visual recognition (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 6898-6907; Xiao, C., Zhu, J., Li, B., He, W., Liu, M., Song, D., Spatially transformed adversarial examples (2018) International Conference on Learning Representations; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., Adversarial examples for semantic segmentation and object detection (2017) International Conference on Computer Vision. IEEE; Yu, F., Koltun, V., Funkhouser, T., Dilated residual networks (2017) Computer Vision and Pattern Recognition (CVPR)",,,Computer Vision Foundation;IEEE,Institute of Electrical and Electronics Engineers Inc.,"17th IEEE/CVF International Conference on Computer Vision, ICCV 2019",27 October 2019 through 2 November 2019,,158036,15505499,9.78E+12,PICVE,,English,Proc IEEE Int Conf Comput Vision,Conference Paper,Final,,Scopus,2-s2.0-85081909913
"Huang Q., Katsman I., Gu Z., He H., Belongie S., Lim S.-N.",57214660367;57207770021;57215772539;57215775714;6603376681;57215775116;,Enhancing adversarial example transferability with an intermediate level attack,2019,Proceedings of the IEEE International Conference on Computer Vision,2019-October,,9008298,4732,4741,,21,10.1109/ICCV.2019.00483,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081908467&doi=10.1109%2fICCV.2019.00483&partnerID=40&md5=858330cbdcad74031b3c8feefbdc8568,"Cornell University, United States; Facebook AI","Huang, Q., Cornell University, United States; Katsman, I., Cornell University, United States; Gu, Z., Cornell University, United States; He, H., Cornell University, United States; Belongie, S., Cornell University, United States; Lim, S.-N., Facebook AI","Neural networks are vulnerable to adversarial examples, malicious inputs crafted to fool trained models. Adversarial examples often exhibit black-box transfer, meaning that adversarial examples for one model can fool another model. However, adversarial examples are typically overfit to exploit the particular architecture and feature representation of a source model, resulting in sub-optimal black-box transfer attacks to other target models. We introduce the Intermediate Level Attack (ILA), which attempts to fine-tune an existing adversarial example for greater black-box transferability by increasing its perturbation on a pre-specified layer of the source model, improving upon state-of-the-art methods. We show that we can select a layer of the source model to perturb without any knowledge of the target models while achieving high transferability. Additionally, we provide some explanatory insights regarding our method and the effect of optimizing for adversarial examples using intermediate feature maps. © 2019 IEEE.",,Computer science; Computers; Electrical engineering; Black boxes; Feature map; Feature representation; Intermediate level; Source modeling; State-of-the-art methods; Target model; Computer vision,,,,,"Athalye, A., Carlini, N., Wagner, D.A., Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples (2018) ICML; Brown, T.B., Mané, D., Roy, A., Abadi, M., Gilmer, J., Adversarial patch (2017) CoRR, , abs/1712. 09665; Cadene, R., (2019) Pretrained-models, , https://github.com/Cadene/pretrained-models.pytorch, pytorch; Carlini, N., Wagner, D.A., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP), pp. 39-57; Deng, J., Dong, W., Socher, R., Li, L., Li, K., Fei-Fei, L., Imagenet: A large-scale hierarchical image database (2009) 2009 IEEE Conference on Computer Vision and Pattern Recognition, pp. 248-255; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., (2017) Boosting Adversarial Attacks with Momentum; Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Xiao, C., Prakash, A., Song, D., (2017) Robust Physical-world Attacks on Deep Learning Models; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2014) CoRR, , abs/1412. 6572; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 770-778; Hu, J., Shen, L., Sun, G., Squeeze-and-excitation networks (2017) CoRR, , abs/1709. 01507; Huang, G., Liu, Z., Van Der Maaten, L., Weinberger, K.Q., Densely connected convolutional networks (2017) 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2261-2269; Inkawhich, N., Wen, W., Helen Li, H., Chen, Y., Feature space perturbations yield more transferable adversarial examples (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 7066-7074; Krizhevsky, A., (2009) Learning Multiple Layers of Features from Tiny Images; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) NIPS; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial examples in the physical world (2016) CoRR, , abs/1607. 02533; Liu, K., (2018) Pytorch cifar10, , https://github.com/kuangliu/pytorch-cifar; Liu, Y., Chen, X., Liu, C., Xiaodong Song, D., Delving into transferable adversarial examples and black-box attacks (2016) CoRR, , abs/1611. 02770; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2017) CoRR, , abs/1706. 06083; Marcel, S., Rodriguez, Y., Torchvision the machine-vision package of torch (2010) ACM Multimedia; Moosavi-Dezfooli, S., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 86-94; Moosavi-Dezfooli, S., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2574-2582; Reddy Mopuri, K., Ganeshan, A., Venkatesh Babu, R., Generalizable data-free objective for crafting universal adversarial perturbations (2018) IEEE Transactions on Pattern Analysis and Machine Intelligence; Papernot, N., McDaniel, P.D., Goodfellow, I.J., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) AsiaCCS; Rozsa, A., Günther, M., Boult, T.E., LOTS about attacking deep features (2017) International Joint Conference on Biometrics (IJCB); Sabour, S., Cao, Y., Faghri, F., Fleet, D.J., Adversarial manipulation of deep representations (2015) CoRR, , abs/1511. 05122; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Adversarial generative nets: Neural network attacks on state-of-the-art face recognition (2017) CoRR, , abs/1801. 00349; Sinha, A., Namkoong, H., Duchi, J.C., (2017) Certifying Some Distributional Robustness with Principled Adversarial Training; Su, J., Vasconcellos Vargas, D., Sakurai, K., One pixel attack for fooling deep neural networks (2017) CoRR, , abs/1710. 08864; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S.E., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1-9; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R., Intriguing properties of neural networks (2013) CoRR, , abs/1312. 6199; Xie, C., Zhang, Z., Zhou, Y., Bai, S., Wang, J., Ren, Z., Yuille, A.L., Improving transferability of adversarial examples with input diversity (2019) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , June; Yuan, X., He, P., Zhu, Q., Rana Bhat, R., Li, X., Adversarial examples: Attacks and defenses for deep learning (2017) CoRR, , abs/1712. 07107; Zhou, W., Hou, X., Chen, Y., Tang, M., Huang, X., Gan, X., Yang, Y., Transferable adversarial perturbations (2018) ECCV",,,Computer Vision Foundation;IEEE,Institute of Electrical and Electronics Engineers Inc.,"17th IEEE/CVF International Conference on Computer Vision, ICCV 2019",27 October 2019 through 2 November 2019,,158036,15505499,9.78E+12,PICVE,,English,Proc IEEE Int Conf Comput Vision,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85081908467
"Subramanya A., Pillai V., Pirsiavash H.",57195937080;57215770475;22235347900;,Fooling network interpretation in image classification,2019,Proceedings of the IEEE International Conference on Computer Vision,2019-October,,9010911,2020,2029,,17,10.1109/ICCV.2019.00211,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081900402&doi=10.1109%2fICCV.2019.00211&partnerID=40&md5=dd03e98ed0cadd7e605e83a02a2b51d2,"University of Maryland, Baltimore County, United States","Subramanya, A., University of Maryland, Baltimore County, United States; Pillai, V., University of Maryland, Baltimore County, United States; Pirsiavash, H., University of Maryland, Baltimore County, United States","Deep neural networks have been shown to be fooled rather easily using adversarial attack algorithms. Practical methods such as adversarial patches have been shown to be extremely effective in causing misclassification. However, these patches are highlighted using standard network interpretation algorithms, thus revealing the identity of the adversary. We show that it is possible to create adversarial patches which not only fool the prediction, but also change what we interpret regarding the cause of the prediction. Moreover, we introduce our attack as a controlled setting to measure the accuracy of interpretation algorithms. We show this using extensive experiments for Grad-CAM interpretation that transfers to occluding patch interpretation as well. We believe our algorithms can facilitate developing more robust network interpretation tools that truly explain the network's underlying decision making process. © 2019 IEEE.",,Computer vision; Decision making; Deep neural networks; Decision making process; Interpretation tools; Misclassifications; Practical method; Robust network; Image classification,,,,,"Adebayo, J., Gilmer, J., Muelly, M., Goodfellow, I.J., Hardt, M., Kim, B., Sanity checks for saliency maps (2018) NeurIPS; Athalye, A., Carlini, N., Wagner, D.A., Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples (2018) ICML; Athalye, A., Engstrom, L., Ilyas, A., Kwok, K., Synthesizing robust adversarial examples (2018) ICML; Baehrens, D., Schroeter, T., Harmeling, S., Kawanabe, M., Hansen, K., Mažller, K., How to explain individual classification decisions (2010) Journal of Machine Learning Research, 11, pp. 1803-1831. , (Jun); Brown, T.B., Mane, D., Roy, A., Abadi, M., Gilmer, J., Adversarial patch (2017) Machine Learning and Computer Security Workshop-NeurIPS; Carlini, N., Wagner, D.A., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) AISec@CCS; Chen, S., Cornelius, C., Martin, J., Horng Chau, D., (2018) Robust Physical Adversarial Attack on Faster R-cnn Object Detector; Ching, T., Himmelstein, D.S., Beaulieu-Jones, B.K., Kalinin, A.A., Do, B.T., Way, G.P., Ferrero, E., Hoffman, M.M., Opportunities and obstacles for deep learning in biology and medicine (2018) Journal of the Royal Society Interface, 15 (141), p. 20170387; Deng, J., Dong, W., Socher, R., Li, L., Li, K., Fei-Fei, L., Imagenet: A large-scale hierarchical image database (2009) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2009. CVPR, pp. 248-255. , IEEE, 2009; Doshi-Velez, F., Kortz, M., Budish, R., Bavitz, C., Gershman, S., O'Brien, D., Schieber, S., Wood, A., (2017) Accountability of Ai under the Law: The Role of Explanation; Finlayson, S.G., Bowers, J.D., Ito, J., Zittrain, J.L., Beam, A.L., Kohane, I.S., Adversarial attacks on medical machine learning (2019) Science, 363 (6433), pp. 1287-1289; Ghorbani, A., Abid, A., Zou, J., (2017) Interpretation of Neural Networks Is Fragile; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2014) International Conference on Learning Representations (ICLR); Hadsell, R., Chopra, S., LeCun, Y., Dimensionality reduction by learning an invariant mapping (2006) 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06), 2, pp. 1735-1742. , IEEE; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 770-778; Heo, J., Joo, S., Moon, T., (2019) Fooling Neural Network Interpretations Via Adversarial Model Manipulation; Iandola, F.N., Moskewicz, M.W., Karayev, S., Girshick, R.B., Darrell, T., Keutzer, K., Densenet: Implementing efficient convnet descriptor pyramids (2014) CoRR, , abs/1404. 1869; Karmon, D., Zoran, D., Goldberg, Y., (2018) Lavan: Localized and Visible Adversarial Noise; Kindermans, P., Hooker, S., Adebayo, J., Alber, M., Schutt, K.T., Dahne, S., Erhan, D., Kim, B., (2017) The (Un) Reliability of Saliency Methods; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2016) International Conference on Learning Representations (ICLR); Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Machine Learning at Scale; Li, K., Wu, Z., Peng, K., Ernst, J., Fu, Y., Tell me where to look: Guided attention inference network (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2921-2929. , IEEE; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) International Conference on Learning Representations; Mosenia, A., Jha, N.K., A comprehensive study of security of internet-of-things (2017) IEEE Transactions on Emerging Topics in Computing, 5 (4), pp. 586-602; Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., Lin, Z., Lerer, A., (2017) Automatic Differentiation in Pytorch; Selvaraju, R.R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., Batra, D., Grad-cam: Visual explanations from deep networks via gradient-based localization (2017) The IEEE International Conference on Computer Vision (ICCV), , Oct; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540. , ACM; Simonyan, K., Vedaldi, A., Zisserman, A., (2013) Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps; Sitawarin, C., Nitin Bhagoji, A., Mosenia, A., Chiang, M., Mittal, P., (2018) Darts: Deceiving Autonomous Cars with Toxic Signs; Song, D., Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Tramer, F., Kohno, T., Physical adversarial examples for object detectors 12th USENIX Workshop on Offensive Technologies (WOOT 18), , Baltimore, MD, 2018. USENIX Association; Su, J., Vasconcellos Vargas, D., Sakurai, K., One pixel attack for fooling deep neural networks (2019) IEEE Transactions on Evolutionary Computation; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R., Intriguing properties of neural networks (2013) ICLR, , abs/1312. 6199; Zajac, M., Zona, K., Rostamzadeh, N., Pinheiro, P.O., (2018) Adversarial Framing for Image and Video Classification; Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., Torralba, A., Object detectors emerge in deep scene cnns (2015) ICLR, , abs/1412. 6856; Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., Torralba, A., Learning deep features for discriminative localization (2016) Computer Vision and Pattern Recognition (CVPR), 2016 IEEE Conference on, pp. 2921-2929. , IEEE",,,Computer Vision Foundation;IEEE,Institute of Electrical and Electronics Engineers Inc.,"17th IEEE/CVF International Conference on Computer Vision, ICCV 2019",27 October 2019 through 2 November 2019,,158036,15505499,9.78E+12,PICVE,,English,Proc IEEE Int Conf Comput Vision,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85081900402
"Zhang Y., Yan J.",57212311005;55556549900;,Domain-adversarial transfer learning for robust intrusion detection in the smart grid,2019,"2019 IEEE International Conference on Communications, Control, and Computing Technologies for Smart Grids, SmartGridComm 2019",,,8909793,,,,2,10.1109/SmartGridComm.2019.8909793,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076397750&doi=10.1109%2fSmartGridComm.2019.8909793&partnerID=40&md5=fefaf2f6950028a363bf0b005d3c3df7,"Concordia University, Department of Computer Science and Software Engineering (CSSE), Montréal, QC, Canada","Zhang, Y., Concordia University, Department of Computer Science and Software Engineering (CSSE), Montréal, QC, Canada; Yan, J., Concordia University, Department of Computer Science and Software Engineering (CSSE), Montréal, QC, Canada","The smart grid faces growing cyber-physical attack threats aimed at the critical systems and processes communicating over the complex cyber-infrastructure. Thanks to the increasing availability of high-quality data and the success of deep learning algorithms, machine learning (ML)-based detection and classification have been increasingly effective and adopted against sophisticated attacks. However, many of these techniques rely on the assumptions that the training and testing datasets share the same distribution and the same class labels in a stationary environment. As such assumptions may fail to hold when the system dynamics shift and new threat variants emerge in a non-stationary environment, the capability of trained ML models to adapt in complex operating scenarios will be critical to their deployment in real-world smart grid communications. To this aim, this paper proposes a domain-adversarial transfer learning framework for robust intrusion detection against smart grid attacks. The framework introduces domain-adversarial training to create a mapping between the labeled source domain and the unlabeled target domain so that the classifiers can learn in a new feature space against unknown threats. The proposed framework with different baseline classifiers was evaluated using a smart grid cyber-attack dataset collected over a realistic hardware-in-the- loop security testbed. The results have demonstrated effective performance improvements of trained classifiers against unseen threats of different types and locations. © 2019 IEEE.",,Classification (of information); Computer crime; Deep learning; Electric power transmission networks; Learning algorithms; Machine learning; Smart power grids; Cyber infrastructures; Effective performance; Hard-ware-in-the-loop; Non-stationary environment; Smart Grid Communications; Stationary environments; Training and testing; Transfer learning; Intrusion detection,,,,,"Mashima, D., Chen, B., Zhou, T., Rajendran, R., Sikdar, B., Securing substations through command authentication using on-the-fly simulation of power system dynamics (2018) 2018 IEEE International Conference on Communications, Control, and Computing Technologies for Smart Grids (SmartGridComm), pp. 1-7. , Oct; Chromik, J., Pilch, C., Brackmann, P., Duhme, C., Everinghoff, F., Giberlein, A., Teodorowicz, T., Remke, A., Context-aware local intrusion detection in scada systems: A testbed and two showcases (2017) 2017 IEEE International Conference on Smart Grid Communications (SmartGridComm), pp. 467-472. , Oct; He, H., Yan, J., Cyber-physical attacks and defences in the smart grid: A survey (2016) IET Cyber-Physical Systems: Theory Applications, 1 (1), pp. 13-27; (2015) Business Blackout: The Insurance Implications of A Cyber Attack on the Us Power Grid, , Lloyds and the University of Cambridge Centre for Risk Studies, Tech. Rep; (2016) Cyber-attack against Ukrainian Critical Infrastructure, , https://www.ics-cert.us-cert.gov/alerts/IR-ALERT-H-16-056-01, The Industrial Control Systems Cyber Emergency Response Team (ICS-CERT), Tech. Rep; Koutsandria, G., Muthukumar, V., Parvania, M., Peisert, S., McParland, C., Scaglione, A., A hybrid network IDS for protective digital relays in the power transmission grid (2014) 2014 IEEE International Conference on Smart Grid Communications (SmartGridComm), pp. 908-913. , Nov; Buczak, A., Guven, E., A survey of data mining and machine learning methods for cyber security intrusion detection (2016) IEEE Communications Surveys & Tutorials, 18 (2), pp. 1153-1176; Zamir, A., Sax, A., Shen, W., Guibas, L., Malik, J., Savarese, S., Taskonomy: Disentangling task transfer learning (2018) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , June; Cao, Z., Long, M., Wang, J., Jordan, M., Partial transfer learning with selective adversarial networks (2018) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , June; Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette, F., Marchand, M., Lempitsky, V., Domain-adversarial training of neural networks (2016) Journal of Machine Learning Research, 17 (1), pp. 2030-2096. , Jan; Industrial Control System (ICS) Cyber Attack Datasets, , https://sites.google.com/a/uah.edu/tommy-morris-uah/ics-data-sets; Chu, Z., Zhang, J., Kosut, O., Sankar, L., Unobservable false data injection attacks against pmus: Feasible conditions and multiplicative attacks (2018) 2018 IEEE International Conference on Communications, Control, and Computing Technologies for Smart Grids (SmartGrid-Comm), pp. 1-6. , Oct; Jamei, M., Scaglione, A., Peisert, S., Low-resolution fault localization using phasor measurement units with community detection (2018) 2018 IEEE International Conference on Communications, Control, and Computing Technologies for Smart Grids (SmartGridComm), pp. 1-6. , Oct; Ozay, M., Esnaola, I., Yarman Vural, F., Kulkarni, S., Poor, H., Machine learning methods for attack detection in the smart grid (2016) IEEE Transactions on Neural Networks and Learning Systems, 27 (8), pp. 1773-1786. , Aug; Yan, J., Tang, B., He, H., Detection of false data attacks in smart grid with supervised learning (2016) 2016 International Joint Conference on Neural Networks (IJCNN), pp. 1395-1402. , July; Zhang, C., Kuppannagari, S.R., Kannan, R., Prasanna, V.K., Generative adversarial network for synthetic time series data generation in smart grids (2018) 2018 IEEE International Conference on Communications, Control, and Computing Technologies for Smart Grids (SmartGridComm), pp. 1-6. , Oct; Borges Hink, R., Beaver, J., Buckner, M., Morris, T., Adhikari, U., Pan, S., Machine learning for power system disturbance and cyber-attack discrimination (2014) 2014 7th International Symposium on Resilient Control Systems (ISRCS), pp. 1-8. , Aug; Wilson, D., Tang, Y., Yan, J., Lu, Z., Deep learning-aided cyberattack detection in power transmission systems (2018) 2018 IEEE Power Energy Society General Meeting (PESGM), pp. 1-5. , Aug; Hu, C., Yan, J., Wang, C., Advanced cyber-physical attack classification with extreme gradient boosting for smart transmission grids 2019 IEEE Power Energy Society General Meeting (PESGM), , accepted; Pan, S., Yang, Q., A survey on transfer learning (2010) IEEE Transactions on Knowledge and Data Engineering, 22 (10), pp. 1345-1359. , Oct; Taghiyarrenani, Z., Fanian, A., Mahdavi, E., Mirzaei, A., Farsi, H., Transfer learning based intrusion detection (2018) 2018 8th International Conference on Computer and Knowledge Engineering (ICCKE), pp. 92-97. , Oct; Ahmadi, R., Macredie, R.D., Tucker, A., Intrusion detection using transfer learning in machine learning classifiers between non-cloud and cloud datasets (2018) Intelligent Data Engineering and Automated Learning (IDEAL), pp. 556-566; Zhao, J., Shetty, S., Pan, J., Feature-based transfer learning for network security (2017) 2017 IEEE Military Communications Conference (MILCOM), pp. 17-22. , Oct; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, pp. 2672-2680",,,,Institute of Electrical and Electronics Engineers Inc.,"2019 IEEE International Conference on Communications, Control, and Computing Technologies for Smart Grids, SmartGridComm 2019",21 October 2019 through 23 October 2019,,155167,,9.78E+12,,,English,"IEEE Int. Conf. Commun., Control, Comput. Technol. Smart Grids, SmartGridComm",Conference Paper,Final,,Scopus,2-s2.0-85076397750
"Kim D., Lee S., Kim N., Jeong S.-G.",57214770551;57212480073;57392428800;44861243900;,Delegated Adversarial Training for Unsupervised Domain Adaptation,2019,"Proceedings - International Conference on Image Processing, ICIP",2019-September,,8803387,2521,2525,,,10.1109/ICIP.2019.8803387,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076812809&doi=10.1109%2fICIP.2019.8803387&partnerID=40&md5=68f2f7d2810b22589d9378928e7a39ce,"Seoul National University, South Korea; NAVER LABS, South Korea","Kim, D., Seoul National University, South Korea; Lee, S., Seoul National University, South Korea; Kim, N., NAVER LABS, South Korea; Jeong, S.-G., NAVER LABS, South Korea","In this paper, we tackle unsupervised domain adaptation, where a target domain is unlabeled and lies on a considerably different distribution from a source domain. To alleviate such data discrepancies, we coin a novel deep neural network architecture that consists of a classifier and a domain discriminator on top of a shared feature extractor. Toward efficient regularization, we delegate a generation of the adversarial attacks to the domain discriminator. We then leverage the domain adversarial images to let the classification network learn important semantic features across the domains. Specifically, we employ consistency loss function that enables the joint use of clean and adversarial data. We present extensive experimental results on various domain adaptation benchmarks to show the efficacy of the proposed method. © 2019 IEEE.",adversarial training; transfer learning; Unsupervised domain adaptation,,,,,,"Krizhevsky, A., Sutskever, I., Hinton, G., Imagenet classification with deep convolution neural networks (2012) NIPS; Girshick, R., Donahue, J., Darrell, T., Malik, J., Rich feature hierarchies for accurate object detection and semantic segmentation (2014) CVPR; Shelhamer, E., Long, J., Darrell, T., Fully convolutional networks for semantic segmentation (2017) IEEE TPAMI; Ren, S., He, K., Girshick, R., Sun, J., Faster r-cnn: Towards real-Time object detection with region proposal networks (2017) IEEE TPAMI; Zhang, K., Zuov, W., Chen, Y., Meng, D., Zhang, L., Beyond a Gaussian denoiser: Residual learning of deep cnn for image denoising (2017) IEEE TIP; Wang, M., Deng, W., Deep visual domain adaptation: A survey (2018) Neurocomputing; Taigman, Y., Polyak, A., Wolf, L., Unsupervised crossdomain image generation (2017) ICLR; Hoffman, J., Tzeng, E., Park, T., Zhu, J., Isola, P., Saenko, K., Efros, A., Darrell, T., Cycada: Cycle-consistent adversarial domain adaptation (2018) ICML; Bousmalis, K., Silberman, N., Dohan, D., Erhan, D., Krishnan, D., Unsupervised pixel-level domain adaptation with generative adversarial networks (2017) CVPR; Goodfellow, I.J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) NIPS; Zhu, J.-Y., Park, T., Isola, P., Efros, A.A., Unpaired image-To-image translation using cycle-consistent adversarial networks (2017) ICCV; Ganin, Y., Lempitsky, V., Unsupervised domain adaptation by backpropagation (2015) ICML; Bousmalis, K., Trigeorgis, G., Silberman, N., Krishnan, D., Erhan, D., Domain separation networks (2016) NIPS; Tzeng, E., Hoffman, J., Saenko, K., Darrell, T., Adversarial discriminative domain adaptation (2017) CVPR; Shu, R., Bui, H., Narui, H., Ermon, S., A dirt-T approach to unsupervised domain adaptation (2018) ICLR; French, G., Mackiewicz, M., Fisher, M., Self-ensembling for visual domain adaptation (2018) ICLR; Chapelle, O., Zien, A., Semi-supervised classification by low density separation (2005) AISTATS; Miyato, T., Maeda, S.I., Koyama, M., Ishii, S., Virtual adversarial training: A regularization method for supervised and semi-supervised learning (2018) IEEE TPAMI; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) SP; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2018) CVPR; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradientbased learning applied to document recognition (1998) Proc. IEEE; Hull, J.J., A database for handwritten text recognition research (1994) IEEE TPAMI; Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., Ng, A.Y., Reading digits in natural images with unsupervised feature learning (2011) NIPS Workshop on Deep Learning and Unsupervised Feature Learning; Krizhevsky, A., (2009) Learning Multiple Layers of Features from Tiny Images, , Tech Report; Coates, A., Lee, H., Ng, A.Y., An analysis of single layer networks in unsupervised feature learning (2011) AISTATS; Kingma, D., Ba, J., Adam: A method for stochastic optimization (2015) ICLR; Maaten, L.V.D., Hinton, G., Visualizing data using t-sne (2008) Journal of Machine Learning Research; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) ICLR",,,"The Institute of Electrical and Electronics Engineers, Signal Processing Society",IEEE Computer Society,"26th IEEE International Conference on Image Processing, ICIP 2019",22 September 2019 through 25 September 2019,,155696,15224880,9.78E+12,,,English,Proc. Int. Conf. Image Process. ICIP,Conference Paper,Final,,Scopus,2-s2.0-85076812809
"Zhu Z.-A., Lu Y.-Z., Chiang C.-K.",57195504754;57195503608;55462217500;,Generating Adversarial Examples by Makeup Attacks on Face Recognition,2019,"Proceedings - International Conference on Image Processing, ICIP",2019-September,,8803269,2516,2520,,14,10.1109/ICIP.2019.8803269,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076803271&doi=10.1109%2fICIP.2019.8803269&partnerID=40&md5=693d1e6af8be9111085b1f68859ec7c0,"Department of Computer Science and Information Engineering, National Chung Cheng University, Taiwan","Zhu, Z.-A., Department of Computer Science and Information Engineering, National Chung Cheng University, Taiwan; Lu, Y.-Z., Department of Computer Science and Information Engineering, National Chung Cheng University, Taiwan; Chiang, C.-K., Department of Computer Science and Information Engineering, National Chung Cheng University, Taiwan","Deep Learning models have been developed rapidly and achieved great success in computer vision and natural language processing. In this paper, we propose to generate adversarial examples to attack well-trained face recognition models by applying makeup effect to face images. It consists of two generative adversarial networks (GANs) based subnetworks, Makeup Transfer Sub-network and Adversarial Attack Sub-network. Makeup Transfer Sub-network transfers the non-makeup face images to makeup faces. Adversarial Attack Sub-networks hides attack information within makeup effect. The generated face images make the well-trained face recognition models misclassified as dodge attack or target attack. The experimental results demonstrate that our method can generate high-quality face makeup images and achieve higher error rates on various face recognition models compared to the existing attack methods. © 2019 IEEE.",Adversarial example attack; deep neural networks; face recognition; generative adversarial networks,,,,,,"Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R., Intriguing properties of neural networks (2013) CoRR, , vol. abs/1312.6199; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2014) CoRR, , vol. abs/1412.6572; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial examples in the physical world (2016) CoRR, , vol. abs/1607.02533; Brown, T.B., Mané, D., Roy, A., Abadi, M., Gilmer, J., Adversarial patch (2017) CoRR, , vol. abs/1712.09665; Athalye, A., Engstrom, L., Ilyas, A., Kwok, K., Synthesizing robust adversarial examples (2018) ICML., 80, pp. 284-293. , of JMLR Workshop and Conference Proceedings, JMLR. org; Xiao, C., Li, B., Zhu, J., He, W., Liu, M., Song, D., Generating adversarial examples with adversarial networks (2018) IJCAI., pp. 3905-3911. , ijcai.org; Harvey, A., (2010) Cv Dazzle: Camouflage from Face Detection, , Master's thesis, New York University; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-The-Art face recognition (2016) ACM Conference on Computer and Communications Security., pp. 1528-1540. , ACM; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, 27, pp. 2672-2680. , Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger, Eds. Curran Associates, Inc; Zhu, J., Park, T., Isola, P., Efros, A.A., Unpaired image-To-image translation using cycle-consistent adversarial networks (2017) ICCV., pp. 2242-2251. , IEEE Computer Society; Isola, P., Zhu, J., Zhou, T., Efros, A.A., Image-To-image translation with conditional adversarial networks (2017) CVPR., pp. 5967-5976. , IEEE Computer Society; Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., Courville, A.C., Improved training of wasserstein gans (2017) NIPS, pp. 5769-5779; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, 25, pp. 1097-1105. , F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger, Eds. Curran Associates, Inc; Iandola, F.N., Han, S., Moskewicz, M.W., Ashraf, K., Dally, W.J., Keutzer, K., (2016) Squeezenet: Alexnet-level Accuracy with 50x Fewer Parameters And 0.5 Mb Model Size, , arXiv preprint arXiv:1602.07360; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition, , arXiv preprint arXiv:1409.1556; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826; Huang, G., Liu, Z., Van Der Maaten, L., Weinberger, K.Q., Densely connected convolutional networks (2017) 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)., pp. 2261-2269. , IEEE; Wu, X., He, R., Sun, Z., Tan, T., A light cnn for deep face representation with noisy labels (2018) IEEE Transactions on Information Forensics and Security, 13 (11), pp. 2884-2896; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Machine Learning at Scale, , arXiv preprint arXiv:1611.01236; Karmon, D., Zoran, D., Goldberg, Y., Lavan: Localized and visible adversarial noise (2018) ICML., 80, pp. 2512-2520. , of JMLR Workshop and Conference Proceedings, JMLR. org",,,"The Institute of Electrical and Electronics Engineers, Signal Processing Society",IEEE Computer Society,"26th IEEE International Conference on Image Processing, ICIP 2019",22 September 2019 through 25 September 2019,,155696,15224880,9.78E+12,,,English,Proc. Int. Conf. Image Process. ICIP,Conference Paper,Final,,Scopus,2-s2.0-85076803271
"Taheri S., Salem M., Yuan J.-S.",57194897616;57205624503;57199894791;,Razornet: Adversarial training and noise training on a deep neural network fooled by a shallow neural network,2019,Big Data and Cognitive Computing,3,3,43,1,17,,4,10.3390/bdcc3030043,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076034925&doi=10.3390%2fbdcc3030043&partnerID=40&md5=d7100c1083339c2cc85ae9e3539c8757,"Department of Electrical and Computer Engineering, University of Central Florida, Orlando, FL  32816-2362, United States","Taheri, S., Department of Electrical and Computer Engineering, University of Central Florida, Orlando, FL  32816-2362, United States; Salem, M., Department of Electrical and Computer Engineering, University of Central Florida, Orlando, FL  32816-2362, United States; Yuan, J.-S., Department of Electrical and Computer Engineering, University of Central Florida, Orlando, FL  32816-2362, United States","In this work, we propose ShallowDeepNet, a novel system architecture that includes a shallow and a deep neural network. The shallow neural network has the duty of data preprocessing and generating adversarial samples. The deep neural network has the duty of understanding data and information as well as detecting adversarial samples. The deep neural network gets its weights from transfer learning, adversarial training, and noise training. The system is examined on the biometric (fingerprint and iris) and the pharmaceutical data (pill image). According to the simulation results, the system is capable of improving the detection accuracy of the biometric data from 1.31% to 80.65% when the adversarial data is used and to 93.4% when the adversarial data as well as the noisy data are given to the network. The system performance on the pill image data is increased from 34.55% to 96.03% and then to 98.2%, respectively. Training on different types of noise can benefit us in detecting samples from unknown and unseen adversarial attacks. Meanwhile, the system training on the adversarial data as well as noisy data occurs only once. In fact, retraining the system may improve the performance further. Furthermore, training the system on new types of attacks and noise can help in enhancing the system performance. © 2019 by the authors. Licensee MDPI, Basel, Switzerland.",Adversarial attacks; Adversarial perturbations; Adversarial training; Biometric recognition; Convolutional neural networks; Data security; Deep learning; Multiple subnetwork; Noise training; Pill recognition; Transfer learning,,,,,,"Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing properties of neural networks, , arXiv arXiv:1312.6199; Bastani, O., Ioannou, Y., Lampropoulos, L., Vytiniotis, D., Nori, A., Criminisi, A., Measuring neural net robustness with constraints Proceedings of the Advances in Neural Information Processing Systems, pp. 2613-2621. , Barcelona, Spain, 5–10 December 2016; Gu, S., Rigazio, L., (2014) Towards deep neural network architectures robust to adversarial examples, , arXiv arXiv:1412.5068; Huang, R., Xu, B., Schuurmans, D., Szepesvári, C., (2015) Learning with a strong adversary, , arXiv arXiv:1511.03034; Jin, J., Dundar, A., Culurciello, E., (2015) Robust convolutional neural networks under adversarial noise, , arXiv arXiv:1511.06306; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Proceedings of the 2016 IEEE Symposium on Security and Privacy (SP), pp. 582-597. , San Jose, CA, USA, 22–26 May IEEE: Piscataway, NJ, USA, 2016; Rozsa, A., Rudd, E.M., Boult, T.E., Adversarial diversity and hard positive generation (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, pp. 25-32. , Las Vegas, NV, USA, 26 June–1 July; Shaham, U., Yamada, Y., Negahban, S., Understanding adversarial training: Increasing local stability of supervised models through robust optimization (2018) Neurocomputing, 307, pp. 195-204. , [CrossRef]; Zheng, S., Song, Y., Leung, T., Goodfellow, I., Improving the robustness of deep neural networks via stability training (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4480-4488. , Las Vegas, NV, USA, 26 June–1 July; Mirjalili, V., Ross, A., Soft biometric privacy: Retaining biometric utility of face images while perturbing gender (2017) 2017 IEEE International Joint Conference on Biometrics (IJCB), pp. 564-573. , October IEEE: Piscataway, NJ, USA; Jia, R., Liang, P., (2017) Adversarial examples for evaluating reading comprehension systems, , arXiv arXiv:1707.07328; Belinkov, Y., Bisk, Y., (2017) Synthetic and natural noise both break neural machine translation, , arXiv arXiv:1711.02173; Samanta, S., Mehta, S., (2017) Towards crafting text adversarial samples, , arXiv arXiv:1707.02812; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets Proceedings of the Advances in neural information processing systems, pp. 2672-2680. , Montreal, QC, Canada, 8–13 December 2014; Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2017) Ensemble adversarial training: Attacks and defenses, , arXiv arXiv:1705.07204; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards deep learning models resistant to adversarial attacks, , arXiv arXiv:1706.06083; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519. , New York, NY, USA, 2–6 April 2017; Połap, D., Woźniak, M., Wei, W., Damaševičius, R., Multi-threaded learning control mechanism for neural networks (2018) Future Gener. Comput. Syst, 87, pp. 16-34; Yu, L., Zhang, W., Wang, J., Yu, Y., Seqgan: Sequence generative adversarial nets with policy gradient (2017) Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence, , San Francisco, CA, USA, 4–9 February; Narayanan, B.N., Hardie, R.C., Balster, E.J., Multiframe Adaptive Wiener Filter Super-Resolution with JPEG2000-Compressed Images, , https://link.springer.com/article/10.1186/1687-6180-2014-55, (accessed on 19 July 2019); Narayanan, B.N., Hardie, R.C., Kebede, T.M., Performance analysis of a computer-aided detection system for lung nodules in CT at different slice thicknesses (2018) J. Med. Imaging, 5, p. 014504. , [CrossRef] [PubMed]; Chivukula, A.S., Liu, W., Adversarial Deep Learning Models with Multiple Adversaries (2018) IEEE Trans. Knowl. Data Eng, 31, pp. 1066-1079. , [CrossRef]; Kwon, H., Kim, Y., Park, K.W., Yoon, H., Choi, D., Multi-targeted adversarial example in evasion attack on deep neural network (2018) IEEE Access, 6, pp. 46084-46096. , [CrossRef]; Shen, J., Zhu, X., Ma, D., TensorClog: An Imperceptible Poisoning Attack on Deep Neural Network Applications (2019) IEEE Access, 7, pp. 41498-41506. , [CrossRef]; Kulikajevas, A., Maskeliūnas, R., Damaševičius, R., Misra, S., Reconstruction of 3D Object Shape Using Hybrid Modular Neural Network Architecture Trained on 3D Models from ShapeNetCore Dataset (2019) Sensors, 19, p. 1553. , [CrossRef] [PubMed]; Carrara, F., Falchi, F., Caldelli, R., Amato, G., Becarelli, R., Adversarial image detection in deep neural networks (2019) Multimed. Tools Appl, 78, pp. 2815-2835. , [CrossRef]; Li, Y., Wang, Y., Defense Against Adversarial Attacks in Deep Learning (2019) Appl. Sci, 9, p. 76. , [CrossRef]; Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., (2017) On the (statistical) detection of adversarial examples, , arXiv arXiv:1702.06280; Gong, Z., Wang, W., Ku, W.S., (2017) Adversarial and clean data are not twins, , arXiv arXiv:1704.04960; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., (2017) On detecting adversarial perturbations, , arXiv arXiv:1702.04267; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting adversarial samples from artifacts, , arXiv arXiv:1703.00410; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Proceedings of the 2017 IEEE Symposium on Security and Privacy (SP), pp. 39-57. , San Jose, CA, USA, 22–24 May IEEE: Piscataway, NJ, USA, 2017; Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette, F., Marchand, M., Lempitsky, V., Domain-adversarial training of neural networks (2016) J. Mach. Learn. Res, 17, pp. 1-35; Marchisio, A., Nanfa, G., Khalid, F., Hanif, M.A., Martina, M., Shafique, M., (2019) CapsAttacks: Robust and Imperceptible Adversarial Attacks on Capsule Networks, , arXiv arXiv:1901.09878; Xu, W., Evans, D., Qi, Y., (2017) Feature squeezing: Detecting adversarial examples in deep neural networks, , arXiv arXiv:1704.01155; Kannan, H., Kurakin, A., Goodfellow, I., (2018) Adversarial logit pairing, , arXiv arXiv:1803.06373; Mopuri, K.R., Babu, R.V., (2018) Gray-box Adversarial Training, , arXiv arXiv:1808.01753; Neelakantan, A., Vilnis, L., Le, Q.V., Sutskever, I., Kaiser, L., Kurach, K., Martens, J., (2015) Adding gradient noise improves learning for very deep networks, , arXiv arXiv:1511.06807; Smilkov, D., Thorat, N., Kim, B., Viégas, F., Wattenberg, M., (2017) Smoothgrad: Removing noise by adding noise, , arXiv arXiv:1706.03825; Gao, F., Wu, T., Li, J., Zheng, B., Ruan, L., Shang, D., Patel, B., SD-CNN: A shallow-deep CNN for improved breast cancer diagnosis (2018) Comput. Med. Imaging Graph, 70, pp. 53-62. , [CrossRef] [PubMed]; Ernst, D., Das, S., Lee, S., Blaauw, D., Austin, T., Mudge, T., Kim, N.S., Flautner, K., Razor: Circuit-level correction of timing errors for low-power operation (2004) IEEE Micro, 24, pp. 10-20. , [CrossRef]; Basu, S., Karki, M., Ganguly, S., DiBiano, R., Mukhopadhyay, S., Gayaka, S., Kannan, R., Nemani, R., Learning sparse feature representations using probabilistic quadtrees and deep belief nets (2017) Neural Process. Lett, 45, pp. 855-867. , [CrossRef]; (2010), http://biometrics.idealtest.org/dbDetailForUser.do?id=7, CASIA-FingerprintV5. (accessed on 26 December 2017); (2010), http://biometrics.idealtest.org/dbDetailForUser.do?id=4, CASIA-IrisV4. (accessed on 26 December 2017); 1k Pharmaceutical Pill Image Dataset, , https://www.kaggle.com/trumedicines/1kpharmaceutical-pill-image-dataset, (accessed on 2 June 2018); Pan, S.J., Yang, Q., A survey on transfer learning (2009) IEEE Trans. Knowl. Data Eng, 22, pp. 1345-1359. , [CrossRef]; Bottou, L., Large-scale machine learning with stochastic gradient descent (2010) Compstat’2010, pp. 177-186. , Physica-Verlag HD: Heidelberg, Germany; Liu, X., Cheng, M., Zhang, H., Hsieh, C.J., Towards robust neural networks via random self-ensemble Proceedings of the European Conference on Computer Vision (ECCV), pp. 369-385. , Munich, Germany, 8–14 September 2018; Ranjan, R., Sankaranarayanan, S., Castillo, C.D., Chellappa, R., (2017) Improving network robustness against adversarial attacks with compact convolution, , arXiv arXiv:1712.00699; Song, Y., Kim, T., Nowozin, S., Ermon, S., Kushman, N., (2017) Pixeldefend: Leveraging generative models to understand and defend against adversarial examples, , arXiv arXiv:1710.10766; Dai, X., Gong, S., Zhong, S., Bao, Z., Bilinear CNN Model for Fine-Grained Classification Based on Subcategory-Similarity Measurement (2019) Appl. Sci, 9, p. 301. , [CrossRef]; Varior, R.R., Haloi, M., Wang, G., Gated siamese convolutional neural network architecture for human re-identification (2016) Proceedings of the European Conference on Computer Vision, pp. 791-808. , Amsterdam, The Netherlands, 8–16 October Springer: Cham, Switzerland, 2016; Ranjan, R., Patel, V.M., Chellappa, R., Hyperface: A deep multi-task learning framework for face detection, landmark localization, pose estimation, and gender recognition (2017) IEEE Trans. Pattern Anal. Mach. Intell, 41, pp. 121-135. , [CrossRef] [PubMed]; Twinanda, A.P., Shehata, S., Mutter, D., Marescaux, J., De Mathelin, M., Padoy, N., Endonet: A deep architecture for recognition tasks on laparoscopic videos (2016) IEEE Trans. Med. Imaging, 36, pp. 86-97. , [CrossRef] [PubMed]","Yuan, J.-S.; Department of Electrical and Computer Engineering, United States; 电子邮件: yuanj@mail.ucf.edu",,,MDPI AG,,,,,25042289,,,,English,Big Data Cogn. Computing,Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85076034925
[无可用作者姓名],[无可用的作者 ID],e-Energy 2019 - Proceedings of the 10th ACM International Conference on Future Energy Systems,2019,e-Energy 2019 - Proceedings of the 10th ACM International Conference on Future Energy Systems,,,,,,581,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068653696&partnerID=40&md5=8ec2fde8f975be21d52f7dd58642e025,,,The proceedings contain 83 papers. The topics discussed include: exploiting vulnerabilities of load forecasting through adversarial attacks; energy predictive models with limited data using transfer learning; semi-automatic generation and labeling of training data for non-intrusive load monitoring; low sampling rate electrical load disaggregation using dictionary representation and graph signal smoothness; waveform signal entropy and compression study of whole-building energy datasets; enabling auto-configuring building services: the road to affordable portable applications for smart grid integration; experimental evaluation of a data driven cooling optimization framework for HVAC control in commercial buildings; and stay or switch: competitive online algorithms for energy plan selection in energy markets with retail choice.,,,,,,,,,,ACM EIG-ENERGYS,"Association for Computing Machinery, Inc","10th ACM International Conference on Future Energy Systems, e-Energy 2019",25 June 2019 through 28 June 2019,,148746,,9.78E+12,,,English,e-Energy - Proc. ACM Int. Conf. Future Energy Syst.,Conference Review,Final,,Scopus,2-s2.0-85068653696
"Fernandes S., Raj S., Ortiz E., Vintila I., Jha S.K.",55662687300;57194457254;57215525147;57215527058;57218716753;,Directed Adversarial Attacks on Fingerprints using Attributions,2019,"2019 International Conference on Biometrics, ICB 2019",,,8987267,,,,2,10.1109/ICB45273.2019.8987267,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081052350&doi=10.1109%2fICB45273.2019.8987267&partnerID=40&md5=aa10ced7b7aa99818367e9747505f750,"University of Central Florida, Computer Science Department, Orlando, FL, United States; Royal Bank of Canada, Solution Acceleration and Innovation Department, Canada","Fernandes, S., University of Central Florida, Computer Science Department, Orlando, FL, United States; Raj, S., University of Central Florida, Computer Science Department, Orlando, FL, United States; Ortiz, E., Royal Bank of Canada, Solution Acceleration and Innovation Department, Canada; Vintila, I., Royal Bank of Canada, Solution Acceleration and Innovation Department, Canada; Jha, S.K., University of Central Florida, Computer Science Department, Orlando, FL, United States","Fingerprint recognition systems verify the identity of individuals and provide access to secure information in various commercial applications. However, with advancements in artificial intelligence, fingerprint-based security methods are vulnerable to attack. Such a breach has the potential to compromise confidential, private and valuable information. In this paper, we attack a state-of-the-art fingerprint recognition system based on transfer learning. Our approach uses attribution analysis to identify the fingerprint region crucial to correct classification, and then perturbs the fingerprint using error masks derived from a neural network to generate an adversarial fingerprint.Image quality assessment metrics applied to calculate the difference between the original and perturbed fingerprints include average difference, maximum difference, normalized absolute error, and peak signal to noise ratio. On the ATVS fingerprint dataset, the differences between these values in the original and corresponding perturbed fingerprint images are negligible. Further, the VeriFinger SDK is used to detect the minutiae and perform matching between the original and perturbed fingerprints. The matching score is above 250, which reinforces the fact that there is virtually no loss between the original and perturbed fingerprints. © 2019 IEEE.",,Biometrics; Image segmentation; Pattern matching; Signal to noise ratio; Transfer learning; Average difference; Commercial applications; Fingerprint dataset; Fingerprint images; Fingerprint recognition systems; Normalized absolute errors; Peak signal to noise ratio; Quality assessment; Palmprint recognition,,,,,"VeriFinger, , http://www.neurotechnology.com/verifinger.html; Leung, T., Jia, Y., Sukthankar, R., Berg, A.C., Matchnet: Unifying feature and metric learning for patchbased matching (2015) 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR, pp. 3279-3286. , June; Brown, M., Lowe, D.G., Automatic panoramic image stitching using invariant features (2007) International Journal of Computer Vision, 74 (1), pp. 59-73. , Aug; Chollet, F., Xception: Deep learning with depthwise separable convolutions (2016) CoRR, , abs/1610.02357; Nogueira, R.F., De Alencar Lotufo, R., Machado, R.C., Evaluating software-based fingerprint liveness detection using convolutional networks and local binary patterns (2014) 2014 IEEEWorkshop on Biometric Measurements and Systems for Security and Medical Applications (BIOMS) Proceedings, pp. 22-29. , Oct; Galbally, J., Alonso-Fernandez, F., Fierrez, J., Ortega-Garcia, J., A high performance fingerprint liveness detection method based on quality related features (2012) Future Generation Computer Systems, 28 (1), pp. 311-321; Galbally, J., Marcel, S., Fierrez, J., Image quality assessment for fake biometric detection: Application to iris, fingerprint, and face recognition (2014) IEEE Transactions on Image Processing, 23 (2), pp. 710-724. , Feb; Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H., Mobilenets: Efficient convolutional neural networks for mobile vision applications (2017) CoRR, , abs/1704.04861; Huang, G., Liu, Z., Weinberger, K.Q., Densely connected convolutional networks (2016) CoRR, , abs/1608.06993; Jia, X., Yang, X., Cao, K., Zang, Y., Zhang, N., Dai, R., Zhu, X., Tian, J., Multi-scale local binary pattern with filters for spoof fingerprint detection (2014) Information Sciences, 268, pp. 91-102. , New Sensing and Processing Technologies for Hand-based Biometrics Authentication; Jain, A.K., Feng, J., Latent fingerprint matching (2011) IEEE Transactions on Pattern Analysis and Machine Intelligence, 33, pp. 88-100. , 01; Ko, K., (2007) User's Guide to Nist Biometric Image Software (Nbis)., , Technical report; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Li, J., Feng, J., Kuo, C.-C.J., Deep convolutional neural network for latent fingerprint enhancement (2018) Signal Processing: Image Communication, 60, pp. 52-63; Marasco, E., Cando, S., Tang, L., Can liveness be automatically detected from latent fingerprints? (2019) 2019 IEEE Winter Applications of Computer Vision Workshops (WACVW, pp. 93-99. , IEEE; Nogueira, R.F., De Alencar Lotufo, R., Machado, R.C., Fingerprint liveness detection using convolutional neural networks (2016) IEEE Transactions on Information Forensics and Security, 11 (6), pp. 1206-1213. , June; Raj, S., Jha, S.K., Pullum, L.L., Ramanathan, A., (2017) Statistical Hypothesis Testing Using Cnn Features for Synthesis of Adversarial Counterexamples to Human and Object Detection Vision Systems., 5; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Bernstein, M., Imagenet large scale visual recognition challenge (2015) International Journal of Computer Vision, 115 (3), pp. 211-252; Sandler, M., Howard, A.G., Zhu, M., Zhmoginov, A., Chen, L., Inverted residuals and linear bottlenecks: Mobile networks for classification, detection and segmentation (2018) CoRR, , abs/1801.04381; Seitz, S.M., Curless, B., Diebel, J., Scharstein, D., Szeliski, R., A comparison and evaluation of multi-view stereo reconstruction algorithms (2006) 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06), 1, pp. 519-528. , June; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2014) CoRR, , abs/1409.1556; Sudiro, S.A., Paindavoine, M., Kusuma, T.M., Simple fingerprint minutiae extraction algorithm using crossing number on valley structure (2007) 2007 IEEE Workshop on Automatic Identification Advanced Technologies, pp. 41-44. , June; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2015) CoRR, , abs/1512.00567; Tang, Y., Gao, F., Feng, J., Liu, Y., Fingernet: An unified deep network for fingerprint minutiae extraction (2017) CoRR, , abs/1709.02228; Xie, S., Girshick, R.B., Dollár, P., Tu, Z., He, K., Aggregated residual transformations for deep neural networks (2016) CoRR, , abs/1611.05431; Yambay, D., Ghiani, L., Denti, P., Marcialis, G.L., Roli, F., Schuckers, S., Livdet 2011 fingerprint liveness detection competition 2011 (2012) 2012 5th IAPR International Conference on Biometrics (ICB, pp. 208-215. , March; Yan, L., Wang, Y., Song, T., Yin, Z., An incremental intelligent object recognition system based on deep learning (2017) 2017 Chinese Automation Congress (CAC, pp. 7135-7138. , Oct; Yoon, S., Jain, A.K., Longitudinal study of fingerprint recognition (2015) Proceedings of the National Academy of Sciences, 112 (28), pp. 8555-8560; Yuan, C., Xia, Z., Jiang, L., Cao, Y., Jonathan Wu, Q.M., Sun, X., Fingerprint liveness detection using an improved cnn with image scale equalization (2019) IEEE Access, 7, pp. 26953-26966; Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., Torralba, A., Learning deep features for discriminative localization (2015) CoRR, , abs/1512.04150; Zoph, B., Vasudevan, V., Shlens, J., Le, Q.V., Learning transferable architectures for scalable image recognition (2017) CoRR, , abs/1707.07012",,,,Institute of Electrical and Electronics Engineers Inc.,"2019 International Conference on Biometrics, ICB 2019",4 June 2019 through 7 June 2019,,157624,,9.78E+12,,,English,"Int. Conf. Biom., ICB",Conference Paper,Final,,Scopus,2-s2.0-85081052350
"Inkawhich N., Wen W., Li H.H., Chen Y.",57194798606;57210588344;57201321031;9737381600;,Feature space perturbations yield more transferable adversarial examples,2019,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,2019-June,,8953700,7059,7067,,30,10.1109/CVPR.2019.00723,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078802353&doi=10.1109%2fCVPR.2019.00723&partnerID=40&md5=4330a19c912b44ee974dfaa5026ee670,"Duke University, Electrical and Computer Engineering Department, Durham, NC  27708, United States","Inkawhich, N., Duke University, Electrical and Computer Engineering Department, Durham, NC  27708, United States; Wen, W., Duke University, Electrical and Computer Engineering Department, Durham, NC  27708, United States; Li, H.H., Duke University, Electrical and Computer Engineering Department, Durham, NC  27708, United States; Chen, Y., Duke University, Electrical and Computer Engineering Department, Durham, NC  27708, United States","Many recent works have shown that deep learning models are vulnerable to quasi-imperceptible input perturbations, yet practitioners cannot fully explain this behavior. This work describes a transfer-based blackbox targeted adversarial attack of deep feature space representations that also provides insights into cross-model class representations of deep CNNs. The attack is explicitly designed for transferability and drives feature space representation of a source image at layer L towards the representation of a target image at L. The attack yields highly transferable targeted examples, which outperform competition winning methods by over 30% in targeted attack metrics. We also show the choice of L to generate examples from is important, transferability characteristics are blackbox model agnostic, and indicate that well trained deep models have similar highly-abstract representations. © 2019 IEEE.",Deep Learning; Others; Vision Applications and Systems,Computer vision; Learning systems; Abstract representation; Black-box model; Feature space; Input perturbation; Learning models; Others; Source images; Vision applications; Deep learning,,,,,"Carlini, N., Wagner, D.A., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP), pp. 39-57; Carlini, N., Wagner, D.A., Audio adversarial examples: Targeted attacks on speech-to-text (2018) 2018 IEEE Security and Privacy Workshops (SPW), pp. 1-7; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., Imagenet: A large-scale hierarchical image database (2009) 2009 IEEE Conference on Computer Vision and Pattern Recognition, pp. 248-255; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., (2017) Boosting Adversarial Attacks with Momentum; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2014) CoRR, , abs/1412. 6572; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 770-778; Huang, G., Liu, Z., Maaten Der Van, L., Weinberger, K.Q., Densely connected convolutional networks (2017) 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2261-2269; Kos, J., Fischer, I., Song, D.X., Adversarial examples for generative models (2018) 2018 IEEE Security and Privacy Workshops (SPW), pp. 36-42; Krizhevsky, A., Nair, V., Hinton, G., Cifar-10 (Canadian Institute for Advanced Research); Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial machine learning at scale (2016) CoRR, , abs/1611. 01236; Kurakin, A., Goodfellow, I.J., Bengio, S., Dong, Y., Liao, F., Liang, M., Pang, T., Abe, M., Adversarial attacks and defences competition (2018) CoRR, , abs/1804. 00097; Liu, K., (2017) Pytorch-cifar, , https://github.com/kuangliu/pytorch-cifar; Liu, Y., Chen, X., Liu, C., Song, D.X., Delving into transferable adversarial examples and black-box attacks (2016) CoRR, , abs/1611. 02770; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2017) CoRR, , abs/1706. 06083; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 86-94; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2574-2582; Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., Ng, A.Y., (2011) Reading Digits in Natural Images with Unsupervised Feature Learning; Papernot, N., McDaniel, P.D., Goodfellow, I.J., Transferability in machine learning: From phenomena to black-box attacks using adversarial samples (2016) CoRR, , abs/1605. 07277; Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., De-Vito, Z., Lin, Z., Lerer, A., (2017) Automatic Differentiation in Pytorch; Pattanaik, A., Tang, Z., Liu, S., Bommannan, G., Chowdhary, G., Robust deep reinforcement learning with adversarial attacks (2018) AAMAS; Sabour, S., Cao, Y., Faghri, F., Fleet, D.J., Adversarial manipulation of deep representations (2015) CoRR, , abs/1511. 05122; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2014) CoRR, , abs/1409. 1556; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R., Intriguing properties of neural networks (2013) CoRR, , abs/1312. 6199; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., Mc-Daniel, P.D., Ensemble adversarial training: Attacks and defenses (2017) CoRR, , abs/1705. 07204; Tramèr, F., Papernot, N., Goodfellow, I.J., Boneh, D., McDaniel, P.D., The space of transferable adversarial examples (2017) CoRR, , abs/1704. 03453; Yosinski, J., Clune, J., Bengio, Y., Lipson, H., How transferable are features in deep neural networks? (2014) NIPS",,,,IEEE Computer Society,"32nd IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2019",16 June 2019 through 20 June 2019,,156730,10636919,9.78E+12,PIVRE,,English,Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit,Conference Paper,Final,,Scopus,2-s2.0-85078802353
"Xie C., Zhang Z., Zhou Y., Bai S., Wang J., Ren Z., Yuille A.L.",57200616617;57200612412;57195627000;57206839797;57142698500;23005801300;7006372632;,Improving transferability of adversarial examples with input diversity,2019,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,2019-June,,8953423,2725,2734,,134,10.1109/CVPR.2019.00284,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078270121&doi=10.1109%2fCVPR.2019.00284&partnerID=40&md5=7e561c7879d359f42e551159601d9fe2,"Johns Hopkins University, United States; University of Oxford, United Kingdom; Baidu Research USA, United States; Wormpex AI Research, China","Xie, C., Johns Hopkins University, United States; Zhang, Z., Johns Hopkins University, United States; Zhou, Y., Johns Hopkins University, United States; Bai, S., University of Oxford, United Kingdom; Wang, J., Baidu Research USA, United States; Ren, Z., Wormpex AI Research, China; Yuille, A.L., Johns Hopkins University, United States","Though CNNs have achieved the state-of-the-art performance on various vision tasks, they are vulnerable to adversarial examples-crafted by adding human-imperceptible perturbations to clean images. However, most of the existing adversarial attacks only achieve relatively low success rates under the challenging black-box setting, where the attackers have no knowledge of the model structure and parameters. To this end, we propose to improve the transferability of adversarial examples by creating diverse input patterns. Instead of only using the original images to generate adversarial examples, our method applies random transformations to the input images at each iteration. Extensive experiments on ImageNet show that the proposed attack method can generate adversarial examples that transfer much better to different networks than existing baselines. By evaluating our method against top defense solutions and official baselines from NIPS 2017 adversarial competition, the enhanced attack reaches an average success rate of 73.0%, which outperforms the top-1 attack submission in the NIPS competition by a large margin of 6.6%. We hope that our proposed attack strategy can serve as a strong benchmark baseline for evaluating the robustness of networks to adversaries and the effectiveness of different defense methods in the future. Code is available at https://github.com/cihangxie/DI-2-FGSM. © 2019 IEEE.",Categorization; Deep Learning; Recognition: Detection; Retrieval; Statistical Learning,Computer vision; Deep learning; Network security; Attack strategies; Categorization; Defense solutions; Input patterns; Original images; Retrieval; State-of-the-art performance; Statistical learning; Iterative methods,,,,,"Arnab, A., Miksik, O., Torr, P.H., (2017) On the Robustness of Semantic Segmentation Models to Adversarial Attacks, , arXiv preprint arXiv: 1711.09856; Athalye, A., Engstrom, L., Ilyas, A., Kwok, K., Synthesizing robust adversarial examples (2018) International Conference on Machine Learning, pp. 284-293; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Srndić, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 387-402; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy; Chen, L.-C., Papandreou, G., Kokkinos, I., Murphy, K., Yuille, A.L., Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs (2017) IEEE Transactions on Pattern Analysis and Machine Intelligence; Cisse, M., Adi, Y., Neverova, N., Keshet, J., (2017) Houdini: Fooling Deep Structured Prediction Models, , arXiv preprint arXiv: 1707.05373; Dalvi, N., Domingos, P., Sanghai, S., Verma, D., Adversarial classification (2004) ACM SIGKDD International Conference on Knowledge Discovery and Data Mining; Dhillon, G.S., Azizzadenesheli, K., Bernstein, J.D., Kossaifi, J., Khanna, A., Lipton, Z.C., Anandkumar, A., Stochastic activation pruning for robust adversarial defense (2018) International Conference on Learning Representations; Dong, Y., Liao, F., Pang, T., Su, H., Hu, X., Li, J., Zhu, J., (2017) Boosting Adversarial Attacks with Momentum, , arXiv preprint arXiv: 1710.06081; Girshick, R., Fast r-cnn (2015) International Conference on Computer Vision; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations; Guo, C., Rana, M., Cissé, M., Maaten Der, L.Van., Countering adversarial images using input transformations (2018) International Conference on Learning Representations; He, K., Zhang, X., Ren, S., Sun, J., Identity mappings in deep residual networks (2016) European Conference on Computer Vision; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I., Tygar, J., Adversarial machine learning (2011) ACM Workshop on Security and Artificial Intelligence; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2017) International Conference on Learning Representations Workshop; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2017) International Conference on Learning Representations; Kurakin, A., Goodfellow, I., Bengio, S., Dong, Y., Liao, F., Liang, M., Pang, T., Xie, C., (2018) Adversarial Attacks and Defences Competition, , arXiv preprint arXiv: 1804.00097; Liao, F., Liang, M., Dong, Y., Pang, T., Hu, X., Zhu, J., Defense against adversarial attacks using high-level representation guided denoiser (2018) Computer Vision and Pattern Recognition; Lin, Y.-C., Hong, Z.-W., Liao, Y.-H., Shih, M.-L., Liu, M.-Y., Sun, M., Tactics of adversarial attack on deep reinforcement learning agents (2017) International Joint Conference on Artificial Intelligence; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) International Conference on Learning Representations; Long, J., Shelhamer, E., Darrell, T., Fully convolutional networks for semantic segmentation (2015) Computer Vision and Pattern Recognition; Luo, Y., Boix, X., Roig, G., Poggio, T., Zhao, Q., (2015) Foveationbased Mechanisms Alleviate Adversarial Examples, , arXiv preprint arXiv: 1511.06292; Meng, D., Chen, H., (2017) Magnet: A Two-pronged Defense Against Adversarial Examples, , arXiv preprint arXiv: 1705.09064; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Computer Vision and Pattern Recognition; Papernot, N., Faghri, F., Carlini, N., Goodfellow, I., Feinman, R., Kurakin, A., Xie, C., Long, R., (2018) Cleverhans v2.1.0: An Adversarial Machine Learning Library, , arXiv preprint arXiv: 1610.00768; Prakash, A., Moran, N., Garber, S., DiLillo, A., Storer, J., (2018) Deflecting Adversarial Attacks with Pixel Deflection, , arXiv preprint arXiv: 1801.08926; Ren, S., He, K., Girshick, R., Sun, J., Faster r-cnn: Towards real-time object detection with region proposal networks (2015) Advances in Neural Information Processing Systems; Samangouei, P., Kabkab, M., Chellappa, R., Defense-gan: Protecting classifiers against adversarial attacks using generative models (2018) International Conference on Learning Representations; Shrivastava, A., Gupta, A., Girshick, R., Training regionbased object detectors with online hard example mining (2016) Computer Vision and Pattern Recognition; Simo-Serra, E., Trulls, E., Ferraz, L., Kokkinos, I., Fua, P., Moreno-Noguer, F., Discriminative learning of deep convolutional feature point descriptors (2015) International Conference on Computer Vision; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) International Conference on Learning Representations; Song, Y., Kim, T., Nowozin, S., Ermon, S., Kushman, N., (2017) Pixeldefend: Leveraging Generative Models to Understand and Defend Against Adversarial Examples, , arXiv preprint arXiv: 1710.10766; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., Inception-v4, inception-resnet and the impact of residual connections on learning (2017) AAAI; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Computer Vision and Pattern Recognition; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses, , arXiv preprint arXiv:1705.07204; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., Mitigating adversarial effects through randomization (2018) International Conference on Learning Representations; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., Adversarial examples for semantic segmentation and object detection (2017) International Conference on Computer Vision; Zhang, Z., Qiao, S., Xie, C., Shen, W., Wang, B., Yuille, A.L., (2017) Single-shot Object Detection with Enriched Semantics, , arXiv preprint arXiv: 1712.00433",,,,IEEE Computer Society,"32nd IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2019",16 June 2019 through 20 June 2019,,156730,10636919,9.78E+12,PIVRE,,English,Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85078270121
Liao Z.,57210362686;,Simultaneous adversarial training - Learn from others' mistakes,2019,"Proceedings - 14th IEEE International Conference on Automatic Face and Gesture Recognition, FG 2019",,,8756539,,,,,10.1109/FG.2019.8756539,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070474166&doi=10.1109%2fFG.2019.8756539&partnerID=40&md5=474b99db41dd644a6cd5e56028e0101d,"Faculty of Engineering, Department of Computing, Imperial College LondonSW7 7AZ, United Kingdom","Liao, Z., Faculty of Engineering, Department of Computing, Imperial College LondonSW7 7AZ, United Kingdom","Adversarial examples are maliciously tweaked images that can easily fool machine learning techniques, such as neural networks, but they are normally not visually distinguishable for human beings. One of the main approaches to solve this problem is to retrain the networks using those adversarial examples, namely adversarial training. However, standard adversarial training might not actually change the decision boundaries but cause the problem of gradient masking, resulting in a weaker ability to generate adversarial examples [39]. Therefore, it cannot alleviate the problem of black-box attacks, where adversarial examples generated from other networks can transfer to the targeted one. In order to reduce the problem of black-box attacks, we propose a novel method that allows two networks to learn from each others' adversarial examples and become resilient to black-box attacks. We also combine this method with a simple domain adaptation to further improve the performance. © 2019 IEEE.",,Learning systems; Black boxes; Decision boundary; Domain adaptation; Human being; Machine learning techniques; Gesture recognition,,,,,"Carlini, N., Wagner, D., (2016) Defensive Distillation is Not Robust to Adversarial Examples, , arXiv preprint; Carlini, N., Wagner, D., (2016) Towards Evaluating the Robustness of Neural Networks, , arXiv preprint; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 3-14. , ACM; Carlini, N., Wagner, D., (2017) Magnet and Efficient Defenses Against Adversarial Attacks are Not Robust to Adversarial Examples, , arXiv preprint; Dabouei, A., Soleymani, S., Dawson, J., Nasrabadi, N.M., (2018) Fast Geometrically-perturbed Adversarial Faces, , arXiv preprint; Dong, Y., Liao, F., Pang, T., Su, H., Hu, X., Li, J., Zhu, J., (2017) Boosting Adversarial Attacks with Momentum, , preprint. preprint; Eidinger, E., Enbar, R., Hassner, T., Age and gender estimation of unfiltered faces (2014) IEEE Transactions on Information Forensics and Security, 9 (12), pp. 2170-2179; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts, , arXiv preprint; Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette, F., Marchand, M., Lempitsky, V., Domain-adversarial training of neural networks (2016) The Journal of Machine Learning Research, 17 (1), pp. 2030-2096; Goel, A., Singh, A., Agarwal, A., Vatsa, M., Singh, R., Smartbox: Benchmarking adversarial detection and mitigation algorithms for face recognition (2018) IEEE BTAS; Gong, Z., Wang, W., Ku, W.-S., (2017) Adversarial and Clean Data are Not Twins, , arXiv preprint; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR; Goswami, G., Ratha, N., Agarwal, A., Singh, R., Vatsa, M., Unravelling robustness of deep learning based face recognition against adversarial attacks (2018) AAAI; Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., (2017) On the (statistical) Detection of Adversarial Examples, , arXiv preprint; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Hendrycks, D., Gimpel, K., Early methods for detecting adversarial images (2017) ICLR Workshop; Hosseini, H., Chen, Y., Kannan, S., Zhang, B., Poovendran, R., (2017) Blocking Transferability of Adversarial Examples in Black-box Learning Systems, , arXiv preprint; Ioffe, S., Szegedy, C., Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015) International Conference on Machine Learning, pp. 448-456; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint; Levi, G., Hassner, T., Age and gender classification using convolutional neural networks (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, pp. 34-42; Liao, Z., Petridis, S., Pantic, M., (2017) Local Deep Neural Networks for Age and Gender Classification, , arXiv preprint; Lu, J., Issaranon, T., Forsyth, D., Safetynet: Detecting and rejecting adversarial examples robustly (2017) CoRR, , 1704.00103; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) ICLR; Meng, D., Chen, H., Magnet: A two-pronged defense against adversarial examples (2017) Proceedings of the ACM SIGSAC Conference on Computer and Communications Security, pp. 135-147. , ACM; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., On detecting adversarial perturbations (2017) Proceedings of 5th International Conference on Learning Representations (ICLR); Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Na, T., Ko, J.H., Mukhopadhyay, S., Cascade adversarial machine learning regularized with a unified embedding (2018) ICLR; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 427-436; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., (2016) Practical Black-box Attacks Against Deep Learning Systems Using Adversarial Examples, , arXiv preprint; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Security and Privacy (SP), 2016 IEEE Symposium On, pp. 582-597. , IEEE; Parkhi, O.M., Vedaldi, A., Zisserman, A., Deep face recognition (2015) British Machine Vision Conference; Rozsa, A., Rudd, E.M., Boult, T.E., Adversarial diversity and hard positive generation (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, pp. 25-32; Salimans, T., Karpathy, A., Chen, X., Kingma, D.P., Pixelcnn++: Improving the pixelcnn with discretized logistic mixture likelihood and other modifications (2017) ICLR Poster; Samangouei, P., Kabkab, M., Chellappa, R., Defense-gan: Protecting classifiers against adversarial attacks using generative models (2018) ICLR; Simon-Gabriel, C.-J., Ollivier, Y., Schölkopf, B., Bottou, L., Lopez-Paz, D., (2018) Adversarial Vulnerability of Neural Networks Increases with Input Dimension, , arXiv preprint; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) ICLR; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) ICLR; Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2018) ICLR; Tramèr, F., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2017) The Space of Transferable Adversarial Examples, , arXiv preprint; Tzeng, E., Hoffman, J., Saenko, K., Darrell, T., Adversarial discriminative domain adaptation (2017) Computer Vision and Pattern Recognition (CVPR), 1, p. 4; Yuan, X., He, P., Zhu, Q., Bhat, R.R., Li, X., (2017) Adversarial Examples: Attacks and Defenses for Deep Learning, , arXiv preprint; Zhao, Z., Dua, D., Singh, S., (2017) Generating Natural Adversarial Examples, , arXiv preprint","Liao, Z.; Faculty of Engineering, United Kingdom",,3dMD;et al.;IMT Lille Douai - Ecole Mines-Telecom;Inria - Inventerus du Monde Numerique;Institut Mines-Telecom;Universite de Lille,Institute of Electrical and Electronics Engineers Inc.,"14th IEEE International Conference on Automatic Face and Gesture Recognition, FG 2019",14 May 2019 through 18 May 2019,,149544,,9.78E+12,,,English,"Proc. - IEEE Int. Conf. Autom. Face Gesture Recognit., FG",Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85070474166
"Ul Haq I., Wang J., Zhu Y.",57190177989;55912021700;7406073839;,An Efficient Authenticated Key Agreement Scheme for Consumer USB MSDs Resilient to Unauthorized File Decryption,2019,IEEE Transactions on Consumer Electronics,65,1,8550696,80,89,,5,10.1109/TCE.2018.2883778,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057773834&doi=10.1109%2fTCE.2018.2883778&partnerID=40&md5=7a7916522c08249d67cb38672750e063,"College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, 210016, China","Ul Haq, I., College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, 210016, China; Wang, J., College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, 210016, China; Zhu, Y., College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, 210016, China","The Mass Storage Class (MSC) of universal serial bus (USB) interface is a collection of communication protocols that enables USB Mass Storage Device(s) [MSD(s)] to be connected with the host system for data transfer in full duplex fashion. USBMSDs are common in use due to their affordable price, high storage capacity, and excellent transmission speed. But because of security vulnerabilities, its use is strictly prohibited in many classified and commercial environments. Authenticated key agreement between client terminal and authentication server is an essential security feature to securely store data on USBMSD. Recently, Giri et al. proposed an authenticated key agreement scheme for USBMSD, having session spanning file decryption characteristics. In this paper, we have reviewed and pointed out several security vulnerabilities, including unauthorized file decryption attack of the aforesaid scheme. This paper introduces the notion of unauthorized file decryption attack and defines its adversarial model. Next, an improved security protocol for USBMSD(s) has been proposed. The formal and informal security along with Automated Validation of Internet Security Protocols and Application (AVISPA) tool verification of proposed scheme shows that it is safe against eminent attacks. The performance comparison in terms of computational complexity, communication overhead, storage space and security features showed that proposed scheme is computationally efficient and has improved security characteristics also. © 1975-2011 IEEE.",Authentication; biometric; mass storage device; password; unauthorized file decryption,Biometrics; Cryptography; Data transfer; Network protocols; Security systems; System buses; Virtual storage; Authenticated key agreement; Communication overheads; Computationally efficient; Mass storage devices; Password; Security vulnerabilities; Unauthorized file decryption; Universal serial bus; Authentication,,,,,"Lamport, L., Password authentication with insecure communication (1981) Commun. ACM, 24 (11), pp. 770-772. , Nov; Chang, C.-C., Wu, T.-C., Remote password authentication with smart cards (1991) IEe Proc. e Comput. Digit. Techn., 138 (3), pp. 165-168. , May; Hwang, M.-S., Li, L.-H., A new remote user authentication scheme using smart cards (2000) IEEE Trans. Consum. Electron., 46 (1), pp. 28-30. , Feb; Juang, W.-S., Efficient password authenticated key agreement using smart cards (2004) Comput. Security, 23 (2), pp. 167-173; He, D., Ma, M., Zhang, Y., Chen, C., Bu, J., A strong user authentication scheme with smart cards for wireless communications (2011) Comput. Commun., 34 (3), pp. 367-374; Li, C.-T., Hwang, M.-S., An efficient biometrics-based remote user authentication scheme using smart cards (2010) J. Netw. Comput. Appl., 33 (1), pp. 1-5; Yang, F.-Y., Wu, T.-D., Chiu, S.-H., A secure control protocol for USB mass storage devices (2010) IEEE Trans. Consum. Electron., 56 (4), pp. 2339-2343. , Nov; Schnorr, C.P., Efficient signature generation by smart cards (1991) J. Cryptol., 4 (3), pp. 161-174; Chen, B., Qin, C., Yu, L., A secure access authentication scheme for removable storage media (2012) J. Inf. Comput. Sci., 9 (15), pp. 4353-4363; Lee, C.-C., Chen, C.-T., Wu, P.-H., Chen, T.-Y., Three-factor control protocol based on elliptic curve cryptosystem for universal serial bus mass storage devices (2013) IET Comput. Digit. Tech., 7 (1), pp. 48-55. , Jan; Bos, J.W., Elliptic curve cryptography in practice (2014) Proc. IACR Cryptol., pp. 157-175; He, D., Kumar, N., Lee, J.-H., Sherratt, R.S., Enhanced three-factor security protocol for consumer USB mass storage devices (2014) IEEE Trans. Consum. Electron., 60 (1), pp. 30-37. , Feb; Giri, D., Sherratt, R.S., Maitra, T., Amin, R., Efficient biometric and password based mutual authentication for consumer USB mass storage devices (2015) IEEE Trans. Consum. Electron., 61 (4), pp. 491-499. , Nov; Amin, R., Sherratt, R.S., Giri, D., Islam, S.H., Khan, M.K., A software agent enabled biometric security algorithm for secure file access in consumer storage devices (2017) IEEE Trans. Consum. Electron., 63 (1), pp. 53-61. , Feb; Giri, D., Sherratt, R.S., Maitra, T., A novel and efficient session spanning biometric and password based three-factor authentication protocol for consumer USB mass storage devices (2016) IEEE Trans. Consum. Electron., 62 (3), pp. 283-291. , Aug; Dolev, D., Yao, A., On the security of public key protocols (1983) IEEE Trans. Inf. Theory, 29 (2), pp. 198-208. , Mar; Automated Validation of Internet Security Protocols and Applications, , http://www.avispa-project.org/, AVISPA, Accessed: Mar. 31, 2018; (2001) Advanced Encryption Standard (AES), , https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.197.pdf, Accessed: Apr. 10, 2018; Dodis, Y., Reyzin, L., Smith, A., Fuzzy extractors: How to generate strong keys from biometrics and other noisy data (2004) Advances in Cryptology-EUROCRYPT, pp. 523-540. , C. Cachin and J. L. Camenisch, Eds. Heidelberg, Germany: Springer; Freedman, M.J., Ishai, Y., Pinkas, B., Reingold, O., Keyword search and oblivious pseudorandom functions (2005) Theory of Cryptography, pp. 303-324. , J. Kilian, Ed. Heidelberg, Germany: Springer; Işler, D., Küpçü, A., Threshold single password authentication (2017) Data Privacy Management, Cryptocurrencies and Blockchain Technology, pp. 143-162. , J. Garcia-Alfaro, G. Navarro-Arribas, H. Hartenstein, and J. Herrera-Joancomartí, Eds. Cham, Switzerland: Springer Int; Kocher, P., Jaffe, J., Jun, B., Differential power analysis (1999) Advances in Cryptology-CRYPTO, pp. 388-397. , M. Wiener, Ed. Heidelberg, Germany: Springer; Barker, E.B., Roginsky, A., (2012) Recommendation for Cryptographic Key Generation, pp. 1-26. , https://csrc.nist.gov/publications/detail/sp/800-133/final, document SP 800-1330, NIST, Gaithersburg, MD, USA; Dworkin, M.J., (2007) Recommendation for Block Cipher Modes of Operation, , Rep., Dec; Bellare, M., Rogaway, P., Entity authentication and key distribution (1993) Proc. 13th Annu. Int. Cryptol. Conf. Adv. Cryptol., pp. 232-249; Pfitzmann, A., Köhntopp, M., (2001) Anonymity, Unobservability, and Pseudonymity-A Proposal for Terminology, pp. 1-9. , Heidelberg: Springer; Das, A., Bonneau, J., Caesar, M., Borisov, N., Wang, X., The tangled Web of password reuse (2014) Proc. Netw. Distrib. Syst. Security Symp., pp. 1-15; (2003), http://www.avispa-project.org/delivs/2.3/d2-3.pdf, A. Validation and I. S. Protocols, Deliverable D2.3: The Intermediate Format. Accessed: Apr. 30, 2018","Zhu, Y.; College of Computer Science and Technology, China; 电子邮件: zhuyw@nuaa.edu.cn",,,Institute of Electrical and Electronics Engineers Inc.,,,,,983063,,ITCED,,English,IEEE Trans Consum Electron,Article,Final,,Scopus,2-s2.0-85057773834
"Wijayanto A.W., Jun Jin C., Madhawa K., Murata T.",56524637100;56024204800;56672917900;7402737180;,Robustness of Compressed Convolutional Neural Networks,2019,"Proceedings - 2018 IEEE International Conference on Big Data, Big Data 2018",,,8622371,4829,4836,,2,10.1109/BigData.2018.8622371,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062588493&doi=10.1109%2fBigData.2018.8622371&partnerID=40&md5=8667c50a3893da68fe3dc0bb34a1a522,"Dept. of Computer Science, Tokyo Institute of Technology, Tokyo, Japan","Wijayanto, A.W., Dept. of Computer Science, Tokyo Institute of Technology, Tokyo, Japan; Jun Jin, C., Dept. of Computer Science, Tokyo Institute of Technology, Tokyo, Japan; Madhawa, K., Dept. of Computer Science, Tokyo Institute of Technology, Tokyo, Japan; Murata, T., Dept. of Computer Science, Tokyo Institute of Technology, Tokyo, Japan","Advancements in deep neural networks have revolutionized the way how we conduct our day-to-day activities ranging from how we unlock our phones to self-driving cars. Convolutional Neural Networks (CNN) play the principal role in learning high level feature representations from visual inputs. It is crucial to know how reliable those neural networks are as human lives can be at stake. Recent experiments on the robustness of CNNs show that they are highly susceptible to small adversarial perturbations. Due to the increasing popularity of mobile devices, there is a significant demand for CNN models which are smaller enough to run on a mobile device without sacrificing the accuracy. Although recent researches have been successful at achieving smaller models with comparable accuracy on standard image datasets, their robustness to adversarial attacks has not been studied. However, massive deployment of smaller models on millions of mobile devices stresses importance of their robustness. In this work, we study how robust such models are with respect to state-of-the-art compression techniques such as quantization. Our contributions are summarized as follows: (1) insights to achieve smaller and robust models (2) a compression framework which is adversarial-aware. Our findings reveal that compressed models are naturally more robust than compact models. This provides an incentive to perform compression rather than designing compact models. Additionally, the latter provides benefits of increased accuracy and higher compression rate, up to 90×. © 2018 IEEE.",compression; deep learning; robustness,Big data; Compaction; Convolution; Deep learning; Neural networks; Robustness (control systems); Technology transfer; Compression rates; Compression techniques; Convolutional neural network; High-level features; Massive deployment; Recent researches; Standard images; State of the art; Deep neural networks,,,,,"LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), p. 436; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9; Han, S., Liu, X., Mao, H., Pu, J., Pedram, A., Horowitz, M.A., Dally, W.J., Eie: Efficient inference engine on compressed deep neural network (2016) Proceedings of the 43rd International Symposium on Computer Architecture, pp. 243-254. , IEEE Press; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, 25, pp. 1097-1105. , Curran Associates, Inc; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) ICLR; Han, S., Mao, H., Dally, W.J., Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding (2016) ICLR; Ullrich, K., Meeds, E., Welling, M., Soft weight-sharing for neural network compression (2017) ICLR; Hubara, I., Courbariaux, M., Soudry, D., El-Yaniv, R., Bengio, Y., Quantized neural networks: Training neural networks with low precision weights and activations (2017) The Journal of Machine Learning ReSearch, 18 (1), pp. 6869-6898; Zhu, C., Han, S., Mao, H., Dally, W.J., Trained ternary quantization (2017) ICLR; Hinton, G., Vinyals, O., Dean, J., Distilling the knowledge in a neural network (2014) NIPS Deep Learning and Representation Learning Workshop; Sainath, T.N., Kingsbury, B., Sindhwani, V., Arisoy, E., Ramabhadran, B., Low-rank matrix factorization for deep neural network training with high-dimensional output targets (2013) Acoustics, Speech and Signal Processing (ICASSP). 2013 IEEE International Conference On, pp. 6655-6659. , IEEE; Sindhwani, V., Sainath, T., Kumar, S., Structured transforms for small-footprint deep learning (2015) Advances in Neural Information Processing Systems, pp. 3088-3096; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) ICLR; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR; Brown, T.B., Mané, D., Roy, A., Abadi, M., Gilmer, J., (2017) Adversarial Patch, , arXiv preprint arXiv: 1712.09665, Dec. 27; Warde-Farley, D., Goodfellow, I., Hazan, T., Papandreou, G., Tarlow, D., Adversarial perturbations of deep neural networks. Perturbations (2016) Optimization, and Statistics, 2; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2017) ICLR Workshop; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) 2016 IEEE Symposium on Security and Privacy (SP), pp. 582-597. , IEEE; Xu, W., Evans, D., Qi, Y., (2017) Feature Squeezing: Detecting Adversarial Examples In Deep Neural Networks, , arXiv preprint arXiv: 1704.01155; Yuan, X., He, P., Zhu, Q., Bhat, R.R., Li, X., (2017) Adversarial Examples: Attacks And Defenses For Deep Learning, , arXiv preprint arXiv: 1712.07107; LeCun, Y., Denker, J.S., Solla, S.A., Optimal brain damage (1990) Advances in Neural Information Processing Systems, 2, pp. 598-605. , Morgan-Kaufmann; Han, S., Pool, J., Tran, J., Dally, W., Learning both weights and connections for efficient neural network (2015) Advances in Neural Information Processing Systems, pp. 1135-1143; Guo, Y., Yao, A., Chen, Y., Dynamic network surgery for efficient dnns (2016) Advances In Neural Information Processing Systems, pp. 1379-1387; Zhou, A., Yao, A., Guo, Y., Xu, L., Chen, Y., Incremental network quantization: Towards lossless cnns with low-precision weights (2017) ICLR; Vanhoucke, V., Senior, A., Mao, M.Z., Improving the speed of neural networks on cpus (2011) Proc. Deep Learning and Unsupervised Feature Learning NIPS Workshop, 1, p. 4. , Citeseer; Iandola, F.N., Han, S., Moskewicz, M.W., Ashraf, K., Dally, W.J., Keutzer, K., (2016) SqueezeNet: AlexNet-Level Accuracy with 50x Fewer Parameters and <0.5MB Model Size, , Feb. 23; Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H., (2017) Mobilenets: Efficient Convolutional Neural Networks for Mobile Vision Applications, , arXiv preprint arXiv:1704.04861; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2017) ICLR; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Bernstein, M., Imagenet large scale visual recognition challenge (2015) International Journal of Computer Vision, 115 (3), pp. 211-252; Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadarrama, S., Darrell, T., Caffe: Convolutional architecture for fast feature embedding (2014) Proceedings of the 22nd ACM International Conference on MultiMedia, pp. 675-678. , ACM; Papernot, N., Faghri, F., Carlini, N., Goodfellow, I., Feinman, R., Kurakin, A., Xie, C., McDaniel, P., (2016) Technical Report on the CleverHans v2.1.0 Adversarial Examples Library, , arXiv preprint arXiv: 1610.00768, Oct. 3; Knoll, B., De Freitas, N., A machine learning perspective on predictive coding with paq8 (2012) Data Compression Conference (DCC). 2012, pp. 377-386. , IEEE",,Song Y.Liu B.Lee K.Abe N.Pu C.Qiao M.Ahmed N.Kossmann D.Saltz J.Tang J.He J.Liu H.Hu X.,Baidu;et al.;Expedia Group;IEEE;IEEE Computer Society;Squirrel AI Learning,Institute of Electrical and Electronics Engineers Inc.,"2018 IEEE International Conference on Big Data, Big Data 2018",10 December 2018 through 13 December 2018,,144531,,9.78E+12,,,English,"Proc. - IEEE Int. Conf. Big Data, Big Data",Conference Paper,Final,,Scopus,2-s2.0-85062588493
"Shi Y., Erpek T., Sagduyu Y.E., Li J.H.",36141159700;36100030900;6507416617;37100868400;,Spectrum Data Poisoning with Adversarial Deep Learning,2019,Proceedings - IEEE Military Communications Conference MILCOM,2019-October,,8599832,407,412,,20,10.1109/MILCOM.2018.8599832,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061444388&doi=10.1109%2fMILCOM.2018.8599832&partnerID=40&md5=417cbe4908ef869f1fc8f11cc56d1fe8,"Intelligent Automation, Inc., Rockville, MD, United States","Shi, Y., Intelligent Automation, Inc., Rockville, MD, United States; Erpek, T., Intelligent Automation, Inc., Rockville, MD, United States; Sagduyu, Y.E., Intelligent Automation, Inc., Rockville, MD, United States; Li, J.H., Intelligent Automation, Inc., Rockville, MD, United States","Machine learning has been applied in wireless communications. In this paper, we consider the case that a cognitive transmitter senses the spectrum and transmits on idle channels determined by a machine learning algorithm. We then present an adversarial machine learning approach to launch a spectrum data poisoning attack. That is, an adversary learns the transmitter's behavior and attempts to falsify the spectrum sensing data over the air by transmitting for a short period of time when the channel is idle to manipulate the input for the decision mechanism of the transmitter. The cognitive engine at the transmitter is a deep neural network model that predicts idle channels with minimum sensing error for data transmissions. The transmitter collects spectrum sensing data and uses it as the input to its machine learning algorithm. In the meantime, the adversary also builds a cognitive engine using another deep neural network model to predict when the transmitter will have a successful transmission based on its spectrum sensing data. The adversary then performs the over-the-air spectrum data poisoning attack, which aims to change the channel occupancy status from idle to busy when the transmitter is sensing, so that the transmitter is fooled into making incorrect transmit decisions. This attack is more energy efficient and harder to detect compared to jamming of data transmissions. We show that this attack is very effective and reduces the throughput of the transmitter substantially. © 2018 IEEE.",Adversarial machine learning; Cognitive radio; Deep learning; Exploratory attack; Spectrum data falsification; Spectrum data poisoning,Cognitive radio; Crime; Data transfer; Deep learning; Deep neural networks; Energy efficiency; Engines; Machine learning; Military communications; Transmitters; Cognitive engines; Decision mechanism; Exploratory attack; Machine learning approaches; Neural network model; Poisoning attacks; Spectrum data falsification; Wireless communications; Learning algorithms,,,,,"Mitola, J., (2000) Cognitive Radio: An Integrated Agent Architecture for Software Defined Radio, Doctor of Technology, Royal Inst, , Technol. (KTH), Stockholm, Sweden; Clancy, T.C., Goergen, N., Security in cognitive radio networks: Threats and mitigation (2008) IEEE Conference on Cognitive Radio Ori-ented Wireless Networks and Communications (CrownCom), , Singapore, May 15-17; Yuan, Z., Niyato, D., Li, H., Song, J.B., Han, Z., Defeating primary user emulation attacks using belief propagation in cognitive radio networks (2012) IEEE Journal Selected Areas in Communications, 30 (10), pp. 1850-1860. , Nov; Sagduyu, Y.E., Securing cognitive radio networks with dynamic trust against spectrum sensing data falsification (2014) IEEE Military Communica-tions Conference (MILCOM), , Baltimore, MD, Oct. 6-8; Yut, F.R., Tang, H., Huang, M., Lit, Z., Mason, P.C., Defense against spectrum sensing data falsification attacks in mobile ad hoc networks with cognitive radios (2009) IEEE Military Communications Con-ference (MILCOM), , Boston, MA, Oct. 18-21; Sagduyu, Y.E., Berry, R., Ephremides, A., Jamming games in wireless networks with incomplete information (2011) IEEE Communications Magazine, 49 (8), pp. 112-118. , Aug; Sagduyu, Y.E., Shi, Y., MacKenzie, A.B., Hou, T., Regret minimization for primary/secondary access to satellite resources with cognitive interference (2018) IEEE Transactions on Wireless Communications, 17 (5), pp. 3512-3523. , May; Zou, Y., Zhu, J., Yang, L., Liang, Y.-C., Yao, Y.-D., Securing physical-layer communications for cognitive radio networks (2015) IEEE Communications Magazine, 53 (9), pp. 48-54. , Sep; Sagduyu, Y.E., Berry, R., Ephremides, A., MAC games for distributed wireless network security with incomplete information of selfish and malicious user types (2009) IEEE International Conference on Game Theory for Networks (GameNets), , Istanbul, Turkey, May 13-15; Lu, Z., Sagduyu, Y.E., Li, J., Securing the backpressure algorithm for wireless networks (2017) IEEE Transactions on Mobile Computing, 16 (4), pp. 1136-1148. , Apr; Lu, Z., Sagduyu, Y.E., Li, J., Queuing the trust: Secure backpressure algorithm against insider threats in wireless networks (2015) IEEE Conference on Computer Communications (INFOCOM), , Hong Kong, Apr. 26-May 1; Sagduyu, Y.E., Berry, R., Ephremides, A., Jamming games for power controlled medium access with dynamic traffic (2010) IEEE International Symposium on Information Theory (ISIT), , Austin, TX, June 12-18; Sagduyu, Y.E., Berry, R., Ephremides, A., Wireless jamming attacks under dynamic traffic uncertainty (2010) IEEE International Symposium on Modeling and Optimization in Mobile, Ad Hoc, and Wireless Networks (WIOPT), , Avignon, France, May 31-June 4; Sagduyu, Y.E., Ephremides, A., SINR-Based MAC games for selfish and malicious Users (2007) Information Theory and Applications (ITA) Workshop, , San Diego, CA, Jan. 29-Feb. 2; Wang, S., Sagduyu, Y.E., Zhang, J., Li, J.H., Traffic shaping impact of network coding on spectrum predictability and jamming attacks (2011) IEEE Military Communications Conference (MILCOM), , Baltimore, MD, Nov. 7-11; Sagduyu, Y.E., Ephremides, A., A game-theoretic analysis of denial of service attacks in wireless random access (2009) Journal of Wireless Networks, 15 (5), pp. 651-666. , July; Davaslioglu, K., Sagduyu, Y.E., Generative adversarial learning for spectrum sensing (2018) IEEE International Conference on Communications (ICC), , Kansas City, MO, May 20-24; Shi, Y., Sagduyu, Y.E., Erpek, T., Davaslioglu, K., Lu, Z., Li, J., Adversarial deep learning for cognitive radio security: Jamming attack and defense strategies (2018) IEEE International Conference on Communications (ICC) Workshop on Promises and Challenges of Machine Learning in Communication Networks, , Kansas City, MO, May 24; Erpek, T., Sagduyu, Y.E., Shi, Y., (2018) Deep Learning for Launching and Mitigating Wireless Jamming Attacks; O'Shea, T., Corgan, J., Clancy, C., Convolutional radio modulation recognition networks (2016) International Conference on Engineering Appli-cations of Neural Networks, , Aberdeen, United Kingdom, Sept. 2-5; Ateniese, G., Mancini, L., Spognardi, A., Villani, A., Vitali, D., Felici, G., Hacking smart machines with smarter ones: How to extract meaningful data from machine learning classifiers (2015) International Jour-nal of Security and Networks, 10 (3), pp. 137-150. , Sept; Tramer, F., Zhang, F., Juels, A., Reiter, M., Ristenpart, T., Stealing machine learning models via prediction APIs (2016) USENIX Security, , Austin, TX, Aug. 10-12; Fredrikson, M., Jha, S., Ristenpart, T., Model inversion attacks that exploit confidence information and basic countermeasures (2015) ACM SIGSAC Conference on Computer and Communications Security, , Denver, CO, Oct. 12-16; Shi, Y., Sagduyu, Y.E., Grushin, A., How to steal a machine learning classifier with deep learning (2017) IEEE Symposium on Technologies for Homeland Security, , Waltham, MA, April 25-26; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Srndic, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, , Prague, Czech Republic, Sept. 23-27; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World; Biggio, B., Nelson, B., Laskov, P., Poisoning attacks against support vector machines (2012) International Conference on International Conference on Machine Learning, , Edinburgh, Scotland, June 26-July 1; Pi, L., Lu, Z., Sagduyu, Y., Chen, S., Defending active learning against adversarial inputs in automated document classification (2016) IEEE Global Conference on Signal and Information Processing (GlobalSIP), , Washington, D. C., Dec. 7-9; Shi, Y., Sagduyu, Y.E., Evasion and causative attacks with adversarial deep learning (2017) IEEE Military Communications Conference, , Baltimore, MD, Oct. 23-25; Shi, Y., Sagduyu, Y.E., Davaslioglu, K., Levy, R., Vulnerability detection and analysis in adversarial deep learning (2018) Guide to Vulnerability Analysis for Computer Networks and Systems: An Artificial Intelligence Approach, pp. 235-258. , S. Parkinson, A. Crampton, R. Hill, Eds Springer",,,AFCEA;IEEE,Institute of Electrical and Electronics Engineers Inc.,"2018 IEEE Military Communications Conference, MILCOM 2018",29 October 2018 through 31 October 2018,,144303,,9.78E+12,PMICE,,English,Proc IEEE Mil Commun Conf MILCOM,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85061444388
Sakha M.B.,57219176824;,Image enhancement and adversarial attack pipeline for scene privacy protection,2019,CEUR Workshop Proceedings,2670,,,,,,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091585012&partnerID=40&md5=832e96b27e81e21d19d8d392ed1cb957,"Habib University, Pakistan","Sakha, M.B., Habib University, Pakistan","In this paper, we propose approaches to prevent automatic inference of scene class by classifiers and also enhance (or maintain) the visual appeal of images. The task is part of the Pixel Privacy challenge of the MediaEval 2019 workshop. The fusion based approaches we propose apply adversarial perturbations on the images enhanced by image enhancement algorithms instead of the original images. They combine the benefits of image style transfer/contrast enhancement and the white-box adversarial attack methods and have not been previously used in the literature for fooling the classifier and enhancing the images at the same time. We also propose to use simple Euclidean transformations which include image translation and rotation and show their efficacy in fooling the classifier. We test the proposed approaches on a subset of the Places365-standard dataset and get promising results. © 2019 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",,Data privacy; Statistical tests; Attack methods; Automatic inference; Euclidean transformations; Image enhancement algorithm; Image translation; Original images; Privacy protection; Visual appeals; Image enhancement,,,,,"Chen, Yang, Lai, Yu-Kun, Liu, Yong-Jin, CartoonGAN: Generative adversarial networks for photo cartoonization (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 9465-9474; Choi, Jaeyoung, Larson, Martha, Li, Xinchao, Li, Kevin, Fried-land, Gerald, Hanjalic, Alan, The geo-privacy bonus of popular photo enhancements (2017) Proceedings of the 2017 ACM on International Conference on Multimedia Retrieval, pp. 84-92. , ACM; Engstrom, Logan, Tran, Brandon, Tsipras, Dimitris, Schmidt, Ludwig, Madry, Aleksander, Exploring the Landscape of Spatial Robustness (2019) International Conference on Machine Learning, pp. 1802-1811; Goodfellow, Ian, Pouget-Abadie, Jean, Mirza, Mehdi, Xu, Bing, Warde-Farley, David, Ozair, Sherjil, Courville, Aaron, Bengio, Yoshua, Generative adversarial nets (2014) Advances in neural information processing systems, pp. 2672-2680; Goodfellow, Ian J, Shlens, Jonathon, Szegedy, Christian, (2014) Explaining and harnessing adversarial examples, , arXiv preprint arXiv:1412.6572 (2014); He, Kaiming, Zhang, Xiangyu, Ren, Shaoqing, Sun, Jian, Deep residual learning for image recognition (2016) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770-778; Kurakin, Alexey, Goodfellow, Ian, Bengio, Samy, (2016) Adversarial examples in the physical world, , arXiv preprint arXiv:1607.02533 (2016); Li, C. Y., Shamsabadi, A. S., Sanchez-Matilla, R., Mazzon, R., Cavallaro, A., Scene Privacy Protection (2019) Proc. IEEE Int. Conf. on Acoustics, Speech and Signal Processing, , Brighton, UK; Liu, Zhuoran, Zhao, Zhengyu, First Steps in Pixel Privacy: Exploring Deep Learning-based Image Enhancement against Large-Scale Image Inference (2018) MediaEval; Liu, Zhuoran, Zhao, Zhengyu, Larson, Martha, Pixel Privacy 2019: Protecting Sensitive Scene Information in Images (2019) Working Notes Proceedings of the MediaEval 2019 Workshop; Madry, Aleksander, Makelov, Aleksandar, Schmidt, Ludwig, Tsipras, Dimitris, Vladu, Adrian, (2017) Towards deep learning models resistant to adversarial attacks, , arXiv preprint arXiv:1706.06083 (2017); Orekondy, Tribhuvanesh, Schiele, Bernt, Fritz, Mario, Towards a visual privacy advisor: Understanding and predicting privacy risks in images (2017) Proceedings of the IEEE International Conference on Computer Vision, pp. 3686-3695; Talebi, Hossein, Milanfar, Peyman, NIMA: Neural image assessment (2018) IEEE Transactions on Image Processing, 27 (8), pp. 3998-4011. , (2018); Ying, Zhenqiang, Li, Ge, Ren, Yurui, Wang, Ronggang, Wang, Wenmin, A new image contrast enhancement algorithm using exposure fusion framework (2017) International Conference on Computer Analysis of Images and Patterns, pp. 36-46. , Springer; Zhou, Bolei, Lapedriza, Agata, Khosla, Aditya, Oliva, Aude, Torralba, Antonio, Places: A 10 million Image Database for Scene Recognition (2017) IEEE Transactions on Pattern Analysis and Machine Intelligence, , (2017)","Sakha, M.B.; Habib UniversityPakistan; 电子邮件: mbilal.sakha@gmail.com",Larson M.Hicks S.Constantin M.G.Bischke B.Porter A.Zhao P.Lux M.Quiros L.C.Calandre J.Jones G.,,CEUR-WS,"2019 Working Notes of the MediaEval Workshop, MediaEval 2019",27 October 2019 through 30 October 2019,,162975,16130073,,,,English,CEUR Workshop Proc.,Conference Paper,Final,,Scopus,2-s2.0-85091585012
"Cheng S., Dong Y., Pang T., Su H., Zhu J.",57209823666;57191433539;57204799576;37017428500;56734692500;,Improving black-box adversarial attacks with a transfer-based prior,2019,Advances in Neural Information Processing Systems,32,,,,,,40,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090169867&partnerID=40&md5=9dde3ef3249f74f65c428131ed49734c,"Dept. of Comp. Sci. and Tech., BNRist Center, State Key Lab for Intell. Tech. and Sys., Institute for AI, THBI Lab, Tsinghua University, Beijing, 100084, China","Cheng, S., Dept. of Comp. Sci. and Tech., BNRist Center, State Key Lab for Intell. Tech. and Sys., Institute for AI, THBI Lab, Tsinghua University, Beijing, 100084, China; Dong, Y., Dept. of Comp. Sci. and Tech., BNRist Center, State Key Lab for Intell. Tech. and Sys., Institute for AI, THBI Lab, Tsinghua University, Beijing, 100084, China; Pang, T., Dept. of Comp. Sci. and Tech., BNRist Center, State Key Lab for Intell. Tech. and Sys., Institute for AI, THBI Lab, Tsinghua University, Beijing, 100084, China; Su, H., Dept. of Comp. Sci. and Tech., BNRist Center, State Key Lab for Intell. Tech. and Sys., Institute for AI, THBI Lab, Tsinghua University, Beijing, 100084, China; Zhu, J., Dept. of Comp. Sci. and Tech., BNRist Center, State Key Lab for Intell. Tech. and Sys., Institute for AI, THBI Lab, Tsinghua University, Beijing, 100084, China","We consider the black-box adversarial setting, where the adversary has to generate adversarial perturbations without access to the target models to compute gradients. Previous methods tried to approximate the gradient either by using a transfer gradient of a surrogate white-box model, or based on the query feedback. However, these methods often suffer from low attack success rates or poor query efficiency since it is non-trivial to estimate the gradient in a high-dimensional space with limited information. To address these problems, we propose a prior-guided random gradient-free (P-RGF) method to improve black-box adversarial attacks, which takes the advantage of a transfer-based prior and the query information simultaneously. The transfer-based prior given by the gradient of a surrogate model is appropriately integrated into our algorithm by an optimal coefficient derived by a theoretical analysis. Extensive experiments demonstrate that our method requires much fewer queries to attack black-box models with higher success rates compared with the alternative state-of-the-art methods. © 2019 Neural information processing systems foundation. All rights reserved.",,Alternative state; High dimensional spaces; Limited information; Optimal coefficient; Query efficiency; Query information; Surrogate model; White-box models,,,,,"Athalye, Anish, Carlini, Nicholas, Wagner, David, Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples (2018) International Conference on Machine Learning (ICML); Biggio, Battista, Corona, Igino, Maiorca, Davide, Nelson, Blaine, Laskov, Pavel, Giacinto, Giorgio, Roli, Fabio, Evasion attacks against machine learning at test time (2013) Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 387-402; Brendel, Wieland, Rauber, Jonas, Bethge, Matthias, Decision-based adversarial attacks: Reliable attacks against black-box machine learning models (2018) International Conference on Learning Representations (ICLR); Brunner, Thomas, Diehl, Frederik, Le, Michael Truong, Knoll, Alois, Guessing smart: Biased sampling for efficient black-box adversarial attacks (2019) The IEEE International Conference on Computer Vision (ICCV); Carlini, Nicholas, Wagner, David, Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy; Chen, Pin Yu, Zhang, Huan, Sharma, Yash, Yi, Jinfeng, Hsieh, Cho Jui, Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) ACM Workshop on Artificial Intelligence and Security (AISec), pp. 15-26; Dong, Yinpeng, Liao, Fangzhou, Pang, Tianyu, Su, Hang, Zhu, Jun, Hu, Xiaolin, Li, Jianguo, Boosting adversarial attacks with momentum (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Dong, Yinpeng, Pang, Tianyu, Su, Hang, Zhu, Jun, Evading defenses to transferable adversarial examples by translation-invariant attacks (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Dong, Yinpeng, Su, Hang, Wu, Baoyuan, Li, Zhifeng, Liu, Wei, Zhang, Tong, Zhu, Jun, Efficient decision-based black-box adversarial attacks on face recognition (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Duchi, John C, Jordan, Michael I, Wainwright, Martin J, Wibisono, Andre, Optimal rates for zero-order convex optimization: The power of two function evaluations (2015) IEEE Transactions on Information Theory, 61 (5), pp. 2788-2806; Ghadimi, Saeed, Lan, Guanghui, Stochastic first-and zeroth-order methods for nonconvex stochastic programming (2013) SIAM Journal on Optimization, 23 (4), pp. 2341-2368; Goodfellow, Ian, Bengio, Yoshua, Courville, Aaron, (2016) Deep Learning, , http://www.deeplearningbook.org, MIT Press; Goodfellow, Ian J, Shlens, Jonathon, Szegedy, Christian, Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations (ICLR); Guo, Chuan, Frank, Jared S, Weinberger, Kilian Q, (2018) Low frequency adversarial perturbation, , arXiv preprint arXiv:1809.08758; Guo, Chuan, Rana, Mayank, Cisse, Moustapha, Van Der Maaten, Laurens, Countering adversarial images using input transformations (2018) International Conference on Learning Representations (ICLR); He, Kaiming, Zhang, Xiangyu, Ren, Shaoqing, Sun, Jian, Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR); He, Kaiming, Zhang, Xiangyu, Ren, Shaoqing, Sun, Jian, Identity mappings in deep residual networks (2016) European Conference on Computer Vision (ECCV); Ilyas, Andrew, Engstrom, Logan, Athalye, Anish, Lin, Jessy, Black-box adversarial attacks with limited queries and information (2018) International Conference on Machine Learning (ICML); Ilyas, Andrew, Engstrom, Logan, Madry, Aleksander, Prior convictions: Black-box adversarial attacks with bandits and priors (2019) International Conference on Learning Representations (ICLR); Kurakin, Alexey, Goodfellow, Ian, Bengio, Samy, Adversarial examples in the physical world (2017) The International Conference on Learning Representations (ICLR) Workshops; Lax, Peter D, Terrell, Maria Shea, (2014) Calculus with applications, , Springer; Liao, Fangzhou, Liang, Ming, Dong, Yinpeng, Pang, Tianyu, Hu, Xiaolin, Zhu, Jun, Defense against adversarial attacks using high-level representation guided denoiser (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Liu, Yanpei, Chen, Xinyun, Liu, Chang, Song, Dawn, Delving into transferable adversarial examples and black-box attacks (2017) International Conference on Learning Representations (ICLR); Madry, Aleksander, Makelov, Aleksandar, Schmidt, Ludwig, Tsipras, Dimitris, Vladu, Adrian, Towards deep learning models resistant to adversarial attacks (2018) International Conference on Learning Representations (ICLR); Maheswaranathan, Niru, Metz, Luke, Tucker, George, Choi, Dami, Sohl-Dickstein, Jascha, Guided evolutionary strategies: Augmenting random search with surrogate gradients (2019) International Conference on Machine Learning (ICML); Nesterov, Yurii, Spokoiny, Vladimir, Random gradient-free minimization of convex functions (2017) Foundations of Computational Mathematics, 17 (2), pp. 527-566; Bhagoji, Arjun Nitin, He, Warren, Li, Bo, Song, Dawn, Practical black-box attacks on deep neural networks using efficient query mechanisms (2018) European Conference on Computer Vision (ECCV); Oh, Seong Joon, Augustin, Max, Schiele, Bernt, Fritz, Mario, Towards reverse-engineering black-box neural networks (2018) International Conference on Learning Representations (ICLR); Papernot, Nicolas, McDaniel, Patrick, Goodfellow, Ian, (2016) Transferability in machine learning: from phenomena to black-box attacks using adversarial samples, , arXiv preprint arXiv:1605.07277; Papernot, Nicolas, McDaniel, Patrick, Goodfellow, Ian, Jha, Somesh, Berkay Celik, Z, Swami, Ananthram, Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security; Russakovsky, Olga, Deng, Jia, Su, Hao, Krause, Jonathan, Satheesh, Sanjeev, Ma, Sean, Huang, Zhiheng, Bernstein, Michael, Imagenet large scale visual recognition challenge (2015) International Journal of Computer Vision, 115 (3), pp. 211-252; Simonyan, Karen, Zisserman, Andrew, Very deep convolutional networks for large-scale image recognition (2015) International Conference on Learning Representations (ICLR); Szegedy, Christian, Zaremba, Wojciech, Sutskever, Ilya, Bruna, Joan, Erhan, Dumitru, Goodfellow, Ian, Fergus, Rob, Intriguing properties of neural networks (2014) International Conference on Learning Representations (ICLR); Szegedy, Christian, Vanhoucke, Vincent, Ioffe, Sergey, Shlens, Jon, Wojna, Zbigniew, Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Tu, Chun-Chen, Ting, Paishun, Chen, Pin-Yu, Liu, Sijia, Zhang, Huan, Yi, Jinfeng, Hsieh, Cho-Jui, Cheng, Shin-Ming, Autozoom: Autoencoder-based zeroth order optimization method for attacking black-box neural networks (2019) Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence (AAAI); Uesato, Jonathan, O'Donoghue, Brendan, van den Oord, Aaron, Kohli, Pushmeet, Adversarial risk and the dangers of evaluating against weak attacks (2018) International Conference on Machine Learning (ICML); Xie, Cihang, Wang, Jianyu, Zhang, Zhishuai, Ren, Zhou, Yuille, Alan, Mitigating adversarial effects through randomization (2018) International Conference on Learning Representations (ICLR)","Zhu, J.; Dept. of Comp. Sci. and Tech., China; 电子邮件: dcszj@mail.tsinghua.edu.cn",,Citadel;Doc.AI;et al.;Lambda;Lyft;Microsoft Research,Neural information processing systems foundation,"33rd Annual Conference on Neural Information Processing Systems, NeurIPS 2019",8 December 2019 through 14 December 2019,,161263,10495258,,,,English,Adv. neural inf. proces. syst.,Conference Paper,Final,,Scopus,2-s2.0-85090169867
"Forutan V., Fischer R.F.H.",16068498900;7403087446;,On the security of lattice-based physical-layer network coding against wiretap attacks,2019,"SCC 2015 - 10th International ITG Conference on Systems, Communications and Coding",,,,,,,2,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084022292&partnerID=40&md5=d2d9c09c496291d84d8aecb2f4f247c1,"Institut für Nachrichtentechnik, Universität Ulm, Ulm, Germany","Forutan, V., Institut für Nachrichtentechnik, Universität Ulm, Ulm, Germany; Fischer, R.F.H., Institut für Nachrichtentechnik, Universität Ulm, Ulm, Germany","We consider Gaussian-channel networks that employ lattice-based physical-layer network coding (PNC) as their routing strategy. Under the assumption that the communication is subject to the adversarial attacks in the form of wiretapping, we address data security from an information-theoretic viewpoint. To this end, we first examine how data transfer in PNC-based networking is vulnerable against wiretapping attacks, and then we show that it, due to the structured codebook employed in PNC, is possible to apply the already available lattice coset coding to obstruct the attackers in obtaining any information from the data communicated over the network. Several wiretap attack scenarios targeted to such networks are considered and possible solutions are discussed. © VDE VERLAG GMBH · Berlin · Offenbach.",,Codes (symbols); Data transfer; Network layers; Attack scenarios; Coset coding; Gaussian channels; Lattice-based; Physical layer network coding (PNC); Routing strategies; Structured codebooks; Network coding,,,,,"Wyner, A., The wire-tap channel (1975) The Bell System Technical Journal, 54 (8), pp. 1355-1387. , Oct; Csiszár, I., Körner, J., Broadcast channels with confidential messages (1978) IEEE Trans. Information Theory, 24 (3), pp. 339-348. , May; Jorswieck, E.A., Wolf, A., Gerbracht, S., Secrecy on the physical layer in wireless networks, Ser. Trends in telecommunications technologies (2010) INTECH, 20, pp. 413-435. , Mar. ch; Bassily, R., Ekrem, E., He, X., Tekin, E., Xie, J., Bloch, M., Ulukus, S., Yener, A., Cooperative security at the physical layer: A summary of recent advances (2013) IEEE Signal Processing Magazine, 30 (5), pp. 16-28. , Sep; Goel, S., Negi, R., Guaranteeing secrecy using artificial noise (2008) IEEE Trans. Wireless Communications, 7 (6), pp. 2180-2189. , Jun; Liu, S., Hong, Y., Viterbo, E., Unshared secret key cryptography (2014) Int. Zurich Seminar on Communications, , Feb; Harrison, W., Almeida, J., Bloch, M., McLaughlin, S., Barros, J., Coding for secrecy: An overview of error-control coding techniques for physical-layer security (2013) IEEE Signal Processing Magazine, 30 (5), pp. 41-50. , Sep; Ahlswede, R., Cai, N., Li, S.-Y., Yeung, R., Network information flow (2000) IEEE Trans. Information Theory, 46 (4), pp. 1204-1216. , Jul; Cai, N., Yeung, R., Secure network coding on a wiretap network (2011) IEEE Trans. Information Theory, 57 (1), pp. 424-435. , Jan; He, X., Yener, A., Providing secrecy with structured codes: Two-user Gaussian channels (2014) IEEE Trans. Information Theory, 60 (4), pp. 2121-2138. , Apr; Zhang, S., Liew, S., Lam, P., Hot topic: Physical-layer network coding (2006) 12th Annual Int. Conference on Mobile Computing and Networking, pp. 358-365; Popovski, P., Yomo, H., Physical network coding in two-way wireless relay channels (2007) IEEE Int. Conference on Communications, pp. 707-712. , Jun; Nazer, B., Gastpar, M., Computing over multiple-access channels with connections to wireless network coding (2006) IEEE Int. Symposium on Information Theory, pp. 1354-1358. , Jul; Nazer, B., Gastpar, M., Compute-and-forward: Harnessing interference through structured codes (2011) IEEE Trans. Information Theory, 57 (10), pp. 6463-6486. , Oct; Richter, J., Franz, E., Engelmann, S., Pfennig, S., Jorswieck, E., Physical layer security vs. Network layer secrecy: Who wins on the untrusted two-way relay channel? (2013) IEEE 18th Int. Workshop on Computer Aided Modeling and Design of Communication Links and Networks, pp. 164-168. , Sep; Shashank, V., Kashyap, N., Lattice coding for strongly secure compute-and-forward in a bidirectional relay (2013) IEEE Int. Symposium on Information Theory, pp. 2775-2779. , Jul; Ling, C., Belfiore, J.-C., Lattice Gaussian coding for capacity and secrecy: Two sides of one coin (2014) Int. Zurich Seminar on Communications, , Feb; Hong, S.-N., Caire, G., Compute-and-forward strategies for cooperative distributed antenna systems (2013) IEEE Trans. Information Theory, 59 (9), pp. 5227-5243. , Sep; Fischer, R.F.H., (2002) Precoding and Signal Shaping for Digital Transmission, , New York, NY, USA: John Wiley & Sons, Inc; Zhan, J., Nazer, B., Erez, U., Gastpar, M., Integer-forcing linear receivers (2010) IEEE Int. Symposium on Information Theory, pp. 1022-1026. , Jun; Zhan, J., Nazer, B., Erez, U., Gastpar, M., Integer-forcing linear receivers (2014) IEEE Trans. Information Theory, , http://arxiv.org/abs/1003.5966, to appear in; Windpassinger, C., Fischer, R.F.H., Low-complexity near-maximum-likelihood detection and precoding for MIMO systems using lattice reduction (2003) IEEE Information Theory Workshop, pp. 345-348. , March; Zamir, R., Lattices are everywhere (2009) Information Theory and Applications Workshop, pp. 392-421. , Feb; Ling, C., Luzzi, L., Belfiore, J., Stehle, D., Semantically secure lattice codes for the Gaussian wiretap channel (2014) IEEE Trans. Information Theory, 60 (10), pp. 6399-6416. , Oct; Belfiore, J.C., Oggier, F., Secrecy gain: A wiretap lattice code design (2010) Int. Symposium on Information Theory and Its Applications, pp. 174-178. , Oct; Erez, U., Zamir, R., Achieving 1/2log(1+SNR) on the AWGN channel with lattice encoding and decoding (2004) IEEE Trans. Information Theory, 50 (10), pp. 2293-2314. , Oct; Ling, C., Belfiore, J.-C., Achieving the AWGN channel capacity with lattice Gaussian coding (2013) IEEE Int. Symposium on Information Theory, pp. 1416-1420. , Jul",,,IEEE;IEEE Information Theory Society;Information Technology Society within VDE (ITG);Rohde and Schwarz;Technische Universitat Hamburg-Hamburg (TUHH),VDE Verlag GmbH,"10th International ITG Conference on Systems, Communications and Coding, SCC 2015",2 February 2015 through 5 February 2015,,151746,,9.78E+12,,,English,"SCC - Int. ITG Conf. Syst., Commun. Coding",Conference Paper,Final,,Scopus,2-s2.0-85084022292
"Song C., Wang L., He K., Hopcroft J.E.",57210639361;55721280000;57204773777;6701837666;,Improving the generalization of adversarial training with domain adaptation,2019,"7th International Conference on Learning Representations, ICLR 2019",,,,,,,25,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083953819&partnerID=40&md5=09c0f4d10bf81b1cbf0fe51dfd00fcb9,"Department of Computer Science, Huazhong University of Science and Technology, Wuhan, 430074, China; Department of Machine Intelligence, Peking University, China; Department of Computer Science, Cornell University, Ithaca, NY  14850, United States","Song, C., Department of Computer Science, Huazhong University of Science and Technology, Wuhan, 430074, China; Wang, L., Department of Machine Intelligence, Peking University, China; He, K., Department of Computer Science, Huazhong University of Science and Technology, Wuhan, 430074, China; Hopcroft, J.E., Department of Computer Science, Cornell University, Ithaca, NY  14850, United States","By injecting adversarial examples into training data, adversarial training is promising for improving the robustness of deep learning models. However, most existing adversarial training approaches are based on a specific type of adversarial attack. It may not provide sufficiently representative samples from the adversarial domain, leading to a weak generalization ability on adversarial examples from other attacks. Moreover, during the adversarial training, adversarial perturbations on inputs are usually crafted by fast single-step adversaries so as to scale to large datasets. This work is mainly focused on the adversarial training yet efficient FGSM adversary. In this scenario, it is difficult to train a model with great generalization due to the lack of representative adversarial samples, aka the samples are unable to accurately reflect the adversarial domain. To alleviate this problem, we propose a novel Adversarial Training with Domain Adaptation (ATDA) method. Our intuition is to regard the adversarial training on FGSM adversary as a domain adaption task with limited number of target domain samples. The main idea is to learn a representation that is semantically meaningful and domain invariant on the clean domain as well as the adversarial domain. Empirical evaluations on Fashion-MNIST, SVHN, CIFAR-10 and CIFAR-100 demonstrate that ATDA can greatly improve the generalization of adversarial training and the smoothness of the learned models, and outperforms state-of-the-art methods on standard benchmark datasets. To show the transfer ability of our method, we also extend ATDA to the adversarial training on iterative attacks such as PGD-Adversial Training (PAT) and the defense performance is improved considerably. © 7th International Conference on Learning Representations, ICLR 2019. All Rights Reserved.",,Iterative methods; Large dataset; Benchmark datasets; Domain adaptation; Domain adaptions; Empirical evaluations; Generalization ability; Learning models; Representative sample; State-of-the-art methods; Deep learning,,,,,"Arpit, D., Jastrzebski, S.K., Ballas, N., Krueger, D., Bengio, E., Kanwal, M.-D.S., Maharaj, T., Lacoste-Julien, S., A closer look at memorization in deep networks (2017) Proceedings of the 34th International Conference on Machine Learning, ICML 2017, pp. 233-242. , Sydney, NSW, Australia, 6-11 August 2017; Borgwardt, K.M., Gretton, A., Rasch, M.J., Kriegel, H.-P., Schölkopf, B., Smola, A.J., Integrating structured biological data by kernel maximum mean discrepancy (2006) Bioinformatics, 22 (14), pp. e49-e57; Clevert, D.-A., Unterthiner, T., Hochreiter, S., (2015) Fast and Accurate Deep Network Learning by Exponential Linear Units (Elus), , arXiv preprint; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2018) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , June; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images, , Technical report, Citeseer; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Machine Learning at Scale, , arXiv preprint; Liao, F., Liang, M., Dong, Y., Pang, T., Zhu, J., Hu, X., Defense against adversarial attacks using high-level representation guided denoiser (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1778-1787; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) International Conference on Learning Representations(ICLR); Van Der Maaten, L., Hinton, G., Visualizing data using t-sne (2008) Journal of Machine Learning Research, 9, pp. 2579-2605. , Nov; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) International Conference on Learning Representations(ICLR); Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., Ng, A.Y., Reading digits in natural images with unsupervised feature learning (2011) NIPS Workshop on Deep Learning and Unsupervised Feature Learning, p. 5. , 2011; Nøkland, A., (2015) Improving Back-Propagation by Adding an Adversarial Gradient, , arXiv preprint; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Li, F.-F., Imagenet large scale visual recognition challenge (2015) International Journal of Computer Vision, 115 (3), pp. 211-252; Sun, B., Saenko, K., Deep coral: Correlation alignment for deep domain adaptation (2016) European Conference on Computer Vision, pp. 443-450; Szegedy, C., Inc, G., Zaremba, W., Sutskever, I., Inc, G., Bruna, J., Erhan, D., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations(ICLR); Tabacof, P., Valle, E., Exploring the space of adversarial images (2016) 2016 International Joint Conference on Neural Networks (IJCNN), pp. 426-433; Torralba, A., Efros, A.A., Unbiased look at dataset bias (2011) Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on, pp. 1521-1528; Tramèr, F., Papernot, N., Goodfellow, I.J., Boneh, D., McDaniel, P.D., (2017) The Space of Transferable Adversarial Examples, , arXiv preprint; Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2018) International Conference on Learning Representations; Wen, Y., Zhang, K., Li, Z., Qiao, Y., A discriminative feature learning approach for deep face recognition (2016) European Conference on Computer Vision, pp. 499-515; Wong, E., Zico Kolter, J., Provable defenses against adversarial examples via the convex outer adversarial polytope (2018) Proceedings of the 35th International Conference on Machine Learning, ICML 2018, pp. 5283-5292. , Stockholmsmässan, Stockholm, Sweden, July 10-15, 2018; Wu, Y., He, K., (2018) Group Normalization, , arXiv preprint; Xiao, H., Rasul, K., Vollgraf, R., (2017) Fashion-Mnist: A Novel Image Dataset for Benchmarking Machine Learning Algorithms, , arXiv preprint","He, K.; Department of Computer Science, China; 电子邮件: brooklet60@hust.edu.cn",,,"International Conference on Learning Representations, ICLR","7th International Conference on Learning Representations, ICLR 2019",6 May 2019 through 9 May 2019,,149936,,,,,English,"Int. Conf. Learn. Represent., ICLR",Conference Paper,Final,,Scopus,2-s2.0-85083953819
"Schott L., Rauber J., Bethge M., Brendel W.",57210636922;57208446440;57210225326;57207550476;,Towards the first adversarially robust neural network model on MnIsT,2019,"7th International Conference on Learning Representations, ICLR 2019",,,,,,,47,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083953010&partnerID=40&md5=7cb6d1eb65689ec40e666be2c4683b44,"Centre for Integrative Neuroscience, University of Tübingen, Germany; Bernstein Center for Computational Neuroscience Tübingen, Germany; Max Planck Institute for Biological Cybernetics, Germany","Schott, L., Centre for Integrative Neuroscience, University of Tübingen, Germany, Bernstein Center for Computational Neuroscience Tübingen, Germany; Rauber, J., Centre for Integrative Neuroscience, University of Tübingen, Germany, Bernstein Center for Computational Neuroscience Tübingen, Germany; Bethge, M., Centre for Integrative Neuroscience, University of Tübingen, Germany, Bernstein Center for Computational Neuroscience Tübingen, Germany, Max Planck Institute for Biological Cybernetics, Germany; Brendel, W., Centre for Integrative Neuroscience, University of Tübingen, Germany, Bernstein Center for Computational Neuroscience Tübingen, Germany","Despite much effort, deep neural networks remain highly susceptible to tiny input perturbations and even for MNIST, one of the most common toy datasets in computer vision, no neural network model exists for which adversarial perturbations are large and make semantic sense to humans. We show that even the widely recognized and by far most successful L∞ defense by Madry et al. (1) has lower L0 robustness than undefended networks and is still highly susceptible to L2 perturbations, (2) classifies unrecognizable images with high certainty, (3) performs not much better than simple input binarization and (4) features adversarial perturbations that make little sense to humans. These results suggest that MNIST is far from being solved in terms of adversarial robustness. We present a novel robust classification model that performs analysis by synthesis using learned class-conditional data distributions. We derive bounds on the robustness and go to great length to empirically evaluate our model using maximally effective adversarial attacks by (a) applying decision-based, score-based, gradient-based and transfer-based attacks for several different Lp norms, (b) by designing a new attack that exploits the structure of our defended model and (c) by devising a novel decision-based attack that seeks to minimize the number of perturbed pixels (L0). The results suggest that our approach yields state-of-the-art robustness on MNIST against L0, L2 and L∞ perturbations and we demonstrate that most adversarial examples are strongly perturbed towards the perceptual boundary between the original and the adversarial class. © 7th International Conference on Learning Representations, ICLR 2019. All Rights Reserved.",,Large dataset; Semantics; Analysis by synthesis; Data distribution; Decision-based; Gradient based; Input perturbation; Neural network model; Robust classification; State of the art; Deep neural networks,,,,,"Athalye, A., Carlini, N., (2018) On the Robustness of the Cvpr 2018 White-Box Adversarial Example Defenses, , arXiv preprint; Athalye, A., Carlini, N., Wagner, D., (2018) Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples, , arXiv preprint; Bengio, Y., Léonard, N., Courville, A., (2013) Estimating or Propagating Gradients through Stochastic Neurons for Conditional Computation, , arXiv preprint; Brendel, W., Bethge, M., (2017) Comment on “Biologically Inspired Protection of Deep Networks from Adversarial Attacks, , arXiv preprint; Brendel, W., Rauber, J., Bethge, M., Decision-based adversarial attacks: Reliable attacks against black-box machine learning models (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=SyZI0GWCZ; Bubeck, S., Price, E., Razenshteyn, I., (2018) Adversarial Examples from Computational Constraints, , arXiv preprint; Buckman, J., Roy, A., Raffel, C., Goodfellow, I., Thermometer encoding: One hot way to resist adversarial examples (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=S18Su-CW; Carlini, N., Wagner, D., (2017) Magnet and"" Efficient Defenses against Adversarial Attacks"" Are Not Robust to Adversarial Examples, , arXiv preprint; Clevert, D.-A., Unterthiner, T., Hochreiter, S., (2015) Fast and Accurate Deep Network Learning by Exponential Linear Units (Elus), , arXiv preprint; Dhillon, G.S., Azizzadenesheli, K., Bernstein, J.D., Kossaifi, J., Khanna, A., Lipton, Z.C., Anandkumar, A., Stochastic activation pruning for robust adversarial defense (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=H1uR4GZRZ; Dong, Y., Liao, F., Pang, T., Su, H., Hu, X., Li, J., Zhu, J., (2017) Boosting Adversarial Attacks with Momentum, , arxiv preprint. arXiv preprint; George, D., Lehrach, W., Kansky, K., Lázaro-Gredilla, M., Laan, C., Marthi, B., Lou, X., Scott Phoenix, D., A generative vision model that trains with high data efficiency and breaks text-based captchas (2017) Science, 358 (6368). , http://science.sciencemag.org/content/358/6368/eaag2612; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint; Guo, C., Rana, M., Cisse, M., Van Der Maaten, L., Countering adversarial images using input transformations (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=SyJ7ClWCb; Hein, M., Andriushchenko, M., Formal guarantees on the robustness of a classifier against adversarial manipulation (2017) Advances in Neural Information Processing Systems, 30, pp. 2266-2276. , Curran Associates, Inc; Ilyas, A., Jalal, A., Asteri, E., Daskalakis, C., Dimakis, A.G., (2017) The Robust Manifold Defense: Adversarial Training Using Generative Models, , arXiv preprint; Ilyas, A., Engstrom, L., Athalye, A., Lin, J., (2018) Black-Box Adversarial Attacks with Limited Queries and Information, , arXiv preprint; Ioffe, S., Szegedy, C., (2015) Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift, , arXiv preprint; Kabilan, V.M., Morris, B., Nguyen, A., (2018) Vectordefense: Vectorization as a Defense to Adversarial Examples, , arXiv preprint; Kingma, D.P., Ba, J., (2014) Adam: A Method for Stochastic Optimization, , arXiv preprint; Kingma, D.P., Welling, M., (2013) Auto-Encoding Variational Bayes, , arXiv preprint; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint; Liao, F., Liang, M., Dong, Y., Pang, T., Zhu, J., Hu, X., (2017) Defense against Adversarial Attacks Using High-Level Representation Guided Denoiser, , arXiv preprint; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=rJzIBfZAb; Meng, D., Chen, H., Magnet: A two-pronged defense against adversarial examples (2017) Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pp. 135-147; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , June; Prakash, A., Moran, N., Garber, S., DiLillo, A., Storer, J., (2018) Deflecting Adversarial Attacks with Pixel Deflection, , arXiv preprint; Raghunathan, A., Steinhardt, J., Liang, P., Certified defenses against adversarial examples (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=Bys4ob-Rb; Rauber, J., Brendel, W., Bethge, M., (2017) Foolbox: A Python Toolbox to Benchmark the Robustness of Machine Learning Models, , http://arxiv.org/abs/1707.04131, arXiv preprint; Samangouei, P., Kabkab, M., Chellappa, R., Defense-Gan: Protecting classifiers against adversarial attacks using generative models (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=BkJ3ibb0-; Schmidt, L., Santurkar, S., Tsipras, D., Talwar, K., Madry, A., (2018) Adversarially Robust Generalization Requires More Data, , http://arxiv.org/abs/1804.11285, CoRR, abs/1804.11285; Schölkopf, B., (2017) Causal Learning, , https://icml.cc/Conferences/2017/Schedule?showEvent=931, Thirty-fourth International Conference on Machine Learning; Shen, S., Jin, G., Gao, K., Zhang, Y., (2017) Ape-Gan: Adversarial Perturbation Elimination with Gan, , arXiv preprint; Song, Y., Kim, T., Nowozin, S., Ermon, S., Kushman, N., PixelDefend: Leveraging generative models to understand and defend against adversarial examples (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=rJUYGxbCW; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint; Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses, , arXiv preprint; Tsipras, D., Santurkar, S., Engstrom, L., Turner, A., Madry, A., (2018) There is No Free Lunch in Adversarial Robustness (but There Are Unexpected Benefits), , arXiv preprint; Uesato, J., O'Donoghue, B., Kohli, P., Van Den Oord, A., Adversarial risk and the dangers of evaluating against weak attacks (2018) Proceedings of the 35th International Conference on Machine Learning, , http://proceedings.mlr.press/v80/uesato18a.html; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., Mitigating adversarial effects through randomization (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=Sk9yuql0Z; Zheng, T., Chen, C., Ren, K., (2018) Distributionally Adversarial Attack, , arXiv preprint",,,,"International Conference on Learning Representations, ICLR","7th International Conference on Learning Representations, ICLR 2019",6 May 2019 through 9 May 2019,,149936,,,,,English,"Int. Conf. Learn. Represent., ICLR",Conference Paper,Final,,Scopus,2-s2.0-85083953010
"Zügner D., Günnemann S.",57188995298;35242528700;,Adversarial attacks on graph neural networks via meta learning,2019,"7th International Conference on Learning Representations, ICLR 2019",,,,,,,89,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083950290&partnerID=40&md5=4a963cbdc0747de26316af0093ca9ad3,"Technical University of Munich, Germany","Zügner, D., Technical University of Munich, Germany; Günnemann, S., Technical University of Munich, Germany","Deep learning models for graphs have advanced the state of the art on many tasks. Despite their recent success, little is known about their robustness. We investigate training time attacks on graph neural networks for node classification that perturb the discrete graph structure. Our core principle is to use meta-gradients to solve the bilevel problem underlying training-time attacks, essentially treating the graph as a hyperparameter to optimize. Our experiments show that small graph perturbations consistently lead to a strong decrease in performance for graph convolutional networks, and even transfer to unsupervised embeddings. Remarkably, the perturbations created by our algorithm can misguide the graph neural networks such that they perform worse than a simple baseline that ignores all relational information. Our attacks do not assume any knowledge about or access to the target classifiers. © 7th International Conference on Learning Representations, ICLR 2019. All Rights Reserved.",,Bi-level problems; Convolutional networks; Graph neural networks; Graph structures; Hyper-parameter; Learning models; State of the art; Training time; Deep learning,,,,,"Adamic, L.A., Glance, N., The political blogosphere and the 2004 US election: Divided they blog (2005) International Workshop on Link Discovery, pp. 36-43; Agostinelli, F., Hoffman, M., Sadowski, P., Baldi, P., (2014) Learning Activation Functions to Improve Deep Neural Networks, , arXiv preprint; Battaglia, P.W., Hamrick, J.B., Bapst, V., Sanchez-Gonzalez, A., Zambaldi, V., Malinowski, M., Tacchetti, A., Faulkner, R., (2018) Relational Inductive Biases, Deep Learning, and Graph Networks, , arXiv preprint; Bengio, S., Bengio, Y., Cloutier, J., Gecsei, J., On the optimization of a synaptic learning rule (1992) Preprints Conf. Optimality in Artificial and Biological Neural Networks, pp. 6-8. , Univ. of Texas; Bengio, Y., Gradient-based optimization of hyperparameters (2000) Neural Computation, 12 (8), pp. 1889-1900; Bojchevski, A., Günnemann, S., Deep Gaussian embedding of graphs: Unsupervised inductive learning via ranking (2018) ICLR; Bojchevski, A., Günnemann, S., (2018) Adversarial Attacks on Node Embeddings, , arXiv preprint; Bojchevski, A., Günnemann, S., Bayesian robust attributed graph clustering: Joint learning of partial anomalies and group structure (2018) AAAI, pp. 2738-2745; Bojchevski, A., Shchur, O., Zügner, D., Günnemann, S., NetGan: Generating graphs via random walks (2018) ICML; Chapelle, O., Schölkopf, B., Zien, A., Semi-supervised learning (2006) Adaptive Computation and Machine Learning Series, , The MIT Press; Chen, Y., Nadji, Y., Kountouras, A., Monrose, F., Perdisci, R., Antonakakis, M., Vasiloglou, N., (2017) Practical Attacks against Graph-Based Clustering, , arXiv preprint; Dai, H., Li, H., Tian, T., Huang, X., Wang, L., Zhu, J., Song, L., Adversarial attack on graph structured data (2018) ICML; Finn, C., Abbeel, P., Levine, S., Model-agnostic meta-learning for fast adaptation of deep networks (2017) ICML; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR; Kipf, T.N., Welling, M., Semi-supervised classification with graph convolutional networks (2017) ICLR; Klicpera, J., Bojchevski, A., Günnemann, S., Predict then propagate: Graph neural networks meet personalized pagerank (2019) International Conference on Learning Representations (ICLR); London, B., Getoor, L., Collective classification of network data (2014) Data Classification: Algorithms and Applications, p. 399; McCallum, A.K., Nigam, K., Rennie, J., Seymore, K., Automating the construction of internet portals with machine learning (2000) Information Retrieval, 3 (2), pp. 127-163; Mei, S., Zhu, X., Using machine teaching to identify optimal training-set attacks on machine learners (2015) AAAI, pp. 2871-2877; Monti, F., Boscaini, D., Masci, J., Rodola, E., Svoboda, J., Bronstein, M.M., Geometric deep learning on graphs and manifolds using mixture model cnns (2017) CVPR, 1, p. 3; Muñoz-González, L., Biggio, B., Demontis, A., Paudice, A., Wongrassamee, V., Lupu, E.C., Roli, F., Towards poisoning of deep learning algorithms with back-gradient optimization (2017) 10th ACM Workshop on Artificial Intelligence and Security, pp. 27-38; Naik, D.K., Mammone, R.J., Meta-neural networks that learn by learning (1992) IJCNN, pp. 437-442; Nichol, A., Schulman, J., (2018) On First-Order Meta-Learning Algorithms, , arXiv preprint; Perozzi, B., Al-Rfou, R., Skiena, S., DeepWalk: Online learning of social representations (2014) SIGKDD, pp. 701-710; Pham, T., Tran, T., Phung, D.Q., Venkatesh, S., Column networks for collective classification (2017) AAAI, pp. 2485-2491; Schmidhuber, J., Learning to control fast-weight memories: An alternative to dynamic recurrent networks (1992) Neural Computation, 4 (1), pp. 131-139; Sen, P., Namata, G., Bilgic, M., Getoor, L., Galligher, B., Eliassi-Rad, T., Collective classification in network data (2008) AI Magazine, 29 (3), p. 93; Szegedy, C., Zaremba, W., Sutskever, I., Inc, G., Bruna, J., Erhan, D., Inc, G., Fergus, R., Intriguing properties of neural networks (2014) ICLR; Thrun, S., Pratt, L., Learning to learn: Introduction and overview (1998) Learning to Learn, pp. 3-17. , Springer; Torkamani, M.A., Lowd, D., Convex adversarial collective classification (2013) ICML, pp. 642-650; Zügner, D., Akbarnejad, A., Günnemann, S., Adversarial attacks on neural networks for graph data (2018) SIGKDD, pp. 2847-2856",,,,"International Conference on Learning Representations, ICLR","7th International Conference on Learning Representations, ICLR 2019",6 May 2019 through 9 May 2019,,149936,,,,,English,"Int. Conf. Learn. Represent., ICLR",Conference Paper,Final,,Scopus,2-s2.0-85083950290
"Gil Y., Chai Y., Gorodissky O., Berant J.",57216969739;57216947227;57216971105;52163188700;,White-to-black: Efficient distillation of black-box adversarial attacks,2019,NAACL HLT 2019 - 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies - Proceedings of the Conference,1,,,1373,1379,,5,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083331960&partnerID=40&md5=957bf1df76478a5a2233576df167bb33,"School of Electrical Engineering, Tel-Aviv University, Israel; School of Computer Science, Tel-Aviv University, Israel; Allen Institute for Artificial Intelligence, United States","Gil, Y., School of Electrical Engineering, Tel-Aviv University, Israel; Chai, Y., School of Computer Science, Tel-Aviv University, Israel; Gorodissky, O., School of Electrical Engineering, Tel-Aviv University, Israel; Berant, J., School of Computer Science, Tel-Aviv University, Israel, Allen Institute for Artificial Intelligence, United States","Adversarial examples are important for understanding the behavior of neural models, and can improve their robustness through adversarial training. Recent work in natural language processing generated adversarial examples by assuming white-box access to the attacked model, and optimizing the input directly against it (Ebrahimi et al., 2018). In this work, we show that the knowledge implicit in the optimization procedure can be distilled into another more efficient neural network. We train a model to emulate the behavior of a white-box attack and show that it generalizes well across examples. Moreover, it reduces adversarial example generation time by 19x-39x. We also show that our approach transfers to a black-box setting, by attacking The Google Perspective API and exposing its vulnerability. Our attack flips the API-predicted label in 42% of the generated examples, while humans maintain high-accuracy in predicting the gold label. © 2019 Association for Computational Linguistics",,Computational linguistics; Distillation; Black boxes; Generation time; High-accuracy; NAtural language processing; Neural models; Optimization procedures; White box; Natural language processing systems,,,,,"Bahdanau, D., Cho, K., Bengio, Y., Neural machine translation by jointly learning to align and translate (2015) International Conference on Learning Representations (ICLR); Belinkov, Y., Bisk, Y., (2017) Synthetic and Natural Noise Both Break Neural Machine Translation, , arXiv preprint; Cho, K., van Merriënboer, B., Bahdanau, D., Bengio, Y., (2014) On the Properties of Neural Machine Translation: Encoder-Decoder Approaches, , arXiv preprint; Ebrahimi, J., Rao, A., Lowd, D., Dou, D., Hotflip: White-box adversarial examples for text classification (2018) Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), 2, pp. 31-36; Feng, S., Wallace, E., Grissom, A., II, Iyyer, M., Rodriguez, P., Boyd-Graber, J., (2018) Pathologies of Neural Models Make Interpretations Difficult; Gao, J., Lanchantin, J., Soffa, M.L., Qi, Y., Black-box generation of adversarial text sequences to evade deep learning classifiers (2018) 2018 IEEE Security and Privacy Workshops (SPW); Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , CoRR, abs/1412.6572; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9 (8), pp. 1735-1780; Hosseini, H., Kannan, S., Zhang, B., Poovendran, R., Deceiving google's perspective api built for detecting toxic comments (2017) The Bright and Dark Sides of Computer Vision: Challenges and Opportunities for Privacy and Security Workshop@CVPR; Iyyer, M., Wieting, J., Gimpel, K., Zettlemoyer, L., Adversarial example generation with syntactically controlled paraphrase networks (2018) NAACL; Jia, R., Liang, P., Adversarial examples for evaluating reading comprehension systems (2017) EMNLP; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2016) ICLR Workshop; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) ICLR; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-Box Attacks Using Adversarial Samples, , arXiv preprint; Ribeiro, M.T., Singh, S., Guestrin, C., Semantically equivalent adversarial rules for debugging nlp models (2018) Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 1, pp. 856-865; Rodriguez, N., Rojas-Galeano, S., (2018) Shielding Google's Language Toxicity Model against Adversarial Attacks; Wallace, E., Rodriguez, P., Feng, S., Boyd-Graber, J., Trick me if you can: Adversarial writing of trivia challenge questions (2018) ACL Student Research Workshop; Weber, N., Shekhar, L., Balasubramanian, N., (2018) The Fine Line between Linguistic Generalization and Failure in Seq2seq-Attention Models, , arXiv preprint",,,Amazon;ASAPP;Bloomberg Engineering;et al.;facebook;Google,Association for Computational Linguistics (ACL),"2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019",2 June 2019 through 7 June 2019,,159851,,9.78E+12,,,English,NAACL HLT - Conf. N. Am. Chapter Assoc. Comput. Linguistics: Hum. Lang. Technol. - Proc. Conf.,Conference Paper,Final,,Scopus,2-s2.0-85083331960
"Wei X., Zhu J., Yuan S., Su H.",55669197900;56734692500;57205187114;37017428500;,Sparse adversarial perturbations for videos,2019,"33rd AAAI Conference on Artificial Intelligence, AAAI 2019, 31st Innovative Applications of Artificial Intelligence Conference, IAAI 2019 and the 9th AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2019",,,,8973,8980,,15,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081884797&partnerID=40&md5=c05cc13e8e869f0c8d137bc4078ca69e,"Dept. of Comp. Sci. and Tech., Institute for Artificial Intelligence, State Key Lab for Intell. Tech. and Sys., THBI Lab, Tsinghua University, Beijing, China","Wei, X., Dept. of Comp. Sci. and Tech., Institute for Artificial Intelligence, State Key Lab for Intell. Tech. and Sys., THBI Lab, Tsinghua University, Beijing, China; Zhu, J., Dept. of Comp. Sci. and Tech., Institute for Artificial Intelligence, State Key Lab for Intell. Tech. and Sys., THBI Lab, Tsinghua University, Beijing, China; Yuan, S., Dept. of Comp. Sci. and Tech., Institute for Artificial Intelligence, State Key Lab for Intell. Tech. and Sys., THBI Lab, Tsinghua University, Beijing, China; Su, H., Dept. of Comp. Sci. and Tech., Institute for Artificial Intelligence, State Key Lab for Intell. Tech. and Sys., THBI Lab, Tsinghua University, Beijing, China","Although adversarial samples of deep neural networks (DNNs) have been intensively studied on static images, their extensions in videos are never explored. Compared with images, attacking a video needs to consider not only spatial cues but also temporal cues. Moreover, to improve the imperceptibility as well as reduce the computation cost, perturbations should be added on as few frames as possible, i.e., adversarial perturbations are temporally sparse. This further motivates the propagation of perturbations, which denotes that perturbations added on the current frame can transfer to the next frames via their temporal interactions. Thus, no (or few) extra perturbations are needed for these frames to misclassify them. To this end, we propose the first white-box video attack method, which utilizes an l2,1-norm based optimization algorithm to compute the sparse adversarial perturbations for videos. We choose the action recognition as the targeted task, and networks with a CNN+RNN architecture as threat models to verify our method. Thanks to the propagation, we can compute perturbations on a shortened version video, and then adapt them to the long version video to fool DNNs. Experimental results on the UCF101 dataset demonstrate that even only one frame in a video is perturbed, the fooling rate can still reach 59.7%. © 2019, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,Backpropagation; Deep neural networks; Action recognition; Attack methods; Computation costs; Current frame; Optimization algorithms; Static images; Temporal cues; Threat models; Recurrent neural networks,,,,,"Baluja, S., Fischer, I., (2017) Adversarial transformation networks: Learning to generate adversarial examples, , arXiv preprint arXiv:1703.09387; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy (SP), pp. 39-57; Donahue, J., Anne Hendricks, L., Guadarrama, S., Rohrbach, M., Venugopalan, S., Saenko, K., Darrell, T., Long-term recurrent convolutional networks for visual recognition and description (2017) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2625-2634; Dong, C., Loy, C. C., He, K., Tang, X., Learning a deep convolutional network for image super-resolution (2014) European Conference on Computer Vision, pp. 184-199; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2018) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 9185-9193; Goodfellow, I. J., Shlens, J., Szegedy, C., (2014) Explaining and harnessing adversarial examples, , arXiv preprint arXiv:1412.6572; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770-778; Hosseini, H., Xiao, B., Poovendran, R., Deceiving google's cloud video intelligence api built for summarizing videos (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, pp. 1-5; Karpathy, A., Toderici, G., Shetty, S., Leung, T., Sukthankar, R., Fei-Fei, L., Large-scale video classification with convolutional neural networks (2014) Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, pp. 1725-1732; Kingma, D., Ba, J., (2014) Adam: A method for stochastic optimization, , arXiv preprint arXiv:1412.6980; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial examples in the physical world, , arXiv preprint arXiv:1607.02533; Liu, Y., Chen, X., Liu, C., Song, D., (2016) Delving into transferable adversarial examples and black-box attacks, , arXiv preprint arXiv:1611.02770; Ma, K., Xu, Q., Cao, X., Robust ordinal embedding from contaminated relative comparisons (2019) AAAI Conference on Artificial Intelligence; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., (2016) Universal adversarial perturbations, , arXiv preprint arXiv:1610.08401; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: a simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 427-436; Poppe, R., A survey on vision-based human action recognition (2010) Image and vision computing, 28 (6), pp. 976-990; Simonyan, K., Zisserman, A., Two-stream convolutional networks for action recognition in videos (2014) Advances in neural information processing systems, pp. 568-576; Soomro, K., Zamir, A. R., Shah, M., (2012) Ucf101: A dataset of 101 human actions classes from videos in the wild, , arXiv preprint arXiv:1212.0402; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing properties of neural networks, , arXiv preprint arXiv:1312.6199; Wang, N., Yeung, D.-Y., Learning a deep compact image representation for visual tracking (2013) Advances in neural information processing systems, pp. 809-817; Wang, L., Xiong, Y., Wang, Z., Qiao, Y., Lin, D., Tang, X., Van Gool, L., Temporal segment networks: Towards good practices for deep action recognition (2016) European Conference on Computer Vision, pp. 20-36. , Springer; Wright, J., Yang, A. Y., Ganesh, A., Sastry, S. S., Ma, Y., Robust face recognition via sparse representation (2009) IEEE transactions on pattern analysis and machine intelligence, 31 (2), pp. 210-227; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., Adversarial examples for semantic segmentation and object detection (2017) IEEE International Conference on Computer Vision; Yang, J., Wright, J., Huang, T. S., Ma, Y., Image super-resolution via sparse representation (2010) IEEE transactions on image processing, 19 (11), pp. 2861-2873; Yue-Hei Ng, J., Hausknecht, M., Vijayanarasimhan, S., Vinyals, O., Monga, R., Toderici, G., Beyond short snippets: Deep networks for video classification (2015) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 4694-4702","Zhu, J.; Dept. of Comp. Sci. and Tech., China; 电子邮件: dcszj@mail.tsinghua.edu.cn",,Association for the Advancement of Artificial Intelligence,AAAI Press,"33rd AAAI Conference on Artificial Intelligence, AAAI 2019, 31st Annual Conference on Innovative Applications of Artificial Intelligence, IAAI 2019 and the 9th AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2019",27 January 2019 through 1 February 2019,,160302,,9.78E+12,,,English,"AAAI Conf. Artif. Intell., AAAI, Innov. Appl. Artif. .igence Conf., IAAI AAAI Symp. Educ. Adv. Artif. Intell., EAAI",Conference Paper,Final,,Scopus,2-s2.0-85081884797
"Zhang J., Zhang Z.",57196388351;57214221681;,LET-Attack: Latent Encodings of Normal-Data Manifold Transferring to Adversarial Examples,2019,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),11933 LNCS,,,136,150,,,10.1007/978-3-030-34637-9_10,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078423143&doi=10.1007%2f978-3-030-34637-9_10&partnerID=40&md5=74427bbcf4665022eebef81ce9f61a67,"Nanjing University of Posts and Telecommunications, Nanjing, China","Zhang, J., Nanjing University of Posts and Telecommunications, Nanjing, China; Zhang, Z., Nanjing University of Posts and Telecommunications, Nanjing, China","Recent studies have highlighted the vulnerability and low robustness of deep learning model against adversarial examples. This issue limits their deployability on ubiquitous applications requiring a high level of security such as driverless system, unmanned aerial vehicle and intrusion detection. In this paper, we propose latent encodings transferring attack (LET-attack) to generate target natural adversarial examples to fool well-trained classifiers. In order to perturb in latent space, we train WGAN-variants on various datasets to achieve feature extraction, image reconstruction and image discrimination against counterfeit with good performance. Thanks to our two-stage procedure of mapping transformation, the adversary performs precise and semantic perturbations on source data referring to target data in latent space. By using the critic in WGAN-variant and the well-trained classifier, the adversary crafts more verisimilar and effective adversarial examples. As shown in the experimental results on MNIST, FashionMNIST, CIFAR-10 and LSUN, LET-attack can yield a distinct set of adversarial examples with partly data manifold targeted transfer and attains similar attack performance against state-of-the-art models in different attack scenarios. What is more, we evaluate LET-attack on the characteristic of transferability in different classifiers on MNIST and CIFAR-10 respectively, and find that the adversarial examples are easy to transfer with high confidence. © Springer Nature Switzerland AG 2019.",Adversarial example; Black-box attack; Mapping transformation; Transferability,Aircraft detection; Antennas; Conformal mapping; Deep learning; Encoding (symbols); Image reconstruction; Intrusion detection; Semantics; Adversarial example; Black boxes; Driverless systems; Image discrimination; Mapping transformation; Transferability; Two stage procedure; Ubiquitous application; Metadata,,,,,"Szegedy, C., Zaremba, W., Sutskever, I., Intriguing properties of neural networks (2013) Comput. Sci.; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2014) Comput. Sci.; Tramèr, F., Papernot, N., Goodfellow, I., (2017) The Space of Transferable Adversarial Examples; Nguyen, A., Yosinski, J., Clune, J., (2014) Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images; Fawzi, A., Fawzi, O., Frossard, P., Analysis of classifiers’ robustness to adversarial perturbations (2015) Mach. Learn., 107 (3), pp. 481-508; Rauber, J., Brendel, W., Bethge, M., (2017) Foolbox: A Python Toolbox to Benchmark the Robustness of Machine Learning Models; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World; Evtimov, I., Eykholt, K., Fernandes, E., (2018) Robust Physical-World Attacks on Deep Learning Models; Rozsa, A., Günther, M., Rudd, E.M., Facial attributes: Accuracy and adversarial robustness (2018) Pattern Recognit. Lett.; Ross, A.S., Doshi-Velez, F., (2017) Improving the Adversarial Robustness and Interpretability of Deep Neural Networks by Regularizing Their Input Gradients; Sinha, A., Namkoong, H., Duchi, J., (2017) Certifying Some Distributional Robustness with Principled Adversarial Training; Tramèr, F., Kurakin, A., Papernot, N., (2017) Ensemble Adversarial Training: Attacks and Defenses; Ma, X., Li, B., Wang, Y., (2018) Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality; Papernot, N., McDaniel, P., (2016) On the Effectiveness of Defensive Distillation; Metzen, J.H., Genewein, T., Fischer, V., (2017) On Detecting Adversarial Perturbations; Meng, D., Chen, H., (2017) Magnet: A Two-Pronged Defense against Adversarial Examples; Zhao, Z., Dua, D., Singh, S., (2017) Generating Natural Adversarial Examples; Arjovsky, M., Chintala, S., Bottou, L., (2017) Wasserstein GAN; Gulrajani, I., Ahmed, F., Arjovsky, M., (2017) Improved Training of Wasserstein Gans; Papernot, N., McDaniel, P., Jha, S., (2015) The Limitations of Deep Learning in Adversarial Settings; Carlini, N., Wagner, D., (2016) Towards Evaluating the Robustness of Neural Networks; Narodytska, N., Kasiviswanathan, S.P., (2016) Simple Black-Box Adversarial Perturbations for Deep Networks; Hayes, J., Danezis, G., (2017) Machine Learning as an Adversarial Service: Learning Black-Box Adversarial Examples; Papernot, N., McDaniel, P., Goodfellow, I., (2017) Practical Black-Box Attacks against Machine Learning; Brendel, W., Rauber, J., Bethge, M., (2017) Decision-Based Adversarial Attacks: Reliable Attacks against Black-Box Machine Learning Models; Baluja, S., Fischer, I., (2017) Adversarial Transformation Networks: Learning to Generate Adversarial Examples; Ebrahimi, J., Lowd, D., Dou, D., (2018) On Adversarial Examples for Character-Level Neural Machine Translation; Carlini, N., Wagner, D., (2016) Defensive Distillation is Not Robust to Adversarial Examples","Zhang, J.; Nanjing University of Posts and TelecommunicationsChina; 电子邮件: zhangjie@njupt.edu.cn",Liu F.Xu J.Xu S.Yung M.,,Springer,"2nd International Conference on Science of Cyber Security, SciSec 2019",9 August 2019 through 11 August 2019,,235729,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,,Scopus,2-s2.0-85078423143
"Pang T., Xu K., Du C., Chen N., Zhu J.",57204799576;56587223300;57194774618;34879572100;56734692500;,Improving adversarial robustness via promoting ensemble diversity,2019,"36th International Conference on Machine Learning, ICML 2019",2019-June,,,8759,8771,,24,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078299436&partnerID=40&md5=eedae9aff246a7fa474583e930543afd,"Department of Computer Science and Technology, Institute for AI, BNRist Center, THBI Lab, Tsinghua-Fuzhou Institute for Data Technology, Tsinghua University, Beijing, China","Pang, T., Department of Computer Science and Technology, Institute for AI, BNRist Center, THBI Lab, Tsinghua-Fuzhou Institute for Data Technology, Tsinghua University, Beijing, China; Xu, K., Department of Computer Science and Technology, Institute for AI, BNRist Center, THBI Lab, Tsinghua-Fuzhou Institute for Data Technology, Tsinghua University, Beijing, China; Du, C., Department of Computer Science and Technology, Institute for AI, BNRist Center, THBI Lab, Tsinghua-Fuzhou Institute for Data Technology, Tsinghua University, Beijing, China; Chen, N., Department of Computer Science and Technology, Institute for AI, BNRist Center, THBI Lab, Tsinghua-Fuzhou Institute for Data Technology, Tsinghua University, Beijing, China; Zhu, J., Department of Computer Science and Technology, Institute for AI, BNRist Center, THBI Lab, Tsinghua-Fuzhou Institute for Data Technology, Tsinghua University, Beijing, China","Though deep neural networks have achieved significant progress on various tasks, often enhanced by model ensemble, existing high-performance models can be vulnerable to adversarial attacks. Many efforts have been devoted to enhancing the robustness of individual networks and then constructing a straightforward ensemble, e.g., by directly averaging the outputs, which ignores the interaction among networks. This paper presents a new method that explores the interaction among individual networks to improve robustness for ensemble models. Technically, we define a new notion of ensemble diversity in the adversarial setting as the diversity among non-maximal predictions of individual members, and present an adaptive diversity promoting (ADP) regularizer to encourage the diversity, which leads to globally better robustness for the ensemble by making adversarial examples difficult to transfer among individual members. Our method is computationally efficient and compatible with the defense methods acting on individual networks. Empirical results on various datasets verify that our method can improve adversarial robustness while maintaining state-of-the-art accuracy on normal examples. The authors would like to thank Chongxuan Li for helpful comments. This work was supported by the National Key Research and Development Program of China (No. 2017YFA0700904), NSFC Projects (Nos. 61620106010, 61621136008,61673241,61571261), Beijing NSF Project (No. LI72037), DITD Program JCKY2017204B064, Tian-gong Institute for Intelligent Computing, Beijing Academy of Artificial Intelligence (BAAI), NVIDIA NVAIL Program, and the projects from Siemens and Intel. © 2019 International Machine Learning Society (IMLS).",,Intelligent computing; Machine learning; Adaptive diversity; Computationally efficient; Ensemble models; Individual network; Model ensembles; Performance Model; Research and development programs; State of the art; Deep neural networks,,,,,"Athalye, A., Carlini, N., Wagner, D., Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples (2018) International Conference on Machine Learning (ICML); Bernstein, D.S., (2005) Matrix Mathematics: Theory, Facts, and Formulas with Application to Linear Systems Theory, 41. , Princeton university press Princeton; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) ACM Workshop on Artificial Intelligence and Security; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (S&P), pp. 39-57. , IEEE; Chen, P.-Y., Sharma, Y., Zhang, H., Yi, J., Hsieh, C.-J., Ead: Elastic-net attacks to deep neural networks via adversarial examples (2018) AAAI Conference on Artificial Intelligence (AAAI); Dauphin, Y.N., Pascanu, R., Gulcehre, C., Cho, K., Gan-Guli, S., Bengio, Y., Identifying and attacking the saddle point problem in high-dimensional non-convex optimization (2014) Advances in Neural Information Processing Systems (NeurIPS), pp. 2933-2941; Dietterich, T.G., Ensemble methods in machine learning (2000) International Workshop on Multiple Classifier Systems, pp. 1-15. , Springer; Dong, Y., Liao, E., Pang, T., Su, H., Hu, X., Li, J., Zhu, J., Boosting adversarial attacks with momentum (2018) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Friedman, J., Hastie, T., Tibshirani, R., (2001) The Elements of Statistical Learning, 1. , Springer series in statistics New York, NY, USA; Goodfellow, I., Bengio, Y., Courville, A., Bengio, Y., (2016) Deep Learning, 1. , MIT press Cambridge; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations (ICLR); Graves, A., Jaitly, N., Towards end-to-end speech recognition with recurrent neural networks (2014) International Conference on Machine Learning (ICML), pp. 1764-1772; Guo, C., Pleiss, G., Sun, Y., Weinberger, K.Q., On calibration of modern neural networks (2017) International Conference on Machine Learning (ICML); He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 770-778; Hornik, K., Stinchcombe, M., White, H., Multilayer feedforward networks are universal approximators (1989) Neural Networks, 2 (5), pp. 359-366; Islam, M.M., Yao, X., Murase, K., A constructive algorithm for training cooperative neural network ensembles (2003) IEEE Transactions on Neural Networks, 14 (4), pp. 820-834; Kannan, H., Kurakin, A., Goodfellow, I., Adversarial logit pairing (2018) Advances in Neural Information Processing Systems (NeurIPS); Kingma, D.P., Ba, J., (2014) Adam: A Method for Stochastic Optimization.; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images., , Technical report; Krogh, A., Vedelsby, J., Neural network ensembles, cross validation, and active learning (1995) Advances in Neural Information Processing Systems (NeurIPS), pp. 231-238; Kulcsza, A., Taskar, B., Detcrminantal point processes for machine learning (2012) Foundations and Trends® in Machine Learning, 5 (2-3), pp. 123-286; Kuncheva, L.I., Whitaker, C.J., Measures of diversity in classifier ensembles and their relationship with the ensemble accuracy (2003) Machine Learning, 51 (2), pp. 181-207; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2017) International Conference on Learning Representations (ICLR) Workshop; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2017) International Conference on Learning Representations (ICLR); Kurakin, A., Boneh, D., Tramr, E., Goodfellow, I., Papernot, N., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2018) International Conference on Learning Representations (ICLR); Kurakin, A., Goodfellow, I., Bengio, S., Dong, Y., Liao, R., Liang, M., Pang, T., Xie, C., (2018) Adversarial Attacks and Defences Competition.; Kwok, J.T., Adams, R.P., Priors for diversity in generative latent variable models (2012) Advances in Neural Information Processing Systems (NeurIPS), pp. 2996-3004; LeCun, Y., Bottou, L., Bengio, Y., Haffncr, P., Gradient-based learning applied to document recognition (1998) Proceedings of the IEEE, 86 (11), pp. 2278-2324; Li, Y., Yosinski, J., Clune, J., Lipson, H., Hopcroft, J.E., Convergent learning: Do different neural networks learn the same representations? (2016) International Conference on Learning Representations (ICLR); Liao, E., Liang, M., Dong, Y., Pang, T., Zhu, J., Hu, X., Defense against adversarial attacks using high-level representation guided denoiser (2018) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Liu, Y., Yao, X., Ensemble learning via negative correlation (1999) Neural Networks, 12 (10), pp. 1399-1404; Liu, Y., Yao, X., Simultaneous training of negatively correlated neural networks in an ensemble (1999) IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics), 29 (6), pp. 716-725; Maaten, L.V.D., Hinton, G., Visualizing data using t-sne (2008) Journal of Machine Learning Research (JMLR), 9, pp. 2579-2605. , (Nov); Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) International Conference on Learning Representations (ICLR); Mariet, Z., Sra, S., Diversity networks (2016) International Conference on Learning Representations (ICLR); Pang, T., Du, C., Dong, Y., Zhu, J., Towards robust detection of adversarial examples (2018) Advances in Neural Information Processing Systems (NeurIPS); Pang, T., Du, C., Zhu, J., Max-mahalanobis linear discriminant analysis networks (2018) International Conference on Machine Learning (ICML); Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., (2016) Practical Black-box Attacks Against Deep Learning Systems Using Adversarial Examples.; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387. , IEEE; Rumelhart, D.E., Hinton, G.E., Williams, R.J., Learning representations by back-propagating errors (1986) Nature, 323 (6088), p. 533; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Bernstein, M., Imagenet large scale visual recognition challenge (2015) International Journal of Computer Vision (IJCV), 115 (3), pp. 211-252; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wo-Jna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2818-2826; Tsymbal, A., Pechenizkiy, M., Cunningham, P., Diversity in search strategies for ensemble feature selection (2005) Information Fusion, 6 (1), pp. 83-98",,,,International Machine Learning Society (IMLS),"36th International Conference on Machine Learning, ICML 2019",9 June 2019 through 15 June 2019,,156104,,9.78E+12,,,English,"Int. Conf. Mach. Learn., ICML",Conference Paper,Final,,Scopus,2-s2.0-85078299436
"Cai J., Wang B., Wang X., Jin B.",57212505881;57211230278;55000633400;57219319257;,Accelerate Black-Box Attack with White-Box Prior Knowledge,2019,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),11936 LNCS,,,394,405,,,10.1007/978-3-030-36204-1_33,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076928198&doi=10.1007%2f978-3-030-36204-1_33&partnerID=40&md5=5860935065de323195b788e236b5fe5c,"Shanghai Key Lab for Trustworthy Computing, School of Computer Science and Technology, East China Normal University, Shanghai, 200062, China; School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China","Cai, J., Shanghai Key Lab for Trustworthy Computing, School of Computer Science and Technology, East China Normal University, Shanghai, 200062, China; Wang, B., School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China; Wang, X., Shanghai Key Lab for Trustworthy Computing, School of Computer Science and Technology, East China Normal University, Shanghai, 200062, China; Jin, B., Shanghai Key Lab for Trustworthy Computing, School of Computer Science and Technology, East China Normal University, Shanghai, 200062, China","We propose an efficient adversarial attack method in the black-box setting. Our Multi-model Efficient Query Attack (MEQA) method takes advantage of the prior knowledge on different models’ relationship to guide the construction of black-box adversarial instances. The MEQA method employs several gradients from different white-box attack models and further the “best” one is selected to replace the gradient of black-box model in each step. The gradient composed by different model gradients will lead a significant loss to the black-box model on these adversarial pictures and then cause misclassification. Our key motivation is to estimate the black-box model with several existing white-box models, which can significantly increase the efficiency from the perspectives of both query sampling and calculating. Compared with gradient estimation based black-box adversarial attack methods, our MEQA method reduces the number of queries from 10000 to 40, which greatly accelerates the black-box adversarial attack. Compared with the zero query black-box adversarial attack method, which also called transfer attack method, MEQA boosts the attack success rate by 30%. We evaluate our method on several black-box models and achieve remarkable performance which proves that MEQA can serve as a baseline method for fast and effective black-box adversarial attacks. © 2019, Springer Nature Switzerland AG.",Efficient black-box attack; Gradient estimation; Model robustness; Transfer attack,Big data; Baseline methods; Black boxes; Black-box model; Gradient estimation; Misclassifications; Model robustness; Transfer attack; White-box models; Query processing,,,,,"Athalye, A., Engstrom, L., Ilyas, A., Kwok, K., (2017) Synthesizing Robust Adversarial Examples; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP), pp. 39-57; Chen, P.Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.J., ZOO: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) Proceedings of the 10Th ACM Workshop on Artificial Intelligence and Security, pp. 15-26. , pp., ACM; Dong, Y., Boosting adversarial attacks with momentum (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 9185-9193. , pp; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Guo, C., Gardner, J.R., You, Y., Wilson, A.G., Weinberger, K.Q., (2019) Simple Black-Box Adversarial Attacks; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778. , pp; Ilyas, A., Engstrom, L., Athalye, A., Lin, J., (2018) Black-Box Adversarial Attacks with Limited Queries and Information; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105. , pp; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World; Liu, Y., Chen, X., Liu, C., Song, D., (2016) Delving into Transferable Adversarial Examples and Black-Box Attacks; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-Box Attacks Using Adversarial Samples; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519. , pp., ACM; Russakovsky, O., ImageNet large scale visual recognition challenge (2015) Int. J. Comput. Vis., 115 (3), pp. 211-252; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-Scale Image Recognition; Szegedy, C., (2013) Intriguing Properties of Neural Networks; Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses; Tu, C.C., (2018) Autozoom: Autoencoder-Based Zeroth Order Optimization Method for Attacking Black-Box Neural Networks","Wang, X.; Shanghai Key Lab for Trustworthy Computing, China; 电子邮件: xfwang@sei.ecnu.edu.cn",Cui Z.Pan J.Zhang S.Xiao L.Yang J.,,Springer,"9th International Conference on Intelligence Science and Big Data Engineering, IScIDE 2019",17 October 2019 through 20 October 2019,,234919,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,,Scopus,2-s2.0-85076928198
"Li X., Lu C., Cheng D., Li W.-H., Cao M., Liu B., Ma J., Zheng W.-S.",55959890900;57204782395;57195735824;56874979100;56875124000;57212514531;57212380741;25928152800;,Towards Photo-Realistic Visible Watermark Removal with Conditional Generative Adversarial Networks,2019,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),11901 LNCS,,,345,356,,5,10.1007/978-3-030-34120-6_28,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076914029&doi=10.1007%2f978-3-030-34120-6_28&partnerID=40&md5=ceed01e00d08e1141909cc9bacd29eba,"Sun Yat-sen University, Guangdong, China; Shanghai University of Finance and Economics, Shanghai, China; Shanghai Jiao Tong University, Shanghai, China; The University of Edinburgh, Edinburgh, United Kingdom; Zhejiang University, Zhejiang, China","Li, X., Sun Yat-sen University, Guangdong, China; Lu, C., Shanghai University of Finance and Economics, Shanghai, China; Cheng, D., Shanghai Jiao Tong University, Shanghai, China; Li, W.-H., The University of Edinburgh, Edinburgh, United Kingdom; Cao, M., Sun Yat-sen University, Guangdong, China; Liu, B., Zhejiang University, Zhejiang, China; Ma, J., Sun Yat-sen University, Guangdong, China; Zheng, W.-S., Sun Yat-sen University, Guangdong, China","Visible watermark plays an important role in image copyright protection and the robustness of a visible watermark to an attack is shown to be essential. To evaluate and improve the effectiveness of watermark, watermark removal attracts increasing attention and becomes a hot research top. Current methods cast the watermark removal as an image-to-image translation problem where the encode-decode architectures with pixel-wise loss are adopted to transfer the transparent watermarked pixels into unmarked pixels. However, when a number of realistic images are presented, the watermarks are more likely to be unknown and diverse (i.e., the watermarks might be opaque or semi-transparent; the category and pattern of watermarks are unknown). When applying existing methods to the real-world scenarios, they mostly can not satisfactorily reconstruct the hidden information obscured under the complex and various watermarks (i.e., the residual watermark traces remain and the reconstructed images lack reality). To address this difficulty, in this paper, we present a new watermark processing framework using the conditional generative adversarial networks (cGANs) for visible watermark removal in the real-world application. The proposed method enables the watermark removal solution to be more closed to the photo-realistic reconstruction using a patch-based discriminator conditioned on the watermarked images, which is adversarially trained to differentiate the difference between the recovered images and original watermark-free images. Extensive experimental results on a large-scale visible watermark dataset demonstrate the effectiveness of the proposed method and clearly indicate that our proposed approach can produce more photo-realistic and convincing results compared with the state-of-the-art methods. © 2019, Springer Nature Switzerland AG.",Conditional generative adversarial networks; Visible watermark; Watermark removal,Copyrights; Image reconstruction; Large dataset; Pixels; Adversarial networks; Hidden information; Image copyright protection; Real-world scenario; Reconstructed image; State-of-the-art methods; Watermarked images; Watermarked pixel; Watermarking,,,,,"Badrinarayanan, V., Kendall, A., Cipolla, R., SegNet: A deep convolutional encoder-decoder architecture for image segmentation (2017) IEEE Trans. Pattern Anal. Mach. Intell., 39 (12), pp. 2481-2495; Cheng, D., Large-scale visible watermark detection and removal with deep convolutional networks (2018) PRCV 2018. LNCS, 11258, pp. 27-40. , https://doi.org/10.1007/978-3-030-03338-5_3, Lai, J.H., et al. (eds.); Dekel, T., Rubinstein, M., Liu, C., Freeman, W.T., On the effectiveness of visible watermarks (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2146-2154. , pp; Goodfellow, I., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, pp. 2672-2680. , pp; Huang, C.H., Wu, J.L., Attacking visible watermarking schemes (2004) IEEE Trans. Multimed., 6 (1), pp. 16-30; Isola, P., Zhu, J.Y., Zhou, T., Efros, A.A., Image-to-image translation with conditional adversarial networks (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1125-1134. , pp; Johnson, J., Alahi, A., Fei-Fei, L., Perceptual losses for real-time style transfer and super-resolution (2016) ECCV 2016. LNCS, 9906, pp. 694-711. , https://doi.org/10.1007/978-3-319-46475-6_43, Leibe, B., Matas, J., Sebe, N., Welling, M. (eds.); Kingma, D.P., Ba, J., (2014) Adam: A Method for Stochastic Optimization; Ledig, C., Photo-realistic single image super-resolution using a generative adversarial network (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4681-4690. , pp; Mirza, M., Osindero, S., (2014) Conditional Generative Adversarial Nets; Pei, S.C., Zeng, Y.C., A novel image recovery algorithm for visible watermarked images (2006) IEEE Trans. Inf. Forensics Secur., 1 (4), pp. 543-550; Qin, C., He, Z., Yao, H., Cao, F., Gao, L., Visible watermark removal scheme based on reversible data hiding and image inpainting (2018) Sig. Proces.: Image Commun., 60, pp. 160-172; Ronneberger, O., Fischer, P., Brox, T., U-Net: Convolutional networks for biomedical image segmentation (2015) MICCAI 2015. LNCS, 9351, pp. 234-241. , https://doi.org/10.1007/978-3-319-24574-4_28, Navab, N., Hornegger, J., Wells, W.M., Frangi, A.F. (eds.), pp., Springer, Cham; Santoyo-Garcia, H., Fragoso-Navarro, E., Reyes-Reyes, R., Sanchez-Perez, G., Nakano-Miyatake, M., Perez-Meana, H., An automatic visible watermark detection method using total variation (2017) 2017 5Th International Workshop on Biometrics and Forensics (IWBF), pp. 1-5. , pp., IEEE; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-Scale Image Recognition; Xu, C., Lu, Y., Zhou, Y., An automatic visible watermark removal technique using image inpainting algorithms (2017) 2017 4Th International Conference on Systems and Informatics (ICSAI), pp. 1152-1157","Ma, J.; Sun Yat-sen UniversityChina; 电子邮件: majch7@mail2.sysu.edu.cn",Zhao Y.Lin C.Barnes N.Chen B.Westermann R.Kong X.,,Springer,"10th International Conference on Image and Graphics, ICIG 2019",23 August 2019 through 25 August 2019,,234869,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85076914029
"Guidotti D., Leofante F., Pulina L., Tacchella A.",57208393527;57191822501;57203955861;6701333647;,Verification and Repair of Neural Networks: A Progress Report on Convolutional Models,2019,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),11946 LNAI,,,405,417,,1,10.1007/978-3-030-35166-3_29,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076768274&doi=10.1007%2f978-3-030-35166-3_29&partnerID=40&md5=356e942c96b82d750d9e8634aaacffb3,"University of Genoa, Genoa, Italy; RWTH Aachen University, Aachen, Germany; University of Sassari, Sassari, Italy","Guidotti, D., University of Genoa, Genoa, Italy; Leofante, F., University of Genoa, Genoa, Italy, RWTH Aachen University, Aachen, Germany; Pulina, L., University of Sassari, Sassari, Italy; Tacchella, A., University of Genoa, Genoa, Italy","Recent public calls for the development of explainable and verifiable AI led to a growing interest in formal verification and repair of machine-learned models. Despite the impressive progress that the learning community has made, models such as deep neural networks remain vulnerable to adversarial attacks, and their sheer size represents a major obstacle to formal analysis and implementation. In this paper we present our current efforts to tackle repair of deep convolutional neural networks using ideas borrowed from Transfer Learning. With results obtained on popular MNIST and CIFAR10 datasets, we show that models of deep convolutional neural networks can be transformed into simpler ones preserving their accuracy, and we discuss how formal repair through convex programming techniques could benefit from this process. © 2019, Springer Nature Switzerland AG.",Convex optimization; Network repair; Transfer Learning,Convex optimization; Convolution; Formal verification; Neural networks; Repair; Convolutional model; Convolutional neural network; Formal analysis; Learning community; Network repairs; Programming technique; Progress report; Transfer learning; Deep neural networks,,,,,"Ehlers, R., Formal verification of piece-wise linear feed-forward neural networks (2017) ATVA 2017. LNCS, 10482, pp. 269-286. , https://doi.org/10.1007/978-3-319-68167-219, D’Souza, D., Narayan Kumar, K. (eds.), pp., Springer, Cham; Frankle, J., Carbin, M., (2018) The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks, , arXiv preprint arXiv; Frankle, J., Carbin, M., The lottery ticket hypothesis: Training pruned neural networks (2018) Corr Abs/, , http://arxiv.org/abs/1803.03635; Gilmer, J., Adams, R.P., Goodfellow, I., Andersen, D., Dahl, G.E., (2018) Motivating the Rules of the Game for Adversarial Example Research, , arXiv preprint arXiv; Goodfellow, I.J., Shlens, J., Szegedy, C., (2015) Explaining and Harnessing Adversarial Examples, , ICLR; Guidotti, D., Leofante, F., Castellini, C., Tacchella, A., Repairing learned controllers with convex optimization: A case study (2019) CPAIOR 2019. LNCS, 11494, pp. 364-373. , https://doi.org/10.1007/978-3-030-19212-924, Rousseau, L.-M., Stergiou, K. (eds.), pp., Springer, Cham; Guidotti, D., Leofante, F., Tacchella, A., Castellini, C., Improving reliability of myocontrol using formal verification (2019) IEEE TNSRE, 27 (4), pp. 564-571; Huang, X., (2018) Safety and Trustworthiness of Deep Neural Networks: A Survey, , arXiv preprint arXiv; Katz, G., Barrett, C., Dill, D.L., Julian, K., Kochenderfer, M.J., Reluplex: An efficient SMT solver for verifying deep neural networks (2017) CAV 2017. LNCS, 10426, pp. 97-117. , https://doi.org/10.1007/978-3-319-63387-95, Majumdar, R., Kunčak, V. (eds.), pp., Springer, Cham; Lecun, Y., Bengio, Y., Hinton, G.E., Deep learning (2015) Nature, 521 (7553), pp. 436-444; Liu, W., Wang, Z., Liu, X., Zeng, N., Liu, Y., Alsaadi, F.E., A survey of deep neural network architectures and their applications (2017) Neurocomputing, 234, pp. 11-26; Nielsen, M.A., (2015) Neural Networks and Deep Learning, 25. , vol., Determination Press, San Francisco; Paszke, A., (2017) Automatic Differentiation in Pytorch; Pedregosa, F., Scikit-learn: Machine learning in Python (2011) J. Mach. Learn. Res., 12, pp. 2825-2830; Pulina, L., Tacchella, A., An abstraction-refinement approach to verification of artificial neural networks (2010) CAV 2010. LNCS, 6174, pp. 243-257. , https://doi.org/10.1007/978-3-642-14295-624, In: Touili, T., Cook, B., Jackson, P. (eds.), Springer, Heidelberg; Rauber, J., Brendel, W., Bethge, M., (2017) Foolbox: A Python Toolbox to Benchmark the Robustness of Machine Learning Models, , http://arxiv.org/abs/1707.04131, arXiv preprint arXiv; Schwarz, M., Schulz, H., Behnke, S., RGB-D object recognition and pose estimation based on pre-trained convolutional neural network features (2015) 2015 IEEE International Conference on Robotics and Automation (ICRA), pp. 1329-1335. , pp., IEEE; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-Scale Image Recognition, , arXiv preprint arXiv; Szegedy, C., (2014) Intriguing Properties of Neural Networks, , ICLR; Taigman, Y., Yang, M., Ranzato, M., Wolf, L., Deepface: closing the gap to human-level performance in face verification (2014) CVPR, pp. 1701-1708. , pp; Tang, Y., (2013) Deep Learning Using Linear Support Vector Machines, p. 1306.0239. , arXiv preprint arXiv; Torrey, L., Shavlik, J., Transfer learning (2010) Handbook of Research on Machine Learning Applications and Trends: Algorithms, Methods, and Techniques, pp. 242-264. , IGI Global; Wong, E., Schmidt, F., Metzen, J.H., Kolter, J.Z., Scaling provable adversarial defenses (2018) Advances in Neural Information Processing Systems, pp. 8400-8409. , pp; Yu, D., Hinton, G.E., Morgan, N., Chien, J., Sagayama, S., Introduction to the special section on deep learning for speech and language processing (2012) IEEE Trans. Audio Speech Lang. Process., 20 (1), pp. 4-6","Tacchella, A.; University of GenoaItaly; 电子邮件: armando.tacchella@unige.it",Alviano M.Greco G.Scarcello F.,,Springer,"18th International Conference of the Italian Association for Artificial Intelligence, AI*IA 2019",19 November 2019 through 22 November 2019,,234369,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,,Scopus,2-s2.0-85076768274
"Heo B., Lee M., Yun S., Choi J.Y.",56119145700;35229740000;55581546300;56683331600;,Knowledge distillation with adversarial samples supporting decision boundary,2019,"33rd AAAI Conference on Artificial Intelligence, AAAI 2019, 31st Innovative Applications of Artificial Intelligence Conference, IAAI 2019 and the 9th AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2019",,,,3771,3778,,34,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076688758&partnerID=40&md5=5fbcf80432cd320f546e5bb7330acc7a,"Department of ECE, ASRI, Seoul National University, South Korea; Division of EE, Hanyang University, South Korea; Clova AI Research, NAVER Corp, South Korea","Heo, B., Department of ECE, ASRI, Seoul National University, South Korea; Lee, M., Division of EE, Hanyang University, South Korea; Yun, S., Clova AI Research, NAVER Corp, South Korea; Choi, J.Y., Department of ECE, ASRI, Seoul National University, South Korea","Many recent works on knowledge distillation have provided ways to transfer the knowledge of a trained network for improving the learning process of a new one, but finding a good technique for knowledge distillation is still an open problem. In this paper, we provide a new perspective based on a decision boundary, which is one of the most important component of a classifier. The generalization performance of a classifier is closely related to the adequacy of its decision boundary, so a good classifier bears a good decision boundary. Therefore, transferring information closely related to the decision boundary can be a good attempt for knowledge distillation. To realize this goal, we utilize an adversarial attack to discover samples supporting a decision boundary. Based on this idea, to transfer more accurate information about the decision boundary, the proposed algorithm trains a student classifier based on the adversarial samples supporting the decision boundary. Experiments show that the proposed method indeed improves knowledge distillation and achieves the state-of-the-arts performance. © 2019, Association for the Advancement of Artificial Intelligence (www.aaai.org).",,Classification (of information); Distillation; Distilleries; Decision boundary; Generalization performance; Learning process; State of the art; Artificial intelligence,,,,,"Bishop, C. M., (2006) Pattern recognition and Machine Learning, , Springer; Cao, X., Gong, N. Z., (2017) Mitigating evasion attacks to deep neural networks via region-based classification, , CoRR abs/1709.05583; Chen, G., Choi, W., Yu, X., Han, T., Chandraker, M., Learning efficient object detection models with knowledge distillation (2017) Neural Information Processing Systems (NIPS); Chen, Y., Wang, N., Zhang, Z., (2017) Darkrank: Accelerating deep metric learning via cross sample similarities transfer, , CoRR abs/1707.01220; Chrabaszcz, P., Loshchilov, I., Hutter, F., (2017) A down-sampled variant of imagenet as an alternative to the CIFAR datasets, , CoRR abs/1707.08819; Cortes, C., Vapnik, V., Support-vector networks (1995) Machine Learning, 20 (3), pp. 273-297; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Neural Information Processing Systems (NIPS), pp. 2672-2680; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations (ICLR); He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Hinton, G., Vinyals, O., Dean, J., Distilling the knowledge in a neural network (2015) NIPS Deep Learning and Representation Learning Workshop; Krizhevsky, A., (2009) Learning multiple layers of features from tiny images, , Technical report; Moosavi-Dezfooli, S., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) IEEE Symposium on Security and Privacy (SP), pp. 582-597; Romero, A., Ballas, N., Kahou, S. E., Chassang, A., Gatta, C., Bengio, Y., (2015) Fitnets: Hints for thin deep nets; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Fei-Fei, L., ImageNet Large Scale Visual Recognition Challenge (2015) International Journal of Computer Vision (IJCV), 115 (3), pp. 211-252; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I. J., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations (ICLR); Wang, C., Lan, X., (2017) Model distillation with knowledge transfer in face classification, alignment and verification, , CoRR abs/1709.02929; Xu, Z., Hsu, Y., Huang, J., (2017) Learning loss for knowledge distillation with conditional adversarial networks, , CoRR abs/1709.00513; Yim, J., Joo, D., Bae, J., Kim, J., A gift from knowledge distillation: Fast optimization, network minimization and transfer learning (2017) IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Zagoruyko, S., Komodakis, N., (2016) Paying more attention to attention: Improving the performance of convolutional neural networks via attention transfer, , CoRR abs/1612.03928",,,Association for the Advancement of Artificial Intelligence,AAAI Press,"33rd AAAI Conference on Artificial Intelligence, AAAI 2019, 31st Annual Conference on Innovative Applications of Artificial Intelligence, IAAI 2019 and the 9th AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2019",27 January 2019 through 1 February 2019,,160302,,9.78E+12,,,English,"AAAI Conf. Artif. Intell., AAAI, Innov. Appl. Artif. .igence Conf., IAAI AAAI Symp. Educ. Adv. Artif. Intell., EAAI",Conference Paper,Final,,Scopus,2-s2.0-85076688758
"Byra M., Sznajder T., Korzinek D., Piotrzkowska-Wroblewska H., Dobruch-Sobczak K., Nowicki A., Marasek K.",56414988400;57212170711;15042645500;56414859000;56458823400;56214353800;23094778900;,Impact of Ultrasound Image Reconstruction Method on Breast Lesion Classification with Deep Learning,2019,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),11867 LNCS,,,41,52,,9,10.1007/978-3-030-31332-6_4,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076116271&doi=10.1007%2f978-3-030-31332-6_4&partnerID=40&md5=e60fb4badaed4cad3324e9503f29a55f,"Department of Ultrasound, Institute of Fundamental Technological Research, Polish Academy of Sciences, Warsaw, Poland; Department of Multimedia, Polish-Japanese Academy of Information Technology, Warsaw, Poland","Byra, M., Department of Ultrasound, Institute of Fundamental Technological Research, Polish Academy of Sciences, Warsaw, Poland; Sznajder, T., Department of Multimedia, Polish-Japanese Academy of Information Technology, Warsaw, Poland; Korzinek, D., Department of Multimedia, Polish-Japanese Academy of Information Technology, Warsaw, Poland; Piotrzkowska-Wroblewska, H., Department of Ultrasound, Institute of Fundamental Technological Research, Polish Academy of Sciences, Warsaw, Poland; Dobruch-Sobczak, K., Department of Ultrasound, Institute of Fundamental Technological Research, Polish Academy of Sciences, Warsaw, Poland; Nowicki, A., Department of Ultrasound, Institute of Fundamental Technological Research, Polish Academy of Sciences, Warsaw, Poland; Marasek, K., Department of Multimedia, Polish-Japanese Academy of Information Technology, Warsaw, Poland","In this work we investigate the usefulness and robustness of transfer learning with deep convolutional neural networks (CNNs) for breast lesion classification in ultrasound (US). Deep learning models can be vulnerable to adversarial examples, engineered input image pixel intensities perturbations that force models to make classification errors. In US imaging, distribution of US image pixel intensities relies on applied US image reconstruction algorithm. We explore the possibility of fooling deep learning models for breast mass classification by modifying US image reconstruction method. Raw radio-frequency US signals acquired from malignant and benign breast masses were used to reconstruct US images, and develop classifiers using transfer learning with the VGG19, InceptionV3 and InceptionResNetV2 CNNs. The areas under the receiver operating characteristic curve (AUCs) obtained for each deep learning model developed and evaluated using US images reconstructed in the same way were equal to approximately 0.85, and there were no associated differences in AUC values between the models (DeLong test p-values &gt; 0.15). However, due to small modifications of the US image reconstruction method the AUC values for the models utilizing the VGG19, InceptionV3 and InceptionResNetV2 CNNs significantly decreased to 0.592, 0.584 and 0.687, respectively. Our study shows that the modification of US image reconstruction algorithm can have significant negative impact on classification performance of deep models. Taking into account medical image reconstruction algorithms may help develop more robust deep learning computer aided diagnosis systems. © 2019, Springer Nature Switzerland AG.",Adversarial attacks; Breast lesion classification; Computer aided diagnosis; Deep learning; Robustness; Transfer learning; Ultrasound imaging,Computer aided diagnosis; Computer aided instruction; Deep learning; Deep neural networks; Image analysis; Image classification; Image segmentation; Medical imaging; Neural networks; Pixels; Robustness (control systems); Ultrasonic imaging; Adversarial attacks; Breast lesion; Computer aided diagnosis systems; Convolutional neural network; Image reconstruction algorithm; Receiver operating characteristic curves; Transfer learning; Ultrasound imaging; Image reconstruction,,,,,"Abadi, M., TensorFlow: A system for large-scale machine learning (2016) OSDI, 16, pp. 265-283; Antropova, N., Huynh, B.Q., Giger, M.L., A deep feature fusion methodology for breast cancer diagnosis demonstrated on three imaging modality datasets (2017) Med. Phys., 44, pp. 5162-5171; Byra, M., Discriminant analysis of neural style representations for breast lesion classification in ultrasound (2018) Biocybern. Biomed. Eng., 38 (3), pp. 684-690; Byra, M., Breast mass classification in sonography with transfer learning using a deep convolutional neural network and color conversion (2019) Med. Phys., 46 (2), pp. 746-755; Byra, M., Nowicki, A., Wróblewska-Piotrzkowska, H., Dobruch-Sobczak, K., Classification of breast lesions using segmented quantitative ultrasound maps of homo-dyned K distribution parameters (2016) Med. Phys., 43 (10), pp. 5561-5569; Cheng, H.D., Shan, J., Ju, W., Guo, Y., Zhang, L., Automated breast cancer detection and classification using ultrasound images: A survey (2010) Pattern Recognit, 43 (1), pp. 299-317. , https://doi.org/10.1016/j.patcog.2009.05.012; Delong, E.R., Delong, D.M., Clarke-Pearson, D.L., Comparing the areas under two or more correlated receiver operating characteristic curves: A nonparametric approach (1988) Biometrics, 44 (3), pp. 837-845; Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L., ImageNet: A large-scale hierarchical image database (2009) IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2009, pp. 248-255; Finlayson, S.G., Kohane, I.S., Beam, A.L., (2018) Adversarial Attacks against Medical Deep Learning Systems; Flores, W.G., de Albuquerque Pereira, W.C., Infantosi, A.F.C., Improving classification performance of breast lesions on ultrasonography (2015) Pattern Recognit, 48 (4), pp. 1125-1136; Giger, M.L., Karssemeijer, N., Schnabel, J.A., Breast image analysis for risk assessment, detection, diagnosis, and treatment of cancer (2013) Annu. Rev. Biomed. Eng., 15, pp. 327-357; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Han, S., A deep learning framework for supporting the classification of breast lesions in ultrasound images (2017) Phys. Med. Biol., 62 (19), p. 7714; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778. , pp; Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P., DeepFool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582. , pp; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 427-436. , pp; Piotrzkowska-Wróblewska, H., Dobruch-Sobczak, K., Byra, M., Nowicki, A., Open access database of raw ultrasonic signals acquired from malignant and benign breast lesions (2017) Med. Phys., 44 (11), pp. 6105-6109; Qi, X., Automated diagnosis of breast ultrasonography images using deep neural networks (2019) Med. Image Anal., 52, pp. 185-198; Robin, X., PROC: An open-source package for R and S+ to analyze and compare ROC curves (2011) BMC Bioinform, 12, p. 77; Shin, H.C., Deep convolutional neural networks for computer-aided detection: CNN architectures, dataset characteristics and transfer learning (2016) IEEE Trans. Med. Imaging, 35 (5), pp. 1285-1298; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-Scale Image Recognition; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., Inception-v4, inception-ResNet and the impact of residual connections on learning (2017) Thirty-First AAAI Conference on Artificial Intelligence; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826. , pp; Topol, E.J., High-performance medicine: The convergence of human and artificial intelligence (2019) Nat. Med., 25 (1), p. 44; Tsui, P.H., Zhou, Z., Lin, Y.H., Hung, C.M., Chung, S.J., Wan, Y.L., Effect of ultrasound frequency on the nakagami statistics of human liver tissues (2017) Plos ONE, 12 (8); Yap, M.H., Automated breast ultrasound lesions detection using convolutional neural networks (2017) IEEE J. Biomed. Health Inform., 22, pp. 1218-1226; Yu, X., Guo, Y., Huang, S.M., Li, M.L., Lee, W.N., Beamforming effects on generalized Nakagami imaging (2015) Phys. Med. Biol., 60 (19), p. 7513","Byra, M.; Department of Ultrasound, Poland; 电子邮件: mbyra@ippt.pan.pl",Morales A.Fierrez J.Sanchez J.S.Ribeiro B.,,Springer,"9th Iberian Conference on Pattern Recognition and Image Analysis, IbPRIA 2019",1 July 2019 through 4 July 2019,,232429,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,,Scopus,2-s2.0-85076116271
[无可用作者姓名],[无可用的作者 ID],"14th Chinese Conference on Biometric Recognition, CCBR 2019",2019,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),11818 LNCS,,,,,518,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075563193&partnerID=40&md5=68bd4161a16aba52d68e73f0933bd0b6,,,The proceedings contain 56 papers. The special focus in this conference is on Biometric Recognition. The topics include: Authentication System Design Based on Dynamic Hand Gesture; structure Feature Learning: Constructing Functional Connectivity Network for Alzheimer’s Disease Identification and Analysis; weakly Supervised Learning of Image Emotion Analysis Based on Cross-spatial Pooling; embarrassingly Easy Zero-Shot Image Recognition; On the Generalization of GAN Image Forensics; deep Residual Equivariant Mapping for Multi-angle Face Recognition; the Impact of Data Correlation on Identification of Computer-Generated Face Images; face Image Deblurring Based on Iterative Spiral Optimazation; adaptiveNet: Toward an Efficient Face Alignment Algorithm; fingerprint Presentation Attack Detection via Analyzing Fingerprint Pairs; cross-Dimension Transfer Learning for Video-Based Facial Expression Recognition; exploring Shape Deformation in 2D Images for Facial Expression Recognition; facial Attractiveness Prediction by Deep Adaptive Label Distribution Learning; LWFD: A Simple Light-Weight Network for Face Detection; dairy Cow Tiny Face Recognition Based on Convolutional Neural Networks; reconstructed Face Recognition; a Two-Stage Method for Assessing Facial Paralysis Severity by Fusing Multiple Classifiers; latent Spatial Features Based on Generative Adversarial Networks for Face Anti-spoofing; similarity Measurement Between Reconstructed 3D Face and 2D Face Based on Deep Learning; real-Time Face Occlusion Recognition Algorithm Based on Feature Fusion; finger Vein Recognition Based on Double-Orientation Coding Histogram; joint Face Detection and Alignment Using Focal Loss-Based Multi-task Convolutional Neural Networks; a Face Recognition Workflow Based Upon Similarity Measurement; 106-Point Facial Landmark Localization with Mobile Networks Based on Regression; long Range Pupil Location Algorithm Based on the Improved Circle Fitting Method.,,,,,,,,,Sun Z.He R.Shan S.Feng J.Guo Z.,,Springer,"14th Chinese Conference on Biometric Recognition, CCBR 2019",12 October 2019 through 13 October 2019,,232889,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Review,Final,,Scopus,2-s2.0-85075563193
"Sharma Y., Ding G.W., Brubaker M.A.",57198896649;57201008172;22233489700;,On the effectiveness of low frequency perturbations,2019,IJCAI International Joint Conference on Artificial Intelligence,2019-August,,,3389,3396,,9,10.24963/ijcai.2019/470,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074942401&doi=10.24963%2fijcai.2019%2f470&partnerID=40&md5=70822003e8a9cae9432e144d051e7bae,Borealis AI,"Sharma, Y., Borealis AI; Ding, G.W., Borealis AI; Brubaker, M.A., Borealis AI","Carefully crafted, often imperceptible, adversarial perturbations have been shown to cause state-of-the-art models to yield extremely inaccurate outputs, rendering them unsuitable for safety-critical application domains. In addition, recent work has shown that constraining the attack space to a low frequency regime is particularly effective. Yet, it remains unclear whether this is due to generally constraining the attack search space or specifically removing high frequency components from consideration. By systematically controlling the frequency components of the perturbation, evaluating against the top-placing defense submissions in the NeurIPS 2017 competition, we empirically show that performance improvements in both the white-box and black-box transfer settings are yielded only when low frequency components are preserved. In fact, the defended models based on adversarial training are roughly as vulnerable to low frequency perturbations as undefended models, suggesting that the purported robustness of state-of-the-art ImageNet defenses is reliant upon adversarial perturbations being high frequency in nature. We do find that under L-inf-norm constraint 16/255, the competition distortion bound, low frequency perturbations are indeed perceptible. This questions the use of the L-inf-norm, in particular, as a distortion metric, and, in turn, suggests that explicitly considering the frequency space is promising for learning robust models which better align with human perception. © 2019 International Joint Conferences on Artificial Intelligence. All rights reserved.",,,,,,,"Alzantot, M., Sharma, Y., Chakraborty, S., Srivastava, M., (2018) Genattack: Practical Black-Box Attacks with Gradient-Free Optimization, , arXiv preprint; Alzantot, M., Sharma, Y., Elgohary, A., Ho, B.-J., Srivastava, M., Chang, K.-W., (2018) Generating Natural Language Adversarial Examples, , arXiv preprint; Athalye, A., Carlini, N., Wagner, D., (2018) Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples, , arXiv preprint; Brendel, W., Rauber, J., Bethge, M., (2017) Decision-Based Adversarial Attacks: Reliable Attacks against Black-Box Machine Learning Models, , arXiv preprint; Carlini, N., Wagner, D., (2017) Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods, , arXiv preprint; Carlini, N., Wagner, D., (2017) Towards Evaluating the Robustness of Neural Networks, , arXiv preprint; Chen, P.-Y., Sharma, Y., Zhang, H., Yi, J., Hsieh, C.-J., (2017) Ead: Elastic-Net Attacks to Deep Neural Networks Via Adversarial Examples, , arXiv preprint; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) AISec'17, pp. 15-26; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., ImageNet: A large-scale hierarchical image database (2009) Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pp. 248-255; Ding, G.W., Sharma, Y., Yik Chau Lui, K., Huang, R., (2018) Max-Margin Adversarial (Mma) Training: Direct Input Space Margin Maximization through Adversarial Training, , arXiv preprint; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., (2017) Boosting Adversarial Attacks with Momentum, , arXiv preprint; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint; Guo, C., Frank, J.S., Weinberger, K.Q., (2018) Low Frequency Adversarial Perturbation, , arXiv preprint; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint; Kurakin, A., Goodfellow, I., Bengio, S., Dong, Y., Liao, F., Liang, M., Pang, T., Abe, M., (2018) Adversarial Attacks and Defences Competition, , arXiv preprint; Lei, Q., Wu, L., Chen, P.-Y., Dimakis, A.G., Dhillon, I.S., Witbrock, M., (2018) Discrete Attacks and Submodular Optimization with Applications to Text Classification, , arXiv preprint; Li, Y., Bradshaw, J., Sharma, Y., (2018) Are Generative Classifiers More Robust to Adversarial Attacks?, , arXiv preprint; Liao, F., Liang, M., Dong, Y., Pang, T., Hu, X., Zhu, J., (2017) Defense against Adversarial Attacks Using High-Level Representation Guided Denoiser, , arXiv preprint; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , arXiv preprint; Papernot, N., McDaniel, P., (2018) Deep K-Nearest Neighbors: Towards Confident, Interpretable and Robust Deep Learning, , arXiv preprint; Ramamohan Rao, K., Yip, P., (2014) Discrete Cosine Transform: Algorithms, Advantages, Applications, , Academic press; Schott, L., Rauber, J., Bethge, M., Brendel, W., (2018) Towards the First Adversarially Robust Neural Network Model on Mnist, , arXiv preprint; Sharma, Y., Chen, P.-Y., (2017) Attacking the Madry Defense Model with L1-Based Adversarial Examples, , arXiv preprint; Sharma, Y., Chen, P.-Y., (2018) Bypassing Feature Squeezing by Increasing Adversary Strength, , arXiv preprint; Sharma, Y., Le, T.-D., Alzantot, M., (2018) Caad 2018: Generating Transferable Adversarial Examples, , arXiv preprint; Smith, L., Gal, Y., (2018) Understanding Measures of Uncertainty for Adversarial Example Detection, , arXiv preprint; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint; Thomas, A., Elibol, O., (2017) Defense against Adversarial Attack: 3rd Place, , https://github.com/anlthms/nips-2017; Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses, , arXiv preprint; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., (2017) Mitigating Adversarial Effects through Randomization, , arXiv preprint; Xie, C., Wu, Y., Van Der Maaten, L., Yuille, A., He, K., (2018) Feature Denoising for Improving Adversarial Robustness, , arXiv preprint; Zhang, R., Isola, P., Efros, A.A., Shechtman, E., Wang, O., (2018) The Unreasonable Effectiveness of Deep Features as a Perceptual Metric, , arXiv preprint; Zhou, W., Hou, X., Chen, Y., Tang, M., Huang, X., Gan, X., Yang, Y., Transferable adversarial perturbations (2018) ECCV, (14), pp. 471-486. , Springer; Zoph, B., Vasudevan, V., Shlens, J., Le, Q.V., (2017) Learning Transferable Architectures for Scalable Image Recognition, , arXiv preprint",,Kraus S.,Baidu;et al.;Huawei;International Joint Conferences on Artifical Intelligence (IJCAI);Sony;Xiao-i,International Joint Conferences on Artificial Intelligence,"28th International Joint Conference on Artificial Intelligence, IJCAI 2019",10 August 2019 through 16 August 2019,,153611,10450823,9.78E+12,,,English,IJCAI Int. Joint Conf. Artif. Intell.,Conference Paper,Final,"All Open Access, Bronze, Green",Scopus,2-s2.0-85074942401
"Li W., Li Z., Sun J., Wang Y., Liu H., Yang J., Gui G.",54789086100;57208153718;56081620100;57207000043;57205514225;57192104836;24168616700;,Spear and Shield: Attack and Detection for CNN-Based High Spatial Resolution Remote Sensing Images Identification,2019,IEEE Access,7,,8756237,94583,94592,,3,10.1109/ACCESS.2019.2927376,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073902766&doi=10.1109%2fACCESS.2019.2927376&partnerID=40&md5=2d7f4317754ca2906bfebc35023a4041,"School of Geographic and Biologic Information, Nanjing University of Posts and Telecommunications, Nanjing, 210023, China; College of Telecommunications and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, 210023, China; Smart Health Big Data Analysis and Location Services Engineering, Laboratory of Jiangsu Province, Nanjing, 210023, China","Li, W., School of Geographic and Biologic Information, Nanjing University of Posts and Telecommunications, Nanjing, 210023, China, College of Telecommunications and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, 210023, China, Smart Health Big Data Analysis and Location Services Engineering, Laboratory of Jiangsu Province, Nanjing, 210023, China; Li, Z., College of Telecommunications and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, 210023, China; Sun, J., College of Telecommunications and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, 210023, China; Wang, Y., College of Telecommunications and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, 210023, China; Liu, H., College of Telecommunications and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, 210023, China; Yang, J., College of Telecommunications and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, 210023, China; Gui, G., College of Telecommunications and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, 210023, China","High spatial resolution remote sensing (HSRRS) images classification and identification is an important technology to acquire land surface information for land resource management, geographical situation monitoring, and global climate change. As the hottest deep learning method, convolutional neural network (CNN) has been successfully applied in HSRRS image classification and identification due to its powerful information extraction capability. However, adversarial perturbations caused by radiation transfer process or artificial or other unpredictable disturbances often deteriorate the stability of CNN. Under this background, we propose a robust architecture for adversarial attack and detection to classify and identify HSRRS images. First of all, two white-box attacks [i.e., large Broyden-Fletcher-Goldfarb-Shanno (L-BFGS) and fast gradient sign method (FGSM)] are adopted respectively to generate adversarial images to confuse the model, and to assess the robustness of the HSRRS image classifier. Second, adversarial detection models based on support vector machine (SVM) with single or fused two level features are proposed to improve the detection accuracy. The features extracted from the testing CNN full connected layers contain adversarial perturbations and real information, from which SVM classifier and discriminate the real and the adversarial images. The adversarial attack model is evaluated in terms of overall accuracy (OA) and kappa coefficient (kc). The simulation results show that the OA decreases from 96.4% to 44.4% and 33.3% for L-BFGS and FGSM attacked classifier model, respectively. The adversarial detection is evaluated via OA, detection probability PD, false alarm probability PFA, and miss probability PM. The simulation results indicate that the fused model with two different level features based on SVM can obtain the best OA (94.5%), PD (0.933), PFA (0.040), and PM (0.067) among the detectors if the classifier is attacked by the FGSM. Meanwhile, when facing the L-BFGS attack, the fused model presents similar performance if the best single level features are utilized. © 2013 IEEE.",attack detection; Convolutional neural network; fast gradient sign method (FGSM); large Broyden-Fletcher-Goldfarb-Shanno (L-BFGS); white-box attack,Classification (of information); Climate change; Convolution; Deep learning; Feature extraction; Image resolution; Information management; Neural networks; Nonlinear programming; Probability; Remote sensing; Support vector machines; Attack detection; Broyden-Fletcher-Goldfarb-Shanno; Convolutional neural network; fast gradient sign method (FGSM); White box; Image classification,,,,,"Zhu, R., Wang, Z., Ma, Z., Wang, G., Xue, J.-H., LRID: A new metric of multi-class imbalance degree based on likelihood-ratio test (2018) Pattern Recognit. Lett., 116, pp. 36-42. , Dec; Li, W., Liu, H., Wang, Y., Li, Z., Jia, Y., Gui, G., Deep learning-based classification methods for remote sensing images in urban built-up areas (2019) IEEE Access, 7, pp. 36274-36284; Wang, Y., Liu, M., Yang, J., Gui, G., Data-driven deep learning for automatic modulation recognition in cognitive radios (2019) IEEE Trans. Veh. Technol., 68 (4), pp. 4074-4077. , Apr; Liu, M., Song, T., Gui, G., Deep cognitive perspective: Resource allocation for NOMA-based heterogeneous IoT with imperfect SIC (2019) IEEE Internet Things J., 6 (2), pp. 2885-2894. , Apr; Huang, H., Xia, W., Xiong, J., Yang, J., Zheng, G., Zhu, X., Unsupervised learning-based fast beamforming design for downlink MIMO (2018) IEEE Access, 7, pp. 7599-7605; Zhong, Y., Han, X., Zhang, L., Multi-class geospatial object detection based on a position-sensitive balancing framework for high spatial resolution remote sensing imagery (2018) ISPRS J. Photogramm. Remote Sens., 138, pp. 281-294. , Apr; Huang, H., Song, Y., Yang, J., Gui, G., Adachi, F., Deep-learning-based millimeter-wave massive MIMO for hybrid precoding (2019) IEEE Trans. Veh. Technol., 68 (3), pp. 3027-3032. , Mar; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. LEEEConf. Comput. Vis. Pattern Recognit. (CVPR), pp. 770-778. , Jun; Xiong, H.Y., Alipanahi, B., Lee, L.J., Bretschneider, H., Merico, D., Yuen, R.K.C., Hua, Y., Frey, B.J., The human splicing code reveals new insights into the genetic determinants of disease (2015) Science, 347 (6218), p. 144; Sutskever, I., Vinyals, O., Le, Q.V., Sequence to sequence learning with neural networks (2014) Proc Adv. Neural Inf. Process. Syst., pp. 1-9. , https://arxiv.org/abs/1409.3215; Chen, L.-C., Papandreou, G., Kokkinos, I., Murphy, K., Yuille, A.L., DeepLab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected CRFs (2017) IEEE Trans. Pattern Anal. Mach. Lntell., 40 (4), pp. 834-848. , Apr; Lee, J.-G., Jun, S., Cho, Y.-W., Lee, H., Kim, G.B., Seo, J.B., Kim, N., Deep learning in medical imaging: General overview (2017) Korean J. Radiol., 18 (4), pp. 570-584; Fawzi, H., Tabuada, P., Diggavi, S., Secure estimation and control for cyber-physical systems under adversarial attacks (2014) LEEE Trans. Autom. Control, 59 (6), pp. 1454-1467. , Jun; Kwon, H., Kim, Y., Park, K.-W., Yoon, H., Choi, D., Multi-targeted adversarial example in evasion attack on deep neural network (2018) LEEE Access, 6, pp. 46084-46096; Akhtar, N., Mian, A., Threat of adversarial attacks on deep learning in computer vision: A survey (2018) IEEE Access, 6, pp. 14410-14430; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, D., Fergus, R., Intriguing properties of neural networks (2014) Proc. Lnt. Conf. Learn. Represent. (LCLR), pp. 1-10. , https://arxiv.org/abs/1312.6199; Fawzi, A., Moosavi-Dezfooli, S.-M., Frossard, P., The robustness of deep networks: A geometrical perspective (2017) LEEE Signal Process. Mag., 34 (6), pp. 50-62. , Nov; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2014) Proc. Int. Conf. Learn. Represent. (ICLR), pp. 1-11. , https://arxiv.org/abs/1412.6572; Liu, Y., Chen, X., Chang, L., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) Proc. Lnt. Conf. Learn. Represent. (LCLR), pp. 1-24. , https://arxiv.org/abs/1611.02770; Wang, Z., Deep learning-based intrusion detection with adversaries (2018) IEEE Access, 6, pp. 38367-38384; Su, J., Vargas, D.V., Sakurai, K., One pixel attack for fooling deep neural networks IEEE Trans. Evol. Comput., , to be published; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Proc. IEEESymp. Secur. Privacy (SP), pp. 39-57. , May; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Proc. IEEESymp. Secur. Privacy (SP), pp. 582-597. , May; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Proc. LEEE Eur. Symp. Secur. Privacy Z (EuroS P), pp. 372-387. , Mar; Zhang, L., Huang, X., Huang, B., Li, P., A pixel shape index coupled with spectral information for classification of high spatial resolution remotely sensed imagery (2006) LEEE Trans. Geosci. Remote Sens., 44 (10), pp. 2950-2961. , Oct; Cheng, G., Yang, C., Yao, X., Guo, L., Han, J., When deep learning meets metric learning: Remote sensing image scene classification via learning discriminative CNNs (2018) LEEE Trans. Geosci. Remote Sens., 56 (5), pp. 2811-2821. , May; Hong, Z., Ming, D., Zhou, K., Guo, Y., Lu, T., Road extraction from a high spatial resolution remote sensing image based on richer convolutional features (2018) IEEE Access, 6, pp. 46988-47000; Pang, J., Li, C., Shi, J., Xu, Z., Feng, H., R2-CNN: Fast tiny object detection in large-scale remote sensing images LEEE Trans. Geosci. Remote Sens., , to be published; Liu, Y., Yao, J., Lu, X., Xia, M., Wang, X., Liu, Y., Roadnet: Learning to comprehensively analyze road networks in complex urban scenes from high-resolution remotely sensed images (2019) LEEE Trans. Geosci. Remote Sens., 57 (4), pp. 2043-2056. , Apr; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2016) Proc. LEEE Conf. Comput. Vis. Pattern Recog-nit. (CVPR), pp. 1-13. , https://arxiv.org/abs/1607.02533, Jul; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., DeepFool: A simple and accurate method to fool deep neural networks (2016) Proc. LEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 2574-2582. , Jun; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2016) Proc. LEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 1-17. , https://arxiv.org/abs/1611.01236, Nov; Papernot, N., McDaniel, P., Sinha, A., Wellman, M., Towards the science of security and privacy in machine learning (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 1-19. , https://arxiv.org/abs/1611.03814, Nov; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., On detecting adversarial perturbations (2017) Proc. Lnt. Conf. Learn. Represent. (LCLR), pp. 1-12. , https://arxiv.org/abs/1702.04267, Feb; Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., (2017) On the (Statistical) Detection of Adversarial Examples, , https://arxiv.org/abs/1702.06280, Feb; Liang, B., Li, H., Su, M., Li, X., Shi, W., Wang, X., Detecting adversarial image examples in deep neural networks with adaptive noise reduction IEEE Trans. Depend. Sec. Comput., , to be published; Xu, W., Evans, D., Qi, Y., Feature squeezing: Detecting adversarial examples in deep neural networks (2017) Proc. Netw. Distrib. Syst. Secur. Symp. (NDSS), pp. 1-15. , https://arxiv.org/abs/1704.01155; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., Detecting adversarial samples from artifacts (2017) Proc. Lnt. Conf. Mach. Learn. (LCML), pp. 1-9. , https://arxiv.org/abs/1703.00410; Miyato, T., Maeda, S.-I., Koyama, M., Ishii, S., Virtual adversarial training: A regularization method for supervised and semi-supervised learning (2019) IEEE Trans. Pattern Anal. Mach. Intell., 41 (8), pp. 1979-1993. , Aug","Sun, J.; College of Telecommunications and Information Engineering, China; 电子邮件: sunjinlong@njupt.edu.cn",,,Institute of Electrical and Electronics Engineers Inc.,,,,,21693536,,,,English,IEEE Access,Article,Final,"All Open Access, Gold",Scopus,2-s2.0-85073902766
"Guidotti D., Leofante F.",57208393527;57191822501;,Repair of convolutional neural networks using convex optimization: Preliminary experiments,2019,CEUR Workshop Proceedings,2457,,,,,,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073263456&partnerID=40&md5=05d28ca7dc2096d2eb81cc351c69277b,"University of Genoa, Genoa, Italy; RWTH Aachen University, Aachen, Germany; University of Sassari, Sassari, Italy","Guidotti, D., University of Genoa, Genoa, Italy; Leofante, F., University of Genoa, Genoa, Italy, RWTH Aachen University, Aachen, Germany, University of Sassari, Sassari, Italy","Recent public calls for the development of explainable and verifiable Artificial Intelligence (AI) led to a growing interest in formal verification and repair of machine-learned models. Despite the impressive progress that the learning community has made, models such as deep neural networks remain vulnerable to adversarial attacks, and their sheer size represents a major obstacle to formal analysis and implementation. In this paper, we present our current efforts to tackle repair of deep convolutional neural networks using ideas borrowed from Transfer Learning. Using results obtained on popular MNIST and CIFAR10 datasets, we show that models of deep convolutional neural networks can be transformed into simpler ones preserving their accuracy, and we discuss how formal repair through convex programming techniques could benefit from this process. © 2019 CEUR-WS. All rights reserved.",Convex Optimization; Network Repair; Transfer Learning,Convex optimization; Convolution; Cyber Physical System; Embedded systems; Neural networks; Repair; Convolutional neural network; Formal analysis; Learning community; Network repairs; Programming technique; Sheer size; Transfer learning; Deep neural networks,,,,,"Frankle, J., Carbin, M., (2018) The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks, , arXiv preprint; Gilmer, J., Adams, R.P., Goodfellow, I., Andersen, D., Dahl, G.E., (2018) Motivating the Rules of the Game for Adversarial Example Research, , arXiv preprint; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR; Guidotti, D., Leofante, F., Castellini, C., Tacchella, A., Repairing learned controllers with convex optimization: A case study (2019) CPAIOR, pp. 364-373; Guidotti, D., Leofante, F., Tacchella, A., Castellini, C., Improving reliability of myocontrol using formal verification (2019) IEEE Transactions on Neural Systems and Rehabilitation Engineering, 27 (4), pp. 564-571; Katz, G., Huang, D.A., Ibeling, D., Julian, K., Lazarus, C., Lim, R., Shah, P., Barrett, C.W., The marabou framework for verification and analysis of deep neural networks (2019) CAV, pp. 443-452; LeCun, Y., Bengio, Y., Hinton, G.E., Deep learning (2015) Nature, 521 (7553), pp. 436-444; Liu, W., Wang, Z., Liu, X., Zeng, N., Liu, Y., Alsaadi, F.E., A survey of deep neural network architectures and their applications (2017) Neurocomputing, 234, pp. 11-26; Nielsen, M.A., (2015) Neural Networks and Deep Learning, 25. , Determination press San Francisco, CA, USA; Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., Lin, Z., Lerer, A., (2017) Automatic Differentiation in Pytorch; Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Duchesnay, E., Scikit-learn: Machine learning in python (2011) Journal of Machine Learning Research, 12, pp. 2825-2830; Pulina, L., Tacchella, A., An abstraction-refinement approach to verification of artificial neural networks (2010) CAV, pp. 243-257; Rauber, J., Brendel, W., Bethge, M., (2017) Foolbox: A Python Toolbox to Benchmark the Robustness of Machine Learning Models, , http://arxiv.org/abs/1707.04131, arXiv preprint; Schwarz, M., Schulz, H., Behnke, S., Rgb-d object recognition and pose estimation based on pre-trained convolutional neural network features (2015) ICRA, pp. 1329-1335; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-Scale Image Recognition, , arXiv preprint; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R., Intriguing properties of neural networks (2014) ICLR; Tang, Y., (2013) Deep Learning Using Linear Support Vector Machines, , arXiv preprint; Torrey, L., Shavlik, J., Transfer learning (2010) Handbook of Research on Machine Learning Applications and Trends: Algorithms, Methods, and Techniques, pp. 242-264. , IGI Global; Wong, E., Schmidt, F., Metzen, J.H., Kolter, J.Z., Scaling provable adversarial defenses (2018) NeurIPS, pp. 8400-8409",,Pulina L.,,CEUR-WS,"2019 Cyber-Physical Systems PhD Workshop, CPSWS 2019",23-Sep-19,,151981,16130073,,,,English,CEUR Workshop Proc.,Conference Paper,Final,,Scopus,2-s2.0-85073263456
"Demontis A., Melis M., Pintor M., Jagielski M., Biggio B., Oprea A., Nita-Rotaru C., Roli F.",56913250700;57200330132;57205115488;57203204598;23090165100;57206038548;6507281794;57194734588;,Why do adversarial attacks transfer? Explaining transferability of evasion and poisoning attacks,2019,Proceedings of the 28th USENIX Security Symposium,,,,321,338,,61,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072900690&partnerID=40&md5=ebe100a708426ec0b1edeef53c787f14,"Department of Electrical and Electronic Engineering, University of Cagliari, Italy; Pluribus One, Italy; Northeastern University, Boston, MA, United States","Demontis, A., Department of Electrical and Electronic Engineering, University of Cagliari, Italy; Melis, M., Department of Electrical and Electronic Engineering, University of Cagliari, Italy; Pintor, M., Department of Electrical and Electronic Engineering, University of Cagliari, Italy; Jagielski, M., Northeastern University, Boston, MA, United States; Biggio, B., Department of Electrical and Electronic Engineering, University of Cagliari, Italy, Pluribus One, Italy; Oprea, A., Northeastern University, Boston, MA, United States; Nita-Rotaru, C., Northeastern University, Boston, MA, United States; Roli, F., Department of Electrical and Electronic Engineering, University of Cagliari, Italy, Pluribus One, Italy","Transferability captures the ability of an attack against a machine-learning model to be effective against a different, potentially unknown, model. Empirical evidence for transferability has been shown in previous work, but the underlying reasons why an attack transfers or not are not yet well understood. In this paper, we present a comprehensive analysis aimed to investigate the transferability of both test-time evasion and training-time poisoning attacks. We provide a unifying optimization framework for evasion and poisoning attacks, and a formal definition of transferability of such attacks. We highlight two main factors contributing to attack transferability: the intrinsic adversarial vulnerability of the target model, and the complexity of the surrogate model used to optimize the attack. Based on these insights, we define three metrics that impact an attack's transferability. Interestingly, our results derived from theoretical analysis hold for both evasion and poisoning attacks, and are confirmed experimentally using a wide range of linear and non-linear classifiers and datasets. © 2019 by The USENIX Association. All rights reserved.",,Comprehensive analysis; Formal definition; Machine learning models; Nonlinear classifiers; Optimization framework; Poisoning attacks; Surrogate model; Training time; Classification (of information),,,,,"Arp, D., Spreitzenbarth, M., Hübner, M., Gascon, H., Rieck, K., Drebin: Efficient and explainable detection of android malware in your pocket (2014) 21st NDSS, , The Internet Society; Athalye, A., Carlini, N., Wagner, D.A., Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples (2018) ICML, Vol. 80 of JMLR W&CP, pp. 274-283. , JMLR.org; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndić, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) ECML PKDD, Part III, Vol. 8190 of LNCS, pp. 387-402. , H. Blockeel et al., editors, Springer Berlin Heidelberg; Biggio, B., Nelson, B., Laskov, P., Poisoning attacks against support vector machines (2012) 29th Int'l Conf. On Machine Learning, pp. 1807-1814. , J. Langford and J. Pineau, editors, Omnipress; Biggio, B., Roli, F., Wild patterns: Ten years after the rise of adversarial machine learning (2018) Pattern Recognition, 84, pp. 317-331; Bishop, C.M., (2007) Pattern Recognition and Machine Learning (Information Science and Stats), , Springer; Carlini, N., Wagner, D.A., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) 10th ACM Workshop on Artificial Intelligence and Security, AISec'17, pp. 3-14. , B. M. Thuraisingham et al., editors, New York, NY, USA, ACM; Carlini, N., Wagner, D.A., Towards evaluating the robustness of neural networks (2017) IEEE Symp. On Sec. On Privacy, pp. 39-57. , IEEE Computer Society; Chen, X., Liu, C., Li, B., Lu, K., Song, D., (2017) Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning, , ArXiv e-prints, abs/1712.05526; Dang, H., Huang, Y., Chang, E.-C., Evading classifiers by morphing in the dark (2017) 24th ACM SIGSAC Conf. On Computer and Comm. Sec., CCS; Demontis, A., Melis, M., Biggio, B., Maiorca, D., Arp, D., Rieck, K., Corona, I., Roli, F., Yes, machine learning can be more secure! A case study on android malware detection IEEE Trans. Dependable and Secure Computing, , press; Demontis, A., Russu, P., Biggio, B., Fumera, G., Roli, F., On security and sparsity of linear classifiers for adversarial settings (2016) Joint IAPR Int'l Workshop on Structural, Syntactic, and Statistical Patt. Rec., Vol. 10029 of LNCS, pp. 322-332. , A. Robles-Kelly et al., editors, Cham, Springer International Publishing; Dong, Y., Liao, F., Pang, T., Hu, X., Zhu, J., Boosting adversarial examples with momentum (2018) CVPR; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR; Grosse, K., Papernot, N., Manoharan, P., Backes, M., McDaniel, P.D., Adversarial examples for malware detection (2017) ESORICS, 10493 (2), pp. 62-79. , of LNCS,. Springer; Gu, T., Dolan-Gavitt, B., Garg, S., Badnets: Identifying vulnerabilities in the machine learning model supply chain (2017) NIPS Workshop on Machine Learning and Computer Security, , abs/1708.06733; Ilyas, A., Engstrom, L., Athalye, A., Lin, J., Black-box adversarial attacks with limited queries and information (2018) 35th ICML, 80, pp. 2137-2146. , J. Dy and A. Krause, editors, PMLR; Jagielski, M., Oprea, A., Biggio, B., Liu, C., Nita-Rotaru, C., Li, B., Manipulating machine learning: Poisoning attacks and countermeasures for regression learning (2018) IEEE Symp. S&P, pp. 931-947; Kantchelian, A., Tygar, J.D., Joseph, A.D., Evasion and hardening of tree ensemble classifiers (2016) 33rd ICML, 48, pp. 2387-2396. , of JMLR W&CP,. JMLR.org; Koh, P.W., Liang, P., Understanding black-box predictions via influence functions (2017) Proc. Of the 34th Int'l Conf. Of Machine Learning, ICML; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) ICLR; Lyu, C., Huang, K., Liang, H.-N., A unified gradient regularization family for adversarial examples (2015) IEEE Int'l Conf. On Data Mining (ICDM), pp. 301-309. , 00,. Los Alamitos, CA, USA, IEEE CS; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) ICLR; Mei, S., Zhu, X., Using machine teaching to identify optimal training-set attacks on machine learners (2015) 29th AAAI Conf. Artificial Intelligence (AAAI'15); Melis, M., Demontis, A., Biggio, B., Brown, G., Fumera, G., Roli, F., Is deep learning safe for robot vision? Adversarial examples against the iCub humanoid (2017) ICCVW ViPAR, pp. 751-759; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) CVPR; Muñoz-González, L., Biggio, B., Demontis, A., Paudice, A., Wongrassamee, V., Lupu, E.C., Roli, F., Towards poisoning of deep learning algorithms with back-gradient optimization (2017) 10th ACM Workshop on AI and Sec., AISec'17, pp. 27-38. , B. M. Thuraisingham et al., editors, New York, NY, USA, ACM; Nelson, B., Barreno, M., Chi, F.J., Joseph, A.D., Rubinstein, B.I.P., Saini, U., Sutton, C., Xia, K., Exploiting machine learning to subvert your spam filter (2008) LEET'08, pp. 1-9. , Berkeley, CA, USA, USENIX Association; Newell, A., Potharaju, R., Xiang, L., Nita-Rotaru, C., On the practicality of integrity attacks on document-level sentiment analysis (2014) AISec; Newsome, J., Karp, B., Song, D., Paragraph: Thwarting signature learning by training maliciously (2006) RAID, pp. 81-105. , Springer; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-Box Attacks Using Adversarial Samples; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Asia CCS'17, pp. 506-519. , New York, NY, USA, ACM; Papernot, N., McDaniel, P.D., Goodfellow, I.J., (2016) Transferability in Machine Learning: From Phenomena to Black-Box Attacks Using Adversarial Samples, , ArXiv e-prints, abs/1605.07277; Perdisci, R., Dagon, D., Lee, W., Fogla, P., Sharif, M., Misleading worm signature generators using deliberate noise injection (2006) IEEE Symp. Sec. & Privacy; Ross, A.S., Doshi-Velez, F., Improving the adversarial robustness and interpretability of deep neural networks by regularizing their input gradients (2018) AAAI, , AAAI Press; Rubinstein, B.I., Nelson, B., Huang, L., Joseph, A.D., Lau, S.-H., Rao, S., Taft, N., Tygar, J.D., Antidote: Understanding and defending against poisoning of anomaly detectors (2009) 9th ACM SIGCOMM Internet Measurement Conf., IMC'09, pp. 1-14; Russu, P., Demontis, A., Biggio, B., Fumera, G., Roli, F., Secure kernel machines against evasion attacks (2016) 9th ACM Workshop on AI and Sec., AISec'16, pp. 59-69. , New York, NY, USA, ACM; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) ACM SIGSAC Conf. On Comp. On Comm. Sec., pp. 1528-1540; Simon-Gabriel, C.J., Ollivier, Y., Schölkopf, B., Bottou, L., Lopez-Paz, D., (2018) Adversarial Vulnerability of Neural Networks Increases with Input Dimension, , ArXiv; Sokolić, J., Giryes, R., Sapiro, G., Rodrigues, M.R.D., Robust large margin deep neural networks (2017) IEEE Trans. On Signal Proc., 65 (16), pp. 4265-4280; Suciu, O., Marginean, R., Kaya, Y., Iii, H.D., Dumitras, T., When does machine learning FAIL? Generalized transferability for evasion and poisoning attacks (2018) 27th USENIX Sec, pp. 1299-1316. , USENIX Assoc; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) ICLR; Tramèr, F., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2017) The Space of Transferable Adversarial Examples, , ArXiv e-prints; Varga, D., Csiszárik, A., Zombori, Z., (2017) Gradient Regularization Improves Accuracy of Discriminative Models, , ArXiv e-prints; Šrndic, N., Laskov, P., Practical evasion of a learning-based classifier: A case study (2014) IEEE Symp. Sec. And Privacy, SP'14, pp. 197-211; Wang, B., Gong, N.Z., Stealing hyperparameters in machine learning (2018) 2018 IEEE Symposium on Security and Privacy (SP), pp. 36-52; Wu, L., Zhu, Z., Tai, C., Enhancing, W.E., (2018) The Transferability of Adversarial Examples with Noise Reduced Gradient, , ArXiv e-prints; Xiao, H., Biggio, B., Brown, G., Fumera, G., Eckert, C., Roli, F., Is feature selection secure against training data poisoning? (2015) JMLR W&CP - 32nd ICML, 37, pp. 1689-1698. , F. Bach and D. Blei, editors; Xu, W., Qi, Y., Evans, D., Automatically evading classifiers a case study on PDF malware classifiers (2016) NDSS, , Internet Society; Zhang, F., Chan, P., Biggio, B., Yeung, D., Roli, F., Adversarial feature selection against evasion attacks (2016) IEEE Trans. On Cybernetics, 46 (3), pp. 766-777",,,Avast;et al.;Facebook;Intel;Microsoft;The USENIX Association,USENIX Association,28th USENIX Security Symposium,14 August 2019 through 16 August 2019,,155143,,9.78E+12,,,English,Proc. USENIX Secur. Symp.,Conference Paper,Final,,Scopus,2-s2.0-85072900690
"Cai R.J., Li X.J., Chong P.H.J.",56393843500;56046929300;7102970085;,An Evolutionary Self-Cooperative Trust Scheme Against Routing Disruptions in MANETs,2019,IEEE Transactions on Mobile Computing,18,1,8350039,42,55,,45,10.1109/TMC.2018.2828814,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045997392&doi=10.1109%2fTMC.2018.2828814&partnerID=40&md5=5a03491e5639eaf790087b037c0864a5,"School of EEE, Nanyang Technological University, 50 Nanyang Ave., Singapore, 639798, Singapore; Department of EEE, Auckland University of Technology, Auckland, 1142, New Zealand","Cai, R.J., School of EEE, Nanyang Technological University, 50 Nanyang Ave., Singapore, 639798, Singapore; Li, X.J., Department of EEE, Auckland University of Technology, Auckland, 1142, New Zealand; Chong, P.H.J., Department of EEE, Auckland University of Technology, Auckland, 1142, New Zealand","How to achieve reliable routing has always been a major issue in the design of communication networks, among which mobile ad hoc networks (MANETs) possess the most adversarial networking environment due to the absence of fixed infrastructure, the nature of open transmission media and the dynamic network topology. These characteristics also make the design of routing protocols in MANETs become even more challenging. In this paper, we propose an evolutionary self-cooperative trust (ESCT) scheme that imitates human cognitive process and relies on trust-level information to prevent various routing disruption attacks. In this scheme, mobile nodes will exchange trust information and analyze received trust information based on their own cognitive judgment. Eventually, each node dynamically evolves its cognition to exclude malicious entities. The most attractive feature of ESCT is that they cannot compromise the system even if the internal attackers know how the security mechanism works. In this paper, we evaluate the performance of ESCT scheme under various routing disruption attack situations. Simulation results affirm that ESCT scheme promotes network scalability and ensures the routing effectiveness in the presence of routing disruption attackers in MANETs. © 2002-2012 IEEE.",black hole attack; gray hole attack; Mobile ad hoc network; trust based routing,Network routing; Network security; Technology transfer; Black hole attack; Dynamic network topology; Gray holes; Mobile ad-hoc network (MANETs); Network scalability; Networking environment; Security mechanism; trust based routing; Mobile ad hoc networks,,,,,"Perkins, C.E., Belding-Royer, E.M., Das, S.R., (2003) Ad Hoc on Demand Distance Vector Routing: IETF RFC 3561, , https://www.ietf.org/rfc/rfc3561.txt, Jul; Clausen, T., Jacquet, P., (2003) Optimized Link State Routing Protocol (OLSR): IETF RFC 3626, , https://www.ietf.org/rfc/rfc3626.txt, Oct; Johnson, D., Hu, Y., Maltz, D., (2007) The Dynamic Routing Protocol (DSR) for Mobile Ad Hoc Networks for IPv4: IETF RFC 4728, , Feb; Djenouri, D., Khelladi, L., Badache, A.N., A survey of security issues in mobile ad hoc and sensor networks (2005) IEEE Commun. Surveys Tutorials, 7, pp. 2-28; Nadeem, A., Howarth, M.P., A survey of MANET intrusion detection & prevention approaches for network layer attacks (2013) IEEE Commun. Surveys Tuts., 15, pp. 2027-2045; Wu, Y., Zhao, Y., Riguidel, M., Wang, G., Yi, P., Security and trust management in opportunistic networks: A survey (2015) Security Comm. Netw., 8, pp. 1812-1827; Yu, M., Leung, K.K., A Trustworthiness-based QoS routing protocol for wireless ad hoc networks (2009) IEEE Trans. Wireless Commun., 8, pp. 1888-1898. , Apr; Movahedi, Z., Hosseini, Z., Bayan, F., Pujolle, G., Trustdistortion resistant trust management frameworks on mobile ad hoc networks: A survey (2016) IEEE Commun. Surveys Tuts., 18, pp. 1287-1309. , Apr.-Jun; Djenouri, D., Badache, N., Struggling against selfishness and black hole attacks in MANETs (2008) Wireless Commun. Mobile Comput., 8, pp. 689-704; Chen, T., Zhu, L., Wu, F., Zhong, S., Stimulating cooperation in vehicular ad hoc networks: A coalitional game theoretic approach (2011) IEEE Trans. Vehicular Technol., 60, pp. 566-579. , Feb; Woungang, I., Dhurandher, S., Peddi, R., Traore, I., Mitigating collaborative blackhole attacks on DSR-based mobile ad hoc networks (2013) Found. Practice Security, 7743, pp. 308-323; Misra, S., Krishna, P.V., Bhiwal, A., Chawla, A., Wolfinger, B., Lee, C., A learning automata-based fault-tolerant routing algorithm for mobile ad hoc networks (2012) J. Supercomputing, 62, pp. 4-23; Pirzada, A.A., McDonald, C., Datta, A., Performance comparison of trust-based reactive routing protocols (2006) IEEE Trans. Mobile Comput., 5, pp. 695-710. , Jun; Pirzada, A.A., McDonald, C., Secure routing protocols for mobile ad-hoc wireless networks (2005) Advanced Wired and Wireless Networks, pp. 57-80. , Boston, MA, USA: Springer; Zapata, M.G., Asokan, N., Securing ad hoc routing protocols (2002) Proc. 1st ACM Workshop Wireless Security, pp. 1-10; Hu, Y.C., Perrig, A., Johnson, D.B., Ariadne: A secure ondemand routing protocol for ad hoc networks (2005) Wireless Netw., 11, pp. 21-38; Al-Karaki, J., Kamal, A., Stimulating node cooperation in mobile ad hoc networks (2008) Wireless Personal Commun., 44, pp. 219-239; Gong, W., You, Z., Chen, D., Zhao, X., Gu, M., Lam, K.-Y., Trust based routing for misbehavior detection in Ad hoc networks (2010) J. Netw., 5, pp. 551-558; Yan Lindsay, S., Wei, Y., Zhu, H., Liu, K.J.R., Information theoretic framework of trust modeling and evaluation for ad hoc networks (2006) IEEE J. Selected Areas Commun., 24, pp. 305-317. , Feb; Hoffman, K., Zage, D., Rotaru, C.N., A survey of attack and defense techniques for reputation systems (2009) ACM Comput. Surveys, 42, pp. 1-31; Buchegger, S., Boudec, J.Y.L., Performance analysis of the CONFIDANT protocol (2002) Proc. 3rd ACM Int. Symp. Mobile Ad Hoc Netw. Comput., pp. 226-236. , Jun; Zhong, S., Chen, J., Yang, Y.R., Sprite: A simple, cheat-proof, credit-based system for mobile ad-hoc networks (2003) Proc. IEEE INFOCOM03, pp. 1987-1997; Das, S.R., Perkins, C.E., Royer, E.M., Performance comparison of two on-demand routing protocols for ad hoc networks (2000) Proc. INFOCOM 19th Annu. Joint Conf. IEEE Comput. Commun. Societies., pp. 3-12; Yu, W., Sun, Y., Liu, K.J.R., HADOF: Defense against routing disruptions in mobile ad hoc networks (2005) Proc. IEEE 24th Ann. Joint Conf. IEEE Comput. Commun. Societies, pp. 1252-1261; Jøsang, A., A logic for uncertain probabilities (2001) Int. J. Uncertainty, Fuzziness Knowl.-Based Syst., 9, pp. 279-311; Koren, Y., Bell, R., Volinsky, C., Matrix factorization techniques for recommender systems (2009) Comput., 42, pp. 30-37; Zhou, P., Jiang, S., Irissappane, A., Zhang, J., Zhou, J., Teo, J.C.M., Toward energy-efficient trust system through watchdog optimization for WSNs (2015) IEEE Trans. Inf. Forensics Security, 10, pp. 613-625; Heinzelman, W.B., Chandrakasan, A.P., Balakrishnan, H., An application-specific protocol architecture for wireless microsensor networks (2002) IEEE Trans. Wireless Commun., 1, pp. 660-670; Attat, A., Tang, H., Vasilakos, A.V., Yu, F.R., Leung, V., A survey of security challenges in cognitive radio networks: Solutions and future research directions (2012) Proc. IEEE, 100, pp. 3172-3186; Conti, M., Giordano, S., Mobile ad hoc networking: Milestones, challenges, and new research directions (2014) IEEE Commun. Mag., 52, pp. 85-96","Chong, P.H.J.; Department of EEE, New Zealand; 电子邮件: peter.chong@aut.ac.nz",,,Institute of Electrical and Electronics Engineers Inc.,,,,,15361233,,,,English,IEEE Trans. Mob. Comput.,Article,Final,,Scopus,2-s2.0-85045997392
"Li Y., Wang Y.",56436141600;57204557051;,Defense against adversarial attacks in deep learning,2018,Applied Sciences (Switzerland),9,1,76,,,,6,10.3390/app9010076,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059125448&doi=10.3390%2fapp9010076&partnerID=40&md5=9c2ea9ba765515b77af6d9ae5ed342e4,"School of Control and Computer Engineering, North China Electric Power University, Beijing, 102206, China","Li, Y., School of Control and Computer Engineering, North China Electric Power University, Beijing, 102206, China; Wang, Y., School of Control and Computer Engineering, North China Electric Power University, Beijing, 102206, China","Neural networks are very vulnerable to adversarial examples, which threaten their application in security systems, such as face recognition, and autopilot. In response to this problem, we propose a new defensive strategy. In our strategy, we propose a new deep denoising neural network, which is called UDDN, to remove the noise on adversarial samples. The standard denoiser suffers from the amplification effect, in which the small residual adversarial noise gradually increases and leads to misclassification. The proposed denoiser overcomes this problem by using a special loss function, which is defined as the difference between the model outputs activated by the original image and denoised image. At the same time, we propose a new model training algorithm based on knowledge transfer, which can resist slight image disturbance and make the model generalize better around the training samples. Our proposed defensive strategy is robust against both white-box or black-box attacks. Meanwhile, the strategy is applicable to any deep neural network-based model. In the experiment, we apply the defensive strategy to a face recognition model. The experimental results show that our algorithm can effectively resist adversarial attacks and improve the accuracy of the model. © 2018 by the authors.",Adversarial attacks; Deep learning; Denoiser; Face recognition;Wasserstein generative adversarial networks (W-GAN); Knowledge transfer,,,,,,"Helmstaedter, M., Briggman, K.L., Turaga, S.C., Jain, V., Seung, H.S., Denk, W., Connectomic reconstruction of the inner plexiform layer in the mouse retina (2013) Nature, 500, pp. 168-174; Xiong, H.Y., Alipanahi, B., Lee, J.L., Bretschneider, H., Merico, D., Yuen, R.K., Morris, Q., The human splicing code reveals new insights into the genetic determinants of disease (2015) Science, 347; Ciodaro, T., Deva, D., de Seixas, J., Damazio, D., Online Particle Detection with Neural Networks Based on Topological Calorimetry Information (2012) Journal of physics: conference series, 368. , IOP Publishing: Bristol, UK; Ackerman, E., How Drive.ai Is Mastering Autonomous Driving with Deep Learning, , https://spectrum.ieee.org/cars-that-think/transportation/self-driving/how-driveai-is-masteringautonomous-driving-with-deep-learning, (accessed on 10 March 2017); Najafabadi, M.M., Villanustre, F., Khoshgoftaar, T.M., Seliya, N., Wald, R., Muharemagic, E., Deep learning applications and challenges in big data analytics (2015) J. Big Data, 2, p. 1; Middlehurst, C., (2015) China Unveils World's First Facial Recognition ATM, , http://www.telegraph.co.uk/news/worldnews/asia/china/11643314/China-unveils-worlds-firstfacial-recognition-ATM.html, accessed on 1 June 2017; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2014) Intriguing properties of neural networks, , arXiv; Goodfellow, I.J., Shlens, J., Szegedy, C., (2015) Explaining and Harnessing Adversarial Examples, , arXiv; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Proceedings of the IEEE European Symposium on Security and Privacy, , Saarbrucken, Germany, 21-24 March; Moosavi-Dezfooli, S.M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , Honolulu, HI, USA, 21-26 July; Siniscalchi, S.M., Salerno, V.M., Adaptation to new microphones using artificial neural networks with trainable activation functions (2017) IEEE Trans. Neural Netw. Learn. Syst, 28, pp. 1959-1965; Salerno, V.M., Rabbeni, G., An extreme learning machine approach to effective energy disaggregation (2018) Electronics, 7, p. 235; Dziugaite, G.K., Ghahramani, Z., Roy, D.M., (2016) A study of the effect of JPG compression on adversarial images, , arXiv; Luo, Y., Boix, X., Roig, G., Poggio, T., Zhao, Q., (2015) Foveation-based mechanisms alleviate adversarial examples, , arXiv; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., Adversarial Examples for Semantic Segmentation and Object Detection (2017), arXiv; Ross, A.S., Doshi-Velez, F., Improving the Adversarial Robustness and Interpretability of Deep Neural Networks by Regularizing their Input Gradients (2017), arXiv; Zhang, A., Wang, H., Li, S., Cui, Y., Liu, Z., Yang, G., Hu, J., Transfer Learning with Deep Recurrent Neural Networks for Remaining Useful Life Estimation (2018) Appl. Sci, 8, p. 2416; Nayebi, A., Ganguli, S., (2017) Biologically inspired protection of deep networks from adversarial attacks, , arXiv; Krotov, D., Hopfield, J.J., (2017) Dense Associative Memory is Robust to Adversarial Inputs, , arXiv; Cisse, M., Adi, Y., Neverova, N., Keshet, J., (2017) Houdini: Fooling deep structured prediction models, , arXiv; Gao, J., Wang, B., Lin, Z., Xu, W., Qi, Y., (2017) DeepCloak: Masking Deep Neural Network Models for Robustness Against Adversarial Samples, , arXiv; Akhtar, N., Liu, J., Mian, A., (2017) Defense against Universal Adversarial Perturbations, , arXiv; Lu, J., Issaranon, T., Forsyth, D., SafetyNet: Detecting and Rejecting Adversarial Examples Robustly (2017), arXiv; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., (2017) On Detecting Adversarial Perturbations, , arXiv; Li, X., Li, F., Adversarial Examples Detection in Deep Networks with Convolutional Filter Statistics (2017) Proceedings of the International Conference on Computer Vision, , Venice, Italy, 22-29 October; Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., (2017) On the (Statistical) Detection of Adversarial Examples, , arXiv; Liao, F., Liang, M., Dong, Y., Pang, T., Zhu, J., Hu, X., (2017) Defense against Adversarial Attacks Using High-Level Representation Guided Denoiser, , arXiv; Gu, S., Rigazio, L., (2015) Towards Deep Neural Network Architectures Robust to Adversarial Examples, , arXiv; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a Defense to Adversarial Perturbations against Deep Neural Networks (2016) Proceedings of the IEEE Symposium on Security and Privacy (SP), pp. 582-597. , San Jose, CA, USA, 22-26 May","Wang, Y.; School of Control and Computer Engineering, China; 电子邮件: 1162227078@ncepu.edu.cn",,,MDPI AG,,,,,20763417,,,,English,Appl. Sci.,Article,Final,"All Open Access, Gold, Green",Scopus,2-s2.0-85059125448
"Arnab A., Miksik O., Torr P.H.S.",57113566800;55064235900;56821543600;,On the Robustness of Semantic Segmentation Models to Adversarial Attacks,2018,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,,,8578197,888,897,,82,10.1109/CVPR.2018.00099,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062833643&doi=10.1109%2fCVPR.2018.00099&partnerID=40&md5=9569513733344ea7ccba1637dc8cf152,"University of Oxford, United Kingdom; Emotech Labs, United Kingdom","Arnab, A., University of Oxford, United Kingdom; Miksik, O., University of Oxford, United Kingdom, Emotech Labs, United Kingdom; Torr, P.H.S., University of Oxford, United Kingdom","Deep Neural Networks (DNNs) have been demonstrated to perform exceptionally well on most recognition tasks such as image classification and segmentation. However, they have also been shown to be vulnerable to adversarial examples. This phenomenon has recently attracted a lot of attention but it has not been extensively studied on multiple, large-scale datasets and complex tasks such as semantic segmentation which often require more specialised networks with additional components such as CRFs, dilated convolutions, skip-connections and multiscale processing. In this paper, we present what to our knowledge is the first rigorous evaluation of adversarial attacks on modern semantic segmentation models, using two large-scale datasets. We analyse the effect of different network architectures, model capacity and multiscale processing, and show that many observations made on the task of classification do not always transfer to this more complex task. Furthermore, we show how mean-field inference in deep structured models and multiscale processing naturally implement recently proposed adversarial defenses. Our observations will aid future efforts in understanding and defending against adversarial examples. Moreover, in the shorter term, we show which segmentation models should currently be preferred in safety-critical applications due to their inherent robustness. © 2018 IEEE.",,Complex networks; Computer vision; Deep neural networks; Large dataset; Network architecture; Safety engineering; Semantics; Complex task; Large-scale datasets; Multiscale processing; Rigorous evaluation; Safety critical applications; Segmentation models; Semantic segmentation; Structured model; Image segmentation,,,,,"Arnab, A., Jayasumana, S., Zheng, S., Torr, P.H.S., Higher order conditional random fields in deep neural networks (2016) ECCV; Arnab, A., Zheng, S., Jayasumana, S., Romera-Paredes, B., Larsson, M., Kirillov, A., Savchynskyy, B., Torr, P.H.S., Conditional random fields meet deep neural networks for semantic segmentation: Combining probabilistic graphical models with deep learning for structured prediction (2018) IEEE Signal Processing Magazine, 35 (1), pp. 37-52; Athalye, A., Sutskever, I., (2017) Synthesizing Robust Adversarial Examples; Badrinarayanan, V., Handa, A., Cipolla, R., (2015) Segnet: A Deep Convolutional Encoder-decoder Architecture for Robust Semantic Pixel-wise Labelling, , CoRR, abs/1505.07293; Barrow, H.G., Tenenbaum, J., (1981) Interpreting Line Drawings As Three-dimensional Surfaces; Biggio, B., Nelson, B., Laskov, P., Poisoning attacks against support vector machines (2012) ICML; Bilinski, P., Prisacariu, V., Dense decoder shortcut connections for single-pass semantic segmentation (2018) CVPR; Carbonetto, P., Freitas, N.D., Conditional mean field (2007) NIPS; Carlini, N., Wagner, D., (2016) Defensive Distillation Is Not Robust to Adversarial Examples; Carlini, N., Wagner, D., (2017) Adversarial examples are not easily detected: Bypassing ten detection methods; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy; Chalupka, K., Perona, P., Eberhardt, F., Visual causal feature learning (2015) UAI; Chandra, S., Kokkinos, I., Fast, exact and multi-scale inference for semantic image segmentation with deep Gaussian crfs (2016) ECCV; Chen, L.-C., Papandreou, G., Kokkinos, I., Murphy, K., Yuille, A.L., Semantic image segmentation with deep convolutional nets and fully connected crfs (2015) ICLR; Chen, L.-C., Papandreou, G., Kokkinos, I., Murphy, K., Yuille, A.L., (2016) Deeplab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected Crfs; Cisse, M., Adi, Y., Neverova, N., Keshet, J., Houdini: Fooling deep structured prediction models (2017) NIPS; Cisse, M., Bojanowski, P., Grave, E., Dauphin, Y., Usunier, N., Parseval networks: Improving robustness to adversarial examples (2017) ICML; Cordts, M., Omran, M., Ramos, S., Rehfeld, T., Enzweiler, M., Benenson, R., Franke, U., Schiele, B., The cityscapes dataset for semantic urban scene understanding (2016) CVPR; Dai, J., He, K., Sun, J., Boxsup: Exploiting bounding boxes to supervise convolutional networks for semantic segmentation (2015) ICCV; Dziugaite, G.K., Ghahramani, Z., Roy, D.M., (2016) A Study of the Effect of Jpg Compression on Adversarial Images; Esteva, A., Kuprel, B., Novoa, R.A., Ko, J., Swetter, S.M., Blau, H.M., Thrun, S., Dermatologist-level classification of skin cancer with deep neural networks (2017) Nature; Everingham, M., Van Gool, L., Williams, C.K., Winn, J., Zisserman, A., The pascal visual object classes (voc) challenge (2010) IJCV; Evtimov, I., Eykholt, K., Fernandes, E., Kohno, T., Li, B., Prakash, A., Rahmati, A., Song, D., (2017) Robust Physicalworld Attacks on Machine Learning Models; Fawzi, A., Frossard, P., Manitest: Are classifiers really invariant? (2015) BMVC; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting adversarial samples from artifacts; Fischer, V., Kumar, M.C., Metzen, J.H., Brox, T., Adversarial examples for semantic image segmentation (2017) ICLR Workshop; Forsyth, D.A., Malik, J., Fleck, M.M., Greenspan, H., Leung, T., Belongie, S., Carson, C., Bregler, C., (1996) Finding Pictures of Objects in Large Collections of Images, , Springer; Gao, J., Wang, B., Qi, Y., Deepmask: Masking dnn models for robustness against adversarial samples (2017) ICLR Workshop; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR; Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., (2017) On the (statistical) detection of adversarial examples; Gu, S., Rigazio, L., Towards deep neural network architectures robust to adversarial examples (2015) ICLR Workshop; Hariharan, B., Arbelaez, P., Bourdev, L., Maji, S., Malik, J., Semantic contours from inverse detectors (2011) ICCV; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) CVPR; He, W., Wei, J., Chen, X., Carlini, N., Song, D., (2017) Adversarial Example Defenses: Ensembles of Weak Defenses Are Not Strong.; Henriques, J.F., Vedaldi, A., Warped convolutions: Efficient invariance to spatial transformations (2017) ICML; Janai, J., Güney, F., Behl, A., Geiger, A., (2017) Computer Vision for Autonomous Vehicles: Problems, Datasets and State-ofthe-art.; Koh, P.W., Liang, P., Understanding black-box predictions via influence functions (2017) ICML; Krahenbuhl, P., Koltun, V., Efficient inference in fully connected CRFs with Gaussian edge potentials (2011) NIPS; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) NIPS; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2017) ICLR Workshop; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2017) ICLR; Lin, G., Shen, C., Reid, I., Efficient piecewise training of deep structured models for semantic segmentation (2016) CVPR; Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Dollar, P., Zitnick, C.L., Microsoft coco: Common objects in context (2014) ECCV; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) ICLR; Long, J., Shelhamer, E., Darrell, T., Fully convolutional networks for semantic segmentation (2015) CVPR; Lu, J., Sibai, H., Fabry, E., Forsyth, D., No need to worry about adversarial examples in object detection in autonomous vehicles (2017) CVPR Workshop; Lu, J., Sibai, H., Fabry, E., Forsyth, D., (2017) Standard Detectors Aren't (Currently) Fooled by Physical Adversarial Stop Signs.; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) ICLR; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., On detecting adversarial perturbations (2017) ICLR; Metzen, J.H., Kumar, M.C., Brox, T., Fischer, V., Universal adversarial perturbations against semantic image segmentation (2017) ICCV; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) CVPR; Murphy, K.P., (2012) Machine Learning: A Probabilistic Perspective, , MIT press; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Blackbox Attacks Using Adversarial Samples.; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, , ACM; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) IEEE Symposium on Security and Privacy; Paszke, A., Chaurasia, A., Kim, S., Culurciello, E., (2016) Enet: A Deep Neural Network Architecture for Real-time Semantic Segmentation.; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-ofthe-art face recognition (2016) Proceedings of the 23rd ACM SIGSAC Conference on Computer and Communications Security; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) ICLR; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) ICLR; Tramer, F., Kurakin, A., Papernot, N., Boneh, D., Mc-Daniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses.; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., Mitigating adversarial effects through randomization (2018) ICLR; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., Adversarial examples for semantic segmentation and object detection (2017) ICCV; Xu, W., Evans, D., Qi, Y., (2017) Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks.; Xu, X., Chen, X., Liu, C., Rohrbach, A., Darell, T., Song, D., (2017) Can You Fool Ai with Adversarial Examples on A Visual Turing Test?.; Yu, F., Koltun, V., Multi-scale context aggregation by dilated convolutions (2016) ICLR; Zhao, H., Qi, X., Shen, X., Shi, J., Jia, J., (2017) Icnet for Real-time Semantic Segmentation on High-resolution Images.; Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J., Pyramid scene parsing network (2017) CVPR; Zheng, S., Jayasumana, S., Romera-Paredes, B., Vineet, V., Su, Z., Du, D., Huang, C., Torr, P., Conditional random fields as recurrent neural networks (2015) ICCV",,,,IEEE Computer Society,"31st Meeting of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2018",18 June 2018 through 22 June 2018,,143811,10636919,9.78E+12,PIVRE,,English,Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85062833643
"Krotov D., Hopfield J.",57147760800;7005786187;,Dense associative memory is robust to adversarial inputs,2018,Neural Computation,30,12,,3151,3167,,22,10.1162/neco_a_01143,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057032370&doi=10.1162%2fneco_a_01143&partnerID=40&md5=c9b8b799a17514fe421605accbc1302d,"Institute for Advanced Study, Princeton, NJ  08540, United States; Princeton Neuroscience Institute, Princeton, NJ  08544, United States","Krotov, D., Institute for Advanced Study, Princeton, NJ  08540, United States; Hopfield, J., Princeton Neuroscience Institute, Princeton, NJ  08544, United States","Deep neural networks (DNNs) trained in a supervised way suffer from two known problems. First, the minima of the objective function used in learning correspond to data points (also known as rubbish examples or fooling images) that lack semantic similarity with the training data. Second, a clean input can be changed by a small, and often imperceptible for human vision, perturbation so that the resulting deformed input is misclassified by the network. These findings emphasize the differences between the ways DNNs and humans classify patterns and raise a question of designing learning algorithms that more accurately mimic human perception compared to the existing methods. Our article examines these questions within the framework of dense associative memory (DAM) models. These models are defined by the energy function, with higher-order (higher than quadratic) interactions between the neurons. We show that in the limit when the power of the interaction vertex in the energy function is sufficiently large, these models have the following three properties. First, the minima of the objective function are free from rubbish images, so that each minimum is a semantically meaningful pattern. Second, artificial patterns poised precisely at the decision boundary look ambiguous to human subjects and share aspects of both classes that are separated by that decision boundary. Third, adversarial images constructed by models with small power of the interaction vertex, which are equivalent to DNN with rectified linear units, fail to transfer to and fool the models with higher-order interactions. This opens up the possibility of using higher-order models for detecting and stopping malicious adversarial attacks. The results we present suggest that DAMs with higher-order energy functions are more robust to adversarial and rubbish inputs than DNNs with rectified linear units. © 2018 Massachusetts Institute of Technology.",,"Associative processing; Associative storage; Learning algorithms; Memory architecture; Semantics; Associative memory; Decision boundary; Energy functions; Higher-order models; Human perception; Interaction vertex; Objective functions; Semantic similarity; Deep neural networks; brain; human; pattern recognition; physiology; Brain; Humans; Neural Networks, Computer; Pattern Recognition, Visual",,,,,"Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and harnessing adversarial examples; Gu, S., Rigazio, L., (2014) Towards deep neural network architectures robust to adversarial examples; Huang, R., Xu, B., Schuurmans, D., Szepesvári, C., (2015) Learning with a strong adversary; Krotov, D., Hopfield, J.J., Dense associative memory for pattern recognition (2016) Advances in neural information processing systems, 29, pp. 1172-1180. , In D. D. Lee, N. Sugiyama, U. V. Luxburg, I. Guyon, & R. Garnett (Eds.) Red Hook, NY: Curran; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2016); Miyato, T., Maeda, S.-I., Koyama, M., Nakae, K., Ishii, S., (2015) Distributional smoothing with virtual adversarial training; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 427-436. , Piscataway, NJ: IEEE; Nøkland, A., (2015) Improving back-propagation by adding an adversarial gradient; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in machine learning: From phenomena to black-box attacks using adversarial samples; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., (2016) Practical black-box attacks against deep learning systems using adversarial examples; Simard, P.Y., Steinkraus, D., Platt, J.C., Best practices for convolutional neural networks applied to visual document analysis (2003) In Proceedings of the International Conference on Document Analysis and Recognition, pp. 958-962. , New York: ACM; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing properties of neural networks; Wang, Q., Guo, W., Zhang, K., Xing, X., Giles, C.L., Liu, X., (2016) Random feature nullification for adversary resistant deep architecture",,,,MIT Press Journals,,,,,8997667,,,30314425,English,Neural Comp.,Letter,Final,"All Open Access, Green",Scopus,2-s2.0-85057032370
"Yin M., Li X., Zhang Y., Wang S.",57202283732;7501701944;7601315649;55364979300;,When deep fool meets deep prior: Adversarial attack on super-resolution network,2018,MM 2018 - Proceedings of the 2018 ACM Multimedia Conference,,,,1930,1938,,6,10.1145/3240508.3240603,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058208532&doi=10.1145%2f3240508.3240603&partnerID=40&md5=c53b04645856ce57d2588312baa6fe5a,"Tsinghua University, China; City University of Hong Kong, Hong Kong","Yin, M., Tsinghua University, China; Li, X., Tsinghua University, China; Zhang, Y., Tsinghua University, China; Wang, S., City University of Hong Kong, Hong Kong","This paper investigates the vulnerability of the deep prior used in deep learning based image restoration. In particular, the image super-resolution, which relies on the strong prior information to regularize the solution space and plays important roles in the image pre-processing for future viewing and analysis, is shown to be vulnerable to the well-designed adversarial examples. We formulate the adversarial example generation process as an optimization problem, and given super-resolution model three different types of attack are designed based on the subsequent tasks: (i) style transfer attack; (ii) classification attack; (iii) caption attack. Another interesting property of our design is that the attack is hidden behind the super-resolution process, such that the utilization of low resolution images is not significantly influenced. We show that the vulnerability to adversarial examples could bring risks to the pre-processing modules such as super-resolution deep neural network, which is also of paramount significance for the security of the whole system. Our results also shed light on the potential security issues of the pre-processing modules, and raise concerns regarding the corresponding countermeasures for adversarial examples. © 2018 Association for Computing Machinery.",Adversarial attack; Caption; Deep prior; Image classification; Style transfer; Super-resolution,Image classification; Image reconstruction; Network security; Optical resolving power; Adversarial attack; Caption; Deep prior; Style transfer; Super resolution; Deep neural networks,,,,,"Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium on, pp. 39-57. , IEEE; Chen, H., Zhang, H., Chen, P.-Y., Yi, J., Hsieh, C.-J., (2017) Show-and-Fool: Crafting Adversarial Examples for Neural Image Captioning, , arXiv preprint 2017; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., ImageNet: A large-scale hierarchical image database (2009) Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on., pp. 248-255. , IEEE; Dong, C., Loy, C.C., He, K., Tang, X., Image super-resolution using deep convolutional networks (2016) IEEE Transactions on Pattern Analysis and Machine Intelligence, 38 (2), pp. 295-307. , 2016; Gatys, L.A., Ecker, A.S., Bethge, M., (2015) A Neural Algorithm of Artistic Style, , arXiv preprint 2015; Girshick, R., (2015) Fast R-Cnn, , arXiv preprint 2015; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint 2014; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of The IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Johnson, J., Alahi, A., Fei-Fei, L., Perceptual losses for real-time style transfer and super-resolution (2016) European Conference on Computer Vision, pp. 694-711. , Springer; Kim, J., Lee, J.K., Lee, K.M., Deeply-recursive convolutional network for image super-resolution (2016) Proceedings of The IEEE Conference on Computer Vision and Pattern Recognition, pp. 1637-1645; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Ledig, C., Theis, L., Huszár, F., Caballero, J., Cunningham, A., Acosta, A., Aitken, A., Wang, Z., (2016) Photo-Realistic Single Image Super-Resolution Using A Generative Adversarial Network, , arXiv preprint 2016; Lin, C.-Y., Rouge: A package for automatic evaluation of summaries (2004) Text Summarization Branches Out, , 2004; Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Dollár, P., Lawrence Zitnick, C., Microsoft coco: Common objects in context (2014) European Conference on Computer Vision, pp. 740-755. , Springer; Dezfooli, S.M.M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387. , IEEE; Papineni, K., Roukos, S., Ward, T., Zhu, W.-J., BLEU: A method for automatic evaluation of machine translation (2002) Proceedings of The 40th Annual Meeting on Association for Computational Linguistics, pp. 311-318. , Association for Computational Linguistics; Rozsa, A., Rudd, E.M., Boult, T.E., Adversarial diversity and hard positive generation (2016) Proceedings of The IEEE Conference on Computer Vision and Pattern Recognition Workshops, pp. 25-32; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proceedings of The 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540. , ACM; Shi, W., Caballero, J., Huszár, F., Totz, J., Aitken, A.P., Bishop, R., Rueckert, D., Wang, Z., Real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network (2016) Proceedings of The IEEE Conference on Computer Vision and Pattern Recognition, pp. 1874-1883; Sutskever, I., Vinyals, O., Le, Q.V., Sequence to sequence learning with neural networks (2014) Advances in Neural Information Processing Systems, pp. 3104-3112; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint 2013; Tabacof, P., Tavares, J., Valle, E., (2016) Adversarial Images for Variational Autoencoders, , arXiv preprint 2016; Vedantam, R., Lawrence Zitnick, C., Parikh, D., CiDer: Consensus-based image description evaluation (2015) Proceedings of The IEEE Conference on Computer Vision and Pattern Recognition, pp. 4566-4575; Vinyals, O., Toshev, A., Bengio, S., Erhan, D., Show and tell: A neural image caption generator (2015) Computer Vision and Pattern Recognition (CVPR), 2015 IEEE Conference on, pp. 3156-3164. , IEEE; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., Adversarial examples for semantic segmentation and object detection (2017) International Conference on Computer Vision, , IEEE; Xu, K., Ba, J., Kiros, R., Cho, K., Courville, A., Salakhudinov, R., Zemel, R., Bengio, Y., Show, attend and tell: Neural image caption generation with visual attention (2015) International Conference on Machine Learning, pp. 2048-2057; Xu, X., Chen, X., Liu, C., Rohrbach, A., Darell, T., Song, D., (2017) Can You Fool AI with Adversarial Examples on A Visual Turing Test?, , arXiv preprint 2017; Yuan, X., He, P., Zhu, Q., Bhat, R.R., Li, X., (2017) Adversarial Examples: Attacks and Defenses for Deep Learning, , arXiv preprint 2017; Zhang, Y., Zhang, Y., Zhang, J., Dai, Q., CCR: Clustering and collaborative representation for fast single image super-resolution (2016) IEEE Transactions on Multimedia, 18 (3), pp. 405-417. , 2016; Zhang, Y., Zhang, Y., Zhang, J., Xu, D., Fu, Y., Wang, Y., Ji, X., Dai, Q., Collaborative representation cascade for single-image super-resolution (2017) IEEE Transactions on Systems, Man, and Cybernetics: Systems, , 2017; Zhao, Z., Dua, D., Singh, S., (2017) Generating Natural Adversarial Examples, , arXiv preprint 2017",,,ACM SIGMM,"Association for Computing Machinery, Inc","26th ACM Multimedia conference, MM 2018",22 October 2018 through 26 October 2018,,142036,,9.78E+12,,,English,MM - Proc. ACM Multimed. Conf.,Conference Paper,Final,,Scopus,2-s2.0-85058208532
"Ye G., Tang Z., Fang D., Zhu Z., Feng Y., Xu P., Chen X., Wang Z.",57193613039;15822992800;8975043000;57200340512;55387599700;56672326500;8317069000;35111811300;,Yet another text CAPTCHA solver: A generative adversarial network based approach,2018,Proceedings of the ACM Conference on Computer and Communications Security,,,,332,348,,50,10.1145/3243734.3243754,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056867234&doi=10.1145%2f3243734.3243754&partnerID=40&md5=8d439e3241b96067a3e883eaa157c406,"Northwest University, China; Peking University, China; Lancaster University, United Kingdom","Ye, G., Northwest University, China; Tang, Z., Northwest University, China; Fang, D., Northwest University, China; Zhu, Z., Peking University, China; Feng, Y., Peking University, China; Xu, P., Northwest University, China; Chen, X., Northwest University, China; Wang, Z., Lancaster University, United Kingdom","Despite several attacks have been proposed, text-based CAPTCHAs1 are still being widely used as a security mechanism. One of the reasons for the pervasive use of text captchas is that many of the prior attacks are scheme-specific and require a labor-intensive and time-consuming process to construct. This means that a change in the captcha security features like a noisier background can simply invalid an earlier attack. This paper presents a generic, yet effective text captcha solver based on the generative adversarial network. Unlike prior machine-learning-based approaches that need a large volume of manually-labeled real captchas to learn an effective solver, our approach requires significantly fewer real captchas but yields much better performance. This is achieved by first learning a captcha synthesizer to automatically generate synthetic captchas to learn a base solver, and then fine-tuning the base solver on a small set of real captchas using transfer learning. We evaluate our approach by applying it to 33 captcha schemes, including 11 schemes that are currently being used by 32 of the top-50 popular websites including Microsoft, Wikipedia, eBay and Google. Our approach is the most capable attack on text captchas seen to date. It outperforms four state-of-the-art text-captcha solvers by not only delivering a significant higher accuracy on all testing schemes, but also successfully attacking schemes where others have zero chance. We show that our approach is highly efficient as it can solve a captcha within 0.05 second using a desktop GPU. We demonstrate that our attack is generally applicable because it can bypass the advanced security features employed by most modern text captcha schemes. We hope. © 2018 Association for Computing Machinery.",Deep learning; Generative adversarial networks; Text-based CAPTCHAs; Transfer learning,Deep learning; Network security; Security systems; Adversarial networks; CAPTCHAs; Labor intensive; Security features; Security mechanism; State of the art; Testing schemes; Transfer learning; Electronic mail filters,,,,,"Are You A Human, , https://www.areyouahuman.com/; Nucaptcha, , www.nucaptcha.com/; Athanasopoulos, E., Antonatos, S., Enhanced captchas: Using animation to tell humans and computers apart (2006) IFIP International Conference on Communications and Multimedia Security, pp. 97-108; Audet, C., Mesh, J.E.D., Jr., Mesh adaptive direct search algorithms for constrained optimization (2006) Siam Journal on Optimization, 17 (1), pp. 188-217; Barreno, M., Nelson, B., Sears, R., Joseph, A.D., Tygar, J.D., Can machine learning be secure? (2006) ACM Symposium on Information, Computer and Communications Security, pp. 16-25; Bigham, J.P., Cavender, A.C., Evaluating existing audio captchas and an interface optimized for non-visual use (2009) Sigchi Conference on Human Factors in Computing Systems, pp. 1829-1838; Bursztein, E., How We Broke The Nucaptcha Video Scheme and What We Proposed to Fix It, , https://elie.net/blog/security/how-we-broke-the-nucaptcha-video-scheme-and-what-we-propose-to-fix-it; Bursztein, E., Aigrain, J., Moscicki, A., Mitchell, J.C., The end is nigh: Generic solving of text-based captchas (2014) USENIX WOOT; Bursztein, E., Bethard, S., DecapTCHA: Breaking 75% of ebay audio captchas (2009) Usenix Conference on Offensive Technologies, p. 8; Bursztein, E., Martin, M., Mitchell, J., Text-based captcha strengths and weaknesses (2011) CCS, pp. 125-138; Chellapilla, K., Larson, K., Simard, P.Y., Czerwinski, M., Computers beat humans at single character recognition in reading based human interaction proofs (hips) (2005) Conference on Email & Anti-Spam; Chow, R., Golle, P., Jakobsson, M., Wang, L., Wang, X., Making captchas clickable (2008) Proceedings of The 9th Workshop on Mobile Computing Systems and Applications, pp. 91-94. , ACM; Elson, J., Douceur, J.R., Howell, J., Saul, J., Asirra:a captcha that exploits interest-aligned manual image categorization (2007) ACM Conference on Computer and Communications Security, CCS 2007, pp. 366-374. , Alexandria, Virginia, Usa, October; Pix2Pix: Image-to-Image Translation with Conditional Adversarial Networks, , https://github.com/phillipi/pix2pix, et al., I; Gao, H., Tang, M., Liu, Y., Zhang, P., Liu, X., Research on the security of microsoftars two-layer captcha (2017) IEEE Transactions on Information Forensics & Security, 12 (7), pp. 1671-1685; Gao, H., Wei, W., Wang, X., Liu, X., Yan, J., The robustness of hollow captchas (2013) ACM Sigsac Conference on Computer & Communications Security, pp. 1075-1086; Gao, H., Yan, J., Cao, F., Zhang, Z., Lei, L., Tang, M., Zhang, P., Li, J., A simple generic attack on text captchas (2016) NDSS; Gao, S., (2014) An Evolutionary Study of Dynamic Cognitive Game Captchas: Automated Attacks and Defenses, , Dissertations & Theses Gradworks; George, D., Lehrach, W., Kansky, K., Llczaro-Gredilla, M., Laan, C., Marthi, B., Lou, X., Wang, H., A generative vision model that trains with high data efficiency and breaks text-based captchas (2017) Science, p. eaag2612; Gold, C., Holub, A., Sollich, P., Bayesian approach to feature selection and parameter tuning for support vector machine classifiers (2005) Neural Networks, 18 (5), pp. 693-701; Goodfellow, I.J., Bulatov, Y., Ibarz, J., Arnoud, S., Shet, V., Multi-digit number recognition from street view imagery using deep convolutional neural networks (2014) International Conference on Learning Representations (ICLR); Goodfellow, I.J., Pougetabadie, J., Mirza, M., Xu, B., Wardefarley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial networks (2014) Advances in Neural Information Processing Systems, 3, pp. 2672-2680; Goodfellow, I.J., Shlens, J., Szegedy, C., Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICML, pp. 1-10; Gossweiler, R., Kamvar, M., Baluja, S., What’s up captcha?:a captcha based on image orientation (2009) International Conference on World Wide Web, WWW 2009, pp. 841-850. , Madrid, Spain, April; Greg, M., Malik, J., Recognizing objects in adversarial cultter: Breaking a visual captcha (2003) IEEE Computer Society Conferene on Computer Vision and Pattern Recognition; He, K., Gkioxari, G., Dollár, P., Girshick, R., Mask, R.-C.N.N., (2017) IEEE International Conference on Computer Vision (ICCV), pp. 2980-2988; He, K., Zhang, X., Ren, S., Sun, J., Deep Residual Learning for Image Recognition, pp. 770-778; Hecht-Nielsen, R., (1989) Theory of The Backpropagation Neural Network, , Harcourt Brace & Co; Hernandezcastro, C.J., Ribagorda, A., Saez, Y., Side-channel attack on labeling captchas (2009) Computer Science; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I.P., Tygar, J.D., Adversarial machine learning (2011) IEEE Internet Computing, 15 (5), pp. 4-6; Isola, P., Zhu, J.-Y., Zhou, T., Efros, A.A., (2016) Image-to-Image Translation with Conditional Adversarial Networks, , arxiv; Strong Captcha Guidelines V1. 2, , J, W; Jiang, Z., Zhao, J., Li, X.-Y., Han, J., Xi, W., Rejecting the attack: Source authentication for wi-fi management frames using csi information (2013) IEEE INFOCOM, pp. 2544-2552; Kingma, D.P., Ba, J., ADaM: A method for stochastic optimization (2014) Computer Science; Krol, K., Parkin, S., Sasse, M.A., Better the devil you know: A user study of two captchas and a possible replacement technology (2016) NDSS Workshop on Usable Security; Le, T.A., Baydin, A.G., Zinkov, R., Wood, F., Using synthetic data to train neural networks is model-based reasoning (2017) International Joint Conference on Neural Networks, pp. 3514-3521; Lea, C., Vidal, R., Reiter, A., Hager, G.D., Temporal convolutional networks: A unified approach to action segmentation (2016) European Conference on Computer Vision, pp. 47-54; Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proceedings of The IEEE, 86 (11), pp. 2278-2324; Li, J., Monroe, W., Shi, T., Jean, S., Ritter, A., Jurafsky, D., Adversarial Learning for Neural Dialogue Generation; Meutzner, H., Kolossa, D., Reducing the cost of breaking audio captchas by active and semi-supervised learning (2014) International Conference on Machine Learning and Applications, pp. 67-73; Miyato, T., Maeda, S., Koyama, M., Nakae, K., Ishii, S., (2015) Distributional Smoothing by Virtual Adversarial Examples, , arXiv; Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D., Riedmiller, M., (2013) Playing Atari with Deep Reinforcement Learning, , arXiv; Mohamed, M., Sachdeva, N., Georgescu, M., Gao, S., Saxena, N., Zhang, C., Kumaraguru, P., Chen, W.B., A three-way investigation of a game-captcha:automated attacks, relay attacks and usability (2014) ACM Symposium on Information, Computer and Communications Security, pp. 195-206; Mohameda, M., Gaob, S., Sachdevac, N., Saxena, N., Zhangd, C., Kumaraguruc, P., Oorschote, P.C.V., On the security and usability of dynamic cognitive game captchas (2017) Journal of Computer Security, pp. 1-26; Ogilvie, W.F., Petoumenos, P., Wang, Z., Leather, H., Fast automatic heuristic construction using active learning (2014) International Workshop on Languages and Compilers for Parallel Computing, pp. 146-160; Ogilvie, W.F., Petoumenos, P., Wang, Z., Leather, H., Minimizing the cost of iterative compilation with active learning (2017) Proceedings of The 2017 International Symposium on Code Generation and Optimization, pp. 245-256. , CGO’17; Osadchy, M., Hernandez-Castro, J., Gibson, S., Dunkelman, O., Plerez-Cabo, D., No bot expects the deepcaptcha! Introducing immutable adversarial examples, with applications to captcha generation (2017) IEEE Transactions on Information Forensics & Security PP, 99, p. 1; Pan, S.J., Yang, Q., A survey on transfer learning (2010) IEEE Transactions on Knowledge & Data Engineering, 22 (10), pp. 1345-1359; Rosenberg, I., Shabtai, A., Rokach, L., Elovici, Y., (2017) Generic Black-Box End-to-End Attack Against Rnns and Other Api Calls Based Malware Classifiers, , arXiv; Schlaikjer, A., A dual-use speech captcha: Aiding visually impaired web users while providing transcriptions of audio streams (2010) LTI; Shahzad, M., Liu, A.X., Samuel, A., Behavior based human authentication on touch screen devices using gestures and signatures (2017) IEEE Transactions on Mobile Computing, 16 (10), pp. 2726-2741; Shrivastava, A., Pfister, T., Tuzel, O., Susskind, J., Wang, W., Webb, R., Learning from simulated and unsupervised images through adversarial training (2017) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2014) Computer Science; Sivakorn, S., Polakis, I., Keromytis, A.D., I am robot: (deep) learning to break semantic image captchas (2016) IEEE European Symposium on Security and Privacy, pp. 388-403; Stark, F., Hazirbas, C., Triebel, R., Cremers, D., Captcha recognition with active deep learning (2015) German Conference on Pattern Recognition Workshop; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2015) Computer Science, pp. 2818-2826; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2013) Computer Science; Tam, J., Simsa, J., Hyde, S., Ahn, L.V., Breaking audio captchas (2008) Conference on Neural Information Processing Systems, pp. 1625-1632. , Vancouver, British Columbia, Canada, December; Von Ahn, L., Blum, M., Hopper, N.J., Langford, J., (2003) CAPTCHA: Using Hard AI Problems for Security, , Springer Berlin Heidelberg; Von Ahn, L., Blum, M., Langford, J., Telling humans and computers apart automatically (2004) Communications of The Acm, 47 (2), pp. 56-60; Xu, W., Qi, Y., Evans, D., Automatically evading classifiers: A case study on pdf malware classifiers (2016) Network and Distributed System Security Symposium; Xu, Y., Reynaga, G., Chiasson, S., Frahm, J.-M., Monrose, F., Van Oorschot, P.C., Security analysis and related usability of motion-based captchas: Decoding codewords in motion (2014) IEEE Transactions on Dependable and Secure Computing, 11 (5), pp. 480-493; Yan, J., Ahmad, A.S.E., Breaking visual captchas with naive pattern recognition algorithms (2007) Computer Security Applications Conference, 2007. ACSAC 2007. Twenty-Third Annual, pp. 279-291; Yan, J., Ahmad, A.S.E., A low-cost attack on a microsoft captcha (2008) ACM Conference on Computer and Communications Security, CCS 2008, pp. 543-554. , Alexandria, Virginia, Usa, October; Yosinski, J., Clune, J., Bengio, Y., Lipson, H., How transferable are features in deep neural networks? (2014) Advances in Neural Information Processing Systems, pp. 3320-3328; Yu, L., Zhang, W., Wang, J., Yu, Y., Seqgan: Sequence Generative Adversarial Nets with Policy Gradient; Zhu, J.-Y., Park, T., Isola, P., Efros, A.A., (2017) Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks, , arXiv preprint","Tang, Z.; Northwest UniversityChina; 电子邮件: zytang@nwu.edu.cn",,ACM SIGSAC,Association for Computing Machinery,"25th ACM Conference on Computer and Communications Security, CCS 2018",15-Oct-18,,141172,15437221,9.78E+12,,,English,Proc ACM Conf Computer Commun Secur,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85056867234
"Bayatbabolghani F., Blanton M.",57191288110;11339505700;,Secure multi-party computation,2018,Proceedings of the ACM Conference on Computer and Communications Security,,,,2157,2159,,6,10.1145/3243734.3264419,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056855668&doi=10.1145%2f3243734.3264419&partnerID=40&md5=68411c4fde8e46731dbed4ae301277cc,"School of Information, University of California, Berkeley, United States; Department of Computer Science and Engineering, University at Buffalo, The State University of New York, United States","Bayatbabolghani, F., School of Information, University of California, Berkeley, United States; Blanton, M., Department of Computer Science and Engineering, University at Buffalo, The State University of New York, United States","Secure multi-party computation (SMC) is an emerging topic which has been drawing growing attention during recent decades. There are many examples which show importance of SMC constructions in practice, such as privacy-preserving decision making and machine learning, auctions, private set intersection, and others. In this tutorial, we provide a comprehensive coverage of SMC techniques, starting from precise definitions and fundamental techniques. Consequently, a significant portion of the tutorial focuses on recent advances in general SMC constructions. We cover garbled circuit evaluation (GCE) and linear secret sharing (LSS) which are commonly used for secure two-party and multi-party computation, respectively. The coverage includes both standard adversarial models: semi-honest and malicious. For GCE, we start with the original Yao’s garbled circuits construction [30] for semi-honest adversaries and consequently cover its recent optimizations such as the “free XOR,” the garbled row reduction, the half-gates optimization, and the use of AES NI techniques. We follow with a discussion of techniques for making GCE resilient to malicious behavior, which includes the cut-and-choose approach and additional techniques to deter known attacks in the presence of malicious participants. In addition, we include the-state-of-the-art protocols for oblivious transfer (OT) and OT extension in the presence of semi-honest and malicious users. For LSS, we start from standard solutions for the semi-honest adversarial model including [5, 28] and consequently move to recent efficient constructions for semi-honest and malicious adversarial models. The coverage includes different types of corruption thresholds (with and without honest majority), which imply different guarantees with respect to abort. © 2018 Copyright held by the owner/author(s).",,Decision making; Learning systems; Efficient construction; Linear secret sharing; Malicious participant; Multiparty computation; Precise definition; Secure multi-party computation; Semi-honest adversaries; State-of-the art protocols; Cryptography,,,,,"Asharov, G., Lindell, Y., Rabin, T., Perfectly-Secure Multiplication for Any t < n/3 (2011) CRYPTO, pp. 240-258; Asharov, G., Lindell, Y., Schneider, T., Zohner, M., More Efficient Oblivious Transfer and Extensions for Faster Secure Computation (2013) ACM Conference on Computer and Communications Security (CCS), pp. 535-548; Asharov, G., Lindell, Y., Schneider, T., Zohner, M., More Efficient Oblivious Transfer Extensions with Security for Malicious Adversaries (2015) EUROCRYPT, pp. 673-701; Bellare, M., Hoang, V., Keelveedhi, S., Rogaway, P., Efficient Garbling from a Fixed-Key Blockcipher (2013) IEEE Symposium on Security and Privacy (S&P), pp. 478-492; Blakley, G.R., Safeguarding Cryptographic Keys (1979) National Computer Conference, 48, pp. 313-317; Bogdanov, D., Laur, S., Willemson, J., Sharemind: A Framework for Fast Privacy-Preserving Computations (2008) European Symposium on Research in Computer Security (ESORICS), pp. 192-206; Damgård, I., Geisler, M., Krøigaard, M., Nielsen, J.B., Asynchronous Multiparty Computation: Theory and Implementation (2009) International Workshop on Public Key Cryptography (PKC), pp. 160-179; Damgård, I., Ishai, Y., Krøigaard, M., Perfectly Secure Multiparty Computation and the Computational Overhead of Cryptography (2010) EUROCRYPT, pp. 445-465; Damgård, I., Keller, M., Larraia, E., Pastro, V., Scholl, P., Smart, N.P., Practical Covertly Secure MPC for Dishonest Majority–Or: Breaking the SPDZ Limits (2013) European Symposium on Research in Computer Security (ESORICS), pp. 1-18; Damgård, I., Nielsen, J.B., Scalable and Unconditionally Secure Multiparty Computation (2007) CRYPTO, pp. 572-590; Damgård, I., Pastro, V., Smart, N., Zakarias, S., Multiparty Computation from Somewhat Homomorphic Encryption (2012) CRYPTO, pp. 643-662; Gennaro, R., Rabin, M., Rabin, T., Simplified VSS and Fast-Track Multiparty Computations with Applications to Threshold Cryptography (1998) ACM Symposium on Principles of Distributed Computing (PODC), pp. 101-111; Goldreich, O., Micali, S., Wigderson, A., Proofs that Yield Nothing but their Validity or All Languages in NP Have Zero-Knowledge Proof Systems (1991) J. ACM, 38 (3), pp. 690-728. , 1991; Goldwasser, S., Micali, S., Wigderson, A., How to Play Any Mental Game, or a Completeness Theorem for Protocols with an Honest Majority (1987) ACM Symposium on The Theory of Computing (STOC), pp. 218-229; Holzer, A., Franz, M., Katzenbeisser, S., Veith, H., Secure Two-Party Computations in ANSI C (2012) AMC Conference on Computer and Communications Security (CCS), pp. 772-783; Ishai, Y., Kilian, J., Nissim, K., Petrank, E., Extending Oblivious Transfers Efficiently (2003) CRYPTO, pp. 145-161; Keller, M., Pastro, V., Rotaru, D., Overdrive: Making SPDZ Great Again (2018) EUROCRYPT, pp. 158-189; Kiraz, M., (2008) Secure and Fair Two-Party Computation, , Ph.D. Dissertation. Technische Universiteit Eindhoven; Kiraz, M., Schoenmakers, B., A Protocol Issue for the Malicious Case of Yao’s Garbled Circuit Construction (2006) Symposium on Information Theory in The Benelux, pp. 283-290; Kolesnikov, V., Schneider, T., Improved Garbled Circuit: Free XOR Gates and Applications (2008) International Colloquium on Automata, Languages, and Programming (ICALP), pp. 486-498; Kreuter, B., Shelat, A., Shen, C.H., Billion-Gate Secure Computation with Malicious Adversaries (2012) USENIX Security Symposium, pp. 285-300; Lindell, Y., Fast Cut-and-Choose Based Protocols for Malicious and Covert Adversaries (2013) CRYPTO, pp. 1-17; Lindell, Y., Pinkas, B., An Efficient Protocol for Secure Two-Party Computation in the Presence of Malicious Adversaries (2007) EUROCRYPT, pp. 52-78; Liu, C., Wang, X.S., Nayak, K., Huang, Y., Shi, E., ObliVM: A Programming Framework for Secure Computation (2015) IEEE Symposium on Security and Privacy (S&P), pp. 359-376; Mohassel, P., Franklin, M., Efficiency Tradeoffs for Malicious Two-Party Computation (2006) International Workshop on Public Key Cryptography (PKC), pp. 458-473; Naor, M., Pinkas, B., Efficient Oblivious Transfer Protocols (2001) ACM-SIAM Symposium on Discrete Algorithms (SODA), pp. 448-457; Pinkas, B., Schneider, T., Smart, N.P., Williams, S.C., Secure Two-Party Computation is Practical (2009) ASIACRYPT, pp. 250-267; Shamir, A., How to Share a Secret (1979) Commun. ACM, 22 (11), pp. 612-613. , 1979; Shelat, A., Shen, C., Two-Output Secure Computation with Malicious Adversaries (2011) EUROCRYPT, pp. 386-405; Yao, A.C., How to Generate and Exchange Secrets (1986) IEEE Symposium on Foundations of Computer Science (FOCS), pp. 162-167; Zahur, S., Evans, D., Obliv-C: A Language for Extensible Data-Oblivious Computation (2015) IACR Cryptology ePrint Archive Report 2015/1153, , 2015; Zahur, S., Rosulek, M., Evans, D., Two Halves Make a Whole: Reducing Data Transfer in Garbled Circuits Using Half Gates (2015) EUROCRYPT, pp. 220-250; Zhang, Y., Blanton, M., Bayatbabolghani, F., Enforcing Input Correctness via Certification in Garbled Circuit Evaluation (2017) European Symposium on Research in Computer Security (ESORICS), pp. 552-569; Zhang, Y., Steele, A., Blanton, M., PICCO: A General-Purpose Compiler for Private Distributed Computation (2013) ACM Conference on Computer and Communications Security (CCS), pp. 813-826",,,ACM SIGSAC,Association for Computing Machinery,"25th ACM Conference on Computer and Communications Security, CCS 2018",15-Oct-18,,141172,15437221,9.78E+12,,,English,Proc ACM Conf Computer Commun Secur,Conference Paper,Final,,Scopus,2-s2.0-85056855668
"Papadis N., Borst S., Walid A., Grissa M., Tassiulas L.",57195963896;7005829058;25723889900;57188694948;36562504600;,Stochastic Models and Wide-Area Network Measurements for Blockchain Design and Analysis,2018,Proceedings - IEEE INFOCOM,2018-April,,8485982,2546,2554,,35,10.1109/INFOCOM.2018.8485982,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056184044&doi=10.1109%2fINFOCOM.2018.8485982&partnerID=40&md5=21fcab7b67a570ac5a2d4233daf0819d,"Department of Electrical Engineering and Yale Institute for Network Science, Yale University, New Haven, CT  06520, United States; Nokia Bell Labs, Murray Hill, NJ  07974, United States","Papadis, N., Department of Electrical Engineering and Yale Institute for Network Science, Yale University, New Haven, CT  06520, United States; Borst, S., Nokia Bell Labs, Murray Hill, NJ  07974, United States; Walid, A., Nokia Bell Labs, Murray Hill, NJ  07974, United States; Grissa, M., Nokia Bell Labs, Murray Hill, NJ  07974, United States; Tassiulas, L., Department of Electrical Engineering and Yale Institute for Network Science, Yale University, New Haven, CT  06520, United States","The Blockchain paradigm provides a popular mechanism for establishing trust and consensus in distributed environments. While Blockchain technology is currently primarily deployed in crypto-currency systems like Bitcoin, the concept is also expected to emerge as a key component of the Internet-of-Things (IoT), enabling novel applications in digital health, smart energy, asset tracking and smart transportation. As Blockchain networks evolve to industrial deployments with large numbers of geographically distributed nodes, the block transfer and processing delays arise as a critical issue which may create greater potential for forks and vulnerability to adversarial attacks. Motivated by these issues, we develop stochastic network models to capture the Blockchain evolution and dynamics and analyze the impact of the block dissemination delay and hashing power of the member nodes on Blockchain performance in terms of the overall block generation rate and required computational power for launching a successful attack. The results provide useful insight in crucial design issues, e.g., how to adjust the 'difficulty-of-work' in the presence of delay so as to achieve a target block generation rate or appropriate level of immunity from adversarial attacks. We employ a combination of analytical calculations and simulation experiments to investigate both stationary and transient performance features, and demonstrate close agreement with measurements on a wide-area network testbed running the Ethereum protocol. © 2018 IEEE.",,Blockchain; Electronic money; Internet of things; Stochastic models; Stochastic systems; Analytical calculation; Computational power; Distributed environments; Industrial deployment; Internet of thing (IOT); Smart transportations; Stochastic network models; Transient performance; Wide area networks,,,,,"Bahack, L., (2013) Theoretical Bitcoin Attacks with Less Than Half of the Computational Power, , https://arxiv.org/pdf/1312.7013.pdf; Bamert, T., Decker, C., Elsen, L., Welten, S., Wattenhofer, R., Have A snack, pay with Bitcoin (2013) Proc. 13th IEEE Int. Conf. Peer-to-Peer Comput; Berman, M., Chase, J.S., Landweber, L., Nakao, A., Ott, M., Raychaudhuri, D., Ricci, R., Seskar, I., GENI: A federated testbed for innovative network experiments (2014) Computer Networks, 61, pp. 5-23; https://coinmarketcap.com/, Cap; Christidis, K., Devetsikiotis, M., Blockchains and smart contracts for the Internet-of-Things (2016) IEEE Access, 4, pp. 2292-2303; Decker, C., Wattenhofer, R., Information propagation in the Bitcoin network (2013) Proc. 13th IEEE Int. Conf. Peer-to-Peer Comput; Ethereum Network Status, , https://ethstats.net/, Accessed: 07/27/2017; Eyal, I., Sirer, E.G., Majority is not enough: Bitcoin mining is vulnerable (2013) Financial Cryptography and Data Security, pp. 436-454. , Springer; GENI: Global Environment for Networking Innovation, , http://www.geni.net, Accessed: 07/27/2017; Geth, , https://github.com/ethereum/go-ethereum/, Accessed: 07/27/2017; Göbel, J., Keeler, H.P., Krzesinski, A.E., Taylor, P.G., Bitcoin Blockchain dynamics: The selfish-mine strategy in the presence of propagation delay (2016) Perf. Eval., 104, pp. 23-41; Karame, G.O., Androulaki, E., Capkun, S., Two bitcoins at the price of one Double-spending attacks on fast payments in Bitcoin (2012) Proc. Conf. Comp. Commun. Security; Kraft, D., Difficulty control for Blockchain-based consensus systems (2016) Peer-to-Peer Netw. Appl., 9, pp. 397-413; Linn, L.A., Koo, M.B., Blockchain for health data and its potential use in health IT and health care related Research (2016) Use of Blockchain for Healthcare and Research Workshop; Nakamoto, S., (2008) Bitcoin: A Peer-to-peer Electronic Cash System, , https://bitcoin.org/bitcoin.pdf; Rosenfeld, M., (2014) Analysis of Hashrate-based Double-spending, , https://arxiv.org/pdf/1402.2009.pdf; Sompolinsky, Y., Zohar, A., Accelerating Bitcoin's transaction processing (2013) Fast Money Grows on Trees, Not Chains, , https://eprint.iacr.org/2013/881.pdf; Wood, G., Ethereum: A secure decentralised generalised transaction ledger (2014) Ethereum Project Yellow Paper, p. 151. , http://gavwood.com/paper.pdf",,,Huawei Technologies,Institute of Electrical and Electronics Engineers Inc.,"2018 IEEE Conference on Computer Communications, INFOCOM 2018",15 April 2018 through 19 April 2018,,140725,0743166X,9.78E+12,PINFE,,English,Proc IEEE INFOCOM,Conference Paper,Final,,Scopus,2-s2.0-85056184044
"Kim J.-Y., Bu S.-J., Cho S.-B.",56526721100;57194697819;7404884741;,Zero-day malware detection using transferred generative adversarial networks based on deep autoencoders,2018,Information Sciences,460-461,,,83,102,,83,10.1016/j.ins.2018.04.092,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047653335&doi=10.1016%2fj.ins.2018.04.092&partnerID=40&md5=d5924513cf666f6302e56d071c6f11b9,"Department of Computer Science, Yonsei University, Seoul, South Korea","Kim, J.-Y., Department of Computer Science, Yonsei University, Seoul, South Korea; Bu, S.-J., Department of Computer Science, Yonsei University, Seoul, South Korea; Cho, S.-B., Department of Computer Science, Yonsei University, Seoul, South Korea","Detecting malicious software (malware) is important for computer security. Among the different types of malware, zero-day malware is problematic because it cannot be removed by antivirus systems. Existing malware detection mechanisms use stored malware characteristics, which hinders detecting zero-day attacks where altered malware is generated to avoid detection by antivirus systems. To detect malware including zero-day attacks robustly, this paper proposes a novel method called transferred deep-convolutional generative adversarial network (tDCGAN), which generates fake malware and learns to distinguish it from real malware. The data generated from a random distribution are similar but not identical to the real data: it includes modified features compared with real data. The detector learns various malware features using real data and modified data generated by the tDCGAN based on a deep autoencoder (DAE), which extracts appropriate features and stabilizes the GAN training. Before training the GAN, the DAE learns malware characteristics, produces general data, and transfers this capacity for stable training of the GAN generator. The trained discriminator passes down the ability to capture malware features to the detector, using transfer learning. We show that tDCGAN achieves 95.74% average classification accuracy which is higher than that of other models and increases the learning stability. It is also the most robust against modeled zero-day attacks compared to others. © 2018 Elsevier Inc.",Autoencoder; Generative adversarial network; Malicious software; Robustness to noise; Transferlearning; Zero-day attack,Computer worms; Feature extraction; Learning systems; Security of data; Adversarial networks; Auto encoders; Robustness to noise; Transferlearning; Zero day attack; Malware,,,,,"Ahmadi, M., Ulyanov, D., Semenov, S., Tromov, M., Giacinto, G., Novel feature extraction, selection and fusion for effective malware family classification (2016) Conf. Data and Application Security and Privacy, pp. 183-194; Akritidis, P., Anagnostakis, K., Markatos, E.P., Efficient content-based detection of zero-day worms (2005) IEEE Int. Conf. Commun., 2, pp. 837-843; Alexander, M., Christopher, O., Mike, T., Inceptionism: going deeper into neural networks (2015), http://googleresearch.blogspot.com/2015/06/inceptionism-going-deeper-into-neural.html, Accessed 17 June 2015; Annachhatre, C., Thomas, A.H., Mark, S., Hidden Markov models for malware classification (2015) J. Hacking Tech., 11, pp. 59-73; Arnold, A., Nallapati, R., Cohen, W., A comparative study of methods for transductive transfer learning (2007) IEEE Int. Conf. Data Mining, pp. 77-82; Berlin, K., David, S., Joshua, S., Malicious behavior detection using windows audit logs (2015) Artif. Intell. Secur., pp. 35-44; Cao, J., Fu, Q., Li, Q., Guo, D., Discovering hidden suspicious accounts in online social networks (2017) Inf. Sci., 394, pp. 123-140; Chen, Z., Yan, Q., Han, H., Wang, S., Peng, L., Wang, L., Yang, B., Machine Learning based mobile malware detection using highly imbalanced network traffic (2018) Inf. Sci., 433-434, pp. 346-364; Christodorescum, M., Jha, S., Seshia, S.A., Song, D., Bryant, R.E., Semantics-aware malware detection (2005) Secur. Privacy, pp. 32-46; Damodaran, A., Di Troia, F., Visaggio, C.A., Austin, T.H., Stamp, M., A Comparison of static, dynamic, and hybrid analysis for malware detection (2017) J. Comput. Virol. Hacking Tech., 13 (1), pp. 1-12; Dauphin, Y.N., Pascanu, R., Gulcehre, C., Cho, K., Ganguli, S., Bengio, Y., Identifying and attacking the saddle point problem in high-dimensional non-convex optimization (2014) Adv. Neural Inf. Process. Syst., pp. 2933-2941; David, S., Numaan, H., ATM malware on the rise (2017), https://blog.trendmicro.com/trendlabs-security-intelligence/atm-malware-on-the-rise, Accessed 08 Aug Seshia; Dean, D., Jr., Kuhn, D., Direct instruction vs. discovery: the long view (2007) Sci. Edu., 91, pp. 384-397; Denton, L.E., Chintala, S., Fergus, R., Deep generative image models using a laplacian pyramid of adversarial networks (2015) Adv. Neural Inf. Process. Syst., pp. 1486-1494; Dhammi, A., Singh, M., Behavior analysis of malware using machine learning (2015) IEEE Int. Conf. Contemp. Comput., pp. 481-486; Drew, J., Moore, T., Hahsler, M., Polymorphic malware detection using sequence classification methods (2016) Secur. Privacy Workshops, pp. 81-87; Garcia, F.C.C., Muga, I.I., Felix, P., (2016), Random forest for malware classification, arXiv preprint arXiv:., 1609.07770; Glorot, X., Bengio, Y., Understanding the difficulty of training deep feedforward neural networks (2010) Int. Conf. Artif. Intell. Stat., pp. 249-256; Goodfellow, I., Pouget-Abadie, J., Mirze, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Adv. Neural Inf. Process. Syst., pp. 2672-2680; Grace, M., Zhou, Y., Zhang, Q., Zou, S., Jiang, X., Riskranker: scalable and accurate zero-day android malware detection (2012) Proceeding International Conference on Mobile Systems, Applications, and Services, pp. 281-294; Huda, S., Miah, S., Hassan, M.M., Islam, R., Yearwood, J., Alrubaian, M., Almogren, A., Defending unknown attacks on cyber-physical systems by semi-supervised approach and available unlabeled data (2017) Inf. Sci., 379, pp. 211-228; Kim, D.J., Jiang, C.D.H., Memisevic, R., (2016), Generating images with recurrent adversarial networks, arXiv preprint arXiv:., 1602.05110; Kim, J.-Y., Bu, S.-J., Cho, S.-B., Malware detection using deep transferred generative adversarial networks (2017) ICONIP, In Int. Conf. on Neural Information Processing, pp. 556-564; Kingma, D., Ba, J., (2014), Adam: a method for stochastic optimization, arXiv preprint arXiv:., 1412.6980; Kong, D., Guanhua, Y., Discriminant malware distance learning on structural information for automated malware classification (2013) Conf. Knowledge discovery and Datamining, pp. 1357-1365; Krizhevsky, A., Hinton, G.E., Using very deep autoencoders for content-based image retrieval (2011) European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, pp. 489-494; Loffe, S., Szegedy, C., Batch normalization: accelerating deep network training by reducing internal covariate shift (2015) Int. Conf. Machine Learning, pp. 448-456; Lu, X., Matsuda, Y., Hori, C., Speech enhancement based on deep denoising autoencoder (2013) Interspeech, pp. 436-440; Maaten, L., Hinton, G., Visualizing data using t-SNE (2008) J. Mach. Learn. Res., 9, pp. 2579-2605; Mas' ud, M.Z., Sahib, S., Abdollah, M.F., Selamat, S.R., Yusof, R., Analysis of feature selection and machine learning classifier in android malware detection (2014) Information Science and Applications, 2014 Int. Conf. on IEEE, pp. 1-5; Mathieu, M., Couprie, C., Lecun, Y., (2015), Deep multi-scale video prediction beyond mean square error, arXiv preprint arXiv:., 1511.05440; Narayanan, B.N., Djaneye-Boundjou, O., Kebede, T.M., Performance analysis of machine learning and pattern recognition algorithms for malware classification (2016) Aerospace and Electronics Conf. and Ohio Innovation Summit, pp. 338-342; Nataraj, L., Karthikeyanm, S., Jacob, G., Manjunath, B.S., Malware images: visualization and automatic classification (2011) Conf. Visualizing for Cyber Security, pp. 1-7; Pascanu, R., Stokes, J.W., Sanossian, H., Marinescu, M., Thomas, A., Malware classification with recurrent network (2015) Acoust. Speech Signal Process., pp. 1916-1920; Radford, A., Metz, L., Chintala, S., (2015), Unsupervised representation learning with deep convolutional generative adversarial networks, arXiv preprint arXiv:., 1511.06434; Santos, I., Brezo, F., Ugarte-Pedrero, X., Bringas, P.G., Opcode sequences as representation of executables for data-mining-based unknown malware detection (2013) Inf. Sci., 231, pp. 64-82; Singh, K., guntuku, S.C., Thakur, A., Hota, C., Big data analytics frameword for peer-to-peer botnet detection using random forests (2017) Inf. Sci., 278, pp. 488-497; Springenberg, J.T., (2015), Unsupervised and semi-supervised learning with categorical generative adversarial networks, arXiv preprint arXiv:., 1511.06390; Vincent, P., Larochelle, H., Bengio, Y., Manzagol, P.A., Extracting and composing robust features with denoising autoencoders (2008) Int. Conf. on Machine Learning, pp. 1096-1103; Wang, Q., Guo, W., Zhang, K., Alexander, G., Ororbia, I.I., Xinyu, X., Lee Giles, C., Xue, L., Adversary resistant deep neural networks with an application to malware detection (2017) Int. Conf. Knowledge Discovery and Data Mining, pp. 1145-1153; Wang, Z., Bovil, A.C., Sheikh, H.R., Simoncelli, E.P., Image quality assessment: from error visibility to structural similarity (2004) IEEE Trans. Image Process., 13, pp. 600-612; Ye, Y., Chen, L., Hou, S., Hardy, W., Li, X., DeepAM: a heterogeneous deep learning framework for intelligent malware detection (2017) Knowl. Inf. Syst., pp. 1-21; Zhao, J., Mathieu, M., Lecun, Y., (2016), Energy-based generative adversarial network, arXiv preprint arXiv:., 1609.03126; Zeiler, M.D., Fergus, R., Visualizing and understanding convolutional networks (2014) European Conf. on Computer Vision, pp. 818-833","Cho, S.-B.; Department of Computer Science, South Korea; 电子邮件: sbcho@yonsei.ac.kr",,,Elsevier Inc.,,,,,200255,,ISIJB,,English,Inf Sci,Article,Final,,Scopus,2-s2.0-85047653335
"Chen L., Sultana S., Sahita R.",55616439900;37082162000;6504685393;,HeNet: A deep learning approach on Intel® processor trace for effective exploit detection,2018,"Proceedings - 2018 IEEE Symposium on Security and Privacy Workshops, SPW 2018",,,8424641,109,115,,16,10.1109/SPW.2018.00025,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052191698&doi=10.1109%2fSPW.2018.00025&partnerID=40&md5=12d0047109763156ffa545055eade47c,"Security and Privacy Lab, Intel Labs, Hillsboro, OR  97124, United States","Chen, L., Security and Privacy Lab, Intel Labs, Hillsboro, OR  97124, United States; Sultana, S., Security and Privacy Lab, Intel Labs, Hillsboro, OR  97124, United States; Sahita, R., Security and Privacy Lab, Intel Labs, Hillsboro, OR  97124, United States","This paper presents HeNet, a hierarchical ensemble neural network, applied to classify hardware-generated control flow traces for malware detection. Deep learning-based malware detection has so far focused on analyzing executable files and runtime API calls. Static code analysis approaches face challenges due to obfuscated code and adversarial perturbations. Behavioral data collected during execution is more difficult to obfuscate but recent research has shown successful attacks against API call based malware classifiers. We investigate control flow based characterization of a program execution to build robust deep learning malware classifiers. HeNet consists of a low-level behavior model and a top-level ensemble model. The low-level model is a per-application behavior model, trained via transfer learning on a time-series of images generated from control flow trace of an execution. We use Intel® Processor Trace enabled processor for low overhead execution tracing and design a lightweight image conversion and segmentation of the control flow trace. The top-level ensemble model aggregates the behavior classification of all the trace segments and detects an attack. The use of hardware trace adds portability to our system and the use of deep learning eliminates the manual effort of feature engineering. We evaluate HeNet against real-world exploitations of PDF readers. HeNet achieves 100% accuracy and 0% false positive on test set, and higher classification accuracy compared to classical machine learning algorithms. © 2018 IEEE.",Control flow; Deep learning; Hierarchical learning; Intel® processor trace; Supervised learning; Threat detection,Classification (of information); Computer crime; Hardware; Image segmentation; Learning algorithms; Malware; Supervised learning; Application behavior models; Behavior classification; Classification accuracy; Control flows; Hierarchical ensemble; Hierarchical learning; Static code analysis; Threat detection; Deep learning,,,,,"Behrends, R., Dillon, L.K., Fleming, S.D., Stirewalt, R.E.K., (2017) Internet Security Threat Report, , Symantec, Tech. Rep., April; Minihane, N., Moreno, F., Peterson, E., Samani, R., Schmugar, C., Sommer, D., Sun, B., (2017) Mcafee Labs Threat Report, , McAfee Labs, Tech. Rep., December; Raff, E., Barker, J., Sylvester, J., Brandon, R., Catanzaro, B., Nicholas, C., (2017) Malware Detection by Eating a Whole Exe, , ArXiv e-prints, oct; Dahl, G.E., Stokes, J.W., Deng, L., Yu, D., Large-scale malware classification using random projections and neural networks (2013) IEEE Intl. Conference on Acoustics, Speech and Signal Processing, pp. 3422-3426. , May; Raff, E., Sylvester, J., Nicholas, C., (2017) Learning the PE Header, Malware Detection with Minimal Domain Knowledge, , ArXiv e-prints, Sep; Davis, A., Wolff, M., Deep learning on disassembly data (2015) BlackHat USA; Saxe, J., Berlin, K., Deep neural network based malware detection using two dimensional binary program features (2015) Intl. Conference on Malicious and Unwanted Software (MALWARE), pp. 11-20. , Oct; Kim, G., Yi, H., Lee, J., Paek, Y., Yoon, S., Lstm-based systemcall language modeling and robust ensemble method for designing hostbased intrusion detection systems (2016) CoRR, ABS161101726; Huang, W., Stokes, J.W., (2016) MtNet: A Multi-Task Neural Network for Dynamic Malware Classification, pp. 399-418. , Springer International Publishing; Kolosnjaji, B., Zarras, A., Webster, G., Eckert, C., (2016) Deep Learning for Classification of Malware System Call Sequences, pp. 137-149; Grosse, K., Papernot, N., Manoharan, P., Backes, M., McDaniel, P.D., Adversarial perturbations against deep neural networks for malware classification (2016) CoRR, ABS160604435; Hu, W., Tan, Y., Black-box attacks against RNN based malware detection algorithms (2017) CoRR, ABS170508131; Rosenberg, I., Shabtai, A., Rokach, L., Elovici, Y., (2017) Generic Blackbox End-to-end Attack Against Rnns and Other Api Calls Based Malware Classifiers, , ArXiv e-prints, July; Abadi, M., Budiu, M., Erlingsson, U., Ligatti, J., Control-flow integrity principles, implementations, and applications (2009) ACM Trans. Inf. Syst. Secur., 13 (1), pp. 41-440; Karim, F., Majumdar, S., Darabi, H., Chen, S., LSTM fully convolutional networks for time series classification (2018) IEEE Access, 6, pp. 1662-1669; Wang, Z., Yan, W., Oates, T., Time series classification from scratch with deep neural networks: A strong baseline (2017) International Joint Conference on Neural Networks (IJCNN), pp. 1578-1585. , May; Pan, S.J., Yang, Q., A survey on transfer learning (2010) IEEE Transactions on Knowledge and Data Engineering, 22 (10), pp. 1345-1359; Yosinski, J., Clune, J., Bengio, Y., Lipson, H., How transferable are features in deep neural networks? (2014) Advances in Neural Information Processing Systems, pp. 3320-3328; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., Inception-v4, inception-resnet and the impact of residual connections on learning (2017) AAAI, pp. 4278-4284; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition, , arXiv preprint; Maaten, L.V.D., Hinton, G., Visualizing data using t-sne (2008) Journal of Machine Learning Research, 9 (NOV), pp. 2579-2605; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proceedings of the IEEE, 86 (11), pp. 2278-2324; Pascanu, R., Stokes, J.W., Sanossian, H., Marinescu, M., Thomas, A., Malware classification with recurrent networks (2015) IEEE Intl. Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 1916-1920. , April; Nataraj, L., Karthikeyan, S., Jacob, G., Manjunath, B., Malware images: Visualization and automatic classification (2011) Proceedings of the 8th International Symposium on Visualization for Cyber Security, p. 4. , ACM; Nataraj, L., Yegneswaran, V., Porras, P., Zhang, J., A comparative assessment of malware classification using binary texture analysis and dynamic analysis (2011) Proceedings of the 4th ACM Workshop on Security and Artificial Intelligence, pp. 21-30. , ACM; Chen, L., Comer, D.C., Priebe, C.E., Sussman, D., Tilton, J.C., Refinement of a method for identifying probable archaeological sites from remotely sensed data (2013) Mapping Archaeological Landscapes from Space, pp. 251-258. , Springer; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., (2016) Universal Adversarial Perturbations, , arXiv preprint; Carlini, N., Wagner, D., (2016) Towards Evaluating the Robustness of Neural Networks, , arXiv preprint; Carlini, N., Barresi, A., Payer, M., Wagner, D., Gross, T.R., Controlflow bending: on the effectiveness of control-flow integrity (2015) USENIX Security Symposium, pp. 161-176; Carlini, N., Wagner, D., ROP is still dangerous: Breaking modern defenses USENIX",,,,Institute of Electrical and Electronics Engineers Inc.,"2018 IEEE Symposium on Security and Privacy Workshops, SPW 2018",24-May-18,,138430,,9.78E+12,,,English,"Proc. - IEEE Symp. Secur. Priv. Workshops, SPW",Conference Paper,Final,,Scopus,2-s2.0-85052191698
"Shrestha P., Saxena N.",57031498700;57206303753;,Listening watch: Wearable two-factor authentication using speech signals resilient to near-far attacks,2018,WiSec 2018 - Proceedings of the 11th ACM Conference on Security and Privacy in Wireless and Mobile Networks,,,,99,110,,8,10.1145/3212480.3212501,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050926699&doi=10.1145%2f3212480.3212501&partnerID=40&md5=5d9890a2ed68bfb3a4f9aa1bbc19dec1,"University of Alabama, Birmingham, United States","Shrestha, P., University of Alabama, Birmingham, United States; Saxena, N., University of Alabama, Birmingham, United States","Reducing the level of user effort involved in traditional two-factor authentication (TFA) constitutes an important research topic. A recent effort in this direction leverages ambient sounds to detect the proximity between the second factor device (phone) and the login terminal (browser), and eliminates the need for the user to transfer PIN codes. This approach is highly usable, but is completely vulnerable against far-near attackers, i.e., ones who are remotely located and can guess the victim's audio environment or make the phone create predictable sounds (e.g., ringers), and those who are in physical proximity of the user. In this paper, we propose Listening-Watch, a new TFA mechanism based on a wearable device (watch/bracelet) and active browser-generated random speech sounds. As the user attempts to login, the browser populates a short random code encoded into speech, and the login succeeds if the watch's audio recording contains this code (decoded using speech recognition), and is similar enough to the browser's audio recording. The remote attacker, who has guessed the user's environment or created predictable phone/watch sounds, will be defeated since authentication success relies upon the presence of the random code in watch's recordings. The proximity attacker will also be defeated unless it is extremely close to the watch, since the wearable microphones are usually designed to be only capable of picking up nearby sounds (e.g., voice commands). Furthermore, due to the use of a wearable second factor device, Listening-Watch naturally enables two-factor security even when logging in from a mobile phone. Our contributions are three-fold. First, we introduce the idea of strong and low-effort TFA based on wearable devices, active speech sounds and speech recognition, giving rise to the Listening-Watch system that is secure against both remote and proximity attackers. Second, we design and implement Listening-Watch for an Android smartwatch (and companion smartphone) and the Chrome browser, without the need for any browser plugins. Third, we evaluate Listening-Watch for authentication errors in both benign and adversarial settings. Our results show that Listening-Watch can result in minimal errors in both settings based on appropriate thresholdization and speaker volume levels. © 2018 Association for Computing Machinery.",,Audio acoustics; Audio equipment; Audio recordings; Authentication; Codes (symbols); Mobile security; Mobile telecommunication systems; Network security; Speech; Telephone sets; Watches; Wearable technology; Wireless networks; Ambient sounds; Design and implements; Mechanism-based; Minimal errors; Physical proximity; Research topics; Two factor authentication; Wearable devices; Speech recognition,,,,,"Yubico, A.B., (2017) Yubico | Trust The Net with YubiKey Strong Two-Factor Authentication, , https://www.yubico.com/, Retrieved May 13, 2017 from; (2017) Two-Factor Authentication - Authy, , https://www.authy.com/, Retrieved May 13, 2017 from; Bonneau, J., Herley, C., Van Oorschot, P.C., Stajano, F., The quest to replace passwords: A framework for comparative evaluation of web authentication schemes (2012) Security and Privacy (SP), 2012 IEEE Symposium on, pp. 553-567; (2017) How to Play Music Through The Internal Pc Speaker, , https://cd3dtech.com/tutorials/general/how-to-play-music-through-the-internal-pc-speaker, Retrieved December 31, 2017 from; (2017) Celestix HOTPin Two Factor Authentication, , http://www.celestixworks.com/HOTPin.asp, Retrieved May 13, 2017 from; (2017) Bluetooth - Google Chrome, , https://developer.chrome.com/apps/app_bluetooth, Retrieved May 13, 2017 from; Czeskis, A., Dietz, M., Kohno, T., Wallach, D., Balfanz, D., Strengthening user authentication through opportunistic cryptographic identity assertions (2012) Proceedings of The 2012 ACM Conference on Computer and Communications Security, pp. 404-414; Du, J., Huo, Q., A feature compensation approach using high-order vector Taylor series approximation of an explicit distortion model for noisy speech recognition (2011) IEEE Transactions on Audio, Speech, and Language Processing, 19 (8), pp. 2285-2293. , 2011; (2010) Integration of Short-Time Fourier Domain Speech Enhancement and Observation Uncertainty Techniques for Robust Automatic Speech Recognition, , Ram n Fern ndez Astudillo. 2010; (2017) Web Bluetooth API (Firefox OS, , https://developer.mozilla.org/en-US/docs/Archive/B2G_OS/Bluetooth_API, Retrieved May 13, 2017 from; Gibson, J., (2017) Introduction to MIDI and Computer Music: The MIDI Standard, , http://www.indiana.edu/~emusic/361/midi.htm, Retrieved December 31, 2017 from; Goodrich, M.T., Sirivianos, M., Solis, J., Tsudik, G., Uzun, E., Loud and clear: Human-verifiable authentication based on audio (2006) Distributed Computing Systems, 2006. ICDCS 2006. 26th IEEE International Conference on., p. 10; Halevi, T., Ma, D., Saxena, N., Xiang, T., Secure proximity detection for NFC devices based on ambient sensor data (2012) Computer Security-ESORICS 2012, pp. 379-396. , Springer; (2017) Basic Trackers Take A Back Seat as Smartwatches Accelerate in The Second Quarter, , https://goo.gl/2wDj4x, According to IDC. Retrieved December 28, 2017 from; (2017) Understanding Microphone Sensitivity, , https://goo.gl/WJhdCi, Retrieved October 27, 2017 from; (2017) Easy Authentication: Duo Security, , https://duo.com/solutions/features/user-experience/easy-authentication, Retrieved May 13, 2017 from; (2017) Gartner Says Worldwide Wearable Device Sales to Grow 17 Percent in 2017, , https://goo.gl/z7DTz1, Retrieved December 28, 2017 from; (2017) Google 2-Step Verification, , https://www.google.com/landing/2step/, Retrieved May 13, 2017 from; (2017) Speech API - Speech Recognition | Google Cloud Platform, , https://cloud.google.com/speech/, Retrieved May 13, 2017 from; Karapanos, N., Marforio, C., Soriente, C., Capkun, S., Sound-proof: Usable two-factor authentication based on ambient sound (2015) USENIX Security Symposium; Koldovsky, Z., Mullek, J., Nouza, J., Miroslav Bal, K., CHIME data separation based on target signal cancellation and noise masking (2011) Machine Listening in Multisource Environments; Kumpardk, G., (2014) Google Acquires SlickLogin, The Sound-Based Password Alternative | TechCrunch, , http://techcrunch.com/2014/02/16/google-acquires-slicklogin-the-sound-based-password-alternative/, Retrieved May 13, 2017 from; Mare, S., Markham, A.M., Cornelius, C., Peterson, R., Kotz, D., Zebra: Zero-effort bilateral recurring authentication (2014) Security and Privacy (SP), 2014 IEEE Symposium on, pp. 705-720; (2017) Butterworth Filter Design, , http://www.mathworks.com/help/signal/ref/butter.html, Retrieved May 13, 2017 from; (2017) Large Vs Small Diagpragms in Microphones, , https://goo.gl/TGjcke, Retrieved October 27, 2017 from; (2017) Nymi | Always On Authentication, , https://nymi.com/, Retrieved October 27, 2017 from; (2017) Omate TrueSmart, , https://www.omate.com/, Retrieved May 13, 2017 from; (2017) Make Listening Safe, , https://goo.gl/4hfd98, Retrieved October 28, 2017 from; (2017) SecurID | RSA Security Token Based Authentication, , https://www.yubico.com/, Retrieved May 13, 2017 from; (2017) Samsung Gear S Smartwatch | Samsung, , http://www.samsung.com/us/explore/gear-s-features-and-specs/, Retrieved May 13, 2017 from; Shirvanian, M., Jarecki, S., Saxena, N., Nathan, N., Two-factor authentication resilient to server compromise using mix-bandwidth devices (2014) Network and Distributed System Security Symposium; Shrestha, B., Shirvanian, M., Shrestha, P., Saxena, N., The sounds of the phones: Dangers of zero-effort second factor login based on ambient audio Conference on Computer and Communications Security, , n. d; Soriente, C., Tsudik, G., Uzun, E., HAPADEP: Human-assisted pure audio device pairing (2008) Information Security, pp. 385-400. , 2008; (2017) Personal Distance - Zones, , http://www.study-body-language.com/Personal-distance.html, Retrieved October 27, 2017 from; (2017) Solfa Cipher, , http://www.wmich.edu/mus-theo/solfa-cipher/, Retrieved December 31, 2017 from; Vinyals, O., Ravuri, S.V., Comparing multilayer perceptron to deep belief network tandem features for robust ASR (2011) Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE International Conference on, pp. 4596-4599; (2017) WebRTC Home | WebRTC, , https://webrtc.org/, Retrieved May 13, 2017 from; Weninger, F., Wollmer, M., Geiger, J., Schuller, B., Gemmeke, J.F., Hurmalainen, A., Virtanen, T., Rigoll, G., Non-negative matrix factorization for highly noise-robust asr: To enhance or to recognize? (2012) Acoustics, Speech and Signal Processing (ICASSP), 2012 IEEE International Conference on, pp. 4681-4684; Williams, B., (2017) Smartwatches Surge to Take The Wearable Crown, , https://goo.gl/tJPtfY, Retrieved December 28, 2017 from; Wilson, K.W., Raj, B., Smaragdis, P., Divakaran, A., Speech denoising using nonnegative matrix factorization with priors (2008) Acoustics, Speech and Signal Processing, 2008. ICASSP 2008. IEEE International Conference on., pp. 4029-4032; Zandbergen, P.A., Barbeau, S.J., Positional accuracy of assisted GPS data from high-sensitivity GPS-enabled mobile phones (2011) Journal of Navigation, 64, pp. 381-399. , 03 2011",,,ACM SIGSAC,"Association for Computing Machinery, Inc","11th ACM Conference on Security and Privacy in Wireless and Mobile Networks, WiSec 2018",18 June 2018 through 20 June 2018,,137827,,9.78E+12,,,English,WiSec - Proc. ACM Conf. Security Priv. Wirel. Mob. Networks,Conference Paper,Final,"All Open Access, Bronze",Scopus,2-s2.0-85050926699
"Yanagita Y., Yamamura M.",57202608258;55812193300;,Gradient masking is a type of overfitting,2018,International Journal of Machine Learning and Computing,8,3,,203,207,,1,10.18178/ijmlc.2018.8.3.688,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048899587&doi=10.18178%2fijmlc.2018.8.3.688&partnerID=40&md5=705843d595ac0ec48426f573f3c3e6a0,"Department of Computer Science, School of Computer, Tokyo Institute of Technology, Yokohama, 226-8503, Japan","Yanagita, Y., Department of Computer Science, School of Computer, Tokyo Institute of Technology, Yokohama, 226-8503, Japan; Yamamura, M., Department of Computer Science, School of Computer, Tokyo Institute of Technology, Yokohama, 226-8503, Japan","Neural networks have recently been attracting attention again as classifiers with high accuracy, so called ""deep learning,"" which is applied in a wide variety of fields. However, this advanced machine learning algorithms are vulnerable to adversarial perturbations. Although they cannot be recognized by humans, these perturbations deliver a fatal blow to the estimation ability of classifiers. Thus, while humans perceive perturbed examples as being the same as the original natural examples, sophisticated classifiers identify them as completely different examples. Although several defensive measures against such adversarial examples have been suggested, they are known to fail in undesirable phenomena, gradient masking. Gradient masking can neutralize the useful gradient for adversaries, but adversarial perturbations tend to transfer across most models, and these models can be deceived by adversarial examples crafted based on other models, which is called a black-box attack. Therefore, it is necessary to develop training methods to withstand black-box attacks and conduct studies to investigate the weak points of current NN training. This paper argues that no special defensive measures are necessary for NN to fall into gradient masking, and it is sufficient to slightly change the initial learning rate of Adam from the recommended value. Moreover, our experiment implies that gradient masking is a type of overfitting. © 2018, International Association of Computer Science and Information Technology.",Adam; Adversarial examples; Gradient masking; Machine learning; Neural network,,,,,,"Hinton, G.E., Osindero, S., Teh, Y.-W., 'A fast learning algorithm for deep belief nets,' (2006) Neural Comput, 18 (7), pp. 1527-1554; Yann, L., Yoshua, B., Geoffrey, H., 'Deep learning,' (2015) Nature, 521 (7553), pp. 436-444; Szegedy, C., 'Intriguing properties of neural networks, ' Proc. ICLR; Ian, G., Jonathon, J.S., Christian, S., 'Exampling and harnessing adversarial examples, ' (2015) Proc. ICLR; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossar, P., 'DeepFool: A simple and accurate method to fool deep neural networks, ' (2016) in IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Papernot, N., Mcdaniel, P., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., 'The limitations of deep learning in adversarial settings, ' (2016) Proc. the 1st IEEE European Symposium on Security and Privacy; Carlini, N., Wagner, D., 'Towards Evaluating the Robustness of Neural Networks, ' (2017) Proc. IEEE Symposium on Security and Privacy; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., 'Universal adversarial perturbations, ' (2017) Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Papernot, N., Mcdaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., 'Practical black-box attacks against machine learning, ' (2017) Proc. ACM Asia Conference on Computer and Communications Security; Papernot, N., Mcdaniel, P., Goodfellow, I., 'Transferability in machine learning: From phenomena to black-box attacks using adversarial samples, ' (2016), arXiv preprint; Tramèr, F., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., 'The space of transferable adversarial examples, "" arXiv preprint arXiv: 1704.03453, 2017. N. Papernot, P. McDaniel, X. Wu, S. Jha, and A. Swami, ""Distillation as a defense to adversarial perturbations against deep neural networks, ' (2016) Proc. 2016 IEEE Symposium on Security and Privacy, pp. 582-597; Papernot, N., McDaniel, P., 'Extending defensive distillation, ' (2017), arXiv preprint; Jimmy Ba, L., Caruana, R., 'Do deep nets really need to be deep?' (2014) Adv. Neural Inf. Process. Syst; Sengupta, S., Chakraborti, T., Kambhampati, S., (2017) 'Securing deep neural nets against adversarial attacks with moving target defense, ', , arXiv preprint; Kingma, D.P., Ba, J.L., 'Adam: A method for stocastic optimization, ' (2015) Proc. ICLR; Polyak, B.T., 'Some methods of speeding up the convergence of iteration methods,' (1964) Comput. Math. Math. Phys, 4 (5), pp. 1-17; Duchi, J., Edu, J.B., Hazan, E., Singer, Y., 'Adaptive subgradient methods for online learning and stochastic optimization*, ' (2011) J. Mach. Learn. Res, 12, pp. 2121-2159; Tieleman, T., Hinton, G., 'Lecture 6.5-RMSProp, COURSERA: Neural networks for machine learning, ' (2012) Tech. Rep",,,,International Association of Computer Science and Information Technology,,,,,20103700,,,,English,Int. J. Mach. Learn. Comput.,Article,Final,"All Open Access, Bronze, Green",Scopus,2-s2.0-85048899587
"Brendel W., Rauber J., Bethge M.",57207550476;57208446440;57210225326;,Decision-based adversarial attacks: Reliable attacks against black-box machine learning models,2018,"6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings",,,,,,,189,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083954048&partnerID=40&md5=d2646cdf5c872ab2eaf5119b5338131f,"Werner Reichardt Centre for Integrative Neuroscience, Eberhard Karls University, Tübingen, Germany","Brendel, W., Werner Reichardt Centre for Integrative Neuroscience, Eberhard Karls University, Tübingen, Germany; Rauber, J., Werner Reichardt Centre for Integrative Neuroscience, Eberhard Karls University, Tübingen, Germany; Bethge, M., Werner Reichardt Centre for Integrative Neuroscience, Eberhard Karls University, Tübingen, Germany","Many machine learning algorithms are vulnerable to almost imperceptible perturbations of their inputs. So far it was unclear how much risk adversarial perturbations carry for the safety of real-world machine learning applications because most methods used to generate such perturbations rely either on detailed model information (gradient-based attacks) or on confidence scores such as class probabilities (score-based attacks), neither of which are available in most real-world scenarios. In many such cases one currently needs to retreat to transfer-based attacks which rely on cumbersome substitute models, need access to the training data and can be defended against. Here we emphasise the importance of attacks which solely rely on the final model decision. Such decision-based attacks are (1) applicable to real-world black-box models such as autonomous cars, (2) need less knowledge and are easier to apply than transfer-based attacks and (3) are more robust to simple defences than gradient- or score-based attacks. Previous attacks in this category were limited to simple models or simple datasets. Here we introduce the Boundary Attack, a decision-based attack that starts from a large adversarial perturbation and then seeks to reduce the perturbation while staying adversarial. The attack is conceptually simple, requires close to no hyperparameter tuning, does not rely on substitute models and is competitive with the best gradient-based attacks in standard computer vision tasks like ImageNet. We apply the attack on two black-box algorithms from Clarifai.com. The Boundary Attack in particular and the class of decision-based attacks in general open new avenues to study the robustness of machine learning models and raise new questions regarding the safety of deployed machine learning systems. An implementation of the attack is available as part of Foolbox (https://github.com/bethgelab/foolbox). © Learning Representations, ICLR 2018 - Conference Track Proceedings.All right reserved.",,Learning algorithms; Risk perception; Safety engineering; Black box algorithms; Class probabilities; Confidence score; Detailed modeling; Machine learning applications; Machine learning models; Modeling decisions; Real-world scenario; Machine learning,,,,,"Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndić, N., Laskov, P., Giacinto, G.-G., Roli, F., Evasion attacks against machine learning at test time (2013) Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 387-402. , Springer; Brendel, W., Bethge, M., Comment on “biologically inspired protection of deep networks from adversarial attacks” (2017) CoRR, , http://arxiv.org/abs/1704.01547, abs/1704.01547; Carlini, N., Wagner, D.A., Towards evaluating the robustness of neural networks (2016) CoRR, , http://arxiv.org/abs/1608.04644, abs/1608.04644; Carlini, N., Wagner, D.A., Defensive distillation is not robust to adversarial examples (2016) CoRR, , http://arxiv.org/abs/1607.04311, abs/1607.04311; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) CoRR, , http://arxiv.org/abs/1708.03999, abs/1708.03999; Cisse, M., Adi, Y., Neverova, N., Keshet, J., Houdini: Fooling deep structured prediction models (2017) CoRR, , http://arxiv.org/abs/1707.05373, abs/1707.05373; Dalvi, N., Domingos, P., Mausam, Sanghai, S., Verma, D., Adversarial classification (2004) Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD’04, pp. 99-108. , http://doi.acm.org/10.1145/1014052.1014066, New York, NY, USA, ACM; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., ImageNet: A large-scale hierarchical image database (2009) Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pp. 248-255. , IEEE; Hayes, J., Danezis, G., Machine learning as an adversarial service: Learning black-box adversarial examples (2017) CoRR, , http://arxiv.org/abs/1708.05207, abs/1708.05207; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2015) CoRR, , http://arxiv.org/abs/1512.03385, abs/1512.03385; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images, , Technical report, University of Toronto; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial examples in the physical world (2016) CoRR, , http://arxiv.org/abs/1607.02533, abs/1607.02533; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proceedings of the IEEE, 86 (11), pp. 2278-2324; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2016) CoRR, , http://arxiv.org/abs/1611.02770, abs/1611.02770; Lowd, D., Meek, C., Adversarial learning (2005) Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining, KDD’05, pp. 641-647. , http://doi.acm.org/10.1145/1081870.1081950, New York, NY, USA, ACM; Lu, J., Issaranon, T., Forsyth, D.A., SafeTyNet: Detecting and rejecting adversarial examples robustly (2017) CoRR, , http://arxiv.org/abs/1704.00103, abs/1704.00103; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2015) CoRR, , http://arxiv.org/abs/1511.04599, abs/1511.04599; Narodytska, N., Kasiviswanathan, S.P., Simple black-box adversarial perturbations for deep networks (2016) CoRR, , http://arxiv.org/abs/1612.06299, abs/1612.06299; Nayebi, A., Ganguli, S., Biologically inspired protection of deep networks from adversarial attacks (2017) CoRR, , http://arxiv.org/abs/1703.09202, abs/1703.09202; Nelson, B., Rubinstein, B.I.P., Huang, L., Joseph, A.D., Lee, S.J., Rao, S., Tygar, J.D., Query strategies for evading convex-inducing classifiers (2012) J. Mach. Learn. Res., 13, pp. 1293-1332. , http://dl.acm.org/citation.cfm?id=2188385.2343688, May; Papernot, N., McDaniel, P.D., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2015) CoRR, , http://arxiv.org/abs/1511.07528, abs/1511.07528; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Security and Privacy (SP), 2016 IEEE Symposium on, pp. 582-597. , IEEE; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519. , ACM; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, Asia CCS’17, pp. 506-519. , http://doi.acm.org/10.1145/3052973.3053009, New York, NY, USA, ACM; Rauber, J., Brendel, W., Bethge, M., Foolbox v0.8.0: A python toolbox to benchmark the robustness of machine learning models (2017) CoRR, , http://arxiv.org/abs/1707.04131, abs/1707.04131; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2014) CoRR, , http://arxiv.org/abs/1409.1556, abs/1409.1556; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R., Intriguing properties of neural networks (2013) CoRR, , http://arxiv.org/abs/1312.6199, abs/1312.6199; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2015) CoRR, , http://arxiv.org/abs/1512.00567, abs/1512.00567; Tramer, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2017) CoRR, , http://arxiv.org/abs/1705.07204, abs/1705.07204, May",,,,"International Conference on Learning Representations, ICLR","6th International Conference on Learning Representations, ICLR 2018",30 April 2018 through 3 May 2018,,149806,,,,,English,"Int. Conf. Learn. Represent., ICLR - Conf. Track Proc.",Conference Paper,Final,,Scopus,2-s2.0-85083954048
"Tramèr F., Kurakin A., Papernot N., Goodfellow I., Boneh D., McDaniel P.",56878876400;57202499592;56732917800;35956088800;7003748305;7006537016;,Ensemble adversarial training: Attacks and defenses,2018,"6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings",,,,,,,340,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083953449&partnerID=40&md5=bf2f71b308c2b1ad53207565cf750d26,"Stanford University, United States; Google Brain, United States; Pennsylvania State University, United States","Tramèr, F., Stanford University, United States; Kurakin, A., Google Brain, United States; Papernot, N., Pennsylvania State University, United States; Goodfellow, I., Google Brain, United States; Boneh, D., Stanford University, United States; McDaniel, P., Pennsylvania State University, United States","Adversarial examples are perturbed inputs designed to fool machine learning models. Adversarial training injects such examples into training data to increase robustness. To scale this technique to large datasets, perturbations are crafted using fast single-step methods that maximize a linear approximation of the model’s loss. We show that this form of adversarial training converges to a degenerate global minimum, wherein small curvature artifacts near the data points obfuscate a linear approximation of the loss. The model thus learns to generate weak perturbations, rather than defend against strong ones. As a result, we find that adversarial training remains vulnerable to black-box attacks, where we transfer perturbations computed on undefended models, as well as to a powerful novel single-step attack that escapes the non-smooth vicinity of the input data via a small random step. We further introduce Ensemble Adversarial Training, a technique that augments training data with perturbations transferred from other models. On ImageNet, Ensemble Adversarial Training yields models with strong robustness to black-box attacks. In particular, our most robust model won the first round of the NIPS 2017 competition on Defenses against Adversarial Attacks (Kurakin et al., 2017c). © Learning Representations, ICLR 2018 - Conference Track Proceedings.All right reserved.",,Large datasets; Linear approximations; Machine learning models; Robust modeling; Single-step method; Strong robustness; Training data; Weak perturbation; Large dataset,,,,,"Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G.S., Zheng, X., (2015) TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems, , https://www.tensorflow.org/.Softwareavailablefromtensorflow.org; Amodei, D., Olah, C., Steinhardt, J., Christiano, P., Schulman, J., Mané, D., (2016) Concrete Problems in Ai Safety, , arXiv preprint; Athalye, A., Carlini, N., Wagner, D., (2018) Obfuscated Gradients Give A False Sense of Security: Circumventing Defenses to Adversarial Examples, , arXiv preprint; Baluja, S., Fischer, I., (2017) Adversarial Transformation Networks: Learning to Generate Adversarial Examples, , arXiv preprint; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndić, N., Laskov, P., Giacinto, G.-G., Roli, F., Evasion attacks against machine learning at test time (2013) ECML-KDD, pp. 387-402. , Springer; Brendel, W., Bethge, M., (2017) Comment on” Biologically Inspired Protection of Deep Networks from Adversarial Attacks, , arXiv preprint; Buckman, J., Roy, A., Raffel, C., Goodfellow, I., Thermometer encoding: One hot way to resist adversarial examples (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=S18Su-CW; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy; Carlini, N., Wagner, D., (2017) Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods, , arXiv preprint; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 15-26; Cisse, M., Piotr, B., Edouard, G., Yann, D., Nicolas, U., (2017) Parseval Networks: Improving Robustness to Adversarial Examples, , arXiv preprint; Colbourn, C.J., (2010) CRC Handbook of Combinatorial Designs, , CRC press; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., ImageNet: A large-scale hierarchical image database (2009) CVPR09; Engstrom, L., Tsipras, D., Schmidt, L., Madry, A., (2017) A Rotation and A Translation Suffice: Fooling Cnns with Simple Transformations, , arXiv preprint; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, pp. 2672-2680; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint; Gu, S., Rigazio, L., (2014) Towards Deep Neural Network Architectures Robust to Adversarial Examples, , arXiv preprint; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Zico Kolter, J., Wong, E., (2017) Provable Defenses against Adversarial Examples Via the Convex Outer Adversarial Polytope, , arXiv preprint; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2017) ICLR; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2017) ICLR; Kurakin, A., Goodfellow, I.J., Bengio, S., (2017) Nips 2017: Defense against Adversarial Attack, , https://www.kaggle.com/c/nips-2017-defense-against-adversarial-attack; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proceedings of the IEEE, 86 (11), pp. 2278-2324; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) ICLR; Luo, Y., Boix, X., Roig, G., Poggio, T., Zhao, Q., (2015) Foveation-Based Mechanisms Alleviate Adversarial Examples, , arXiv preprint; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , arXiv preprint; Mansour, Y., Mohri, M., Rostamizadeh, A., (2009) Domain Adaptation: Learning Bounds and Algorithms, , arXiv preprint; Mishkin, D., Sergievskiy, N., Matas, J., Systematic evaluation of convolution neural network advances on the imagenet (2017) Computer Vision and Image Understanding; Nayebi, A., Ganguli, S., (2017) Biologically Inspired Protection of Deep Networks from Adversarial Attacks, , arXiv preprint; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387; Papernot, N., McDaniel, P., Sinha, A., Wellman, M., (2016) Towards the Science of Security and Privacy in Machine Learning, , arXiv preprint; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Security and Privacy (SP), 2016 IEEE Symposium on, pp. 582-597; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) Asia Conference on Computer and Communications Security (ASIACCS), pp. 506-519; Raghunathan, A., Steinhardt, J., Liang, P., Certified defenses against adversarial examples (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=Bys4ob-Rb; Sinha, A., Namkoong, H., Duchi, J., Certifiable distributional robustness with principled adversarial training (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=Hk6kPgZA; Srivastava, N., Hinton, G.E., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., Dropout: A simple way to prevent neural networks from overfitting (2014) Journal of Machine Learning Research, 15 (1), pp. 1929-1958; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A., (2016) Inception-V4, Inception-Resnet and the Impact of Residual Connections on Learning, , arXiv preprint; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) CVPR, pp. 2818-2826; Tramèr, F., Zhang, F., Juels, A., Reiter, M.K., Ristenpart, T., Stealing machine learning models via prediction apis (2016) Usenix Security; Tramèr, F., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2017) The Space of Transferable Adversarial Examples, , arXiv preprint; Xiao, C., Li, B., Zhu, J.-Y., He, W., Liu, M., Song, D., (2018) Generating Adversarial Examples with Adversarial Networks, , https://openreview.net/forum?id=HknbyQbC; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., Mitigating adversarial effects through randomization (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=Sk9yuql0Z; Zhang, C., Zhang, L., Ye, J., Generalization bounds for domain adaptation (2012) Advances in Neural Information Processing Systems, pp. 3320-3328",,,,"International Conference on Learning Representations, ICLR","6th International Conference on Learning Representations, ICLR 2018",30 April 2018 through 3 May 2018,,149806,,,,,English,"Int. Conf. Learn. Represent., ICLR - Conf. Track Proc.",Conference Paper,Final,,Scopus,2-s2.0-85083953449
"Na T., Ko J.H., Mukhopadhyay S.",57189643082;56921245400;8330116700;,Cascade adversarial machine learning regularized with a unified embedding,2018,"6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings",,,,,,,22,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083952353&partnerID=40&md5=d39378dd2eeb4062726e0f94111c4ff8,"School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA  30332, United States","Na, T., School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA  30332, United States; Ko, J.H., School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA  30332, United States; Mukhopadhyay, S., School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA  30332, United States","Injecting adversarial examples during training, known as adversarial training, can improve robustness against one-step attacks, but not for unknown iterative attacks. To address this challenge, we first show iteratively generated adversarial images easily transfer between networks trained with the same strategy. Inspired by this observation, we propose cascade adversarial training, which transfers the knowledge of the end results of adversarial training. We train a network from scratch by injecting iteratively generated adversarial images crafted from already defended networks in addition to one-step adversarial images from the network being trained. We also propose to utilize embedding space for both classification and low-level (pixel-level) similarity learning to ignore unknown pixel level perturbation. During training, we inject adversarial images without replacing their corresponding clean images and penalize the distance between the two embeddings (clean and adversarial). Experimental results show that cascade adversarial training together with our proposed low-level similarity learning efficiently enhances the robustness against iterative attacks, but at the expense of decreased robustness against one-step attacks. We show that combining those two techniques can also improve robustness under the worst case black box attack scenario. © Learning Representations, ICLR 2018 - Conference Track Proceedings.All right reserved.",,Embeddings; Machine learning; Pixels; Attack scenarios; Black boxes; Clean images; Pixel level; Similarity learning; Iterative methods,,,,,"Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) Proceedings of the International Conference on Learning Representations (ICLR); He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) 2016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2016, pp. 770-778. , http://dx.doi.org/10.1109/CVPR.2016.90, Las Vegas, NV, USA, June 27-30, 2016; Huang, R., Xu, B., Schuurmans, D., Szepesvári, C., Learning with a strong adversary (2015) CoRR, , http://arxiv.org/abs/1511.03034, abs/1511.03034; Krizhevsky, A., (2009) Learning Multiple Layers of Features from Tiny Images, , Technical report; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial machine learning at scale (2017) Proceedings of the International Conference on Learning Representations (ICLR); LeCun, Y., Cortes, C., (2010) MNIST Handwritten Digit Database, , http://yann.lecun.com/exdb/mnist/; Parkhi, O.M., Vedaldi, A., Zisserman, A., Deep face recognition (2015) Proceedings of the British Machine Vision Conference (BMVC); Schroff, F., Kalenichenko, D., Philbin, J., FaceNet: A unified embedding for face recognition and clustering (2015) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , June; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2017) CoRR, , http://arxiv.org/abs/1705.07204, abs/1705.07204; Wen, Y., Zhang, K., Li, Z., Qiao, Y., A discriminative feature learning approach for deep face recognition (2016) Computer Vision - ECCV 2016 - 14th European Conference, pp. 499-515. , http://dx.doi.org/10.1007/978-3-319-46478-7_31, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, VII",,,,"International Conference on Learning Representations, ICLR","6th International Conference on Learning Representations, ICLR 2018",30 April 2018 through 3 May 2018,,149806,,,,,English,"Int. Conf. Learn. Represent., ICLR - Conf. Track Proc.",Conference Paper,Final,,Scopus,2-s2.0-85083952353
"Lu P.-H., Chen P.-Y., Yu C.-M.",57200512365;36930105800;14322694600;,On the limitation of local intrinsic dimensionality for characterizing the subspaces of adversarial examples,2018,"6th International Conference on Learning Representations, ICLR 2018 - Workshop Track Proceedings",,,,,,,7,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083950196&partnerID=40&md5=a14473bcb9ec28acc1ed744ef13e724d,"National Chung Hsing University, Taichung, Taiwan; IBM Research NY, United States","Lu, P.-H., National Chung Hsing University, Taichung, Taiwan; Chen, P.-Y., IBM Research NY, United States; Yu, C.-M., National Chung Hsing University, Taichung, Taiwan","Understanding and characterizing the subspaces of adversarial examples aid in studying the robustness of deep neural networks (DNNs) to adversarial perturbations. Very recently, Ma et al. (2018) proposed to use local intrinsic dimensionality (LID) in layer-wise hidden representations of DNNs to study adversarial subspaces. It was demonstrated that LID can be used to characterize the adversarial subspaces associated with different attack methods, e.g., the Carlini and Wagner’s (C&W) attack and the fast gradient sign attack. In this paper, we use MNIST and CIFAR-10 to conduct two new sets of experiments that are absent in existing LID analysis and report the limitation of LID in characterizing the corresponding adversarial subspaces, which are (i) oblivious attacks and LID analysis using adversarial examples with different confidence levels; and (ii) black-box transfer attacks. For (i), we find that the performance of LID is very sensitive to the confidence parameter deployed by an attack, and the LID learned from ensembles of adversarial examples with varying confidence levels surprisingly gives poor performance. For (ii), we find that when adversarial examples are crafted from another DNN model, LID is ineffective in characterizing their adversarial subspaces. These two findings together suggest the limited capability of LID in characterizing the subspaces of adversarial examples. © 6th International Conference on Learning Representations, ICLR 2018 - Workshop Track Proceedings. All rights reserved.",,Black boxes; Confidence levels; Different attacks; Intrinsic dimensionalities; Layer-wise; Poor performance; Deep neural networks,,,,,"Athalye, A., Carlini, N., Wagner, D., (2018) Obfuscated Gradients Give A False Sense of Security: Circumventing Defenses to Adversarial Examples; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy (S&P), pp. 39-57; Chen, P.-Y., Sharma, Y., Zhang, H., Yi, J., Hsieh, C.-J., (2017) Ead: Elastic-Net Attacks to Deep Neural Networks Via Adversarial Examples; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR’15; Houle, M.E., Kashima, H., Nett, M., Generalized expansion dimension (2012) IEEE International Conference onData Mining Workshops (ICDMW), pp. 587-594; Karger, D.R., Ruhl, M., Finding nearest neighbors in growth-restricted metrics (2002) ACM Symposium on Theory of Computing, pp. 741-750; Liu, Y., Chen, X., Liu, C., Song, D., (2016) Delving into Transferable Adversarial Examples and Black-Box Attacks; Ma, X., Li, B., Wang, Y., Erfani, S.M., Wijewickrema, S., Houle, M.E., Schoenebeck, G., Bailey, J., (2018) Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality; Meng, D., Chen, H., Magnet: A two-pronged defense against adversarial examples (2017) ACM CCS; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-Box Attacks Using Adversarial Samples; Sharma, Y., Chen, P.-Y., (2017) Attacking the Madry Defense Model with L1-Based Adversarial Examples; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks",,,,"International Conference on Learning Representations, ICLR","6th International Conference on Learning Representations, ICLR 2018",30 April 2018 through 3 May 2018,,149807,,,,,English,"Int. Conf. Learn. Represent., ICLR - Workshop Track Proc.",Conference Paper,Final,,Scopus,2-s2.0-85083950196
"Zhou W., Hou X., Chen Y., Tang M., Huang X., Gan X., Yang Y.",57303422100;56026918900;57203387347;57204471584;57204472671;57204466148;57206629478;,Transferable adversarial perturbations,2018,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),11218 LNCS,,,471,486,,8,10.1007/978-3-030-01264-9_28,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055725664&doi=10.1007%2f978-3-030-01264-9_28&partnerID=40&md5=68b3a4f3e5552d51d336980ffc7b4c93,"Basic Research Group, Security Platform Department, Tencent, Beijing, China","Zhou, W., Basic Research Group, Security Platform Department, Tencent, Beijing, China; Hou, X., Basic Research Group, Security Platform Department, Tencent, Beijing, China; Chen, Y., Basic Research Group, Security Platform Department, Tencent, Beijing, China; Tang, M., Basic Research Group, Security Platform Department, Tencent, Beijing, China; Huang, X., Basic Research Group, Security Platform Department, Tencent, Beijing, China; Gan, X., Basic Research Group, Security Platform Department, Tencent, Beijing, China; Yang, Y., Basic Research Group, Security Platform Department, Tencent, Beijing, China","State-of-the-art deep neural network classifiers are highly vulnerable to adversarial examples which are designed to mislead classifiers with a very small perturbation. However, the performance of black-box attacks (without knowledge of the model parameters) against deployed models always degrades significantly. In this paper, We propose a novel way of perturbations for adversarial examples to enable black-box transfer. We first show that maximizing distance between natural images and their adversarial examples in the intermediate feature maps can improve both white-box attacks (with knowledge of the model parameters) and black-box attacks. We also show that smooth regularization on adversarial perturbations enables transferring across models. Extensive experimental results show that our approach outperforms state-of-the-art methods both in white-box and black-box attacks. © 2018, Springer Nature Switzerland AG.",Adversarial perturbations; Black-box attacks; Transferability,Deep neural networks; Image enhancement; Adversarial perturbations; Black boxes; Model parameters; Neural network classifier; Small perturbations; State of the art; State-of-the-art methods; Transferability; Computer vision,,,,,"Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Hinton, G., Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups (2012) IEEE Sig. Process. Mag., 29 (6), pp. 82-97; Sutskever, I., Vinyals, O., Le, Q.V., Sequence to sequence learning with neural networks (2014) Advances in Neural Information Processing Systems, pp. 3104-3112; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 427-436; Moosavi-Dezfooli, S.M., Fawzi, A., Fawzi, O., Frossard, P., (2016) Universal Adversarial Perturbations, , arXiv preprint arXiv; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations; Kurakin, A., Goodfellow, I.J., Bengio, S., (2016) Adversarial Machine Learning at Scale. Arxiv: Computer Vision and Pattern Recognition; Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P., DeepFool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., (2017) Inception-V4, Inception-Resnet and the Impact of Residual Connections on Learning, pp. 4278-4284. , AAA; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses, , arXiv preprint arXiv; Szegedy, C., (2013) Intriguing Properties of Neural Networks, , arXiv preprint arXiv; Kurakin, A., Goodfellow, I.J., Bengio, S., (2016) Adversarial Examples in the Physical World. Arxiv: Computer Vision and Pattern Recognition; Perronnin, F., Sánchez, J., Mensink, T., Improving the fisher kernel for large-scale image classification (2010) ECCV 2010. LNCS, 6314, pp. 143-156. , Daniilidis, K., Maragos, P., Paragios, N. (eds.) , Springer, Heidelberg, https://doi.org/10.1007/978-3-642-15561-111; Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L., ImageNet: A large-scale hierarchical image database (2009) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 248-255. , IEEE; Russakovsky, O., ImageNet large scale visual recognition challenge (2015) Int. J. Comput. Vis. (IJCV), 115 (3), pp. 211-252; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-Scale Image Recognition, , arXiv preprint arXiv; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826; He, K., Zhang, X., Ren, S., Sun, J., Identity mappings in deep residual networks (2016) ECCV 2016. LNCS, 9908, pp. 630-645. , Leibe, B., Matas, J., Sebe, N., Welling, M. (eds.) , Springer, Cham, https://doi.org/10.1007/978-3-319-46493-0 38; Nicolas, P., (2017) Cleverhans V2.0.0: An Adversarial Machine Learning Library, , arXiv preprint arXiv; Abadi, M., (2016) Tensorflow: Large-Scale Machine Learning on Heterogeneous Distributed Systems, , arXiv preprint arXiv; Dong, Y., Boosting adversarial attacks with momentum (2018) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , June; Carlini, N., Wagner, D., (2016) Towards Evaluating the Robustness of Neural Networks, , arXiv preprint arXiv","Zhou, W.; Basic Research Group, China; 电子邮件: wen8.zhou@gmail.com",Ferrari V.Sminchisescu C.Weiss Y.Hebert M.,,Springer Verlag,"15th European Conference on Computer Vision, ECCV 2018",8 September 2018 through 14 September 2018,,219419,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,,Scopus,2-s2.0-85055725664
"Xiao C., Deng R., Li B., Yu F., Liu M., Song D.",56379538100;57204286868;57188689924;57141404100;9733562100;7402443870;,Characterizing adversarial examples based on spatial consistency information for semantic segmentation,2018,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),11214 LNCS,,,220,237,,5,10.1007/978-3-030-01249-6_14,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055114623&doi=10.1007%2f978-3-030-01249-6_14&partnerID=40&md5=4736459ce6c1dd9978a0f79e2bc1fede,"University of Michigan, Ann Arbor, United States; Simon Fraser University, Burnaby, Canada; UIUC, Champaign, United States; UC Berkeley, Berkeley, United States","Xiao, C., University of Michigan, Ann Arbor, United States; Deng, R., Simon Fraser University, Burnaby, Canada; Li, B., UIUC, Champaign, United States, UC Berkeley, Berkeley, United States; Yu, F., UC Berkeley, Berkeley, United States; Liu, M., University of Michigan, Ann Arbor, United States; Song, D., UC Berkeley, Berkeley, United States","Deep Neural Networks (DNNs) have been widely applied in various recognition tasks. However, recently DNNs have been shown to be vulnerable against adversarial examples, which can mislead DNNs to make arbitrary incorrect predictions. While adversarial examples are well studied in classification tasks, other learning problems may have different properties. For instance, semantic segmentation requires additional components such as dilated convolutions and multiscale processing. In this paper, we aim to characterize adversarial examples based on spatial context information in semantic segmentation. We observe that spatial consistency information can be potentially leveraged to detect adversarial examples robustly even when a strong adaptive attacker has access to the model and detection strategies. We also show that adversarial examples based on attacks considered within the paper barely transfer among models, even though transferability is common in classification. Our observations shed new light on developing adversarial attacks and defenses to better understand the vulnerabilities of DNNs. © Springer Nature Switzerland AG 2018.",Adversarial example; Semantic segmentation; Spatial consistency,Computer vision; Semantics; Adversarial example; Classification tasks; Learning problem; Multiscale processing; Semantic segmentation; Spatial consistency; Spatial context; Deep neural networks,,,,,"Badrinarayanan, V., Kendall, A., Cipolla, R., SegNet: A deep convolutional encoder-decoder architecture for image segmentation (2017) IEEE Trans. Pattern Anal. Mach. Intell., 39 (12), pp. 2481-2495; Bhagoji, A.N., He, W., Li, B., Song, D., (2017) Exploring the Space of Black-Box Attacks on Deep Neural Networks; Brostow, G.J., Shotton, J., Fauqueur, J., Cipolla, R., Segmentation and recognition using structure from motion point clouds (2008) ECCV 2008. LNCS, 5302, pp. 44-57. , https://doi.org/10.1007/978-3-540-88682-2_5, Forsyth, D., Torr, P., Zisserman, A. (eds.), Springer, Heidelberg; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) Proceedings of the 10Th ACM Workshop on Artificial Intelligence and Security, pp. 3-14. , ACM; Carlini, N., Wagner, D.A., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy, pp. 39-57. , https://doi.org/10.1109/SP.2017.49, SP 2017, San Jose, CA, USA, 22-26 May 2017; Chan, T.F., Wong, C.K., Total variation blind deconvolution (1998) IEEE Trans. Image Process., 7 (3), pp. 370-375; Chen, H., Zhang, H., Chen, P.Y., Yi, J., Hsieh, C.J., Attacking visual language grounding with adversarial examples: A case study on neural image captioning (2018) Proceedings of the 56Th Annual Meeting of the Association for Computational Linguistics, Long Papers, 1, pp. 2587-2597; Chen, P.Y., Sharma, Y., Zhang, H., Yi, J., Hsieh, C.J., (2017) EAD: Elastic-Net Attacks to Deep Neural Networks via Adversarial Examples; Chen, P.Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.J., ZOO: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) Proceedings of the 10Th ACM Workshop on Artificial Intelligence and Security, pp. 15-26. , ACM; Cisse, M., Adi, Y., Neverova, N., Keshet, J., (2017) Houdini: Fooling Deep Structured Prediction Models; Cordts, M., The cityscapes dataset for semantic urban scene understanding (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3213-3223; Cui, W., Wang, Y., Fan, Y., Feng, Y., Lei, T., Localized FCM clustering with spatial information for medical image segmentation and bias field estimation (2013) J. Biomed. Imaging, 2013, p. 13; Das, N., (2017) Keeping the Bad Guys Out: Protecting and Vaccinating Deep Learning with JPEG Compression; Dziugaite, G.K., Ghahramani, Z., Roy, D.M., (2016) A Study of the Effect of JPG Compression on Adversarial Images; Everingham, M., Eslami, S.M.A., van Gool, L., Williams, C.K.I., Winn, J., Zisserman, A., The pascal visual object classes challenge: A retrospective (2015) Int. J. Comput. Vis., 111 (1), pp. 98-136; Evtimov, I., (2017) Robust Physical-World Attacks on Machine Learning Models; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; He, W., Wei, J., Chen, X., Carlini, N., Song, D., Adversarial example defense: Ensembles of weak defenses are not strong (2017) 11Th USENIX Workshop on Offensive Technologies (WOOT 2017), , https://www.usenix.org/conference/woot17/workshop-program/presentation/he, USENIX Association, Vancouver; Hinton, G., Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups (2012) IEEE Signal Process. Mag., 29 (6), pp. 82-97; Hosseini, H., Chen, Y., Kannan, S., Zhang, B., Poovendran, R., (2017) Blocking Transferability of Adversarial Examples in Black-Box Learning Systems; Johnson, B., Xie, Z., Unsupervised image segmentation evaluation and refinement using a multi-scale approach (2011) ISPRS J. Photogramm. Remote. Sens., 66 (4), pp. 473-483; Krähenbühl, P., Koltun, V., Efficient inference in fully connected CRFs with Gaussian edge potentials (2011) Advances in Neural Information Processing Systems, pp. 109-117; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Leung, T., Malik, J., Representing and recognizing the visual appearance of materials using three-dimensional textons (2001) Int. J. Comput. Vis., 43 (1), pp. 29-44; Lin, G., Shen, C., van Den Hengel, A., Reid, I., Efficient piecewise training of deep structured models for semantic segmentation (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3194-3203; Liu, Y., Chen, X., Liu, C., Song, D., (2016) Delving into Transferable Adversarial Examples and Black-Box Attacks; Long, J., Shelhamer, E., Darrell, T., Fully convolutional networks for semantic segmentation (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3431-3440; Ma, X., (2018) Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 427-436. , IEEE; Noda, K., Arie, H., Suga, Y., Ogata, T., Multimodal integration learning of robot behavior using deep neural networks (2014) Robot. Auton. Syst., 62 (6), pp. 721-736; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-Box Attacks Using Adversarial Samples; Ronneberger, O., Fischer, P., Brox, T., U-Net: Convolutional networks for biomedical image segmentation (2015) MICCAI 2015. LNCS, 9351, pp. 234-241. , https://doi.org/10.1007/978-3-319-24574-4_28, Navab, N., Hornegger, J., Wells, W.M., Frangi, A.F. (eds.), Springer, Cham; Saha, P.K., Udupa, J.K., Odhner, D., Scale-based fuzzy connected image segmentation: Theory, algorithms, and validation (2000) Comput. Vis. Image Underst., 77 (2), pp. 145-174; Shannon, C.E., Communication theory of secrecy systems (1949) Bell Labs Tech. J., 28 (4), pp. 656-715; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540. , ACM; Szegedy, C., (2013) Intriguing Properties of Neural Networks; Tabacof, P., Valle, E., Exploring the space of adversarial images (2016) 2016 International Joint Conference on Neural Networks (IJCNN), pp. 426-433. , IEEE; Tong, L., Li, B., Hajaj, C., Xiao, C., Vorobeychik, Y., Hardening classifiers against evasion: The good, the bad, and the ugly (2017) Corr; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses; Weng, T.W., (2018) Towards Fast Computation of Certified Robustness for Relu Networks; Weng, T.W., Evaluating the robustness of neural networks: An extreme value theory approach (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=BkUHlMZ0b; Wu, Z., Shen, C., van den Hengel, A., (2016) Wider Or Deeper: Revisiting the Resnet Model for Visual Recognition; Xiao, C., Li, B., Zhu, J.Y., He, W., Liu, M., Song, D., Generating adversarial examples with adversarial networks (2018) Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI 2018, pp. 3905-3911. , https://doi.org/10.24963/ijcai.2018/543, International Joint Conferences on Artificial Intelligence Organization, July; Xiao, C., Sarabi, A., Liu, Y., Li, B., Liu, M., Dumitras, T., From patching delays to infection symptoms: Using risk profiles for an early discovery of vulnerabilities exploited in the wild (2018) 27Th USENIX Security Symposium (USENIX Security 2018). USENIX Association, , https://www.usenix.org/conference/usenixsecurity18/presentation/xiao, Baltimore; Xiao, C., Zhu, J.Y., Li, B., He, W., Liu, M., Song, D., Spatially transformed adversarial examples (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=HyydRMZC-; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., Mitigating adversarial effects through randomization (2018) International Conference on Learning Representations; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., Adversarial examples for semantic segmentation and object detection (2017) International Conference on Computer Vision. IEEE; Yu, F., Koltun, V., Multi-scale context aggregation by dilated convolutions (2016) International Conference on Learning Representations (ICLR; Yu, F., Koltun, V., Funkhouser, T., Dilated residual networks (2017) Computer Vision and Pattern Recognition (CVPR); Yu, F., Wang, D., Darrell, T., (2017) Deep Layer Aggregation; Yu, F., (2018) BDD100K: A Diverse Driving Video Database with Scalable Annotation Tooling; Zeng, D., Liu, K., Lai, S., Zhou, G., Zhao, J., Relation classification via convolutional deep neural network (2014) Proceedings of COLING 2014, the 25Th International Conference on Computational Linguistics: Technical Papers, pp. 2335-2344; Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J., Pyramid scene parsing network (2017) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2881-2890","Xiao, C.; University of MichiganUnited States; 电子邮件: xiaocw@umich.edu",Hebert M.Ferrari V.Sminchisescu C.Weiss Y.,,Springer Verlag,"15th European Conference on Computer Vision, ECCV 2018",8 September 2018 through 14 September 2018,,219419,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85055114623
"Bhagoji A.N., He W., Li B., Song D.",57189365305;57207135651;57188689924;7402443870;,Practical black-box attacks on deep neural networks using efficient query mechanisms,2018,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),11216 LNCS,,,158,174,,44,10.1007/978-3-030-01258-8_10,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055098585&doi=10.1007%2f978-3-030-01258-8_10&partnerID=40&md5=3a733ff1374cb61554364c2914b00a67,"Princeton University, Princeton, United States; University of California, Berkeley, Berkeley, United States; University of Illinois at Urbana-Champaign, Champaign, United States","Bhagoji, A.N., Princeton University, Princeton, United States; He, W., University of California, Berkeley, Berkeley, United States; Li, B., University of Illinois at Urbana-Champaign, Champaign, United States; Song, D., University of California, Berkeley, Berkeley, United States","Existing black-box attacks on deep neural networks (DNNs) have largely focused on transferability, where an adversarial instance generated for a locally trained model can “transfer” to attack other learning models. In this paper, we propose novel Gradient Estimation black-box attacks for adversaries with query access to the target model’s class probabilities, which do not rely on transferability. We also propose strategies to decouple the number of queries required to generate each adversarial sample from the dimensionality of the input. An iterative variant of our attack achieves close to 100% attack success rates for both targeted and untargeted attacks on DNNs. We carry out a thorough comparative evaluation of black-box attacks and show that Gradient Estimation attacks achieve attack success rates similar to state-of-the-art white-box attacks on the MNIST and CIFAR-10 datasets. We also apply the Gradient Estimation attacks successfully against real-world classifiers hosted by Clarifai. Further, we evaluate black-box attacks against state-of-the-art defenses based on adversarial training and show that the Gradient Estimation attacks are very effective even against these defenses. © Springer Nature Switzerland AG 2018.",Adversarial examples; Black-box attacks; Deep neural networks; Image classification,Computer vision; Image classification; Adversarial examples; Black boxes; Class probabilities; Comparative evaluations; Gradient estimation; Learning models; Query mechanisms; State of the art; Deep neural networks,,,,,"Athalye, A., Carlini, N., Wagner, D., Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples (2018) Proceedings of the 35Th International Conference on Machine Learning; Brendel, W., Rauber, J., Bethge, M., Decision-based adversarial attacks: Reliable attacks against black-box machine learning models (2018) International Conference on Learning Representations; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy; Chen, P.Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.J., Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) 11Th ACM Workshop on Artificial Intelligence and Security; (2017) Clarifai — Image & Video Recognition API, , https://clarifai.com.Accessed22, Aug; Dang, H., Yue, H., Chang, E.C., Evading classifiers by morphing in the dark (2017) 24Th ACM Conference on Computer and Communications Security; Goodfellow, I., Bengio, Y., Courville, A., (2016) Deep Learning, , MIT Press, Cambridge; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations; (2017) Vision Api-Image Content analysis—Google Cloud Platform, , https://cloud.google.com/vision/.Accessed22, Aug; Gu, S., Rigazio, L., (2014) Towards Deep Neural Network Architectures Robust to Adversarial Examples, , arXiv preprint arXiv; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Hildebrand, F.B., (1962) Advanced Calculus for Applications, 63. , Prentice-Hall Engle-wood Cliffs, NJ; Ilyas, A., Engstrom, L., Athalye, A., Lin, J., Black-box adversarial attacks with limited queries and information (2018) Proceedings of the 35Th International Conference on Machine Learning; Kennedy, J., Particle swarm optimization (2011) Encyclopedia of Machine Learning, pp. 760-766. , https://doi.org/10.1007/978-0-387-30164-8, Sammut, C., Webb, G.I. (eds.), Springer, Heidelberg; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint arXiv; Lecun, Y., Cortes, C., (1998) The MNIST Database of Handwritten Digits; Liu, A., (2016) Clarifai Featured Hack: Block Unwanted Nudity in Blog Comments with Disqus, , https://goo.gl/TCCVrR, Accessed 22 Aug 2017; Moosavi-Dezfooli, S.M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2016) IEEE Conference on Computer Vision and Pattern Recognition; Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) IEEE Conference on Computer Vision and Pattern Recognition; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) International Conference on Learning Representations; Narodytska, N., Kasiviswanathan, S.P., (2016) Simple Black-Box Adversarial Perturbations for Deep Networks; Nelson, B., Query strategies for evading convex-inducing classifiers (2012) J. Mach. Learn. Res., 13 (1), pp. 1293-1332; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-Box Attacks Using Adversarial Samples, , arXiv preprint arXiv; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against deep learning systems using adversarial examples (2017) ACM Asia Conference on Computer and Communications Security; Salimans, T., Ho, J., Chen, X., Sutskever, I., (2017) Evolution Strategies as a Scalable Alternative to Reinforcement Learning, , arXiv preprint arXiv; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) ACM Conference on Computer and Communications Security; Shlens, J., (2014) A Tutorial on Principal Component Analysis.; Spall, J.C., Multivariate stochastic approximation using a simultaneous perturbation gradient approximation (1992) IEEE Trans. Autom. Control, 37 (3), pp. 332-341; Spall, J.C., (2005) Introduction to Stochastic Search and Optimization: Estimation, Simulation, and Control, 65. , Wiley, Hoboken; Szegedy, C., Intriguing properties of neural networks (2014) International Conference on Learning Representations; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2018) International Conference on Learning Representations; https://www.ibm.com/watson/services/visual-recognition/, Accessed 27 Aug 2017; Wright, S.J., Nocedal, J., Numerical optimization (1999) Springer Sci., 35 (67-68), p. 7; Xu, W., Qi, Y., Evans, D., Automatically evading classifiers (2016) Proceedings of the 2016 Network and Distributed Systems Symposium; Zagoruyko, S., Komodakis, N., (2016) Wide Residual Networks","Bhagoji, A.N.; Princeton UniversityUnited States; 电子邮件: abhagoji@princeton.edu",Hebert M.Ferrari V.Sminchisescu C.Weiss Y.,,Springer Verlag,"15th European Conference on Computer Vision, ECCV 2018",8 September 2018 through 14 September 2018,,219419,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,,Scopus,2-s2.0-85055098585
"Barbar M., Sui Y., Zhang H., Chen S., Xue J.",57202886844;54788439800;57202801696;35241832100;7202881461;,Live path CFI against control flow hijacking attacks,2018,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10946 LNCS,,,768,779,,1,10.1007/978-3-319-93638-3_45,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049771195&doi=10.1007%2f978-3-319-93638-3_45&partnerID=40&md5=63f31c6e214464b01ede0832e066122a,"University of Technology Sydney, Sydney, Australia; University of Newcastle, Callaghan, Australia; CSIRO/Data61, Sydney, Australia; University of New South Wales, Sydney, Australia","Barbar, M., University of Technology Sydney, Sydney, Australia; Sui, Y., University of Technology Sydney, Sydney, Australia; Zhang, H., University of Newcastle, Callaghan, Australia; Chen, S., CSIRO/Data61, Sydney, Australia; Xue, J., University of New South Wales, Sydney, Australia","Through memory vulnerabilities, control flow hijacking allows an attacker to force a running program to execute other than what the programmer has intended. Control Flow Integrity (CFI) aims to prevent the adversarial effects of these attacks. CFI attempts to enforce the programmer’s intent by ensuring that a program only runs according to a control flow graph (CFG) of the program. The enforced CFG can be built statically or dynamically, and Per-Input Control Flow Integrity (PICFI) represents a recent advance in dynamic CFI techniques. PICFI begins execution with the empty CFG of a program and lazily adds edges to the CFG during execution according to concrete inputs. However, this CFG grows monotonically, i.e., edges are never removed when corresponding control flow transfers become illegal. This paper presents LPCFI, Live Path Control Flow Integrity, to more precisely enforce forward edge CFI using a dynamically computed CFG by both adding and removing edges for all indirect control flow transfers from indirect callsites, thereby raising the bar against control flow hijacking attacks. © Springer International Publishing AG, part of Springer Nature 2018.",Control Flow Integrity,Data flow analysis; Security of data; Control flow graphs; Control flows; Control-flow integrities; Indirect control; Path control; Flow graphs,,,,,"Shacham, H., The geometry of innocent flesh on the bone: Return-into-libc without function calls (on the x86) (2007) CCS 2007, pp. 552-561; Schuster, F., Tendyck, T., Liebchen, C., Davi, L., Sadeghi, A.-R., Holz, T., Counterfeit object-oriented programming: On the difficulty of preventing code reuse attacks in C++ applications (2015) S&P 2015, pp. 745-762; Abadi, M., Budiu, M., Erlingsson, Ú., Ligatti, J., Control-flow integrity principles, implementations, and applications (2009) ACM Trans. Inf. Syst. Secur., 13 (1), pp. 4:1–4:40; Niu, B., Tan, G., Per-input control-flow integrity (2015) CCS 2015; Evans, I., Long, F., Otgonbaatar, U., Shrobe, H., Rinard, M., Okhravi, H., Sidiroglou-Douskos, S., Control jujutsu: On the weaknesses of fine-grained control flow integrity (2015) CCS 2015, pp. 901-913; Sui, Y., Xue, J., SVF: Interprocedural static value-flow analysis in LLVM (2016) CC 2016, pp. 265-266; Ding, R., Qian, C., Song, C., Harris, B., Kim, T., Lee, W., Efficient protection of path-sensitive control security (2017) USENIX Security 2017, pp. 131-148; Sinnadurai, S., Zhao, Q., Wong, W.-F., (2008) Transparent Runtime Shadow Stack: Protection against Malicious Return Address Modifications; Erlingsson, Ú., Abadi, M., Vrable, M., Budiu, M., Necula, G.C., XFI: Software guards for system address spaces (2006) OSDI 2006, pp. 75-88; Tice, C., Roeder, T., Collingbourne, P., Checkoway, S., Erlingsson, Ú., Lozano, L., Pike, G., Enforcing forward-edge control-flow integrity in GCC & LLVM (2014) USENIX Security 2014, pp. 941-955; Zhang, C., Carr, S.A., Li, T., Ding, Y., Song, C., Payer, M., Song, D., VTrust: Regaining trust on virtual calls (2016) NDSS 2016; Jang, D., Tatlock, Z., Lerner, S., SafeDispatch: Securing C++ virtual calls from memory corruption attacks (2014) NDSS 2014; Haller, I., Göktaş, E., Athanasopoulos, E., Portokalidis, G., Bos, H., ShrinkWrap: VTable protection without loose ends (2015) ACSAC 2015, pp. 341-350; Fan, X., Sui, Y., Liao, X., Xue, J., Boosting the precision of virtual call integrity protection with partial pointer analysis for C++ (2017) ISSTA 2017, pp. 329-340; Barbar, M., Sui, Y., Zhang, H., Chen, S., Xue, J., Live path control flow integrity (2018) ICSE 2018; Sui, Y., Xue, J., On-demand strong update analysis via value-flow refinement (2016) FSE 2016, pp. 460-473; Castro, M., Costa, M., Harris, T., Securing software by enforcing data-flow integrity (2016) OSDI 2016, pp. 147-160; Kuznetsov, V., Szekeres, L., Payer, M., Candea, G., Sekar, R., Song, D., Code-pointer integrity (2014) OSDI 2014, pp. 147-163","Barbar, M.; University of Technology SydneyAustralia; 电子邮件: mbarbar@runbox.com",Susilo W.Yang G.,Australian Government Department of Defence Science and Technology;Cryptography - Open Access Journal by MDPI;DATA61;et al;School of Computing and Information Technology;Springer,Springer Verlag,"23rd Australasian Conference on Information Security and Privacy, ACISP 2018",11 July 2018 through 13 July 2018,,215579,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,,Scopus,2-s2.0-85049771195
"Xie C., Wang J., Zhang Z., Zhou Y., Xie L., Yuille A.",57200616617;57142698500;57200612412;57195627000;35189768200;7006372632;,Adversarial Examples for Semantic Segmentation and Object Detection,2017,Proceedings of the IEEE International Conference on Computer Vision,2017-October,,8237415,1378,1387,,281,10.1109/ICCV.2017.153,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041912770&doi=10.1109%2fICCV.2017.153&partnerID=40&md5=b364ab7034e1ce3864de4b5c696d6155,"Department of Computer Science, Johns Hopkins University, Baltimore, MD  21218, United States; Baidu Research USA, Sunnyvale, CA  94089, United States","Xie, C., Department of Computer Science, Johns Hopkins University, Baltimore, MD  21218, United States; Wang, J., Baidu Research USA, Sunnyvale, CA  94089, United States; Zhang, Z., Department of Computer Science, Johns Hopkins University, Baltimore, MD  21218, United States; Zhou, Y., Department of Computer Science, Johns Hopkins University, Baltimore, MD  21218, United States; Xie, L., Department of Computer Science, Johns Hopkins University, Baltimore, MD  21218, United States; Yuille, A., Department of Computer Science, Johns Hopkins University, Baltimore, MD  21218, United States","It has been well demonstrated that adversarial examples, i.e., natural images with visually imperceptible perturbations added, cause deep networks to fail on image classification. In this paper, we extend adversarial examples to semantic segmentation and object detection which are much more difficult. Our observation is that both segmentation and detection are based on classifying multiple targets on an image (e.g., the target is a pixel or a receptive field in segmentation, and an object proposal in detection). This inspires us to optimize a loss function over a set of targets for generating adversarial perturbations. Based on this, we propose a novel algorithm named Dense Adversary Generation (DAG), which applies to the state-of-the-art networks for segmentation and detection. We find that the adversarial perturbations can be transferred across networks with different training data, based on different architectures, and even for different recognition tasks. In particular, the transfer ability across networks with the same architecture is more significant than in other cases. Besides, we show that summing up heterogeneous perturbations often leads to better transfer performance, which provides an effective method of black-box adversarial attack. © 2017 IEEE.",,Computer vision; Network architecture; Object detection; Object recognition; Semantics; Loss functions; Multiple targets; Natural images; Novel algorithm; Receptive fields; Semantic segmentation; State of the art; Transfer performance; Image segmentation,,,,,"Baluja, S., Fischer, I., (2017) Adversarial Transformation Networks: Learning to Generate Adversarial Examples, , arXiv preprint arXiv:; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy, , IEEE; Chen, L.-C., Papandreou, G., Kokkinos, I., Murphy, K., Yuille, A.L., Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs (2017) IEEE Transactions on Pattern Analysis and Machine Intelligence; Cordts, M., Omran, M., Ramos, S., Rehfeld, T., Enzweiler, M., Benenson, R., Franke, U., Schiele, B., The cityscapes dataset for semantic urban scene understanding (2016) Computer Vision and Pattern Recognition, , IEEE; Dai, J., Li, Y., He, K., Sun, J., R-fcn: Object detection via region-based fully convolutional networks (2016) Advances in Neural Information Processing Systems; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., Imagenet: A large-scale hierarchical image database (2009) Computer Vision and Pattern Recognition, , IEEE; Donahue, J., Jia, Y., Vinyals, O., Hoffman, J., Zhang, N., Tzeng, E., Darrell, T., Decaf: A deep convolutional activation feature for generic visual recognition (2014) International Conference on Machine Learning; Everingham, M., Zisserman, A., Williams, C.K., Van Gool, L., Allan, M., Bishop, C.M., Chapelle, O., Dorkó, G., (2007) The Pascal Visual Object Classes Challenge 2007 (Voc2007) Results; Fischer, V., Kumar, M.C., Metzen, J.H., Brox, T., Adversarial examples for semantic image segmentation (2017) International Conference on Learning Representations Workshop; Girshick, R., Fast r-cnn (2015) International Conference on Computer Vision, , IEEE; Girshick, R., Donahue, J., Darrell, T., Malik, J., Rich feature hierarchies for accurate object detection and semantic segmentation (2014) Computer Vision and Pattern Recognition, , IEEE; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Computer Vision and Pattern Recognition, , IEEE; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2017) International Conference on Learning Representations; Lin, T.-Y., Dollár, P., Girshick, R., He, K., Hariharan, B., Belongie, S., Feature pyramid networks for object detection (2017) Computer Vision and Pattern Recognition, , IEEE; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) International Conference on Learning Representations; Long, J., Shelhamer, E., Darrell, T., Fully convolutional networks for semantic segmentation (2015) Computer Vision and Pattern Recognition, , IEEE; Luo, Y., Boix, X., Roig, G., Poggio, T., Zhao, Q., (2015) Foveationbased Mechanisms Alleviate Adversarial Examples, , arXiv preprint arXiv:1511.06292; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., On detecting adversarial perturbations (2017) International Conference on Learning Representations; Metzen, J.H., Kumar, M.C., Brox, T., Fischer, V., (2017) Universal Adversarial Perturbations Against Semantic Image Segmentation, , arXiv preprint arXiv:1704.05712; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) Computer Vision and Pattern Recognition, , IEEE; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Computer Vision and Pattern Recognition, , IEEE; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Computer Vision and Pattern Recognition, , IEEE; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) ACM on Asia Conference on Computer and Communications Security. ACM; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) IEEE Symposium on Security and Privacy, , IEEE; Ren, S., He, K., Girshick, R., Sun, J., Faster r-cnn: Towards real-time object detection with region proposal networks (2015) Advances in Neural Information Processing Systems; Sharif Razavian, A., Azizpour, H., Sullivan, J., Carlsson, S., Cnn features off-the-shelf: An astounding baseline for recognition (2014) CVPR Workshops, , IEEE; Shen, W., Wang, X., Wang, Y., Bai, X., Zhang, Z., Deepcontour: A deep convolutional feature learned by positivesharing loss for contour detection (2015) Computer Vision and Pattern Recognition, , IEEE; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) International Conference on Learning Representations; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) Computer Vision and Pattern Recognition, , IEEE; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., Mc-Daniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses, , arXiv preprint arXiv:1705.07204; Wang, J., Zhang, Z., Xie, C., Premachandran, V., Yuille, A., (2015) Unsupervised Learning of Object Semantic Parts from Internal States of Cnns by Population Encoding, , arXiv preprint arXiv:1511.06855; Xie, S., Tu, Z., Holistically-nested edge detection (2015) International Conference on Computer Vision, , IEEE; Zeiler, M.D., Fergus, R., Visualizing and understanding convolutional networks (2014) European Conference on Computer Vision, , Springer; Zheng, S., Jayasumana, S., Romera-Paredes, B., Vineet, V., Su, Z., Du, D., Huang, C., Torr, P.H., Conditional random fields as recurrent neural networks (2015) International Conference on Computer Vision, , IEEE",,,,Institute of Electrical and Electronics Engineers Inc.,"16th IEEE International Conference on Computer Vision, ICCV 2017",22 October 2017 through 29 October 2017,,133704,15505499,9.78E+12,PICVE,,English,Proc IEEE Int Conf Comput Vision,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-85041912770
"Das D., Das S.",57209055303;7406323916;,Intelligent resource allocation scheme for the cognitive radio network in the presence of primary user emulation attack,2017,IET Communications,11,15,,2370,2379,,10,10.1049/iet-com.2016.0235,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032748305&doi=10.1049%2fiet-com.2016.0235&partnerID=40&md5=042f8bbe485a884a608fa3cc33ede327,"Department of Electrical Engineering, NIT, Rourkela, India","Das, D., Department of Electrical Engineering, NIT, Rourkela, India; Das, S., Department of Electrical Engineering, NIT, Rourkela, India","An energy-efficient cognitive radio network (CRN) design is one of the primary requirements for the low-battery-driven wireless terminals in the presence of primary user emulation attack. Furthermore, sensing accuracy is also essential for allocating vacant bands to the secondary users (SUs) for data transmission. Hence, this study focuses on designing an energy-efficient double threshold-based CRN. The adversarial effects arising in the presence of the attacker are analysed and are treated as constraints while formulating the energy efficiency (EE) maximisation problem. To develop the formulation, a unique SU selection algorithm to identify most eligible SUs for data transmission is proposed. The EE is then maximised by minimising the total power consumption through novel adaptive resource allocation algorithm. Hence, the authors proposed approaches are based on the suitable selection of SUs and adaptive power allocation under the constraints of maximum throughput, controlled transmission power providing sufficient protection to the primary user, minimum power consumption and minimum false alarm probability. The extensive simulation results demonstrate that the proposed scheme substantially increases EE with lower complexity over the conventional scheme. © 2017, The Institution of Engineering and Technology.",,Data transfer; Electric power supplies to apparatus; Electric power utilization; Energy efficiency; Resource allocation; Adaptive power allocation; Adaptive resource allocations; Cognitive radio network; Cognitive radio network (CRN); Extensive simulations; False alarm probability; Primary user emulation attack (PUEA); Total power consumption; Cognitive radio,,,,,"Akyildiz, I.F., Lee, W.-Y., Vuran, M.C., 'Next generation/dynamic spectrum access/cognitive radio wireless networks: a survey' (2006) Comput. Netw, 50 (13), pp. 2127-2159; Das, D., Das, S., 'Primary user emulation attack in cognitive radio networks: a survey' (2013) IRACST-Int. J. Comput. Netw. Wireless Commun, 3, pp. 312-318; Yu, R., Zhang, Y., Liu, Y., 'Securing cognitive radio networks against primary user emulation attacks' (2016) IEEE Netw, 30 (6), pp. 62-69; Bhowmick, A., Chandra, A., Dhar Roy, S., 'Double threshold-based cooperative spectrum sensing for a cognitive radio network with improved energy detectors' (2015) IET Commun, 9 (18), pp. 2216-2226; Duan, L., Zhang, L., Chu, Y., 'Cooperative spectrum sensing with double threshold detection based on reputation in cognitive radio' (2009) Proc. 5th Int. Conf. Wireless Communications, Networking and Mobile Computing, WiCOM 2009, pp. 1-4; Jiang, Z., Zhengguang, X., Furong, W., 'Double threshold energy detection of cooperative spectrum sensing in cognitive radio' (2008) 3rd Int. Conf. Cognitive Radio Oriented Wireless Networks and Communications, 2008, CrownCom 2008, pp. 1-5; Mohammed, F., Deriche, M., 'A two-threshold cooperative spectrum sensing algorithm using swarm intelligence' (2013) Computing, pp. 59-62. , Communications and IT Applications Conf. (ComComAp), 2013, no; Zhang, X., Su, H., 'CREAM-MAC: cognitive radio-enabled multi-channel MAC protocol over dynamic spectrum access networks' (2011) IEEE J. Sel. Top. Signal Process, 5 (1), pp. 110-123; Alahmadi, A., Fang, Z., Song, T., 'Subband PUEA detection and mitigation in OFDM-based cognitive radio networks' (2015) IEEE Trans. Inf. Forensics Sec, 10 (10), pp. 2131-2142; Saber, M.J., Sadough, S.M.S., 'Optimal soft combination for multiple antenna energy detection under primary user emulation attacks' (2015) AEU-Int. J. Electron. Commun, 69 (9), pp. 1181-1188; Sharifi, A.A., Sharifi, M., Niya, M.J.M., 'Secure cooperative spectrum sensing under primary user emulation attack in cognitive radio networks: attack-aware threshold selection approach' (2016) AEU-Int. J. Electron. Commun, 70 (1), pp. 95-104; Haghighat, M., Fathi, H., Sadough, S.M.S., 'Robust resource allocation for OFDM-based cognitive radio in the presence of primary user emulation attack' (2012) Radioengineering, 21 (4), pp. 1085-1091; Du, J., Guo, D., Zhang, B., 'A robust cooperative spectrum sensing-assisted multiuser resource allocation scheme' (2015) Math. Probl. Eng., 2015, p. 12; Chen, J., Lv, L., Liu, Y., 'Energy efficient relay selection and power allocation for cooperative cognitive radio networks' (2015) IET Commun, 9 (13), pp. 1661-1668; Xu, X., Bao, J., Cao, H., 'Energy-efficiency-based optimal relay selection scheme with a BER constraint in cooperative cognitive radio networks' (2016) IEEE Trans. Veh. Technol, 65 (1), pp. 191-203; Zahmati, A.S., Fernando, X., Grami, A., 'Energy-aware secondary user selection in cognitive sensor networks' (2014) IET Wirel. Sens. Syst, 4 (2), pp. 86-96; Wu, Y., Zhu, Q., Huang, J., 'Revenue sharing based resource allocation for dynamic spectrum access networks' (2014) IEEE J. Sel. Areas Commun, 32 (11), pp. 2280-2296; Illanko, K., Naeem, M., Anpalagan, A., 'Energy-efficient frequency and power allocation for cognitive radios in television systems' (2016) IEEE Syst. J, 10 (1), pp. 313-324; Wu, Y., Wang, J., Qian, L., 'Optimal power control for energy efficient D2D communication and its distributed implementation' (2015) IEEE Commun. Lett, 19 (5), pp. 815-818; Quan, Z., Cui, S., Sayed, A.H., 'Optimal linear cooperation for spectrum sensing in cognitive radio networks' (2008) IEEE J. Sel. Top. Signal Process, 2 (1), pp. 28-40; Chu, E., Peh, Y., Member, S., 'Optimization of cooperative sensing in cognitive radio networks: a sensing-throughput tradeoff view' (2009) IEEE Trans. Veh. Technol, 58 (9), pp. 5294-5299; Yoon, S.U., Ekici, E., 'Voluntary spectrum handoff: a novel approach to spectrum management in CRNs' (2010) IEEE Int. Conf. Communications, pp. 1-5; Shi, W., Wang, S., Chen, D., 'Energy-and spectrum-efficiency tradeoff in OFDM-based cognitive radio systems' (2014) 2014 IEEE Global Communications Conf. GLOBECOM 2014, pp. 3092-3097; Ciochina, S., Paleologu, C., Benesty, J., 'An optimized NLMS algorithm for acoustic echo cancellation' (2015) ISSCS 2015-Int. Symp. Signals, pp. 1-19. , Circuits and Systems; Wang, D., Bai, B., Chen, W., 'Energy efficient secure communication over decode-and-forward relay channels' (2015) IEEE Trans. Commun, 63 (3), pp. 892-905; Hu, H., Zhang, H., Yu, H., 'Energy-efficient sensing for delay-constrained cognitive radio systems via convex optimization' (2016) J. Optim. Theory Appl, 168 (1), pp. 310-331","Das, D.; Department of Electrical Engineering, India; 电子邮件: deepadas.ctc@gmail.com",,,Institution of Engineering and Technology,,,,,17518628,,,,English,IET Commun.,Article,Final,,Scopus,2-s2.0-85032748305
"Abhishek Anand S., Saxena N.",57209188098;57206303753;,Coresident evil: Noisy vibrational pairing in the face of Co-located acoustic eavesdropping,2017,"Proceedings of the 10th ACM Conference on Security and Privacy in Wireless and Mobile Networks, WiSec 2017",,,,173,183,,7,10.1145/3098243.3098256,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027711791&doi=10.1145%2f3098243.3098256&partnerID=40&md5=2760012f2045054bc21efe9ef6aeaee0,"University of Alabama, Birmingham, United States","Abhishek Anand, S., University of Alabama, Birmingham, United States; Saxena, N., University of Alabama, Birmingham, United States","An interesting approach to pairing devices involves the use of a vibrational channel, over which the keying material (e.g., a short PIN) is sent. This approach is efficient (only a unidirectional transfer of PIN is needed) and simple (the sending device requires a vibration motor and receiving device requires an accelerometer). However, it has been shown to be susceptible to acoustic emanations usually produced by the vibration motor. Recent research introduced a mechanism to defeat these attacks by attempting to mask the acoustic leakage with deliberate acoustic noises. In this paper, we pursue a systematic investigation of the security of such a ""noisy vibrational pairing"" mechanism in a strong yet realistic adversarial model where the eavesdropper is co-located with the victim device(s). Our contributions are two-fold. First, we show that existing noisy vibrational pairing mechanisms - based on white noise as the masking signal - are vulnerable against a co-located eavesdropper (although they may defeat a distant eavesdropper). We build our attack based on standard signal processing and noise filtering techniques, and show that it can result in a complete compromise of pairing security. Second, we propose a defense that bolsters the masking signal with low-frequency audio tones. We present and address the challenges associated with producing such low-frequency sounds with current commodity hardware. We show that our defensive approach can not only resist our above attack but is also robust to more sophisticated, noise filtering and source separation methods when applicable. We also establish that the insertion of low-frequency sounds does not affect the receiving device's capability to sense the vibrations generated by the sending device. The suggested defense may therefore be used to enhance the security of noisy vibrational pairing without affecting its performance on a wide variety of devices. © 2017 ACM.",,Acoustic noise; Mobile security; Mobile telecommunication systems; Signal processing; Source separation; Spurious signal noise; White noise; Wireless networks; Commodity hardware; Low-frequency sounds; Masking signals; Pairing mechanism; Recent researches; Separation methods; Standard signals; Vibration motor; Network security,,,,,"(2016) AmpAudio, , https://www.ampaudio.com, 4 2016; Anand, S., Saxena, N., Vibreaker: Securing vibrational pairing with deliberate acoustic noise (2016) 9th ACM Conference on Security & Privacy in Wireless and Mobile Networks (WiSec'16); Boyko, V., MacKenzie, P., Patel, S., Provably secure password-authenticated key exchange using diffie-hellman (2000) Eurocrypt; Cardoso, J., Blind source separations: Statistical principles (1998) Proc. IEEE, 9 (10), pp. 2009-2025. , 1998; Cichocki, A., Karhunen, J., Kasprzak, W., Vigario, R., Neural networks for blind separation with unknown number of sources (1999) NeuroComputing, 24 (1), p. 5593. , 1999; De Luca, A., Von Zezschwitz, E., Raghunathan, V., Humann, H., VibraPass-secure authentication based on shared lies (2009) International Conference for Human-computer Interaction (CHI) (CHI'09); Fiona, A.H.Y., (2006) Keyboard Acoustic Triangulation Attack, , http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.100.3156&rep=rep1&type=pdf, 2006. Final Year Project; (2017) GuardRFID Announces Ultra Low Profile Active RFID Tag Which Includes Motion and Temperature Sensing, , http://www.guardrfid.com/news/guardrid-announces-ultra-low-proile-active-rid-tag-which-includes-motion-and-temperature, 3 2017; Halevi, T., Saxena, N., Acoustic eavesdropping attacks on constrained wireless device pairing (2013) IEEE Transactions on Information Forensics and Security (TIFS); Hyvarinen, A., Fast and robust fixed-point algorithms for independent component analysis (1999) IEEE Transactions on Neural Networks, 10 (3), pp. 626-634. , 1999; (2017) B6 Omnidirectional Lavalier, , http://www.countryman.com/b6-omnidirectional-lavalier-microphone, 3 2017; (2016) JBL - Clip Portable Bluetooth Speaker, , http://www.bestbuy.com/site/jbl-clip-portable-bluetooth-speaker-purple/6050039.p?id=1219696711027&skuId=6050039, 4 2016; Kainda, R., Flechais, I., Roscoe, A.W., Usability and security of out-of-band channels in secure device pairing protocols (2009) SOUPS; Kim, Y., Lee, W.S., Raghunathan, V., Jha, N.K., Raghunathan, A., Vibration-based secure side channel for medical devices (2015) Proceedings of the 52Nd Annual Design Automation Conference (DAC'15); (2016) Altec Lansing - Mini H2O Bluetooth Speaker, , http://www.alteclansing.com/en/al-products/mini-h20-speaker, 4 2016; (2017) JBL Soundboost Speaker, , https://www.motorola.com/us/products/moto-mods/jbl-soundboost-speaker, 3 2017; Roy, N., Gowda, M., Choudhury, R.R., Ripple: Communicating through physical vibration (2015) 12th USENIX Symposium on Network Systems Design and Implementation (NSDI'15); Saxena, N., Borhan Uddin, Md., Voris, J., Asokan, N., Vibrateto-unlock: Mobile phone assisted user authentication to multiple personal RFID tags (2011) IEEE International Conference on Pervasive Computing and Communications (Percom'11); (2017) SensMaster's Samui and Boyard Available Now with Cost-effective Motion Detector, , http://www.veryfields.net/active-rfid-tags-with-motion-detector-sensmaster, 3 2017; (2017) Sony SRS-XB2, , http://www.sony.com/electronics/wireless-speakers/srs-xb2, 3 2017; (2017) LET'S SAY HELLO MOTO, CEBU!, , http://www.uterlyrandomtechie.com/lets-say-hello-moto-cebu, 3 2017; (2016) Zagg Speaker Case, , http://www.zagg.com/us/en_us/cases/iphone-6-case/speaker-case, 4 2016; Zhang, B., Zhan, Q., Chen, S., Li, M., Ren, K., Wang, C., Di Ma, PriWhisper: Enabling keyless secure acoustic communication for smartphones (2014) IEEE Internet of Things Journal, 1 (1), pp. 33-45. , 2014",,,"ACM Special Interest Group on Security, Audit, and Control (SIGSAC);National Science Foundation (NSF)","Association for Computing Machinery, Inc","10th ACM Conference on Security and Privacy in Wireless and Mobile Networks, WiSec 2017",18 July 2017 through 20 July 2017,,129154,,9.78E+12,,,English,"Proc. ACM Conf. Secur. Priv. Wirel. Mob. Netw., WiSec",Conference Paper,Final,,Scopus,2-s2.0-85027711791
"Kurakin A., Goodfellow I.J., Bengio S.",57202499592;35956088800;57203254475;,Adversarial machine learning at scale,2017,"5th International Conference on Learning Representations, ICLR 2017 - Conference Track Proceedings",,,,,,,408,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088231002&partnerID=40&md5=3817712882165d26bde2bb06a4f58137,"Google Brain, United States; OpenAI, United States","Kurakin, A., Google Brain, United States; Goodfellow, I.J., OpenAI, United States; Bengio, S., Google Brain, United States","Adversarial examples are malicious inputs designed to fool machine learning models. They often transfer from one model to another, allowing attackers to mount black box attacks without knowledge of the target model's parameters. Adversarial training is the process of explicitly training a model on adversarial examples, in order to make it more robust to attack or to reduce its test error on clean inputs. So far, adversarial training has primarily been applied to small problems. In this research, we apply adversarial training to ImageNet (Russakovsky et al., 2014). Our contributions include: (1) recommendations for how to succes-fully scale adversarial training to large models and datasets, (2) the observation that adversarial training confers robustness to single-step attack methods, (3) the finding that multi-step attack methods are somewhat less transferable than single-step attack methods, so single-step attacks are the best for mounting black-box attacks, and (4) resolution of a “label leaking” effect that causes adversarially trained models to perform better on adversarial examples than on clean examples, because the adversarial example construction process uses the true label and the model can learn to exploit regularities in the construction process. © ICLR 2019 - Conference Track Proceedings. All rights reserved.",,Construction; Large dataset; Attack methods; Black boxes; Construction process; Large models; Machine learning models; Multi-step attacks; Target model; Test errors; Machine learning,,,,,"Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndic, N., Laskov, P., Giacinto, G.-G., Roli, F., Evasion attacks against machine learning at test time (2013) Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 387-402. , Springer; Clevert, D.-A., Unterthiner, T., Hochreiter, S., (2015) Fast and Accurate Deep Network Learning by Exponential Linear Units (Elus), , http://arxiv.org/abs/1511.07289, CoRR, abs/1511.07289; Dalvi, N., Domingos, P., Sanghai, S., Verma, D., Adversarial classification (2004) Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 99-108; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , http://arxiv.org/abs/1412.6572, CoRR, abs/1412.6572; Huang, R., Xu, B., Schuurmans, D., Szepesvári, C., Learning with a strong adversary (2015) CoRR, , http://arxiv.org/abs/1511.03034, abs/1511.03034; Ioffe, S., Szegedy, C., (2015) Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , https://arxiv.org/abs/1607.02533, Technical report, arXiv; Miyato, T., Dai, A.M., Goodfellow, I., (2016) Virtual Adversarial Training for Semi-Supervised Text Classification, , arXiv preprint; Miyato, T., Maeda, S.-I., Koyama, M., Nakae, K., Ishii, S., Distributional smoothing with virtual adversarial training (2016) International Conference on Learning Representations (ICLR2016), , April; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-Box Attacks Using Adversarial Samples, , http://arxiv.org/abs/1605.07277, ArXiv e-prints, May; Papernot, N., McDaniel, P.D., Wu, X., Jha, S., Swami, A., (2015) Distillation as a Defense to Adversarial Perturbations against Deep Neural Networks, , http://arxiv.org/abs/1511.04508, CoRR, abs/1511.04508; Papernot, N., McDaniel, P.D., Goodfellow, I.J., Jha, S., Berkay Celik, Z., Swami, A., (2016) Practical Black-Box Attacks against Deep Learning Systems Using Adversarial Examples, , http://arxiv.org/abs/1602.02697, CoRR, abs/1602.02697; Rozsa, A., Günther, M., Boult, T.E., (2016) Are Accuracy and Robustness Correlated?, , arXiv preprint; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Bernstein, M., (2014) Imagenet Large Scale Visual Recognition Challenge, , arXiv preprint; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R., Intriguing properties of neural networks (2014) ICLR, , http://arxiv.org/abs/1312.6199, abs/1312.6199; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., (2015) Rethinking the Inception Architecture for Computer Vision, , http://arxiv.org/abs/1512.00567, CoRR, abs/1512.00567; Szegedy, C., Ioffe, S., Vanhoucke, V., Inception-v4, inception-resnet and the impact of residual connections on learning (2016) CoRR, , http://arxiv.org/abs/1602.07261, abs",,,,"International Conference on Learning Representations, ICLR","5th International Conference on Learning Representations, ICLR 2017",24 April 2017 through 26 April 2017,,149804,,,,,English,"Int. Conf. Learn. Represent., ICLR - Conf. Track Proc.",Conference Paper,Final,,Scopus,2-s2.0-85088231002
"Liu Y., Chen X., Liu C., Song D.",57210574154;57208640696;55873082700;7402443870;,Delving into transferable adversarial examples and black-box attacks,2017,"5th International Conference on Learning Representations, ICLR 2017 - Conference Track Proceedings",,,,,,,241,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088225756&partnerID=40&md5=84bfcdfc146d3ce2983bbd860c3547ce,"Shanghai Jiao Tong University, China; University of the California, Berkeley, United States","Liu, Y., Shanghai Jiao Tong University, China, University of the California, Berkeley, United States; Chen, X., Shanghai Jiao Tong University, China, University of the California, Berkeley, United States; Liu, C., University of the California, Berkeley, United States; Song, D., University of the California, Berkeley, United States","An intriguing property of deep neural networks is the existence of adversarial examples, which can transfer among different architectures. These transferable adversarial examples may severely hinder deep neural network-based applications. Previous works mostly study the transferability using small scale datasets. In this work, we are the first to conduct an extensive study of the transferability over large models and a large scale dataset, and we are also the first to study the transferability of targeted adversarial examples with their target labels. We study both non-targeted and targeted adversarial examples, and show that while transferable non-targeted adversarial examples are easy to find, targeted adversarial examples generated using existing approaches almost never transfer with their target labels. Therefore, we propose novel ensemble-based approaches to generating transferable adversarial examples. Using such approaches, we observe a large proportion of targeted adversarial examples that are able to transfer with their target labels for the first time. We also present some geometric studies to help understanding the transferable adversarial examples. Finally, we show that the adversarial examples generated using ensemble-based approaches can successfully attack Clarifai.com, which is a black-box image classification system. © ICLR 2019 - Conference Track Proceedings. All rights reserved.",,Large dataset; Black boxes; Image classification systems; Large models; Large-scale dataset; Network based applications; Non-targeted; Small scale; Target labels; Deep neural networks,,,,,"Carlini, N., Wagner, D., (2016) Towards Evaluating the Robustness of Neural Networks, , arXiv preprint; Fawzi, A., Moosavi-Dezfooli, S.-M., Frossard, P., Robustness of classifiers: From adversarial to random noise (2016) Advances in Neural Information Processing Systems, pp. 1624-1632; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint; He, K., Zhang, X., Ren, S., Sun, J., (2015) Deep Residual Learning for Image Recognition, , arXiv preprint; Kingma, D.P., Ba, J., (2014) Adam: A Method for Stochastic Optimization, , http://arxiv.org/abs/1412.6980, CoRR, abs/1412.6980; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proceedings of the IEEE, 86 (11), pp. 2278-2324; Liu, Y., Chen, X., Liu, C., Song, D., (2016) Delving into Transferable Adversarial Examples and Black-Box Attacks, , arXiv preprint; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., (2016) Universal Adversarial Perturbations, , arXiv preprint; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-Box Attacks Using Adversarial Samples, , arXiv preprint; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., (2016) Practical Black-Box Attacks against Deep Learning Systems Using Adversarial Examples, , arXiv preprint; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Fei-Fei, L., ImageNet large scale visual recognition challenge (2015) International Journal of Computer Vision (IJCV), 115 (3), pp. 211-252; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-Scale Image Recognition, , http://arxiv.org/abs/1409.1556, CoRR, abs/1409.1556; Stallkamp, J., Schlipsing, M., Salmen, J., Igel, C., Man vs. Computer: Benchmarking machine learning algorithms for traffic sign recognition (2012) Neural Networks, , http://www.sciencedirect.com/science/article/pii/S0893608012000457, 0):-; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S.E., Anguelov, D., Erhan, D., Rabinovich, A., (2014) Going Deeper with Convolutions, , http://arxiv.org/abs/1409.4842, CoRR, abs/1409.4842",,,,"International Conference on Learning Representations, ICLR","5th International Conference on Learning Representations, ICLR 2017",24 April 2017 through 26 April 2017,,149804,,,,,English,"Int. Conf. Learn. Represent., ICLR - Conf. Track Proc.",Conference Paper,Final,,Scopus,2-s2.0-85088225756
"Possas R., Zhou Y.",57197825519;55718571500;,Effectiveness of Adversarial Attacks on Class-Imbalanced Convolutional Neural Networks,2017,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10635 LNCS,,,333,342,,,10.1007/978-3-319-70096-0_35,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035137433&doi=10.1007%2f978-3-319-70096-0_35&partnerID=40&md5=adb32253550546b53c88c1ce52057a3d,"School of Information Technologies, University of Sydney, Camperdown, NSW, Australia","Possas, R., School of Information Technologies, University of Sydney, Camperdown, NSW, Australia; Zhou, Y., School of Information Technologies, University of Sydney, Camperdown, NSW, Australia","Convolutional neural networks (CNNs) performance has increased considerably in the last couple of years. However, as with most machine learning methods, these networks suffer from the data imbalance problem - when the underlying training dataset is comprised of an unequal number of samples for each label/class. Such imbalance enforces a phenomena known as domain shift that causes the model to have poor generalisation when presented with previously unseen data. Recent research has focused on a technique called gradient sign that intensifies domain shift in CNNs by modifying inputs to deliberately yield erroneous model outputs, while appearing unmodified to human observers. Several commercial systems rely on image recognition techniques to perform well. Therefore, adversarial attacks poses serious threats to their integrity. In this work we present an experimental study that sheds light on the link between adversarial attacks, imbalanced learning and transfer learning. Through a series of experiments we evaluate the fast gradient sign method on class imbalanced CNNs, linking model vulnerabilities to the characteristics of its underlying training set and internal model knowledge. © 2017, Springer International Publishing AG.",Adversarial examples; Convolutional neural networks; Gradient sign; Imbalanced training; Transfer learning,Image recognition; Learning systems; Neural networks; Adversarial examples; Commercial systems; Convolutional neural network; Imbalanced Learning; Internal modeling; Machine learning methods; Recent researches; Transfer learning; Convolution,,,,,"Barua, S., Islam, M.M., Murase, K., A novel synthetic minority oversampling technique for imbalanced data set learning (2011) ICONIP 2011, Part II. LNCS, 7063, pp. 735-744. , Lu, B.-L., Zhang, L., Kwok, J. (eds.), Springer, Heidelberg; Billovits, C., Eric, M., Agarwala, N., (2016) Hitting Depth: Investigating Robustness to Adversarial Examples in Deep Convolutional Neural Networks; Dauphin, Y., De Vries, H., Bengio, Y., Equilibrated adaptive learning rates for non-convex optimization (2015) Advances in Neural Information Processing Systems, pp. 1504-1512; Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L., Imagenet: A large-scale hierarchical image database (2009) IEEE Conference on Computer Vision and Pattern Recognition, CVPR, pp. 248-255; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; He, H., Bai, Y., Garcia, E.A., Li, S., Adasyn: Adaptive synthetic sampling approach for imbalanced learning (2008) IEEE International Joint Conference on Neural Networks, pp. 1322-1328; Japkowicz, N., Stephen, S., The class imbalance problem: A systematic study (2002) Intell. Data Anal, 6 (5), pp. 429-449; Krawczyk, B., Learning from imbalanced data: Open challenges and future directions (2016) Prog. Artif. Intell., 5 (4), pp. 221-232; Krizhevsky, A., (2009) Cifar-10 and Cifar-100 Datasets, , https://www.cs.toronto.edu/; Laskov, P., Lippmann, R., Machine learning in adversarial environments (2010) Mach. Learn., 81 (2), pp. 115-119; Lawrence, S., Giles, C.L., Tsoi, A.C., Back, A.D., Face recognition: A convolutional neural-network approach (1997) IEEE Trans. Neural Netw., 8 (1), pp. 98-113; Lowd, D., Meek, C., Adversarial learning (2005) Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining, pp. 641-647. , http://doi.acm.org/10.1145/1081870.1081950; Papernot, N., (2016) On the Integrity of Deep Learning Systems in Adversarial Settings; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-Box Attacks Using Adversarial Samples; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., (2016) Practical Black-Box Attacks against Deep Learning Systems Using Adversarial Examples; Quionero-Candela, J., Sugiyama, M., Schwaighofer, A., Lawrence, N.D., (2009) Dataset Shift in Machine Learning, , The MIT Press, Cambridge; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-Scale Image Recognition; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks; Yosinski, J., Clune, J., Bengio, Y., Lipson, H., How transferable are features in deep neural networks? (2014) Advances in Neural Information Processing Systems, pp. 3320-3328","Possas, R.; School of Information Technologies, Australia; 电子邮件: rafael.possas@sydney.edu.au",Zhao D.El-Alfy E.M.Liu D.Xie S.Li Y.,,Springer Verlag,"24th International Conference on Neural Information Processing, ICONIP 2017",14 November 2017 through 18 November 2017,,204399,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,,Scopus,2-s2.0-85035137433
"Kim J.-Y., Bu S.-J., Cho S.-B.",56526721100;57194697819;7404884741;,Malware detection using deep transferred generative adversarial networks,2017,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10634 LNCS,,,556,564,,32,10.1007/978-3-319-70087-8_58,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035114862&doi=10.1007%2f978-3-319-70087-8_58&partnerID=40&md5=d489058130547a2f8288c546507ae532,"Department of Computer Science, Yonsei University, Seoul, South Korea","Kim, J.-Y., Department of Computer Science, Yonsei University, Seoul, South Korea; Bu, S.-J., Department of Computer Science, Yonsei University, Seoul, South Korea; Cho, S.-B., Department of Computer Science, Yonsei University, Seoul, South Korea","Malicious software is generated with more and more modified features of which the methods to detect malicious software use characteristics. Automatic classification of malicious software is efficient because it does not need to store all characteristic. In this paper, we propose a transferred generative adversarial network (tGAN) for automatic classification and detection of the zero-day attack. Since the GAN is unstable in training process, often resulting in generator that produces nonsensical outputs, a method to pre-train GAN with autoencoder structure is proposed. We analyze the detector, and the performance of the detector is visualized by observing the clustering pattern of malicious software using t-SNE algorithm. The proposed model gets the best performance compared with the conventional machine learning algorithms. © Springer International Publishing AG 2017.",Autoencoder; Generative adversarial network; Malicious software; Transfer learning; Zero-day attack,Computer crime; Learning algorithms; Learning systems; Adversarial networks; Auto encoders; Automatic classification; Conventional machines; Malware detection; Training process; Transfer learning; Zero day attack; Malware,,,,,"Dhammi, A., Singh, M., Behavior analysis of malware using machine learning (2015) IEEE International Conference on Contemporery Computing, pp. 481-486; Christodorescum, M., Jha, S., Seshia, S.A., Song, D., Bryant, R.E., Semantics-aware malware detection (2005) Security and Privacy, pp. 32-46; Nataraj, L., Karthikeyanm, S., Jacob, G., Manjunath, B.S., Malware images: Visualization and automatic classification (2011) Proceedings of the Conference on Visualizing for Cyber Security, p. 4; Kong, D., Guanhua, Y., Discriminant malware distance learning on structural information for automated malware classification (2013) Proceedings of the Conference on Knowledge Discovery and Datamining, pp. 1357-1365; Pascanu, R., Stokes, J.W., Sanossian, H., Marinescu, M., Thomas, A., Malware classification with recurrent network (2015) Acoustics, Speech and Signal Processing, pp. 1916-1920; Akritidis, P., Kostas, A., Evangelos, M.P., Efficient content-based detection of zero-day worms (2005) Communications, 2, pp. 837-843; Grace, M., Zhou, Y., Zhang, Q., Zou, S., Jiang, X., RiskRanker: Scalable and accurate zero-day android malware detection (2012) Proceedings of the Conference on Mobile Systems, Applications, and Services, pp. 281-294; Goodfellow, I., Pouget-Abadie, J., Mirze, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, pp. 2672-2680; Radford, A., Luke, M., Soumith, C., (2015) Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks; Bourlard, H., Yves, K., Auto-association by multilayer perceptrons and singular value decomposition (1988) Biol. Cybern, 59, pp. 291-294; Lu, X., Matsuda, Y., Hori, C., Speech enhancement based on deep denoising autoencoder (2013) Interspeech, pp. 436-440; Ng, A., Sparse autoencoder. CS294A Lecture (2011) Notes, 72, pp. 1-19; Chandar, A.P.S., Lauly, S., Larochelle, H., Khapra, M., Ravindran, B., Raykar, C.V., Saha, A., An autoencoder approach to learning bilingual word representations (2014) Advances in Neural Information Processing Systems, pp. 1853-1861; Arnold, A., Nallapati, R., Cohen, W., A comparative study of methods for transductive transfer learning (2007) Proceedings of the IEEE International Conference on Data Mining, pp. 77-82; Microsoft Malware Classification Challenge (BIG 2015), , https://www.kaggle.com/c/malware-classification, Accessed 4 Nov 2015; Zeiler, M., Taylor, G., Fergus, R., Adaptive deconvolutional networks for mid and high level feature learning (2011) IEEE International Conference on Computer Vision, pp. 2018-2025; Lecun, Y., Bengio, Y., Convolutional networks for images, speech, and time series (1995) In: The Handbook of Brain Theory and Neural Networks, 3361, p. 1995; Jake, D., Tyler, M., Michael, H., Polymorphic malware detection using sequence calssification methods (2016) Security and Privacy Workshops, pp. 81-87; Narayanan, B.N., Djaneye-Boundjou, O., Kebede, T.M., Performance analysis of machine learning and pattern recognition algorithms for malware classification (2016) Aerospace and Electronics Conference and Ohio Innovation Summit, pp. 338-342; Maaten, L., Hinton, G., Visualizing data using t-SNE (2008) J. Mach. Learn. Res, 9, pp. 2579-2605","Cho, S.-B.; Department of Computer Science, South Korea; 电子邮件: sbcho@yonsei.ac.kr",Li Y.Liu D.Xie S.El-Alfy E.M.Zhao D.,,Springer Verlag,"24th International Conference on Neural Information Processing, ICONIP 2017",14 November 2017 through 18 November 2017,,204399,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,,Scopus,2-s2.0-85035114862
"Cai R.J., Li X.J., Chong P.H.J.",56393843500;56046929300;7102970085;,A novel self-checking ad hoc routing scheme against active black hole attacks,2016,Security and Communication Networks,9,10,,943,957,,5,10.1002/sec.1390,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968562152&doi=10.1002%2fsec.1390&partnerID=40&md5=46640196e7fc6a09ba7baa4cb5b4faa3,"School of EEE, Nanyang Technological University, Singapore; School of Engineering, Auckland University of Technology, Auckland, New Zealand","Cai, R.J., School of EEE, Nanyang Technological University, Singapore; Li, X.J., School of Engineering, Auckland University of Technology, Auckland, New Zealand; Chong, P.H.J., School of EEE, Nanyang Technological University, Singapore","It is challenging to design a routing scheme that can successfully operate in the presence of adversarial environment in mobile ad hoc network (MANET), where several types of severe routing security threats can be easily employed against normal routing. Among them, active black hole attack is a typical one. Most existing defense schemes postulated that active black hole attackers have no knowledge about the internal prevention mechanisms of MANETs. However, due to the open and self-organized nature of MANET, it is necessary to assume that all nodes, including attackers, know how the security mechanism works. In this paper, we propose a distributed self-checking scheme that can effectively prevent various forms of active black hole attackers. Even the internal attackers who know the security mechanism cannot get any benefit to launch those attacks. Simulation results affirm that our proposed solution is robust and able to improve the packet delivery ratio significantly in an adversarial MANET environment as compared with other routing schemes. © 2016 John Wiley & Sons, Ltd.",Active black hole; Neighborhood connectivity; Trust-based routing,Gravitation; Mobile security; Mobile telecommunication systems; Network routing; Network security; Routing protocols; Stars; Technology transfer; Active black holes; Adversarial environments; Internal attacker; Neighborhood connectivity; Packet delivery ratio; Routing security; Security mechanism; Trust-based routing; Mobile ad hoc networks,,,,,"Djenouri, D., Khelladi, L., Badache, A.N., A survey of security issues in mobile ad hoc and sensor networks (2005) IEEE Communications Surveys & Tutorials, 7 (4), pp. 2-28; Tseng, F.-H., Chou, L.-D., Chao, H.-C., A survey of black hole attacks in wireless mobile ad hoc networks (2011) Human-centric Computing and Information Sciences, 1 (1), pp. 1-16; Cai, J., Yi, P., Ye, T., Yongkai, Z., Ning, L., (2009) The simulation and comparison of routing attacks on DSR protocol., pp. 1-4. , in Proc. of the 5th International Conference on Wireless Communications, Networking and Mobile Computing (WiCom), Beijing, China; Hu, Y.C., Perrig, A., Johnson, D.B., Ariadne: a secure on-demand routing protocol for ad hoc networks (2005) Wireless Networks, 11 (1), pp. 21-38; Gong, W., You, Z., Chen, D., Zhao, X., Gu, M., Lam, K.-Y., Trust based routing for misbehavior detection in ad hoc networks (2010) Journal of Networks, 5 (5), pp. 551-558; Woungang, I., Dhurandher, S., Peddi, R., Traore, I., Mitigating collaborative blackhole attacks on DSR-based mobile ad hoc networks (2013) Foundations and Practice of Security, pp. 308-323. , In Springer: Berlin Heidelberg; Jian-Ming, C., Po-Chun, T., Han-Chieh, C., Jiann-Liang, C., (2011) Developing a BDSR scheme to avoid black hole attack based on proactive and reactive architecture in MANETs., pp. 1-5. , in Proc. of the 13th International Conference on Advanced Communication Technology (ICACT), Seoul, Korea; Hoffman, K., Zage, D., Nita-Rotaru, C., A survey of attack and defense techniques for reputation systems (2009) ACM Computing Surveys, 42 (1), pp. 1-31; Pirzada, A., McDonald, C., Secure routing protocols for mobile ad-hoc wireless networks (2005) Advanced Wired and Wireless Networks, pp. 57-80. , In Springer: US; Zapata, M.G., Asokan, N., Securing ad hoc routing protocols (2002) Proc. of the 2002 ACM Workshop on Wireless Security, pp. 1-10. , In Atlanta: United states; Wei, Y., Yan, S., Liu, K.J.R., HADOF: defense against routing disruptions in mobile ad hoc networks (2005) Proc. of the IEEE INFOCOM, pp. 1252-1261. , In, IEEE: Miami, USA; Djenouri, D., Badache, N., Struggling against selfishness and black hole attacks in MANETs (2008) Wireless Communications and Mobile Computing, 8 (6), pp. 689-704; Padmanabhan, V.N., Simon, D.R., Secure traceroute to detect faulty or malicious routing (2003) ACM SIGCOMM Computer Communication Review, 33 (1), pp. 77-82; Hongmei, D., Li, W., Agrawal, D.P., Routing security in wireless ad hoc networks (2002) IEEE Communications Magazine, 40 (10), pp. 70-75; Weerasinghe, H., Huirong, F., Preventing cooperative black hole attacks in mobile ad hoc networks: simulation implementation and evaluation (2007) Proc. of the Future Generation Communication and Networking (FGCN 2007), pp. 362-367. , In, IEEE: Jeju, South Korea; Pirzada, A.A., McDonald, C., Datta, A., Performance comparison of trust-based reactive routing protocols (2006) IEEE Transactions on Mobile Computing, 5 (6), pp. 695-710; RahimiZadeh, K., Kabiri, P., Trust-based routing method using a mobility-based clustering approach in mobile ad hoc networks (2014) Security and Communication Networks, 7 (11), pp. 1746-1763; Misra, S., Krishna, P.V., Abraham, K.I., Adaptive link-state routing and intrusion detection in wireless mesh networks (2010) Information Security, IET, 4 (4), pp. 374-389; Al-Shurman, M., Yoo, S.-M., Park, S., (2004) Black hole attack in mobile ad hoc networks., pp. 96-97. , in Proc. of the 42nd annual Southeast regional conference, Huntsville, Alabama; Narula, P., Dhurandher, S.K., Misra, S., Woungang, I., Security in mobile ad-hoc networks using soft encryption and trust-based multi-path routing (2008) Computer Communications, 31 (4), pp. 760-769; Misra, S., Krishna, P.V., Bhiwal, A., Chawla, A., Wolfinger, B., Lee, C., A learning automata-based fault-tolerant routing algorithm for mobile ad hoc networks (2012) The Journal of Supercomputing, 62 (1), pp. 4-23; Oommen, B.J., Misra, S., Fault-tolerant routing in adversarial mobile ad hoc networks: an efficient route estimation scheme for non-stationary environments (2010) Telecommunication Systems, 44 (1-2), pp. 159-169; Das, S.R., Perkins, C.E., Royer, E.M., Performance comparison of two on-demand routing protocols for ad hoc networks (2000) Proc. of the IEEE INFOCOM, pp. 3-12. , In, IEEE: Tel Aviv, Israel; Bettstetter, C., Resta, G., Santi, P., The node distribution of the random waypoint mobility model for wireless ad hoc networks (2003) IEEE Transactions on Mobile Computing, 2 (3), pp. 257-269","Chong, P.H.J.; School of EEE, Singapore; 电子邮件: EHJCHONG@ntu.edu.sg",,,John Wiley and Sons Inc.,,,,,19390114,,,,English,Secur. Commun. Networks,Article,Final,"All Open Access, Bronze",Scopus,2-s2.0-84968562152
Grant T.,16232836500;,Specifying functional requirements for simulating professional offensive cyber operations,2015,"Proceedings of the 10th International Conference on Cyber Warfare and Security, ICCWS 2015",,,,108,117,,1,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969211031&partnerID=40&md5=cd8b8673dd316c1b34dc3e92d3dc1978,"R-BAR, Benschop, Netherlands","Grant, T., R-BAR, Benschop, Netherlands","Several nations have acquired or are acquiring the capability for conducting professional offensive cyber operations to fight wars and to combat crime and terrorism. For the capability to be effective, they need to know how the attack process works, what resources are required, what doctrine should be followed, and how to command, control, and govern such integrated operations. Simulation is a powerful technology for gaining understanding about these issues. While the general principles and techniques for developing and employing simulations are well known, their application to professional offensive cyber operations is new. The purpose of this paper is to present a preliminary requirements specification for a new, agent-based simulator capable of modelling professional offensive cyber operations in a networked environment. Because attack may be the best means for defence, simulation encompasses the adversarial interaction between attacker(s) and defender(s). The requirements cover the applications-independent simulation infrastructure, touching on time handling, stochastic behaviour, the modelling representation, interfacing, and simulation control, and the cyber operations application. Cyber-specific use cases are grouped by stakeholder and phase of operation.",Agent-based modelling; Attack process; Command & control; Networks; OODA; Operations research; Requirements engineering; Simulation; Wargaming,Autonomous agents; Computational methods; Computer crime; Networks (circuits); Operations research; Requirements engineering; Stochastic systems; Technology transfer; Terrorism; Agent-based modelling; Functional requirement; Integrated Operations; Networked environments; OODA; Requirements specifications; Simulation; Wargaming; Professional aspects,,,,,"Bailey, Kaplan, Weinburg, (2012) Playing War Games to Prepare for a Cyberattack, , McKinsey (July); Bouquet, P., Fairley, R.E., (2013) SWEBOK V3.0: Guide to the Software Engineering Body of Knowledge, , IEEE Computer Society, Washington DC; Boyd, J.R., (1996) The Essence of Winning and Losing, , Unpublished lecture notes, Maxwell Air Force Base, Alabama, USA; Burns, S., War Gamers Handbook: A Guide for Professional War Gamers, , War Gaming Department, US Naval War College, Newport, RI; Christel, M., Kang, K.C., Issues in requirements elicitation (1992) Technical Report CMU-SEI-92-TR-012, Carnegie Mellon University, , PA, USA; Curry, J., Price, T., (2013) Dark Guest: Training Games for Cyber Warfare. Volume 1. Wargaming Internet Based Attacks. Second Edition, , Wargaming.co; Denning, P.J., Denning, D.E., Discussing cyber attack (2010) Communications of the ACM, 53 (9), pp. 29-31; Dollenkamp, M., (2007) Examining OODA as an Architectural Basis for Intrusion Detection Systems, , MSc thesis, University of Liverpool, UK, 25 December 2007; Dollenkamp, M., (2007) Research in the Feasibility of OODA as an Architectural Basis for Intrusion Detection Systems, , MSc thesis, University of Liverpool, UK, 24 December 2007; Georgeff, M., Pell, B., Pollack, M., Tambe, M., Wooldridge, M., The belief-desire-intention model of agency (1999) Intelligent Agents V: Agents Theories, Architectures, and Languages, pp. 1-10. , Springer Berlin Heidelberg; Gilbert, N., (2008) Agent-Based Models, , SAGE Publications, Thousand Oaks, CA; Grant, T.J., Measuring the potential benefits of NCW: 9/11 as case study (2006) Proceedings, 11th International Command &amp; Control Research &amp; Technology Symposium (paper 103), , Alberts, D.S. (Ed.) Washington DC: US DoD Command & Control Research Program; Grant, T.J., Formalized ontology for representing C2 systems as layered networks (2014) Network Topology in Command & Control: Organization, Operation, and Evolution, pp. 85-124. , Grant, T.J., Janssen, R. & Monsuur, H. (eds.), (2014) IGI Global, Hershey, PA, USA, chapter 5; Grant, T.J., Kooter, B.M., Comparing OODA and other models as operational view architecture (2005) Proceedings, 10th International Command &amp; Control Research &amp; Technology Symposium (ICCRTS 2005), , Alberts, D.S. (ed.) McLean, VA, paper 196; Grant, T.J., Venter, H.S., Eloff, J.H.P., Simulating adversarial interactions between intruders and system administrators using OODA-RR (2007) Proceedings, Annual Conference of South African Institute of Computer Scientists and Information Technologists (SAICSIT 2007), pp. 46-55. , Barnard, L., & Botha, R.A. (eds.) Fish River Sun, Sunshine Coast, South Africa; Grant, T.J., Burke, I., Van Heerden, R., Comparing models of offensive cyber operations (2012) Proceedings, 7th International Conference on Information Warfare &amp; Security (ICIW 2012), pp. 108-121. , Lysenko, V. (ed.) Center for Information Assurance & Cybersecurity, University of Washington, Seattle, WA; Grant, T.J., Prins, R., Identifying tools and technologies for professional offensive cyber operations (2013) Proceedings, 8th International Conference on Information Warfare &amp; Security (ICIW 2013), pp. 80-89. , Hart, D. (ed) Regis University, Denver, CO; Hübner, J.F., Sichman, J.S., Boissier, O., A model for the structural, functional, and deontic specification of organizations in multi-agent systems (2002) Proceedings, 16th Brazilian Symposium on AI (SBIA 2002), LNAI 2507, pp. 118-128. , Springer; Langley, P., Laird, J.E., Rogers, S., Cognitive architectures: Research issues and challenges (2009) Cognitive Systems Research, 10 (2), pp. 141-160; Lin, H., Lifting the veil on cyber offense (2009) IEEE Security & Privacy, 7 (4), pp. 15-21; Miller, J.H., Page, S.E., (2007) Complex Adaptive Systems: An Introduction to Computational Models of Social Life, , Princeton University Press, NJ; Owens, W., Dam, K., Lin, H., (2009) Technology, Policy, Law, and Ethics Regarding U.S. Acquisition and use of Cyberattack Capabilities, , Washington D.C.: The National Academies Press; Pidd, M., (2004) Computer Simulation in Management Science. 5th Edition, , John Wiley & Sons; Simon, H.A., Theories of bounded rationality (1972) Decision and Organization, 1, pp. 161-176; Van Diggelen, J., Bradshaw, J.M., Grant, T.J., Johnson, M., Neerincx, M., Policy-based design of human-machine collaboration in manned space missions (2009) Proceedings, 3rd IEEE International Conference on Space Mission Challenges for Information Technology 2009 (SMC-IT09), pp. 376-383. , Bergman, L.A. & Grenander, S. (eds.) Pasadena, California, USA; Wooldridge, M., (2002) An Introduction to Multi-Agent Systems, , John Wiley & Sons","Grant, T.; R-BARNetherlands; 电子邮件: tim.grant.work@gmail.com",Zaaiman J.Leenen L.,,Academic Conferences Limited,"10th International Conference on Cyber Warfare and Security, ICCWS 2015",24 March 2015 through 25 March 2015,,119855,,9.78E+12,,,English,"Proc. Int. Conf. Cyber Warf. Secur., ICCWS",Conference Paper,Final,,Scopus,2-s2.0-84969211031
"Döttling N., Kraschewski D., Müller-Quade J., Nilges T.",36871555900;37060972300;6603186276;55598893000;,General statistically secure computation with bounded-resettable hardware tokens,2015,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),9014,,,319,344,,8,10.1007/978-3-662-46494-6_14,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924689911&doi=10.1007%2f978-3-662-46494-6_14&partnerID=40&md5=249e7ee69784016d8071313197f7c311,"Aarhus University, Denmark; TNG Technology Consulting GmbH, Munich, Germany; Karlsruhe Institute of Technology, Germany","Döttling, N., Aarhus University, Denmark; Kraschewski, D., TNG Technology Consulting GmbH, Munich, Germany; Müller-Quade, J., Karlsruhe Institute of Technology, Germany; Nilges, T., Karlsruhe Institute of Technology, Germany","Universally composable secure computation was assumed to require trusted setups, until it was realized that parties exchanging (untrusted) tamper-proof hardware tokens allow an alternative approach (Katz; EUROCRYPT 2007). This discovery initialized a line of research dealing with two different types of tokens. Using only a single stateful token, one can implement general statistically secure two-party computation (Döttling, Kraschewski, Müller-Quade; TCC 2011); though all security is lost if an adversarial token receiver manages to physically reset and rerun the token. Stateless tokens, which are secure by definition against any such resetting-attacks, however, do provably not suffice for statistically secure computation in general (Goyal, Ishai, Mahmoody, Sahai; CRYPTO 2010). We investigate the natural question of what is possible if an adversary can reset a token at most a bounded number of times (e.g., because each resetting attempt imposes a significant risk to trigger a self-destruction mechanism of the token). Somewhat surprisingly, our results come close to the known positive results with respect to non-resettable stateful tokens. In particular, we construct polynomially many instances of statistically secure and universally composable oblivious transfer, using only a constant number of tokens. Our techniques have some abstract similarities to previous solutions, which we grasp by defining a new security property for protocols that use oracle access. Additionally, we apply our techniques to zero-knowledge proofs and obtain a protocol that achieves the same properties as bounded-query zero-knowledge PCPs (Kilian, Petrank, Tardos; STOC 1997), even if a malicious prover may issue stateful PCP oracles. © International Association for Cryptologic Research 2015.",,Computation theory; Cryptography; Hardware tokens; Oblivious transfer; Secure computation; Secure two-party computations; Security properties; Universally composable; Zero knowledge; Zero knowledge proof; Hardware security,,,,,"Arora, S., Safra, S., Probabilistic checking of proofs; A new characterization of NP (1992) Foundations of Computer Science-Proceedings of FOCS 1992, pp. 2-13. , IEEE Computer Society; Barak, B., Goldreich, O., Goldwasser, S., Lindell, Y., Resettably-sound zeroknowledge and its applications (2001) Foundations of Computer Science-Proceedings of FOCS 2001, pp. 116-125. , IEEE Computer Society; Barak, B., Lindell, Y., Vadhan, S.P., Lower bounds for non-black-box zero knowledge (2006) J. Comput. Syst. Sci, 72 (2), pp. 321-391; Beaver, D., Precomputing oblivious transfer (1995) Advances in Cryptology-CRYPT0 1995. LNCS, 963, pp. 97-109. , Coppersmith, D. (ed.),. Springer, Heidelberg; Bitansky, N., Paneth, O., On the impossibility of approximate obfuscation and applications to resettable cryptography (2013) Symposium on Theory of Computing-Proceedings of STOC 2013, pp. 241-250. , Boneh, D., Roughgarden, T., Feigenbaum, J. (eds.),. ACM; Canetti, R., Universally composable security: A new paradigm for cryptographic protocols (2001) Foundations of Computer Science-Proceedings of FOCS 2001, pp. 136-145. , http://eprint.iacr.org/2000/067, IEEE Computer Society, revised full version online; Canetti, R., Goldreich, O., Goldwasser, S., Micali, S., Resettable zero-knowledge (extended abstract) (2000) Symposium on Theory of Computing-Proceedings of STOC 2000, pp. 235-244. , Yao, F.F., Luks, E.M. (eds.),. ACM; Chandran, N., Goyal, V., Sahai, A., New constructions for UC secure computation using tamper-proof hardware (2008) EUROCRYPT 2008. LNCS, 4965, pp. 545-562. , Smart,(ed.),. Springer, Heidelberg; Cheraghchi, M., Shokrollahi, A., Almost-uniform sampling of points on highdimensional algebraic varieties (2009) Symposium on Theoretical Aspects of Computer Science-Proceedings of STACS 2009. LIPIcs, 3, pp. 277-288. , Albers, S., Marion, J.Y. (eds.),. Schloss Dagstuhl-Leibniz-Zentrum für Informatik, Germany; Cho, C., Ostrovsky, R., Scafuro, A., Visconti, I., Simultaneously resettable arguments of knowledge (2012) TCC 2012. LNCS, 7194, pp. 530-547. , Cramer, R. (ed.),. Springer, Heidelberg; Choi, S.G., Katz, J., Schröder, D., Yerukhimovich, A., Zhou, H.-S., (Efficient) universally composable oblivious transfer using a minimal number of stateless tokens (2014) TCC 2014. LNCS, 8349, pp. 638-662. , Lindell, Y (ed.), Springer, Heidelberg; Chung, K.M., Ostrovsky, R., Pass, R., Visconti, I., Simultaneous resettability from one-way functions (2013) Foundations of Computer Science-Proceedings of FOCS 2013, pp. 60-69. , IEEE Computer Society; Chung, K.M., Pass, R., Seth, K., Non-black-box simulation from one-way functions and applications to resettable security (2013) Symposium on Theory of Computing-Proceedings of STOC 2013, pp. 231-240. , Boneh, D., Roughgarden, T., Feigenbaum, J. (eds.),. ACM; Di Crescenzo, G., Persiano, G., Visconti, I., Constant-round resettable zero knowledge with concurrent soundness in the bare public-key model (2004) CRYPTO 2004. LNCS, 3152, pp. 237-253. , Franklin, M. (ed.),. Springer, Heidelberg; Di Crescenzo, G., Persiano, G., Visconti, I., Improved setup assumptions for 3-round resettable zero knowledge (2004) ASIACRYPT 2004. LNCS, 3329, pp. 530-544. , Lee, P.J. (ed.),. Springer, Heidelberg; Damgård, I., Scafuro, A., Unconditionally secure and universally composable commitments from physical assumptions (2013) ASIACRYPT 2013, 8270, pp. 100-119. , Sako, K., Sarkar, P. (eds.), Part II. LNCS,. Springer, Heidelberg; Deng, Y., Feng, D., Goyal, V., Lin, D., Sahai, A., Yung, M., Resettable cryptography in constant rounds-the case of zero knowledge (2011) ASIACRYPT 2011. LNCS, 7073, pp. 390-406. , Lee, D.H., Wang, X. (eds.),. Springer, Heidelberg; Deng, Y., Goyal, V., Sahai, A., Resolving the simultaneous resettability conjecture and a new non-black-box simulation strategy (2009) Foundations of Computer Science-Proceedings of FOCS 2009, pp. 251-260. , IEEE Computer Society; Deng, Y., Lin, D., Resettable zero knowledge with concurrent soundness in the bare public-key model under standard assumption (2008) Inscrypt 2007. LNCS, 4990, pp. 123-137. , Pei, D., Yung, M., Lin, D., Wu, C. (eds.),. Springer, Heidelberg; Dodis, Y., Ostrovsky, R., Reyzin, L., Smith, A., Fuzzy extractors: How to generate strong keys from biometrics and other noisy data (2008) SIAM J. Comput, 38 (1), pp. 97-139; Döttling, N., Kraschewski, D., Müller-Quade, J., Unconditional and composable security using a single stateful tamper-proof hardware token (2011) TCC 2011. LNCS, 6597, pp. 164-181. , http://eprint.iacr.org/2012/135, Ishai, Y. (ed.),. Springer, Heidelberg, extended full version; Döttling, N., Kraschewski, D., Müller-Quade, J., Nilges, T., General statistically secure computation with bounded-resettable hardware tokens (2014) IACR Cryptology ePrint Archive, 2014. , http://eprint.iacr.org/2014/555, Report 555; Döttling, N., Mie, T., Müller-Quade, J., Nilges, T., Implementing resettable UCfunctionalities with untrusted tamper-proof hardware-tokens (2013) TCC 2013. LNCS, 7785, pp. 642-661. , Sahai, A. (ed.),. Springer, Heidelberg; Dziembowski, S., Kazana, T., Wichs, D., Key-evolution schemes resilient to space-bounded leakage (2011) CRYPTO 2011. LNCS, 6841, pp. 335-353. , Rogaway, P. (ed.),. Springer, Heidelberg; Feige, U., Goldwasser, S., Lovász, L., Safra, S., Szegedy, M., Approximating clique is almost NP-complete (preliminary version) (1991) Foundations of Computer Science-Proceedings of FOCS 1991, pp. 2-12. , IEEE Computer Society; Goldreich, O., Kahan, A., How to construct constant-round zero-knowledge proof systems for NP (1996) J Cryptology, 9 (3), pp. 167-190; Goldwasser, S., Kalai, Y.T., Rothblum, G.N., One-time programs (2008) CRYPTO 2008. LNCS, 5157, pp. 39-56. , Wagner, D. (ed.),. Springer, Heidelberg; Goyal, V., Ishai, Y., Mahmoody, M., Sahai, A., Interactive locking, zero-knowledge PCPs, and unconditional cryptography (2010) CRYPTO 2010. LNCS, 6223, pp. 173-190. , Rabin, T. (ed.),. Springer, Heidelberg; Goyal, V., Ishai, Y., Sahai, A., Venkatesan, R., Wadia, A., Founding cryptography on tamper-proof hardware tokens (2010) TCC 2010. LNCS, 5978, pp. 308-326. , Micciancio, D. (ed.),. Springer, Heidelberg; Goyal, V., Maji, H.K., Stateless cryptographic protocols (2011) Foundations of Computer Science-Proceedings of FOCS 2011, pp. 678-687. , Ostrovsky, R. (ed.),. IEEE; Goyal, V., Sahai, A., Resettably secure computation (2009) EUROCRYPT 2009. LNCS, 5479, pp. 54-71. , Joux, A. (ed.),. Springer, Heidelberg; Harnik, D., Ishai, Y., Kushilevitz, E., Nielsen, J.B., OT-combiners via secure computation (2008) TCC 2008. LNCS, 4948, pp. 393-411. , Canetti, R. (ed.),. Springer, Heidelberg; Ishai, Y., Kushilevitz, E., Ostrovsky, R., Prabhakaran, M., Sahai, A., Efficient non-interactive secure computation (2011) EUROCRYPT 2011. LNCS, 6632, pp. 406-425. , Paterson, K.G. (ed.),. Springer, Heidelberg; Ishai, Y., Kushilevitz, E., Ostrovsky, R., Sahai, A., Extracting correlations (2009) Foundations of Computer Science-Proceedings of FOCS 2009, pp. 261-270. , IEEE Computer Society; Ishai, Y., Mahmoody, M., Sahai, A., On efficient zero-knowledge PCPs (2012) TCC 2012. LNCS, 7194, pp. 151-168. , Cramer, R. (ed.),. Springer, Heidelberg; Ishai, Y., Prabhakaran, M., Sahai, A., Founding cryptography on oblivious transfer-efficiently (2008) CRYPTO 2008. LNCS, 5157, pp. 572-591. , Wagner, D. (ed.),. Springer, Heidelberg; Kalai, Y.T., Raz, R., Interactive PCP (2008) ICALP 2008, 5126, pp. 536-547. , Aceto, L., Damgård, I., Goldberg, L.A., Halldórsson, M.M., Ingólfsdóttir, A., Walukiewicz, I. (eds.), Part II. LNCS,. Springer, Heidelberg; Katz, J., Universally composable multi-party computation using tamper-proof hardware (2007) EUROCRYPT 2007. LNCS, 4515, pp. 115-128. , Naor, M. (ed.),. Springer, Heidelberg; Katz, J., Vaikuntanathan, V., Signature schemes with bounded leakage resilience (2009) ASIACRYPT 2009. LNCS, 5912, pp. 703-720. , Matsui, M. (ed.),. Springer, Heidelberg; Kilian, J., Petrank, E., Concurrent and resettable zero-knowledge in polyloalgorithm rounds (2001) Symposium on Theory of Computing-Proceedings of STOC 2001, pp. 560-569. , Vitter, J.S., Spirakis, P.G., Yannakakis, M. (eds.),. ACM; Kilian, J., Petrank, E., Tardos, G., Probabilistically checkable proofs with zero knowledge (1997) Symposium on Theory of Computing-Proceedings of STOC 1997, pp. 496-505. , Leighton, F.T., Shor, P.W. (eds.),. ACM; Micali, S., Reyzin, L., Min-round resettable zero-knowledge in the public-key model (2001) EUROCRYPT 2001. LNCS, 2045, pp. 373-393. , Pfitzmann, B. (ed.),. Springer, Heidelberg; Moran, T., Segev, G., David and Goliath commitments: UC computation for asymmetric parties using tamper-proof hardware (2008) EUROCRYPT 2008. LNCS, 4965, pp. 527-544. , Smart,(ed.),. Springer, Heidelberg; Wegman, M.N., Carter, L., New hash functions and their use in authentication and set equality (1981) J. Comput. Syst. Sci, 22 (3), pp. 265-279; Wolf, S., Wullschleger, J., Oblivious transfer is symmetric (2006) EUROCRYPT 2006. LNCS, 4004, pp. 222-232. , Vaudenay, S. (ed.),. Springer, Heidelberg; Yung, M., Zhao, Y., Generic and practical resettable zero-knowledge in the bare public-key model (2007) EUROCRYPT 2007. LNCS, 4515, pp. 129-147. , Naor, M. (ed.),. Springer, Heidelberg; Zhao, Y., Deng, X., Lee, C.H., Zhu, H., Resettable zero-knowledge in the weak public-key model (2003) EUROCRYPT 2003. LNCS, 2656, pp. 123-139. , Biham, E. (ed.),. Springer, Heidelberg",,Dodis Y.Nielsen J.B.,Google Inc;International Association for Cryptologic Research,Springer Verlag,"12th Theory of Cryptography Conference, TCC 2015",23 March 2015 through 25 March 2015,,114279,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Paper,Final,,Scopus,2-s2.0-84924689911
"Rührmair U., Van Dijk M.",35776885900;7102854233;,PUFs in security protocols: Attack models and security evaluations,2013,Proceedings - IEEE Symposium on Security and Privacy,,,6547116,286,300,,70,10.1109/SP.2013.27,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881249992&doi=10.1109%2fSP.2013.27&partnerID=40&md5=6be2bef79c10901bc6285ee5002223f0,"Computer Science Department, Technische Universität München, 80333 München, Germany; CSAIL, MIT, Cambridge, MA, United States","Rührmair, U., Computer Science Department, Technische Universität München, 80333 München, Germany; Van Dijk, M., CSAIL, MIT, Cambridge, MA, United States","In recent years, PUF-based schemes have not only been suggested for the basic security tasks of tamper sensitive key storage or system identification, but also for more complex cryptographic protocols like oblivious transfer (OT), bit commitment (BC), or key exchange (KE). In these works, so-called ""Strong PUFs"" are regarded as a new, fundamental cryptographic primitive of their own, comparable to the bounded storage model, quantum cryptography, or noisebased cryptography. This paper continues this line of research, investigating the correct adversarial attack model and the actual security of such protocols. In its first part, we define and compare different attack models. They reach from a clean, first setting termed the ""stand-alone, good PUF model"" to stronger scenarios like the ""bad PUF model"" and the ""PUF re-use model"". We argue why these attack models are realistic, and that existing protocols would be faced with them if used in practice. In the second part, we execute exemplary security analyses of existing schemes in the new attack models. The evaluated protocols include recent schemes from Brzuska et al. published at Crypto 2011 [1] and from Ostrovsky et al. [18]. While a number of protocols are certainly secure in their own, original attack models, the security of none of the considered protocols for OT, BC, or KE is maintained in all of the new, realistic scenarios. One consequence of our work is that the design of advanced cryptographic PUF protocols needs to be strongly reconsidered. Furthermore, it suggests that Strong PUFs require additional hardware properties in order to be broadly usable in such protocols: Firstly, they should ideally be ""erasable"", meaning that single PUF-responses can be erased without affecting other responses. If the area efficient implementation of this feature turns out to be difficult, new forms of Controlled PUFs [8] (such as Logically Erasable and Logically Reconfigurable PUFs [13]) may suffice in certain applications. Secondly, PUFs should be ""certifiable"", meaning that one can verify that the PUF has been produced faithfully and has not been manipulated in any way afterwards. The combined implementation of these features represents a pressing and challenging problem, which we pose to the PUF hardware community in this work. © 2013 IEEE.",(Strong) Physical Unclonable Functions; (Strong) PUFs; Attack Models; Bit Commitment; Certifiable PUFs; Erasable PUFs; Key Exchange; Oblivious Transfer,(Strong) PUFs; Attack model; Bit commitment; Certifiable PUFs; Erasable PUFs; Key exchange; Oblivious transfer; Physical unclonable functions; Computer hardware; Design; Hardware; Quantum cryptography; Network security,,,,,"Brzuska, C., Fischlin, M., Schröder, H., Katzenbeisser, S., Physical Unclonable Functions in the Universal Composition Framework (2011) CRYPTO; Brzuska, C., Fischlin, M., Schröder, H., Katzenbeisser, S., Physical Unclonable Functions in the Universal Composition Framework (2011) Cryptology ePrint Archive, , Full version of the paper. Report 2011/681, Downloaded March 2012; Canetti, R., Universally Composable Security: A New Paradigm for Cryptographic Protocols (2001) FOCS, pp. 136-145; Chen, Q., Csaba, G., Lugli, P., Schlichtmann, U., Rührmair, U., The Bistable Ring PUF: A new architecture for strong Physical Unclonable Functions (2011) HOST, pp. 134-141; Van Dijk, M., System and method of reliable forward secret key sharing with physical random functions (2004), US Patent No. 7,653,197, October; Van Dijk, M., Rührmair, U., Physical Unclonable Functions in Cryptographic Protocols: Security Proofs and Impossibility Results (2012) Cryptology ePrint Archive, , Report 2012/228, Downloaded April 2012; Gassend, B., (2003) Physical Random Functions, , MSc Thesis, MIT; Gassend, B., Van Dijk, M., Clarke, D.E., Torlak, E., Devadas, S., Tuyls, P., Controlled physical random functions and applications (2008) ACM TISSEC, 10 (4); Gassend, B., Clarke, D.E., Van Dijk, M., Devadas, S., Silicon physical random functions ACM Conference on Computer and Communications Security 2002, pp. 148-160; Gassend, B., Lim, D., Clarke, D., Van Dijk, M., Devadas, S., Identification and authentication of integrated circuits (2004) Concurrency and Computation: Practice & Experience, 16 (11), pp. 1077-1098; Guajardo, J., Kumar, S.S., Schrijen, G.J., Tuyls, P., FPGA Intrinsic PUFs and Their Use for IP Protection (2007) CHES, pp. 63-80; Holcomb, D.E., Burleson, W.P., Fu, K., Initial SRAM state as a fingerprint and source of true random numbers for RFID tags Proceedings of the Conference on RFID Security, 2007; Katzenbeisser, S., Koçabas, Ü., Van Der Leest, V., Sadeghi, A.-R., Schrijen, G.J., Wachsmann, C., Recyclable PUFs: Logically Reconfigurable PUFs (2011) Journal of Cryptographic Engineering, 1 (3), pp. 177-186; Kilian, J., Founding cryptography on oblivious transfer (1988) STOC; Kumar, S.S., Guajardo, J., Maes, R., Schrijen, G.J., Tuyls, P., The Butterfly PUF: Protecting IP on every FPGA (2008) HOST, pp. 67-70; Kursawe, K., Sadeghi, A.R., Schellekens, D., Tuyls, P., Skoric, B., Reconfigurable physical unclonable functions - Enabling technology for tamper-resistant storage (2009) HOST, pp. 22-29; Lee, J.-W., Lim, D., Gassend, B., Suh, G.E., Van Dijk, M., Devadas, S., A technique to build a secret key in integrated circuits with identification and authentication applications Proceedings of the IEEE VLSI Circuits Symposium, 2004; Ostrovsky, R., Scafuro, A., Visconti, I., Wadia, A., Universally Composable Secure Computation with (Malicious) Physically Uncloneable Functions (2012) Cryptology ePrint Archive, , Report 2012/143, First version downloaded in April 2012. Throughout our paper, we refer to the numbering of figures and protocols of the latest version of Ostrovsky et al. that was available at the time of preparing our camera ready paper. This latest version stems from Nov. 14, 2012; Pappu, R., (2001) Physical One-Way Functions, , PhD Thesis, Massachusetts Institute of Technology; Pappu, R., Recht, B., Taylor, J., Gershenfeld, N., Physical One-Way Functions (2002) Science, 297, pp. 2026-2030. , 20 September; Rivest, R., Illegitimi non carborundum (2011) CRYPTO, , Invited keynote talk; Rührmair, U., Oblivious Transfer based on Physical Unclonable Functions (2010) TRUST 2010, pp. 430-440. , Springer; Rührmair, U., Busch, H., Katzenbeisser, S., Strong PUFs: Models, Constructions and Security Proofs (2010) Towards Hardware Intrinsic Security: Foundation and Practice, , A.-R. Sadeghi, P. Tuyls (Editors): Springer; Rührmair, U., Devadas, S., Koushanfar, F., Security based on Physical Unclonability and Disorder (2011) Introduction to Hardware Security and Trust, , M. Tehranipoor and C. Wang (Editors): Springer; Rührmair, U., Van Dijk, M., Practical Security Analysis of PUF-based Two-Player Protocols (2012) Cryptographic Hardware and Embedded Systems (CHES 2012), , Springer; Rührmair, U., Jaeger, C., Algasinger, M., An Attack on PUF-based Session Key Exchange and a Hardware-based Countermeasure: Erasable PUFs (2011) Financial Cryptography (FC 2011), , Springer; Rührmair, U., Jaeger, C., Bator, M., Stutzmann, M., Lugli, P., Csaba, G., Cryptographic Applications of High-Capacity Crossbar Memories (2011) IEEE Transactions on Nanotechnology; Rührmair, U., Sehnke, F., Sölter, J., Dror, G., Devadas, S., Schmidhuber, J., Modeling Attacks on Physical Unclonable Functions (2010) ACM Conference on Computer and Communications Security (CCS'10); Rührmair, U., Sölter, J., Sehnke, F., On the Foundations of Physical Unclonable Functions (2009) Cryptology ePrint Archive, , Report 2009/277; Suh, G.E., Devadas, S., Physical Unclonable Functions for Device Authentication and Secret Key Generation (2007) DAC, pp. 9-14; Tuyls, P., Schrijen, G.-J., Skoric, B., Van Geloven, J., Verhaegh, N., Wolters, R., Read-proof hardware from protective coatings (2006) Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 4249 LNCS, pp. 369-383. , Cryptographic Hardware and Embedded Systems, CHES 2006 - 8th International Workshop, Proceedings; Tuyls, P., Skoric, B., Strong Authentication with Physical Unclonable Functions (2007) Security, Privacy and Trust in Modern Data Management, , M. Petkovic, W. Jonker (Eds.), Springer","Computer Science Department, , 80333 München, Germany",,,,"34th IEEE Symposium on Security and Privacy, SP 2013",19 May 2013 through 22 May 2013,"San Francisco, CA",98359,10816011,9.78E+12,,,English,Proc. IEEE Symp. Secur. Privacy,Conference Paper,Final,"All Open Access, Green",Scopus,2-s2.0-84881249992
"Jansen R., Syverson P., Hopper N.",57213501987;7004114892;15020775000;,Throttling tor bandwidth parasites,2012,Proceedings of the 21st USENIX Security Symposium,,,,349,363,,26,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052672939&partnerID=40&md5=4363022a2bf8ed582314c58138ce0408,"U.S. Naval Research Laboratory, United States; University of Minnesota, United States","Jansen, R., U.S. Naval Research Laboratory, United States; Syverson, P., U.S. Naval Research Laboratory, United States; Hopper, N., University of Minnesota, United States","Tor is vulnerable to network congestion and performance problems due to bulk data transfers. A large fraction of the available network capacity is consumed by a small percentage of Tor users, resulting in severe service degradation for the majority. Bulk users continuously drain relays of excess bandwidth, creating new network bottlenecks and exacerbating the effects of existing ones. While this problem may currently be attributed to rational users utilizing the network, it may also be exploited by a relatively low-resource adversary using similar techniques to contribute to a network denial of service (DoS) attack. Degraded service discourages the use of Tor, affecting both Tor’s client diversity and anonymity. Equipped with mechanisms from communication networks, we design and implement three Tor-specific algorithms that throttle bulk transfers to reduce network congestion and increase network responsiveness. Unlike existing techniques, our algorithms adapt to network dynamics using only information local to a relay. We experiment with full-network deployments of our algorithms under a range of light to heavy network loads. We find that throttling results in significant improvements to web client performance while mitigating the negative effects of bulk transfers. We also analyze how throttling affects anonymity and compare the security of our algorithms under adversarial attack. We find that throttling reduces information leakage compared to unthrottled Tor while improving anonymity against realistic adversaries. Copyright © 2019 21st USENIX Security Symposium. All rights reserved.",,Bandwidth; Data transfer; Denial-of-service attack; Bulk data transfer; Design and implements; Information leakage; Network bottlenecks; Network congestions; Network denial of service; Performance problems; Service degradation; Network security,,,,,"The Libevent Event Notification Library, , http://monkey.org/provos/libevent/, Version 2.0; The Shadow Simulator, , http://shadow.cs.umn.edu/; The Tor Metrics Portal, , http://metrics.torproject.org/; https://www.torproject.org/; Throttling Algorithms Code Repository, , https://github.com/robgjansen/torclone; Acquisti, A., Dingledine, R., Syverson, P., On the economics of anonymity (2003) Proceedings of Financial Cryptography, p. 2742. , January R. N. Wright, Ed., Springer-Verlag, LNCS; Alsabah, M., Bauer, K., Goldberg, I., Grunwald, D., McCoy, D., Savage, S., Voelker, G., Defenestrator: Throwing out windows in tor (2011) Proceedings of the 11th International Symposium on Privacy Enhancing Technologies; Back, A., Moller, U., Stiglic, A., Traffic Analysis Attacks and Trade-offs in Anonymity Providing Systems (2001) Proceedings of Information Hiding Workshop, pp. 245-257; Blake, S., Black, D., Carlson, M., Davies, E., Wang, Z., Weiss, W., (1998) An Architecture for Differentiated Services; Borisov, N., Danezis, G., Mittal, P., Tabriz, P., Denial of service or denial of security? (2007) Proceedings of the 14th ACM Conference on Computer and Communications Security, pp. 92-102; Braden, B., Clark, D., Shenker, S., Integrated Service in the Internet Architecture: An Overview; Chen, F., Perry, M., Improving Tor Path Selection, , https://gitweb.torproject.org/torspec.git/blob/HEAD:/proposals/151-path-selection-improvements.txt; Chun, B., Culler, D., Roscoe, T., Bavier, A., Peterson, L., Wawrzoniak, M., Bowman, M., Planetlab: An Overlay Testbed for Broad-coverage Services (2003) SIGCOMM Computer Communication Review, 33, pp. 3-12; Crotti, M., Dusi, M., Gringoli, F., Salgarelli, L., Traffic classification through simple statistical fingerprinting (2007) SIGCOMM Comput. Commun. Rev., 37, pp. 5-16. , January; Demers, A., Keshav, S., Shenker, S., Analysis and simulation of a fair queueing algorithm (1989) ACM SIGCOMM Computer Communication Review, 19, pp. 1-12; Dingledine, R., Iran Blocks Tor, , https://blog.torproject.org/blog/iran-blocks-tor-tor-releases-same-day-fix; Dingledine, R., Research Problem: Adaptive Throttling of Tor Clients by Entry Guards, , https://blog.torproject.org/blog/research-problem-adaptive-throttling-tor-clients-entry-guards; Dingledine, R., Mathewson, N., Anonymity loves Company: Usability and the network effect (2006) Proceedings of the Fifth Workshop on the Economics of Information Security (WEIS 2006), , Cambridge, UK, June; Dingledine, R., Mathewson, N., Syverson, P., ToR: The second-generation onion router (2004) Proceedings of the 13th USENIX Security Symposium; Dovrolis, C., Ramanathan, P., A case for relative differentiated services and the proportional differentiation model (1999) Network, IEEE, 13 (5), pp. 26-34; Dovrolis, C., Stiliadis, D., Ramanathan, P., Proportional differentiated services: Delay differentiation and packet scheduling (1999) Proceedings of the Conference on Applications, Technologies, Architectures, and Protocols for Computer Communication, pp. 109-120; Evans, N., Dingledine, R., Grothoff, C., A practical congestion attack on Tor using long paths (2009) Proceedings of the 18th USENIX Security Symposium, pp. 33-50; Goldschlag, D.M., Reed, M.G., Syverson, P.F., Hiding routing information (1996) Proceedings of Information Hiding Workshop, pp. 137-150; Hahne, E., Round-robin Scheduling for Max-min Fairness in Data Networks (1991) IEEE Journal on Selected Areas in Communications, 9 (7), pp. 1024-1039; Hahne, E., Gallager, R., Round-robin Scheduling for Fair Flow Control in Data Communication Networks (1986) NASA STI/Recon Technical Report N, 86, p. 30047; Hardin, G., The tragedy of the Commons (1968) Science, 162 (3859), pp. 1243-1248. , December; Hernandez-Campos, F., Jeffay, K., Smith, F., Tracking the evolution of web traffic: 1995-2003 (2003) The 11th IEEE/ACM International Symposium on Modeling, Analysis, and Simulation of Computer Telecommunications Systems, pp. 16-25; Hintz, A., Fingerprinting Websites using Traffic Analysis (2002) Proceedings of Privacy Enhancing Technologies Workshop, pp. 171-178; Hjelmvik, E., John, W., Statistical protocol identification with SPID: Preliminary results (2009) Swedish National Computer Networking Workshop; Hopper, N., Vasserman, E., Chan-Tin, E., How much anonymity does network latency leak? (2010) ACM Transactions on Information and System Security, 13 (2), pp. 1-28; Jansen, R., Hopper, N., Shadow: Running TOR in a box for accurate and efficient experimentation (2012) Proceedings of the 19th Network and Distributed System Security Symposium; Jansen, R., Hopper, N., Kim, Y., Recruiting new tor relays with braids (2010) Proceedings of the 17th ACM Conference on Computer and Communications Security, pp. 319-328; Jansen, R., Syverson, P., Hopper, N., (2011) Throttling Tor Bandwidth Parasites, , Tech. Rep. 11-019, University of Minnesota; Katevenis, M., Fast switching and fair control of congested flow in broadband networks (1987) Selected Areas in Communications, IEEE Journal on, 5 (8), pp. 1315-1326; Kelly, F., Maulloo, A., Tan, D., Rate control for communication networks: Shadow prices, proportional fairness and stability (1998) Journal of the Operational Research Society, 49 (3), pp. 237-252; Kohnen, C., Uberall, C., Adamsky, F., Rakocevic, V., Rajarajan, M., Jager, R., Enhancements to statistical protocol identification (SPID) for self-organised QoS in LANs (2010) Computer Communications and Networks (ICCCN), 2010 Proceedings of 19th International Conference on, pp. 1-6; Loesing, K., (2009) Measuring the Tor Network: Evaluation of Client Requests to Directories, , Tech. rep., Tor Project; McCoy, D., Bauer, K., Grunwald, D., Kohno, T., Sicker, D., Shining light in dark places: Understanding the Tor network (2008) Proceedings of the 8th International Symposium on Privacy Enhancing Technologies, pp. 63-76; Mittal, P., Khurshid, A., Juen, J., Caesar, M., Borisov, N., Stealthy traffic analysis of low-latency anonymous communication using throughput fingerprinting (2011) Proceedings of the 18th ACM Conference on Computer and Communications Security, , October; Modadugu, N., Rescorla, E., The design and implementation of datagram TLS (2004) Proceedings of the 11th Network and Distributed System Security Symposium; Moore, W.B., Wacek, C., Sherr, M., Exploring the potential benefits of expanded rate limiting in Tor: Slow and steady wins the race with tortoise (2011) Proceedings of 2011 Annual Computer Security Applications Conference, , December; Murdoch, S., Danezis, G., Low-cost Traffic Analysis of Tor (2005) IEEE Symposium on Security and Privacy, pp. 183-195; Ngan, T.-W.J., Dingledine, R., Wallach, D.S., Building incentives into ToR (2010) The Proceedings of Financial Cryptography; Øverlier, L., Syverson, P., Locating hidden servers (2006) Proceedings of the 2006 IEEE Symposium on Security and Privacy, , May IEEE CS; Ramachandran, S., (2010) Web Metrics: Size and Number of Resources, , http://code.google.com/speed/articles/web-metrics.html, Accessed February, 2012; Raymond, J., Traffic analysis: Protocols, attacks, design issues, and open problems (2001) Designing Privacy Enhancing Technologies, pp. 10-29; Reardon, J., Goldberg, I., Improving Tor using a TCP-over-DTLS tunnel (2009) Proceedings of the 18th USENIX Security Symposium; Reed, M., Syverson, P., Goldschlag, D., Anonymous connections and onion routing (1998) IEEE Journal on Selected Areas in Communications, 16 (4), pp. 482-494; Serjantov, A., Sewell, P., Passive Attack Analysis for Connection-based Anonymity Systems (2003) Computer Security–ESORICS, pp. 116-131; Shenker, S., Partridge, C., Guerin, R., (1997) RFC 2212: Specification of Guaranteed Quality of Service, , Sept. Status: PROPOSED STANDARD; Snader, R., Borisov, N., A tune-up for TOR: Improving security and performance in the Tor network (2008) Proceedings of the 16th Network and Distributed Security Symposium; Tang, C., Goldberg, I., An improved algorithm for Tor circuit scheduling (2010) Proceedings of the 17th ACM Conference on Computer and Communications Security, pp. 329-339; Tschorsch, F., Scheuermann, B., Refill Intervals, , https://gitweb.torproject.org/torspec.git/blob/HEAD:/proposals/183refillintervals.txt; Tschorsch, F., Scheuermann, B., (2011) Tor Is Unfair–and What to Do about It; Turner, J., New directions in communications(or which way to the information age?) (1986) IEEE Communications Magazine, 24 (10), pp. 8-15; Viecco, C., UDP-OR: A fair onion transport design (2008) Proceedings of Hot Topics in Privacy Enhancing Technologies; Wang, T., Bauer, K., Forero, C., Goldberg, I., Congestion-aware Path Selection for Tor (2012) Proceedings of Financial Cryptography; Wright, M., Adler, M., Levine, B.N., Shields, C., An analysis of the degradation of anonymous protocols (2002) Proceedings of the Network and Distributed Security Symposium - NDSS’02, , February IEEE; Wright, M., Adler, M., Levine, B.N., Shields, C., Defending anonymous communication against passive logging attacks (2003) Proceedings of the 2003 IEEE Symposium on Security and Privacy, pp. 28-43. , May; Zhang, L., Deering, S., Estrin, D., Shenker, S., Zappala, D., RSVP: A new resource reservation protocol (1993) Network, IEEE, 7 (5), pp. 8-18",,,,USENIX Association,21st USENIX Security Symposium,8 August 2012 through 10 August 2012,,155134,,,,,English,Proc. USENIX Secur. Symp.,Conference Paper,Final,,Scopus,2-s2.0-85052672939
"Rohret D., Jimenez A.",55576642100;56016736700;,Exploitation/attacks within the radio frequency spectrum,2012,"7th International Conference on Information Warfare and Security, ICIW 2012",,,,245,253,,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893114862&partnerID=40&md5=074efa4e06683c1900aad712b1122f17,"Computer Sciences Corporation, Inc, Joint Information Operations Warfare Center/Vulnerability Assessment Team, San Antonio, TX, United States; Dynetics, Inc, Joint Information Operations Warfare Center/Vulnerability Assessment Team, San Antonio, TX, United States","Rohret, D., Computer Sciences Corporation, Inc, Joint Information Operations Warfare Center/Vulnerability Assessment Team, San Antonio, TX, United States; Jimenez, A., Dynetics, Inc, Joint Information Operations Warfare Center/Vulnerability Assessment Team, San Antonio, TX, United States","Radio frequency (RF) and Computer Network Exploitation and Attacks (CNE/CNA) can no longer be viewed as separate activities or actions within the Radio Frequency (RF) spectrum for military or commercial operations. Integration of Internet Protocol (IP) capabilities allowing for node addressing, data transfer, and communications between systems once considered only Electronic Warfare (EW)-centric, may provide nationstate and non-nation-state adversaries and opportunistic malicious hackers the ability to exploit systems previously considered autonomous. Furthermore, network operations can be affected from wireless and remotely-operating RF systems associated to, or trusted with, operational networks. Basic RF jamming techniques provide an adversary the ability to affect blue force IP over radio communications and data transmissions with little or no risk to themselves by obfuscating their efforts as an Open Systems Interconnection (OSI) layer 2-6 attack rather than a layer 1 attack. The Joint Information Operations Warfare Center (JIOWC) Vulnerability Assessment Team (JVAT) performs adversarial red team tactics against developmental Joint Capability Technology Demonstrations (JCTDs), to include CNE/CNA and RF system of systems. The evolution of 'smart' weapons technologies, to include most information operations (IO) capabilities, now represents the norm in systems development. Command and control (C ) and common operational pictures (COPs) with integrated IP over radio, provide multiple attack vectors and unique opportunities for adversaries. Organizations that manage and develop EW and/or wireless networks must adapt policies and organizational processes to meet the changing environment and to deal with an increasingly savvy adversary who only requires open-source tools and technologies to successfully attack sophisticated RF networked systems. In this paper the authors identify adversarial tactics used against developmental systems with integrated EW and CNO capabilities; using only open-source and publically available equipment, data, and technologies. The authors will also discuss adversarial techniques from three case studies based on actual red teaming assessments on developmental systems.",Assessments; CNA/CNE; Intelligent jamming; OSI Layers 2-6; Radio frequency; Red teaming,Data transfer; Electronic warfare; Internet protocols; Jamming; Personal computing; Radio waves; Technology; Assessments; CNA/CNE; OSI layers; Radio frequencies; Red teaming; Network layers,,,,,"Adamy, D.L., EW 103: Tactical Battlefield Communications Electronic Warfare (2009), Artech House Radar Library, Boston; Gast, M., Wireless Networks: The Definitive Guide (2002), O'Reilly Media; Gorry, F., Broadcast, Multicast, and Unicast (2011), http://www.erg.abdn.ac.uk./users/gorry/course/intropages/uni-b-mcast.html, University of Aberdeen, England; (2011), http://www.grouper.ieee.org/goups/802, IEEE 802.11/802.16 Standards; Stevens, W.R., TCP/IP Illustrated (1999), 1. , Addison-Wesley Publishing; Coalition Operating Area Surveillance And Targeting Systems Assessment Plan (2008), JIOWC Vulnerability Assessment Team, Joint Information Operations Warfare Center, San Antonio, TX; Coalition Operating Area Surveillance and Targeting System (COASTS) Thailand Field Experiment (2009), JIOWC Vulnerability Assessment Team, Joint Information Operations Warfare Center, San Antonio, TX; Coalition Operating Area Surveillance And Targeting Systems Initial Vulnerability Analysis Report (2008), JIOWC Vulnerability Assessment Team, Joint Information Operations Warfare Center, San Antonio, TX; Schleher, C.D., Electronic Warfare in the Information Age (1999), Artech House Radar Library, Boston; Thomas, T.L., Cyber silhouettes: shadows over information operations (2005), Foreign Military Studies Office (FMSO)",,,,Curran Associates Inc.,"7th International Conference on Information Warfare and Security, ICIW 2012",22 March 2012 through 23 March 2012,"Seattle, WA",102414,,9.78E+12,,,English,Int. Conf. Inform. Warf. Secur.,Conference Paper,Final,,Scopus,2-s2.0-84893114862
"Kong D., Jhi Y.-C., Gong T., Zhu S., Liu P., Xi H.",24831922800;24778740500;55390518800;8886024500;36727836300;7102571247;,SAS: Semantics aware signature generation for polymorphic worm detection,2011,International Journal of Information Security,10,5,,269,283,,7,10.1007/s10207-011-0132-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052922553&doi=10.1007%2fs10207-011-0132-7&partnerID=40&md5=033665046e481b832f2840eb998e6a9c,"College of Information Science and Technology, The Pennsylvania State University, University Park, PA, United States; Department of Computer Science and Engineering, The Pennsylvania State University, University Park, PA, United States; Department of Automation, University of Science and Technology of China, Hefei, China","Kong, D., College of Information Science and Technology, The Pennsylvania State University, University Park, PA, United States; Jhi, Y.-C., Department of Computer Science and Engineering, The Pennsylvania State University, University Park, PA, United States; Gong, T., Department of Automation, University of Science and Technology of China, Hefei, China; Zhu, S., Department of Computer Science and Engineering, The Pennsylvania State University, University Park, PA, United States; Liu, P., College of Information Science and Technology, The Pennsylvania State University, University Park, PA, United States; Xi, H., Department of Automation, University of Science and Technology of China, Hefei, China","String extraction and matching techniques have been widely used in generating signatures for worm detection, but how to generate effective worm signatures in an adversarial environment still remains a challenging problem. For example, attackers can freely manipulate byte distributions within the attack payloads and thus inject well-crafted noisy packets to contaminate the suspicious flow pool. To address these attacks, we propose SAS, a novel Semantics Aware Statistical algorithm for automatic signature generation. When SAS processes packets in a suspicious flow pool, it uses data flow analysis techniques to remove non-critical bytes. We then apply a hidden Markov model (HMM) to the refined data to generate state-transition-graph-based signatures. To our best knowledge, this is the first work combining semantic analysis with statistical analysis to automatically generate worm signatures. Our experiments show that the proposed technique can accurately detect worms with concise signatures. Moreover, our results indicate that SAS is more robust to the byte distribution changes and noise injection attacks compared to Polygraph and Hamsa. © 2011 Springer-Verlag.",Data flow analysis; Hidden Markov model; Machine learning; Semantics; Worm signature generation,Adversarial environments; Data flow; Machine-learning; Matching techniques; Noise injection; Noisy packets; Polymorphic worms; Semantic analysis; Signature generation; Statistical algorithm; Worm detection; Worm signatures; Data transfer; Hidden Markov models; Lakes; Network security; Semantics; Data flow analysis,,,,,"Jempiscodes-a Polymorphic Shellcode Generator, , http://www.shellcode.com.ar/en/proyectos.html; Baecher, P., Koetter, M., Getting Around Non-executable Stack (and Fix), , http://www.libemu.carnivore.it/; Bania, P., Evading Network-level Emulation, , http://www.packetstormsecurity.org/papers/bypass/pbania-evading-nemu2009.pdf; Borders, K., Prakash, A., Zielinski, M., Spector: Automatically analyzing shell code (2007) Proceedings of the 23rd Annual Computer Security Applications Conference, pp. 501-514; Gu, B., Bai, X., Yang, Z., Adam, C., Xuan, D., Malicious shellcode detection with virtual memory snapshots (2010) Proceedings of IEEE International Conference On Computer Communications (IEEE INFOCOM); Brumley, D., Caballero, J., Liang, Z., Newsome, J., Song, D., Towards automatic discovery of deviations in binary implementations with applications to error detection and fingerprint generation (2007) Proceedings of the 16th USENIX Security; Christodorescu, M., Jha, S., Seshia, S., Song, D., Bryant, R., Semantics-aware malware detection (2005) 2005 IEEE Symposium On Security and Privacy; Chung, S.P., Mok, A.K., Advanced allergy attacks: Does a corpus really help (2007) Recent Advances In Intrusion Detection (RAID), pp. 236-255. , Springer, Berlin; Collberg, C., Thomborson, C., Low, D., (1997) A Taxonomy of Obfuscating Transformations, , Technical Report 148, University of Auckland; Detristan, T., Ulenspiegel, T., Malcom, Y., Superbus, M., Underduk, V., Polymorphic Shellcode Engine Using Spectrum Analysis, , http://www.phrack.org/show.php?p=61&a=9; Fogla, P., Sharif, M., Perdisci, R., Kolesnikov, O., Lee, W., Polymorphic blending attacks (2006) Proceedings of the 15th USENIX Security Symposium; Forsell, M., Leppänen, V., Mtpa-a processor architecture for mp-socs employing the moving threads paradigm (2009) PDPTA, pp. 198-204; Gundy, M.V., Balzarotti, D., Vigna, G., Catch me, if you can: Evading network signatures with web-based polymorphic worms (2007) Proceedings of the First USENIX Workshop On Offensive Technologies (WOOT), , Boston, MA; Gundy, M.V., Chen, H., Su, Z., Vigna, G., Feature omission vulnerabilities: Thwarting signature generation for polymorphic worms (2007) Proceeding of Annual Computer Security Applications Conference (ACSAC); Kc, G.S., Keromytis, A.D., e-nexsh: Achieving an effectively non-executable stack and heap via system-call policing (2005) ACSAC, pp. 286-302; Kim, H.A., Karp, B., Autograph: Toward automated, distributed worm signature detection (2004) Proceedings of the 13th Usenix Security Symposium; Kreibich, C., Crowcroft, J., Honeycomb: Creating intrusion detection signatures using honeypots (2003) Proceedings of the Workshop On Hot Topics In Networks (HotNets); Krugel, C., Kirda, E., Polymorphic worm detection using structural information of executables (2005) 2005 International Symposium On Recent Advances In Intrusion Detecion; Krügel, C., Lippmann, R., Clark, A., Emulation-based detection of non-self-contained polymorphic shellcode (2007) Recent Advances In Intrusion Detection, 10th International Symposium, Lecture Notes In Computer Science, 4637. , Springer, Berlin; Li, Z., Hamsa Code, , http://www.zhichunli.org/; Li, Z., Sanghi, M., Chen, Y., Kao, M.Y., Chavez, B., Hamsa: Fast signature generation for zero-day polymorphic worms with provable attack resilience (2006) IEEE Symposium On Security and Privacy; Liang, Z., Sekar, R., Automatic generation of buffer overflow attack signatures: An approach based on program behavior models (2005) Proceedings of the Anual Computer Security Applications Conference; Liang, Z., Sekar, R., Fast and automated generation of attack signatures: A basis for building self-protecting servers (2005) Proceedings of the 12th ACM Conference On Computer and Communications Security; Macaulay, S., Admmutate: Polymorphic Shellcode Engine, , http://www.ktwo.ca/security.html; Mason, J., Small, S., Monrose, F., Macmanus, G., English shellcode (2009) ACM Conference On Computer and Communications Security, , ACM; Moore, H., The Metasploit Project, , http://www.metasploit.com; Moser, A., Kruegel, C., Kirda, E., Limits of static analysis for malware detection (2007) Proceedings of the 23rd Anual Computer Security Applications Conference; Newsome, J., Karp, B., Song, D., Polygraph: Automatic signature generation for polymorphic worms (2005) IEEE Symposium On Security and Privacy; Newsome, J., Karp, B., Song, D., Paragraph: Thwarting signature learning by training maliciously (2006) Recent Advances In Intrusion Detection (RAID), pp. 81-105. , Springer, Berlin; Newsome, J., Song, D., Dynamic taint analysis for automatic detection, analysis, and signature generation of exploits on commodity software (2005) Proceedings of Network and Distributed System Security Symposium; Pedro, N.D., Domingos, P., Sumit, M., Verma, S.D., Adversarial classification (2004) 10th ACM SIGKDD Conference On Knowledge Discovery and Data Mining, pp. 99-108; Perdisci, R., Dagon, D., Lee, W., Misleading worm signature generators using deliberate noise injection (2006) Proceedings of the 2006 IEEE Symposium On Security and Privacy; Rabiner, L.R., A tutorial on hidden markov models and selected applications in speech recognition (1999) Proceedings of the IEEE, 77 (2), pp. 257-286; Ray, E., Ms-sql Worm, , http://www.sans.org/resources/malwarefaq/ms-sql-exploit.php; Singh, S., Estan, C., Varghese, G., Savage, S., (2003) Earlybird System for Real-Time Detection of Unknown Worms, Technical Report, , San Diego: University of California at San Diego; Smirnov, A., cker Chiueh, T., Dira: Automatic detection, identification and repair of control-hijacking attacks (2005) NDSS; Song, Y., Locasto, M.E., Stavrou, A., Keromytis, A.D., Stolfo, S.J., On the infeasibility of modeling polymorphic shellcode (2007) Proceedings of the 14th ACM Conference On Computer and Communications Security(CCS), pp. 541-551; Szor, P., (2005) The Art of Computer Virus Research and Defense, pp. 112-134. , Upper Saddle River: Addison Wesley; Venkataraman, S., Blum, A., Song, D., Limits of learning-based signature generation with adversaries (2008) Proceedings of the 15th Annual Network and Distributed System Security Symposium; Wang, X., Jhi, Y.C., Zhu, S., Liu, P., Still: Exploit code detection via static taint and initialization analyses (2008) Proceedings of Anual Computer Security Applications Conference (ACSAC); Wang, X., Pan, C.C., Liu, P., Zhu, S., Sigfree: a signature-free buffer overflow attack blocker (2006) 15th Usenix Security Symposium","Kong, D.; College of Information Science and Technology, , University Park, PA, United States; 电子邮件: dkong@ist.psu.edu",,,,,,,,16155262,,,,English,Int. J. Inf. Secur.,Article,Final,,Scopus,2-s2.0-80052922553
[无可用作者姓名],[无可用的作者 ID],"13th International Conference on Information Security and Cryptology, ICISC 2010",2011,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),6829 LNCS,,,,,434,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037371829&partnerID=40&md5=49152cf1f773068b58723044f43e55fc,,,The proceedings contain 28 papers. The special focus in this conference is on Information Security and Cryptology. The topics include: Efficient pairing computation on elliptic curves in hessian form; FPGA implementation of an improved attack against the DECT standard cipher; chameleon: A versatile emulator for contactless smartcards; revisiting address space randomization; evaluation of a spyware detection system using thin client computing; a comparative usability evaluation of traditional password managers; an adversarial evaluation of network signaling and control mechanisms; secure personalized recommendation system for mobile user; Protecting white-box AES with dual ciphers; bias analysis of a certain problem with applications to E0 and shannon cipher; ɛ-MACs: Towards More Secure and More Efficient Constructions of Secure Channels; on equivalence classes of boolean functions; public discussion must be back and forth in secure message transmission; scalar product-based distributed oblivious transfer; unconditionally secure rational secret sharing in standard communication networks; oblivious transfer with complex attribute-based access control; fault attacks on the montgomery powering ladder; first principal components analysis: A new side channel distinguisher; Fault analysis on stream cipher MUGI; known and chosen key differential distinguishers for block ciphers; Related-key attack on the full HIGHT; Preimage attacks against PKC98-hash and HAS-V; Passive cryptanalysis of the unconditionally secure authentication protocol for RFID systems; Cryptanalysis of RSA with small prime combination; the twin bilinear diffie-hellman inversion problem and applications; group signatures are suitable for constrained devices.,,,,,,,,,Rhee K.-H.Nyang D.,,Springer Verlag,"13th International Conference on Information Security and Cryptology, ICISC 2010",1 December 2010 through 3 December 2010,,206039,3029743,9.78E+12,,,English,Lect. Notes Comput. Sci.,Conference Review,Final,,Scopus,2-s2.0-85037371829
"Kong D., Jhi Y.-C., Gong T., Zhu S., Liu P., Xi H.",24831922800;24778740500;55390518800;8886024500;36727836300;7102571247;,SAS: Semantics aware signature generation for polymorphic worm detection,2010,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering",50 LNICST,,,1,19,,8,10.1007/978-3-642-16161-2_1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84869597546&doi=10.1007%2f978-3-642-16161-2_1&partnerID=40&md5=b9d8ef8e49ab23be8925431f35c489a0,"School of Information Science and Technology, University of Science and Technology of China, Hefei, China; Dept. of Computer Sicence and Engineering, Pennsylvania State University, University Park, PA 16802, United States; College of Information Sciences and Technology, Pennsylvania State University, University Park, PA 16802, United States","Kong, D., School of Information Science and Technology, University of Science and Technology of China, Hefei, China, College of Information Sciences and Technology, Pennsylvania State University, University Park, PA 16802, United States; Jhi, Y.-C., Dept. of Computer Sicence and Engineering, Pennsylvania State University, University Park, PA 16802, United States; Gong, T., School of Information Science and Technology, University of Science and Technology of China, Hefei, China; Zhu, S., Dept. of Computer Sicence and Engineering, Pennsylvania State University, University Park, PA 16802, United States; Liu, P., College of Information Sciences and Technology, Pennsylvania State University, University Park, PA 16802, United States; Xi, H., School of Information Science and Technology, University of Science and Technology of China, Hefei, China","String extraction and matching techniques have been widely used in generating signatures for worm detection, but how to generate effective worm signatures in an adversarial environment still remains challenging. For example, attackers can freely manipulate byte distributions within the attack payloads and also can inject well-crafted noisy packets to contaminate the suspicious flow pool. To address these attacks, we propose SAS, a novel Semantics Aware Statistical algorithm for automatic signature generation. When SAS processes packets in a suspicious flow pool, it uses data flow analysis techniques to remove non-critical bytes. We then apply a Hidden Markov Model (HMM) to the refined data to generate state-transition-graph based signatures. To our best knowledge, this is the first work combining semantic analysis with statistical analysis to automatically generate worm signatures. Our experiments show that the proposed technique can accurately detect worms with concise signatures. Moreover, our results indicate that SAS is more robust to the byte distribution changes and noise injection attacks comparing to Polygraph and Hamsa.© Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering 2010.",Data flow analysis; Hidden Markov model; Machine learning; Semantics; Worm signature generation,Adversarial environments; Data flow; Machine-learning; Matching techniques; Noise injection; Noisy packets; Polymorphic worms; Semantic analysis; Signature generation; Statistical algorithm; Worm detection; Worm signatures; Data transfer; Hidden Markov models; Lakes; Network security; Semantics; Telecommunication networks; Data flow analysis,,,,,"Moser, A., Kruegel, C., Kirda, E., Limits of static analysis for malware detection (2007) Proceedings of the 23rd Annual Computer Security Applications Conference; Kim, H.A., Karp, B., Autograph: Toward automated, distributed worm signature detection (2004) Proceedings of the 13th Usenix Security Symposium; Kreibich, C., Crowcroft, J., Honeycomb: Creating intrusion detection signatures using hon-eypots (2003) Proceedings of the Workshop on Hot Topics in Networks, , HotNets; Singh, S., Estan, C., Varghese, G., Savage, S., Earlybird system for real-time detection of unknown worms (2003) Technical Report, Univ. of California, , San Diego; Newsome, J., Karp, B., Song, D., Polygraph: Automatic signature generation for polymorphic worms (2005) IEEE Symposium on Security and Privacy; Li, Z., Sanghi, M., Chen, Y., Kao, M.Y., Chavez, B., Hamsa: Fast signature generation for zero-day polymorphic worms with provable attack resilience (2006) IEEE Symposium on Security and Privacy; Chung, S.P., Mok, A.K., Advanced allergy attacks: Does a corpus really help (2007) RAID 2007, 4637, pp. 236-255. , Kruegel, C., Lippmann, R., Clark, A. (eds.) LNCS Springer, Heidelberg; Newsome, J., Karp, B., Song, D., Paragraph: Thwarting signature learning by training maliciously (2006) Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 4219, pp. 81-105. , Recent Advances in Intrusion Detection - 9th International Symposium, RAID 2006, Proceedings; Perdisci, R., Dagon, D., Lee, W., Misleading worm signature generators using deliberate noise injection (2006) Proceedings of the 2006 IEEE Symposium on Security and Privacy; Liang, Z., Sekar, R., Fast and automated generation of attack signatures: A basis for building self-protecting servers (2005) Proceedings of the 12th ACM Conference on Computer and Communications Security; Newsome, J., Song, D., Dynamic taint analysis for automatic detection, analysis, and signature generation of exploits on commodity software (2005) Proceedings of Network and Distributed System Security Symposium; Liang, Z., Sekar, R., Automatic generation of buffer overflow attack signatures: An approach based on program behavior models (2005) Proceedings of the Annual Computer Security Applications Conference; Wang, X., Pan, C.C., Liu, P., Zhu, S., Sigfree: A signature-free buffer overflow attack blocker (2006) 15th Usenix Security Symposium; Borders, K., Prakash, A., Zielinski, M., Spector: Automatically analyzing shell code (2007) Proceedings of the 23rd Annual Computer Security Applications Conference, pp. 501-514; Wang, X., Jhi, Y.C., Zhu, S., Liu, P., Still: Exploit code detection via static taint and initialization analyses (2008) Proceedings of Anual Computer Security Applications Conference, , ACSAC; Krügel, C., Lippmann, R., Clark, A., Emulation-based detection of non-self-contained polymorphic shellcode (2007) RAID 2007, 4637, pp. 87-106. , Kruegel, C., Lippmann, R., Clark, A. (eds.) LNCS Springer, Heidelberg; Baecher, P., Koetter, M., Getting Around Non-executable Stack (and Fix), , http://libemu.carnivore.it/; Szor, P., (2005) The Art of Computer Virus Research and Defense, pp. 112-134. , Addison-Wesley, Reading; Bania, P., Evading Network-level Emulation, , http://www.packetstormsecurity.org/papers/bypass/pbania-evading-nemu2009. pdf; Collberg, C., Thomborson, C., Low, D., A taxonomy of obfuscating transformations (1997) Technical Report 148, University of Auckland; Detristan, T., Ulenspiegel, T., Malcom, Y., Superbus, M., Underduk, V., Polymorphic Shellcode Engine Using Spectrum Analysis, , http://www.phrack.org/show.php?p=61&a=9; Ray, E., Ms-sql Worm, , http://www.sans.org/resources/malwarefaq/ms-sql-exploit.php; Song, Y., Locasto, M.E., Stavrou, A., Keromytis, A.D., Stolfo, S.J., On the infeasibility of modeling polymorphic shellcode (2007) Proceedings of the 14th ACM Conference on Computer and Communications Security (CCS), pp. 541-551; Rabiner, L.R., A tutorial on hidden Markov models and selected applications in speech recognition (1999) Proceedings of the IEEE, 77 (2), pp. 257-286; Moore, H., http://www.metasploit.com; Gundy, M.V., Chen, H., Su, Z., Vigna, G., Feature omission vulnerabilities: Thwarting signature generation for polymorphic worms (2007) Proceeding of Annual Computer Security Applications Conference, , ACSAC; Fogla, P., Sharif, M., Perdisci, R., Kolesnikov, O., Lee, W., Polymorphic blending attacks (2006) Proceedings of the 15th USENIX Security Symposium; Venkataraman, S., Blum, A., Song, D., Limits of learning-based signature generation with adversaries (2008) Proceedings of the 15th Annual Network and Distributed System Security Symposium; Gundy, M.V., Balzarotti, D., Vigna, G., Catch me, if you can: Evading network signatures with web-based polymorphic worms (2007) Proceedings of the First USENIX Workshop on Offensive Technologies (WOOT), , Boston, MA; Dalvi, N., Domingos, P., Sumit, M., Sanghai, S., Verma, D., Adversarial classification (2004) KDD-2004 - Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 99-108. , KDD-2004 - Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining; Brumley, D., Caballero, J., Liang, Z., Newsome, J., Song, D., Towards automatic discovery of deviations in binary implementations with applications to error detection and fingerprint generation (2007) Proceedings of the 16th USENIX Security; Christodorescu, M., Jha, S., Seshia, S., Song, D., Bryant, R., Semantics-aware malware detection (2005) 2005 IEEE Symposium on Security and Privacy; Krugel, C., Kirda, E., Polymorphic worm detection using structural information of executables (2005) 2005 International Symposium on Recent Advances in Intrusion Detecion","Kong, D.; School of Information Science and Technology, , Hefei, China; 电子邮件: kdg@mail.ustc.edu.cn",,"Inst. Comput. Sci., Soc.-Informatics Telecommun. Eng. (ICST)",,"6th International Conference on Security and Privacy in Communication Networks, SecureComm 2010",7 September 2010 through 9 September 2010,Singapore,86055,18678211,364216160X; 9783642161605,,,English,Lect. Notes Inst. Comput. Sci. Soc. Informatics Telecommun. Eng.,Conference Paper,Final,,Scopus,2-s2.0-84869597546
