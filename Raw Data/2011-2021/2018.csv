Authors,Author(s) ID,Title,Year,Source title,Volume,Issue,Art. No.,Page start,Page end,Page count,Cited by,DOI,Link,Affiliations,Authors with affiliations,Abstract,Author Keywords,Index Keywords,Molecular Sequence Numbers,Chemicals/CAS,Tradenames,Manufacturers,References,Correspondence Address,Editors,Sponsors,Publisher,Conference name,Conference date,Conference location,Conference code,ISSN,ISBN,CODEN,PubMed ID,Language of Original Document,Abbreviated Source Title,Document Type,Publication Stage,Open Access,Source,EID
"Schlotfeldt B., Tzoumas V., Thakur D., Pappas G.J.","57170799500;55533930600;55643503500;57203254826;","Resilient Active Information Gathering with Mobile Robots",2018,"IEEE International Conference on Intelligent Robots and Systems",,,"8593630","4309","4316",,9,"10.1109/IROS.2018.8593630","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062943926&doi=10.1109%2fIROS.2018.8593630&partnerID=40&md5=2502ffa3291c8218088ee5e6ad9ca0c1","Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA  19104, United States","Schlotfeldt, B., Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA  19104, United States; Tzoumas, V., Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA  19104, United States; Thakur, D., Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA  19104, United States; Pappas, G.J., Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA  19104, United States","Applications of safety, security, and rescue in robotics, such as multi-robot target tracking, involve the execution of information acquisition tasks by teams of mobile robots. However, in failure-prone or adversarial environments, robots get attacked, their communication channels get jammed, and their sensors may fail, resulting in the withdrawal of robots from the collective task, and consequently the inability of the remaining active robots to coordinate with each other. As a result, traditional design paradigms become insufficient and, in contrast, resilient designs against system-wide failures and attacks become important. In general, resilient design problems are hard, and even though they often involve objective functions that are monotone or submodular, scalable approximation algorithms for their solution have been hitherto unknown. In this paper, we provide the first algorithm, enabling the following capabilities: minimal communication, i.e., the algorithm is executed by the robots based only on minimal communication between them; system-wide resiliency, i.e., the algorithm is valid for any number of denial-of-service attacks and failures; and provable approximation performance, i.e., the algorithm ensures for all monotone (and not necessarily submodular) objective functions a solution that is finitely close to the optimal. We quantify our algorithms approximation performance using a notion of curvature for monotone set functions. We support our theoretical analyses with simulated and real-world experiments, by considering an active information gathering scenario, namely, multi-robot target tracking. © 2018 IEEE.",,"Approximation algorithms; Clutter (information theory); Denial-of-service attack; Industrial robots; Mobile robots; Multipurpose robots; Network security; Target tracking; Adversarial environments; Approximation performance; Information acquisitions; Information gathering; Monotone set functions; Objective functions; Real world experiment; Resilient design; Intelligent robots",,,,,"Michini, M., Hsieh, M.A., Forgoston, E., Schwartz, I.B., Robotic tracking of coherent structures in flows (2014) IEEE Transactions on Robotics, 30 (3), pp. 593-603; Nieto-Granda, C., Rogers, J.G., III, Christensen, H., Multi-robot exploration strategies for tactical tasks in urban environments (2013) SPIE Defense, Security, and Sensing. International Society for Optics and Photonics, pp. 87410B-87410B; Kumar, V., Michael, N., Opportunities and challenges with autonomous micro aerial vehicles (2012) The International Journal of Robotics Research, 31 (11), pp. 1279-1291; Karaman, S., Frazzoli, E., High-speed flight in an ergodic forest (2012) IEEE Intern. Confer. on Robotics and Automation, pp. 2899-2906; Cadena, C., Carlone, L., Carrillo, H., Latif, Y., Scaramuzza, D., Neira, J., Reid, I., Leonard, J.J., Past, present, and future of simultaneous localization and mapping: Toward the robust-perception age (2016) IEEE Transactions on Robotics, 32 (6), pp. 1309-1332; Cieslewski, T., Kaufmann, E., Scaramuzza, D., Rapid exploration with multi-rotors: A frontier selection method for high speed flight (2017) IEEE/RSJ Int. Conf. on Intel. Robots and Systems, pp. 2135-2142; Santos, M., Diaz-Mercado, Y., Egerstedt, M., Coverage control for multirobot teams with heterogeneous sensing capabilities (2018) IEEE Robotics and Automation Letters, 3 (2), pp. 919-925; Krause, A., (2008) Optimizing Sensing: Theory and Applications, , Ph. D. dissertation, Carnegie Mellon University; Williams, J.L., (2007) Information Theoretic Sensor Management, , Ph. D. dissertation, Massachusetts Institute of Technology; Tzoumas, V., Jadbabaie, A., Pappas, G.J., Near-optimal sensor scheduling for batch state estimation (2016) IEEE 55th Conference on Decision and Control, pp. 2695-2702; Hoffmann, G.M., Tomlin, C.J., Mobile sensor network control using mutual information methods and particle filters (2010) IEEE Transactions on Automatic Control, 55 (1), pp. 32-47; Julian, B.J., Angermann, M., Schwager, M., Rus, D., Distributed robotic sensor networks: An information-theoretic approach (2012) The Inter. Journal of Robotics Research, 31 (10), pp. 1134-1154; Dames, P., Schwager, M., Kumar, V., Rus, D., A decentralized control policy for adaptive information gathering in hazardous environments (2012) IEEE Conference on Decision and Control, pp. 2807-2813; Dames, P., Kumar, V., Autonomous localization of an unknown number of targets using teams of mobile sensors (2015) IEEE Trans. on Autom. Science and Eng., 12 (3), pp. 850-864; Charrow, B., Kumar, V., Michael, N., Approximate representations for multi-robot control policies that maximize mutual information (2014) Autonomous Robots, 37 (4), pp. 383-400; Chung, T.H., Burdick, J.W., Murray, R.M., A decentralized motion coordination strategy for dynamic target tracking (2006) IEEE International Conference on Robotics and Automation, pp. 2416-2422; Kreucher, C.M., (2005) An Information-based Approach to Sensor Resource Allocation, , Ph. D. dissertation, University of Michigan; Atanasov, N., Le Ny, J., Daniilidis, K., Pappas, G.J., Information acquisition with sensing robots: Algorithms and error bounds (2014) IEEE International Confer. on Robotics and Automation, pp. 6447-6454; Schlotfeldt, B., Thakur, D., Atanasov, N., Kumar, V., Pappas, G.J., Anytime planning for decentralized multi-robot active information gathering (2018) IEEE Robotics and Automation Letters; Atanasov, N., Le Ny, J., Daniilidis, K., Pappas, G.J., Decentralized active information acquisition: Theory and application to multi-robot slam (2015) IEEE Int. Conf. on Rob. and Autom., pp. 4775-4782; Orlin, J.B., Schulz, A.S., Udwani, R., Robust monotone submodular function maximization (2016) Inter. Conference on Integer Programming and Combinatorial Optimization, pp. 312-324; Tzoumas, V., Gatsis, K., Jadbabaie, A., Pappas, G.J., Resilient monotone submodular function maximization (2017) IEEE Conference on Decision and Control, pp. 1362-1367; Tzoumas, V., Jadbabaie, A., Pappas, G.J., Resilient Monotone Sequential Maximization, , ArXiv e-prints: 1803. 07954; Bertsekas, D.P., (2005) Dynamic Programming and Optimal Control, 1. , Athena Scientific; Feige, U., A threshold of ln (n) for approximating set cover (1998) Journal of the ACM, 45 (4), pp. 634-652; Nemhauser, G., Wolsey, L., Fisher, M., An analysis of approximations for maximizing submodular set functions-I (1978) Mathematical Programming, 14 (1), pp. 265-294; Conforti, M., Cornuéjols, G., Submodular set functions, matroids and the greedy algorithm (1984) Discrete Applied Mathematics, 7 (3), pp. 251-274; Sviridenko, M., Vondrák, J., Ward, J., Optimal approximation for submodular and supermodular optimization with bounded curvature (2017) Math. of Operations Research, 42 (4), pp. 1197-1218; Jawaid, S.T., Smith, S.L., Submodularity and greedy algorithms in sensor scheduling for linear dynamical systems (2015) Automatica, 61, pp. 282-288",,,"Bosch;et al.;JD.Com;Kuka;PAL Robotics;Santander","Institute of Electrical and Electronics Engineers Inc.","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2018","1 October 2018 through 5 October 2018",,144267,21530858,9781538680940,85RBA,,"English","IEEE Int Conf Intell Rob Syst",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85062943926
"Guo W., Wang Q., Zhang K., Ororbia A.G., Huang S., Liu X., Giles C.L., Lin L., Xing X.","57189320119;56723064100;57195597686;56394594800;57205746584;24178306600;55665046700;37052417100;23391338800;","Defending Against Adversarial Samples Without Security through Obscurity",2018,"Proceedings - IEEE International Conference on Data Mining, ICDM","2018-November",,"8594838","137","146",,5,"10.1109/ICDM.2018.00029","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061405847&doi=10.1109%2fICDM.2018.00029&partnerID=40&md5=e6e57fb52f7a3f1d4a06a9062ee44390","Pennsylvania State University, United States; McGill University, Canada; Netflix, Inc., Canada; Rochester Institute of Technology, United States","Guo, W., Pennsylvania State University, United States; Wang, Q., McGill University, Canada; Zhang, K., Pennsylvania State University, United States; Ororbia, A.G., Rochester Institute of Technology, United States; Huang, S., Netflix, Inc., Canada; Liu, X., McGill University, Canada; Giles, C.L., Pennsylvania State University, United States; Lin, L., Pennsylvania State University, United States; Xing, X., Pennsylvania State University, United States","It has been recently shown that deep neural networks (DNNs) are susceptible to a particular type of attack that exploits a fundamental flaw in their design. This attack consists of generating particular synthetic examples referred to as adversarial samples. These samples are constructed by slightly manipulating real data-points that change 'fool' the original DNN model, forcing it to misclassify previously correctly classified samples with high confidence. Many believe addressing this flaw is essential for DNNs to be used in critical applications such as cyber security. Previous work has shown that learning algorithms that enhance the robustness of DNN models all use the tactic of 'security through obscurity'. This means that security can be guaranteed only if one can obscure the learning algorithms from adversaries. Once the learning technique is disclosed, DNNs protected by these defense mechanisms are still susceptible to adversarial samples. In this work, we investigate by examining how previous research dealt with this and propose a generic approach to enhance a DNN's resistance to adversarial samples. More specifically, our approach integrates a data transformation module with a DNN, making it robust even if we reveal the underlying learning algorithm. To demonstrate the generality of our proposed approach and its potential for handling cyber security applications, we evaluate our method and several other existing solutions on datasets publicly available, such as a large scale malware dataset and MNIST and IMDB datasets. Our results indicate that our approach typically provides superior classification performance and robustness to attacks compared with state-of-art solutions. © 2018 IEEE.","Adversarial deep learning; Data transformation; Malware detection; Security through obscurity","Computer crime; Data mining; Deep neural networks; Large dataset; Malware; Metadata; Classification performance; Critical applications; Data transformation; Defense mechanism; Generic approach; Learning techniques; Malware detection; Security through obscurity; Learning algorithms",,,,,"Bastani, O., Ioannou, Y., Lampropoulos, L., Vytiniotis, D., Nori, A., Criminisi, A., Measuring neural net robustness with constraints (2016) Proceedings of the 29th Conference on Neural Information Processing Systems (NIPS); Berlin, K., Slater, D., Saxe, J., Malicious behavior detection using windows audit logs (2015) Proceedings of the 8th ACM Workshop on Artificial Intelligence and Security (AISec); Bhagoji, A.N., Cullina, D., Mittal, P., (2017) Dimensionality Reduction As A Defense Against Evasion Attacks on Machine Learning Classifiers; Cao, X., Gong, N.Z., Mitigating evasion attacks to deep neural networks via region-based classification (2017) Proceedings of the 33rd Annual Computer Security Applications Conference (ACSAC); Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Proceedings of the 38th IEEE Symposium on Security and Privacy (S&P); Ciresan, D.C., Meier, U., Gambardella, L.M., Schmidhuber, J., (2010) Deep Big Simple Neural Nets Excel on Handwritten Digit Recognition, , CoRR; Cisse, M., Bojanowski, P., Grave, E., Dauphin, Y., Usunier, N., Parseval networks: Improving robustness to adversarial examples (2017) Proceedings of the 34th International Conference on Machine Learning (ICML); D'Aspremont, A., Boyd, S., (2003) Relaxations and Randomized Methods for Nonconvex Qcqps, , Stanford University; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) Proceedings of the 3rd International Conference on Learning Representations (ICLR); Horn, R.A., Johnson, C.R., (1990) Matrix Analysis. Corrected Reprint of the 1985 Original; Hornik, K., Approximation capabilities of multilayer feedforward networks (1991) Neural Networks; Kerckhoffs, A., La cryptographie militaire (1883) Journal des Sciences Militaires; LeCun, Y., Cortes, C., Burges, C.J., (1998) The Mnist Database of Handwritten Digits; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) Proceedings of the 5th International Conference on Learning Representations (ICLR); Maas, A.L., Daly, R.E., Pham, P.T., Huang, D., Ng, A.Y., Potts, C., Learning word vectors for sentiment analysis (2011) Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL); Maaten L, V.D., Hinton, G., Visualizing data using t-sne (2008) Journal of Machine Learning Research; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks; Meng, D., Chen, H., Magnet: A two-pronged defense against adversarial examples (2017) Proceedings of the 24th ACM Conference on Computer and Communications Security (CCS); Mikolov, T., Sutskever, I., Chen, K., Corrado, G.S., Dean, J., Distributed representations of words and phrases and their compositionality (2013) Proceedings of the 26th Conference on Neural Information Processing Systems (NIPS); Mohan, V., Hamlen, K.W., Frankenstein: Stitching malware from benign binaries (2012) 6th USENIX Workshop on Offensive Technologies (WOOT); Ororbia, I., Alexander, G., Giles, C.L., Kifer, D., Unifying adversarial training algorithms with flexible deep data gradient regularization (2016) Neural Computation; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Proceedings of the 1st IEEE European Symposium on Security and Privacy (EuroS&P); Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Proceedings of the 37th IEEE Symposium on Security and Privacy (S&P); Pei, K., Cao, Y., Yang, J., Jana, S., Deepxplore: Automated whitebox testing of deep learning systems (2017) Proceedings of the 26th Symposium on Operating Systems Principles (SOSP); Roweis, S.T., Saul, L.K., Nonlinear dimensionality reduction by locally linear embedding (2000) Science; Sabour, S., Cao, Y., Faghri, F., Fleet, D.J., (2015) Adversarial Manipulation of Deep Representations; Sammon, J.W., A nonlinear mapping for data structure analysis (1969) IEEE Transactions on Computers; Sinha, A., Namkoong, H., Duchi, J., Certifiable distributional robustness with principled adversarial training (2018) Proceedings of the 6th International Conference on Learning Representations (ICLR); Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) Proceedings of the 2nd International Conference on Learning Representations (ICLR); Van Der Maaten, L., Postma, E.O., Van Den Herik, H.J., (2008) Dimensionality Reduction: A Comparative Review; Vavasis, S.A., (1991) Nonlinear Optimization: Complexity Issues; Wang, Q., Guo, W., Zhang, K., Ororbia, I.I.A.G., Xing, X., Liu, X., Giles, C.L., Adversary resistant deep neural networks with an application to malware detection (2017) Proceedings of the 23rd International Conference on Knowledge Discovery and Data Mining (KDD); Wu, X., Jang, U., Chen, L., Jha, S., Reinforcing adversarial robustness using model confidence induced by adversarial training (2018) Proceedings of the 35th International Conference on Machine Learning (ICML); Xiao, C., Li, B., Zhu, J.-Y., He, W., Liu, M., Song, D., Generating adversarial examples with adversarial networks (2018) Proceedings of the 27th International Joint Conference on Artificial Intelligence (IJCAI); Xu, W., Evans, D., Qi, Y., Feature squeezing: Detecting adversarial examples in deep neural networks (2018) Proceedings of the 24th Network and Distributed Systems Security Symposium (NDSS); Xu, X., Chen, X., Liu, C., Rohrbach, A., Darell, T., Song, D., Fooling vision and language models despite localization and attention mechanism (2018) Proceedings of the 30th IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Zhao, Z., Dua, D., Singh, S., Generating natural adversarial examples (2018) Proceedings of the 6th International Conference on Learning Representations (ICLR)",,,"Alibaba.Com;et al.;IEEE;IEEE Computer Society;Living Analytics Research Centre (LARC);Squirrel Al Learning","Institute of Electrical and Electronics Engineers Inc.","18th IEEE International Conference on Data Mining, ICDM 2018","17 November 2018 through 20 November 2018",,144190,15504786,9781538691588,,,"English","Proc. IEEE Int. Conf. Data Min. ICDM",Conference Paper,"Final","",Scopus,2-s2.0-85061405847
"Song Q., Jin H., Huang X., Hu X.","57195599749;57205739479;57193628904;35114937200;","Multi-label Adversarial Perturbations",2018,"Proceedings - IEEE International Conference on Data Mining, ICDM","2018-November",,"8594975","1242","1247",,7,"10.1109/ICDM.2018.00166","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061378038&doi=10.1109%2fICDM.2018.00166&partnerID=40&md5=363819ca3a2e04b0cfd7527aa8cc16c7","Department of Computer Science and Engineering, Texas AandM University, United States","Song, Q., Department of Computer Science and Engineering, Texas AandM University, United States; Jin, H., Department of Computer Science and Engineering, Texas AandM University, United States; Huang, X., Department of Computer Science and Engineering, Texas AandM University, United States; Hu, X., Department of Computer Science and Engineering, Texas AandM University, United States","Adversarial examples are delicately perturbed inputs, which aim to mislead machine learning models towards incorrect outputs. While existing work focuses on generating adversarial perturbations in multiclass classification problems, many real-world applications fall into the multi-label setting, in which one instance could be associated with more than one label. To analyze the vulnerability and robustness of multi-label learning models, we investigate the generation of multi-label adversarial perturbations. This is a challenging task due to the uncertain number of positive labels associated with one instance, and the fact that multiple labels are usually not mutually exclusive with each other. To bridge the gap, in this paper, we propose a general attacking framework targeting multi-label classification problem and conduct a premier analysis on the perturbations for deep neural networks. Leveraging the ranking relationships among labels, we further design a ranking-based framework to attack multi-label ranking algorithms. Experiments on two different datasets demonstrate the effectiveness of the proposed frameworks and provide insights of the vulnerability of multi-label deep models under diverse targeted attacks. © 2018 IEEE.","Adversarial attack; Adversarial machine learning; Multi label learning","Classification (of information); Deep neural networks; Learning algorithms; Machine learning; Adversarial attack; Machine learning models; Multi label classification; Multi-label; Multi-label learning; Multi-label rankings; Multiclass classification problems; Multiple labels; Data mining",,,,,"Vorobeychik, Y., Adversarial ai (2016) IJCAI; Liu, N., Yang, H., Hu, X., Adversarial detection with model interpretation (2018) KDD; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) ICLR; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) CVPR; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) S&P; Huang, S.-J., Gao, N., Chen, S., Multi-instance multi-label active learning (2017) IJCAI; Hoi, S.C., Jin, R., Lyu, M.R., Large-scale text categorization by batch mode active learning (2006) WWW; Boutell, M.R., Luo, J., Shen, X., Brown, C.M., Learning multi-label scene classification (2004) Pattern Recognition; Gupta, A., Lamba, H., Kumaraguru, P., Joshi, A., Faking sandy: Characterizing and identifying fake images on twitter during hurricane sandy (2013) WWW; Papernot, N., McDaniel, P., Sinha, A., Wellman, M., (2016) Towards the Science of Security and Privacy in Machine Learning; Wu, Y., Bamman, D., Russell, S., Adversarial training for relation extraction (2017) EMNLP; Tang, L., Rajan, S., Narayanan, V.K., Large scale multi-label classification via metalabeler (2009) WWW; Schapire, R.E., Singer, Y., Boostexter: A boosting-based system for text categorization (2000) Machine Learning; Zhang, M.-L., Zhou, Z.-H., Multilabel neural networks with applications to functional genomics and text categorization (2006) TKDE; Agresti, A., Kateri, M., Categorical data analysis (2011) International Encyclopedia of Statistical Science; Everingham, M., Van Gool, L., Williams, C.K., Winn, J., Zisserman, A., The pascal visual object classes (voc) challenge (2010) IJCV; Everingham, M., Eslami, S.A., Van Gool, L., Williams, C.K., Winn, J., Zisserman, A., The pascal visual object classes challenge: A retrospective (2015) IJCV; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) CVPR; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Bernstein, M., Imagenet large scale visual recognition challenge (2015) IJCV; Wu, X.-Z., Zhou, Z.-H., A unified view of multi-label performance measures (2016) ICML; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) ICLR",,,"Alibaba.Com;et al.;IEEE;IEEE Computer Society;Living Analytics Research Centre (LARC);Squirrel Al Learning","Institute of Electrical and Electronics Engineers Inc.","18th IEEE International Conference on Data Mining, ICDM 2018","17 November 2018 through 20 November 2018",,144190,15504786,9781538691588,,,"English","Proc. IEEE Int. Conf. Data Min. ICDM",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85061378038
"Pengcheng L., Yi J., Zhang L.","55494986400;36095116600;55966103100;","Query-Efficient Black-Box Attack by Active Learning",2018,"Proceedings - IEEE International Conference on Data Mining, ICDM","2018-November",,"8594968","1200","1205",,13,"10.1109/ICDM.2018.00159","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061348179&doi=10.1109%2fICDM.2018.00159&partnerID=40&md5=c8dafcec47666b208e19a495f36020bc","National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, 210023, China; JD AI Research, Singapore","Pengcheng, L., National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, 210023, China; Yi, J., JD AI Research, Singapore; Zhang, L., National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, 210023, China","Deep neural network (DNN) as a popular machine learning model is found to be vulnerable to adversarial attack. This attack constructs adversarial examples by adding small perturbations to the raw input, while appearing unmodified to human eyes but will be misclassified by a well-trained classifier. In this paper, we focus on the black-box attack setting where attackers have almost no access to the underlying models. To conduct black-box attack, a popular approach aims to train a substitute model based on the information queried from the target DNN. The substitute model can then be attacked using existing white-box attack approaches, and the generated adversarial examples will be used to attack the target DNN. Despite its encouraging results, this approach suffers from poor query efficiency, i.e., attackers usually needs to query a huge amount of times to collect enough information for training an accurate substitute model. To this end, we first utilize state-of-the-art white-box attack methods to generate samples for querying, and then introduce an active learning strategy to significantly reduce the number of queries needed. Besides, we also propose a diversity criterion to avoid the sampling bias. Our extensive experimental results on MNIST and CIFAR-10 show that the proposed method can reduce more than 90% of queries while preserve attacking success rates and obtain an accurate substitute model which is more than 85% similar with the target oracle. © 2018 IEEE.","Active learning; Deep neural network","Artificial intelligence; Data mining; Active Learning; Active learning strategies; Attack methods; Machine learning models; Model-based OPC; Query efficiency; Small perturbations; State of the art; Deep neural networks",,,,,"LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), p. 436; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Metzen, J.H., Kumar, M.C., Brox, T., Fischer, V., Universal Adversarial Perturbations against Semantic Image Segmentation (2017) Proceedings of the 2017 IEEE International Conference on Computer Vision; Cheng, M., Yi, J., Zhang, H., Chen, P.-Y., Hsieh, C.-J., (2018) Seq2Sick: Evaluating the Robustness of Sequence-to-Sequence Models with Adversarial Examples; Xu, X., Chen, X., Liu, C., Rohrbach, A., Darell, T., Song, D., (2017) Can You Fool AI with Adversarial Examples on A Visual Turing Test; Chen, H., Zhang, H., Chen, P.-Y., Yi, J., Hsieh, C.-J., (2017) Show-and-Fool: Crafting Adversarial Examples for Neural Image Captioning; Carlini, N., Wagner, D., (2018) Audio Adversarial Examples: Targeted Attacks on Speech-to-Text; Sun, M., Tang, F., Yi, J., Wang, F., Zhou, J., (2018) Identify Susceptible Locations in Medical Records Via Adversarial Attacks on Deep Predictive Models; Evtimov, I., Eykholt, K., Fernandes, E., Kohno, T., Li, B., Prakash, A., Rahmati, A., Song, D., (2017) Robust Physical-World Attacks on Machine Learning Models; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Proceedings of the 2017 IEEE Symposium on Security and Privacy, pp. 39-57; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the 2016 IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 15-26; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519; Buckman, J., Roy, A., Raffel, C., Goodfellow, I., Thermometer encoding: One hot way to resist adversarial examples (2018) Proceedings of the International Conference on Learning Representations; Guo, C., Rana, M., Cissé, M., Van der Maaten, L., (2017) Countering Adversarial Images Using Input Transformations; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., (2017) Mitigating Adversarial Effects Through Randomization; Athalye, A., Carlini, N., Wagner, D., (2018) Obfuscated Gradients Give A False Sense of Security: Circumventing Defenses to Adversarial Examples; Athalye, A., Sutskever, I., (2017) Synthesizing Robust Adversarial Examples; Narodytska, N., Kasiviswanathan, S.P., (2016) Simple Black-Box Adversarial Perturbations for Deep Networks; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Proceedings of the 2016 IEEE European Symposium on Security and Privacy, pp. 372-387; Tu, C.-C., Ting, P., Chen, P.-Y., Liu, S., Zhang, H., Yi, J., Hsieh, C.-J., Cheng, S.-M., (2018) AutoZOOM: Autoencoder-based Zeroth Order Optimization Method for Attacking Black-box Neural Networks; Hayes, J., Danezis, G., (2017) Machine Learning As An Adversarial Service: Learning Black-Box Adversarial Examples; Settles, B., (2010) Active Learning Literature Survey, 52 (11), pp. 55-66. , University of Wisconsin, Madison; Zhu, J., Wang, H., Yao, T., Tsou, B.K., Active learning with sampling by uncertainty and density for word sense disambiguation and text classification (2008) Proceedings of the 22nd International Conference on Computational Linguistics, 1, pp. 1137-1144. , Association for Computational Linguistics; Small, K., Roth, D., Margin-based active learning for structured predictions (2010) International Journal of Machine Learning and Cybernetics, 1 (1-4), pp. 3-25; Har-Peled, S., Roth, D., Zimak, D., Constraint classification for multiclass classification and ranking (2003) Advances in Neural Information Processing Systems, 16, pp. 809-816; Zheng, Z., Padmanabhan, B., On active learning for data acquisition (2002) Proceedings of the 2002 IEEE International Conference on Data Mining; Scheffer, T., Decomain, C., Wrobel, S., Active hidden markov models for information extraction (2001) Proceedings of the International Symposium on Intelligent Data Analysis, pp. 309-318. , Springer; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World; Rozsa, A., Rudd, E.M., Boult, T.E., Adversarial diversity and hard positive generation (2016) Proceedings of the 2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops, pp. 25-32; LeCun, Y., (1998) The MNIST Database of Handwritten Digits, , http://yann.lecun.com/exdb/mnist/; Xiao, H., Rasul, K., Vollgraf, R., (2017) Fashion-mnist: A Novel Image Dataset for Benchmarking Machine Learning Algorithms; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images, , Technical report, University of Toronto; Vitter, J.S., Random sampling with a reservoir (1985) ACM Transactions on Mathematical Software, 11 (1), pp. 37-57",,,"Alibaba.Com;et al.;IEEE;IEEE Computer Society;Living Analytics Research Centre (LARC);Squirrel Al Learning","Institute of Electrical and Electronics Engineers Inc.","18th IEEE International Conference on Data Mining, ICDM 2018","17 November 2018 through 20 November 2018",,144190,15504786,9781538691588,,,"English","Proc. IEEE Int. Conf. Data Min. ICDM",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85061348179
"Su J., Vargas D.V., Sakurai K.","57183432800;55827483600;7402174117;","Empirical evaluation on robustness of deep convolutional neural networks activation functions against adversarial perturbation",2018,"Proceedings - 2018 6th International Symposium on Computing and Networking Workshops, CANDARW 2018",,,"8590903","223","227",,1,"10.1109/CANDARW.2018.00049","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061449814&doi=10.1109%2fCANDARW.2018.00049&partnerID=40&md5=31a98aa29b5dd14c0208c601b9ccf6bc","Kyushu University, Japan","Su, J., Kyushu University, Japan; Vargas, D.V., Kyushu University, Japan; Sakurai, K., Kyushu University, Japan","Recent research has shown that deep convolutional neural networks (DCNN) are vulnerable to several different types of attacks while the reasons of such vulnerability are still under investigation. For instance, the adversarial perturbations can conduct a slight change on a natural image to make the target DCNN make the wrong recognition, while the reasons that DCNN is sensitive to such small modification are divergent from one research to another. In this paper, we evaluate the robustness of two commonly used activation functions of DCNN, namely the sigmoid and ReLu, against the recently proposed low-dimensional one-pixel attack. We show that the choosing of activation functions can be an important factor that influences the robustness of DCNN. The results show that comparing with sigmoid, the ReLu non-linearity is more vulnerable which allows the low dimensional one-pixel attack exploit much higher success rate and confidence of launching the attack. The results give insights on designing new activation functions to enhance the security of DCNN. © 2018 IEEE.","Adversarial perturbation; Deep Neural Network; Image Processing","Binary alloys; Chemical activation; Convolution; Function evaluation; Image processing; Lutetium alloys; Neural networks; Pixels; Rhenium alloys; Activation functions; Adversarial perturbation; Convolutional neural network; Empirical evaluations; Low dimensional; Natural images; New activation functions; Recent researches; Deep neural networks",,,,,"Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Dang, H., Huang, Y., Chang, E.-C., (2017) Evading Classifiers by Morphing in the Dark.; Das, S., Suganthan, P.N., Differential evolution: A survey of the stateof-The-Art (2011) IEEE Transactions on Evolutionary Computation, 15 (1), pp. 4-31; Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; (2017) Analysis of Universal Adversarial Perturbations, , arXiv preprint arXiv:1705.09554; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint arXiv:1412.6572; Moosavi Dezfooli, S.M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) Proceedings of 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Number EPFLCONF-226156; Narodytska, N., Kasiviswanathan, S., Simple black-box adversarial attacks on deep neural networks (2017) 2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), pp. 1310-1318. , IEEE; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 427-436; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519. , ACM; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387. , IEEE; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition, , arXiv preprint arXiv:1409.1556; Springenberg, J., Dosovitskiy, A., Brox, T., Riedmiller, M., Striving for simplicity: The all convolutional net ICLR (Workshop Track); Storn, R., Price, K., Differential evolution-A simple and efficient heuristic for global optimization over continuous spaces (1997) Journal of Global Optimization, 11 (4), pp. 341-359; Szegedy, C.E.A., Intriguing properties of neural networks (2014) ICLR. Citeseer; Su, J., Vargas, D., Sakurai, K., (2017) One Pixel Attack for Fooling Deep Neural Networks, , arXiv preprint arXiv:1710.08864; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., (2015) Distillation As A Defense to Adversarial Perturbations Against Deep Neural Networks, , arXiv preprint arXiv: 1511.04508; Sankaranarayanan, S., Jain, A., Chellappa, R., Lim, S.N., (2017) Regularizing Deep Networks Using Efficient Layerwise Adversarial Training, , arXiv preprint arXiv: 1705.07819; Tanay, T., (2016) L. Griffin A Boundary Tilting Persepective on the Phenomenon of Adversarial Examples, , arXiv preprint arXiv: 1608.07690; Luo, Y., Boix, X., Roig, G., Poggio, T., Zhao, Q., (2015) A Boundary Tilting Persepective on the Phenomenon of Adversarial Examples, , arXiv preprint arXiv: 1511.06292; Novak, R., Bahri, Y., Abolafia, D., Pennington, J., Sohl-Dickstein, J., Sensitivity and Generalization in Neural Networks: An Empirical Study, p. 2018. , arXiv preprint arXiv:1802.08760; Nair, V., Hinton, G., Rectified linear units improve restricted boltzmann machines (2010) Proceedings of the 27th International Conference on Machine Learning (ICML-10), pp. 807-814; He, K., Zhang, X., Ren, S., Sun, J., Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification, p. 2015. , arXiv preprint arXiv: 1502.01852; Gulcehre, C., Moczulski, M., Denil, M., Bengio, Y., (2016) Noisy Activation Functions, , arXiv preprint arXiv: 1603.00391; Yann, L., LeNet-5, Convolutional Neural Networks; Alex, K., (2009) Learning Multiple Layers of Features from Tiny Images",,,,"Institute of Electrical and Electronics Engineers Inc.","6th International Symposium on Computing and Networking Workshops, CANDARW 2018","27 November 2018 through 30 November 2018",,144070,,9781538691847,,,"English","Proc. - Int. Symp. Comput. Netw. Workshops, CANDARW",Conference Paper,"Final","",Scopus,2-s2.0-85061449814
"Li Y., Wang Y.","56436141600;57204557051;","Defense against adversarial attacks in deep learning",2018,"Applied Sciences (Switzerland)","9","1","76","","",,6,"10.3390/app9010076","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059125448&doi=10.3390%2fapp9010076&partnerID=40&md5=9c2ea9ba765515b77af6d9ae5ed342e4","School of Control and Computer Engineering, North China Electric Power University, Beijing, 102206, China","Li, Y., School of Control and Computer Engineering, North China Electric Power University, Beijing, 102206, China; Wang, Y., School of Control and Computer Engineering, North China Electric Power University, Beijing, 102206, China","Neural networks are very vulnerable to adversarial examples, which threaten their application in security systems, such as face recognition, and autopilot. In response to this problem, we propose a new defensive strategy. In our strategy, we propose a new deep denoising neural network, which is called UDDN, to remove the noise on adversarial samples. The standard denoiser suffers from the amplification effect, in which the small residual adversarial noise gradually increases and leads to misclassification. The proposed denoiser overcomes this problem by using a special loss function, which is defined as the difference between the model outputs activated by the original image and denoised image. At the same time, we propose a new model training algorithm based on knowledge transfer, which can resist slight image disturbance and make the model generalize better around the training samples. Our proposed defensive strategy is robust against both white-box or black-box attacks. Meanwhile, the strategy is applicable to any deep neural network-based model. In the experiment, we apply the defensive strategy to a face recognition model. The experimental results show that our algorithm can effectively resist adversarial attacks and improve the accuracy of the model. © 2018 by the authors.","Adversarial attacks; Deep learning; Denoiser; Face recognition;Wasserstein generative adversarial networks (W-GAN); Knowledge transfer",,,,,,"Helmstaedter, M., Briggman, K.L., Turaga, S.C., Jain, V., Seung, H.S., Denk, W., Connectomic reconstruction of the inner plexiform layer in the mouse retina (2013) Nature, 500, pp. 168-174; Xiong, H.Y., Alipanahi, B., Lee, J.L., Bretschneider, H., Merico, D., Yuen, R.K., Morris, Q., The human splicing code reveals new insights into the genetic determinants of disease (2015) Science, 347; Ciodaro, T., Deva, D., de Seixas, J., Damazio, D., Online Particle Detection with Neural Networks Based on Topological Calorimetry Information (2012) Journal of physics: conference series, 368. , IOP Publishing: Bristol, UK; Ackerman, E., How Drive.ai Is Mastering Autonomous Driving with Deep Learning, , https://spectrum.ieee.org/cars-that-think/transportation/self-driving/how-driveai-is-masteringautonomous-driving-with-deep-learning, (accessed on 10 March 2017); Najafabadi, M.M., Villanustre, F., Khoshgoftaar, T.M., Seliya, N., Wald, R., Muharemagic, E., Deep learning applications and challenges in big data analytics (2015) J. Big Data, 2, p. 1; Middlehurst, C., (2015) China Unveils World's First Facial Recognition ATM, , http://www.telegraph.co.uk/news/worldnews/asia/china/11643314/China-unveils-worlds-firstfacial-recognition-ATM.html, accessed on 1 June 2017; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2014) Intriguing properties of neural networks, , arXiv; Goodfellow, I.J., Shlens, J., Szegedy, C., (2015) Explaining and Harnessing Adversarial Examples, , arXiv; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Proceedings of the IEEE European Symposium on Security and Privacy, , Saarbrucken, Germany, 21-24 March; Moosavi-Dezfooli, S.M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , Honolulu, HI, USA, 21-26 July; Siniscalchi, S.M., Salerno, V.M., Adaptation to new microphones using artificial neural networks with trainable activation functions (2017) IEEE Trans. Neural Netw. Learn. Syst, 28, pp. 1959-1965; Salerno, V.M., Rabbeni, G., An extreme learning machine approach to effective energy disaggregation (2018) Electronics, 7, p. 235; Dziugaite, G.K., Ghahramani, Z., Roy, D.M., (2016) A study of the effect of JPG compression on adversarial images, , arXiv; Luo, Y., Boix, X., Roig, G., Poggio, T., Zhao, Q., (2015) Foveation-based mechanisms alleviate adversarial examples, , arXiv; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., Adversarial Examples for Semantic Segmentation and Object Detection (2017), arXiv; Ross, A.S., Doshi-Velez, F., Improving the Adversarial Robustness and Interpretability of Deep Neural Networks by Regularizing their Input Gradients (2017), arXiv; Zhang, A., Wang, H., Li, S., Cui, Y., Liu, Z., Yang, G., Hu, J., Transfer Learning with Deep Recurrent Neural Networks for Remaining Useful Life Estimation (2018) Appl. Sci, 8, p. 2416; Nayebi, A., Ganguli, S., (2017) Biologically inspired protection of deep networks from adversarial attacks, , arXiv; Krotov, D., Hopfield, J.J., (2017) Dense Associative Memory is Robust to Adversarial Inputs, , arXiv; Cisse, M., Adi, Y., Neverova, N., Keshet, J., (2017) Houdini: Fooling deep structured prediction models, , arXiv; Gao, J., Wang, B., Lin, Z., Xu, W., Qi, Y., (2017) DeepCloak: Masking Deep Neural Network Models for Robustness Against Adversarial Samples, , arXiv; Akhtar, N., Liu, J., Mian, A., (2017) Defense against Universal Adversarial Perturbations, , arXiv; Lu, J., Issaranon, T., Forsyth, D., SafetyNet: Detecting and Rejecting Adversarial Examples Robustly (2017), arXiv; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., (2017) On Detecting Adversarial Perturbations, , arXiv; Li, X., Li, F., Adversarial Examples Detection in Deep Networks with Convolutional Filter Statistics (2017) Proceedings of the International Conference on Computer Vision, , Venice, Italy, 22-29 October; Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., (2017) On the (Statistical) Detection of Adversarial Examples, , arXiv; Liao, F., Liang, M., Dong, Y., Pang, T., Zhu, J., Hu, X., (2017) Defense against Adversarial Attacks Using High-Level Representation Guided Denoiser, , arXiv; Gu, S., Rigazio, L., (2015) Towards Deep Neural Network Architectures Robust to Adversarial Examples, , arXiv; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a Defense to Adversarial Perturbations against Deep Neural Networks (2016) Proceedings of the IEEE Symposium on Security and Privacy (SP), pp. 582-597. , San Jose, CA, USA, 22-26 May","Wang, Y.; School of Control and Computer Engineering, China; email: 1162227078@ncepu.edu.cn",,,"MDPI AG",,,,,20763417,,,,"English","Appl. Sci.",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85059125448
"Tesfay T., Jamei M., Scaglione A., Khorsand M., Hedman K., Bazzi R.","54581796500;56455131100;7005577332;36069229500;24536873200;6603908945;","AVAIL: Assured Volt-Ampère Information Ledger",2018,"2018 IEEE International Conference on Communications, Control, and Computing Technologies for Smart Grids, SmartGridComm 2018",,,"8587601","","",,1,"10.1109/SmartGridComm.2018.8587601","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061033406&doi=10.1109%2fSmartGridComm.2018.8587601&partnerID=40&md5=dafdf3ac1bfdb67d7a27a80d45353f03","Arizona State University, Tempe, AZ, United States","Tesfay, T., Arizona State University, Tempe, AZ, United States; Jamei, M., Arizona State University, Tempe, AZ, United States; Scaglione, A., Arizona State University, Tempe, AZ, United States; Khorsand, M., Arizona State University, Tempe, AZ, United States; Hedman, K., Arizona State University, Tempe, AZ, United States; Bazzi, R., Arizona State University, Tempe, AZ, United States","To address the need for trusted information across bulk power systems, our paper proposes a new type of distributed ledger (or Blockchain), for a shared management of sensitive information in power systems. We call our Blockchain design the Assured Volt Ampere Information Ledger (AVAIL). The AVAIL' abstractions fit data needs of prototypical grid applications in wide area protection and control, energy management systems, and markets. The contribution of this paper is to draw directly from the distinct requirements of these applications and the valid assumptions about the adversaries, to shape the AVAIL abstractions. AVAIL is unique for the following features: 1) Adversarial model: Our design principles consider an adversarial model where attacks affect physical resources; 2) Non-binary validity: In our setting we allow for a spectrum of validity; 3) Validity enforcement: Validity in our setting is governed by physical laws. © 2018 IEEE.",,"Abstracting; Blockchain; Electric power systems; Electric power transmission networks; Energy management systems; Smart power grids; Bulk power systems; Design Principles; Grid applications; Physical resources; Sensitive informations; Shared management; Valid assumption; Wide area protection and control; Information management",,,,,"North American Electric Reliability Corporation, , C. I. P. NERC-CIP; Goranovíc, A., Meisel, M., Fotiadis, L., Wilker, S., Treytl, A., Sauter, T., Blockchain applications in microgrids an overview of current projects and concepts (2017) Industrial Electronics Society, IECON 2017-43rd Annual Conference of the IEEE. IEEE, pp. 6153-6158; Horta, J., (2017) Novel Paradigms for Advanced Distribution Grid Energy Management; Münsing, E., Mather, J., Moura, S., Blockchains for decentralized optimization of energy resources in microgrid networks (2017) IEEE CCTA 2017. IEEE, pp. 2164-2171; Zizzo, G., Sanseverino, E.R., Ippolito, M.G., Di Silvestre, M.L., Gallo, P., A technical approach to p2p energy transactions in microgrids (2018) IEEE Transactions on Industrial Informatics; Power Ledger (Powr), , https://powerledger.io/,Tech.Rep; Montemayor, L., Boersma, T., (2018) Comprehensive Guide to Companies Involved in Blockchain and Energy, , Solarplaza, Tech. Rep; Yang, T., Guo, Q., Tai, X., Sun, H., Zhang, B., Zhao, W., Lin, C., Applying blockchain technology to decentralized operation in future energy internet (2017) Energy Internet and Energy System Integration (EI2), 2017 IEEE Conference On. IEEE, pp. 1-5; Merz, M., Gridchain-blockchain-based process integration for the smart grids of the future (2017) Enerchain; Liang, G., Weller, S.R., Luo, F., Zhao, J., Dong, Z.Y., Distributed blockchain-based data protection framework for modern power systems against cyber attacks (2018) IEEE Transactions on Smart Grid; Nakamoto, S., (2008) Bitcoin: A Peer-to-peer Electronic Cash System; Androulaki, E., Barger, A., Bortnikov, V., Cachin, C., Christidis, K., De Caro, A., Enyeart, D., Manevich, Y., (2018) Hyperledger Fabric: A Distributed Operating System for Permissioned Blockchains; Buterin, V., (2014) A Next-generation Smart Contract and Decentralized Application Platform, , white paper; Dwork, C., Naor, M., Pricing via processing or combating junk mail (1992) Annual International Cryptology Conference, , Springer; Garay, J., Kiayias, A., Leonardos, N., The bitcoin backbone protocol: Analysis and applications (2015) Annual International Conference on the Theory and Applications of Cryptographic Techniques, , Springer; Lamport, L., Shostak, R., Pease, M., The byzantine generals problem (1982) ACM Transactions on Programming Languages and Systems (TOPLAS), 4 (3), pp. 382-401; Hou, D., Dolezilek, D., (2008) Iec 61850-what It Can and Cannot Offer to Traditional Protection Schemes, , Schweitzer Engineering Laboratories, Inc 20080912; Thorp, J., Phadke, A., Horowitz, S., Tamronglak, S., Anatomy of power system disturbances: Importance sampling (1998) International Journal of Electrical Power & Energy Systems, 20 (2), pp. 147-152; Tesfay, T.T., Hubaux, J.-P., Le Boudec, J.-Y., Oechslin, P., Cybersecure communication architecture for active power distribution networks (2014) Proceedings of the 29th Annual ACM Symposium on Applied Computing. ACM, pp. 545-552; He, H., Yan, J., Cyber-physical attacks and defences in the smart grid: A survey (2016) IET Cyber-Physical Systems: Theory & Applications, 1 (1), pp. 13-27; Liu, Y., Ning, P., Reiter, M.K., False data injection attacks against state estimation in electric power grids (2011) ACM Transactions on Information and System Security (TISSEC), 14 (1), p. 13; Jamei, M., Scaglione, A., Roberts, C., Stewart, E., Peisert, S., McParland, C., McEachern, A., Anomaly detection using optimally-placed -PMU sensors in distribution grids (2017) IEEE Trans. on Power Systems; Kelly, E.J., An adaptive detection algorithm (1986) IEEE Transactions on Aerospace and Electronic Systems, (2), pp. 115-127; Poon, J., Buterin, V., Plasma: Scalable autonomous smart contracts (2017) White Paper; Version 14. 0 (2009) DIgSILENT GmbH, , D. P. F. Manual and D. PowerFactory, Gomaringen, Germany",,,,"Institute of Electrical and Electronics Engineers Inc.","2018 IEEE International Conference on Communications, Control, and Computing Technologies for Smart Grids, SmartGridComm 2018","29 October 2018 through 31 October 2018",,143892,,9781538679548,,,"English","IEEE Int. Conf. Commun., Control, Comput. Technol. Smart Grids, SmartGridComm",Conference Paper,"Final","",Scopus,2-s2.0-85061033406
"Yue L.I., Pengjian X.U., Pang M.","57225460095;56498337700;57206731041;","Adversarial attacks on word2vec and neural network",2018,"ACM International Conference Proceeding Series",,,,"","",,1,"10.1145/3302425.3302472","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061911667&doi=10.1145%2f3302425.3302472&partnerID=40&md5=b46e36c0a25b2b5b74322958ba6a27c2","College of Computer Science and Technolog, Donghua Universit, Shanghai, China","Yue, L.I., College of Computer Science and Technolog, Donghua Universit, Shanghai, China; Pengjian, X.U., College of Computer Science and Technolog, Donghua Universit, Shanghai, China; Pang, M., College of Computer Science and Technolog, Donghua Universit, Shanghai, China","The security of machine learning is of great importance. Image vulnerability has been known in the literature for a long time. This paper is concerned with the text vulnerability. The word2vec is widely used to produce the word embedding, which plays an important role in natural language processing. The quality of word embedding affects the performance of the neural network. Using word embedding is to find the useful information that may exist between the individual words. This paper proposes a method to alter the original text, whose word embeddings also change. And the adversarial samples are able to make the classifier make a mistake. © 2018 Association for Computing Machinery.","Adversarial sample; Neural network; Text classification; Vulnerability; Word2vec","Artificial intelligence; Classification (of information); Embeddings; Learning algorithms; Learning systems; Natural language processing systems; Neural networks; Text processing; NAtural language processing; Text classification; Vulnerability; Word2vec; Network security",,,,,"Nie, S., Lin, L., Du, Y., Free-Fall: Hacking Tesla from Wireless to Can Bus[C], , BlackHat, Las Vegas, c2017; Silver, D., Mastering the game of Go with deep neural networks and tree search[J] (2016) Nature, 529 (7587), p. 484; Tomas, M., Efficient estimation of word representations in vector space[J] (2013) CoRR, , abs/1301.3781; Biggio, B., Nelson, B., Laskov, P., Poisoning attacks against support vector machines[C] The 29th International Coference on International Conference on Machine Learning, pp. 1467-1474. , Edinburgh Scotland, c2012; Papernot, N., The limitations of deep learning in adversarial settings[C] IEEE European Symposium on Security and Privacy, the Congress Center Saar, , Saarbrücken Germany, c2016; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks[J] (2017) Commun. ACM, 60 (6), pp. 84-90; Szegedy, C., Intriguing properties of neural networks[J] (2013) CoRR, , abs/1312.6199; Behzadan, V., Munir, A., Vulnerability of Deep Reinforcement Learning to Policy Induction Attacks[C], , MLDM, Cham, c2017; Huang, S.P., Goodfellow, I., Duan, Y., Abbeel, P., Adversarial attacks on neural network policies[J] (2017) CoRR, , Nicolas; Kurakin, A., Goodfellow, I.J., Bengio, S., (2016) Adversarial Examples in the Physical World[J], , e-prints, abs/1607.02533; Papernot, N., Practical black-box attacks against machine learning[C] The 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519. , Abu Dhabi United Arab Emirates, c2017; Liang, B., Deep Text Classification Can Be Fooled[C], pp. 4208-4215. , IJCAI, Stockholm Sweden, c2018; Samanta, S., Mehta, S., Towards. Crafting text adversarial samples[J] (2017) CoRR, , abs/1707.02812; Le, Q., Mikolov, T., Distributed representations of sentences and documents[C] The 31st International Conference on International Conference on Machine Learning, , Beijing, China. c2014; Maas, A.L., Learning word vectors for sentiment analysis[C] The 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, Portland Oregon USA, 1, pp. 142-150. , C2011:",,,"City University of Hong Kong;The Hong Kong Polytechnic University","Association for Computing Machinery","2018 International Conference on Algorithms, Computing and Artificial Intelligence, ACAI 2018","21 December 2018 through 23 December 2018",,144893,,9781450366250,,,"English","ACM Int. Conf. Proc. Ser.",Conference Paper,"Final","",Scopus,2-s2.0-85061911667
"Dieter K., McCamish B., Cotilla-Sanchez E., Bass R.B., Wallace S., Zhao X.","57192105150;56344824400;36642360600;57191852951;57203270397;56586980900;","Power System Spoof Detection with a Hybrid Hardware/Software Benchmarking Framework",2018,"IEEE Power and Energy Society General Meeting","2018-August",,"8585743","","",,1,"10.1109/PESGM.2018.8585743","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060815325&doi=10.1109%2fPESGM.2018.8585743&partnerID=40&md5=1bbf29f3c7c9fa60eec008b9ce9da7c5","Oregon State University, Corvallis, OR, United States; Portland State University, Portland, OR, United States; Washington State University, Vancouver, WA, United States","Dieter, K., Oregon State University, Corvallis, OR, United States; McCamish, B., Oregon State University, Corvallis, OR, United States; Cotilla-Sanchez, E., Oregon State University, Corvallis, OR, United States; Bass, R.B., Portland State University, Portland, OR, United States; Wallace, S., Washington State University, Vancouver, WA, United States; Zhao, X., Washington State University, Vancouver, WA, United States","The integration of monitoring and control networks at different voltage levels and across utility boundaries has made it harder to maintain and asses the resilience of power systems due to increasing cyber attacks. On the software side, a variety of research efforts pursue cyber protection algorithms, such as spoof detection techniques. On the hardware and firmware side, research has demonstrated the feasibility of adversarial attacks by providing an entry point at the device level. This work proposes and evaluates two detection performance metrics for a variety of cyber spoofing attacks introduced in a realistic Phasor Measurement Unit (PMU) network for a hybrid transmission and distribution power system. This research finds that both proposed metrics show promise in aiding a spoof detection algorithm in consistently detecting spoofs in power system measurements. © 2018 IEEE.",,"Computer crime; Electric power transmission; Firmware; Network security; Detection performance; Different voltages; Hardware/software; Hybrid transmissions; Monitoring and control; Protection algorithms; Research efforts; Spoofing attacks; Phasor measurement units",,,,,"Advanced Metering Infrastructure Installations in the U. S. A, , U. S. Energy Information Administration, Tech. Rep; Number of Smart Meter Installations, Worldwide, , Navigant Research, Tech. Rep; Geib, A., How privacy-conscious consumers are fooling, hacking smart meters (2012) Natural News, , July; McDaniel, P., McLaughlin, S., Security and privacy challenges in the smart grid (2009) IEEE Security Privacy, 7 (3), pp. 75-77. , May; Shakshuki, E., Shuaib, K., Trabelsi, Z., Abed-Hafez, M., Gaouda, A., Alahmad, M., Resiliency of smart power meters to common security attacks (2015) Procedia Computer Science, 52, pp. 145-152; (2011) Smart Meters and Smart Meter Systems: A Metering Industry Perspective, , Edison Electric Institute and Association of Edison Illuminating Companies, Tech. Rep; Natarayan, A., (2012) The Emerging Smart Grid: Opportunities for Increased System Reliability and Potential Security Risks, , Ph. D. dissertation, Carnegie Mellon University; Lassetter, C., Cotilla-Sanchez, E., Kim, J., Load oscillating smart meter attack (2016) Signal and Information Processing (GlobalSIP), 2016 IEEE Global Conference On. IEEE, pp. 821-825; Higgin, K., Smart meter hack shuts off the lights (2014) InformationWeek, , October; Landford, J., Meier, R., Barella, R., Zhao, X., Cotilla-Sanchez, E., Bass, R., Wallace, S., Fast sequence component analysis for attack detection in synchrophasor networks (2017) Sustainable Energy, Grids and Networks; Venkatasubramanian, V., Real-time strategies for unwrapping of synchrophasor phase angles (2016) IEEE Transactions on Power Systems, 31 (6), pp. 5033-5041. , Nov; Liu, S., Mashayekh, S., Kundur, D., Zourntos, T., Butler-Purry, K.L., A smart grid vulnerability analysis framework for coordinated variable structure switching attacks (2012) Power and Energy Society General Meeting, 2012 IEEE. IEEE, pp. 1-6",,,,"IEEE Computer Society","2018 IEEE Power and Energy Society General Meeting, PESGM 2018","5 August 2018 through 10 August 2018",,143833,19449925,9781538677032,,,"English","IEEE Power Energy Soc. Gen. Meet.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85060815325
"Akhtar Z., Monteiro J., Falk T.H.","46661628200;57203234004;7004897891;","Adversarial Examples Detection Using No-Reference Image Quality Features",2018,"Proceedings - International Carnahan Conference on Security Technology","2018-October",,"8585591","","",,5,"10.1109/CCST.2018.8585591","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060673515&doi=10.1109%2fCCST.2018.8585591&partnerID=40&md5=c347b1e467d60f4ad3257a92a313faf5","INRS-EMT, University of Quebec, Montreal, Canada","Akhtar, Z., INRS-EMT, University of Quebec, Montreal, Canada; Monteiro, J., INRS-EMT, University of Quebec, Montreal, Canada; Falk, T.H., INRS-EMT, University of Quebec, Montreal, Canada","Recently, it has been discovered that Deep Neural Networks (DNNs) are highly vulnerable to deliberate perturbations, which, when added to the input sample, can mislead the DNNs based systems. The corresponding samples with deliberate perturbations are called adversarial examples (AEs). The challenge of AEs is very critical in security and safety systems, which if fooled or misled can yield serious consequences. Therefore, it is essential to devise methods to enhance the robustness of DNNs against adversarial attacks. Quintessential mechanism is adversarial examples detection. An adversarial attack detection method aims at disambiguating clean samples from AEs. More recently, few techniques have been proposed in the literature, nonetheless majority of them are very complex or not able to attain low enough error rates. In this paper, we present a novel technique to improve the security of DNNs by detecting different types of AEs. The proposed framework presents a very low degree of complexity and utilizes ten nonintrusive image quality features to distinguish between legitimate and adversarial attack samples. Experimental analysis on the standard MNIST and CIFAR10 datasets shows promising results not only for different adversarial examples generation methods but also various additive perturbations. © 2018 IEEE.","Adversarial Attacks; Adversarial Examples; Deep Learning; Deep Neural Networks; Pattern Classification","Complex networks; Deep learning; Image quality; Pattern recognition; Security systems; Adversarial Attacks; Adversarial Examples; Attack detection; Experimental analysis; Generation method; No-reference images; Novel techniques; Quality features; Deep neural networks",,,,,"Goodfellow, I., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint, arXiv 1412.6572; Papernot, N., Distillation as a defense to adversarial perturbations against deep neural networks (2016) IEEE S&P, pp. 582-597; Samangouei, P., (2018) Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models, , arXiv 1805, 06605; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts, pp. 1-9. , arXiv 1703.00410; Xu, W., Evans, D., Qi, Y., (2017) Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks, pp. 1-15. , arXiv 1704.01155; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., (2017) On Detecting Adversarial Perturbations, pp. 1-12. , arXiv 1702.04267; Grosse, K., (2017) On the (Statistical) Detection of Adversarial Examples, pp. 1-13. , preprint arXiv 1702.06280; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, pp. 1-14. , arXiv 1607.02533; Moosavi-Dezfooli, S.M., Deepfool: A simple and accurate method to fool deep neural networks (2016) IEEE CVPR, pp. 2574-2582; Mittal, A., Blind/referenceless image spatial quality evaluator (2011) Asilomar Conf. on Signals, Systems and Computers, pp. 723-727; Fang, Y., No-reference quality assessment of contrast-distorted images based on natural scene statistics (2015) SPL, 22 (7), pp. 838-842; Blanchet, G., Moisan, L., An explicit sharpness index related to global phase coherence (2012) IEEE ICASSP, pp. 1065-1068; Blanchet, G., Moisan, L., No-reference image quality assessment and blind deblurring with sharpness metrics exploiting Fourier phase information (2015) Journal of Math. Imag. and Vision, 52 (1), pp. 145-172; Saad, M.A., Bovik, A.C., Blind image quality assessment: A natural scene statistics approach in the dct domain (2012) IEEE Transactions on Image Processing, 21 (8), pp. 3339-3352; Moorthy, A.K., Bovik, A.C., Blind image quality assessment: From natural scene statistics to perceptual quality (2011) IEEE TIP; Liu, L., Hua, Y., Zhao, Q., Huang, H., Bovik, A.C., Blind image quality assessment by relative gradient statistics and adaboosting neural network (2016) Signal Proc.: Image Communication, 40, pp. 1-15; Xue, W., Zhang, L., Mou, X., Learning without human scores for blind image quality assessment (2013) IEEE CVPR, pp. 995-1002; Liu, H.L., No-reference image quality assessment in curvelet domain (2014) Signal Processing: Image Comm, 29 (4), pp. 494-505; Sheikh, H.R., No-reference quality assessment using natural scene statistics: Jpeg2000 (2005) IEEE TIP 1918-1927, 14 (11); Rauber, J., (2017) Foolbox v0.8.0: A Python Toolbox to Benchmark the Robustness of Machine Learning Models, , arXiv 1707.04131; Simonyan, K., Zisserman, A., (2015) Very Deep Convolutional Networks for Large-Scale Image Recognition, pp. 1-14. , arXiv 1409.1556; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) IEEE CPPR, pp. 770-778; Bagnall, A., Bunescu, R., Stewart, G., (2017) Training Ensembles to Detect Adversarial Examples, pp. 1-5. , arXiv 1712.04006; Monteiro, J., Akhtar, Z., Falk, T.H., (2018) Generalizable Adversarial Examples Detection Using Decisions Mismatch, , arXiv preprint",,"Rich B.G.","AESS;Genetec;IEEE;SENSTAR","Institute of Electrical and Electronics Engineers Inc.","52nd Annual IEEE International Carnahan Conference on Security Technology, ICCST 2018","22 October 2018 through 25 October 2018",,143840,10716572,9781538679319,,,"English","Proc. Int. Carnahan Conf. Secur. Technol.",Conference Paper,"Final","",Scopus,2-s2.0-85060673515
"Bhattacharjee A., Banerjee S., Das S.","57209588102;55702079100;55476994500;","SpoofNET: Resolving Facial Makeup based Spoofs",2018,"ACM International Conference Proceeding Series",,,"3293377","","",,,"10.1145/3293353.3293377","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098199271&doi=10.1145%2f3293353.3293377&partnerID=40&md5=04bb08464992af5284eac0b5169addb5","Indian Institute of Technology Madras, Chennai, Tamil Nadu, India","Bhattacharjee, A., Indian Institute of Technology Madras, Chennai, Tamil Nadu, India; Banerjee, S., Indian Institute of Technology Madras, Chennai, Tamil Nadu, India; Das, S., Indian Institute of Technology Madras, Chennai, Tamil Nadu, India","Face Recognition (FR) under adversarial conditions has been a big challenge for researchers in the Computer Vision and Machine Learning communities in the recent past. Most of state-of-the-art face recognition systems have been designed to overcome degradations in a face due to variations in pose, illumination, contrast, resolution, along with blur. However, interestingly none have addressed the fascinating issue of makeup as a spoof attack, which drastically changes the appearance of a face, making it difficult for even humans to detect and identify the impostor. In this paper, we propose a novel multi-component deep convolutional neural network (CNN) based architecture which performs the complex task of makeup removal from a disguised face, to reveal the original mugshot image of the impostor (i.e. without makeup). The proposed network also performs the hard tasks of FR on a disguised face in addition to recognition of identity and generation of the face of the spoofed target, by minimizing a novel multi-component objective function. Comparison of performance with a few recent state-of-the-art methods of FR over three benchmark datasets reveals the superiority of our proposed method for both synthesis as well as recognition (FR) tasks. © 2018 ACM.",,"Benchmarking; Computer vision; Convolutional neural networks; Deep neural networks; Benchmark datasets; Comparison of performance; Complex task; Face recognition systems; Machine learning communities; Multicomponents; Objective functions; State of the art; Face recognition",,,,,"Ahonen, T., Hadid, A., Pietikainen, M., Face description with local binary patterns: Application to face recognition (2006) IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI), 28 (12), pp. 2037-2041. , 2006; Asthana, A., Zafeiriou, S., Cheng, S., Pantic, M., Incremental face alignment in the wild (2014) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1859-1866; Baktashmotlagh, M., Harandi, M.T., Lovell, B.C., Salzmann, M., Domain adaptation on the statistical manifold (2014) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2481-2488; Banerjee, S., Das, S., Soft-margin learning for multiple feature-kernel combinations with domain adaptation, for recognition in surveillance face dataset (2016) IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW) on Biometrics, pp. 169-174; Banerjee, S., Das, S., MakeUpMirror: Mirroring make-ups and verifying faces post make-up (2018) IET Biometrics, , 2018; Banerjee, S., Das, S., Mutual variation of information on transfer-cnn for face recognition with degraded probe samples (2018) Neurocomputing, 310, pp. 299-315. , 2018; Banerjee, S., Samanta, S., Das, S., Face recognition in surveillance conditions with bag-of-words, using unsupervised domain adaptation (2014) Indian Conference on Computer Vision Graphics and Image Processing (ICVGIP), p. 50; Bovik, A.C., (2009) The Essential Guide to Video Processing, , Academic Press; Chen, C., Dantcheva, A., Ross, A., Automatic facial makeup detection with application in face recognition (2013) International Conference on Biometrics (ICB), pp. 1-8; Chen, C., Dantcheva, A., Swearingen, T., Ross, A., Spoofing faces using makeup: An investigative study (2017) IEEE International Conference on Identity, Security and Behavior Analysis (ISBA), pp. 1-8; Chen, J.C., Zheng, J., Patel, V.M., Chellappa, R., Fisher vector encoded deep convolutional features for unconstrained face verification (2016) IEEE International Conference on Image Processing (ICIP), pp. 2981-2985; Dantcheva, A., Chen, C., Ross, A., Can facial cosmetics affect the matching accuracy of face recognition systems? (2012) IEEE International Conference on Biometrics: Theory, Applications and Systems (BTAS), pp. 391-398; De Marsico, M., Nappi, M., Riccio, D., Wechsler, H., Robust face recognition after plastic surgery using region-based approaches (2015) Pattern Recognition, 48 (4), pp. 1261-1276. , 2015; Donahue, J., Jia, Y., Vinyals, O., Hoffman, J., Zhang, N., Tzeng, E., Darrell, T., DeCAF: A deep convolutional activation feature for generic visual recognition (2014) International Conference on Machine Learning (ICML), pp. 647-655; Duan, L., Xu, D., Tsang, I., Learning with augmented features for heterogeneous domain adaptation (2012) International Conference on Machine Learning (ICML), pp. 711-718; Ghifary, M., Kleijn, W., Zhang, M., Balduzzi, D., Li, A., Deep reconstruction-classification networks for unsupervised domain adaptation (2016) European Conference on Computer Vision (ECCV), pp. 597-613. , Springer; Gong, B., Grauman, K., Sha, F., Connecting the dots with landmarks: Discriminatively learning domain-invariant features for unsupervised domain adaptation (2013) International Conference on Machine Learning (ICML), pp. 222-230; Gopalan, R., Li, R., Chellappa, R., Domain adaptation for object recognition: An unsupervised approach (2011) Proceedings of the IEEE International Conference on Computer Vision (ICCV), pp. 999-1006; Guo, G., Wen, L., Yan, S., Face authentication with makeup changes (2014) IEEE Transactions on Circuits and Systems for Video Technology, 24 (5), pp. 814-825. , 2014; Hoffman, J., Guadarrama, S., Tzeng, E.S., Hu, R., Donahue, J., Girshick, R., Darrell, T., Saenko, K., LSDA: Large scale detection through adaptation (2014) Advances in Neural Information Processing Systems (NIPS), pp. 3536-3544; Hou, X., Li, Y., Li, T., Weakly-supervised dual generative adversarial networks for makeup-removal (2017) International Conference on Neural Information Processing (ICONIP), pp. 603-611; Hu, J., Ge, Y., Lu, J., Feng, X., Makeup-robust face verification (2013) IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 2342-2346; Huang, G.B., Ramesh, M., Berg, T., Learned-Miller, E., Labeled faces in the wild: A database for studying face recognition in unconstrained environments (2007) Technical Report No. 07-49, , University of Massachusetts, Amherst; Jain, A.K., Ross, A.A., Nandakumar, K., Introduction (2011) Introduction to Biometrics, pp. 1-49. , Springer; Kingma, D.P., Ba, J., (2014) Adam: A Method for Stochastic Optimization, , 2014; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems (NIPS), pp. 1097-1105; Li, M., Li, Y., He, Y., (2018) Makeup Removal System with Deep Learning, , Technical Report, CS230 Deep Learning, Stanford University; Li, Y., Song, L., Wu, X., He, R., Tan, T., (2017) Anti-Makeup: Learning A Bi-level Adversarial Network for Makeup-invariant Face Verification, , 2017; Jialin Pan, S., Tsang, I.W., Kwok, J.T., Yang, Q., Domain adaptation via transfer component analysis (2011) IEEE Transactions on Neural Networks (NN), 22 (2), pp. 199-210. , 2011; Jialin Pan, S., Yang, Q., A survey on transfer learning (2010) IEEE Transactions on Knowledge and Data Engineering (KDE), 22 (10), pp. 1345-1359. , 2010; Parkhi, O.M., Vedaldi, A., Zisserman, A., Deep face recognition (2015) British Machine Vision Conference (BMVC), 1, p. 6; Patel, V.M., Gopalan, R., Li, R., Chellappa, R., Visual domain adaptation: A survey of recent advances (2015) IEEE Signal Processing Magazine, 32 (3), pp. 53-69. , 2015; Jonathon Phillips, P., Flynn, P.J., Scruggs, T., Bowyer, K.W., Chang, J., Hoffman, K., Marques, J., Worek, W., Overview of the face recognition grand challenge (2005) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 1, pp. 947-954; Jonathon Phillips, P., Wechsler, H., Huang, J., Rauss, P.J., The feret database and evaluation procedure for face-recognition algorithms (1998) Image and Vision Computing (IVC), 16 (5), pp. 295-306. , 1998; Schroff, F., Kalenichenko, D., Philbin, J., Facenet: A unified embedding for face recognition and clustering (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 815-823; Shore, J., Johnson, R., Axiomatic derivation of the principle of maximum entropy and the principle of minimum cross-entropy (1980) IEEE Transactions on Information Theory, 26 (1), pp. 26-37. , 1980; Sim, T., Baker, S., Bsat, M., The cmu pose, illumination, and expression (pie) database (2002) Proceedings of the IEEE International Conference on Automatic Face and Gesture Recognition (FG), pp. 53-58; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition, , 2014; Sun, Y., Liang, D., Wang, X., Tang, X., (2015) Deepid3: Face Recognition with Very Deep Neural Networks, , 2015; Sun, Y., Wang, X., Tang, X., Deep learning face representation from predicting 10, 000 classes (2014) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1891-1898; Taigman, Y., Yang, M., Ranzato, M., Wolf, L., Deepface: Closing the gap to human-level performance in face verification (2014) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1701-1708; Wang, S., Zhang, L., Liang, Y., Pan, Q., Semi-coupled dictionary learning with applications to image super-resolution and photo-sketch synthesis (2012) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2216-2223; Wang, X., Schneider, J., Flexible transfer learning under support and model shift (2014) Advances in Neural Information Processing Systems (NIPS), pp. 1898-1906; Wolf, L., Hassner, T., Maoz, I., Face recognition in unconstrained videos with matched background similarity (2011) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 529-534; Wright, J., Yang, A.Y., Ganesh, A., Shankar Sastry, S., Ma, Y., Robust face recognition via sparse representation (2009) IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI), 31 (2), pp. 210-227. , 2009; Yi, D., Liu, R., Chu, R., Lei, Z., Li, S.Z., Face matching between near infrared and visible light images (2007) International Conference on Biometrics (ICB), pp. 523-530. , Springer; Zhang, K., Scholkopf, B., Muandet, K., Wang, Z., Domain adaptation under target and conditional shift (2013) International Conference on Machine Learning (ICML), pp. 819-827; Zhao, W., Chellappa, R., (2011) Face Processing: Advanced Modeling and Methods, , Academic Press; Zhao, W., Chellappa, R., Jonathon Phillips, P., Rosenfeld, A., Face recognition: A literature survey (2003) ACM Computing Surveys (CSUR), 35 (4), pp. 399-458. , 2003; Zhu, Z., Luo, P., Wang, X., Tang, X., (2014) Recover Canonical-view Faces in the Wild with Deep Neural Networks, , 2014",,,"Bosch;et al.;Intel;KLA-Tencor;Mathworks;Microsoft","Association for Computing Machinery","11th Indian Conference on Computer Vision, Graphics and Image Processing, ICVGIP 2018","18 December 2018 through 22 December 2018",,165785,,9781450366151,,,"English","ACM Int. Conf. Proc. Ser.",Conference Paper,"Final","",Scopus,2-s2.0-85098199271
"Subramanya A., Mopuri K.R., Babu R.V.","57195937080;57024033600;57202410887;","BatchOut: Batch-level feature augmentation to improve robustness to adversarial examples",2018,"ACM International Conference Proceeding Series",,,"3293387","","",,,"10.1145/3293353.3293387","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098116407&doi=10.1145%2f3293353.3293387&partnerID=40&md5=e424ee5d69a957df02381fa7907de2b4","Video Analytics Lab, Indian Institute of Science, Bangalore, India","Subramanya, A., Video Analytics Lab, Indian Institute of Science, Bangalore, India; Mopuri, K.R., Video Analytics Lab, Indian Institute of Science, Bangalore, India; Babu, R.V., Video Analytics Lab, Indian Institute of Science, Bangalore, India","Machine Learning models are known to be susceptible to small but structured changes to their inputs that can result in wrong inferences. It has been shown that such samples, called adversarial samples, can be created rather easily for standard neural network architectures. These adversarial samples pose a serious threat for deploying state-of-the-art deep neural network models in the real world. We propose a feature augmentation technique called BatchOut to learn robust models towards such examples. The proposed approach is a generic feature augmentation technique that is not specific to any adversary and handles multiple attacks. We evaluate our algorithm on benchmark datasets and architectures to show that models trained using our method are less susceptible to adversaries created using multiple methods. © 2018 ACM.","Adversarial examples; Convolutional Neural Networks; Feature Augmentation; Machine Learning","Computer vision; Deep neural networks; Network architecture; Augmentation techniques; Benchmark datasets; Generic features; Machine learning models; Multiple methods; Neural network model; Standard neural; State of the art; Neural networks",,,,,"Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G.S., Devin, M., (2016) Tensorflow: Large-scale Machine Learning on Heterogeneous Distributed Systems, , 2016; Athalye, A., Carlini, N., Wagner, D., (2018) Obfuscated Gradients Give A False Sense of Security: Circumventing Defenses to Adversarial Examples, , 2018; Bengio, Y., Mesnil, G., Dauphin, Y., Rifai, S., Better mixing via deep representations (2013) International Conference on Machine Learning, pp. 552-560; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndi, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 387-402. , Springer; Biggio, B., Fumera, G., Roli, F., Pattern recognition systems under attack: Design issues and research challenges (2014) International Journal of Pattern Recognition and Artificial Intelligence, 28 (7), p. 1460002. , 2014; Biggio, B., Nelson, B., Laskov, P., (2012) Poisoning Attacks against Support Vector Machines, , 2012; Vivek, B.S., Reddy Mopuri, K., Venkatesh Babu, R., Gray-box adversarial training (2018) The European Conference on Computer Vision (ECCV); Carlini, N., Wagner, D., (2016) Defensive Distillation Is Not Robust to Adversarial Examples, , 2016; DeVries, T., Taylor, G.W., (2017) Dataset Augmentation in Feature Space, , 2017; Dieleman, S., SchlAter, J., Raffel, C., Olson, E., Kaae Sãÿnderby, S., Nouri, D., (2015) Lasagne: First Release, , https://doi.org/10.5281/zenodo.27878, Aug. 2015; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2014) CoRR, , abs/1412. 6572 2014; Gu, S., Rigazio, L., (2014) Towards Deep Neural Network Architectures Robust to Adversarial Examples, , 2014; Guo, C., Rana, M., Cisse, M., Van Der Maaten, L., (2017) Countering Adversarial Images Using Input Transformations, , 2017; Hinton, G., Vinyals, O., Dean, J., (2015) Distilling the Knowledge in A Neural Network, , 2015; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, P.B.I., Tygar, J.D., Adversarial machine learning (2011) Proceedings of the 4th ACM Workshop on Security and Artificial Intelligence (AISec '11); Krizhevsky, A., (2009) Learning Multiple Layers of Features from Tiny Images, , 2009; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , 2016; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial machine learning at scale (2016) CoRR, , abs/1611. 01236 2016; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradientbased learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324. , 1998; Li, X., Li, F., (2016) Adversarial Examples Detection in Deep Networks with Convolutional Filter Statistics, , 2016; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , 2017; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., On detecting adversarial perturbations (2017) ICLR, , 2017; Moosavi-Dezfooli, S., Fawzi, A., Frossard, P., DeepFool: A simple and accurate method to fool deep neural networks (2016) CVPR, , 2016; Reddy Mopuri, K., Ganeshan, A., Venkatesh Babu, R., Generalizable data-free objective for crafting universal adversarial perturbations (2018) IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), , 2018; Reddy Mopuri, K., Garg, U., Venkatesh Babu, R., Fast feature fool: A data independent approach to universal adversarial perturbations (2017) Proceedings of the British Machine Vision Conference (BMVC); Reddy Mopuri, K., Ojha, U., Garg, U., Venkatesh Babu, R., NAG: Network for adversary generation (2018) Proceedings of the IEEE Computer Vision and Pattern Recognition (CVPR); Reddy Mopuri, K., Krishna Uppala, P., Venkatesh Babu, R., Ask, acquire, and attack: Data-free uap generation using class impressions (2018) The European Conference on Computer Vision (ECCV); Ozair, S., Bengio, Y., (2014) Deep Directed Generative Autoencoders, , 2014; Papernot, N., Goodfellow, I., Sheatsley, R., Feinman, R., McDaniel, P., Cleverhans v1. 0. 0: An adversarial machine learning library (2016), 2016; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium On. IEEE, pp. 372-387; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Security and Privacy (SP), 2016 IEEE Symposium On. IEEE, pp. 582-597; Papernot, N., McDaniel, P.D., Goodfellow, I.J., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against deep learning systems using adversarial examples (2016) CoRR, , abs/1602. 02697 2016; Sabour, S., Cao, Y., Faghri, F., Fleet, D.J., (2015) Adversarial Manipulation of Deep Representations, , 2015; Sankaranarayanan, S., Jain, A., Chellappa, R., Nam Lim, S., (2017) Regularizing Deep Networks Using Efficient Layerwise Adversarial Training, , 2017; Song, Y., Kim, T., Nowozin, S., Ermon, S., Kushman, N., (2017) Pixeldefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples, , 2017; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R., Intriguing properties of neural networks (2013) CoRR, , http://arxiv.org/abs/1312.6199, abs/1312. 6199 2013; Tanay, T., Griffin, L., (2016) A Boundary Tilting Persepective on the Phenomenon of Adversarial Examples, , 2016; Development Team, T., (2016) Theano: A Python Framework for Fast Computation of Mathematical Expressions, , http://arxiv.org/abs/1605.02688, e-prints abs/1605. 02688 May 2016",,,"Bosch;et al.;Intel;KLA-Tencor;Mathworks;Microsoft","Association for Computing Machinery","11th Indian Conference on Computer Vision, Graphics and Image Processing, ICVGIP 2018","18 December 2018 through 22 December 2018",,165785,,9781450366151,,,"English","ACM Int. Conf. Proc. Ser.",Conference Paper,"Final","",Scopus,2-s2.0-85098116407
"Ashraf U.","24464996300;","PROSE-Proactive resilience in internet of things: Targeted attacks and countermeasures",2018,"IEEE Sensors Journal","18","24","8469074","10049","10057",,2,"10.1109/JSEN.2018.2871499","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053609576&doi=10.1109%2fJSEN.2018.2871499&partnerID=40&md5=591be6a3bdfbc7a42d4d0e95282a8c8a","Department of Computer Networks and Communications, King Faisal University, Hofuf, 31982, Saudi Arabia","Ashraf, U., Department of Computer Networks and Communications, King Faisal University, Hofuf, 31982, Saudi Arabia","Internet of Things (IoT) is the frontier of wireless networking and provides unprecedented control and information over the network. In particular, the advent of Industrial IoTs and the use of IoT in security and military have necessitated the need to respect stringent delay and reliability constraints, while IoTs promise innovative solutions but their evolution also poses some concerns, with security being the foremost. Due to the fact that these systems operate on sensitive data and are often involved in industrial production processes or critical battleground communication; therefore they are ideal targets for a range of network attacks. This paper explores the novel problem of the elimination of critical IoT nodes to minimize the data-carrying capacity of the IoT network resulting in denial of service. This paper proposes PROSE-a proactive network fortifying solution which focuses on designing resilient IoTs by proactively identifying critical nodes in the network so that they can be protected by installing backups. We assume a worst-case scenario with an adversary that has complete knowledge of the network topology and traffic patterns and can capture/disable a subset of nodes with the aim of minimizing the maximum network flow. PROSE contributes by proactively identifying the nodes that are most vulnerable to the throughput attack assuming a worst-case adversarial scenario and models the problem as a mixed integer linear program. In addition, we propose an efficient heuristic algorithm. Simulation results validate that PROSE efficiently identifies the most vulnerable IoT nodes. © 2018 IEEE.","fortification; interdiction; Wireless mesh networks","Denial-of-service attack; Heuristic algorithms; Integer programming; MESH networking; Wireless mesh networks (WMN); Data-carrying capacity; fortification; Industrial production; Innovative solutions; interdiction; Internet of Things (IOT); Mixed integer linear program; Reliability constraints; Internet of things",,,,,"Chen, C.-P., Mukhopadhyay, S.C., Chuang, C.-L., Liu, M.-Y., Jiang, J.-A., Efficient coverage and connectivity preservation with load balance for wireless sensor networks (2015) IEEE Sensors J, 15 (1), pp. 48-62. , Jan; Dagdeviren, O., Akram, V.K., Tavli, B., Yildiz, H.U., Atilgan, C., Distributed detection of critical nodes in wireless sensor networks using connected dominating set (2016) Proc. IEEE SENSORS, pp. 1-3. , Oct./Nov; Yuksel, A., Uzun, E., Tavli, B., The impact of elimination of the most critical node on wireless sensor network lifetime (2015) Proc. IEEE SAS, pp. 1-5. , Apr; Yildiz, H.U., Tavli, B., Kahjogh, B.O., Dogdu, E., The impact of incapacitation of multiple critical sensor nodes on wireless sensor network lifetime (2017) IEEE Wireless Commun. Lett, 6 (3), pp. 306-309. , Jun; Oteafy, S.M.A., Hassanein, H.S., Component-based wireless sensor networks: A dynamic paradigm for synergetic and resilient architectures (2013) Proc. IEEE LCN, pp. 735-738. , Oct; Oteafy, S.M.A., Hassanein, H.S., Resilient IoT architectures over dynamic sensor networks with adaptive components (2017) IEEE Internet Things J, 4 (2), pp. 474-483. , Apr; Gusev, M., Ristov, S., Prodan, R., Dzanko, M., Bilic, I., Resilient IoT eHealth solutions in case of disasters (2017) Proc. 9th Int. Workshop Resilient Netw. Design Modeling (RNDM), pp. 1-7. , Sep; Han, X., Cao, X., Lloyd, E.L., Shen, C.-C., Fault-tolerant relay node placement in heterogeneous wireless sensor networks (2010) IEEE Trans. Mobile Comput, 9 (5), pp. 643-656. , May; Rana, M.M., Attack resilient wireless sensor networks for smart electric vehicles (2017) IEEE Sensors Lett, 1 (2). , Apr; Kamruzzaman, M., Sarkar, N.I., Gutierrez, J., Ray, S.K., A study of IoT-based post-disaster management (2017) Proc. IEEE ICOIN, pp. 406-410. , Jan; Kahjogh, B.O., Demirkol, I., Careglio, D., Pascual, J.D., The impact of critical node elimination on the latency of wireless sensor networks (2017) Proc. ICUFN, pp. 182-187. , Jul; Gope, P., Lee, J., Quek, T.Q.S., Resilience of DoS attacks in designing anonymous user authentication protocol for wireless sensor networks (2016) IEEE Sensors J, 17 (2), pp. 498-503. , Jan; Lee, J.-Y., Lin, W.-C., Huang, Y.-H., A lightweight authentication protocol for Internet of things (2014) Proc. IEEE ISNE, pp. 1-2. , May; Yao, X., Han, X., Du, X., Zhou, X., A lightweight multicast authentication mechanism for small scale IoT applications (2013) IEEE Sensors J, 13 (10), pp. 3693-3701. , Oct; Khan, Z.A., Ullrich, J., Voyiatzis, A.G., Herrmann, P., A trust-based resilient routing mechanism for the Internet of Things (2017) Proc. ACM Conf. ARES; Niati, R., Yazdani, N., Nourani, M., Deployment of spare nodes in wireless sensor networks (2006) Proc. IEEE Conf. IFIP, p. 5. , Apr; Singh, P., Buttar, A.S., Spare node deployment approach for the improvement of the lifetime of wireless sensor networks (2014) Int. J. Adv. Res. Comput. Sci, 5 (6), pp. 95-99; Bakr, B.A., Lilien, L.T., Extending lifetime of wireless sensor networks by management of spare nodes (2014) Procedia Comput. Sci, 34, pp. 493-498. , Dec; Handy, M.J., Haase, M., Timmermann, D., Low energy adaptive clustering hierarchy with deterministic cluster-head selection (2002) Proc. IEEE Int. Workshop Mobile Wireless Commun. Netw., pp. 368-372. , Sep; Aman, M.N., Chua, K.C., Sikdar, B., Mutual authentication in IoT systems using physical unclonable functions (2017) IEEE Internet Things J, 4 (5), pp. 1327-1340. , Oct; Gope, P., Lee, J., Quek, T.Q.S., Lightweight and practical anonymous authentication protocol for RFID systems using physically unclonable functions (2018) IEEE Trans. Inf. Forensics Security, 13 (11), pp. 2831-2843. , Nov; Gope, P., Sikdar, B., Lightweight and privacy-preserving two-factor authentication scheme for IoT devices IEEE Internet Things J., , to be published; Gope, P., Hwang, T., BSN-care: A secure IoT-based modern healthcare system using body sensor network (2016) IEEE Sensors J, 16 (5), pp. 1368-1376. , Mar; Said, O., Albagory, Y., Nofal, M., Al Raddady, F., IoT-RTP and IoT-RTCP: Adaptive protocols for multimedia transmission over Internet of things environments (2017) IEEE Access, 5, pp. 16757-16773; Jiang, W., Meng, L., Design of real time multimedia platform and protocol to the Internet of Things (2012) Proc. IEEE TrustCom, pp. 1805-1810. , Jun; Wang, W., Wang, Q., Sohraby, K., Multimedia sensing as a service (MSaaS): Exploring resource saving potentials of at cloud-edge IoT and fogs (2017) IEEE Internet Things J, 4 (2), pp. 487-495. , Apr; Ashraf, U., Yuen, C., Capacity-aware topology resilience in software-defined networks IEEE Syst. J., , to be published; Tozlu, S., Senel, M., Mao, W., Keshavarzian, A., Wi-Fi enabled sensors for Internet of things: A practical approach (2012) IEEE Commun. Mag, 50 (6), pp. 134-143. , Jun; (2009) G2m5477 Preliminary Datasheet, , G2 Microsyst., Oakland, CA, USA, May; (2012) Gs1500m Product Brief-Preliminary, , http://www.gainspan.com, GainSpan Corp., San Jose, CA, USA, Apr; Cheng, X., Mohapatra, P., Lee, S.-J., Banerjee, S., MARIA: Interference-aware admission control and QoS routing in wireless mesh networks (2008) Proc. IEEE Int. Conf. Commun., pp. 2865-2870. , May","Ashraf, U.; Department of Computer Networks and Communications, Saudi Arabia; email: uashraf@kfu.edu.sa",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,1530437X,,,,"English","IEEE Sensors J.",Article,"Final","",Scopus,2-s2.0-85053609576
"Khrulkov V., Oseledets I.","57201467534;8529104000;","Art of Singular Vectors and Universal Adversarial Perturbations",2018,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",,,"8578991","8562","8570",,28,"10.1109/CVPR.2018.00893","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062888611&doi=10.1109%2fCVPR.2018.00893&partnerID=40&md5=771a3c59efbee27b042c4f579ad3ad02","Skolkovo Institute of Science and Technology, Russian Federation; Skolkovo Institute of Science and Technology, Institute of Numerical Mathematics, RAS, France","Khrulkov, V., Skolkovo Institute of Science and Technology, Russian Federation; Oseledets, I., Skolkovo Institute of Science and Technology, Institute of Numerical Mathematics, RAS, France","Vulnerability of Deep Neural Networks (DNNs) to adversarial attacks has been attracting a lot of attention in recent studies. It has been shown that for many state of the art DNNs performing image classification there exist universal adversarial perturbations - image-agnostic perturbations mere addition of which to natural images with high probability leads to their misclassification. In this work we propose a new algorithm for constructing such universal perturbations. Our approach is based on computing the so-called (p, q)-singular vectors of the Jacobian matrices of hidden layers of a network. Resulting perturbations present interesting visual patterns, and by using only 64 images we were able to construct universal perturbations with more than 60 % fooling rate on the dataset consisting of 50000 images. We also investigate a correlation between the maximal singular value of the Jacobian matrix and the fooling rate of the corresponding singular vector, and show that the constructed perturbations generalize across networks. © 2018 IEEE.",,"Computer vision; Deep neural networks; Network layers; Hidden layers; High probability; Misclassifications; Natural images; Singular values; Singular vectors; State of the art; Visual pattern; Jacobian matrices",,,,,"Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G.S., Zheng, X., (2015) Tensor-Flow: Large-scale Machine Learning on Heterogeneous Systems, , Software available from tensorflow. org. 8; Bhaskara, A., Vijayaraghavan, A., Approximating matrix p-norms (2011) Proceedings of the Twenty-second Annual ACMSIAM Symposium on Discrete Algorithms, pp. 497-511. , SIAM, 2; Boyd, D.W., The power method for lp norms (1974) Linear Algebra and Its Applications, 9, pp. 95-101. , 2; Gers, F.A., Schmidhuber, J., Cummins, F., (1999) Learning to Forget: Continual Prediction with LSTM, , 1; Goodfellow, I., Papernot, N., McDaniel, P., (2016) Cleverhans v0. 1: An Adversarial Machine Learning Library, , 1; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , 1, 8; Graves, A., Mohamed, A.-R., Hinton, G., Speech recognition with deep recurrent neural networks (2013) Acoustics, Speech and Signal Processing (Icassp), 2013 Ieee International Conference on, pp. 6645-6649. , IEEE, 1; Grosse, K., Papernot, N., Manoharan, P., Backes, M., McDaniel, P., (2016) Adversarial Perturbations Against Deep Neural Networks for Malware Classification, , 1; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778. , 1, 4; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , 1, 8; LeCun, Y., Bengio, Y., Convolutional networks for images, speech, and time series (1995) The Handbook of Brain Theory and Neural Networks, 3361 (10), p. 1995. , 1; Liu, Y., Chen, X., Liu, C., Song, D., (2016) Delving into Transferable Adversarial Examples and Black-box Attacks, , 8; Mikolov, T., Kombrink, S., Burget, L., Ernockỳ, J.C., Khudanpur, S., Extensions of recurrent neural network language model (2011) Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE International Conference on, pp. 5528-5531. , IEEE. 1; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., (2016) Universal Adversarial Perturbations, , 1, 4, 5, 8; Olah, C., Mordvintsev, A., Schubert, L., Feature visualization (2017) Distill, , https://distill.pub/2017/featurevisualization, 4, 8; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Security and Privacy (SP), 2016 IEEE Symposium on, pp. 582-597. , IEEE, 1; Pearlmutter, B.A., Fast exact multiplication by the hessian (1994) Neural Computation, 6 (1), pp. 147-160. , 3; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Bernstein, M., Imagenet large scale visual recognition challenge (2015) International Journal of Computer Vision, 115 (3), pp. 211-252. , 4; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition, , 4; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9. , 1, 4; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , 1, 8; Trefethen, L.N., Bau, D., III, Numerical linear algebra (1997) Siam, 50. , 2",,,,"IEEE Computer Society","31st Meeting of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2018","18 June 2018 through 22 June 2018",,143811,10636919,9781538664209,PIVRE,,"English","Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85062888611
"Prakash A., Moran N., Garber S., Dilillo A., Storer J.","57194418224;57191255609;57194420056;57192541823;57000678400;","Deflecting Adversarial Attacks with Pixel Deflection",2018,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",,,"8578992","8571","8580",,82,"10.1109/CVPR.2018.00894","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062869551&doi=10.1109%2fCVPR.2018.00894&partnerID=40&md5=a511ac6a165e8bf1b51e083f60c033ce","Brandeis University, United States","Prakash, A., Brandeis University, United States; Moran, N., Brandeis University, United States; Garber, S., Brandeis University, United States; Dilillo, A., Brandeis University, United States; Storer, J., Brandeis University, United States","CNNs are poised to become integral parts of many critical systems. Despite their robustness to natural variations, image pixel values can be manipulated, via small, carefully crafted, imperceptible perturbations, to cause a model to misclassify images. We present an algorithm to process an image so that classification accuracy is significantly preserved in the presence of such adversarial manipulations. Image classifiers tend to be robust to natural noise, and adversarial attacks tend to be agnostic to object location. These observations motivate our strategy, which leverages model robustness to defend against adversarial perturbations by forcing the image to match natural image statistics. Our algorithm locally corrupts the image by redistributing pixel values via a process we term pixel deflection. A subsequent wavelet-based denoising operation softens this corruption, as well as some of the adversarial changes. We demonstrate experimentally that the combination of these techniques enables the effective recovery of the true class, against a variety of robust attacks. Our results compare favorably with current state-of-the-art defenses, without requiring retraining or modifying the CNN. © 2018 IEEE.",,"Computer vision; Pixels; Classification accuracy; Critical systems; Image Classifiers; Image pixel value; Model robustness; Natural image statistics; Natural variation; State of the art; Image classification",,,,,"Adams, M.D., (2001) The jpeg-2000 Still Image Compression Standard, , ( last revised : June 30, 2001). 5; Akhtar, N., Liu, J., Mian, A., (2017) Defense Against Universal Adversarial Perturbations, , 3; Antonini, M., Barlaud, M., Mathieu, P., Daubechies, I., Image coding using wavelet transform (1992) IEEE Transactions on Image Processing, 1 (2), pp. 205-220. , 5; Bottou, L., Bengio, Y., LeCun, Y., Global training of document processing systems using graph transformer networks (1997) CVPR, , 1; Carlini, N., Wagner, D.A., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP), , 2, 7, 8; Chang, S.G., Yu, B., Vetterli, M., Adaptive wavelet thresholding for image denoising and compression (2000) IEEE Transactions on Image Processing : A Publication of the IEEE Signal Processing Society, 99, pp. 1532-1546. , 5, 6; Chattopadhyay, A., Sarkar, A., Howlader, P., Balasubramanian, V.N., (2017) Grad-cam++: Generalized Gradient-based Visual Explanations for Deep Convolutional Networks, , CoRR, abs/1710. 11063, 4; Das, N., Shanbhogue, M., Chen, S.-T., Hohman, F., Chen, L., Kounavis, M.E., Chau, D.H., (2017) Keeping the Bad Guys Out: Protecting and Vaccinating Deep Learning with JPEG Compression, , CoRR, abs/1705. 02900, 5, 8; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei Li, F., Imagenet: A large-scale hierarchical image database (2009) 2009 IEEE Conference on Computer Vision and Pattern Recognition, pp. 248-255. , 6; Diamond, S., Sitzmann, V., Boyd, S.P., Wetzstein, G., Heide, F., (2017) Dirty Pixels: Optimizing Image Classification Architectures for Raw Sensor Data, , CoRR, abs/1701. 06487, 3; Dziugaite, G.K., Ghahramani, Z., Roy, D.M., (2016) A Study of the Effect of JPG Compression on Adversarial Images, , CoRR, abs/1608. 00853, 3, 5, 8; Field, D.J., Relations between the statistics of natural images and the response properties of cortical cells (1987) Josa A, 4 (12), pp. 2379-2394. , 5; Getreuer, P., Rudin-osher-fatemi total variation denoising using split bregman (2012) IPOL Journal, 2, pp. 74-95. , 3; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , CoRR, abs/1412. 6572, 2; Guo, C., Rana, M., Cissé, M., Van Der Maaten, L., (2017) Countering Adversarial Images Using Input Transformations, , 3, 5, 7, 8; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , 6; Huang, X., Shen, C., Boix, X., Zhao, Q., Salicon: Reducing the semantic gap in saliency prediction by adapting deep neural networks (2015) 2015 IEEE International Conference on Computer Vision (ICCV), pp. 262-270. , 4; Hubel, D.H., Wiesel, T.N., Receptive fields of single neurones in the cat's striate cortex (1959) The Journal of Physiology, 148, pp. 574-591. , 5; Jansen, M., (2012) Noise Reduction by Wavelet Thresholding, Volume 161, , Springer Science & Business Media. 6; Kurakin, A., Goodfellow, I.J., Bengio, S., (2016) Adversarial Examples in the Physical World, , CoRR, abs/1607. 02533, 2, 3, 5, 8; Liu, Y., Chen, X., Liu, C., Song, D.X., (2016) Delving into Transferable Adversarial Examples and Black-box Attacks, , CoRR, abs/1611. 02770, 2; Luo, Y., Boix, X., Roig, G., Poggio, T.A., Zhao, Q., (2015) Foveation-based Mechanisms Alleviate Adversarial Examples, , CoRR, abs/1511. 06292, 3, 4; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , CoRR, abs/1706. 06083, 2, 3; Marcelja, S., Mathematical description of the responses of simple cortical cells (1980) Journal of the Optical Society of America, 70 (11), pp. 1297-1300. , 5; Matthias Kümmerer, Y.V., Theis, L., Bethge, M., Deep Gaze I: Boosting Saliency Prediction with Feature Maps Trained on Imagenet, , journal=CoRR, 4; Meng, D., Chen, H., Magnet: A two-pronged defense against adversarial examples (2017) CCS, , 3, 6; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2574-2582. , 2; Nguyen, A.M., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 427-436. , 3; Nicolas Papernot, I.G.R.F., Carlini, N., (2017) Cleverhans v2. 0. 0: An Adversarial Machine Learning Library, , 6; Oquab, M., Bottou, L., Laptev, I., Sivic, J., Is object localization for free-weakly-supervised learning with convolutional neural networks (2015) 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 685-694. , 4; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium On. IEEE, , 2; Papernot, N., McDaniel, P.D., Goodfellow, I.J., Jha, S., Celik, Z.B., Swami, A., (2016) Practical Black-box Attacks Against Deep Learning Systems Using Adversarial Examples, , CoRR, abs/1602. 02697, 1, 2; Papernot, N., McDaniel, P.D., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) 2016 IEEE Symposium on Security and Privacy (SP), , 3; Prakash, A., Moran, N., Garber, S., DiLillo, A., Storer, J., Semantic perceptual image compression using deep convolu-tion networks (2017) 2017 Data Compression Conference (DCC), , 4; Rangarajan, R., Venkataramanan, R., Shah, S., (2002) Image Denoising Using Wavelets, , 5, 6; Rust, N.C., Schwartz, O., Movshon, J.A., Simoncelli, E.P., Spatiotemporal elements of macaque v1 receptive fields (2005) Neuron, 46, pp. 945-956. , 5; Simoncelli, E.P., (1999) Bayesian Denoising of Visual Images in the Wavelet Domain, , 5; Su, J., Vargas, D.V., Sakurai, K., (2017) One Pixel Attack for Fooling Deep Neural Networks, , CoRR, abs/1710. 08864, 3; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R., (2013) Intriguing Properties of Neural Networks, , CoRR, abs/1312. 6199, 2; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R., (2013) Intriguing Properties of Neural Networks, , CoRR, abs/1312. 6199, 3; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., Mc-Daniel, P.D., (2017) Ensemble Adversarial Training: Attacks and Defenses, , CoRR, abs/1705. 07204, 3, 7; Tramèr, F., Papernot, N., Goodfellow, I.J., Boneh, D., McDaniel, P.D., (2017) The Space of Transferable Adversarial Examples, , CoRR, abs/1704. 03453, 6; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., Mitigating adversarial effects through randomization (2018) International Conference on Learning Representations, , 3, 7, 8; Xu, W., Evans, D., Qi, Y., (2017) Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks, , CoRR, abs/1704. 01155, 8; Yosinski, J., Clune, J., Nguyen, A.M., Fuchs, T.J., Lipson, H., (2015) Understanding Neural Networks Through Deep Visualization, , CoRR, abs/1506. 06579, 4; Zhou, B., Khosla, A., Lapedriza, À., Oliva, A., Torralba, A., Learning deep features for discriminative localization (2016) 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2921-2929. , 4",,,,"IEEE Computer Society","31st Meeting of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2018","18 June 2018 through 22 June 2018",,143811,10636919,9781538664209,PIVRE,,"English","Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85062869551
"Poursaeed O., Katsman I., Gao B., Belongie S.","56285127500;57207770021;57207773966;6603376681;","Generative Adversarial Perturbations",2018,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",,,"8578563","4422","4431",,79,"10.1109/CVPR.2018.00465","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062857493&doi=10.1109%2fCVPR.2018.00465&partnerID=40&md5=41a554bcd0c34b408907b50cfeb6e7f5","Cornell University, United States; Cornell Tech, United States; Shanghai Jiao Tong University, China","Poursaeed, O., Cornell University, United States, Cornell Tech, United States; Katsman, I., Cornell University, United States; Gao, B., Cornell University, United States, Shanghai Jiao Tong University, China; Belongie, S., Cornell University, United States, Cornell Tech, United States","In this paper, we propose novel generative models for creating adversarial examples, slightly perturbed images resembling natural images but maliciously crafted to fool pre-trained models. We present trainable deep neural networks for transforming images to adversarial perturbations. Our proposed models can produce image-agnostic and image-dependent perturbations for targeted and non-targeted attacks. We also demonstrate that similar architectures can achieve impressive results in fooling both classification and semantic segmentation models, obviating the need for hand-crafting attack methods for each task. Using extensive experiments on challenging high-resolution datasets such as ImageNet and Cityscapes, we show that our perturbations achieve high fooling rates with small perturbation norms. Moreover, our attacks are considerably faster than current iterative methods at inference time. © 2018 IEEE.",,"Deep neural networks; Image segmentation; Iterative methods; Semantics; Attack methods; Generative model; High-resolution datasets; Natural images; Non-targeted; Semantic segmentation; Small perturbations; Computer vision",,,,,"Akhtar, N., Liu, J., Mian, A., (2017) Defense Against Universal Adversarial Perturbations, , 2; Arnab, A., Miksik, O., Torr, P.H., (2017) On the Robustness of Semantic Segmentation Models to Adversarial Attacks, , 2; Athalye, A., Carlini, N., Wagner, D., (2018) Obfuscated Gradients Give A False Sense of Security: Circumventing Defenses to Adversarial Examples, , 2; Athalye, A., Sutskever, I., (2017) Synthesizing Robust Adversarial Examples, , 2; Badrinarayanan, V., Kendall, A., Cipolla, R., (2015) Segnet: A Deep Convolutional Encoder-decoder Architecture for Image Segmentation, , 1; Baluja, S., Fischer, I., (2017) Adversarial Transformation Networks: Learning to Generate Adversarial Examples, , 2; Bhagoji, A.N., He, W., Li, B., Song, D., (2017) Exploring the Space of Black-box Attacks on Deep Neural Networks, , 3, 5, 7; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium on, pp. 39-57. , IEEE, 2, 3, 5, 6; Chen, L.-C., Papandreou, G., Kokkinos, I., Murphy, K., Yuille, A.L., (2016) Deeplab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected Crfs, , 1; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) Proceedings of the 10th ACMWorkshop on Artificial Intelligence and Security, pp. 15-26. , ACM 7; Cisse, M., Adi, Y., Neverova, N., Keshet, J., (2017) Houdini: Fooling Deep Structured Prediction Models, , 2; Cordts, M., Omran, M., Ramos, S., Rehfeld, T., Enzweiler, M., Benenson, R., Franke, U., Schiele, B., The cityscapes dataset for semantic urban scene understanding (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3213-3223. , 7; Das, N., Shanbhogue, M., Chen, S.-T., Hohman, F., Li, S., Chen, L., Kounavis, M.E., Chau, D.H., (2018) Shield: Fast, Practical Defense and Vaccination for Deep Learning Using Jpeg Compression, , 2; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., Imagenet: A large-scale hierarchical image database (2009) Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pp. 248-255. , IEEE, 5; Denton, E.L., Chintala, S., Fergus, R., Deep generative image models using a laplacian pyramid of adversarial networks (2015) Advances in Neural Information Processing Systems, pp. 1486-1494. , 3; Dhillon, G.S., Azizzadenesheli, K., Lipton, Z.C., Bernstein, J., Kossaifi, J., Khanna, A., Anandkumar, A., (2018) Stochastic Activation Pruning for Robust Adversarial Defense, , 2; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, pp. 2672-2680. , 3; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , 2, 5, 7; Guo, C., Rana, M., Cissé, M., Van Der Maaten, L., (2017) Countering Adversarial Images Using Input Transformations, , 2; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778. , 1; Huang, X., Li, Y., Poursaeed, O., Hopcroft, J., Belongie, S., (2016) Stacked Generative Adversarial Networks, , 3; Isola, P., Zhu, J.-Y., Zhou, T., Efros, A.A., (2016) Imageto-image Translation with Conditional Adversarial Networks, , 3; Johnson, J., Alahi, A., Fei-Fei, L., Perceptual losses for real-time style transfer and super-resolution (2016) European Conference on Computer Vision, pp. 694-711. , Springer, 3; Kingma, D., Ba, J., (2014) Adam: A Method for Stochastic Optimization, , 2; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105. , 1; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , 2, 3; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Machine Learning at Scale, , 2, 3; Larsen, A.B.L., Sønderby, S.K., Larochelle, H., Winther, O., (2015) Autoencoding beyond Pixels Using A Learned Similarity Metric, , 3; Liu, Y., Chen, X., Liu, C., Song, D., (2016) Delving into Transferable Adversarial Examples and Black-box Attacks, , 7; Long, J., Shelhamer, E., Darrell, T., Fully convolutional networks for semantic segmentation (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3431-3440. , 1, 7; Lu, J., Sibai, H., Fabry, E., Forsyth, D., (2017) No Need to Worry about Adversarial Examples in Object Detection in Autonomous Vehicles, , 2; Ma, X., Li, B., Wang, Y., Erfani, S.M., Wijewickrema, S., Houle, M.E., Schoenebeck, G., Bailey, J., (2018) Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality, , 2; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , 2; Metzen, J.H., Kumar, M.C., Brox, T., Fischer, V., (2017) Universal Adversarial Perturbations Against Semantic Image Segmentation, , 2, 7, 8; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., (2016) Universal Adversarial Perturbations, , 1, 2, 5; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., Soatto, S., (2017) Analysis of Universal Adversarial Perturbations, , 2; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582. , 2; Mopuri, K.R., Garg, U., Babu, R.V., (2017) Fast Feature Fool: A Data Independent Approach to Universal Adversarial Perturbations, , 2; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 427-436. , 2; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples, , 7; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., (2016) Practical Black-box Attacks Against Deep Learning Systems Using Adversarial Examples, , 7; Prakash, A., Moran, N., Garber, S., Dilillo, A., Storer, J., (2018) Deflecting Adversarial Attacks with Pixel Deflection, , 2; Radford, A., Metz, L., Chintala, S., (2015) Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks, , 3; Raghunathan, A., Steinhardt, J., Liang, P., (2018) Certified Defenses Against Adversarial Examples, , 2; Rakin, A.S., He, Z., Gong, B., Fan, D., (2018) Robust Preprocessing: A Robust Defense Method Against Adversary Attack, , 2; Ronneberger, O., Fischer, P., Brox, T., U-net: Convolutional networks for biomedical image segmentation (2015) International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 234-241. , 3 Springer; Roy, A., Raffel, C., Goodfellow, I., Buckman, J., (2018) Thermometer Encoding: One Hot Way to Resist Adversarial Examples., , 2; Samangouei, P., Kabkab, M., Chellappa, R., (2018) Defense-gan: Protecting Classifiers Against Adversarial Attacks Using Generative Models., , 2; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition, , 1; Song, Y., Kim, T., Nowozin, S., Ermon, S., Kushman, N., (2017) Pixeldefend: Leveraging Generative Models to Understand and Defend Against Adversarial Examples, , 2; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9. , 1; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826. , 1; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , 1, 2, 7; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., Mc-Daniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses, , 2; Vijaykeerthy, D., Suri, A., Mehta, S., Kumaraguru, P., (2018) Hardening Deep Neural Networks Via Adversarial Model Cascades, , 2; Weng, T.-W., Zhang, H., Chen, P.-Y., Yi, J., Su, D., Gao, Y., Hsieh, C.-J., Daniel, L., (2018) Evaluating the Robustness of Neural Networks: An Extreme Value Theory Approach, , 2; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., (2017) Mitigating Adversarial Effects Through Randomization, , 2; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., (2017) Adversarial Examples for Semantic Segmentation and Object Detection, , 2, 7; Yu, F., Koltun, V., (2015) Multi-scale Context Aggregation by Dilated Convolutions, , 1; Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J., (2016) Pyramid Scene Parsing Network, , 1; Zhu, J.-Y., Park, T., Isola, P., Efros, A.A., (2017) Unpaired Imageto-image Translation Using Cycle-consistent Adversarial Networks, , 3",,,,"IEEE Computer Society","31st Meeting of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2018","18 June 2018 through 22 June 2018",,143811,10636919,9781538664209,PIVRE,,"English","Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85062857493
"Bibi A., Alfadly M., Ghanem B.","57188638438;57207777873;24331436200;","Analytic Expressions for Probabilistic Moments of PL-DNN with Gaussian Input",2018,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",,,"8579046","9099","9107",,10,"10.1109/CVPR.2018.00948","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062849514&doi=10.1109%2fCVPR.2018.00948&partnerID=40&md5=78a1df9fded6e363c8fbc40f5d182901","King Abdullah University of Science and Technology (KAUST), Saudi Arabia","Bibi, A., King Abdullah University of Science and Technology (KAUST), Saudi Arabia; Alfadly, M., King Abdullah University of Science and Technology (KAUST), Saudi Arabia; Ghanem, B., King Abdullah University of Science and Technology (KAUST), Saudi Arabia","The outstanding performance of deep neural networks (DNNs), for the visual recognition task in particular, has been demonstrated on several large-scale benchmarks. This performance has immensely strengthened the line of research that aims to understand and analyze the driving reasons behind the effectiveness of these networks. One important aspect of this analysis has recently gained much attention, namely the reaction of a DNN to noisy input. This has spawned research on developing adversarial input attacks as well as training strategies that make DNNs more robust against these attacks. To this end, we derive in this paper exact analytic expressions for the first and second moments (mean and variance) of a small piecewise linear (PL) network (Affine, ReLU, Affine) subject to general Gaussian input. We experimentally show that these expressions are tight under simple linearizations of deeper PL-DNNs, especially popular architectures in the literature (e.g. LeNet and AlexNet). Extensive experiments on image classification show that these expressions can be used to study the behaviour of the output mean of the logits for each class, the interclass confusion and the pixel-level spatial noise sensitivity of the network. Moreover, we show how these expressions can be used to systematically construct targeted and non-targeted adversarial attacks. © 2018 IEEE.",,"Benchmarking; Computer vision; Piecewise linear techniques; Analytic expressions; Gaussian inputs; Non-targeted; Piecewise linear; Second moments; Spatial noise; Training strategy; Visual recognition; Deep neural networks",,,,,"An, G., The effects of adding noise during backpropagation training on a generalization performance (1996) Neural Computation, 8 (3), pp. 643-674; Bakry, A., Elhoseiny, M., El-Gaaly, T., Elgammal, A., (2016) Digging Deep into the Layers of Cnns: In Search of How Cnns Achieve View Invariance; Bishop, C.M., Training with noise is equivalent to tikhonov regularization (2008) Training, 7 (1); Chicco, D., Sadowski, P., Baldi, P., Deep autoencoder neural networks for gene ontology annotation predictions (2014) Proceedings of the 5th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics, pp. 533-540. , ACM; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., Imagenet: A large-scale hierarchical image database (2009) Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pp. 248-255. , IEEE; Dosovitskiy, A., Brox, T., Inverting visual representations with convolutional networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4829-4837; Escorcia, V., Heilbron, F.C., Niebles, J.C., Ghanem, B., Daps: Deep action proposals for action understanding (2016) European Conference on Computer Vision, pp. 768-784. , Springer; Fawzi, A., Frossard, P., Manitest: Are classifiers really invariant (2015) British Machine Vision Conference (BMVC), Number EPFL-CONF-210209; Fawzi, A., Frossard, P., Measuring the effect of nuisance variables on classifiers (2016) British Machine Vision Conference (BMVC), Number EPFL-CONF-220613; Fawzi, A., Moosavi-Dezfooli, S.-M., Frossard, P., Robustness of classifiers: From adversarial to random noise (2016) Advances in Neural Information Processing Systems, pp. 1632-1640; Fawzi, A., Moosavi Dezfooli, S.M., Frossard, P., (2017) A Geometric Perspective on the Robustness of Deep Networks, , Technical report, Institute of Electrical and Electronics Engineers; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Grandvalet, Y., Canu, S., Boucheron, S., Noise injection: Theoretical prospects (1997) Neural Computation, 9 (5), pp. 1093-1108; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Hinton, G., Deng, L., Yu, D., Dahl, G.E., Mohamed, A.-R., Jaitly, N., Senior, A., Sainath, T.N., Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups (2012) IEEE Signal Processing Magazine, 29 (6), pp. 82-97; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; LeCun, Y., (1998) The Mnist Database of Handwritten Digits, , http://yann.lecun.com/exdb/mnist/; LeCun, Y., Haffner, P., Bottou, L., Bengio, Y., Object recognition with gradient-based learning (1999) Shape, Contour and Grouping in Computer Vision, p. 823; Long, J., Shelhamer, E., Darrell, T., Fully convolutional networks for semantic segmentation (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3431-3440; Luo, Y., Yang, F., (2014) Deep Learning with Noise; Mahendran, A., Vedaldi, A., Understanding deep image representations by inverting them (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 5188-5196; McMahon, E., An extension of price's theorem (corresp.) (1964) IEEE Transactions on Information Theory, 10 (2), p. 168; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., (2016) Universal Adversarial Perturbations; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 427-436; Papoulis, A., (1965) Probability, Random Variables, and Stochastic Processes, p. 161; Price, R., A useful theorem for nonlinear devices having Gaussian inputs (1958) IRE Transactions on Information Theory, 4 (2), pp. 69-72; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition; Soatto, S., Chiuso, A., (2014) Visual Representations: Defining Properties and Deep Approximations; Su, J., Vargas, D.V., Kouichi, S., (2017) One Pixel Attack for Fooling Deep Neural Networks; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks; Tran, D., Bourdev, L., Fergus, R., Torresani, L., Paluri, M., Learning spatiotemporal features with 3d convolutional networks (2015) Proceedings of the IEEE International Conference on Computer Vision, pp. 4489-4497; Vondrick, C., Khosla, A., Malisiewicz, T., Torralba, A., Hoggles: Visualizing object detection features (2013) Proceedings of the IEEE International Conference on Computer Vision, pp. 1-8",,,,"IEEE Computer Society","31st Meeting of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2018","18 June 2018 through 22 June 2018",,143811,10636919,9781538664209,PIVRE,,"English","Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85062849514
"Arnab A., Miksik O., Torr P.H.S.","57113566800;55064235900;56821543600;","On the Robustness of Semantic Segmentation Models to Adversarial Attacks",2018,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",,,"8578197","888","897",,82,"10.1109/CVPR.2018.00099","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062833643&doi=10.1109%2fCVPR.2018.00099&partnerID=40&md5=9569513733344ea7ccba1637dc8cf152","University of Oxford, United Kingdom; Emotech Labs, United Kingdom","Arnab, A., University of Oxford, United Kingdom; Miksik, O., University of Oxford, United Kingdom, Emotech Labs, United Kingdom; Torr, P.H.S., University of Oxford, United Kingdom","Deep Neural Networks (DNNs) have been demonstrated to perform exceptionally well on most recognition tasks such as image classification and segmentation. However, they have also been shown to be vulnerable to adversarial examples. This phenomenon has recently attracted a lot of attention but it has not been extensively studied on multiple, large-scale datasets and complex tasks such as semantic segmentation which often require more specialised networks with additional components such as CRFs, dilated convolutions, skip-connections and multiscale processing. In this paper, we present what to our knowledge is the first rigorous evaluation of adversarial attacks on modern semantic segmentation models, using two large-scale datasets. We analyse the effect of different network architectures, model capacity and multiscale processing, and show that many observations made on the task of classification do not always transfer to this more complex task. Furthermore, we show how mean-field inference in deep structured models and multiscale processing naturally implement recently proposed adversarial defenses. Our observations will aid future efforts in understanding and defending against adversarial examples. Moreover, in the shorter term, we show which segmentation models should currently be preferred in safety-critical applications due to their inherent robustness. © 2018 IEEE.",,"Complex networks; Computer vision; Deep neural networks; Large dataset; Network architecture; Safety engineering; Semantics; Complex task; Large-scale datasets; Multiscale processing; Rigorous evaluation; Safety critical applications; Segmentation models; Semantic segmentation; Structured model; Image segmentation",,,,,"Arnab, A., Jayasumana, S., Zheng, S., Torr, P.H.S., Higher order conditional random fields in deep neural networks (2016) ECCV; Arnab, A., Zheng, S., Jayasumana, S., Romera-Paredes, B., Larsson, M., Kirillov, A., Savchynskyy, B., Torr, P.H.S., Conditional random fields meet deep neural networks for semantic segmentation: Combining probabilistic graphical models with deep learning for structured prediction (2018) IEEE Signal Processing Magazine, 35 (1), pp. 37-52; Athalye, A., Sutskever, I., (2017) Synthesizing Robust Adversarial Examples; Badrinarayanan, V., Handa, A., Cipolla, R., (2015) Segnet: A Deep Convolutional Encoder-decoder Architecture for Robust Semantic Pixel-wise Labelling, , CoRR, abs/1505.07293; Barrow, H.G., Tenenbaum, J., (1981) Interpreting Line Drawings As Three-dimensional Surfaces; Biggio, B., Nelson, B., Laskov, P., Poisoning attacks against support vector machines (2012) ICML; Bilinski, P., Prisacariu, V., Dense decoder shortcut connections for single-pass semantic segmentation (2018) CVPR; Carbonetto, P., Freitas, N.D., Conditional mean field (2007) NIPS; Carlini, N., Wagner, D., (2016) Defensive Distillation Is Not Robust to Adversarial Examples; Carlini, N., Wagner, D., (2017) Adversarial examples are not easily detected: Bypassing ten detection methods; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy; Chalupka, K., Perona, P., Eberhardt, F., Visual causal feature learning (2015) UAI; Chandra, S., Kokkinos, I., Fast, exact and multi-scale inference for semantic image segmentation with deep Gaussian crfs (2016) ECCV; Chen, L.-C., Papandreou, G., Kokkinos, I., Murphy, K., Yuille, A.L., Semantic image segmentation with deep convolutional nets and fully connected crfs (2015) ICLR; Chen, L.-C., Papandreou, G., Kokkinos, I., Murphy, K., Yuille, A.L., (2016) Deeplab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected Crfs; Cisse, M., Adi, Y., Neverova, N., Keshet, J., Houdini: Fooling deep structured prediction models (2017) NIPS; Cisse, M., Bojanowski, P., Grave, E., Dauphin, Y., Usunier, N., Parseval networks: Improving robustness to adversarial examples (2017) ICML; Cordts, M., Omran, M., Ramos, S., Rehfeld, T., Enzweiler, M., Benenson, R., Franke, U., Schiele, B., The cityscapes dataset for semantic urban scene understanding (2016) CVPR; Dai, J., He, K., Sun, J., Boxsup: Exploiting bounding boxes to supervise convolutional networks for semantic segmentation (2015) ICCV; Dziugaite, G.K., Ghahramani, Z., Roy, D.M., (2016) A Study of the Effect of Jpg Compression on Adversarial Images; Esteva, A., Kuprel, B., Novoa, R.A., Ko, J., Swetter, S.M., Blau, H.M., Thrun, S., Dermatologist-level classification of skin cancer with deep neural networks (2017) Nature; Everingham, M., Van Gool, L., Williams, C.K., Winn, J., Zisserman, A., The pascal visual object classes (voc) challenge (2010) IJCV; Evtimov, I., Eykholt, K., Fernandes, E., Kohno, T., Li, B., Prakash, A., Rahmati, A., Song, D., (2017) Robust Physicalworld Attacks on Machine Learning Models; Fawzi, A., Frossard, P., Manitest: Are classifiers really invariant? (2015) BMVC; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting adversarial samples from artifacts; Fischer, V., Kumar, M.C., Metzen, J.H., Brox, T., Adversarial examples for semantic image segmentation (2017) ICLR Workshop; Forsyth, D.A., Malik, J., Fleck, M.M., Greenspan, H., Leung, T., Belongie, S., Carson, C., Bregler, C., (1996) Finding Pictures of Objects in Large Collections of Images, , Springer; Gao, J., Wang, B., Qi, Y., Deepmask: Masking dnn models for robustness against adversarial samples (2017) ICLR Workshop; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR; Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., (2017) On the (statistical) detection of adversarial examples; Gu, S., Rigazio, L., Towards deep neural network architectures robust to adversarial examples (2015) ICLR Workshop; Hariharan, B., Arbelaez, P., Bourdev, L., Maji, S., Malik, J., Semantic contours from inverse detectors (2011) ICCV; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) CVPR; He, W., Wei, J., Chen, X., Carlini, N., Song, D., (2017) Adversarial Example Defenses: Ensembles of Weak Defenses Are Not Strong.; Henriques, J.F., Vedaldi, A., Warped convolutions: Efficient invariance to spatial transformations (2017) ICML; Janai, J., Güney, F., Behl, A., Geiger, A., (2017) Computer Vision for Autonomous Vehicles: Problems, Datasets and State-ofthe-art.; Koh, P.W., Liang, P., Understanding black-box predictions via influence functions (2017) ICML; Krahenbuhl, P., Koltun, V., Efficient inference in fully connected CRFs with Gaussian edge potentials (2011) NIPS; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) NIPS; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2017) ICLR Workshop; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2017) ICLR; Lin, G., Shen, C., Reid, I., Efficient piecewise training of deep structured models for semantic segmentation (2016) CVPR; Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Dollar, P., Zitnick, C.L., Microsoft coco: Common objects in context (2014) ECCV; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) ICLR; Long, J., Shelhamer, E., Darrell, T., Fully convolutional networks for semantic segmentation (2015) CVPR; Lu, J., Sibai, H., Fabry, E., Forsyth, D., No need to worry about adversarial examples in object detection in autonomous vehicles (2017) CVPR Workshop; Lu, J., Sibai, H., Fabry, E., Forsyth, D., (2017) Standard Detectors Aren't (Currently) Fooled by Physical Adversarial Stop Signs.; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) ICLR; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., On detecting adversarial perturbations (2017) ICLR; Metzen, J.H., Kumar, M.C., Brox, T., Fischer, V., Universal adversarial perturbations against semantic image segmentation (2017) ICCV; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) CVPR; Murphy, K.P., (2012) Machine Learning: A Probabilistic Perspective, , MIT press; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Blackbox Attacks Using Adversarial Samples.; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, , ACM; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) IEEE Symposium on Security and Privacy; Paszke, A., Chaurasia, A., Kim, S., Culurciello, E., (2016) Enet: A Deep Neural Network Architecture for Real-time Semantic Segmentation.; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-ofthe-art face recognition (2016) Proceedings of the 23rd ACM SIGSAC Conference on Computer and Communications Security; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) ICLR; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) ICLR; Tramer, F., Kurakin, A., Papernot, N., Boneh, D., Mc-Daniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses.; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., Mitigating adversarial effects through randomization (2018) ICLR; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., Adversarial examples for semantic segmentation and object detection (2017) ICCV; Xu, W., Evans, D., Qi, Y., (2017) Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks.; Xu, X., Chen, X., Liu, C., Rohrbach, A., Darell, T., Song, D., (2017) Can You Fool Ai with Adversarial Examples on A Visual Turing Test?.; Yu, F., Koltun, V., Multi-scale context aggregation by dilated convolutions (2016) ICLR; Zhao, H., Qi, X., Shen, X., Shi, J., Jia, J., (2017) Icnet for Real-time Semantic Segmentation on High-resolution Images.; Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J., Pyramid scene parsing network (2017) CVPR; Zheng, S., Jayasumana, S., Romera-Paredes, B., Vineet, V., Su, Z., Du, D., Huang, C., Torr, P., Conditional random fields as recurrent neural networks (2015) ICCV",,,,"IEEE Computer Society","31st Meeting of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2018","18 June 2018 through 22 June 2018",,143811,10636919,9781538664209,PIVRE,,"English","Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85062833643
"Liao F., Liang M., Dong Y., Pang T., Hu X., Zhu J.","57194680047;57204289094;57191433539;57204799576;55496159600;56734692500;","Defense Against Adversarial Attacks Using High-Level Representation Guided Denoiser",2018,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",,,"8578289","1778","1787",,215,"10.1109/CVPR.2018.00191","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062826279&doi=10.1109%2fCVPR.2018.00191&partnerID=40&md5=34532291cdb1f26e1e74dcc312a83dfb","Department of Computer Science and Technology, Tsinghua Lab of Brain and Intelligence, Beijing National Research Center for Information Science and Technology, BNRist Lab, Tsinghua University100084, China","Liao, F., Department of Computer Science and Technology, Tsinghua Lab of Brain and Intelligence, Beijing National Research Center for Information Science and Technology, BNRist Lab, Tsinghua University100084, China; Liang, M., Department of Computer Science and Technology, Tsinghua Lab of Brain and Intelligence, Beijing National Research Center for Information Science and Technology, BNRist Lab, Tsinghua University100084, China; Dong, Y., Department of Computer Science and Technology, Tsinghua Lab of Brain and Intelligence, Beijing National Research Center for Information Science and Technology, BNRist Lab, Tsinghua University100084, China; Pang, T., Department of Computer Science and Technology, Tsinghua Lab of Brain and Intelligence, Beijing National Research Center for Information Science and Technology, BNRist Lab, Tsinghua University100084, China; Hu, X., Department of Computer Science and Technology, Tsinghua Lab of Brain and Intelligence, Beijing National Research Center for Information Science and Technology, BNRist Lab, Tsinghua University100084, China; Zhu, J., Department of Computer Science and Technology, Tsinghua Lab of Brain and Intelligence, Beijing National Research Center for Information Science and Technology, BNRist Lab, Tsinghua University100084, China","Neural networks are vulnerable to adversarial examples, which poses a threat to their application in security sensitive systems. We propose high-level representation guided denoiser (HGD) as a defense for image classification. Standard denoiser suffers from the error amplification effect, in which small residual adversarial noise is progressively amplified and leads to wrong classifications. HGD overcomes this problem by using a loss function defined as the difference between the target model's outputs activated by the clean image and denoised image. Compared with ensemble adversarial training which is the state-of-the-art defending method on large images, HGD has three advantages. First, with HGD as a defense, the target model is more robust to either white-box or black-box adversarial attacks. Second, HGD can be trained on a small subset of the images and generalizes well to other images and unseen classes. Third, HGD can be transferred to defend models other than the one guiding it. In NIPS competition on defense against adversarial attacks, our HGD solution won the first place and outperformed other models by a large margin.1 © 2018 IEEE.",,"Computer vision; Network security; Clean images; Defending method; Error amplification; Large images; Loss functions; Sensitive systems; State of the art; Target model; Image denoising",,,,,"Baluja, S., Ian Fischer., (2017) Adversarial Transformation Networks: Learning to Generate Adversarial Examples; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Srndíc, N., Laskov, P., Giacinto, G., Fabio, R., Evasion attacks against machine learning at test time (2013) Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 387-402; Carlini, N., Wagner, D., (2017) Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods; Das, N., Shanbhogue, M., Chen, S.-T., Hohman, F., Chen, L., Kounavis, M.E., Chau, D.H., (2017) Keeping the Bad Guys Out: Protecting and Vaccinating Deep Learning with Jpeg Compression; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., Imagenet: A large-scale hierarchical image database (2009) IEEE Conference on Computer Vision and Pattern Recognition, pp. 248-255; Dosovitskiy, A., Brox, T., Generating images with perceptual similarity metrics based on deep networks (2016) Advances in Neural Information Processing Systems, pp. 658-666; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Graese, A., Rozsa, A., Boult, T.E., Assessing threat of adversarial examples on deep neural networks (2016) Machine Learning and Applications (ICMLA), pp. 69-74. , 2016. 15th IEEE International Conference on; Gu, S., Rigazio, L., (2014) Towards Deep Neural Network Architectures Robust to Adversarial Examples; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; He, K., Zhang, X., Ren, S., Sun, J., Identity mappings in deep residual networks (2016) European Conference on Computer Vision, pp. 630-645; Hinton, G., Vinyals, O., Dean, J., (2015) Distilling the Knowledge in A Neural Network; Ioffe, S., Szegedy, C., Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015) International Conference on Machine Learning, pp. 448-456; Johnson, J., Alahi, A., Li, F.-F., Perceptual losses for real-time style transfer and super-resolution (2016) European Conference on Computer Vision, pp. 694-711. , Springer; Kingma, D., Jimmy, Ba., (2014) Adam: A Method for Stochastic Optimization; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Machine Learning at Scale; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proceedings of the IEEE, 86 (11), pp. 2278-2324; Meng, D., Chen, H., Magnet: A two-pronged defense against adversarial examples (2017) Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pp. 135-147; Nayebi, A., Ganguli, S., (2017) Biologically Inspired Protection of Deep Networks from Adversarial Attacks; Osadchy, M., Hernandez-Castro, J., Gibson, S., Dunkelman, O., Ṕerez-Cabo, D., No bot expects the deepcaptcha! introducing immutable adversarial examples with applications to captcha (2016) IACR Cryptology EPrint Archive, 2016, p. 336; Papernot, N., McDaniel, P., Ian Goodfellow., (2016) Transferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) ACM Asia Conference on Computer and Communications Security, pp. 506-519; Papernot, N., McDaniel, P., Sinha, A., Wellman, M., (2016) Towards the Science of Security and Privacy in Machine Learning; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) IEEE Symposium on Security and Privacy (SP), pp. 582-597; Rasmus, A., Berglund, M., Honkala, M., Valpola, H., Raiko, T., Semi-supervised learning with ladder networks (2015) Advances in Neural Information Processing Systems, pp. 3546-3554; Ridgeway, K., Snell, J., Roads, B., Zemel, R.S., Mozer, M.C., (2015) Learning to Generate Images with Perceptual Similarity Metrics; Ronneberger, O., Fischer, P., Brox, T., U-net: Convolutional networks for biomedical image segmentation (2015) International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 234-241; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., Inception-v4, inception-resnet and the impact of residual connections on learning (2017) AAAI, pp. 4278-4284; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks; Tramer, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses; Vincent, P., Larochelle, H., Bengio, Y., Manzagol, P.-A., Extracting and composing robust features with denoising autoencoders (2008) International Conference on Machine Learning, pp. 1096-1103; Xie, S., Girshick, R., Dolĺar, P., Tu, Z., Kaiming, He., (2016) Aggregated Residual Transformations for Deep Neural Networks; Zhang, K., Zuo, W., Chen, Y., Meng, D., Zhang, L., Beyond a Gaussian denoiser: Residual learning of deep cnn for image denoising (2017) IEEE Transactions on Image Processing","Hu, X.; Department of Computer Science and Technology, China; email: xlhu@tsinghua.edu.cn",,,"IEEE Computer Society","31st Meeting of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2018","18 June 2018 through 22 June 2018",,143811,10636919,9781538664209,PIVRE,,"English","Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85062826279
"Xu X., Chen X., Liu C., Rohrbach A., Darrell T., Song D.","57221066129;57208640696;55873082700;56406263600;7003377605;7402443870;","Fooling Vision and Language Models Despite Localization and Attention Mechanism",2018,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",,,"8578618","4951","4961",,18,"10.1109/CVPR.2018.00520","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058652903&doi=10.1109%2fCVPR.2018.00520&partnerID=40&md5=e2b1182236f586a1bcb005eeab9e5906","Shanghai Jiao, Tong University, China; EECS, UC Berkeley, United States; MPI for Informatics, United States","Xu, X., Shanghai Jiao, Tong University, China, EECS, UC Berkeley, United States; Chen, X., Shanghai Jiao, Tong University, China; Liu, C., Shanghai Jiao, Tong University, China; Rohrbach, A., EECS, UC Berkeley, United States, MPI for Informatics, United States; Darrell, T., EECS, UC Berkeley, United States; Song, D., EECS, UC Berkeley, United States","Adversarial attacks are known to succeed on classifiers, but it has been an open question whether more complex vision systems are vulnerable. In this paper, we study adversarial examples for vision and language models, which incorporate natural language understanding and complex structures such as attention, localization, and modular architectures. In particular, we investigate attacks on a dense captioning model and on two visual question answering (VQA) models. Our evaluation shows that we can generate adversarial examples with a high success rate (i.e., > 90%) for these models. Our work sheds new light on understanding adversarial attacks on vision systems which have a language component and shows that attention, bounding box localization, and compositional internal structures are vulnerable to adversarial attacks. These observations will inform future work towards building effective defenses. © 2018 IEEE.",,"Computational linguistics; Natural language processing systems; Attention mechanisms; Complex structure; Internal structure; Language component; Modular architectures; Natural language understanding; Question Answering; Vision systems; Computer vision",,,,,"Agrawal, A., Batra, D., Parikh, D., Kembhavi, A., Don't just assume; Look and answer: Overcoming priors for visual question answering (2018) IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Anderson, P., He, X., Buehler, C., Teney, D., Johnson, M., Gould, S., Zhang, L., (2017) Bottom-up and Top-down Attention for Image Captioning and Vqa., , arXiv preprint arXiv: 1707.07998; Andreas, J., Rohrbach, M., Darrell, T., Klein, D., Learning to compose neural networks for question answering (2016) Proc. Of NAACL; Andreas, J., Rohrbach, M., Darrell, T., Klein, D., Neural module networks (2016) Proc. Of CVPR; Antol, S., Agrawal, A., Lu, J., Mitchell, M., Batra, D., Zitnick, C.L., Parikh, D., Vqa: Visual question answering (2015) Proc. Of ICCV; Athalye, A., Sutskever, I., (2017) Synthesizing Robust Adversarial Examples., , arXiv preprint arXiv: 1707.07397; Bahdanau, D., Cho, K., Bengio, Y., Neural machine translation by jointly learning to align and translate (2015) Proc. Of ICLR; Carlini, N., Wagner, D., (2016) Defensive Distillation Is Not Robust to Adversarial Examples., , arXiv preprint arXiv: 1607.04311; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) AISec; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP)., pp. 39-57. , IEEE; Donahue, J., Hendricks, L.A., Guadarrama, S., Rohrbach, M., Venugopalan, S., Saenko, K., Darrell, T., Long-Term recurrent convolutional networks for visual recognition and description (2015) Proc. Of CVPR; Fang, H., Gupta, S., Iandola, F.N., Srivastava, R., Deng, L., Dollár, P., Gao, J., Zweig, G., From captions to visual concepts and back (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts., , arXiv preprint arXiv: 1703.00410; Fischer, V., Kumar, M.C., Metzen, J.H., Brox, T., (2017) Adversarial Examples for Semantic Image Segmentation., , arXiv preprint arXiv: 1703.01101; Fu, K., Jin, J., Cui, R., Sha, F., Zhang, C., (2016) Aligning Where to See and What to Tell: Image Captioning with Region-based Attention and Scene-specific Contexts.; Fukui, A., Park, D.H., Yang, D., Rohrbach, A., Darrell, T., Rohrbach, M., Multimodal compact bilinear pooling for visual question answering and visual grounding (2016) Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP); Gao, H., Mao, J., Zhou, J., Huang, Z., Wang, L., Xu, W., Are you talking to a machine? Dataset and methods for multilingual image question answering (2015) Proc. Of NIPS; Gong, Z., Wang, W., Ku, W.-S., (2017) Adversarial and Clean Data Are Not Twins., , arXiv preprint arXiv: 1704.04960; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) Proc. Of ICLR; Goyal, Y., Khot, T., Summers-Stay, D., Batra, D., Parikh, D., Making the V in VQA matter: Elevating the role of image understanding in visual question answering (2017) IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., (2017) On the (Statistical) Detection of Adversarial Examples., , arXiv preprint arXiv: 1702.06280; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR); He, W., Wei, J., Chen, X., Carlini, N., Song, D., (2017) Adversarial Example Defenses: Ensembles of Weak Defenses Are Not Strong., , arXiv preprint arXiv: 1706.04701; Hendrik Metzen, J., Chaithanya Kumar, M., Brox, T., Fischer, V., Universal adversarial perturbations against semantic image segmentation (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Hu, R., Andreas, J., Rohrbach, M., Darrell, T., Saenko, K., Learning to reason: End-To-end module networks for visual question answering (2017) Proc. Of ICCV; Huang, S., Papernot, N., Goodfellow, I., Duan, Y., Abbeel, P., (2017) Adversarial Attacks on Neural Network Policies., , arXiv preprint arXiv: 1702.02284; Jabri, A., Joulin, A., Van Der Maaten, L., Revisiting visual question answering baselines (2016) European Conference on Computer Vision (ECCV); Jia, R., Liang, P., Adversarial examples for evaluating reading comprehension systems (2017) Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP); Johnson, J., Hariharan, B., Van Der Maaten, L., Hoffman, J., Fei-Fei, L., Zitnick, C.L., Girshick, R., Inferring and executing programs for visual reasoning (2017) Proc. Of ICCV; Johnson, J., Karpathy, A., Fei-Fei, L., Densecap: Fully convolutional localization networks for dense captioning (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)., pp. 4565-4574; Kafle, K., Kanan, C., An analysis of visual question answering algorithms (2017) 2017 IEEE International Conference on Computer Vision (ICCV).; Karpathy, A., Fei-Fei, L., Deep visual-semantic alignments for generating image descriptions (2015) Proc. Of CVPR; Kiros, R., Salakhutdinov, R., Zemel, R.S., Unifying visual-semantic embeddings with multimodal neural language models (2015) Transactions of the Association for Computational Linguistics (TACL)., 9, pp. 595-603; Kos, J., Song, D., (2017) Delving into Adversarial Attacks on Deep Policies., , arXiv preprint arXiv: 1705.06452; Krishna, R., Zhu, Y., Groth, O., Johnson, J., Hata, K., Kravitz, J., Chen, S., Shamma, D.A., Visual genome: Connecting language and vision using crowdsourced dense image annotations (2017) International Journal of Computer Vision, 123 (1), pp. 32-73; Kumar, A., Irsoy, O., Su, J., Bradbury, J., English, R., Pierce, P., Ondruska, I., Socher, R., Ask me anything: Dynamic memory networks for natural language processing (2016) Proceedings of the International Conference on Machine Learning (ICML).; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2017) Proc. Of ICLR; Lavie, M.D.A., Meteor universal: Language specific translation evaluation for any target language (2014) Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)., p. 376; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradientbased learning applied to document recognition (1998) Proceedings of the IEEE, 86 (11), pp. 2278-2324; Li, Y., Ouyang, W., Zhou, B., Wang, K., Wang, X., Scene graph generation from objects, phrases and caption regions (2017) Proc. Of ICCV; Lin, Y.-C., Hong, Z.-W., Liao, Y.-H., Shih, M.-L., Liu, M.-Y., Sun, M., Tactics of adversarial attack on deep reinforcement learning agents (2017) Proc. Of IJCAI; Liu, C., Mao, J., Sha, F., Yuille, A., Attention correctness in neural image captioning (2017) Proc. Of AAAI; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) Proc. Of ICLR; Lu, J., Sibai, H., Fabry, E., Forsyth, D., (2017) No Need to Worry about Adversarial Examples in Object Detection in Autonomous Vehicles., , arXiv preprint arXiv: 1707.03501; Lu, J., Sibai, H., Fabry, E., Forsyth, D., (2017) Standard Detectors Aren't (Currently) Fooled by Physical Adversarial Stop Signs., , arXiv preprint arXiv: 1710.03337; Lu, J., Xiong, C., Parikh, D., Socher, R., Knowing when to look: Adaptive attention via a visual sentinel for image captioning (2017) Proc. Of CVPR; Lu, J., Yang, J., Batra, D., Parikh, D., Hierarchical coattention for visual question answering (2016) Proc. Of NIPS, 2; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks., , arXiv preprint arXiv: 1706.06083; Malinowski, M., Rohrbach, M., Fritz, M., Ask your neurons: A neural-based approach to answering questions about images (2015) Proc. Of CVPR, pp. 1-9; Mao, J., Xu, W., Yang, Y., Wang, J., Huang, Z., Yuille, A., Deep captioning with multimodal recurrent neural networks (m-rnn) (2015) Proc. Of ICLR; Meng, D., Chen, H., Magnet: A two-pronged defense against adversarial examples (2017) CCS; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., (2017) On Detecting Adversarial Perturbations, , 2017; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) Proc. Of CVPR; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Proc. Of CVPR, p. 427. , IEEE; Noh, H., Seo, P.H., Han, B., Image question answering using convolutional neural network with dynamic parameter prediction (2016) Proc. Of CVPR; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples., , arXiv preprint arXiv: 1605.07277; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., (2016) Practical Black-box Attacks Against Deep Learning Systems Using Adversarial Examples., , arXiv preprint arXiv: 1602.02697; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Proc. Of Euro S&P, p. 372. , IEEE; Papernot, N., McDaniel, P., Swami, A., Harang, R., Crafting adversarial input sequences for recurrent neural networks (2016) MILCOM., , IEEE; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Security and Privacy (SP), 2016 IEEE Symposium on, pp. 582-597. , IEEE; Pedersoli, M., Lucas, T., Schmid, C., Verbeek, J., Areas of attention for image captioning (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Ren, M., Kiros, R., Zemel, R., Image question answering: A visual semantic embedding model and a new dataset (2015) Proc. Of NIPS; Ren, S., He, K., Girshick, R., Sun, J., Faster R-CNN: Towards real-Time object detection with region proposal networks (2015) Proc. Of NIPS; Shih, K.J., Singh, S., Hoiem, D., Where to look: Focus regions for visual question answering (2016) Proc. Of CVPR; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., (2014) Going Deeper with Convolutions., , arXiv: 1409.4842; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) Proc. Of ICLR; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., Mc-Daniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses., , arXiv preprint arXiv: 1705.07204; Tramèr, F., Papernot, N., Goodfellow, I., Boneh, D., Mc-Daniel, P., (2017) The Space of Transferable Adversarial Examples., , arXiv preprint arXiv: 1704.03453; Vinyals, O., Toshev, A., Bengio, S., Erhan, D., (2014) Show and Tell: A Neural Image Caption Generator., , arXiv: 1411.4555; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., Adversarial examples for semantic segmentation and object detection (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Xiong, C., Merity, S., Socher, R., Dynamic memory networks for visual and textual question answering (2016) Proceedings of the International Conference on Machine Learning (ICML); Xu, H., Saenko, K., Attend and answer: Exploring question-guided spatial attention for visual question answering (2016) Proceedings of the European Conference on Computer Vision (ECCV); Xu, K., Ba, J., Kiros, R., Cho, K., Courville, A., Salakhudinov, R., Zemel, R., Bengio, Y., Show attend and tell: Neural image caption generation with visual attention (2015) International Conference on Machine Learning, pp. 2048-2057; Yang, L., Tang, K., Yang, J., Li, L.-J., Dense captioning with joint inference and visual context (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Yang, Z., He, X., Gao, J., Deng, L., Smola, A., Stacked attention networks for image question answering (2016) Proc. Of CVPR; Yang, Z., Yuan, Y., Wu, Y., Salakhutdinov, R., Cohen Encode, W.W., Review, and decode: Reviewer module for caption generation (2016) Proc. Of NIPS; You, Q., Jin, H., Wang, Z., Fang, C., Luo, J., Image captioning with semantic attention (2016) Proc. Of CVPR, pp. 4651-4659; Yu, D., Fu, J., Mei, T., Rui, Y., Multi-level attention networks for visual question answering (2017) Proc. Of CVPR; Yu, Y., Ko, H., Choi, J., Kim, G., End-To-end concept word detection for video captioning, retrieval, and question answering (2017) Proc. Of CVPR; Zhu, Y., Groth, O., Bernstein, M., Fei-Fei, L., Visual7W: Grounded question answering in images (2016) Proc. Of CVPR",,,,"IEEE Computer Society","31st Meeting of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2018","18 June 2018 through 22 June 2018",,143811,10636919,9781538664209,PIVRE,,"English","Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85058652903
"Dong Y., Liao F., Pang T., Su H., Zhu J., Hu X., Li J.","57191433539;57194680047;57204799576;37017428500;56734692500;55496159600;55924903000;","Boosting Adversarial Attacks with Momentum",2018,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",,,"8579055","9185","9193",,540,"10.1109/CVPR.2018.00957","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057255236&doi=10.1109%2fCVPR.2018.00957&partnerID=40&md5=61e3786c9a3bafbd97c32e15d979450f","Department of Computer Science and Technology, Tsinghua Lab of Brain and Intelligence, Beijing National Research Center for Information Science and Technology, BNRist Lab, Tsinghua University100084, China; Intel Labs China, China","Dong, Y., Department of Computer Science and Technology, Tsinghua Lab of Brain and Intelligence, Beijing National Research Center for Information Science and Technology, BNRist Lab, Tsinghua University100084, China; Liao, F., Department of Computer Science and Technology, Tsinghua Lab of Brain and Intelligence, Beijing National Research Center for Information Science and Technology, BNRist Lab, Tsinghua University100084, China; Pang, T., Department of Computer Science and Technology, Tsinghua Lab of Brain and Intelligence, Beijing National Research Center for Information Science and Technology, BNRist Lab, Tsinghua University100084, China; Su, H., Department of Computer Science and Technology, Tsinghua Lab of Brain and Intelligence, Beijing National Research Center for Information Science and Technology, BNRist Lab, Tsinghua University100084, China; Zhu, J., Department of Computer Science and Technology, Tsinghua Lab of Brain and Intelligence, Beijing National Research Center for Information Science and Technology, BNRist Lab, Tsinghua University100084, China; Hu, X., Department of Computer Science and Technology, Tsinghua Lab of Brain and Intelligence, Beijing National Research Center for Information Science and Technology, BNRist Lab, Tsinghua University100084, China; Li, J., Intel Labs China, China","Deep neural networks are vulnerable to adversarial examples, which poses security concerns on these algorithms due to the potentially severe consequences. Adversarial attacks serve as an important surrogate to evaluate the robustness of deep learning models before they are deployed. However, most of existing adversarial attacks can only fool a black-box model with a low success rate. To address this issue, we propose a broad class of momentum-based iterative algorithms to boost adversarial attacks. By integrating the momentum term into the iterative process for attacks, our methods can stabilize update directions and escape from poor local maxima during the iterations, resulting in more transferable adversarial examples. To further improve the success rates for black-box attacks, we apply momentum iterative algorithms to an ensemble of models, and show that the adversarially trained models with a strong defense ability are also vulnerable to our black-box attacks. We hope that the proposed methods will serve as a benchmark for evaluating the robustness of various deep models and defense methods. With this method, we won the first places in NIPS 2017 Non-targeted Adversarial Attack and Targeted Adversarial Attack competitions. © 2018 IEEE.",,"Computer vision; Deep neural networks; Momentum; Network security; Black-box model; Ensemble of models; Iterative algorithm; Iterative process; Learning models; Local maximum; Momentum term; Non-targeted; Iterative methods",,,,,"Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy, , 3; Caruana, R., Niculescu-Mizil, A., Crew, G., Ksikes, A., Ensemble selection from libraries of models (2004) ICML, , 4; Dong, Y., Su, H., Zhu, J., Bao, F., (2017) Towards Interpretable Deep Neural Networks by Leveraging Adversarial Examples, , 3; Duch, W., Korczak, J., Optimization and global minimization methods suitable for neural networks (1998) Neural Computing Surveys, 2, pp. 163-212. , 3; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR, , 1, 2, 3; Hansen, L.K., Salamon, P., Neural network ensembles (1990) IEEE Transactions on Pattern Analysis and Machine Intelligence, 12 (10), pp. 993-1001. , 4; He, K., Zhang, X., Ren, S., Sun, J., Identity mappings in deep residual networks (2016) ECCV, , 5; Krogh, A., Vedelsby, J., Neural network ensembles, cross validation and active learning (1994) NIPS, , 4; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , 1, 2, 3; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2017) ICLR, , 1, 2, 3, 8; Li, Y., Gal, Y., Dropout inference in Bayesian neural networks with alpha-divergences (2017) ICML, , 3; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) ICLR, , 1, 2, 3, 4, 6, 7; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., On detecting adversarial perturbations (2017) ICLR, , 3; Moosavi-Dezfooli, S.M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) CVPR, , 1; Pang, T., Du, C., Zhu, J., (2017) Robust Deep Learning Via Reverse Cross-entropy Training and Thresholding Test, , 3; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, , 2; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) IEEE Symposium on Security and Privacy, , 3; Polyak, B.T., Some methods of speeding up the convergence of iteration methods (1964) USSR Computational Mathematics and Mathematical Physics, 4 (5), pp. 1-17. , 3; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Bernstein, M., Imagenet large scale visual recognition challenge (2015) International Journal of Computer Vision, 115 (3), pp. 211-252. , 2, 5; Sutskever, I., Martens, J., Dahl, G., Hinton, G., On the importance of initialization and momentum in deep learning (2013) ICML, , 3; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., Inception-v4, inception-resnet and the impact of residual connections on learning (2017) AAAI, , 5; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) CVPR, , 1, 5; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) ICLR, , 1, 3; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., Mc-Daniel, P., Ensemble adversarial training: Attacks and defenses (2018) ICLR, , 2, 3, 5","Zhu, J.; Department of Computer Science and Technology, China; email: dcszj@mail.tsinghua.edu.cn",,,"IEEE Computer Society","31st Meeting of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2018","18 June 2018 through 22 June 2018",,143811,10636919,9781538664209,PIVRE,,"English","Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85057255236
"Lee K., Xu W., Fan F., Tu Z.","57207757664;57207777778;57207769431;7102010636;","Wasserstein Introspective Neural Networks",2018,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",,,"8578488","3702","3711",,19,"10.1109/CVPR.2018.00390","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055440474&doi=10.1109%2fCVPR.2018.00390&partnerID=40&md5=60bd5c8e57095273d7eab68ff1c70348","University of California San Diego, United States","Lee, K., University of California San Diego, United States; Xu, W., University of California San Diego, United States; Fan, F., University of California San Diego, United States; Tu, Z., University of California San Diego, United States","We present Wasserstein introspective neural networks (WINN) that are both a generator and a discriminator within a single model. WINN provides a significant improvement over the recent introspective neural networks (INN) method by enhancing INN's generative modeling capability. WINN has three interesting properties: (1) A mathematical connection between the formulation of the INN algorithm and that of Wasserstein generative adversarial networks (WGAN) is made. (2) The explicit adoption of the Wasserstein distance into INN results in a large enhancement to INN, achieving compelling results even with a single classifier - e.g., providing nearly a 20 times reduction in model size over INN for unsupervised generative modeling. (3) When applied to supervised classification, WINN also gives rise to improved robustness against adversarial examples in terms of the error reduction. In the experiments, we report encouraging results on unsupervised learning problems including texture, face, and object modeling, as well as a supervised classification task against adversarial attacks. Our code is available online1. © 2018 IEEE.",,"Supervised learning; Textures; Adversarial networks; Error reduction; Generative model; Model size; Object model; Single models; Supervised classification; Wasserstein distance; Computer vision",,,,,"Ackley, D.H., Hinton, G.E., Sejnowski, T.J., A learning algorithm for boltzmann machines (1985) Cognitive Science, 9 (1), pp. 147-169. , 1; Arjovsky, M., Chintala, S., Bottou, L., Wasserstein generative adversarial networks (2017) ICML, , 1, 2, 3, 4, 6, 8; Ba, L.J., Kiros, R., Hinton, G.E., (2016) Layer Normalization, , 7, 8 CoRR, abs/1607. 06450; Baldi, P., Autoencoders, unsupervised learning, and deep architectures (2012) ICML Workshop on Unsupervised and Transfer Learning, pp. 37-49. , 1; Della Pietra, S., Della Pietra, V., Lafferty, J., Inducing features of random fields (1997) IEEE Transactions on Pattern Analysis and Machine Intelligence, 19 (4), pp. 380-393. , 1; Dosovitskiy, A., Springenberg, J.T., Brox, T., Learning to generate chairs with convolutional neural networks (2015) CVPR, , 1; Dumoulin, V., Belghazi, I., Poole, B., Mastropietro, O., Lamb, A., Arjovsky, M., Courville, A., Adversarially learned inference (2017) ICLR, , 6; Freund, Y., Schapire, R.E., A decision-theoretic generalization of on-line learning and an application to boosting (1997) J. of Comp. and Sys. Sci., 55 (1). , 2; Gatys, L., Ecker, A.S., Bethge, M., Texture synthesis using convolutional neural networks (2015) NIPS, , 3, 5, 6; Gatys, L.A., Ecker, A.S., Bethge, M., (2015) A Neural Algorithm of Artistic Style, , 6; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) NIPS, , 1, 3, 7; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, 27, pp. 2672-2680. , Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger, editors Curran Associates, Inc. 2; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR, , 7; Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., Courville, A., Improved training of wasserstein gans (2017) NIPS, , 1, 2, 4, 5, 6, 8; Han, T., Lu, Y., Zhu, S.-C., Wu, Y.N., Alternating backpropagation for generator network (2017) AAAI, , 2; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) CVPR, , 1, 7, 8; Hinton, G.E., Osindero, S., Teh, Y.-W., A fast learning algorithm for deep belief nets (2006) Neural Computation, 18 (7), pp. 1527-1554. , 1; Huang, G., Liu, Z., Van Der Maaten, L., Weinberger, K.Q., Densely connected convolutional networks (2017) CVPR, , 1, 8; Huang, X., Li, Y., Poursaeed, O., Hopcroft, J., Belongie, S., Stacked generative adversarial networks (2017) CVPR, , 6; Isola, P., Zhu, J.-Y., Zhou, T., Efros, A.A., Image-to-image translation with conditional adversarial networks (2017) CVPR, , 5; Jin, L., Lazarow, J., Tu, Z., Introspective classification with convolutional nets (2017) NIPS, , 2, 3, 4, 5, 7, 8; Karras, T., Aila, T., Laine, S., Lehtinen, J., Progressive growing of gans for improved quality, stability, and variation (2018) ICLR, , 8; Kingma, D., Ba, J., Adam: A method for stochastic optimization (2015) ICLR, , 5; Kingma, D.P., Welling, M., Auto-encoding variational bayes (2014) ICLR, , 1; Krizhevsky, A., Nair, V., Hinton, G., Cifar-10 (Canadian Institute for Advanced Research), , 6; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) NIPS, , 1, 6; Kulkarni, T.D., Whitney, W.F., Kohli, P., Tenenbaum, J., Deep convolutional inverse graphics network (2015) NIPS, , 1; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2017) ICLR, , 7; Lazarow, J., Jin, L., Tu, Z., Introspective neural networks for generative modeling (2017) ICCV, , 2, 3, 4, 5, 6; LeCun, Y., Boser, B., Denker, J.S., Henderson, D., Howard, R., Hubbard, W., Jackel, L., Backpropagation applied to handwritten zip code recognition (1989) Neural Computation, , 1; Lee, C.-Y., Xie, S., Gallagher, P., Zhang, Z., Tu, Z., Deeply-supervised nets (2015) AISTATS, , 1; Liu, S., Bousquet, O., Chaudhuri, K., Approximation and convergence properties of generative adversarial learning (2017) NIPS, , 3; Liu, Z., Luo, P., Wang, X., Tang, X., Deep learning face attributes in the wild (2015) ICCV, , 6; Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., Ng, A.Y., Reading digits in natural images with unsupervised feature learning (2011) NIPS Workshop on Deep Learning and Unsupervised Feature Learning, 2011, p. 5. , 6; Ngiam, J., Chen, Z., Koh, P.W., Ng, A.Y., Learning deep energy models (2011) ICML, , 2; Olshausen, B.A., Field, D.J., Sparse coding with an overcomplete basis set: A strategy employed by v1? (1997) Vision research, 37 (23), pp. 3311-3325. , 1; Pinsker, M.S., (1960) Information and Information Stability of Random Variables and Processes., , 8; Radford, A., Metz, L., Chintala, S., Unsupervised representation learning with deep convolutional generative adversarial networks (2016) ICLR, , 1, 6, 7; Ramachandran, P., Zoph, B., Le, Q.V., (2017) Searching for Activation Functions, , 8 CoRR, abs/1710. 05941; Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., Chen, X., Improved techniques for training gans (2016) NIPS, , 6; Sason, I., Verdú, S., F-divergence inequalities (2016) IEEE Transactions on Information Theory, 62 (11), pp. 5973-6006. , 8; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) ICLR, , 1; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) CVPR, , 1; Tu, Z., Learning generative models via discriminative approaches (2007) CVPR, , 1, 2, 3, 5, 7; Ulyanov, D., Lebedev, V., Vedaldi, A., Lempitsky, V., Texture networks: Feed-forward synthesis of textures and stylized images (2016) ICML, , 3, 6; Warde-Farley, D., Bengio, Y., Improving generative adversarial networks with denoising feature matching (2017) ICLR, , 6; Welling, M., Teh, Y.W., Bayesian learning via stochastic gradient langevin dynamics (2011) ICML, , 3, 4; Welling, M., Zemel, R.S., Hinton, G.E., Self supervised boosting (2002) NIPS, , 1, 2; Wu, Y.N., Si, Z., Gong, H., Zhu, S.-C., Learning active basis model for object detection and recognition (2010) International Journal of Computer Vision, 90 (2), pp. 198-235. , 1; Xie, J., Lu, Y., Gao, R., Zhu, S.-C., Wu, Y.N., Cooperative learning of energy-based model and latent variable model via mcmc teaching (2018) AAAI, , 2; Xie, J., Lu, Y., Zhu, S.-C., Wu, Y.N., A theory of generative convnet (2016) ICML, , 2; Xie, S., Girshick, R., Dollár, P., Tu, Z., He, K., Aggregated residual transformations for deep neural networks (2017) CVPR, , 1; Zhu, S.-C., Mumford, D., A stochastic grammar of images (2007) Foundations and Trends R in Computer Graphics and Vision, 2 (4), pp. 259-362. , 1; Zhu, S.C., Wu, Y.N., Mumford, D., Minimax entropy principle and its application to texture modeling (1997) Neural Computation, 9 (8), pp. 1627-1660. , 1",,,,"IEEE Computer Society","31st Meeting of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2018","18 June 2018 through 22 June 2018",,143811,10636919,9781538664209,PIVRE,,"English","Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85055440474
"Eykholt K., Evtimov I., Fernandes E., Li B., Rahmati A., Xiao C., Prakash A., Kohno T., Song D.","57195202771;57207759307;54918888300;57207865075;57076113200;56379538100;7202316627;7201820043;7402443870;","Robust Physical-World Attacks on Deep Learning Visual Classification",2018,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",,,"8578273","1625","1634",,472,"10.1109/CVPR.2018.00175","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051538251&doi=10.1109%2fCVPR.2018.00175&partnerID=40&md5=e4312f4b8273cc013f4d6b893e27c1d0","University of Michigan, Ann Arbor, United States; University of Washington, United States; University of California, Berkeley, United States","Eykholt, K., University of Michigan, Ann Arbor, United States; Evtimov, I., University of Washington, United States; Fernandes, E., University of Washington, United States; Li, B., University of California, Berkeley, United States; Rahmati, A., University of Michigan, Ann Arbor, United States; Xiao, C., University of Michigan, Ann Arbor, United States; Prakash, A., University of Michigan, Ann Arbor, United States; Kohno, T., University of Washington, United States; Song, D., University of California, Berkeley, United States","Recent studies show that the state-of-the-art deep neural networks (DNNs) are vulnerable to adversarial examples, resulting from small-magnitude perturbations added to the input. Given that that emerging physical systems are using DNNs in safety-critical situations, adversarial examples could mislead these systems and cause dangerous situations. Therefore, understanding adversarial examples in the physical world is an important step towards developing resilient learning algorithms. We propose a general attack algorithm, Robust Physical Perturbations (RP2), to generate robust visual adversarial perturbations under different physical conditions. Using the real-world case of road sign classification, we show that adversarial examples generated using RP2 achieve high targeted misclassification rates against standard-architecture road sign classifiers in the physical world under various environmental conditions, including viewpoints. Due to the current lack of a standardized testing method, we propose a two-stage evaluation methodology for robust physical adversarial examples consisting of lab and field tests. Using this methodology, we evaluate the efficacy of physical adversarial manipulations on real objects. With a perturbation in the form of only black and white stickers, we attack a real stop sign, causing targeted misclassification in 100% of the images obtained in lab settings, and in 84.8% of the captured video frames obtained on a moving vehicle (field test) for the target classifier. © 2018 IEEE.",,"Computer vision; Learning algorithms; Roads and streets; Safety engineering; Testing; Traffic signs; Dangerous situations; Environmental conditions; Evaluation methodologies; Misclassification rates; Road sign classifications; Standard architecture; Standardized testing; Visual classification; Deep neural networks",,,,,"Athalye, A., (2017) Robust Adversarial Examples, , https://blog.openai.com/robust-adversarial-inputs/; Athalye, A., Sutskever, I., (2017) Synthesizing Robust Adversarial Examples; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndíc, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 387-402. , Springer; Bou-Ammar, H., Voos, H., Ertel, W., Controller design for quadrotor uavs using reinforcement learning (2010) Control Applications (CCA), pp. 2130-2135. , IEEE, 2010. IEEE International Conference on; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), pp. 39-57. , IEEE, 2017. IEEE Symposium on; Cisse, M., Adi, Y., Neverova, N., Keshet, J., (2017) Houdini: Fooling Deep Structured Prediction Models; Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Song, D., Kohno, T., Rahmati, A., Tramer, F., (2017) Note on Attacking Object Detectors with Adversarial Stickers, , Dec; Geiger, A., Lenz, P., Urtasun, R., Are we ready for autonomous driving? The kitti vision benchmark suite (2012) Computer Vision and Pattern Recognition (CVPR), pp. 3354-3361. , IEEE, 2012. IEEE Conference on; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Kos, J., Fischer, D.I., (2017) Song. Adversarial Examples for Generative Models; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, 25, pp. 1097-1105. , Curran Associates, Inc; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World; Le, Q.V., Zou, W.Y., Yeung, S.Y., Ng, A.Y., Learning hierarchical invariant spatio-temporal features for action recognition with independent subspace analysis (2011) Proceedings of the 2011 IEEE Conference on Computer Vision and Pattern Recognition, CVPR '11, pp. 3361-3368. , Washington, DC, USA. IEEE Computer Society; Li, B., Vorobeychik, Y., Feature cross-substitution in adversarial classification (2014) Advances in Neural Information Processing Systems, pp. 2087-2095; Li, B., Vorobeychik, Y., Scalable optimization of randomized operational decisions in adversarial classification settings (2015) AISTATS; Lillicrap, T.P., Hunt, J.J., Pritzel, A., Heess, N., Erez, T., Tassa, Y., Silver, D., Wierstra, D., (2015) Continuous Control with Deep Reinforcement Learning; Liu, Y., Chen, X., Liu, C., Song, D., (2016) Delving into Transferable Adversarial Examples and Black-box Attacks; Lu, J., Sibai, H., Fabry, E., Forsyth, D., (2017) No Need to Worry about Adversarial Examples in Object Detection in Autonomous Vehicles; Metzen, J.H., Kumar, M.C., Brox, T., Fischer, V., (2017) Universal Adversarial Perturbations Against Semantic Image Segmentation; Mogelmose, A., Trivedi, M.M., Moeslund, T.B., Visionbased traffic sign detection and analysis for intelligent driver assistance systems: Perspectives and survey (2012) Trans. Intell. Transport. Sys., 13 (4), pp. 1484-1497. , Dec; Moosavi-Dezfooli, S., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2016) CoRR, , abs/1610.08401; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., (2015) Deepfool: A Simple and Accurate Method to Fool Deep Neural Networks; Mostegel, C., Rumpler, M., Fraundorfer, F., Bischof, H., Uav-based autonomous image acquisition with multi-view stereo quality assurance by confidence prediction (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, pp. 1-10; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 427-436; Papernot, N., Goodfellow, I., Sheatsley, R., Feinman, R., McDaniel, P., (2016) Cleverhans v1.0.0: An Adversarial Machine Learning Library; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519. , ACM; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), pp. 372-387. , IEEE, 2016. IEEE European Symposium on; Sabour, S., Cao, Y., Faghri, F., Fleet, D.J., (2015) Adversarial Manipulation of Deep Representations; Sermanet, P., LeCun, Y., Traffic sign recognition with multiscale convolutional networks (2011) Neural Networks (IJCNN), the 2011 International Joint Conference on, pp. 2809-2813. , IEEE; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-ofthe-art face recognition (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540. , ACM; Stallkamp, J., Schlipsing, M., Salmen, J., Igel, C., Man vs. Computer: Benchmarking machine learning algorithms for traffic sign recognition (2012) Neural Networks; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2015) CoRR; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations; Taigman, Y., Yang, M., Ranzato, M., Wolf, L., Deepface: Closing the gap to human-level performance in face verification (2014) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1701-1708; Tramèr, F., Zhang, F., Juels, A., Reiter, M.K., Ristenpart, T., Stealing machine learning models via prediction apis (2016) USENIX Security; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., (2017) Adversarial Examples for Semantic Segmentation and Object Detection; Yadav, V., (2016) P2-trafficsigns, , https://github.com/vxy10/p2-TrafficSigns; Zhang, F., Leitner, J., Milford, M., Upcroft, B., Corke, P., (2015) Towards Vision-based Deep Reinforcement Learning for Robotic Motion Control",,,,"IEEE Computer Society","31st Meeting of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2018","18 June 2018 through 22 June 2018",,143811,10636919,9781538664209,PIVRE,,"English","Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit",Conference Paper,"Final","",Scopus,2-s2.0-85051538251
"Hayes J.","57192153560;","On visible adversarial perturbations & digital watermarking",2018,"IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops","2018-June",,"8575371","1678","1685",,19,"10.1109/CVPRW.2018.00210","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060871396&doi=10.1109%2fCVPRW.2018.00210&partnerID=40&md5=f92a2d573aeed6da50047250c1c5ca44","University College London, United Kingdom","Hayes, J., University College London, United Kingdom","Given a machine learning model, adversarial perturbations transform images such that the model's output is classified as an attacker chosen class. Most research in this area has focused on adversarial perturbations that are imperceptible to the human eye. However, recent work has considered attacks that are perceptible but localized to a small region of the image. Under this threat model, we discuss both defenses that remove such adversarial perturbations, and attacks that can bypass these defenses. © 2018 IEEE.",,"Digital watermarking; Learning systems; Human eye; Machine learning models; Small region; Threat modeling; Computer vision",,,,,"Athalye, A., Carlini, N., Wagner, D., (2018) Obfuscated Gradients Give A False Sense of Security: Circumventing Defenses to Adversarial Examples, , arXiv preprint arXiv:1802. 00420; Athalye, A., Sutskever, I., (2017) Synthesizing Robust Adversarial Examples, , arXiv preprint arXiv:1707. 07397; Bastani, O., Ioannou, Y., Lampropoulos, L., Vytiniotis, D., Nori, A., Criminisi, A., Measuring neural net robustness with constraints (2016) Advances in Neural Information Processing Systems, pp. 2613-2621; Bhagoji, A.N., Cullina, D., Mittal, P., (2017) Dimensionality Reduction As A Defense Against Evasion Attacks on Machine Learning Classifiers, , arXiv preprint arXiv:1704. 02654; Brown, T.B., Mané, D., Roy, A., Abadi, M., Gilmer, J., (2017) Adversarial Patch, , arXiv preprint arXiv:1712. 09665; Buckman, J., Roy, A., Raffel, C., Goodfellow, I., Thermometer encoding: One hot way to resist adversarial examples (2018) International Conference on Learning Representations; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 3-14. , ACM; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium on, pp. 39-57. , IEEE; Chen, P.-Y., Sharma, Y., Zhang, H., Yi, J., Hsieh, C.-J., (2017) Ead: Elasticnet Attacks to Deep Neural Networks Via Adversarial Examples, , arXiv preprint arXiv:1709. 04114; Dhillon, G.S., Azizzadenesheli, K., Bernstein, J.D., Kossaifi, J., Khanna, A., Lipton, Z.C., Anandkumar, A., Stochastic activation pruning for robust adversarial defense (2018) International Conference on Learning Representations; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts, , arXiv preprint arXiv:1703. 00410; Gong, Z., Wang, W., Ku, W.-S., (2017) Adversarial and Clean Data Are Not Twins, , arXiv preprint arXiv:1704. 04960; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint arXiv:1412. 6572; Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., (2017) On the (Statistical) Detection of Adversarial Examples, , arXiv preprint arXiv:1702. 06280; Gu, S., Rigazio, L., (2014) Towards Deep Neural Network Architectures Robust to Adversarial Examples, , arXiv preprint arXiv:1412. 5068; Guo, C., Rana, M., Cissé, M., Maaten Der Van, L., (2017) Countering Adversarial Images Using Input Transformations, , arXiv preprint arXiv:1711. 00117; Hendrycks, D., Gimpel, K., (2017) Early Methods for Detecting Adversarial Images; Huang, R., Xu, B., Schuurmans, D., Szepesvári, C., Learning with a strong adversary (2015) ArXiv Preprint arXiv:1511. 03034; Jin, J., Dundar, A., Culurciello, E., (2015) Robust Convolutional Neural Networks under Adversarial Noise, , arXiv preprint arXiv:1511. 06306; Karmon, D., Zoran, D., Goldberg, Y., (2018) Lavan: Localized and Visible Adversarial Noise, , arXiv preprint arXiv:1801. 02608; Li, X., Li, F., (2016) Adversarial Examples Detection in Deep Networks with Convolutional Filter Statistics, , CoRR, abs/1612. 07767, 7; Liang, B., Li, H., Su, M., Li, X., Shi, W., Wang, X., (2017) Detecting Adversarial Examples in Deep Networks with Adaptive Noise Reduction, , arXiv preprint arXiv:1705. 08378; Ma, X., Li, B., Wang, Y., Erfani, S.M., Wijewickrema, S., Schoenebeck, G., Houle, M.E., Bailey, J., Characterizing adversarial subspaces using local intrinsic dimensionality (2018) International Conference on Learning Representations; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , arXiv preprint arXiv:1706. 06083; Moosavi Dezfooli, S.M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Number EPFL-CONF-218057; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387. , IEEE; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Security and Privacy (SP), 2016 IEEE Symposium on, pp. 582-597. , IEEE; Quiring, E., Arp, D., Rieck, K., (2017) Fraternal Twins: Unifying Attacks on Machine Learning and Digital Watermarking, , arXiv preprint arXiv:1703. 05561; Rozsa, A., Rudd, E.M., Boult, T.E., Adversarial diversity and hard positive generation (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, pp. 25-32; Samangouei, P., Kabkab, M., Chellappa, R., Defense-GAN: Protecting classifiers against adversarial attacks using generative models (2018) International Conference on Learning Representations; Shaham, U., Yamada, Y., Negahban, S., (2015) Understanding Adversarial Training: Increasing Local Stability of Neural Nets Through Robust Optimization, , arXiv preprint arXiv:1511. 05432; Simonyan, K., Vedaldi, A., Zisserman, A., (2013) Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps, , arXiv preprint arXiv:1312. 6034; Song, Y., Kim, T., Nowozin, S., Ermon, S., Kushman, N., Pixeldefend: Leveraging generative models to understand and defend against adversarial examples (2018) International Conference on Learning Representations; Springenberg, J.T., Dosovitskiy, A., Brox, T., Riedmiller, M., (2014) Striving for Simplicity: The All Convolutional Net, , arXiv preprint arXiv:1412. 6806; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint arXiv:1312. 6199; Telea, A., An image inpainting technique based on the fast marching method (2004) Journal of Graphics Tools, 9 (1), pp. 23-34; Uesato, J., O'Donoghue, B., Oord A, V.D., Kohli, P., (2018) Adversarial Risk and the Dangers of Evaluating Against Weak Attacks, , arXiv preprint arXiv:1802. 05666; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., Mitigating adversarial effects through randomization (2018) International Conference on Learning Representations; Zeiler, M.D., Fergus, R., Visualizing and understanding convolutional networks (2014) European Conference on Computer Vision, pp. 818-833. , Springer; Zheng, S., Song, Y., Leung, T., Goodfellow, I., Improving the robustness of deep neural networks via stability training (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4480-4488","Hayes, J.; University College LondonUnited Kingdom; email: j.hayes@cs.ucl.ac.uk",,,"IEEE Computer Society","31st Meeting of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, CVPRW 2018","18 June 2018 through 22 June 2018",,143792,21607508,9781538661000,,,"English","IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recogn. Workshops",Conference Paper,"Final","",Scopus,2-s2.0-85060871396
[No author name available],[No author id available],"Proceedings - 2018 15th Conference on Computer and Robot Vision, CRV 2018",2018,"Proceedings - 2018 15th Conference on Computer and Robot Vision, CRV 2018",,,,"","",407,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060544136&partnerID=40&md5=930c1faa276dd18805d70abf21b02540",,"","The proceedings contain 50 papers. The topics discussed include: real-time deep hair matting on mobile devices; occluded leaf matching with full leaf databases using explicit occlusion modeling; deep autoencoders with aggregated residual transformations for urban reconstruction from remote sensing data; real-time end-to-end action detection with two-stream networks; generalized Hadamard-product fusion operators for visual question answering; on the robustness of deep learning models to universal adversarial attack; real-time 3D face verification with a consumer depth camera; hierarchical feature map characterization in fashion interpretation; and a hierarchical deep architecture and mini-batch selection method for joint traffic sign and light detection.",,,,,,,,,,"Canadian Image Processing and Pattern Recognition Society /Association Canadienne de Traitement d�Images et de Reconnaissance des Formes (CIPPRS/ACTIRF);ELEMENT;EPSON, Exceed your vision;et al.;MDA;York University, Centre for Vision Research","Institute of Electrical and Electronics Engineers Inc.","15th Conference on Computer and Robot Vision, CRV 2018","9 May 2018 through 11 May 2018",,143745,,9781538664810,,,"English","Proc. - Conf. Comput. Robot Vis., CRV",Conference Review,"Final","",Scopus,2-s2.0-85060544136
"Karim R., Islam M.A., Mohammed N., Bruce N.D.B.","55407386600;57214493814;23025118200;8347469300;","On the robustness of deep learning models to universal adversarial attack",2018,"Proceedings - 2018 15th Conference on Computer and Robot Vision, CRV 2018",,,"8575736","55","62",,3,"10.1109/CRV.2018.00018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060520553&doi=10.1109%2fCRV.2018.00018&partnerID=40&md5=426bea1bef4505908bb6e3bb65f8f7d8","Department of Computer Science, University of Manitoba, Winnipeg, MB, Canada; Department of Computer Science, Ryerson University, Toronto, ON, Canada","Karim, R., Department of Computer Science, University of Manitoba, Winnipeg, MB, Canada; Islam, M.A., Department of Computer Science, University of Manitoba, Winnipeg, MB, Canada; Mohammed, N., Department of Computer Science, University of Manitoba, Winnipeg, MB, Canada; Bruce, N.D.B., Department of Computer Science, Ryerson University, Toronto, ON, Canada","In recent years, there have been significant advances in deep learning applied to problems in high-level vision tasks (e.g. image classification, object detection, semantic segmentation etc.) which has been met with a great deal of success. State-of-the-art methods that have shown impressive results on recognition tasks typically share a common structure involving stage-wise encoding of the image, followed by a generic classifier. However, these architectures have been shown to be vulnerable to the adversarial perturbations which may undermine the security of the systems supported by deep neural nets. In this work, initially we present rigorous evaluation of adversarial attacks on recent deep learning models for two different high-level tasks (image classification and semantic segmentation). Then we propose a model and dataset independent approach to generate adversarial perturbation and also the transferability of perturbation across different datasets and tasks. Moreover, we analyze the effect of different network architectures which will aid future efforts in understanding and defending against adversarial perturbations. We perform comprehensive experiments on several standard image classification and segmentation datasets to demonstrate the effectiveness of our proposed approach. © 2018 IEEE.","Adverserial Perturbation; Image Classification; Semantic Segmentation; Transferability of Perturbation","Classification (of information); Computer vision; Deep neural networks; Image segmentation; Network architecture; Object detection; Semantics; Adverserial Perturbation; Common structures; Generic classifier; High-level visions; Rigorous evaluation; Semantic segmentation; State-of-the-art methods; Transferability of Perturbation; Image classification",,,,,"Arnab, A., Miksik, O., Torr, P.H., (2017) On the Robustness of Semantic Segmentation Models to Adversarial Attacks.; Chen, L.-C., Papandreou, G., Kokkinos, I., Murphy, K., Yuille, A.L., Semantic image segmentation with deep convolutional nets and fully connected crfs (2015) ICLR, 7; Chen, L.-C., Papandreou, G., Kokkinos, I., Murphy, K., Yuille, A.L., (2016) Deeplab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected Crfs., 7; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., Imagenet: A large-scale hierarchical image database (2009) Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pp. 248-255. , IEEE; Everingham, M., Van Gool, L., Williams, C.K.I., Winn, J., Zisserman, A., (2012) The PASCAL Visual Object Classes Challenge, 5, p. 7. , (VOC2012) Results; Girshick, R., Fast r-cnn (2015) Proceedings of the IEEE International Conference on Computer Vision, pp. 1440-1448; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples.; He, K., Gkioxari, G., Dolĺar, P., Girshick, R., (2017) Mask R-cnn.; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Hendrik Metzen, J., Chaithanya Kumar, M., Brox, T., Fischer, V., Universal adversarial perturbations against semantic image segmentation (2017) CVPR; Huang, G., Liu, Z., Weinberger, K.Q., Van Der Maaten, L., (2016) Densely Connected Convolutional Networks.; Islam, M.A., Rochan, M., Bruce, N.D., Wang, Y., Gated feedback refinement network for dense image labeling (2017) 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4877-4885. , IEEE; Janai, J., Güney, F., Behl, A., Geiger, A., (2017) Computer Vision for Autonomous Vehicles: Problems, Datasets and State-of-theart.; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World.; Long, J., Shelhamer, E., Darrell, T., Fully convolutional networks for semantic segmentation (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3431-3440; Lu, J., Sibai, H., Fabry, E., Forsyth, D., (2017) No Need to Worry about Adversarial Examples in Object Detection in Autonomous Vehicles.; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., (2016) Universal Adversarial Perturbations.; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582. , 2, 4, 5; Mopuri, K.R., Garg, U., Babu, R.V., (2017) Fast Feature Fool: A Data Independent Approach to Universal Adversarial Perturbations., , 3, 4, 5; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 427-436; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Security and Privacy (SP), 2016 IEEE Symposium on, pp. 582-597. , IEEE; Ren, S., He, K., Girshick, R., Sun, J., Faster r-cnn: Towards real-time object detection with region proposal networks (2015) Advances in Neural Information Processing Systems, pp. 91-99; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on stateof-The-art face recognition (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540. , ACM; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition.; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks.; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., Adversarial examples for semantic segmentation and object detection (2017) ICCV; Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J., (2016) Pyramid Scene Parsing Network., 5, p. 7",,,"Canadian Image Processing and Pattern Recognition Society /Association Canadienne de Traitement d�Images et de Reconnaissance des Formes (CIPPRS/ACTIRF);ELEMENT;EPSON, Exceed your vision;et al.;MDA;York University, Centre for Vision Research","Institute of Electrical and Electronics Engineers Inc.","15th Conference on Computer and Robot Vision, CRV 2018","9 May 2018 through 11 May 2018",,143745,,9781538664810,,,"English","Proc. - Conf. Comput. Robot Vis., CRV",Conference Paper,"Final","",Scopus,2-s2.0-85060520553
"Li Y., Abdel-Khalik H.S., Bertino E.","57196442761;8575537300;7102307605;","Analysis of Adversarial Learning of Reactor State",2018,"2018 IEEE International Symposium on Technologies for Homeland Security, HST 2018",,,"8574137","","",,1,"10.1109/THS.2018.8574137","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060490553&doi=10.1109%2fTHS.2018.8574137&partnerID=40&md5=ae252506522ec0a704f5438ec4e5ac57","School of Nuclear Engeering, Purdue University, West Lafayette, IN, United States; Department of Computer Science, Purdue University, West Lafayette, IN, United States","Li, Y., School of Nuclear Engeering, Purdue University, West Lafayette, IN, United States; Abdel-Khalik, H.S., School of Nuclear Engeering, Purdue University, West Lafayette, IN, United States; Bertino, E., Department of Computer Science, Purdue University, West Lafayette, IN, United States","With the recent successful attack attempts against the digital control systems of critical infrastructures, there is a need to develop new defense strategies that take into account two important realities: state-sponsored attackers can rely on a number of techniques including espionage, social engineering, and brute force techniques, etc. to gain access to the raw data used to control system behavior; and attackers can falsify operational data in manners that do not trigger conventional outlier/anomaly detection techniques in order to remain undetected, which is referred to as false data injection attacks. This paper explores the use of model-based techniques which have been recently promoted as potential approach for identifying data injection attacks. Specifically, we explore whether attackers can emulate the predictions of the models used by the defender. For demonstration, we employ a simplified point kinetics models with a number of unknown parameters and explore how inference techniques may be used to fully determine the dynamical behavior of the system. Results indicate that attackers can emulate the model predictions with high accuracy, indicating that the brute force application of model-based defenses is not effective and must be supplemented by other defense measures. © 2018 IEEE.","False data injection; Physics guided model; Signature building","Digital control systems; National security; Security systems; Adversarial learning; Detection techniques; Dynamical behaviors; False data injection; False data injection attacks; Inference techniques; Model based techniques; Point-kinetics models; Network security",,,,,"Urbina, D., Limiting the impact of stealthy attacks on industrial control systems (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1092-1105. , 24 October; Hashemian, H.M., (2006) Maintenance of Process Instrumentation in Nuclear Power Plants, pp. 68-73. , Springer, 2. Oxford: Clarendon, 1892; Breiman, L., Friedman, J.H., Estimating optimal transformations multiple regression and correlation (1985) Journal of the American Statistical Association, 80 (391). , September Theory and Method; Zarei, M., Ghaderi, R., Minuchehr, A., Progress in nuclear energy space independent xenon oscillations control in vver reactor-: A bifurcation analysis approach (2016) Progress in Nuclear Energy, 88, pp. 19-27; Li, Y., Bertino, E., Abdel-Khalik, H., Non-parametric based inverse approach of nuclear reactor dynamic behavior Proceedings of the PHYSOR 2018, Cancun, Mexico; Touran, N.W., (2012), https://github.com/partofthething/ace",,,,"Institute of Electrical and Electronics Engineers Inc.","2018 IEEE International Symposium on Technologies for Homeland Security, HST 2018","23 October 2018 through 24 October 2018",,143654,,9781538634431,,,"English","IEEE Int. Symp. Technol. Homel. Secur., HST",Conference Paper,"Final","",Scopus,2-s2.0-85060490553
"Shi Y., Sagduyu Y.E., Davaslioglu K., Li J.H.","36141159700;6507416617;36343287800;37100868400;","Active Deep Learning Attacks under Strict Rate Limitations for Online API Calls",2018,"2018 IEEE International Symposium on Technologies for Homeland Security, HST 2018",,,"8574124","","",,11,"10.1109/THS.2018.8574124","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060475709&doi=10.1109%2fTHS.2018.8574124&partnerID=40&md5=bfdbc6bab5499c95da8e56d27085cf80","Intelligent Automation, Inc, Rockville, MD  20855, United States","Shi, Y., Intelligent Automation, Inc, Rockville, MD  20855, United States; Sagduyu, Y.E., Intelligent Automation, Inc, Rockville, MD  20855, United States; Davaslioglu, K., Intelligent Automation, Inc, Rockville, MD  20855, United States; Li, J.H., Intelligent Automation, Inc, Rockville, MD  20855, United States","Machine learning has been applied to a broad range of applications and some of them are available online as application programming interfaces (APIs) with either free (trial) or paid subscriptions. In this paper, we study adversarial machine learning in the form of back-box attacks on online classifier APIs. We start with a deep learning based exploratory (inference) attack, which aims to build a classifier that can provide similar classification results (labels) as the target classifier. To minimize the difference between the labels returned by the inferred classifier and the target classifier, we show that the deep learning based exploratory attack requires a large number of labeled training data samples. These labels can be collected by calling the online API, but usually there is some strict rate limitation on the number of allowed API calls. To mitigate the impact of limited training data, we develop an active learning approach that first builds a classifier based on a small number of API calls and uses this classifier to select samples to further collect their labels. Then, a new classifier is built using more training data samples. This updating process can be repeated multiple times. We show that this active learning approach can build an adversarial classifier with a small statistical difference from the target classifier using only a limited number of training data samples. We further consider evasion and causative (poisoning) attacks based on the inferred classifier that is built by the exploratory attack. Evasion attack determines samples that the target classifier is likely to misclassify, whereas causative attack provides erroneous training data samples to reduce the reliability of the re-trained classifier. The success of these attacks show that adversarial machine learning emerges as a feasible threat in the realistic case with limited training data. © 2018 IEEE.","Active learning; Adversarial machine learning; Causative attack.; Deep learning; Evasion attack; Exploratory attack","Application programming interfaces (API); Artificial intelligence; Classification (of information); E-learning; Learning algorithms; National security; Security systems; Active Learning; Causative attack; Classification results; Evasion attack; Exploratory attack; Labeled training data; Limited training data; Statistical differences; Deep learning",,,,,"Cloud Vision API, , https://cloud.google.com/vision; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint arXiv:1412.6572; Barreno, M., Nelson, B., Sears, R., Joseph, A., Tygar, J., Can machine learning be secure? (2006) ACM Symposium on Information, Computer and Communications Security, , Taipei, Taiwan, Mar; Tramer, F., Zhang, F., Juels, A., Reiter, M., Ristenpart, T., Stealing machine learning models via prediction APIs (2016) USENIX Security Symposium, , Austin, TX, Aug; Shi, Y., Sagduyu, Y.E., Davaslioglu, K., Levy, R., Vulnerability detection and analysis in adversarial deep learning (2018) Guide to Vulnerability Analysis for Computer Networks and Systems: An Artificial Intelligence Approach, pp. 235-258. , S. Parkinson, A. Crampton, R. Hill, Eds. Springer; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z., Swami, A., Practical black-box attacks against deep learning systems using adversarial examples (2017) ACM Conference on Computer and Communications Security (CCS), , Dallas, TX, Oct.-Nov; Shi, Y., Sagduyu, Y.E., Grushin, A., How to steal a machine learning classifier with deep learning (2017) IEEE Symposium on Technologies for Homeland Security (HST), , Boston, MA, Apr; Ateniese, G., Mancini, L., Spognardi, A., Villani, A., Vitali, D., Felici, G., Hacking smart machines with smarter ones: How to extract meaningful data from machine learning classifiers (2015) International Journal of Security and Networks, 10 (3), pp. 137-150; Fredrikson, M., Jha, S., Ristenpart, T., Model inversion attacks that exploit confidence information and basic countermeasures (2015) ACM SIGSAC Conference on Computer and Communications Security, , Denver, CO, Oct; Tramer, F., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2017) The Space of Transferable Adversarial Examples, , ArXiv e-prints arXiv:1704.03453; Shi, Y., Sagduyu, Y.E., Erpek, T., Davaslioglu, K., Lu, Z., Li, J., Adversarial deep learning for cognitive radio security: Jamming attack and defense strategies (2018) IEEE International Conference on Communications (ICC) Workshop on Promises and Challenges of Machine Learning in Communication Networks, , Kansas City, MO, May; Erpek, T., Sagduyu, Y.E., Shi, Y., (2018) Deep Learning for Launching and Mitigating Wireless Jamming Attacks, , arXiv preprint arXiv:1807.02567; Shi, Y., Sagduyu, Y.E., Evasion and causative attacks with adversarial deep learning (2017) IEEE Military Communications Conference (MILCOM), , Baltimore, MD, Oct; Davaslioglu, K., Sagduyu, Y.E., Generative adversarial learning for spectrum sensing (2018) IEEE International Conference on Communications (ICC), , Kansas City, MO, May; DatumBox Machine Learning API, , http://www.datumbox.com/machine-learning-api/; Pi, L., Lu, Z., Sagduyu, Y., Chen, S., Defending active learning against adversarial inputs in automated document classification (2016) IEEE Global Conference on Signal and Information Processing (GlobalSIP), , Washington, D.C, Dec; Settles, B., Active learning (2012) Synthesis Lectures on Artificial Intelligence and Machine Learning, Morgan &Claypool Publishers, 6, pp. 1-114; Savas, O., Sagduyu, Y.E., Deng, J., Li, J., Tactical big data analytics: Challenges, use cases, and solutions (2014) ACM SIGMETRICS Performance Evaluation Review, 41 (4), pp. 86-89. , March; El Jamous, Z., Soltani, S., Sagduyu, Y.E., Li, J.H., RADAR: An automated system for near real-time detection and diversion of malicious network traffic (2016) IEEE Symposium on Technologies for Homeland Security (HST), , Bosto, MA, May; Cheng, Y., Sagduyu, Y.E., Deng, J., Li, J., Liu, P., Integrated situational awareness for cyber-attack detection, analysis, and mitigation (2012) SPIE Defense, Security and Sensing Conference, , Baltimore, MD, Apr; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Srndic, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML-PKDD), , Prague, Czech Republic, Sept; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint arXiv:1607.02533; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2016) IEEE European Symposium on Security and Privacy, , Saarbrucken, Germany, Mar; Mozaffari-Kermani, M., Sur-Kolay, S., Raghunathan, A., Jha, N.K., Systematic poisoning attacks on and defenses for machine learning in healthcare (2015) IEEE Journal of Biomedical and Health Informatics, 19 (6), pp. 1893-1905. , Nov; Biggio, B., Nelson, B., Laskov, P., Poisoning attacks against support vector machines International Conference on Machine Learning (ICML), Edinburgh, Scotland, June 26-July 1, 2012; Alfeld, S., Zhu, X., Barford, P., Data poisoning attacks against autoregressive models (2016) AAAI Conference on Artificial Intelligence, , Phoenix, AZ, Feb; Shi, Y., Erpek, T., Sagduyu, Y.E., Li, J., Spectrum data poisoning with adversarial deep learning (2018) IEEE Military Communications Conference (MILCOM), , Los Angeles, CA, Oct; Microsoft Cognitive Toolkit (CNTK), , https://docs.microsoft.com/en-us/cognitive-toolkit",,,,"Institute of Electrical and Electronics Engineers Inc.","2018 IEEE International Symposium on Technologies for Homeland Security, HST 2018","23 October 2018 through 24 October 2018",,143654,,9781538634431,,,"English","IEEE Int. Symp. Technol. Homel. Secur., HST",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85060475709
"Ferdowsi A., Challita U., Saad W., Mandayam N.B.","57194340613;56266966900;57203259001;7006046302;","Robust Deep Reinforcement Learning for Security and Safety in Autonomous Vehicle Systems",2018,"IEEE Conference on Intelligent Transportation Systems, Proceedings, ITSC","2018-November",,"8569635","307","312",,45,"10.1109/ITSC.2018.8569635","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060489935&doi=10.1109%2fITSC.2018.8569635&partnerID=40&md5=54058218be0ff29663a8f505c4550d50","Wireless at VT, Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, United States; Ericsson Research, Stockholm, Sweden; WINLAB, Dept. of ECE, Rutgers University, New Brunswick, NJ, United States","Ferdowsi, A., Wireless at VT, Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, United States; Challita, U., Ericsson Research, Stockholm, Sweden; Saad, W., Wireless at VT, Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, United States; Mandayam, N.B., WINLAB, Dept. of ECE, Rutgers University, New Brunswick, NJ, United States","The dependence of autonomous vehicles (AVs) on sensors and communication links exposes them to cyber-physical (CP) attacks by adversaries that seek to take control of the AVs by manipulating their data. In this paper, the state estimation process for monitoring AV dynamics, in presence of CP attacks, is analyzed and a novel adversarial deep reinforcement learning (RL) algorithm is proposed to maximize the robustness of AV dynamics control to CP attacks. The attacker's action and the AV's reaction to CP attacks are studied in a game-theoretic framework. In the formulated game, the attacker seeks to inject faulty data to AV sensor readings so as to manipulate the inter-vehicle optimal safe spacing and potentially increase the risk of AV accidents or reduce the vehicle flow on the roads. Meanwhile, the AV, acting as a defender, seeks to minimize the deviations of spacing so as to ensure robustness to the attacker's actions. Since the AV has no information about the attacker's action and due to the infinite possibilities for data value manipulations, each player uses long short term memory (LSTM) blocks to learn the expected spacing deviation resulting from its own action and feeds this deviation to a reinforcement learning (RL) algorithm. Then, the attacker's RL algorithm chooses the action which maximizes the spacing deviation, while the AV's RL algorithm seeks to find the optimal action that minimizes such deviation. Simulation results show that the proposed adversarial deep RL algorithm can improve the robustness of the AV dynamics control as it minimizes the intra-AV spacing deviation. © 2018 IEEE.",,"Accidents; Deep learning; Dynamics; Game theory; Intelligent systems; Intelligent vehicle highway systems; Learning algorithms; Long short-term memory; Reinforcement learning; Robust control; Robustness (control systems); Vehicles; Autonomous Vehicles; Cyber physicals; Data values; Estimation process; Game-theoretic; Optimal actions; Sensor readings; Vehicle flow; Vehicle to vehicle communications",,,,,"Ferdowsi, A., Challita, U., Saad, W., (2017) Deep Learning for Reliable Mobile Edge Analytics in Intelligent Transportation Systems, , arXiv preprint arXiv:1712. 04135; Mozaffari, M., Saad, W., Bennis, M., Debbah, M., Unmanned aerial vehicle with underlaid device-to-device communications: Performance and tradeoffs (2016) IEEE Transactions on Wireless Communications, 15 (6), pp. 3949-3963. , June; Zeng, T., Semiari, O., Saad, W., Bennis, M., (2018) Joint Communication and Control for Wireless Autonomous Vehicular Platoon Systems, , arXiv preprint arXiv:1804. 05290; Kargl, F., Papadimitratos, P., Buttyan, L., Mter, M., Schoch, E., Wiedersheim, B., Thong, T.V., Hubaux, J.P., Secure vehicular communication systems: Implementation, performance, and research challenges (2008) IEEE Communications Magazine, 46 (11), pp. 110-118. , November; Ferdowsi, A., Saad, W., Mandayam, N.B., (2017) Colonel Blotto Game for Secure State Estimation in Interdependent Critical Infrastructure, , arXiv preprint arXiv:1709. 09768; Ferdowsi, A., Saad, W., Maham, B., Mandayam, N.B., A Colonel Blotto game for interdependence-aware cyber-physical systems security in smart cities (2017) Proceedings of the 2nd International Workshop on Science of Smart City Operations and Platforms Engineering, Ser. SCOPE '17. Pittsburgh, Pennsylvania: ACM, pp. 7-12; Kleberger, P., Olovsson, T., Jonsson, E., Security aspects of the in-vehicle network in the connected car (2011) Proc. of IEEE Intelligent Vehicles Symposium (IV), pp. 528-533. , Baden-Baden, Germany, June; Woo, S., Jo, H.J., Lee, D.H., A practical wireless attack on the connected car and security protocol for in-vehicle can (2015) IEEE Transactions on Intelligent Transportation Systems, 16 (2). , April; Chaudhry, H., Bohn, T., Security concerns of a plug-in vehicle Proceedings of IEEE PES Innovative Smart Grid Technologies (ISGT), pp. 1-6. , Washington, DC, USA, Jan 2012; Studnia, I., Nicomette, V., Alata, E., Deswarte, Y., Kaniche, M., Laarouchi, Y., Survey on security threats and protection mechanisms in embedded automotive networks (2013) Proc. of IEEE/IFIP Conference on Dependable Systems and Networks Workshop (DSN-W), pp. 1-12. , Budapest, Hungary, June; Kim, T., Studer, A., Dubey, R., Zhang, X., Perrig, A., Bai, F., Bellur, B., Iyer, A., Vanet alert endorsement using multi-source filters (2010) Proceedings of the Seventh ACM International Workshop on VehiculAr InterNETworking, pp. 51-60. , Chicago, IL, USA, September; Sun, M., Li, M., Gerdes, R., A data trust framework for vanets enabling false data detection and secure vehicle tracking (2017) Proc. of IEEE Conference on Communications and Network Security (CNS), pp. 1-9. , Las Vegas, NV, USA, Oct; Petrillo, A., Pescap, A., Santini, S., A collaborative approach for improving the security of vehicular scenarios: The case of platooning (2018) Computer Communications, 122, pp. 59-75; Tuohy, S., Glavin, M., Hughes, C., Jones, E., Trivedi, M., Kilmartin, L., Intra-vehicle networks: A review (2015) IEEE Transactions on Intelligent Transportation Systems, 16 (2), pp. 534-545. , April; Calandriello, G., Papadimitratos, P., Hubaux, J.P., Lioy, A., On the performance of secure vehicular communication systems (2011) IEEE Transactions on Dependable and Secure Computing, 8 (6), pp. 898-912. , Nov; Brackstone, M., McDonald, M., Car-following: A historical review (1999) Transportation Research Part F: Traffic Psychology and Behaviour, 2 (4), pp. 181-196; Dorf, R.C., Bishop, R.H., (2011) Modern Control Systems, , Pearson; Han, Z., Niyato, D., Saad, W., Başar, T., Hjørungnes, A., (2012) Game Theory in Wireless and Communication Networks: Theory, Models, and Applications, , Cambridge University Press; Ferdowsi, A., Challita, U., Saad, W., Mandayam, N.B., (2018) Robust Deep Reinforcement Learning for Security and Safety in Autonomous Vehicle Systems, , arXiv preprint arXiv:1805. 00983; Başar, T., Olsder, G.J., Dynamic noncooperative game theory (1998) SIAM; Heinrich, J., Silver, D., (2016) Deep Reinforcement Learning from Self-play in Imperfect-information Games, , arXiv preprint arXiv:1603. 01121; Ferdowsi, A., Saad, W., (2018) Deep Learning for Signal Authentication and Security in Massive Internet of Things Systems, , arXiv preprint arXiv:1803. 00916; Chen, M., Challita, U., Saad, W., Yin, C., Debbah, M., (2017) Machine Learning for Wireless Networks with Artificial Intelligence: A Tutorial on Neural Networks, , arXiv preprint arXiv:1710. 02913; Graves, A., Mohamed, A.R., Hinton, G., Speech recognition with deep recurrent neural networks (2013) Proc. of IEEE International Conference on Acoustics, Speech and Signal Processing, , May",,,,"Institute of Electrical and Electronics Engineers Inc.","21st IEEE International Conference on Intelligent Transportation Systems, ITSC 2018","4 November 2018 through 7 November 2018",,143575,,9781728103235,,,"English","IEEE Conf Intell Transport Syst Proc ITSC",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85060489935
"Danger J.-L., Guilley S., Heuser A., Legay A., Ming T.","7003282713;55919930400;53879784400;56271160800;55727630600;","Physical security versus masking schemes",2018,"Cyber-Physical Systems Security",,,,"269","284",,2,"10.1007/978-3-319-98935-8_13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063927638&doi=10.1007%2f978-3-319-98935-8_13&partnerID=40&md5=0e6ad2d412703056010b73fb49f44fbc","Télécom ParisTech, Paris, France; Secure-IC S.A.S., Cesson-Sévigné, France; Secure-IC, Paris, France; École normale supérieure, Paris, France; CNRS, IRISA, Rennes, France; Wuhan University, Wuhan, China","Danger, J.-L., Télécom ParisTech, Paris, France, Secure-IC S.A.S., Cesson-Sévigné, France; Guilley, S., Télécom ParisTech, Paris, France, Secure-IC, Paris, France, École normale supérieure, Paris, France; Heuser, A., CNRS, IRISA, Rennes, France; Legay, A., CNRS, IRISA, Rennes, France; Ming, T., Wuhan University, Wuhan, China","Numerous masking schemes have been designed as provable countermeasures against side-channel attacks. However, currently, several side-channel attack models coexist, such as ""probing"" and ""bounded moment"" models, at bit or word levels. From a defensive standpoint, it is thus unclear which protection strategy is the most relevant to adopt. In this survey article, we review adversarial hypotheses and challenge masking schemes with respect to practical attacks. In a view to explain in a pedagogical way how to secure implementations, we highlight the key aspects to be considered when implementing a masking scheme. © Springer Nature Switzerland AG 2018.",,"Masking schemes; Physical security; Protection strategy; Secure implementation; Word level; Side channel attack",,,,,"Balasch, J., Faust, S., Gierlichs, B., Inner product masking revisited (2015) Advances in Cryptology-EUROCRYPT 2015-34th Annual International Conference on the Theory and Applications of Cryptographic Techniques, Sofia, Bulgaria, April 26-30, 2015, Proceedings, Part I. Lecture Notes in Computer Science, 9056, pp. 486-510. , ed. by E. Oswald, M. Fischlin (Springer, Berlin); Balasch, J., Faust, S., Gierlichs, B., Paglialonga, C., Standaert, F.-X., Consolidating inner product masking (2017) Advances in Cryptology-ASIACRYPT 2017-23rd International Conference on the Theory and Applications of Cryptology and Information Security, Hong Kong, China, December 3-7, 2017, Proceedings, Part I. Lecture Notes in Computer Science, pp. 724-754. , ed. by T. Takagi, T. Peyrin (Springer, Berlin); Bhasin, S., Guilley, S., Sauvage, L., Danger, J.-L., Unrolling cryptographic circuits: a simple countermeasure against side-channel attacks (2010) Topics in Cryptology-CT-RSA 2010, The Cryptographers' Track at the RSA Conference 2010, San Francisco, CA, USA, March 1-5, 2010. Proceedings. Lecture Notes in Computer Science, 5985, pp. 195-207. , ed. by J. Pieprzyk (Springer, Berlin); Bhasin, S., Danger, J.-L., Guilley, S., Najm, Z., Side-channel leakage and trace compression using normalized inter-class variance (2014) Proceedings of the Third Workshop on Hardware and Architectural Support for Security and Privacy, HASP '14, pp. 7:1-7:9. , (ACM, New York); Blömer, J., Guajardo, J., Krummel, V., Provably secure masking of AES (2004) Selected Areas in Cryptography. Lecture Notes in Computer Science, 3357, pp. 69-83. , ed. by H. Handschuh, M.A. Hasan (Springer, Berlin); Bringer, J., Carlet, C., Chabanne, H., Guilley, S., Maghrebi, H., (2014) WISTP International Conference on Information Security Theory and Practice. Lecture Notes in Computer Science, 8501, pp. 40-56. , http://eprint.iacr.org/2014/665/, Orthogonal direct sum masking: a smartcard friendly computation paradigm in a code, with builtin protec tion against side-channel and fault attacks. Cryptology ePrint Archive, Report 2014/665, 2014. (extended version of conference paper (J. Bringer, C. Carlet, H. Chabanne, S. Guilley, H. Maghrebi, Orthogonal direct sum masking-a smartcard friendly computation paradigm in a code, with builtin protection against side-channel and fault attacks, (Springer, Berlin) Heraklion, Greece; Carlet, C., Guilley, S., Statistical properties of side-channel and fault injection attacks using coding theory (2018) Cryptogr. Commun, 10 (5), pp. 909-933. , https://doi.org/10.1007/s12095-017-0271-4; Coron, J.-S., Higher order masking of look-up tables (2014) Annual International Conference on the Theory and Applications of Cryptographic Techniques, EUROCRYPT. Lecture Notes in Computer Science, 8441, pp. 441-458. , ed. by P.Q. Nguyen, E. Oswald (Springer, Berlin); Danger, J.-L., Guilley, S., Nguyen, P., Nguyen, R., Souissi, Y., Analyzing security breaches of countermeasures throughout the refinement process in hardware design flow (2017) Design, Automation & Test in Europe Conference & Exhibition, DATE 2017, pp. 1129-1134. , Lausanne, Switzerland, March 27-31, 2017. ed. by D. Atienza, G. Di Natale (IEEE, Piscataway); Easter, R.J., Quemard, J.-P., Kondo, J., Text for ISO/IEC 1st CD 17825-Information technology-Security techniques-Non-invasive attack mitigation test metrics for cryptographic modules, March 22 2014. Prepared within ISO/IEC JTC 1/SC 27/WG 3 http://www.iso.org/iso/iso_catalogue/catalogue_tc/catalogue_detail.htm?csnumber=60612; Guilley, S., Heuser, A., Rioul, O., Codes for side-channel attacks and protections (2017) Codes, Cryptology and Information Security-Second International Conference, C2SI 2017, Rabat, pp. 35-55. , Morocco, April 10-12, 2017, Proceedings-In Honor of Claude Carlet. Lecture Notes in Computer Science ed. by S. El Hajji, A. Nitaj, E.M. Souidi (Springer, Berlin), 10194; Ishai, Y., Sahai, A., Wagner, D., Private circuits: securing hardware against probing attacks (2003) Annual International Cryptology Conference, CRYPTO. Lecture Notes in Computer Science, 2729, pp. 463-481. , (Springer, Berlin). Santa Barbara, California; Mangard, S., Oswald, E., Popp, T., (2006) Power Analysis Attacks: Revealing the Secrets of Smart Cards, , http://www.springer.com/,http://www.dpabook.org/, (Springer, Berlin); Moradi, A., Guilley, S., Heuser, A., Detecting hidden leakages (2014) Applied Cryptography and Network Security. 12th International Conference on Applied Cryptography and Network Security, (8479). , ed. by I. Boureanu, P. Owesarski, S. Vaudenay (Springer, Berlin), Lausanne, Switzerland; (1999), http://csrc.nist.gov/publications/fips/fips46-3/fips46-3.pdf, FIPS PUB 46-3, Oct; (2001), http://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.197.pdf, FIPS PUB 197, Nov (also ISO/IEC 18033-3:2010); Papagiannopoulos, K., Veshchikov, N., Mind the gap: towards secure 1st-order masking in software (2017) Constructive Side-Channel Analysis and Secure Design: 8th International Workshop, Paris, France, COSADE, , (Springer, Berlin); Poussier, R., Guo, Q., Standaert, F.-X., Carlet, C., Guilley, S., Connecting and improving direct sum masking and inner product masking (2017) Smart Card Research and Advanced Applications-16th International Conference, CARDIS 2017, Lugano, Switzerland, November 13-15, 2017, Revised Selected Papers, , ed. by Y. Teglia, T. Eisenbarth. Lecture Notes in Computer Science (Springer, Berlin); Poussier, R., Guo, Q., Standaert, F.-X., Carlet, C., Guilley, S., Connecting and improving direct sum masking and inner product masking (2017) Smart Card Research and Advanced Applications-16th International Conference, CARDIS 2017, Lugano, Switzerland, November 13-15, 2017, Revised Selected Papers Lecture Notes in Computer Science, pp. 123-141. , ed. by T. Eisenbarth, Y. Teglia (Springer, Berlin), 10728; Prouff, E., Rivain, M., A generic method for secure SBox implementation International Workshop on Information Security Applications WISA (2007) Lecture Notes in Computer Science, 4867, pp. 227-244. , ed. by Sehun Kim, Moti Yung, and Hyung-Woo Lee (Springer, Berlin); Prouff, E., Rivain, M., Masking against side-channel attacks: a formal security proof (2013) Advances in Cryptology-EUROCRYPT 2013, 32nd Annual International Conference on the Theory and Applications of Cryptographic Techniques, Athens, Greece, May 26-30, 2013. Proceedings. Lecture Notes in Computer Science, 7881, pp. 142-159. , ed. by T. Johansson, P.Q. Nguyen(Springer, Berlin); Rivain, M., Prouff, E., Provably secure higher-order masking of AES (2010) International Workshop on Cryptographic Hardware and Embedded Systems, CHES. Lecture Notes in Computer Science, 6225, pp. 413-427. , ed. by S. Mangard, F.-X. Standaert (Springer, Berlin); Wang, W., Standaert, F.-X., Yu, Y., Pu, S., Liu, J., Guo, Z., Gu, D., Inner product masking for bitslice ciphers and security order amplification for linear leakages (2016) Smart Card Research and Advanced Applications-15th International Conference, CARDIS 2016, Cannes, France, November 7-9, 2016, Revised Selected Papers Lecture Notes in Computer Science, pp. 174-191. , ed. by K. Lemke-Rust, M. Tunstall (Springer, Berlin), 10146; Yli-Mäyry, V., Homma, N., Aoki, T., Improved power analysis on unrolled architecture and its application to PRINCE block cipher (2015) Lightweight Cryptography for Security and Privacy-4th International Workshop, LightSec 2015, Bochum, Germany, September 10-11, 2015, Revised Selected Papers. Lecture Notes in Computer Science, 9542, pp. 148-163. , ed. by T. Güneysu, G. Leander, A. Moradi (Springer, Berlin)","Danger, J.-L.; Télécom ParisTechFrance; email: jean-luc.danger@telecom-paristech.fr",,,"Springer International Publishing",,,,,,9783319989358; 9783319989341,,,"English","Cyber-Phys. Syst. Secur.",Book Chapter,"Final","",Scopus,2-s2.0-85063927638
"Wortman P.A., Tehranipoor F., Chandy J.A.","55357200500;57076949900;57206540360;","An Adversarial Risk-based Approach for Network Architecture Security Modeling and Design",2018,"2018 International Conference on Cyber Security and Protection of Digital Services, Cyber Security 2018",,,"8560685","","",,1,"10.1109/CyberSecPODS.2018.8560685","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060477440&doi=10.1109%2fCyberSecPODS.2018.8560685&partnerID=40&md5=80f28bd02e9d53a924a2f090aa6e6590","University of Connecticut, Storrs, CT  06269, United States; San Francisco State University, San Francisco, CA  94132, United States","Wortman, P.A., University of Connecticut, Storrs, CT  06269, United States; Tehranipoor, F., San Francisco State University, San Francisco, CA  94132, United States; Chandy, J.A., University of Connecticut, Storrs, CT  06269, United States","Network architecture design and verification has become increasingly complicated as a greater number of security considerations, implementations, and factors are included in the design process. In the design process, one must account for various costs of interwoven layers of security. Generally these costs are simplified for evaluation of risk to the network. The obvious implications of adding security are the need to account for the impacts of loss (risk) and accounting for the ensuing increased design costs. The considerations that are not traditionally examined are those of the adversary and the defender of a given system. Without accounting for the view point of the individuals interacting with a network architecture, one can not verify and select the most advantageous security implementation. This work presents a method for obtaining a security metric that takes into account not only the risk of the defender, but also the probability of an attack originating from the motivation of the adversary. We then move to a more meaningful metric based on a monetary unit that architects can use in choosing a best fit solution for a given network critical path design problem. © 2018 IEEE.","Secure network architecture; Security metrics; Security risk analysis; System security modeling","Design; Network architecture; Risk analysis; Risk assessment; Network architecture design; Risk based approaches; Secure network architecture; Security considerations; Security implementations; Security metrics; Security risk analysis; System security; Network security",,,,,"Karimian, N., Wortman, P.A., Tehranipoor, F., (2016) Evolving Authentication Design Considerations for the Internet of Biometric Things (IoBT), Proceedings of the Eleventh, , IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Syn thesis; Mukhopadhyay, A., Chatterjee, S., Saha, D., Mahanti, A., Sadhukhan, S.K., Cyber-risk decision models: To insure IT or not? (2013) Decision Support Systems, 56, pp. 11-26; Pal, R., Golubchik, L., Psounis, K., Hui, P., Will cyber-insurance improve network security? A market analysis (2014) IEEE INFOCOM 2014-IEEE Conference on Computer Communications, pp. 235-243; Odell, L.A., Fauntleroy, J.C., Wagner, R.R., Cyber insurance-managing cyber risk (2015) Institute for Defense Analysis, , April; Biener, C., Eling, M., Wirfs, J.H., Insurability of cyber risk: An empirical analysis (2015) The Geneva Papers on Risk and Insurance Issues and Practice, 40 (1), pp. 131-158. , January; Armando, A., Compagna, L., SATMC: A sat-based model checker for security protocols (2004) Logics in Artificial Intelligence, 3229, pp. 730-733; Brucker, A.D., Hang, I., Lückemeyer, G., Ruparel, R., SecureBPMN: Modeling and enforcing access control requirements in business processes (2012) Proceedings of the 17th ACM Symposium on Access Control Models and Technologies, pp. 123-126; Gonzalez, N., Miers, C., Redgolo, F., Simpĺcio, M., Carvalho, T., Näslund, M., Pourzandi, M., A quantitative analysis of current security concerns and solutions for cloud computing (2012) Journal of Cloud Computing: Advances, System and Applications Advances, Systems and Applications; Mukherjee, D., Attributed metagraph modelling to design business process security management (2013) Journal: International Letters of Social and Humanistic Sciences, (6), pp. 41-48; Marotta, A., Martinelli, S.N., Yautsiukhin, A., A survery on cyber-insurance (2015) Technical Report, , November; Latvala, O., Toivonen, J., Evesti, A., Sihvonen, M., Jordan, V., Security risk visualization with semantic risk model (2016) Procedia Computer Science, 83, pp. 1194-1199; Labunets, K., Massacci, F., Paci, F., Marczak, S., De Oliveira, F.M., (2017) Model Comprehension for Security Risk Assessment: An Empirical Comparison of Tabular Vs. Graphical Representations; Shameli-Sendi, A., Aghababaei-Barzegar, R., Cheriet, M., Taxonomy of information security risk assessment (ISRA (2016) Computers & Security, 57, pp. 14-30; Chockalingam, S., Hadziosmanović, D., Pieters, W., Texeira, A., Van Gelder, P., (2016) Integrated Safety and Security Risk Assessment Methods: A Survey of Key Characteristics and Applications; Kong, H., Hong, M.K., Kim, T., Security risk assessment framework for smart car using the attack tree analysis (2017) Journal of Ambient Intelligence and Humanized Computing, pp. 1-21; Wangen, G., Hallstensen, C., Snekkenes, E., A framework for estimating information security risk assessment method completeness (2017) International Journal of Information Security, pp. 1-19; Ferrante, A., Milosevic, J., Janjusevic, M., A security-enhanced design methodology for embedded systems (2013) International Conference on Security and Cryptography (SECRYPT); Sangiovanni-Vincentelli, A., Quo vadis SLD? Reasoning about the trends and challenges of system level design (2007) Proceedings of the IEEE, , March; Ou, X., Boyer, W.F., Miles, A., McQueen. A scalable approach to attack graph generation (2006) Proceedings of the 13th ACM Conference on Computer and Communications Security, CCS 06, pp. 336-345. , New York, NY, USA, ACM; Ingols, K., Lippmann, R., Piwowarski, K., Practical attack graph generation for network defense (2006) 2006 22nd Annual Computer Security Applications Conference (ACSAC06), pp. 121-130. , Dec; Swiler, L.P., Phillips, C., Ellis, D., Chakerian, S., Computer-Attack graph generation tool. in DARPA Information Survivability Conference amp; Exposition II, 2001. DISCEX 01 (2001) Proceedings, 2, pp. 307-321; Multiple Vulnerabilities in ASUS Routers, , https://wwws.nightwatchcybersecurity.com/2017/05/09/multiple-vulnerabilities-in-Asus-routers/",,,"Secudit","Institute of Electrical and Electronics Engineers Inc.","4th International Conference on Cyber Security and Protection of Digital Services, Cyber Security 2018","11 June 2018 through 12 June 2018",,143422,,9781538646830,,,"English","Int. Conf. Cyber Secur. Prot. Digit. Serv., Cyber Security",Conference Paper,"Final","",Scopus,2-s2.0-85060477440
"Jain E., Brown S., Chen J., Neaton E., Baidas M., Dong Z., Gu H., Artan N.S.","57215269555;57216451469;57215292970;57215272664;57215275148;8550534200;7402683068;15834204800;","Adversarial text generation for google's perspective API",2018,"Proceedings - 2018 International Conference on Computational Science and Computational Intelligence, CSCI 2018",,,"8947631","1136","1141",,5,"10.1109/CSCI46756.2018.00220","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078523880&doi=10.1109%2fCSCI46756.2018.00220&partnerID=40&md5=bb1bb4f9ad9f9abe5993ee63cfb4cd1a","Department of Computer Science Tufts, University MedfordMA  02155, United States; College of Engineering and Computing Sciences, New York Institute of Technology, New York, NY  10023, United States; Department of Electrical Engineering, University of California, Berkeley, CA  94720, United States; Department of Biopsychology, University of Michigan, Ann Arbor, MI  48109, United States; College of Engineering and Computing Sciences New York, Institute of Technology New YorkNY  10023, United States","Jain, E., Department of Computer Science Tufts, University MedfordMA  02155, United States; Brown, S., College of Engineering and Computing Sciences, New York Institute of Technology, New York, NY  10023, United States; Chen, J., Department of Electrical Engineering, University of California, Berkeley, CA  94720, United States; Neaton, E., Department of Biopsychology, University of Michigan, Ann Arbor, MI  48109, United States; Baidas, M., College of Engineering and Computing Sciences New York, Institute of Technology New YorkNY  10023, United States; Dong, Z., College of Engineering and Computing Sciences New York, Institute of Technology New YorkNY  10023, United States; Gu, H., College of Engineering and Computing Sciences New York, Institute of Technology New YorkNY  10023, United States; Artan, N.S., College of Engineering and Computing Sciences New York, Institute of Technology New YorkNY  10023, United States","With the preponderance of harassment and abuse, social media platforms and online discussion platforms seek to curb toxic comments. Google's Perspective aims to help platforms classify toxic comments. We have created a pipeline to modify toxic comments to evade Perspective. This pipeline uses existing adversarial machine learning attacks to find the optimal perturbation which will evade the model. Since these attacks typically target images, as opposed to discrete text data, we include a process to generate text candidates from perturbed features and select candidates to retain syntactic similarity. We demonstrated that using a model with just 10,000 queries, changing three words in each comment evades Perspective 25% of the time, suggesting that building a surrogate model may not require many queries and a more robust approach is needed to improve the toxic comment classifier accuracy. © 2018 IEEE.","Adversarial; Deep learning; Google perspective; Machine learning; Natural language processing","Deep learning; Learning algorithms; Learning systems; Machine learning; Natural language processing systems; Pipelines; Social networking (online); Adversarial; Google perspective; NAtural language processing; Online discussions; Optimal perturbation; Robust approaches; Social media platforms; Syntactic similarities; Search engines",,,,,"Blackwell, L., Dimond, J., Schoenebeck, S., Lampe, C., Classification and its consequences for online harassment: Design insights from heartmob (2017) Proc. ACM Hum.-Comput. Interact., 1, pp. 241-2419. , http://doi.acm.org/10.1145/3134659, CSCW Dec; (2018), https://conversationai.github.io/, Jigsaw; Hosseini, H., Kannan, S., Zhang, B., Poovendran, R., (2017) Deceiving Google's Perspective Api Built for Detecting Toxic Comments, , http://arxiv.org/abs/1702.08138, CoRR abs/1702. 08138; Li, S., Chen, Y., Peng, Y., Bai, L., (2018) Learning More Robust Features with Adversarial Training, , CoRR abs/1804. 07757; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R., (2013) Intriguing Properties of Neural Networks, , CoRRabs/1312. 6199; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium On. IEEE, pp. 372-387; Carlini, N., Wagner, D., (2016) Towards Evaluating the Robustness of Neural Networks; Akhtar, N., Mian, A., (2018) Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security. ACM, pp. 15-26; Narodytska, N., Kasiviswanathan, S.P., (2016) Simple Black-box Adversarial Perturbations for Deep Networks, , http://arxiv.org/abs/1612.06299, CoRR abs/1612. 06299; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security. ACM, pp. 506-519; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples; Liu, Y., Chen, X., Liu, C., Song, D., (2016) Delving into Transferable Adversarial Examples and Black-box Attacks; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World; Rodriguez, N., Galeano, S.R., (2018) Shielding Google's Language Toxicity Model Against Adversarial Attacks, , http://arxiv.org/abs/1801.01828, CoRR abs/1801. 01828; Samanta, S., Mehta, S., (2017) Towards Crafting Text Adversarial Samples; Papernot, N., McDaniel, P.D., Swami, A., Harang, R.E., (2016) Crafting Adversarial Input Sequences for Recurrent Neural Networks, , http://arxiv.org/abs/1604.08275, CoRR abs/1604. 08275; Liang, B., Li, H., Su, M., Bian, P., Li, X., Shi, W., (2017) Deep Text Classification Can Be Fooled, , http://arxiv.org/abs/1704.08006, CoRR abs/1704. 08006; Gao, J., Lanchantin, J., Soffa, M.L., Qi, Y., (2018) Black-box Generation of Adversarial Text Sequences to Evade Deep Learning Classifiers, , http://arxiv.org/abs/1801.04354, CoRR abs/1801. 04354; Grainger, J., Whitney, C., Does the huamn mnid raed wrods as a wlohe? (2004) Trends in Cognitive Sciences, 8 (2), pp. 58-59; Carreiras, M., Grainger, J., Sublexical representations and the front endof visual word recognition (2004) Language and Cognitive Processes, 19 (3), pp. 321-331; Su, J., Vargas, D.V., Sakurai, K., (2017) One Pixel Attack for Fooling Deep Neural Networks, , CoRR abs/1710. 08864; Aitchison, J., Language change (2005) The Routledge Companion to Semiotics and Linguistics. Routledge, pp. 111-120; Sonnad, N., (2016) Alt-right Trolls Are Using These Code Words for Racial Slurs Online; Bencina, J., (2017), https://github.com/jbencina; Kim, Y., (2014) Convolutional Neural Networks for Sentence Classification; Goodfellow, I.J., Papernot, N., McDaniel, P.D., (2016) Cleverhans v0. 1: An Adversarial Machine Learning Library, , CoRR abs/1610. 00768; (2018), https://github.com/yahoojapan/NGT, Y. J. Research; Honnibal, M., Montani, I., (2017) Spacy 2: Natural Language Understanding with Bloom Embeddings, Convolutional Neural Networks and Incremental Parsing, , To appear; Kiros, R., Zhu, Y., Salakhutdinov, R.R., Zemel, R., Urtasun, R., Torralba, A., Fidler, S., Skip-thought vectors (2015) Advances in Neural Information Processing Systems, pp. 3294-3302",,,"American Council on Science and Education","Institute of Electrical and Electronics Engineers Inc.","2018 International Conference on Computational Science and Computational Intelligence, CSCI 2018","13 December 2018 through 15 December 2018",,156537,,9781728113609,,,"English","Proc. - Int. Conf. Comput. Sci. Comput. Intell., CSCI",Conference Paper,"Final","",Scopus,2-s2.0-85078523880
"Cantelli-Forti A., Colajanni M.","57215329510;7003997441;","Adversarial fingerprinting of cyber attacks based on stateful honeypots",2018,"Proceedings - 2018 International Conference on Computational Science and Computational Intelligence, CSCI 2018",,,"8947682","19","24",,,"10.1109/CSCI46756.2018.00012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078517539&doi=10.1109%2fCSCI46756.2018.00012&partnerID=40&md5=8d4f92f60fe85590d4095aeb2e03504b","RaSS-CNIT National Laboratory, University of Pisa, Pisa, Italy; Department of Engineering Enzo Ferrari, University of Modena and Reggio Emilia, Modena, Italy","Cantelli-Forti, A., RaSS-CNIT National Laboratory, University of Pisa, Pisa, Italy; Colajanni, M., Department of Engineering Enzo Ferrari, University of Modena and Reggio Emilia, Modena, Italy","The cyber defenses of Critical Infrastructures require early detection of new threats and attacks. This includes defensive systems that are able to learn from novel attacks and to detect 0-day vulnerabilities as early as possible. Honeypots are not defensive systems based on prevention, but they still represent an effective way to gather information about attacks from the source. Nevertheless, most existing solutions operate in a stateless way. As a consequence, they are easily identified by expert attackers, and they are unable to track progress of individual attacks in large applications. We propose a novel approach that enables a so called stateful honeypot. The idea comes from the observation that a typical cyber attack to a Critical Infrastructure is carried out through multiple attempts and intrusions. Hence the main goal is to fingerprint each attacker by observing and registering his adopted methods, tools and actions. Once identified, the adversary is redirected to his specific environment that preserves the history of his previous operations including the installation of rootkits or backdoors. The proposed solution paves the way to a more effective generation of honeypots that are necessary to face the augmented complexity of cyber attacks. © 2018 IEEE.","Critical infrastructure protection; Cyber security; Decoy system; Honey pot; Traffic redirection","Artificial intelligence; Critical infrastructures; Network security; Public works; Critical infrastructure protection; Cyber security; Decoy systems; Honeypots; Traffic redirections; Computer crime",,,,,"(2004) Critical Infrastructure Protection in the Fight Against Terrorism, , EUCommission; Spitzner, L., The honeynet project: Trapping the hackers (2003) IEEE Security & Privacy, 1 (2), pp. 15-23. , March 2003; Callegari, C., Forti, A.C., D'Amore, G., De La Hoz, E., Echarri, D., Garca-Ferreira, I., Lpez-Civera, G., An architecture for securing communications in critical infrastructure (2016) ICETE 2016-Proceedings of the 13th International Joint Conference on E-Business and Telecommunications, p. 111; Fan, W., Fernandez, A novel SDN based stealthy TCP connection handover mechanism for hybrid honeypot systems (2017) 2017 IEEE Conference on Network Softwarization; Nawrocki, M., Whlisch, M., Schmidt, C., Keil, T.C., Schnfelder, J., (2016) A Survey on Honeypot Software and Data Analysis, , ArXiv e-prints, Aug; Bailey, M., Cooke, E., Watson, D., Jahanian, F., Provos, N., A hybrid honeypot architecture for scalable network monitoring (2014) Technical Report CSE-TR-499-04 University of Michigan; Artail, H., Safa, H., Sraj, M., Kuwatly, I., Al-Masri, Z., A hybrid honeypot framework for improving intrusion detection systems in protecting organizational networks (2016) Computers and Security, 25 (4), pp. 274-288; Panjwani, S., Tan, S., Jarrin, K.M., Cukier, M., An experimental evaluation to determine if port scans are precursors to an attack (2005) Proceedings of the International Conference on Dependable Systems and Networks, p. 602; Zhang, F., Zhou, S., Qin, Z., Liu, J., Honeypot: A supplemented active defense system for network security (2003) Proceedings of the Fourth International Conference on Parallel and Distributed Computing, Applications and Technologies, 2003, p. 231235. , IEEE; Achleitner, S., La Porta, T.F., Mcdaniel, P., Sugrim, S., Krishnamurthy, S.V., Chadha, R., Deceiving network reconnaissance using SDN-based virtual topologies (2017) IEEE Transactions on Network and Service Management, 14 (4), pp. 1098-1112; Zhang, C.Y., Rajimwale, A., Arpaci-Dusseau, A.C., ArpaciDusseau, R.H., End-to-end data integrity for file systems: A ZFS case study (2010) Proc. USENIX Conference on File and Storage Technologies; Rodeh, O., B-trees, shadowing, and clones (2008) Trans. Storage, 3 (4), p. 27. , (February 2008); Bace, R.G., (2000) Intrusion Detection, , (Book) Sams Publishing; Carlen, P.L., Traffic flow confidentiality mechanisms and their impact on traffic (2013) Military Communications and Information Systems Conference (MCC), p. 16. , 2013. IEEE; Woodring, S., (2001) Port Mirroring in Channel Directors and Switches, , US Patent App; Btrfs Project Official Status Web Page on Linux Kernel Wiki, , https://btrfs.wiki.kernel.org/index.php/Status, [retrieved on 7 Novembre 2018]",,,"American Council on Science and Education","Institute of Electrical and Electronics Engineers Inc.","2018 International Conference on Computational Science and Computational Intelligence, CSCI 2018","13 December 2018 through 15 December 2018",,156537,,9781728113609,,,"English","Proc. - Int. Conf. Comput. Sci. Comput. Intell., CSCI",Conference Paper,"Final","",Scopus,2-s2.0-85078517539
"Sun L., Tan M., Zhou Z.","57218583420;57218584832;56416761400;","A survey of practical adversarial example attacks",2018,"Cybersecurity","1","1","9","","",,10,"10.1186/s42400-018-0012-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075745691&doi=10.1186%2fs42400-018-0012-9&partnerID=40&md5=499ed7c8a21fdaa258e8be39c19ffc72","Fudan University, Shanghai, China","Sun, L., Fudan University, Shanghai, China; Tan, M., Fudan University, Shanghai, China; Zhou, Z., Fudan University, Shanghai, China","Adversarial examples revealed the weakness of machine learning techniques in terms of robustness, which moreover inspired adversaries to make use of the weakness to attack systems employing machine learning. Existing researches covered the methodologies of adversarial example generation, the root reason of the existence of adversarial examples, and some defense schemes. However practical attack against real world systems did not appear until recent, mainly because of the difficulty in injecting a artificially generated example into the model behind the hosting system without breaking the integrity. Recent case study works against face recognition systems and road sign recognition systems finally abridged the gap between theoretical adversarial example generation methodologies and practical attack schemes against real systems. To guide future research in defending adversarial examples in the real world, we formalize the threat model for practical attacks with adversarial examples, and also analyze the restrictions and key procedures for launching real world adversarial example attacks. © 2019, The Author(s).","Adversarial examples; AI systems security; Attacks","Machine learning; Face recognition systems; Machine learning techniques; Real systems; Real-world; Real-world system; Road sign recognition; Threat modeling; Face recognition",,,,,"Athalye, A., Carlini, N., Wagner, D.A., Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples (2018) CoRR, abs/1802.00420, pp. 1-12. , 1802.00420; Bhagoji, A.N., He, W., Li, B., Song, D., (2017) Exploring the Space of Black-Box Attacks on Deep Neural Networks, , arXiv preprint arXiv:1712.09491; Buckman, J., Roy, A., Raffel, C., Goodfellow, I., Thermometer encoding: One hot way to resist adversarial examples (2018) International Conference on Learning Representations, , In; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 3-14. , ACM, Dallas; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 38th IEEE Symposium on Security and Privacy (SP), pp. 39-57. , IEEE, San Jose; Dhillon, G.S., Azizzadenesheli, K., Lipton, Z.C., Bernstein, J., Kossaifi, J., Khanna, A., Anandkumar, A., (2018) Stochastic Activation Pruning for Robust Adversarial Defense, , arXiv preprint arXiv:1803.01442; Evtimov, I., Eykholt, K., Fernandes, E., Kohno, T., Li, B., Prakash, A., Rahmati, A., Song, D., Robust physical-world attacks on deep learning models (2017) CoRR, abs/1707.08945, pp. 1-11. , 1707.08945; Gong, Z., Wang, W., Ku, W.S., (2017) Adversarial and Clean Data are Not Twins, , arXiv preprint arXiv:1704.04960; Guo, C., Rana, M., Cissé, M., van Der Maaten, L., (2017) Countering Adversarial Images Using Input Transformations, , arXiv preprint arXiv:1711.00117; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, pp. 1-11. , ArXiv e-prints; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint arXiv:1607.02533; Ma, X., Li, B., Wang, Y., Erfani, S.M., Wijewickrema, S., Houle, M.E., Schoenebeck, G., Bailey, J., (2018) Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality, , arXiv preprint arXiv:1801.02613; Mahendran, A., Vedaldi, A., Understanding deep image representations by inverting them (2015) Computer Vision and Pattern Recognition (CVPR), 2015 IEEE Conference on, pp. 5188-5196. , IEEE, Boston; Meng, D., Chen, H., Magnet: a two-pronged defense against adversarial examples (2017) Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pp. 135-147. , ACM, Dallas; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 427-436. , IEEE, Boston; Papernot, N., McDaniel, P.D., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2015) CoRR, abs/1511.07528, pp. 1-16; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Security and Privacy (SP), 2016 IEEE Symposium on, pp. 582-597. , IEEE, San Jose; Papernot, N., McDaniel, P.D., Goodfellow, I.J., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against deep learning systems using adversarial examples (2016) Corr Abs/1602, p. 02697; Samangouei, P., Kabkab, M., Chellappa, R., Defense-gan: Protecting classifiers against adversarial attacks using generative models (2018) CoRR, abs/1805.06605, pp. 1-17. , 1805.06605; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540. , ACM, Vienna; Song, Y., Kim, T., Nowozin, S., Ermon, S., Kushman, N., (2017) Pixeldefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples., , arXiv preprint arXiv:1710.10766; Su, J., Vargas, D.V., Kouichi, S., (2017) One Pixel Attack for Fooling Deep Neural Networks., , arXiv preprint arXiv:1710.08864; Sun, Y., Wang, X., Tang, X., Deep learning face representation from predicting 10,000 classes (2014) In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1891-1898; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks., , arXiv preprint arXiv:1312.6199; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., (2017) Mitigating Adversarial Effects through Randomization., , arXiv preprint arXiv:1711.01991; Yuan, X., He, P., Zhu, Q., Bhat, R.R., Li, X., (2017) Adversarial Examples: Attacks and Defenses for Deep Learning., , arXiv preprint arXiv:1712.07107; Zhou, Z., Tang, D., Wang, X., Han, W., Liu, X., Zhang, K., (2018) Invisible Mask: Practical Attacks on Face Recognition with Infrared., , arXiv preprint arXiv:1803.04683","Zhou, Z.; Fudan UniversityChina; email: zhouzhe@fudan.edu.cn",,,"Springer Science and Business Media B.V.",,,,,20964862,,,,"English","Cybersecur.",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85075745691
"Hua Y., Hu L., Chen F.","57210287963;57202752730;55619290102;","An adaptive malicious punishment over secure distributed estimation under attacks",2018,"2018 IEEE 4th International Conference on Computer and Communications, ICCC 2018",,,"8780590","2195","2199",,1,"10.1109/CompComm.2018.8780590","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070814036&doi=10.1109%2fCompComm.2018.8780590&partnerID=40&md5=54992b0e9d22841c8bd14160927440b8","Department of Electronic and Information Engineering, Chongqing Key Laboratory of Nonlinear Circuits and Intelligent Information Processing, Southwest University, Chongqing, China","Hua, Y., Department of Electronic and Information Engineering, Chongqing Key Laboratory of Nonlinear Circuits and Intelligent Information Processing, Southwest University, Chongqing, China; Hu, L., Department of Electronic and Information Engineering, Chongqing Key Laboratory of Nonlinear Circuits and Intelligent Information Processing, Southwest University, Chongqing, China; Chen, F., Department of Electronic and Information Engineering, Chongqing Key Laboratory of Nonlinear Circuits and Intelligent Information Processing, Southwest University, Chongqing, China","In this paper, we propose an adaptive malicious punishment DLMS algorithm to mitigate the adversarial attack. Two types of attacks are proposed in the WSNs. The adaptive threshold is designed to detect attacks. Then corresponding weight of malicious nodes can be reduced, due to the punishing factor. The simulations demonstrate that the proposed algorithm is robust to the adversarial attacks. © 2018 IEEE.","Component; Detecting malicious nodes; DLMS; The adaptive threshold; The malicious attack; The punishing weight","Computers; Adaptive thresholds; Component; DLMS; Malicious attack; Malicious nodes; The punishing weight; Computer science",,,,,"Chen, F., Li, X., Duan, S., Wang, L., Wu, J., Diffusion generalized maximum correntropy criterion algorithm for distributed estimation over multitask network (2018) Digital Signal Processing.; Huang, W., Yang, X., Shen, G., Communication-reducing diffusion lms algorithm over multitask networks (2017) Information Sciences, 382-383, pp. 115-134; Chen, F., Shi, T., Duan, S., Wang, L., Wu, J., Diffusion least logarithmic absolute difference algorithm for distributed estimation (2017) Signal Processing, p. 142; Cattivelli, F.S., Sayed, A.H., Diffusion lms strategies for distributed estimation (2010) IEEE Transactions on Signal Processing, 58 (3), pp. 1035-1048; Lopes, C.G., Sayed, A.H., Diffusion least-mean squares over adaptive networks: Formulation and performance analysis (2007) IEEE Transactions on Signal Processing, 56 (7), pp. 3122-3136; Sang, M.J., Seo, J.H., Park, P.G., A variable step-size diffusion normalized least-mean-square algorithm with a combination method based on mean-square deviation (2015) Circuits Systems & Signal Processing, 34 (10), pp. 3291-3304; Mateos, G., Schizas, I.D., Giannakis, G.B., (2009) Distributed Recursive Least-squares for Consensus-based In-network Adaptive Estimation, , IEEE Press; Marano, S., Matta, V., Tong, L., Distributed detection in the presence of byzantine attacks (2009) IEEE Transactions on Signal Processing, 57 (1), pp. 16-29; Kailkhura, B., Brahma, S., Varshney, P.K., Data falsification attacks on consensus-based detection systems (2013) International Symposium on Communications and Information Technologies, PP, p. 1. , IEEE; Liu, Y., Li, C., Secure distributed estimation over wireless sensor networks under attacks (2018) IEEE Transactions on Aerospace & Electronic Systems, PP (99), p. 1. , 3; Chen, Y., Kar, S., Moura, J.M.F., Resilient distributed estimation through adversary detection (2018) IEEE Transactions on Signal Processing, PP (99), p. 1",,,"IEEE;SIE","Institute of Electrical and Electronics Engineers Inc.","4th IEEE International Conference on Computer and Communications, ICCC 2018","7 December 2018 through 10 December 2018",,150224,,9781538683392,,,"English","IEEE Int. Conf. Comput. Commun., ICCC",Conference Paper,"Final","",Scopus,2-s2.0-85070814036
"Kesarwani M., Kaul A., Singh G., Deshpande P.M., Haritsa J.R.","57202646952;57202643737;57209127676;57225685450;7003832747;","Collusion-Resistant Processing of SQL Range Predicates",2018,"Data Science and Engineering","3","4",,"323","340",,1,"10.1007/s41019-018-0081-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062723241&doi=10.1007%2fs41019-018-0081-5&partnerID=40&md5=850a3b0525d486eb200334460164c4c6","IBM Research, Bangalore, India; Kena Labs, Bangalore, India; Indian Institute of Science, Bangalore, India","Kesarwani, M., IBM Research, Bangalore, India; Kaul, A., IBM Research, Bangalore, India; Singh, G., IBM Research, Bangalore, India; Deshpande, P.M., Kena Labs, Bangalore, India; Haritsa, J.R., Indian Institute of Science, Bangalore, India","Prior solutions for securely handling SQL range predicates in outsourced Cloud-resident databases have primarily focused on passive attacks in the Honest-but-Curious adversarial model, where the server is only permitted to observe the encrypted query processing. We consider here a significantly more powerful adversary, wherein the server can launch an active attack by clandestinely issuing specific range queries via collusion with a few compromised clients. The security requirement in this environment is that data values from a plaintext domain of size N should not be leaked to within an interval of size H. Unfortunately, all prior encryption schemes for range predicate evaluation are easily breached with only O(log 2 ψ) range queries, where ψ= N/ H. To address this lacuna, we present SPLIT, a new encryption scheme where the adversary requires exponentially more—O(ψ) —range queries to breach the interval constraint and can therefore be easily detected by standard auditing mechanisms. The novel aspect of SPLIT is that each value appearing in a range-sensitive column is first segmented into two parts. These segmented parts are then independently encrypted using a layered composition of a secure block cipher with the order-preserving encryption and prefix-preserving encryption schemes, and the resulting ciphertexts are stored in separate tables. At query processing time, range predicates are rewritten into an equivalent set of table-specific sub-range predicates, and the disjoint union of their results forms the query answer. A detailed evaluation of SPLIT on benchmark database queries indicates that its execution times are well within a factor of two of the corresponding plaintext times, testifying its efficiency in resisting active adversaries. © 2018, The Author(s).","Cloud; Range; Security; SQL",,,,,,"Agrawal, R., Kiernan, J., Srikant, R., Xu, Y., Order-preserving encryption for numeric data (2004) Proceedings of ACM SIGMOD Conference; Arasu, A., Blanas, S., Eguro, K., Kaushik, R., Kossmann, D., Ramamurthy, R., Venkatesan, R., Orthogonal security with cipherbase (2013) Proceedings of CIDR Conference; Bajaj, S., Sion, R., Trusteddb: A trusted hardware based outsourced database engine (2011) In: PVLDB, 4 (12); Bellare, M., Ristenpart, T., Rogaway, P., Stegers, T., Format-preserving encryption (2009) Proceedings of Selected Areas in Cryptography Conference; Boldyreva, A., Chenette, N., Lee, Y., Oneill, A., Order-preserving symmetric encryption (2009) Proceedings of EUROCRYPT Conference; Boldyreva, A., Chenette, N., O’Neill, A., Order-preserving encryption revisited: Improved security analysis and alternative solutions (2011) Proceedings of CRYPTO Conference; Chi, J., Hong, C., Zhang, M., Zhang, Z., Fast multi-dimensional range queries on encrypted cloud databases (2017) Proceedings of DASFAA Conference; Cutello, V., Nicosia, G., Pavone, M., A hybrid immune algorithm with information gain for the graph coloring problem (2003) Proceedings of Genetic and Evolutionary Computation Conference; Demertzis, I., Papadopoulos, S., Papapetrou, O., Deligiannakis, A., Garofalakis, M., Practical private range search revisited (2016) Proceedings of ACM SIGMOD Conference; Dowsland, K.A., Thompson, J.M., An improved ant colony optimisation heuristic for graph colouring (2008) Proc Discrete Appl Math, 156 (3), pp. 313-324; Hacigümüs, H., Iyer, B.R., Li, C., Mehrotra, S., Executing SQL over encrypted data in the database-service-provider model (2002) Proceedings of ACM SIGMOD Conference; Hore, B., Mehrotra, S., Tsudik, G., A privacy-preserving index for range queries (2004) Proceedings of VLDB Conference; Kerschbaum, F., Frequency-hiding order-preserving encryption (2015) Proceedings of CCS Conference; Knuth, D.E., (1998) Sorting and searching. The art of computer programming, 3. , 2, Addison-Wesley, Reading; Li, J., Omiecinski, E.R., Efficiency and security trade-off in supporting range queries on encrypted databases (2005) Proceedings of Dbsec Conference; Li, R., Liu, A.X., Wang, A.L., Bruhadeshwar, B., Fast range query processing with strong privacy protection for cloud computing (2014) PVLDB, 7 (14), pp. 1953-1964; Lindell, Y., Katz, J., (2014) Introduction to modern cryptography, , Chapman and Hall/CRC, Boca Raton; Popa, R.A., Li, F.H., Zeldovich, N., An ideal-security protocol for order-preserving encoding (2013) Proceedings of IEEE Symposium on Security and Privacy; Popa, R.A., Redfield, C.M.S., Zeldovich, N., Balakrishnan, H., CryptDB: processing queries on an encrypted database (2012) Commun ACM, 55 (9), pp. 103-111; Tu, S., Kaashoek, M.F., Madden, S., Zeldovich, N., Processing analytical queries over encrypted data (2013) PVLDB, 6 (5), pp. 289-300; Wong, W.K., Kao, B., Cheung, D.W., Li, R., Yiu, S., Secure query processing with data interoperability in a cloud database environment (2014) Proceedings of ACM SIGMOD Conference; Xu, J., Fan, J., Ammar, M.H., Moon, A.B., Prefix-preserving IP address anonymization: Measurement-based security evaluation and a new cryptography-based scheme (2002) Proceedings of ICNP Conference; https://aws.amazon.com/ec2/pricing/; http://dsl.cds.iisc.ac.in/publications/report/TR/TR-2016-01.pdf","Kesarwani, M.; IBM ResearchIndia; email: manishkesarwani@in.ibm.com",,,"Springer",,,,,23641185,,,,"English","Data Sci. Eng.",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85062723241
"Li J.-H.","56103299700;","Cyber security meets artificial intelligence: a survey",2018,"Frontiers of Information Technology and Electronic Engineering","19","12",,"1462","1474",,34,"10.1631/FITEE.1800573","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059738116&doi=10.1631%2fFITEE.1800573&partnerID=40&md5=9dfcd625b08483b3eaacc31d7d2e12eb","School of Cyber Security, Shanghai Jiao Tong University, Shanghai, 200240, China","Li, J.-H., School of Cyber Security, Shanghai Jiao Tong University, Shanghai, 200240, China","There is a wide range of interdisciplinary intersections between cyber security and artificial intelligence (AI). On one hand, AI technologies, such as deep learning, can be introduced into cyber security to construct smart models for implementing malware classification and intrusion detection and threating intelligence sensing. On the other hand, AI models will face various cyber threats, which will disturb their sample, learning, and decisions. Thus, AI models need specific cyber security defense and protection technologies to combat adversarial machine learning, preserve privacy in machine learning, secure federated learning, etc. Based on the above two aspects, we review the intersection of AI and cyber security. First, we summarize existing research efforts in terms of combating cyber attacks using AI, including adopting traditional machine learning methods and existing deep learning solutions. Then, we analyze the counterattacks from which AI itself may suffer, dissect their characteristics, and classify the corresponding defense methods. Finally, from the aspects of constructing encrypted neural network and realizing a secure federated deep learning, we expatiate the existing research on how to build a secure AI system. © 2018, Editorial Office of Journal of Zhejiang University Science and Springer-Verlag GmbH Germany, part of Springer Nature.","Artificial intelligence (AI); Attack detection; Cyber security; Defensive techniques; TP309","Artificial intelligence; Computer crime; Deep learning; Intrusion detection; Malware; Attack detection; Cyber security; Defensive techniques; Machine learning methods; Malware classifications; Protection technologies; Research efforts; TP309; Network security",,,,,"Abeshu, A., Chilamkurti, N., Deep learning: the frontier for distributed attack detection in fog–to–things computing (2018) IEEE Commun Mag, 56 (2), pp. 169-175; Akhtar, N., Mian, A., Threat of adversarial attacks on deep learning in computer vision: a survey (2018) IEEE Access, 6, pp. 14410-14430; Akhtar, N., Liu, J., Mian, A., (2018) Defense against universal adversarial perturbations, pp. 3389-3398; Arulkumaran, K., Deisenroth, M.P., Brundage, M., Deep reinforcement learning: a brief survey (2017) IEEE Signal Process Mag, 34 (6), pp. 26-38; Aygün, R.C., Yavuz, A.G., (2017) A stochastic data discrimination based autoencoder approach for network anomaly detection; Bonawitz, K., Ivanov, V., Kreuter, B., (2017) Practical secure aggregation for privacy–preserving machine learning; Bost, R., Popa, R.A., Tu, S., (2015) Machine learning classification over encrypted data; Chowdhury, M.M.U., Hammond, F., Konowicz, G., (2017) A few–shot deep learning approach for improved intrusion detection; Cisse, M., Adi, Y., Neverova, N., (2017) Houdini: fooling deep structured prediction models, , https://doi.org/arxiv.org/abs/1707.05373; Cubuk, E.D., Zoph, B., Schoenholz, S.S., (2017) Intriguing properties of adversarial examples, , https://doi.org/arxiv.org/abs/1711.02846; Dada, E.G., (2017) A hybridized SVM–kNN–pdAPSO approach to intrusion detection system; Deng, L., Yu, D., Deep learning: methods and applications (2014) Found Trend Sig Process, 7 (3-4), pp. 197-387; Feinman, R., Curtin, R.R., Shintre, S., (2017) Detecting adversarial samples from artifacts, , https://doi.org/arxiv.org/abs/1703.00410; Gao, W., Morris, T., Reaves, B., (2010) On SCADA control system command and response injection and intrusion detection; Gebhart, T., Schrater, P., (2017) Adversary detection in neural networks via persistent homology, , https://doi.org/arxiv.org/abs/1711.10056; Golovko, V.A., Deep learning: an overview and main paradigms (2017) Opt Memory Neur Netw, 26 (1), pp. 1-17; Goodfellow, I.J., Pouget–Abadie, J., Mirza, M., (2014) Generative adversarial networks, , https://doi.org/arxiv.org/abs/1406.2661; Goodfellow, I.J., Shlens, J., Szegedy, C., (2015) Explaining and harnessing adversarial examples, , https://doi.org/arxiv.org/abs/1412.6572; Gu, S.X., Rigazio, L., (2015) Towards deep neural network architectures robust to adversarial examples, , https://doi.org/arxiv.org/abs/1412.5068; Guan, Z.T., Li, J., Wu, L.F., Achieving efficient and secure data acquisition for cloud–supported Internet of Things in smart grid (2017) IEEE Internet Things^J, 4 (6), pp. 1934-1944; Hatcher, W.G., Yu, W., A survey of deep learning: platforms, applications and emerging research trends (2018) IEEE Access, 6, pp. 24411-24432; He, W., Wei, J., Chen, X.Y., (2017) Adversarial example defenses: ensembles of weak defenses are not strong, , https://doi.org/arxiv.org/abs/1706.04701; Kokila, R.T., Selvi, S.T., Govindarajan, K., (2014) DDoS detection and analysis in SDN–based environment using support vector machine classifier; Korczak, J., Hernes, M., (2017) Deep learning for financial time series forecasting in a–trader system; Krotov, D., Hopfield, J., (2018) Dense associative memory is robust to adversarial inputs; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), pp. 436-444; Lee, H., Han, S., Lee, J., (2017) Generative adversarial trainer: defense to adversarial perturbations with^GAN, , https://doi.org/arxiv.org/abs/1705.03387; Li, G.L., Wu, J., Li, J.H., Service popularity–based smart resources partitioning for fog computing–enabled industrial Internet of Things (2018) IEEE Trans Ind Inform, 14 (10), pp. 4702-4711; Li, L.Z., Ota, K., Dong, M.X., Deep learning for smart industry: efficient manufacture inspection system with fog computing (2018) IEEE Trans Ind Inform, 14 (10), pp. 4665-4673; Li, L.Z., Ota, K., Dong, M.X., (2018) DeepNFV: a light–weight framework for intelligent edge network functions virtualization; Liang, B., Li, H.C., Su, M.Q., (2017) Detecting adversarial image examples in deep networks with adaptive noise reduction, , https://doi.org/arxiv.org/abs/1705.08378; Loukas, G., Vuong, T., Heartfield, R., Cloud–based cyber–physical intrusion detection for vehicles using deep learning (2018) IEEE Access, 6, pp. 3491-3508; Luo, Y., Boix, X., Roig, G., (2015) Foveation–based mechanisms alleviate adversarial examples, , https://doi.org/arxiv.org/abs/1511.06292; Lyu, C., Huang, K.Z., Liang, H.N., (2015) A unified gradient regularization family for adversarial examples; Manning, C.D., Surdeanu, M., Bauer, J., (2014) The Stanford CoreNLP natural language processing toolkit; McMahan, H.B., Moore, E., Ramage, D., (2016) Communication–efficient learning of deep networks from decentralized data, , https://doi.org/arxiv.org/abs/1602.05629; Meng, D.Y., Chen, H., (2017) MagNet: a two–pronged defense against adversarial examples; Meng, W.Z., Li, W.J., Kwok, L.F., Design of intelligent KNNbased alarm filter using knowledge–based alert verification in intrusion detection (2015) Secur Commun Netw, 8 (18), pp. 3883-3895; Meng, X., Shan, Z., Liu, F.D., (2017) MCSMGS: malware classification model based on deep learning; Mnih, V., Kavukcuoglu, K., Silver, D., Human–level control through deep reinforcement learning (2015) Nature, 518 (7540), pp. 529-533; Moon, D., Im, H., Kim, I., DTB–IDS: an intrusion detection system based on decision tree using behavior analysis for preventing^APT attacks (2017) J Supercomput, 73 (7), pp. 2881-2895; Moosavi–Dezfooli, S.M., Fawzi, A., Frossard, P., (2016) DeepFool: a simple and accurate method to fool deep neural networks; Moosavi–Dezfooli, S.M., Fawzi, A., Fawzi, O., (2017) Universal adversarial perturbations; Mopuri, K.R., Garg, U., Babu, R.V., (2017) Fast feature fool: a data independent approach to universal adversarial perturbations, , https://doi.org/arxiv.org/abs/1707.05572; Nayebi, A., Ganguli, S., (2017) Biologically inspired protection of deep networks from adversarial attacks, , https://doi.org/arxiv.org/abs/1703.09202; Olalere, M., Abdullah, M.T., Mahmod, R., (2016) Identification and evaluation of discriminative lexical features of malware^URL for real–time classification; Ota, K., Dao, M.S., Mezaris, V., (2017) Deep learning for mobile multimedia: a survey.^ACM Trans Multim Comput Commun Appl; Papernot, N., McDaniel, P., Jha, S., (2016) The limitations of deep learning in adversarial settings; Phong, L.T., Aono, Y., Hayashi, T., Privacypreserving deep learning via additively homomorphic encryption (2018) IEEE Trans Inform Forens Secur, 13 (5), pp. 1333-1345; Ren, S.Q., He, K.M., Girshick, R., Faster R–CNN: towards real–time object detection with region proposal networks (2017) IEEE Trans Patt Anal Mach Intell, 39 (6), pp. 1137-1149; Ross, A.S., Doshi–Velez, F., (2017) Improving the adversarial robustness and interpretability of deep neural networks by regularizing their input gradients, , https://doi.org/arxiv.org/abs/1711.09404; Sabour, S., Cao, Y.S., Faghri, F., (2015) Adversarial manipulation of deep representations, , https://doi.org/arxiv.org/abs/1511.05122; Shahid, N., Aleem, S.A., Naqvi, I.H., (2012) Support vector machine based fault detection & classification in smart grids; Shokri, R., Shmatikov, V., (2015) Privacy–preserving deep learning. Proc 53rd Annual Allerton Conf on Communication, Control, and Computing; Syarif, A.R., Gata, W., (2017) Intrusion detection system using hybrid binary^PSO and K–nearest neighborhood algorithm; Vinayakumar, R., Soman, K.P., Poornachandran, P., Detecting Android malware using long short–term memory (LSTM) (2018) J Int Fuzzy Syst, 34 (3), pp. 1277-1288; Vollmer, T., Manic, M., (2009) Computationally efficient neural network intrusion security awareness; Vuong, T.P., Loukas, G., Gan, D., (2015) Decision tree–based detection of denial of service and command injection attacks on robotic vehicles; Wu, J., Dong, M.X., Ota, K., Big data analysis–based secure cluster management for optimized control plane in software–defined networks (2018) IEEE Trans Netw Serv Manag, 15 (1), pp. 27-38; Xie, C.H., Wang, J.Y., Zhang, Z.S., (2017) Adversarial examples for semantic segmentation and object detection; Xin, Y., Kong, L.S., Liu, Z., Machine learning and deep learning methods for cybersecurity (2018) IEEE Access, 6, pp. 35365-35381; Xu, W.L., Evans, D., Qi, Y.J., (2017) Feature squeezing mitigates and detects Carlini/Wagner adversarial examples, , https://doi.org/arxiv.org/abs/1705.10686; Yuan, X.Y., (2017) PhD forum: deep learning–based real–time malware detection with multi–stage analysis; Zhao, G.Z., Zhang, C.X., Zheng, L.J., (2017) Intrusion detection using deep belief network and probabilistic neural network; Zhu, D.L., Jin, H., Yang, Y., (2017) DeepFlow: deep learning–based malware detection by mining Android application for abnormal usage of sensitive data; Zolotukhin, M., Hämäläinen, T., Kokkonen, T., Increasing web service availability by detecting application–layer DDoS attacks in encrypted traffic (2016) Proc 23rd Int Conf on Telecommunications","Li, J.-H.; School of Cyber Security, China; email: lijh888@sjtu.edu.cn",,,"Zhejiang University",,,,,20959184,,,,"English","Front. Inf. Technol. Electr. Eng.",Review,"Final","",Scopus,2-s2.0-85059738116
"Kwon H., Kim Y., Yoon H., Choi D.","57197769092;55699558400;15061371300;8660876600;","Random untargeted adversarial example on Deep neural network",2018,"Symmetry","10","12","738","","",,10,"10.3390/sym10120738","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059017272&doi=10.3390%2fsym10120738&partnerID=40&md5=a4f017262c7b0b191f7df75141f4506d","School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, 34141, South Korea; Department of Electrical Engineering, Korea Military Academy, Seoul, 01805, South Korea; Department of Medical Information, Kongju National University, Gongju-si, 32588, South Korea; KAIST, 291 Daehak-ro, Yuseong-gu, Daejeon, 305-701, South Korea","Kwon, H., School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, 34141, South Korea, KAIST, 291 Daehak-ro, Yuseong-gu, Daejeon, 305-701, South Korea; Kim, Y., Department of Electrical Engineering, Korea Military Academy, Seoul, 01805, South Korea; Yoon, H., School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, 34141, South Korea; Choi, D., Department of Medical Information, Kongju National University, Gongju-si, 32588, South Korea","Deep neural networks (DNNs) have demonstrated remarkable performance in machine learning areas such as image recognition, speech recognition, intrusion detection, and pattern analysis. However, it has been revealed that DNNs have weaknesses in the face of adversarial examples, which are created by adding a little noise to an original sample to cause misclassification by the DNN. Such adversarial examples can lead to fatal accidents in applications such as autonomous vehicles and disease diagnostics. Thus, the generation of adversarial examples has attracted extensive research attention recently. An adversarial example is categorized as targeted or untargeted. In this paper, we focus on the untargeted adversarial example scenario because it has a faster learning time and less distortion compared with the targeted adversarial example. However, there is a pattern vulnerability with untargeted adversarial examples: Because of the similarity between the original class and certain specific classes, it may be possible for the defending system to determine the original class by analyzing the output classes of the untargeted adversarial examples. To overcome this problem, we propose a new method for generating untargeted adversarial examples, one that uses an arbitrary class in the generation process. Moreover, we show that our proposed scheme can be applied to steganography. Through experiments, we show that our proposed scheme can achieve a 100% attack success rate with minimum distortion (1.99 and 42.32 using the MNIST and CIFAR10 datasets, respectively) and without the pattern vulnerability. Using a steganography test, we show that our proposed scheme can be used to fool humans, as demonstrated by the probability of their detecting hidden classes being equal to that of random selection. © 2018 by the authors.","Adversarial example; Deep neural network; Random selection; Untargeted adversarial example",,,,,,"Schmidhuber, J., Deep learning in neural networks: An overview (2015) Neural Netw, 61, pp. 85-117; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) Proceedings of the International Conference on Learning Representations, , Banff, AB, Canada, 14-16 April; LeCun, Y., Cortes, C., Burges, C.J., MNIST Handwritten Digit Database (2010) AT&T Labs, 2. , http://yann.lecun.com/exdb/mnist, (accessed on 4 December 2018 ); Kwon, H., Kim, Y., Yoon, H., Choi, D., Fooling a Neural Network in Military Environments: Random Untargeted Adversarial Example (2018) Proceedings of the Military Communications Conference, , Los Angeles, CA, USA, 29-31 October; Cheddad, A., Condell, J., Curran, K., Mc Kevitt, P., Digital image steganography: Survey and analysis of current methods (2010) Signal Process, 90, pp. 727-752; Krizhevsky, A., Nair, V., Hinton, G., (2014) The CIFAR-10 Dataset, , http://www.cs.toronto.edu/kriz/cifar.html, (accessed on 4 December 2018 ); Barreno, M., Nelson, B., Joseph, A.D., Tygar, J., The security of machine learning (2010) Mach. Learn, 81, pp. 121-148; Biggio, B., Nelson, B., Laskov, P., Poisoning attacks against support vector machines (2012) Proceedings of the 29th International Coference on International Conference on Machine Learning, pp. 1467-1474. , Edinburgh, UK, 26 June-1 July; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Proceedings of the 2017 IEEE Symposium on Security and Privacy (SP), pp. 39-57. , San Jose, CA, USA, 22-24 May; Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582. , Las Vegas, NV, USA, 26 June-1 July; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519. , Abu Dhabi, UAE, 2-6 April; Kwon, H., Kim, Y., Park, K.W., Yoon, H., Choi, D., Advanced Ensemble Adversarial Example on Unknown Deep Neural Network Classifiers (2018) IEICE Trans. Inf. Syst, 101, pp. 2485-2500; Meng, D., Chen, H., Magnet: A two-pronged defense against adversarial examples (2017) Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pp. 135-147. , Dallas, TX, USA, 30 October-3 November; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 3-14. , Dallas, TX, USA, 3 November; Kwon, H., Yoon, H., Choi, D., POSTER: Zero-Day Evasion Attack Analysis on Race between Attack and Defense (2018) Proceedings of the 2018 on Asia Conference on Computer and Communications Security, pp. 805-807. , Songdo, Incheon, Korea, 4-8 June; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial Machine Learning at Scale (2017) Proceedings of the International Conference on Learning Representations (ICLR), , Toulon, France, 24-26 April; Narodytska, N., Kasiviswanathan, S., Simple black-box adversarial attacks on deep neural networks (2017) Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), pp. 1310-1318. , Honolulu, HI, USA, 21-26 July; Strauss, T., Hanselmann, M., Junginger, A., Ulmer, H., (2017) Ensemble Methods as a Defense to Adversarial Perturbations Against Deep Neural Networks, , arXiv; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and Harnessing Adversarial Examples (2015) Proceedings of the International Conference on Learning Representations, , San Diego, CA, USA, 7-9 May; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2017) Proceedings of the ICLRWorkshop, , Toulon, France, 24-26 April; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Proceedings of the 2016 IEEE Symposium on Security and Privacy (SP), pp. 582-597. , San Jose, CA, USA, 23-25 May; Kwon, H., Kim, Y., Park, K.W., Yoon, H., Choi, D., Friend-safe Evasion Attack: An adversarial example that is correctly recognized by a friendly classifier (2018) Comput. Secur, 78, pp. 380-397; Kwon, H., Kim, Y., Park, K.W., Yoon, H., Choi, D., Multi-Targeted Adversarial Example in Evasion Attack on Deep Neural Network (2018) IEEE Access, 6, pp. 46084-46096; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Proceedings of the 2016 IEEE European Symposium on Security and Privacy, pp. 372-387. , San Jose, CA, USA, 23-25 May; Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Isard, M., TensorFlow: A System for Large-Scale Machine Learning (2016) InProceedings of the 12th USENIX Symposium on Operating Systems Design and Implementation, 16, pp. 265-283. , Savannah, GA, USA, 2-4 November; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86, pp. 2278-2324; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778. , Las Vegas, NV, USA, 27-30 June; Kereliuk, C., Sturm, B.L., Larsen, J., Deep learning and music adversaries (2015) IEEE Trans. Multimed, 17, pp. 2059-2071","Choi, D.; Department of Medical Information, South Korea; email: sunchoi@kongju.ac.kr",,,"MDPI AG",,,,,20738994,,,,"English","Symmetry",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85059017272
"Bender M.A., Fineman J.T., Gilbert S., Young M.","35726657100;7006822085;9276991800;8952066700;","Scaling exponential backoff: Constant throughput, polylogarithmic channel-access attempts, and robustness",2018,"Journal of the ACM","66","1","6","","",,7,"10.1145/3276769","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058811277&doi=10.1145%2f3276769&partnerID=40&md5=26a06ab5c0245552cd2a4570f2392e2b","Department of Computer Science, Office 245, Stony Brook University, Stony Brook, NY  11794-2424, United States; Department of Computer Science, St. Mary's Hall, Georgetown University, 3700 O St. NW Office 346, Washington, DC  20057-1232, United States; Department of Computer Science, COM2-3-23, National University of Singapore, 1, 13 Computing Drive Office, Singapore; Department of Computer Science and Engineering, Butler Hall, Office 312, Mississippi State University, 4665 George Perry Street, MS, 39762, United States","Bender, M.A., Department of Computer Science, Office 245, Stony Brook University, Stony Brook, NY  11794-2424, United States; Fineman, J.T., Department of Computer Science, St. Mary's Hall, Georgetown University, 3700 O St. NW Office 346, Washington, DC  20057-1232, United States; Gilbert, S., Department of Computer Science, COM2-3-23, National University of Singapore, 1, 13 Computing Drive Office, Singapore; Young, M., Department of Computer Science and Engineering, Butler Hall, Office 312, Mississippi State University, 4665 George Perry Street, MS, 39762, United States","Randomized exponential backoff is a widely deployed technique for coordinating access to a shared resource. A good backoff protocol should, arguably, satisfy three natural properties: (1) it should provide constant throughput, wasting as little time as possible; (2) it should require few failed access attempts, minimizing the amount of wasted effort; and (3) it should be robust, continuing to work efficiently even if some of the access attempts fail for spurious reasons. Unfortunately, exponential backoff has some well-known limitations in two of these areas: it can suffer subconstant throughput under bursty traffic, and it is not robust to adversarial disruption. The goal of this article is to “fix” exponential backoff by making it scalable, particularly focusing on the case where processes arrive in an online, worst-case fashion. We present a relatively simple backoff protocol, Re-Backoff, that has, at its heart, a version of exponential backoff. It guarantees expected constant throughput with dynamic process arrivals and requires only an expected polylogarithmic number of access attempts per process. Re-Backoff is also robust to periods where the shared resource is unavailable for a period of time. If it is unavailable for D time slots, Re-Backoff provides the following guarantees. For n packets, the expected number of access attempts for successfully sending a packet is O(log 2 (n + D)). For the case of an infinite number of packets, we provide a similar result in terms of the maximum number of processes that are ever in the system concurrently. © 2018 Association for Computing Machinery.","Adversarial scheduling; Algorithms; Contention resolution; Distributed computing; Exponential backoff; Jamming attacks; Robustness; Throughput; Wireless networks","Algorithms; Distributed computer systems; Robustness (control systems); Scheduling algorithms; Wireless networks; Contention resolution; Exponential backoff; Infinite numbers; Jamming attacks; Natural properties; Polylogarithmic; Polylogarithmic numbers; Shared resources; Throughput",,,,,"Aldous, D.J., Ultimate instability of exponential back-off protocol for acknowledgment-based transmission control of random access communication channels (1987) IEEE Transactions on Information Theory, 33 (2), pp. 219-223. , 1987; Anantharamu, L., Chlebus, B.S., Kowalski, D.R., Rokicki, M.A., Medium access control for adversarial channels with jamming (2011) Proceedings of The 18th International Colloquium on Structural Information and Communication Complexity (SIROCCO'11), pp. 89-100; Anantharamu, L., Chlebus, B.S., Rokicki, M.A., Adversarial multiple access channel with individual injection rates (2009) Proceedings of The 13th International Conference on Principles of Distributed Systems (OPODIS'09), pp. 174-188; Anta, A.F., Mosteiro, M.A., Muñoz, J.R., Unbounded contention resolution in multiple-access channels (2013) Algorithmica, 67 (3), pp. 295-314. , 2013; Awerbuch, B., Richa, A., Scheideler, C., A jamming-resistant MAC protocol for single-hop wireless networks (2008) Proceedings of The 27th ACM Symposium on Principles of Distributed Computing (PODC'08), pp. 45-54; Azar, Y., Broder, A.Z., Karlin, A.R., Upfal, E., Balanced allocations (1999) SIAM Journal on Computing, 29 (1), pp. 180-200. , Sept. 1999; Bender, M.A., Farach-Colton, M., He, S., Kuszmaul, B.C., Leiserson, C.E., Adversarial contention resolution for simple channels (2005) Proceedings of The 17th Annual ACM Symposium on Parallelism in Algorithms and Architectures (SPAA'05), pp. 325-332; Bender, M.A., Fineman, J.T., Gilbert, S., Contention resolution with heterogeneous job sizes (2006) Proceedings of The 14th Annual European Symposium on Algorithms (ESA'06), pp. 112-123; Bender, M.A., Fineman, J.T., Gilbert, S., Young, M., How to scale exponential backoff: Constant throughput, polylog access attempts, and robustness (2016) Proceedings of The 27th Annual ACM-SIAM Symposium on Discrete Algorithms (SODA'16), pp. 636-654; Bender, M.A., Kopelowitz, T., Pettie, S., Young, M., Contention resolution with log-logstar channel accesses (2016) Proceedings of The 48th Annual Symposium on The Theory of Computing (STOC'16), pp. 499-508; Berenbrink, P., Czumaj, A., Englert, M., Friedetzky, T., Nagel, L., Multiple-choice balanced allocation in (almost) parallel (2012) Approximation, Randomization, and Combinatorial Optimization. Algorithms and Techniques (APPROX-RANDOM'12), pp. 411-422; Berenbrink, P., Czumaj, A., Steger, A., Vöcking, B., Balanced allocations: The heavily loaded case (2006) SIAM Journal on Computing, 35 (6), pp. 1350-1385. , 2006; Berenbrink, P., Khodamoradi, K., Sauerwald, T., Stauffer, A., Balls-into-bins with nearly optimal load distribution (2013) Proceedings of The 25th Annual ACM Symposium on Parallelism in Algorithms and Architectures (SPAA'13), pp. 326-335; Bernstein, D.J., (1998) Qmail - An Email Message Transfer Agent, , http://cr.yp.to/qmail.html, Retrieved from; Bianchi, G., Performance analysis of the IEEE 802.11 distributed coordination function (2006) IEEE Journal on Selected Areas in Communications, 18 (3), pp. 535-547. , Sept. 2006; Bianchi, G., Tinnirello, I., Kalman filter estimation of the number of competing terminals in an IEEE 802.11 network (2003) Proceedings of The 22nd Annual Joint Conference of The IEEE Computer and Communications Societies (INFOCOM'03), 2, pp. 844-852; Cali, F., Conti, M., Gregori, E., Dynamic tuning of the IEEE 802.11 protocol to achieve a theoretical throughput limit (2000) IEEE/ACM Transactions on Networking, 8 (6), pp. 785-799. , 2000; Cali, F., Conti, M., Gregori, E., IEEE 802.11 protocol: Design and performance evaluation of an adaptive backoff mechanism (2000) IEEE Journal on Selected Areas in Communications, 18 (9), pp. 1774-1786. , 2000; Capetanakis, J.I., Generalized TDMA: The multi-accessing tree protocol (1979) IEEE Transactions on Communications, 27 (10), pp. 1476-1484. , Oct. 1979; Chlebus, B.S., De Marco, G., Kowalski, D.R., Scalable wake-up of multi-channel single-hop radio networks (2016) Theoretical Computer Science, 615, pp. 23-44. , C Feb. 2016; Chlebus, B.S., Gasieniec, L., Kowalski, D.R., Radzik, T., On the wake-up problem in radio networks (2005) Proceedings of The 32nd International Colloquium on Automata, Languages and Programming (ICALP'05), pp. 347-359; Chlebus, B.S., Kowalski, D.R., A better wake-up in radio networks (2004) Proceedings of 23rd ACM Symposium on Principles of Distributed Computing (PODC'04), pp. 266-274; Chlebus, B.S., Kowalski, D.R., Rokicki, M.A., Adversarial queuing on the multiple-access channel (2006) Proceedings of The 25th Annual ACM Symposium on Principles of Distributed Computing (PODC'06), pp. 92-101; Chlebus, B.S., Kowalski, D.R., Rokicki, M.A., Adversarial queuing on the multiple access channel (2012) ACM Transactions on Algorithms, 8 (1), p. 5. , 2012; Chrobak, M., Gasieniec, L., Kowalski, D.R., The wake-up problem in multihop radio networks (2007) SIAM Journal on Computing, 36 (5), pp. 1453-1471. , 2007; Cole, R., Frieze, A.M., Maggs, B.M., Mitzenmacher, M., Richa, A.W., Sitaraman, R.K., Upfal, E., On balls and bins with deletions (1998) Proceedings of The 2nd International Workshop on Randomization and Approximation Techniques in Computer Science (RANDOM'98), pp. 145-158; Costales, B., Allman, E., (2002) Sendmail, , 3rd ed.). O'Reilly; De Marco, G., Stachowiak, G., Asynchronous shared channel (2017) Proceedings of The ACM Symposium on Principles of Distributed Computing (PODC'17), pp. 391-400; Fineman, J.T., Newport, C., Wang, T., Contention resolution on multiple channels with collision detection Proceedings of The ACM Symposium on Principles of Distributed Computing (PODC'16), pp. 175-184; Ganeriwal, S., Kumar, R., Srivastava, M.B., Timing-sync protocol for sensor networks (2003) Proceedings of The 1st International Conference on Embedded Networked Sensor Systems (SenSys'03), pp. 138-149; Ganeriwal, S., Pöpper, C., Capkun, S., Srivastava, M.B., Secure time synchronization in sensor networks (2008) ACM Transactions on Information and System Security, 11 (23), pp. 1-35. , 2008; Geréb-Graus, M., Tsantilas, T., Efficient optical communication in parallel computers (1992) Proceedings of The 4th Annual ACM Symposium on Parallel Algorithms and Architectures (SPAA'92), pp. 41-48; Goldberg, L.A., Jerrum, M., Leighton, T., Rao, S., A doubly logarithmic communication algorithm for the completely connected optical communication parallel computer (1993) Proceedings of The 4th Annual ACM Symposium on Parallel Algorithms and Architectures (SPAA'93), pp. 300-309; Goldberg, L.A., MacKenzie, P.D., Analysis of practical backoff protocols for contention resolution with multiple servers (1996) Proceedings of The 7th Annual ACM-SIAM Symposium on Discrete Algorithms (SODA'96), pp. 554-563; Goldberg, L.A., MacKenzie, P.D., Paterson, M., Srinivasan, A., (2000) Contention Resolution with Constant Expected Delay, 47 (6), pp. 1048-1096. , Nov. 2000; Goodman, J., Greenberg, A.G., Madras, N., March, P., Stability of binary exponential backoff (1988) Journal of The ACM, 35 (3), pp. 579-602. , July 1988; (2014) GCM (Google Cloud Messaging) Advanced Topics, , http://developer.android.com/google/gcm/adv.html#retry, Retrieved from; Greenberg, A.G., Flajolet, P., Ladner, R.E., Estimating the multiplicities of conflicts to speed their resolution in multiple access channels (1987) Journal of The ACM, 34 (2), pp. 289-325. , April 1987; Greenberg, A.G., Winograd, S., A lower bound on the time needed in the worst case to resolve conflicts deterministically in multiple access channels (1985) Journal of The ACM, 32 (3), pp. 589-596. , July 1985; Haas, Z.J., Deng, J., Dual busy tone multiple access (DBTMA) - A multiple access control scheme for ad hoc networks (2002) IEEE Transactions on Communications, 50 (6), pp. 975-985. , June 2002; Hastad, J., Leighton, T., Rogoff, B., Analysis of backoff protocols for multiple access channels (1996) SIAM Journal on Computing, 25 (4), pp. 740-774. , 1996; Herlihy, M., Eliot, J., Moss, B., Transactional memory: Architectural support for lock-free data structures (1993) Proceedings of The 20th International Conference on Computer Architecture, pp. 289-300. , http://www.cs.brown.edu/people/mph/isca2.ps, Retrieved from; Hussain, A., Heidemann, J., Papadopoulos, C., A framework for classifying denial of service attacks (2003) 2003 Conference on Applications, Technologies, Architectures, and Protocols for Computer Communications (SIGCOMM'03), pp. 99-110; Jacobson, V., Congestion avoidance and control (1988) SIGCOMM Computer Communication Review, 18 (4), pp. 314-329. , Aug. 1988; Jurdzinski, T., Stachowiak, G., The cost of synchronizing multiple-access channels (2015) Proceedings of The ACM Symposium on Principles of Distributed Computing (PODC'15), pp. 421-430; Klonowski, M., Pajak, D., Electing a leader in wireless networks quickly despite jamming (2015) Proceedings of The 27th ACM on Symposium on Parallelism in Algorithms and Architectures, pp. 304-312; Kurose, J.F., Ross, K., (2002) Computer Networking: A Top-Down Approach Featuring The Internet, , 2nd ed.). Addison-Wesley Longman Publishing Co., Boston, MA; Kwak, B.-J., Song, N.-O., Miller, L.E., Performance analysis of exponential backoff (2005) IEEE/ACM Transactions on Networking, 13 (2), pp. 343-355. , 2005; Li, Y., Ye, W., Heidemann, J., Energy and latency control in low duty cycle MAC protocols (2005) Proceedings of The IEEE Wireless Communications and Networking Conference (WCNC'05), pp. 676-682; De Marco, G., Kowalski, D.R., Fast nonadaptive deterministic algorithm for conflict resolution in a dynamic multiple-access channel (2015) SIAM Journal on Computing, 44 (3), pp. 868-888. , 2015; De Marco, G., Kowalski, D.R., Contention resolution in a non-synchronized multiple access channel (2017) Theoretical Computer Science, 689 (2017), pp. 1-13; Metcalfe, R.M., Boggs, D.R., Ethernet: Distributed packet switching for local computer networks (1976) Communications of The ACM, 19 (7), pp. 395-404. , July 1976; Mills, D.L., Internet time synchronization: The network time protocol (1991) IEEE Transactions on Communications, 39 (10), pp. 1482-1493. , 1991; Mitzenmacher, M., The power of two choices in randomized load balancing (2001) IEEE Transactions on Parallel and Distributed Systems, 12 (10), pp. 1094-1104. , Oct. 2001; Mitzenmacher, M., Upfal, E., (2005) Probability and Computing: Randomized Algorithms and Probabilistic Analysis, , Cambridge University Press; Mitzenmacher, M., Richa, A.W., Sitaraman, R., The power of two random choices: A survey of techniques and results (2001) Combinatorial Optimization, 9, pp. 255-304. , 2001; Mondal, A., Kuzmanovic, A., Removing exponential backoff from TCP (2008) SIGCOMM Computer Communication Review, 38 (5), pp. 17-28. , Sept. 2008; Ogierman, A., Richa, A., Scheideler, C., Schmid, S., Zhang, J., SADE: Competitive MAC under adversarial SINR (2018) Distributed Computing, 31 (3), pp. 241-254. , June 2018; (2011) Google Documents List API Version 3.0: Implementing Exponential Backoff, , https://developers.google.com/google-apps/documents-list/?csw=1#implementing_exponential_backoff, Google Apps Platform; Raghavan, P., Upfal, E., Stochastic contention resolution with short delays (1995) Proceedings of The 27th Annual ACM Symposium on The Theory of Computing (STOC'95), pp. 229-237; Raghavan, P., Upfal, E., Stochastic contention resolution with short delays (1999) SIAM Journal on Computing, 28 (2), pp. 709-719. , 1999; Rajwar, R., Goodman, J.R., Speculative lock elision: Enabling highly concurrent multithreaded execution (2001) Proceedings of The 34th Annual International Symposium on Microarchitecture, pp. 294-305. , http://www.cs.wisc.edu/rajwar/papers/micro01.pdf, Retrieved from; Richa, A., Scheideler, C., Schmid, S., Zhang, J., A jamming-resistant MAC protocol for multi-hop wireless networks (2010) Proceedings of The International Symposium on Distributed Computing (DISC'10), pp. 179-193; Richa, A., Scheideler, C., Schmid, S., Zhang, J., Competitive and fair medium access despite reactive jamming (2011) Proceedings of The 31st International Conference on Distributed Computing Systems (ICDCS'11), pp. 507-516; Richa, A., Scheideler, C., Schmid, S., Zhang, J., Competitive and fair throughput for co-existing networks under adversarial interference (2012) Proceedings of The 31st ACM Symposium on Principles of Distributed Computing (PODC'12), pp. 291-300; Richa, A., Scheideler, C., Schmid, S., Zhang, J., Competitive throughput in multi-hop wireless networks despite adaptive jamming (2013) Distributed Computing, 26 (3), pp. 159-171. , 2013; Richa, A., Scheideler, C., Schmid, S., Zhang, J., An efficient and fair MAC protocol robust to reactive interference (2013) IEEE/ACM Transactions on Networking, 21 (1), pp. 760-771. , 2013; (2012) Error Retries and Exponential Backoff in AWS, , http://docs.aws.amazon.com/general/latest/gr/api-retries.html, Retrieved from; Wu, C.S., Li, V.O.K., Receiver-initiated busy-tone multiple access in packet radio networks (1988) Proceedings of The ACM Workshop on Frontiers in Computer Communications Technology (SIGCOMM'87), pp. 336-342; Song, N.-O., Kwak, B.-J., Miller, L.E., On the stability of exponential backoff (2003) Journal of Research of The National Institute of Standards and Technology, 108 (4), pp. 289-297. , 2003; Vöcking, B., How asymmetry helps load balancing (2003) Journal of The ACM, 50 (4), pp. 568-589. , 2003; Walters, J.P., Liang, Z., Shi, W., Chaudhary, V., Wireless sensor network security: A survey (2007) Security in Distributed, Grid, Mobile, and Pervasive Computing, , Auerbach Publications; Willard, D.E., Log-logarithmic selection resolution protocols in a multiple access channel (1986) SIAM Journal on Computing, 15 (2), pp. 468-477. , May 1986; Xiao, Y., Performance analysis of priority schemes for IEEE 802.11 and IEEE 802.11e wireless LANs (2005) IEEE Transactions on Wireless Communications, 4 (4), pp. 1506-1515. , July 2005; Xu, W., Trappe, W., Zhang, Y., Wood, T., The feasibility of launching and detecting jamming attacks in wireless networks (2005) ACM International Symposium on Mobile Ad Hoc Networking and Computing (Mobihoc'05), pp. 46-57",,,,"Association for Computing Machinery",,,,,00045411,,JOACF,,"English","J ACM",Conference Paper,"Final","All Open Access, Bronze",Scopus,2-s2.0-85058811277
"Krotov D., Hopfield J.","57147760800;7005786187;","Dense associative memory is robust to adversarial inputs",2018,"Neural Computation","30","12",,"3151","3167",,22,"10.1162/neco_a_01143","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057032370&doi=10.1162%2fneco_a_01143&partnerID=40&md5=c9b8b799a17514fe421605accbc1302d","Institute for Advanced Study, Princeton, NJ  08540, United States; Princeton Neuroscience Institute, Princeton, NJ  08544, United States","Krotov, D., Institute for Advanced Study, Princeton, NJ  08540, United States; Hopfield, J., Princeton Neuroscience Institute, Princeton, NJ  08544, United States","Deep neural networks (DNNs) trained in a supervised way suffer from two known problems. First, the minima of the objective function used in learning correspond to data points (also known as rubbish examples or fooling images) that lack semantic similarity with the training data. Second, a clean input can be changed by a small, and often imperceptible for human vision, perturbation so that the resulting deformed input is misclassified by the network. These findings emphasize the differences between the ways DNNs and humans classify patterns and raise a question of designing learning algorithms that more accurately mimic human perception compared to the existing methods. Our article examines these questions within the framework of dense associative memory (DAM) models. These models are defined by the energy function, with higher-order (higher than quadratic) interactions between the neurons. We show that in the limit when the power of the interaction vertex in the energy function is sufficiently large, these models have the following three properties. First, the minima of the objective function are free from rubbish images, so that each minimum is a semantically meaningful pattern. Second, artificial patterns poised precisely at the decision boundary look ambiguous to human subjects and share aspects of both classes that are separated by that decision boundary. Third, adversarial images constructed by models with small power of the interaction vertex, which are equivalent to DNN with rectified linear units, fail to transfer to and fool the models with higher-order interactions. This opens up the possibility of using higher-order models for detecting and stopping malicious adversarial attacks. The results we present suggest that DAMs with higher-order energy functions are more robust to adversarial and rubbish inputs than DNNs with rectified linear units. © 2018 Massachusetts Institute of Technology.",,"Associative processing; Associative storage; Learning algorithms; Memory architecture; Semantics; Associative memory; Decision boundary; Energy functions; Higher-order models; Human perception; Interaction vertex; Objective functions; Semantic similarity; Deep neural networks; brain; human; pattern recognition; physiology; Brain; Humans; Neural Networks, Computer; Pattern Recognition, Visual",,,,,"Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and harnessing adversarial examples; Gu, S., Rigazio, L., (2014) Towards deep neural network architectures robust to adversarial examples; Huang, R., Xu, B., Schuurmans, D., Szepesvári, C., (2015) Learning with a strong adversary; Krotov, D., Hopfield, J.J., Dense associative memory for pattern recognition (2016) Advances in neural information processing systems, 29, pp. 1172-1180. , In D. D. Lee, N. Sugiyama, U. V. Luxburg, I. Guyon, & R. Garnett (Eds.) Red Hook, NY: Curran; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2016); Miyato, T., Maeda, S.-I., Koyama, M., Nakae, K., Ishii, S., (2015) Distributional smoothing with virtual adversarial training; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 427-436. , Piscataway, NJ: IEEE; Nøkland, A., (2015) Improving back-propagation by adding an adversarial gradient; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in machine learning: From phenomena to black-box attacks using adversarial samples; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., (2016) Practical black-box attacks against deep learning systems using adversarial examples; Simard, P.Y., Steinkraus, D., Platt, J.C., Best practices for convolutional neural networks applied to visual document analysis (2003) In Proceedings of the International Conference on Document Analysis and Recognition, pp. 958-962. , New York: ACM; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing properties of neural networks; Wang, Q., Guo, W., Zhang, K., Xing, X., Giles, C.L., Liu, X., (2016) Random feature nullification for adversary resistant deep architecture",,,,"MIT Press Journals",,,,,08997667,,,"30314425","English","Neural Comp.",Letter,"Final","All Open Access, Green",Scopus,2-s2.0-85057032370
"Khorshidpour Z., Tahmoresnezhad J., Hashemi S., Hamzeh A.","36668707900;57003652000;14038956200;13405284800;","Domain invariant feature extraction against evasion attack",2018,"International Journal of Machine Learning and Cybernetics","9","12",,"2093","2104",,1,"10.1007/s13042-017-0692-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056591445&doi=10.1007%2fs13042-017-0692-6&partnerID=40&md5=119b1211e15c9bc48422d5980840684b","Department of Computer Science Engineering and Information Technology, School of Electrical and Computer Engineering, Shiraz University, Shiraz, Iran","Khorshidpour, Z., Department of Computer Science Engineering and Information Technology, School of Electrical and Computer Engineering, Shiraz University, Shiraz, Iran; Tahmoresnezhad, J., Department of Computer Science Engineering and Information Technology, School of Electrical and Computer Engineering, Shiraz University, Shiraz, Iran; Hashemi, S., Department of Computer Science Engineering and Information Technology, School of Electrical and Computer Engineering, Shiraz University, Shiraz, Iran; Hamzeh, A., Department of Computer Science Engineering and Information Technology, School of Electrical and Computer Engineering, Shiraz University, Shiraz, Iran","In the security application, an attacker might violate the data stationary assumption that is a common assumption in the most machine learning techniques. This problem named as the domain shift problem arises when training (source) and test (target) data follow different distributions. The inherent adversarial nature of the security applications considerably effects on the robustness of a learning system. For that, a classifier designer needs to evaluate the robustness of a learning system under potential attacks during the design phase. The previous studies investigate the effect of reduced feature vector on the security evaluation of a learning classifier. They demonstrate that traditional feature selection techniques lead to even worsen performance. Therefore, an adversary-aware feature selection algorithm is proposed to improve the robustness of the learning systems. However, prior studies in domain adaptation techniques which are fundamental in addressing domain shift problem demonstrate that original space may not be directly suitable for refining this distribution mismatch, because some features may have been distorted by the domain shift. In this paper, we propose domain invariant feature extraction model based on domain adaptation technique in order to address domain shift problem caused by an adversary. We conduct an experiment that graphically shows the effect of a successful attack on the MNIST handwritten digits classification task. After that, we design synthetic datasets to investigate the effect of reduced feature vector on the performance of a learning system under attack. Moreover, our proposed feature extraction model significantly outperforms the adversarial-aware feature selection and traditional feature selection models on the application of spam filtering. © 2017, Springer-Verlag Berlin Heidelberg.","Adversarial environment; Domain adaptation; Domain shift; Evasion attack; Spam filtering","Character recognition; Extraction; Learning systems; Adversarial environments; Domain adaptation; Domain shift; Evasion attack; Spam filtering; Feature extraction",,,,,"Barreno, M., Nelson, B., Joseph, A.D., Tygar, J., The security of machine learning (2010) Mach Learn, 81 (2), pp. 121-148; Barreno, M., Nelson, B., Sears, R., Joseph, A.D., Tygar, J.D., Can machine learning be secure? (2006) Proceedings of the 2006 ACM Symposium on Information, Computer and Communications Security, pp. 16-25. , ACM; Basu, T., Murthy, C., A supervised term selection technique for effective text categorization (2016) Int J Mach Learn Cybern, 7 (5), pp. 877-892; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndić, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Machine Learning and Knowledge Discovery in Databases. Springer, pp. 387-402; Biggio, B., Fumera, G., Roli, F., Security evaluation of pattern classifiers under attack (2014) Knowl Data Eng IEEE Trans, 26 (4), pp. 984-996; Blitzer, J., McDonald, R., Pereira, F., Domain adaptation with structural correspondence learning (2006) Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pp. 120-128. , Association for Computational Linguistics; Brückner, M., Kanzow, C., Scheffer, T., Static prediction games for adversarial learning problems (2012) J Mach Learn Res, 13 (1), pp. 2617-2654; Brückner, M., Scheffer, T., Stackelberg games for adversarial prediction problems (2011) Proceedings of the 17Th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 547-555. , ACM; Byrd, R.H., Lu, P., Nocedal, J., Zhu, C., A limited memory algorithm for bound constrained optimization (1995) SIAM J Sci Comput, 16 (5), pp. 1190-1208; Cao, J., Chen, T., Fan, J., Landmark recognition with compact bow histogram and ensemble ELM (2016) Multimed Tools Appl, 75 (5), pp. 2839-2857; Chen, J., Guo, M., Wang, X., Liu, B., A comprehensive review and comparison of different computational methods for protein remote homology detection (2016) Briefings in Bioinformatics, 19 (2), pp. 231-244; Frustratingly easy domain adaptation (2007) Proceedings of the 45Th Annual Meeting of the Association of Computational Linguistics, pp. 256-263. , Prague, Czech Republic; Dekel, O., Shamir, O., Xiao, L., Learning to classify with missing and corrupted features (2010) Mach Learn, 81 (2), pp. 149-178; Duan, L., Tsang, I.W., Xu, D., Maybank, S.J., Domain transfer svm for video concept detection (2009) IEEE Conference on Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE, pp. 1375-1381; Gopalan, R., Li, R., Chellappa, R., Unsupervised adaptation across domain shifts by generating intermediate data representations (2014) Pattern Ana Mach Intell IEEE Trans, 36 (11), pp. 2288-2302; Huang, J., Gretton, A., Borgwardt, K.M., Schölkopf, B., Smola, A.J., Correcting sample selection bias by unlabeled data (2006) Advances in Neural Information Processing Systems, pp. 601-608; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I., Tygar, J., Adversarial machine learning (2011) Proceedings of the 4Th ACM Workshop on Security and Artificial Intelligence, pp. 43-58. , ACM; Jorgensen, Z., Zhou, Y., Inge, M., A multiple instance learning strategy for combating good word attacks on spam filters (2008) J Mach Learn Res, 9, pp. 1115-1146; Kołcz, A., Teo, C.H., Feature weighting for improved classifier robustness (2009) CEAS09: Sixth Conference on Email and Anti-Spam; Li, B., Vorobeychik, Y., Feature cross-substitution in adversarial classification (2014) Advances in Neural Information Processing Systems, pp. 2087-2095; Liu, B., Wang, S., Dong, Q., Li, S., Liu, X., Identification of DNA-binding proteins by combining auto-cross covariance transformation and ensemble learning (2016) IEEE Trans Nanobiosci, 15 (4), pp. 328-334; Long, M., Wang, J., Ding, G., Sun, J., Yu, P., Transfer feature learning with joint distribution adaptation (2013) In: Proceedings of the IEEE International Conference on Computer Vision, pp. 2200-2207; Long, M., Wang, J., Ding, G., Sun, J., Yu, P., Transfer joint matching for unsupervised domain adaptation (2014) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1410-1417; Lowd, D., Meek, C., Adversarial learning (2005) Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining. ACM, pp. 641-647; Macdonald, C., Ounis, I., Soboroff, I., Overview of the TREC 2007 blog track (2007) TREC, 7, pp. 31-43. , Citeseer; Nelson, B., Barreno, M., Chi, F.J., Joseph, A.D., Rubinstein, B.I., Saini, U., Sutton, C., Xia, K., Misleading learners: Co-opting your spam filter (2009) Machine Learning in Cyber Trust, pp. 17-51. , Springer; Hearst, M.A., Support vector machines (1998) IEEE Intell Syst App, 13 (4), pp. 18-28; Pan, S.J., Ni, X., Sun, J.-T., Yang, Q., Chen, Z., Cross-domain sentiment classification via spectral feature alignment (2010) In: Proceedings of the 19Th International Conference on World Wide Web, pp. 751-760. , ACM; Pan, S.J., Tsang, I.W., Kwok, J.T., Yang, Q., Domain adaptation via transfer component analysis (2011) Neural Netw IEEE Trans, 22 (2), pp. 199-210; Saenko, K., Kulis, B., Fritz, M., Darrell, T., Adapting visual category models to new domains (2010) Computer vision—ECCV 2010, pp. 213-226. , Springer; Shah, A.R., Oehmen, C.S., Webb-Robertson, B.-J., Svm-hustlean iterative semi-supervised machine learning approach for pairwise protein remote homology detection (2008) Bioinformatics, 24 (6), pp. 783-790; Uguroglu, S., Carbonell, J., Feature selection for transfer learning (2011) Machine Learning and Knowledge Discovery in Databases. Springer, pp. 430-442; Wang, F., Liu, W., Chawla, S., On sparse feature attacks in adversarial learning (2014) 2014 IEEE International Conference on Data Mining (ICDM). IEEE, pp. 1013-1018; Xiao, H., Biggio, B., Brown, G., Fumera, G., Eckert, C., Roli, F., Is feature selection secure against training data poisoning? (2015) Proceedings of the 32Nd International Conference on Machine Learning (ICML-15), pp. 1689-1698; Zhang, F., Adversarial feature selection against evasion attacks (2016) IEEE Trans Cybern, 46 (3), pp. 766-777; Zhu, C., Byrd, R.H., Lu, P., Nocedal, J., Algorithm 778: L-bfgs-b: Fortran subroutines for large-scale bound-constrained optimization (1997) ACM Trans Math Softw (TOMS), 23 (4), pp. 550-560","Hashemi, S.; Department of Computer Science Engineering and Information Technology, Iran; email: s_hashemi@shirazu.ac.ir",,,"Springer Verlag",,,,,18688071,,,,"English","Intl. J. Mach. Learn. Cybern.",Article,"Final","",Scopus,2-s2.0-85056591445
"Lange J., Massart C., Mouraux A., Standaert F.-X.","57195492802;57195492259;6602503125;7003669750;","Side-channel attacks against the human brain: the PIN code case study (extended version)",2018,"Brain Informatics","5","2","12","","",,4,"10.1186/s40708-018-0090-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055685693&doi=10.1186%2fs40708-018-0090-1&partnerID=40&md5=a131a24365fcd79b9fa557d2ff6db8cb","UCLouvain, Louvain-la-Neuve, 1348, Belgium","Lange, J., UCLouvain, Louvain-la-Neuve, 1348, Belgium; Massart, C., UCLouvain, Louvain-la-Neuve, 1348, Belgium; Mouraux, A., UCLouvain, Louvain-la-Neuve, 1348, Belgium; Standaert, F.-X., UCLouvain, Louvain-la-Neuve, 1348, Belgium","We revisit the side-channel attacks with brain–computer interfaces (BCIs) first put forward by Martinovic et al. at the USENIX 2012 Security Symposium. For this purpose, we propose a comprehensive investigation of concrete adversaries trying to extract a PIN code from electroencephalogram signals. Overall, our results confirm the possibility of partial PIN recovery with high probability of success in a more quantified manner and at the same time put forward the challenges of full/systematic PIN recovery. They also highlight that the attack complexities can significantly vary in function of the adversarial capabilities (e.g., supervised/profiled vs. unsupervised/non-profiled), hence leading to an interesting trade-off between their efficiency and practical relevance. We then show that similar attack techniques can be used to threat the privacy of BCI users. We finally use our experiments to discuss the impact of such attacks for the security and privacy of BCI applications at large, and the important emerging societal challenges they raise. © 2018, The Author(s).","Brain–computer interfaces (BCIs); Electroencephalography (EEGs); Privacy; Security","Brain computer interface; Computer privacy; Data privacy; Economic and social effects; Electroencephalography; Electrophysiology; Attack complexity; BCI applications; Electroencephalogram signals; Extended versions; High probability; Human brain; Security; Security and privacy; Side channel attack; article; brain computer interface; electroencephalogram; electroencephalography; human; privacy; probability; remission",,,,,"Engel, J., Kuhl, D.E., Phelps, M.E., Crandall, P.H., Comparative localization of foci in partial epilepsy by PCT and EEG (1982) Ann Neurol, 12 (6), pp. 529-537; Portas, C.M., Krakow, K., Allen, P., Josephs, O., Armony, J.L., Frith, C.D., Auditory processing across the sleep-wake cycle: simultaneous EEG and FMRI monitoring in humans (2000) Neuron, 28 (3), pp. 991-999; Lin, C., Wu, R., Liang, S., Chao, W., Chen, Y., Jung, T., Eeg-based drowsiness estimation for safety driving using independent component analysis (2005) IEEE Trans Circuits Syst, 52–I (12), pp. 2726-2738; Coyle, D., Príncipe, J.C., Lotte, F., Nijholt, A., Guest editorial: brain/neuronal—computer game interfaces and interaction (2013) IEEE Trans Comput Intell AI Games, 5 (2), pp. 77-81; Bonaci, T., Calo, R., Chizeck, H.J., App stores for the brain: privacy and security in brain–computer interfaces (2015) IEEE Technol Soc Mag, 34 (2), pp. 32-39; Ienca, M., Hacking the brain: brain–computer interfacing technology and the ethics of neurosecurity (2016) Ethics Inf Technol, 18 (2), pp. 117-129; Martinovic, I., Davies, D., Frank, M., Perito, D., Ros, T., Song, D., On the feasibility of side-channel attacks with brain-computer interfaces (2012) USENIX Security Symposium. Proceedings, pp. 143-158. , Kohno T, ed, USENIX Association; Farwell, L.A., Donchin, E., The truth will out: interrogative polygraphy (lie detection) with event-related brain potentials (1991) Psychophysiology, 28 (5), pp. 531-547; Inzlicht, M., McGregor, I., Hirsh, J.B., Nash, K., Neural markers of religious conviction (2009) Psychol Sci, 20 (3), pp. 385-392; Berlad, I., Pratt, H., P300 in response to the subject’s own name (1995) Electroencephalogr Clin Neurophysiol, 96 (5), pp. 472-474; Kutas, M., Hillyard, S.A., Reading senseless sentences: brain potentials reflect semantic incongruity (1980) Science, 207, pp. 203-205; Kutas, M., Hillyard, S.A., Brain potentials during reading reflect word expectancy and semantic association (1984) Nature, 307, pp. 161-163; http://emotiv.com/, Last retrieved July 2016; (2016), http://neurosky.com/, Last retrieved July; Mangard, S., Oswald, E., Popp, T., (2007) Power analysis attacks—revealing the secrets of smart cards, , Springer, Berlin; (2016), http://www.chesworkshop.org/, Last retrieved July; Standaert, F., Malkin, T., Yung, M., A unified framework for the analysis of side-channel key recovery attacks (2009) EUROCRYPT. Proceedings, Volume 5479 of LNCS. Springer, pp. 443-461. , Joux A; Veyrat-Charvillon, N., Gérard, B., Renauld, M., Standaert, F., An optimal key enumeration algorithm and its application to side-channel attacks (2012) SAC. Proceedings, Volume 7707 of LNCS, pp. 390-406. , KnudsenLR, Wu H, Springer; Archambeau, C., Peeters, E., Standaert, F., Quisquater, J., Template attacks in principal subspaces (2006) CHES 2006. Proceedings, 4249, pp. 1-14. , Goubin L, Matsui M; Chari, S., Rao, J.R., Rohatgi, P., Template attacks (2002) CHES. Proceedings. Volume 2523 of LNCS, pp. 13-28. , Kaliski Jr BS, Koç ÇK, Paar C, Springer; Batina, L., Gierlichs, B., Prouff, E., Rivain, M., Standaert, F., Veyrat-Charvillon, N., Mutual information analysis: a comprehensive study (2011) J Cryptol, 24 (2), pp. 269-291; Durvaux, F., Standaert, F., Veyrat-Charvillon, N., How to certify the leakage of a chip? (2014) EUROCRYPT. Proceedings, Volume 8441 of LNCS. Springer, pp. 459-476. , Nguyen PQ, Oswald E; Silverman, B.W., (1986) Density estimation for statistics and data analysis, , Chapman & Hall, London; Renauld, M., Standaert, F., Veyrat-Charvillon, N., Kamel, D., Flandre, D., A formal study of power variability issues and side-channel attacks for nanoscale devices (2011) EUROCRYPT 2011. Proceedings, Volume 6632 of LNCS. Springer, pp. 109-128. , Paterson KG; Duc, A., Faust, S., Standaert, F., Making masking security proofs concrete—or how to evaluate the security of any leaking device (2015) EUROCRYPT 2015. Proceedings, 9056, pp. 401-429. , Oswald E, Fischlin M, eds, Part I, of LNCS. Springer; Efron, B., Tibshirani, R.J., (1994) An introduction to the bootstrap, , CRC Press, Boca Raton; Standaert, F.-X., Koeune, F., Schindler, W., How to Compare Profiled Side-Channel Attacks? (2009) Applied Cryptography and Network Security, pp. 485-498. , Springer Berlin Heidelberg, Berlin, Heidelberg; Marcel, S., Millán, J.R., Person authentication using brainwaves (EEG) and maximum A posteriori model adaptation (2007) IEEE Trans Pattern Anal Mach Intell, 29 (4), pp. 743-752; Paranjape, R.B., Mahovsky, J., Benedicenti, L., Koles, Z., The electroencephalogram as a biometric (2001) Electrical and Computer Engineering, 2, pp. 1363-1366. , IEEE; Veyrat-Charvillon, N., Gérard, B., Standaert, F., Security evaluations beyond computing power (2013) EUROCRYPT. Proceedings, 7881, pp. 126-141. , Johansson T, Nguyen PQ; Smart, N.P., Computing on encrypted data (2016) Kayaks and Dreadnoughts in a Sea of Crypto, , September 2016","Standaert, F.-X.; UCLouvainBelgium; email: fstandae@uclouvain.be",,,"Springer Berlin Heidelberg",,,,,21984018,,,,"English","Brain Informatics",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85055685693
"Biggio B., Roli F.","23090165100;57194734588;","Wild patterns: Ten years after the rise of adversarial machine learning",2018,"Pattern Recognition","84",,,"317","331",,380,"10.1016/j.patcog.2018.07.023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050603085&doi=10.1016%2fj.patcog.2018.07.023&partnerID=40&md5=db06d07e44c9130f26a1d0f4fba0ea81","Department of Electrical and Electronic Engineering, University of Cagliari, Italy; Pluribus One, Cagliari, Italy","Biggio, B., Department of Electrical and Electronic Engineering, University of Cagliari, Italy, Pluribus One, Cagliari, Italy; Roli, F., Department of Electrical and Electronic Engineering, University of Cagliari, Italy, Pluribus One, Cagliari, Italy","Learning-based pattern classifiers, including deep networks, have shown impressive performance in several application domains, ranging from computer vision to cybersecurity. However, it has also been shown that adversarial input perturbations carefully crafted either at training or at test time can easily subvert their predictions. The vulnerability of machine learning to such wild patterns (also referred to as adversarial examples), along with the design of suitable countermeasures, have been investigated in the research field of adversarial machine learning. In this work, we provide a thorough overview of the evolution of this research area over the last ten years and beyond, starting from pioneering, earlier work on the security of non-deep learning algorithms up to more recent work aimed to understand the security properties of deep learning algorithms, in the context of computer vision and cybersecurity tasks. We report interesting connections between these apparently-different lines of work, highlighting common misconceptions related to the security evaluation of machine-learning algorithms. We review the main threat models and attacks defined to this end, and discuss the main limitations of current work, along with the corresponding future challenges towards the design of more secure learning algorithms. © 2018 Elsevier Ltd","Adversarial examples; Adversarial machine learning; Deep learning; Evasion attacks; Poisoning attacks; Secure learning","Artificial intelligence; Computer vision; Deep learning; Evolutionary algorithms; Adversarial examples; Evasion attacks; Input perturbation; Pattern classifier; Poisoning attacks; Secure learning; Security evaluation; Security properties; Learning algorithms",,,,,"Gu, J., Wang, Z., Kuen, J., Ma, L., Shahroudy, A., Shuai, B., Liu, T., Chen, T., Recent advances in convolutional neural networks (2018) Pattern Recognit., 77, pp. 354-377; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) Proceedings of the ICLR; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) Proceedings of the ICLR; Nguyen, A.M., Yosinski, J., Clune, J., Deep neural networks are easily fooled: high confidence predictions for unrecognizable images (2015) Proceedings of the IEEE CVPR, pp. 427-436; Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P., Deepfool: a simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE CVPR, pp. 2574-2582; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Proceedings of the IEEE (SP), pp. 582-597; Melis, M., Demontis, A., Biggio, B., Brown, G., Fumera, G., Roli, F., Is deep learning safe for robot vision? adversarial examples against the iCub humanoid (2017) Proceedings of the ICCV Workshop; Meng, D., Chen, H., MagNet: a two-pronged defense against adversarial examples (2017) Proceedings of the Twenty Fourth ACM (CCS); Lu, J., Issaranon, T., Forsyth, D., SafetyNet: detecting and rejecting adversarial examples robustly (2017) Proceedings of the IEEE ICCV; Li, X., Li, F., Adversarial examples detection in deep networks with convolutional filter statistics (2017) Proceedings of the IEEE ICCV; Grosse, K., Papernot, N., Manoharan, P., Backes, M., McDaniel, P.D., Adversarial examples for malware detection (2017) Proceedings of the ESORICS (2), LNCS, 10493, pp. 62-79. , Springer; Jordaney, R., Sharad, K., Dash, S.K., Wang, Z., Papini, D., Nouretdinov, I., Cavallaro, L., Transcend: detecting concept drift in malware classification models (2017) Proceedings of the USENIX Security Symposium, pp. 625-642. , USENIX Association; McDaniel, P., Papernot, N., Celik, Z.B., Machine learning in adversarial settings (2016) IEEE Secur. Priv., 14 (3), pp. 68-72; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Proceedings of the First IEEE European Symposium Security and Privacy, pp. 372-387; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the ASIA CCS, pp. 506-519. , ACM; Carlini, N., Wagner, D.A., Towards evaluating the robustness of neural networks (2017) Proceedings of the IEEE SP, pp. 39-57; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: real and stealthy attacks on state-of-the-art face recognition (2016) Proceedings of the CCS, pp. 1528-1540. , ACM; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., Adversarial examples for semantic segmentation and object detection (2017) Proceedings of the IEEE ICCV; Dalvi, N., Domingos, P., Mausam, Sanghai, S., Verma, D., Adversarial classification (2004) Proceedings of the ICKDDM, pp. 99-108; Lowd, D., Meek, C., Adversarial learning (2005) Proceedings of the ICKDDM, pp. 641-647. , ACM Press Chicago, IL, USA; Lowd, D., Meek, C., Good word attacks on statistical spam filters, Mountain View, CA, USA (2005) Proceedings of the Second CEAS; Matsumoto, T., Matsumoto, H., Yamada, K., Hoshino, S., Impact of artificial “gummy” fingers on fingerprint systems (2002) Datenschutz und Datensicherheit, 26 (8); Barreno, M., Nelson, B., Sears, R., Joseph, A.D., Tygar, J.D., Can machine learning be secure? (2006) Proceedings of the ASIA CCS, pp. 16-25. , ACM; Nelson, B., Barreno, M., Chi, F.J., Joseph, A.D., Rubinstein, B.I.P., Saini, U., Sutton, C., Xia, K., Exploiting machine learning to subvert your spam filter (2008) Proceedings of the LEET, USENIX Association, pp. 1-9; Rubinstein, B.I., Nelson, B., Huang, L., Joseph, A.D., Lau, S.H., Rao, S., Taft, N., Tygar, J.D., Antidote: understanding and defending against poisoning of anomaly detectors (2009) Proceedings of the IMC, pp. 1-14. , ACM; Biggio, B., Nelson, B., Laskov, P., Poisoning attacks against support vector machines (2012) Proceedings of the Twenty Ninth ICML, pp. 1807-1814; Kloft, M., Laskov, P., Online anomaly detection under adversarial impact (2010) Proceedings of the Thirteenth AISTATS, pp. 405-412; Kloft, M., Laskov, P., Security analysis of online centroid anomaly detection (2012) Proceedings of the JMLR, pp. 3647-3690; Xiao, H., Biggio, B., Brown, G., Fumera, G., Eckert, C., Roli, F., Is feature selection secure against training data poisoning? (2015) Proceedings of the Thirt Second ICML, 37, pp. 1689-1698; Biggio, B., Corona, I., Nelson, B., Rubinstein, B., Maiorca, D., Fumera, G., Giacinto, G., Roli, F., Security evaluation of support vector machines in adversarial environments (2014) Support Vector Machines Applications, pp. 105-153. , Y. Ma G. Guo Springer International Publishing Cham; Mei, S., Zhu, X., Using machine teaching to identify optimal training-set attacks on machine learners (2015) Proceedings of the Twenty Ninth AAAI; Koh, P.W., Liang, P., Understanding black-box predictions via influence functions (2017) Proceedings of the ICML; noz González, L.M., Biggio, B., Demontis, A., Paudice, A., Wongrassamee, V., Lupu, E.C., Roli, F., Towards poisoning of deep learning algorithms with back-gradient optimization (2018) Proceedings of the AISec, pp. 27-38. , ACM; Wittel, G.L., Wu, S.F., On attacking statistical spam filters (2004) Proceedings of the First CEAS; Globerson, A., Roweis, S.T., Nightmare at test time: robust learning by feature deletion (2006) Proceedings of the Twenty Third ICML, 148, pp. 353-360. , ACM; Teo, C.H., Globerson, A., Roweis, S., Smola, A., Convex learning with invariances (2008) Proceedings of the NIPS, pp. 1489-1496. , MIT Press; Dekel, O., Shamir, O., Xiao, L., Learning to classify with missing and corrupted features (2010) Mach. Learn., 81, pp. 149-178; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndić, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Proceedings of the ECML PKDD, Part III, LNCS, 8190, pp. 387-402. , Springer; Šrndic, N., Laskov, P., Practical evasion of a learning-based classifier: a case study (2014) Proceedings of the IEEE SP, pp. 197-211; Barreno, M., Nelson, B., Joseph, A., Tygar, J., The security of machine learning (2010) Mach. Learn., 81, pp. 121-148; Biggio, B., Fumera, G., Roli, F., Security evaluation of pattern classifiers under attack (2014) IEEE Trans. Knowl. Data Eng., 26 (4), pp. 984-996; Biggio, B., Fumera, G., Roli, F., Pattern recognition systems under attack: design issues and research challenges (2014) Int. J. Pattern Recognit. Artif. Intell., 28 (7), p. 1460002; Biggio, B., Fumera, G., Russu, P., Didaci, L., Roli, F., Adversarial biometric recognition: a review on biometric system security from the adversarial machine-learning perspective (2015) IEEE Signal Proc. Mag., 32 (5), pp. 31-41; Kolcz, A., Teo, C.H., Feature weighting for improved classifier robustness (2009) Proceedings of the Sixth CEAS; Biggio, B., Fumera, G., Roli, F., Adversarial pattern classification using multiple classifiers and randomisation (2008) Proceedings of the SSPR, LNCS, 5342, pp. 500-509. , Springer; Brückner, M., Kanzow, C., Scheffer, T., Static prediction games for adversarial learning problems (2012) Proceedings of the JMLR, 13, pp. 2617-2654; Bulò, S.R., Biggio, B., Pillai, I., Pelillo, M., Roli, F., Randomized prediction games for adversarial machine learning (2017) IEEE Trans. Neural Netw. Learn. Syst., 28 (11), pp. 2466-2478; Demontis, A., Melis, M., Biggio, B., Maiorca, D., Arp, D., Rieck, K., Corona, I., Roli, F., Yes, machine learning can be more secure! a case study on android malware detection, IEEE Trans. Dep. Secure Comp. doi; Laskov, P., Lippmann, R., (2007), NIPS Workshop on Machine Learning in Adversarial Environments for Computer Security; Laskov, P., Lippmann, R., Machine learning in adversarial environments (2010) Mach. Learn., 81, pp. 115-119; Joseph, A.D., Laskov, P., Roli, F., Tygar, J.D., Nelson, B., Machine learning methods for computer security (dagstuhl perspectives workshop 12371) (2013) Dagstuhl Manif., 3 (1), pp. 1-30; Thuraisingham, B.M., Biggio, B., Freeman, D.M., Miller, B., Sinha, A., (2017), AISec ’17: Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, New York, NY, USA, ACM; Joseph, A.D., Nelson, B., Rubinstein, B.I.P., Tygar, J., Adversarial Machine Learning (2018), Cambridge University Press; Corona, I., Giacinto, G., Roli, F., Adversarial attacks against intrusion detection systems: taxonomy, solutions and open issues (2013) Inf. Sci., 239, pp. 201-225; Han, X., Kheir, N., Balzarotti, D., PhishEye: live monitoring of sandboxed phishing kits (2016) Proceedings of the ACM CCS, pp. 1402-1413; Corona, I., Biggio, B., Contini, M., Piras, L., Corda, R., Mereu, M., Mureddu, G., Roli, F., DeltaPhish: detecting phishing webpages in compromised websites (2017) Proceedings of the ESORICS, LNCS, 10492, pp. 370-388. , Springer; Biggio, B., Fumera, G., Pillai, I., Roli, F., A survey and experimental evaluation of image spam filtering techniques (2011) Pattern Recognit. Lett., 32 (10), pp. 1436-1446; Attar, A., Rad, R.M., Atani, R.E., A survey of image spamming and filtering techniques (2013) Artif. Intell. Rev., 40 (1), pp. 71-105; Fumera, G., Pillai, I., Roli, F., Spam filtering based on the analysis of text information embedded into images (2006) J. Mach. Learn. Res., 7, pp. 2699-2720; Thomas, A.O., Rusu, A., Govindaraju, V., Synthetic handwritten captchas (2009) Pattern Recognit., 42 (12), pp. 3365-3373. , New Frontiers in Handwriting Recognition; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B., Tygar, J.D., Adversarial machine learning, Chicago, IL, USA (2011) Proceedings of the Fourth AISec, pp. 43-57; Biggio, B., Pillai, I., Bulò, S.R., Ariu, D., Pelillo, M., Roli, F., Is data clustering in adversarial settings secure? (2013) Proceedings of the AISec, pp. 87-98. , ACM; Biggio, B., Rieck, K., Ariu, D., Wressnegger, C., Corona, I., Giacinto, G., Roli, F., Poisoning behavioral malware clustering (2014) Proceedings of the AISec, pp. 27-36. , ACM; Biggio, B., Bulò, S.R., Pillai, I., Mura, M., Mequanint, E.Z., Pelillo, M., Roli, F., Poisoning complete-linkage hierarchical clustering (2014) Proceedings of the SSPR, LNCS, 8621, pp. 42-52. , Springer; Zhang, F., Chan, P., Biggio, B., Yeung, D., Roli, F., Adversarial feature selection against evasion attacks (2016) IEEE Trans. Cybern., 46 (3), pp. 766-777; Tramèr, F., Zhang, F., Juels, A., Reiter, M.K., Ristenpart, T., Stealing machine learning models via prediction APIs (2016) Proceedings of the USENIX Security Symposium, USENIX Association, pp. 601-618; Xu, W., Qi, Y., Evans, D., Automatically evading classifiers (2016) Proceedings of the NDSS, , The Internet Society; Chen, P.Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.J., ZOO: zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) AISec, pp. 15-26. , ACM; Dang, H., Huang, Y., Chang, E., Evading classifiers by morphing in the dark (2017) Proceedings of the ACM CCS, pp. 119-133. , ACM; Nelson, B., Rubinstein, B.I., Huang, L., Joseph, A.D., Lee, S.J., Rao, S., Tygar, J.D., Query strategies for evading convex-inducing classifiers (2012) J. Mach. Learn. Res., 13, pp. 1293-1332; Gu, T., Dolan-Gavitt, B., Garg, S., BadNets: identifying vulnerabilities in the machine learning model supply chain (2017), Proceedings of the NIPS Workshop on Mach. Learn. and Comp. Sec., abs/1708.06733; Chen, X., Liu, C., Li, B., Lu, K., Song, D., Targeted backdoor attacks on deep learning systems using data poisoning, ArXiv e-prints, abs/1712.05526; Fredrikson, M., Jha, S., Ristenpart, T., Model inversion attacks that exploit confidence information and basic countermeasures (2015) Proceedings of the ACM CCS, pp. 1322-1333. , ACM; Adler, A., Vulnerabilities in biometric encryption systems (2005) Proceedings of the Fifth ICAVBPA, LNCS, 3546, pp. 1100-1109. , T. Kanade A.K. Jain N.K. Ratha Springer; Galbally, J., McCool, C., Fierrez, J., Marcel, S., Ortega-Garcia, J., On the vulnerability of face verification systems to hill-climbing attacks (2010) Pattern Recognit., 43 (3), pp. 1027-1038; Martinez-Diaz, M., Fierrez, J., Galbally, J., Ortega-Garcia, J., An evaluation of indirect attacks and countermeasures in fingerprint verification systems (2011) Pattern Recognit Lett., 32 (12), pp. 1643-1651; Demontis, A., Russu, P., Biggio, B., Fumera, G., Roli, F., On security and sparsity of linear classifiers for adversarial settings (2016) Proceedings of the SSPR, LNCS, 10029, pp. 322-332. , Springer; Russu, P., Demontis, A., Biggio, B., Fumera, G., Roli, F., Secure kernel machines against evasion attacks (2016) Proceedings of the AISec, pp. 59-69. , ACM; Kantchelian, A., Tygar, J.D., Joseph, A.D., Evasion and hardening of tree ensemble classifiers (2016) Proceedings of the ICML, JMLR W&CP, 48, pp. 2387-2396; Athalye, A., Engstrom, L., Ilyas, A., Kwok, K., Synthesizing robust adversarial examples (2018) Proceedings of the ICLR; Fogla, P., Sharif, M., Perdisci, R., Kolesnikov, O., Lee, W., Polymorphic blending attacks (2006) Proceedings of the USENIX Security Symposium, USENIX Association, pp. 241-256; Biggio, B., Fumera, G., Roli, F., Multiple classifier systems for robust classifier design in adversarial environments (2010) Int. J. Mach. Learn. Cybern., 1 (1), pp. 27-41; Šrndić, N., Laskov, P., Detection of malicious PDF files based on hierarchical document structure (2013) Proceedings of the Twentieth NDSS, , The Internet Society; Xu, H., Caramanis, C., Mannor, S., Robustness and regularization of support vector machines (2009) J. Mach. Learn. Res., 10, pp. 1485-1510; Carlini, N., Wagner, D.A., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) Proceedings of the AISec, pp. 3-14. , ACM; Athalye, A., Carlini, N., Wagner, D.A., Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples (2018) Proceedings of the ICML, JMLR W&CP, JMLR.org, 80, pp. 274-283; Dong, Y., Liao, F., Pang, T., Hu, X., Zhu, J., Boosting adversarial examples with momentum (2018) Proceedings of the IEEE CVPR; Huang, X., Kwiatkowska, M., Wang, S., Wu, M., Safety verification of deep neural networks (2017) Proceedings of the Twenty Ninth ICCAV, Part I, LNCS, 10426, pp. 3-29. , Springer; Pei, K., Cao, Y., Yang, J., Jana, S., DeepXplore: automated whitebox testing of deep learning systems (2017) Proceedings of the Twenty Sixth SOSP, pp. 1-18. , ACM; Newsome, J., Karp, B., Song, D., Paragraph: thwarting signature learning by training maliciously (2006) Proceedings of the RAID, LNCS, pp. 81-105. , Springer; Barth, A., Rubinstein, B.I., Sundararajan, M., Mitchell, J.C., Song, D., Bartlett, P.L., A learning-based approach to reactive security (2012) IEEE Trans. Dependable Secure Comput., 9 (4), pp. 482-493; Kuncheva, L.I., Classifier ensembles for detecting concept change in streaming data: overview and perspectives (2008) Proceedings of the SUEMA, pp. 5-10; Dougherty, E.R., Hua, J., Xiong, Z., Chen, Y., Optimal robust classifiers (2005) Pattern Recognit., 38 (10), pp. 1520-1532; Liu, W., Chawla, S., Mining adversarial patterns via regularized loss minimization (2010) Mach. Learn., 81 (1), pp. 69-83; Großhans, M., Sawade, C., Brückner, M., Scheffer, T., Bayesian games for adversarial regression problems (2013) Proceedings of the Thirtieth ICML, JMLR W&CP, 28, pp. 55-63; Wooldridge, M., Does game theory work? (2012) IEEE IS, 27 (6), pp. 76-80; Cybenko, G., Landwehr, C.E., Security analytics and measurements (2012) IEEE Secur. Priv., 10 (3), pp. 5-8; Qi, Z., Tian, Y., Shi, Y., Robust twin support vector machine for pattern classification (2013) Pattern Recognit., 46 (1), pp. 305-316; Torkamani, M.A., Lowd, D., On robustness and regularization of structural support vector machines (2014) Proceedings of the ICML, PMLR, 32, pp. 577-585; Wong, E., Kolter, J.Z., Provable defenses against adversarial examples via the convex outer adversarial polytope (2018) Proceedings of the ICML, JMLR W&CP, JMLR.org, 80, pp. 5283-5292; Lyu, C., Huang, K., Liang, H.N., A unified gradient regularization family for adversarial examples (2015) Proceedings of the ICDM, IEEE CS, pp. 301-309; Sokolić, J., Giryes, R., Sapiro, G., Rodrigues, M.R.D., Robust large margin deep neural networks (2017) IEEE Trans. Signal Process., 65 (16), pp. 4265-4280; Simon-Gabriel, C.J., Ollivier, Y., Schölkopf, B., Bottou, L., Lopez-Paz, D., (2018), Adversarial vulnerability of neural networks increases with input dimension. ArXiv e-prints., abs/1802.01421; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) Proceedings of the ICLR; Biggio, B., Corona, I., He, Z.M., Chan, P., Giacinto, G., Yeung, D., Roli, F., One-and-a-half-class multiple classifier systems for secure learning against evasion attacks at test time (2015) Proceedings of the MCS, LNCS, 9132, pp. 168-180. , Springer; Bendale, A., Boult, T.E., Towards open set deep networks (2016) Proceedings of the IEEE CVPR, pp. 1563-1572; Moreno-Torres, J.G., Raeder, T., Alaiz-Rodri-guez, R., Chawla, N.V., Herrera, F., A unifying view on dataset shift in classification (2012) Pattern Recognit., 45 (1), pp. 521-530; Pillai, I., Fumera, G., Roli, F., Multi-label classification with a reject option (2013) Pattern Recognit., 46 (8), pp. 2256-2266; Wild, P., Radu, P., Chen, L., Ferryman, J., Robust multimodal face and fingerprint fusion in the presence of spoofing attacks (2016) Pattern Recognit., 50, pp. 17-25; Biggio, B., Fumera, G., Marcialis, G.L., Roli, F., Statistical meta-analysis of presentation attacks for secure multibiometric systems (2017) IEEE Trans. Pattern Anal. Mach. Intell., 39 (3), pp. 561-575; Biggio, B., Corona, I., Fumera, G., Giacinto, G., Roli, F., Bagging classifiers for fighting poisoning attacks in adversarial classification tasks (2011) Proceedings of the MCS, LNCS, 6713, pp. 350-359. , Springer-Verlag; Zantedeschi, V., Nicolae, M., Rawat, A., Efficient defenses against adversarial attacks (2017) Proceedings of the AISec, pp. 39-49. , ACM; Zheng, S., Song, Y., Leung, T., Goodfellow, I., Improving the robustness of deep neural networks via stability training (2016) Proceedings of the IEEE CVPR, pp. 4480-4488; Maiorca, D., Biggio, B., Chiappe, M.E., Giacinto, G., Adversarial detection of flash malware: limitations and open issues, CoRR ArXiv, abs/1710.10225; Nelson, B., Biggio, B., Laskov, P., Understanding the risk factors of learning in adversarial environments (2011) Proceedings of the AISec, pp. 87-92; Cretu, G.F., Stavrou, A., Locasto, M.E., Stolfo, S.J., Keromytis, A.D., Casting out demons: sanitizing training data for anomaly sensors (2008) Proceedings of the IEEE CS, pp. 81-95; Liu, C., Li, B., Vorobeychik, Y., Oprea, A., Robust linear regression against training data poisoning (2017) Proceedings of the AISec, pp. 91-102. , ACM; Steinhardt, J., Koh, P.W., Liang, P., Certified defenses for data poisoning attacks (2017) Proceedings of the NIPS; Jagielski, M., Oprea, A., Biggio, B., Liu, C., Nita-Rotaru, C., Li, B., Manipulating machine learning: poisoning attacks and countermeasures for regression learning (2018) Proceedings of the Thirty Ninth IEEE Symposium Security and Privacy; Xu, G., Cao, Z., Hu, B.G., Principe, J.C., Robust support vector machines based on the rescaled hinge loss function (2017) Pattern Recognit., 63, pp. 139-148; Christmann, A., Steinwart, I., On robust properties of convex risk minimization methods for pattern recognition (2004) J. Mach. Learn. Res., 5, pp. 1007-1034; Bootkrajang, J., Kaban, A., Learning kernel logistic regression in the presence of class label noise (2014) Pattern Recognit., 47 (11), pp. 3641-3655; Rubinstein, B.I.P., Bartlett, P.L., Huang, L., Taft, N., Learning in a large function space: privacy-preserving mechanisms for SVM learning (2012) J. Priv. Conf., 4 (1), pp. 65-100; Dietterich, T., Steps toward robust artificial intelligence (2017) AI Mag., 38 (3); Lipton, Z., The mythos of model interpretability (2016) Proceedings of the ICML Workshop on Human Interpretability of Machine Learning","Biggio, B.; Department of Electrical and Electronic Engineering, Italy; email: battista.biggio@diee.unica.it",,,"Elsevier Ltd",,,,,00313203,,PTNRA,,"English","Pattern Recogn.",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85050603085
"Ashraf U., Yuen C.","24464996300;24473792300;","Capacity-Aware Topology Resilience in Software-Defined Networks",2018,"IEEE Systems Journal","12","4","7993057","3737","3746",,4,"10.1109/JSYST.2017.2726680","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028937922&doi=10.1109%2fJSYST.2017.2726680&partnerID=40&md5=8bf5700fe4007d1b31fd3e25d7cdfb20","Department of Communications, Networking College of Computer Science and Information Technology, King Faisal University, Hofuf, Saudi Arabia; Department of Engineering Product Development (EPD), Singapore University of Technology and Design, Singapore, Singapore","Ashraf, U., Department of Communications, Networking College of Computer Science and Information Technology, King Faisal University, Hofuf, Saudi Arabia; Yuen, C., Department of Engineering Product Development (EPD), Singapore University of Technology and Design, Singapore, Singapore","Network resilience against failures due to natural disasters, equipment malfunction, and malicious attacks has become important for software-defined networks. The current state of the art focuses on two directions: controller redundancy and related recovery mechanisms for resilience in the control plane, and reactive or proactive strategies for resilience against failure of switches or links in the data plane. However, proactive network topology resilience against multiswitch failure by installing backup switches at key locations has been overlooked. We propose a proactive network-topology resilience scheme against worst case adversarial multiswitch failures by installing backup switches at key locations to maximize long-term traffic demands. We formulate this problem as a trilevel optimization, which helps the network operator identify the key N positions for installing backup switches. We develop mixed integer linear programming formulations to maximize aggregate demand satisfaction and maximize the minimum fair demand satisfaction while satisfying constraints such as connectivity, control-plane latency limits, and association capacity of controllers. The proposed models are NP-hard; therefore, we propose efficient heuristic-based greedy algorithms to solve large instances of the above-mentioned problems. We implement the proposed solutions and present the numerical results, which show optimality of the exact formulations and efficiency of the greedy algorithms. © 2007-2012 IEEE.","Demand satisfaction; network resilience; software-defined networks (SDNs)","Controllers; Disasters; Heuristic algorithms; Integer programming; Topology; Aggregate demands; Association capacity; Demand satisfaction; Equipment malfunctions; Mixed integer linear programming; Network resilience; Proactive networks; Recovery mechanisms; Software defined networking",,,,,,,,,"Institute of Electrical and Electronics Engineers Inc.",,,,,19328184,,,,"English","IEEE Syst. J.",Article,"Final","",Scopus,2-s2.0-85028937922
"Fan W., Agarwal S., Farid H.","56683740100;57200524642;7007029048;","Rebroadcast attacks: Defenses, reattacks, and redefenses",2018,"European Signal Processing Conference","2018-September",,"8553401","942","946",,3,"10.23919/EUSIPCO.2018.8553401","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059822584&doi=10.23919%2fEUSIPCO.2018.8553401&partnerID=40&md5=0959f882c771147ef43b4a2f126b16d7","Computer Science Dartmouth College, Hanover, NH  03755, United States","Fan, W., Computer Science Dartmouth College, Hanover, NH  03755, United States; Agarwal, S., Computer Science Dartmouth College, Hanover, NH  03755, United States; Farid, H., Computer Science Dartmouth College, Hanover, NH  03755, United States","A rebroadcast attack, in which an image is manipulated and then re-imaged, is a simple attack against forensic techniques designed to distinguish original from edited images. Various techniques have been developed to detect rebroadcast attacks. These forensic analyses, however, face new threats from sophisticated machine learning techniques that are designed to modify images to circumvent detection. We describe a framework to analyze the resilience of rebroadcast detection to adversarial attacks. We describe the impact of repeated attacks and defenses on the efficacy of detecting rebroadcast content. This basic framework may be applicable to understanding the resilience of a variety of forensic techniques. © EURASIP 2018.",,"Digital forensics; Learning systems; Forensic analysis; Forensic Techniques; Rebroadcast attack; Sophisticated machines; Signal processing",,,,,"Farid, H., (2016) Photo Forensics, , MIT Press; Tešić, J., Metadata practices for consumer photos (2011) IEEE Multimedia Magazine, 12, pp. 86-92; Kee, E., Johnson, M.K., Farid, H., Digital image authentication from JPEG headers (2011) IEEE Transactions on Information Forensics and Security, 6 (3), pp. 1066-1075; Gloe, T., Forensic analysis of ordered data structures on the example of JPEG files (2012) IEEE International Workshop on Information Forensics and Security, pp. 139-144; Kee, E., Farid, H., Digital image authentication from thumbnails (2010) Proc. SPIE, Media Forensics and Security II; Popescu, A.C., Farid, H., Exposing digital forgeries in color filter array interpolated images (2005) IEEE Transactions on Signal Processing, 53 (10), pp. 3948-3959; Kirchner, M., Efficient estimation of CFA pattern configuration in digital camera images (2010) Proc. SPIE, Electronic Imaging, Media Forensics and Security; Tuama, A., Comby, F., Chaumont, M., Camera model identification with the use of deep convolutional neural networks (2016) IEEE International Workshop on Information Forensics and Security, pp. 1-6; Bondi, L., Baroffio, L., Güera, D., Bestagini, P., Delp, E.J., Tubaro, S., First steps toward camera model identification with convolutional neural networks (2017) IEEE Signal Processing Letter, 24 (3), pp. 259-263; Chen, B.C., Ghosh, P., Morariu, V.I., Davis, L.S., Detection of metadata tampering through discrepancy between image content and metadata using multi-task deep learning (2017) IEEE Conference on Computer Vision and Pattern Recognition Workshops, pp. 1872-1880; Barni, M., Bondi, L., Bonettini, N., Bestagini, P., Costanzo, A., Maggini, M., Tondi, B., Tubaro, S., Aligned and non-aligned double JPEG detection using convolutional neural networks (2017) Journal of Visual Communication and Image Representation, 49, pp. 153-163; Amerini, I., Uricchio, T., Ballan, L., Caldelli, R., Localization of JPEG double compression through multi-domain convolutional neural networks (2017) IEEE Conference on Computer Vision and Pattern Recognition Workshops, pp. 1865-1871; Farid, H., Lyu, S., Higher-order wavelet statistics and their application to digital forensics (2003) IEEE Workshop on Statistical Analysis in Computer Vision (in Conjunction with CVPR), 8, p. 94; Cao, H., Kot, A.C., Identification of recaptured photographs on LCD screens (2010) IEEE International Conference on Acoustics, Speech, and Signal Processing, pp. 1790-1793; Yin, J., Fang, Y., Markov-based image forensics for photographic copying from printed picture (2012) ACM International Conference on Multimedia, pp. 1113-1116; Gao, X., Ng, T.T., Qiu, B., Chang, S., Single-view recaptured image detection based on physics-based features (2010) IEEE International Conference on Multimedia and Expo, pp. 1469-1474; Yin, J., Fang, Y., Digital image forensics for photographic copying (2012) Proc. SPIE, Media Watermarking, Security, and Forensics, p. 83030F; Mahdian, B., Novozámsky, A., Saic, S., Identification of aliasing-based patterns in re-captured LCD screens (2015) IEEE International Conference on Image Processing, pp. 616-620. , ` and; Thongkamwitoon, T., Muammar, H., Dragotti, P., An image recapture detection algorithm based on learning dictionaries of edge profiles (2015) IEEE Transactions on Information Forensics and Security, 10 (5), pp. 953-968; Yang, P., Ni, R., Zhao, Y., Recapture image forensics based on Laplacian convolutional neural networks (2016) International Workshop on Digital Watermarking, pp. 119-128; Zhai, X., Ni, R., Zhao, Y., Recaptured image detection based on texture features (2013) International Conference on Intelligent Information Hiding and Multimedia Signal Processing, pp. 234-237; Ke, Y., Shan, Q., Qin, F., Min, W., Image recapture detection using multiple features (2013) International Journal of Multimedia and Ubiquitous Engineering, 8 (5), pp. 71-82; Li, H., Wang, S., Kot, A.C., Image recapture detection with convolutional and recurrent neural networks (2017) Proc. Electronic Imaging, Media Watermarking, Security, and Forensics, 2017 (7), pp. 87-91; Agarwal, S., Fan, W., Farid, H., A diverse large-scale dataset for evaluating rebroadcast attacks (2018) IEEE International Conference on Acoustics, Speech, and Signal Processing; Guo, Z., Zhang, L., Zhang, D., Rotation invariant texture classification using LBP variance (LBPV) with global matching (2010) Pattern Recognition, 43 (3), pp. 706-719; Ojala, T., Pietikainen, M., Maenpaa, T., Multiresolution gray-scale and rotation invariant texture classification with local binary patterns (2002) IEEE Transactions on Pattern Analysis and Machine Intelligence, 24 (7), pp. 971-987; Mallat, S.G., A theory for multiresolution signal decomposition: The wavelet representation (1989) IEEE Transactions on Pattern Analysis and Machine Intelligence, 11 (7), pp. 674-693; Shi, Y.Q., Chen, C., Chen, W., A Markov process based approach to effective attacking JPEG steganography (2006) International Conference on Information Hiding, pp. 249-264; Wang, K., A simple and effective image-statistics-based approach to detecting recaptured images from LCD screens (2017) Digital Investigation, 23, pp. 75-87; Chen, Z., Tondi, B., Li, X., Ni, R., Zhao, Y., Barni, M., A gradient-based pixel-domain attack against SVM detection of global image manipulations (2017) IEEE International Workshop on Information Forensics and Security, pp. 1-6; PyTorch, , http://pytorch.org/",,,,"European Signal Processing Conference, EUSIPCO","26th European Signal Processing Conference, EUSIPCO 2018","3 September 2018 through 7 September 2018",,143333,22195491,9789082797015,,,"English","European Signal Proces. Conf.",Conference Paper,"Final","",Scopus,2-s2.0-85059822584
"Schöttle P., Schlögl A., Pasquini C., Böhme R.","25928803100;56263108600;56005491900;56213351900;","Detecting adversarial examples - A lesson from multimedia security",2018,"European Signal Processing Conference","2018-September",,"8553164","947","951",,10,"10.23919/EUSIPCO.2018.8553164","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059814924&doi=10.23919%2fEUSIPCO.2018.8553164&partnerID=40&md5=78dd27706616f058f55c4291979bb9a4","Department of Computer Science, University of Innsbruck, Innsbruck, Austria","Schöttle, P., Department of Computer Science, University of Innsbruck, Innsbruck, Austria; Schlögl, A., Department of Computer Science, University of Innsbruck, Innsbruck, Austria; Pasquini, C., Department of Computer Science, University of Innsbruck, Innsbruck, Austria; Böhme, R., Department of Computer Science, University of Innsbruck, Innsbruck, Austria","Adversarial classification is the task of performing robust classification in the presence of a strategic attacker. Originating from information hiding and multimedia forensics, adversarial classification recently received a lot of attention in a broader security context. In the domain of machine learning-based image classification, adversarial classification can be interpreted as detecting so-called adversarial examples, which are slightly altered versions of benign images. They are specifically crafted to be misclassified with a very high probability by the classifier under attack. Neural networks, which dominate among modern image classifiers, have been shown to be especially vulnerable to these adversarial examples. However, detecting subtle changes in digital images has always been the goal of multimedia forensics and steganalysis, two major subfields of multimedia security. We highlight the conceptual similarities between these fields and secure machine learning. Furthermore, we adapt a linear filter, similar to early steganalysis methods, to detect adversarial examples that are generated with the projected gradient descent (PGD) method, the state-of-the-art algorithm for this task. We test our method on the MNIST database and show for several parameter combinations of PGD that our method can reliably detect adversarial examples. Additionally, the combination of adversarial re-training and our detection method effectively reduces the attack surface of attacks against neural networks. Thus, we conclude that adversarial examples for image classification possibly do not withstand detection methods from steganalysis, and future work should explore the effectiveness of known techniques from multimedia security in other adversarial settings. © EURASIP 2018.","Adversarial Classification; Adversarial Examples; Multimedia Forensics; Steganalysis","Artificial intelligence; Classification (of information); Forensic science; Learning systems; Steganography; Adversarial classifications; Adversarial Examples; Multimedia forensics; Multimedia security; Parameter combination; Robust classification; State-of-the-art algorithms; Steganalysis; Image classification",,,,,"Dritsoula, L., Loiseau, P., Musacchio, J., A game-theoretic analysis of adversarial classification (2017) IEEE Transactions on Information Forensics and Security, 12 (12), pp. 3094-3109; Barni, M., Pérez-González, F., Coping with the enemy: Advances in adversary-aware signal processing (2013) 2013 IEEE International Conference on Acoustics, Speech and Signal Processing, pp. 8682-8686; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations (ICLR); Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: from Phenomena to Black-Box Attacks Using Adversarial Samples, , arXiv preprint; Barreno, M., Nelson, B., Sears, R., Joseph, A.D., Tygar, J.D., Can machine learning be secure? (2006) Proceedings of the 2006 ACM Symposium on Information, Computer and Communications Security, pp. 16-25. , ACM; Biggio, B., Nelson, B., Laskov, P., Poisoning attacks against support vector machines (2012) 29th International Conference on Machine Learning, pp. 1807-1814. , J. Langford and J. Pineau, Eds. Omnipress; Grosse, K., Papernot, N., Manoharan, P., Backes, M., McDaniel, P., Adversarial examples for malware detection (2017) European Symposium on Research in Computer Security, pp. 62-79. , Springer; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) IEEE European Symposium on Security and Privacy, pp. 372-387. , IEEE; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) International Conference on Learning Representations; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy, pp. 39-57. , IEEE; Kirchner, M., Böhme, R., Hiding traces of resampling in digital images (2008) IEEE Transactions on Information Forensics and Security, 3 (4), pp. 582-592. , Dec; Sencar, H.T., Memon, N., (2013) Digital Image Forensics: There is More to a Picture Than Meets the Eye, , Springer Science & Business Media; Kirchner, M., Böhme, R., Tamper hiding: Defeating image forensics (2007) Information Hiding, pp. 326-341. , T. Furon, F. Cayre, G. Doërr, and Bas, Eds. Springer Berlin Heidelberg; Fridrich, J., (2009) Steganography in Digital Media: Principles, Algorithms, and Applications, , New York, NY, USA: Cambridge University Press; Quiring, E., Arp, D., Rieck, K., Forgotten siblings: Unifying attacks on machine learning and digital watermarking (2018) IEEE European Symposium on Security and Privacy; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint; Xu, W., Evans, D., Qi, Y., Feature squeezing: Detecting adversarial examples in deep neural networks (2018) Network and Distributed System Security Symposium; Tramèr, F., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2017) The Space of Transferable Adversarial Examples, , arXiv preprint; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) IEEE Conference on Computer Vision and Pattern Recognition, pp. 86-94. , IEEE; Ker, A.D., Böhme, R., Revisiting weighted stego-image steganalysis (2008) Security, Forensics, Steganography, and Watermarking of Multimedia Contents X, 6819, p. 681905. , E. J. Delp III, W. Wong, J. Dittmann, and N. D. Memon, Eds.,. SPIE; Fillatre, L., Adaptive steganalysis of least significant bit replacement in grayscale natural images (2012) IEEE Transactions on Signal Processing, 60 (2), pp. 556-569; LeCun, Y., Cortes, C., Burges, C., MNIST handwritten digit database (2010) AT&T Labs, 2. , http://yann.lecun.com/exdb/mnist, Online; Papernot, N., McDaniel, P., Sinha, A., Wellman, M., Sok: Security and privacy in machine learning (2018) IEEE European Symposium on Security and Privacy",,,,"European Signal Processing Conference, EUSIPCO","26th European Signal Processing Conference, EUSIPCO 2018","3 September 2018 through 7 September 2018",,143333,22195491,9789082797015,,,"English","European Signal Proces. Conf.",Conference Paper,"Final","",Scopus,2-s2.0-85059814924
"Quiring E., Rieck K.","56875387900;14016551700;","Adversarial machine learning against digital watermarking",2018,"European Signal Processing Conference","2018-September",,"8553343","519","523",,4,"10.23919/EUSIPCO.2018.8553343","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059812156&doi=10.23919%2fEUSIPCO.2018.8553343&partnerID=40&md5=35847a2591139b29b466d3a25b3bb903","Technische Universität Braunschweig, Brunswick, Germany","Quiring, E., Technische Universität Braunschweig, Brunswick, Germany; Rieck, K., Technische Universität Braunschweig, Brunswick, Germany","Machine learning and digital watermarking are independent research areas. Their methods, however, are vulnerable to similar attacks if operated in an adversarial environment. Recent research has thus started to bring both fields together by introducing a unified view for black-box attacks and defenses between learning and watermarking methods. In this paper, we extend this work and examine a novel black-box attack against digital watermarking based on concepts from adversarial learning. With a set of marked images, we let a neural network approximate the watermark detection and use this network to remove the watermark. The attack does not require knowledge of the watermarking scheme. © EURASIP 2018.","Adversarial Examples; Digital Watermarking","Artificial intelligence; Digital watermarking; Learning systems; Signal processing; Adversarial environments; Adversarial Examples; Adversarial learning; Independent research; Recent researches; Watermark detection; Watermarking methods; Watermarking schemes; E-learning",,,,,"Barni, M., Comesaña-Alfaro, P., Pérez-González, F., Tondi, B., Are you threatening me?: Towards smart detectors in watermarking (2014) Proceedings of SPIE, 9028; Barni, M., Pérez-González, F., Coping with the enemy: Advances in adversary-aware signal processing (2013) IEEE International Conference on Acoustics, Speech, and Signal Processing, pp. 8682-8686; Bas, P., Westfeld, A., Two key estimation techniques for the broken arrows watermarking scheme (2009) Proc. of ACM Workshop on Multimedia and Security, pp. 1-8; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndić, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Machine Learning and Knowledge Discovery in Databases, pp. 387-402. , Springer; Carlini, N., Wagner, D.A., Towards evaluating the robustness of neural networks (2017) Proc. of IEEE Symposium on Security and Privacy, pp. 39-57; Choubassi, M.E., Moulin, P., Noniterative algorithms for sensitivity analysis attacks (2007) IEEE Transactions on Information Forensics and Security, 2 (2), pp. 113-126; Comesaña, P., Pérez-Freire, L., Pérez-González, F., Blind Newton sensitivity attack (2006) IEE Proceedings - Information Security, 153 (3), pp. 115-125; Cox, I.J., Linnartz, J.-P.M.G., Public watermarks and resistance to tampering (1997) Proc. of IEEE International Conference on Image Processing (ICIP), pp. 26-29; Cox, I.J., Miller, M., Bloom, J., Fridrich, J., Kalker, T., (2002) Digital Watermarking and Steganography, , Morgan Kaufmann Publishers; Dang-Nguyen, D.-T., Pasquini, C., Conotter, V., Boato, G., RaiSE: A raw images dataset for digital image forensics (2015) 6th ACM Multimedia Systems Conference, pp. 219-224; Furon, T., Bas, P., Broken arrows (2008) EURASIP Journal on Information Security, 2008, pp. 1-13; Gloe, T., Böhme, R., The Dresden Image Database for benchmarking digital image forensics (2010) Journal of Digital Forensic Practice, 3 (2-4), pp. 150-159; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I.P., Tygar, J.D., Adversarial machine learning (2011) Proc. of ACM Workshop on Artificial Intelligence and Security (AISEC), pp. 43-58; Linnartz, J.-P.M.G., Van Dijk, M., Analysis of the sensitivity attack against electronic watermarks in images (1998) Proc. of Information Hiding Conference, 1525, pp. 258-272; Lowd, D., Meek, C., Good word attacks on statistical spam filters (2005) Conference on Email and Anti-Spam; Adversarial learning (2005) Proc. of ACM SIGKDD Conference on Knowledge Discovery in Data Mining (KDD), pp. 641-647; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: from Phenomena to Black-Box Attacks Using Adversarial Samples, , Tech. Rep; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) Proc. of ACM Asia Conference on Computer Computer and Communications Security (Asia CCS), pp. 506-519; Papernot, N., McDaniel, P., Sinha, A., Wellman, M.P., Sok: Security and privacy in machine learning (2018) Proc. of IEEE European Symposium on Security and Privacy (EuroS&P), , Apr; Quiring, E., Arp, D., Rieck, K., Forgotten siblings: Unifying attacks on machine learning and digital watermarking (2018) Proc. of IEEE European Symposium on Security and Privacy (EuroS&P), , Apr; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R., Intriguing properties of neural networks (2013) Computing Research Repository (CoRR), , Tech. Rep. abs/1312.6199; Tondi, B., Comesaña-Alfaro, P., Pérez-González, F., Barni, M., On the effectiveness of meta-detection for countering oracle attacks in watermarking (2015) Workshop on Information Forensics and Security (WIFS), pp. 1-6; Tramèr, F., Zhang, F., Juels, A., Reiter, M.K., Ristenpart, T., Stealing machine learning models via prediction apis (2016) Proc. of USENIX Security Symposium, pp. 601-618; (2008) BOWS-2 Web Page, , http://bows2.ec-lille.fr/, Website last visited August 2017",,,,"European Signal Processing Conference, EUSIPCO","26th European Signal Processing Conference, EUSIPCO 2018","3 September 2018 through 7 September 2018",,143333,22195491,9789082797015,,,"English","European Signal Proces. Conf.",Conference Paper,"Final","",Scopus,2-s2.0-85059812156
"Gragnaniello D., Marra F., Poggi G., Verdoliva L.","55547170900;57209195452;7005255639;6506573720;","Analysis of adversarial attacks against CNN-based image forgery detectors",2018,"European Signal Processing Conference","2018-September",,"8553560","967","971",,13,"10.23919/EUSIPCO.2018.8553560","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059809164&doi=10.23919%2fEUSIPCO.2018.8553560&partnerID=40&md5=b45dce9cbac6a895e6ec8b00d1630ec3","Department of Electrical Engineering and Information Technology, University Federico II of Naples, Naples, Italy","Gragnaniello, D., Department of Electrical Engineering and Information Technology, University Federico II of Naples, Naples, Italy; Marra, F., Department of Electrical Engineering and Information Technology, University Federico II of Naples, Naples, Italy; Poggi, G., Department of Electrical Engineering and Information Technology, University Federico II of Naples, Naples, Italy; Verdoliva, L., Department of Electrical Engineering and Information Technology, University Federico II of Naples, Naples, Italy","With the ubiquitous diffusion of social networks, images are becoming a dominant and powerful communication channel. Not surprisingly, they are also increasingly subject to manipulations aimed at distorting information and spreading fake news. In recent years, the scientific community has devoted major efforts to contrast this menace, and many image forgery detectors have been proposed. Currently, due to the success of deep learning in many multimedia processing tasks, there is high interest towards CNN-based detectors, and early results are already very promising. Recent studies in computer vision, however, have shown CNNs to be highly vulnerable to adversarial attacks, small perturbations of the input data which drive the network towards erroneous classification. In this paper we analyze the vulnerability of CNN-based image forensics methods to adversarial attacks, considering several detectors and several types of attack, and testing performance on a wide range of common manipulations, both easily and hardly detectable. © EURASIP 2018.","Convolutional neural networks; Generative adversarial networks; Image counterforensics","Deep learning; Digital storage; Image analysis; Neural networks; Adversarial networks; Convolutional neural network; Counter-Forensics; Image forensics; Multimedia processing; Scientific community; Small perturbations; Testing performance; Digital forensics",,,,,"Korus, P., Digital image integrity a survey of protection and verification techniques (2017) Digital Signal Processing, 71, pp. 1-26; Farid, H., Lyu, S., Higher-order wavelet statistics and their application to digital forensics (2003) IEEE Workshop on Statistical Analysis in Computer Vision (in Conjunction with CVPR), pp. 1-8; Bayram, S., Avcibaş, I., Sankur, B., Memon, N., Image manipulation detection (2006) Journal of Electronic Imaging, 15 (4), pp. 1-17; Pevny, T., Bas, P., Fridrich, J., Steganalysis by subtractive pixel adjacency matrix (2010) IEEE Transactions on Information Forensics and Security, 5 (2), pp. 215-224. , `; Fridrich, J., Kodovsky, J., Rich models for steganalysis of digital images (2012) IEEE Transactions on Information Forensics and Security, 7, pp. 868-882; Cozzolino, D., Gragnaniello, D., Verdoliva, L., Image forgery detection through residual-based local descriptors and block-matching (2014) IEEE Conference on Image Processing, pp. 5297-5301. , October; Boroumand, M., Fridrich, J., Scalable processing history detector for JPEG images (2017) IS&T Electronic Imaging - Media Watermarking, Security, and Forensics; Li, H., Luo, W., Qiu, X., Huang, J., Identification of various image operations using residual-based features (2018) IEEE Transactions on Circuits and Systems for Video Technology, 28 (1), pp. 31-45; Cozzolino, D., Poggi, G., Verdoliva, L., SpliceBuster: A new blind image splicing detector (2015) IEEE International Workshop on Information Forensics and Security, pp. 1-6; Bayar, B., Stamm, M., A deep learning approach to universal image manipulation detection using a new convolutional layer (2016) ACM Workshop on Information Hiding and Multimedia Security; Cozzolino, D., Poggi, G., Verdoliva, L., Recasting residual-based local descriptors as convolutional neural networks: An application to image forgery detection (2017) ACM Workshop on Information Hiding and Multimedia Security, pp. 1-6. , june; Boroumand, M., Fridrich, J., Deep learning for detecting processing history of images (2018) IS&T Electronic Imaging - Media Watermarking, Security, and Forensics; Marra, F., Gragnaniello, D., Cozzolino, D., Verdoliva, L., Detection of GAN-generated fake images over social networks (2018) 1st IEEE International Workshop on “Fake MultiMedia, , April; Barni, M., Fontani, M., Tondi, B., A universal attack against histogram-based image forensics (2013) International Journal of Digital Crime and Forensics, 5 (3), pp. 35-52; Iuliani, M., Rossetto, S., Bianchi, T., De Rosa, A., Piva, A., Barni, M., Image counter-forensics based on feature injection (2014) Proc. of SPIE, 9028; Marra, F., Poggi, G., Roli, F., Sansone, C., Verdoliva, L., Counter-forensics in machine learning based forgery detection (2015) Proc. of SPIE, 9409; Chen, Z., Tondi, B., Li, X., Ni, R., Zhao, Y., Barni, M., A gradient-based pixel-domain attack against SVM detection of global image manipulations (2017) IEEE Workshop on Information Forensics and Security; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations; Kim, D., Jang, H.-U., Mun, S.-M., Choi, S., Lee, H.-K., Median filtered image restoration and anti-forensics using adversarial networks (2018) IEEE Signal Processing Letters, 25 (2), pp. 278-282; Chollet, F., Xception: Deep learning with depthwise separable convolutions (2017) IEEE Conference on Computer Vision and Pattern Recognition, pp. 1800-1807; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) IEEE European Symposium on Security and Privacy, pp. 372-387; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2014) CoRR, , abs/1409.1556",,,,"European Signal Processing Conference, EUSIPCO","26th European Signal Processing Conference, EUSIPCO 2018","3 September 2018 through 7 September 2018",,143333,22195491,9789082797015,,,"English","European Signal Proces. Conf.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85059809164
"Kolosnjaji B., Demontis A., Biggio B., Maiorca D., Giacinto G., Eckert C., Roli F.","57008970900;56913250700;23090165100;55334827100;6701832237;35490246700;57194734588;","Adversarial malware binaries: Evading deep learning for malware detection in executables",2018,"European Signal Processing Conference","2018-September",,"8553214","533","537",,92,"10.23919/EUSIPCO.2018.8553214","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058628512&doi=10.23919%2fEUSIPCO.2018.8553214&partnerID=40&md5=5b1f57ce3a64278d318daf838e514373","Technical University of Munich, Germany; University of Cagliari, Italy; Pluribus One, Italy","Kolosnjaji, B., Technical University of Munich, Germany; Demontis, A., University of Cagliari, Italy; Biggio, B., University of Cagliari, Italy, Pluribus One, Italy; Maiorca, D., University of Cagliari, Italy; Giacinto, G., University of Cagliari, Italy, Pluribus One, Italy; Eckert, C., Technical University of Munich, Germany; Roli, F., University of Cagliari, Italy, Pluribus One, Italy","Machine learning has already been exploited as a useful tool for detecting malicious executable files. Data retrieved from malware samples, such as header fields, instruction sequences, or even raw bytes, is leveraged to learn models that discriminate between benign and malicious software. However, it has also been shown that machine learning and deep neural networks can be fooled by evasion attacks (also known as adversarial examples), i.e., small changes to the input data that cause misclassification at test time. In this work, we investigate the vulnerability of malware detection methods that use deep networks to learn from raw bytes. We propose a gradient-based attack that is capable of evading a recently-proposed deep network suited to this purpose by only changing few specific bytes at the end of each malware sample, while preserving its intrusive functionality. Promising results show that our adversarial malware binaries evade the targeted network with high probability, even though less than 1% of their bytes are modified. © EURASIP 2018.",,"Artificial intelligence; Computer crime; Computer viruses; Deep neural networks; Signal processing; Deep networks; Executables; Gradient based; High probability; Input datas; Malicious executable files; Malware detection; Misclassifications; Malware",,,,,"Abou-Assaleh, T., Cercone, N., Keselj, V., Sweidan, R., N-gram-based detection of new malicious code (2004) COMPSAC'04, pp. 41-42. , Washington, DC, USA, IEEE CS; Anderson, H.S., Kharkar, A., Filar, B., Roth, P., Evading machine learning malware detection (2017) Black Hat; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndić, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) ECML PKDD, Part III, 8190, pp. 387-402. , of LNCS,. Springer Berlin Heidelberg; Biggio, B., Fumera, G., Roli, F., Security evaluation of pattern classifiers under attack (2014) IEEE TKDE, 26 (4), pp. 984-996; Biggio, B., Roli, F., (2018) Wild Patterns: Ten Years After the Rise of Adversarial Machine Learning, , e-prints; Chen, L., Hou, S., Ye, Y., SecureDroid: Enhancing security of machine learning-based detection against adversarial android malware attacks (2017) ACSAC, pp. 362-372. , ACM; Cogswell, M., Ahmed, F., Girshick, R., Zitnick, L., Batra, D., (2015) Reducing Overfitting in Deep Networks by Decorrelating Representations, , stat, Nov; Dauphin, Y.N., Fan, A., Auli, M., Grangier, D., (2016) Language Modeling with Gated Convolutional Networks, , cs, Dec; Demontis, A., Melis, M., Biggio, B., Maiorca, D., Arp, D., Rieck, K., Corona, I., Roli, F., Yes, machine learning can be more secure! A case study on android malware detection IEEE Trans. Dependable and Secure Computing, , press; Doshi-Velez, F., Kim, B., (2017) Towards a Rigorous Science of Interpretable Machine Learning, , e-prints; Grosse, K., Papernot, N., Manoharan, P., Backes, M., McDaniel, P.D., Adversarial examples for malware detection (2017) ESORICS, 10493 (2), pp. 62-79. , of LNCS,. Springer; Huang, A., Al-Dujaili, A., Hemberg, E., O'Reilly, U.-M., (2018) Adversarial Deep Learning for Robust Detection of Binary Encoded Malware, , e-prints; Kaspersky, (2017) Machine Learning for Malware Detection; Kreuk, F., Barak, A., Aviv-Reuven, S., Baruch, M., Pinkas, B., Keshet, J., Deceiving end-to-end deep learning malware detectors using adversarial examples (2018) CoRR, , abs/1802.04528; Lipton, Z.C., The mythos of model interpretability (2016) ICML Workshop on Human Interpretability in Machine Learning, pp. 96-100; Maiorca, D., Biggio, B., Chiappe, M.E., Giacinto, G., (2017) Adversarial Detection of Flash Malware: Limitations and Open Issues; Pietrek, M., (1994) Peering Inside the PE: A Tour of the Win32 Portable Executable File Format; Raff, E., Barker, J., Sylvester, J., Brandon, R., Catanzaro, B., Nicholas, C., (2017) Malware Detection by Eating a Whole EXE, , arXiv preprint; Rieck, K., Holz, T., Willems, C., Düssel, P., Laskov, P., Learning and classification of malware behavior (2008) DIMVA'08, pp. 108-125. , Berlin, Heidelberg, Springer-Verlag; Rossow, C., Dietrich, C.J., Grier, C., Kreibich, C., Paxson, V., Pohlmann, N., Bos, H., Van Steen, M., Prudent practices for designing malware experiments: Status quo and outlook (2012) IEEE Symp. Security and Privacy, pp. 65-79. , IEEE; Schultz, M.G., Eskin, E., Zadok, E., Stolfo, S.J., Data mining methods for detection of new malicious executables (2001) IEEE Symp. Security and Privacy, SP'01, pp. 38-49. , Washington, DC, USA, IEEE CS; (2017) Internet Security Threat Report, , Symantec; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) Int'l Conf. Learn. Repr.; Tong, L., Li, B., Hajaj, C., Xiao, C., Vorobeychik, Y., (2017) Hardening Classifiers Against Evasion: The Good, the Bad, and the Ugly; Xu, W., Qi, Y., Evans, D., Automatically evading classifiers (2016) 23rd NDSS. The Internet Society; Yan, G., Brown, N., Kong, D., Exploring discriminatory features for automated malware classification (2013) DIMVA'13, pp. 41-61. , Berlin, Heidelberg, Springer-Verlag; Yang, W., Kong, D., Xie, T., Gunter, C.A., Malware detection in adversarial settings: Exploiting feature evolutions and confusions in android apps (2017) ACSAC, pp. 288-302. , ACM; Zhang, F., Chan, P., Biggio, B., Yeung, D., Roli, F., Adversarial feature selection against evasion attacks (2016) IEEE T. Cyb., 46 (3), pp. 766-777",,,,"European Signal Processing Conference, EUSIPCO","26th European Signal Processing Conference, EUSIPCO 2018","3 September 2018 through 7 September 2018",,143333,22195491,9789082797015,,,"English","European Signal Proces. Conf.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85058628512
"Clio S., Han I., Jeong H., Kim J., Koo S., Oh H., Park M.","57205428640;57205428358;57205426908;57192419285;57205427248;57203172400;57200890311;","Cyber kill chain based threat taxonomy and its application on cyber common operational picture",2018,"2018 International Conference on Cyber Situational Awareness, Data Analytics and Assessment, CyberSA 2018",,,"8551383","","",,8,"10.1109/CyberSA.2018.8551383","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059987177&doi=10.1109%2fCyberSA.2018.8551383&partnerID=40&md5=47fa4b836ad3ddf33fcee38cc7ebb5fe","Agency for Defense Development, Seoul, South Korea","Clio, S., Agency for Defense Development, Seoul, South Korea; Han, I., Agency for Defense Development, Seoul, South Korea; Jeong, H., Agency for Defense Development, Seoul, South Korea; Kim, J., Agency for Defense Development, Seoul, South Korea; Koo, S., Agency for Defense Development, Seoul, South Korea; Oh, H., Agency for Defense Development, Seoul, South Korea; Park, M., Agency for Defense Development, Seoul, South Korea","Over a decade, intelligent and persistent forms of cyber threats have been damaging to the organizations' cyber assets and missions. In this paper, we analyze current cyber kill chain models that explain the adversarial behavior to perform advanced persistent threat (APT) attacks, and propose a cyber kill chain model that can be used in view of cyber situation awareness. Based on the proposed cyber kill chain model, we propose a threat taxonomy that classifies attack tactics and techniques for each attack phase using CAPEC, ATTCK that classify the attack tactics, techniques, and procedures (TTPs) proposed by MITRE. We also implement a cyber common operational picture (CyCOP) to recognize the situation of cyberspace. The threat situation can be represented on the CyCOP by applying cyber kill chain based threat taxonomy. © 2018 IEEE.","cyber common operational picture; cyber kill chain; cyber situation awareness; threat taxonomy; visualization","Flow visualization; Common operational picture; Cyber threats; Cyberspaces; ITS applications; Kill chain; Situation awareness; Taxonomies",,,,,"Moore, D., Paxson, V., Savage, S., Shannon, C., Staniford, S., Weaver, N., Inside the slammer worm (2003) IEEE Security & Privacy, 99 (4), pp. 33-39; Youm, H.Y., Sg, I., (2011) Koreas Experience of Massive DDoS Attacks from Botnet, , ITU-T SG 17; (2013) APT1: Exposing One of China's Cyber Espionage Units, , http://www.fireeye.com/content/dam/fireeye-www/services/pdfs/mandiant-apt1-report.pdf, Fire Eye FireEye; (2011) SK Hack by An Advanced Persistent Threat, , http://www.commandfive.com/papers/C5APTSKHack.pdf, Command Five Pty Ltd Sep; Howes, N.R., Mezzino, M., Sarkesain, J., (2004) On Cyber Warfare Command and Control Systems, , MISSILE DEFENSE AGENCYWASHINGTON DC, Tech. Rep; (2011) Advanced Persistent Threats: A Decade in Review, , http://www.commandfive.com/papers/C5APTADecadeInReview.pdf, Command Five Pty Ltd Jun; Giura, P., Wang, W., A context-based detection framework for advanced persistent threats (2012) Cyber Security (CyberSecurity), 2012 International Conference On. IEEE, pp. 69-74; Vukalovíc, J., Delija, D., Advanced Persistent Threats-detection and defense (2015) Information and Communication Technology, Electronics and Microelectronics (MIPRO 2015 38th International Convention On. IEEE, pp. 1324-1330; Mathew, S., Upadhyaya, S., Sudit, M., Stotz, A., Situation awareness of multistage cyber attacks by semantic event fusion (2010) Military Communications Conference, 2010-Milcom, pp. 1286-1291. , 2010, IEEE; Yang, S.J., Stotz, A., Holsopple, J., Sudit, M., Kuhl, M., High level information fusion for tracking and projection of multistage cyber attacks (2009) Information Fusion, 10 (1), pp. 107-121; Hutchins, E.M., Cloppert, M.J., Amin, R.M., Intelligence-driven computer network defense informed by analysis of adversary campaigns and intrusion kill chains (2011) Leading Issues in Information Warfare & Security Research, 1 (1), p. 80; (2015) Department of Defense Cybersecurity Test and Evaluation Guidebook, , http://www.dote.osd.mil/docs/TempGuide3/CybersecurityTEGuidebookJuly12015v10.pdf, United States DoD Version 1.0; Breaking the Kill Chain: Knowing, Detecting, Disrupting and Eradicating the Advanced Threat, , http://www.secureworks.com/resources/wp-breaking-the-kill-chain, Secureworks; Threat-based Defense: Understanding An Attackers Tactics and Techniques Is Key to Successful Cyber Defense, , http://www.mitre.org/capabilities/cybersecurity/threat-based-defense, MITRE; Shiva, S., Simmons, C., Ellis, C., Dasgupta, D., Wu, Q., AVODIT: A cyber attack taxonomy (2009) University of Memphis, , Technical Report CS-09-003; Uma, M., Padmavathi, G., A survey on various cyber attacks and their classification (2013) IJ Network Security, 15 (5), pp. 390-396; http://attack.mitre.org/wiki/MainPage, MITRE ATT&CK; Uma, M., Padmavathi, G., PRE-ATT&CK, , http://attack.mitre.org/pre-attack/index.php/MainPage; Uma, M., Padmavathi, G., CAPEC, , http://capec.mitre.org; Bryant, B.D., Saiedian, H., A novel kill-chain framework for remote security log analysis with SIEM software (2017) Computers & Security, 67, pp. 198-210; Harris, B., Konikoff, E., Petersen, P., Breaking the DDoS attack chain (2013) Institute for Software Research; Yadav, T., Rao, A.M., Technical aspects of cyber kill chain (2015) International Symposium on Security in Computing and Communication, pp. 438-452. , Springer; Conti, G., Nelson, J., Raymond, D., Towards a cyber common operating picture (2013) Cyber Conflict (CyCon 2013 5th International Conference On. IEEE, pp. 1-17; Esteve, M., Pérez, I., Palau, C., Carvajal, F., Hingant, J., Fresneda, M.A., Sierra, J.P., Cyber common operational picture: A tool for cyber hybrid situational awareness improvement (2016) North Atlantic Treaty Organization (NATO) Science and Technology Organization (STO), , Technical Report STO-MP-IST-148; Iannacone, M., Bohn, S., Nakamura, G., Gerth, J., Huffer, K., Bridges, R., Ferragut, E., Goodall, J., Developing an ontology for cyber security knowledge graphs (2015) Proceedings of the 10th Annual Cyber and Information Security Research Conference ACM, p. 12; Mavroeidis, V., Bromander, S., Cyber threat intelligence model: An evaluation of taxonomies, sharing standards, ontologies within cyber threat intelligence (2017) Proceedings of the IEEE",,,,"Institute of Electrical and Electronics Engineers Inc.","2018 International Conference on Cyber Situational Awareness, Data Analytics and Assessment, CyberSA 2018","11 June 2018 through 12 June 2018",,143200,,9781538645659,,,"English","Int. Conf. Cyber Situational Aware., Data Anal. Assess., CyberSA",Conference Paper,"Final","",Scopus,2-s2.0-85059987177
"Asadi N., Rege A., Obradovic Z.","57212911015;56165469100;57156081500;","Analysis of adversarial movement through characteristics of graph topological ordering",2018,"2018 International Conference on Cyber Situational Awareness, Data Analytics and Assessment, CyberSA 2018",,,"8551361","","",,3,"10.1109/CyberSA.2018.8551361","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059985619&doi=10.1109%2fCyberSA.2018.8551361&partnerID=40&md5=192c931d67c896e8dda9748a96c16dc2","Computer and Information Sciences Department, Temple University, United States; Department of Criminal Justice, Temple University, United States; Data Analytics and Biomedical Informatics Center, Temple University, United States","Asadi, N., Computer and Information Sciences Department, Temple University, United States; Rege, A., Department of Criminal Justice, Temple University, United States; Obradovic, Z., Computer and Information Sciences Department, Temple University, United States, Data Analytics and Biomedical Informatics Center, Temple University, United States","Capturing the patterns in adversarial movement can provide valuable information regarding how the adversaries progress through cyberattacks. This information can be further employed for making comparisons and interpretations of decision making of the adversaries. In this study, we propose a framework based on concepts of social networks to characterize and compare the patterns, variations and shifts in the movements made by an adversarial team during a real-time cybersecurity exercise. We also explore the possibility of movement association with the skill sets using topological sort networks. This research provides priliminary insight on adversarial movement complexity and linearity and decision-making as cyberattacks unfold. © 2018 IEEE.","adaptive human behavior; dynamic decision-making; mixed methods; network theory; social network","Behavioral research; Circuit theory; Decision making; Decision theory; Social networking (online); Cyber-attacks; Cybersecurity exercise; Dynamic decision making; Human behaviors; Mixed method; Skill sets; Topological order; Topological sort; Topology",,,,,"(2012) Lifecycle of An Advanced Persistent Threat, , http://www.redteamusa.com/PDF/Lifecyclen%20ofn%20ann%20Advancedn%20Persistentn%20Threat.pdf, DELL Accessed: 2016-12-20; (2015) Advanced Persistent Threats: Understand the Threat, , http://www.secureworks.com/cyber-threatintelligence/advanced-persistent-threat/understand-thethreat/, DELL Accessed: 2015-06-10; Barnum, S., Standardizing Cyber Threat Intelligence Information with the Structured Threat Information EXpression, , http://www.mitre.org/sites/default/files/publications/stix.pdf; Borrion, H., Quality assurance in crime scripting (2013) Crime Science, 2 (1), p. 1; Branlat, M., Morison, A., Woods, D.D., Challenges in managing uncertainty during cyber events: Lessons from the staged-world study of a largescale adversarial cyber security exercise (2011) Human Systems Integration Symposium, pp. 10-25; Branlat, M., A study of adversarial interplay in a cybersecurity event (2011) Proceedings of the 10th International Conference on Naturalistic Decision Making, , NDM 2011). May 31st to June 3rd; (2012) Stalking the Kill Chain, , http://www.emc.com/collateral/hardware/solution-overview/h11154-stalking-the-kill-chain-so.pdf, RSA (RSA Division of EMC) Accessed: 2012; Guzman, J.D., An analytical comparison of social network measures (2014) IEEE Transactions on Computational Social Systems, 1 (1), pp. 35-45; Kalvin, A.D., Varol, Y.L., On the generation of all topological sortings (1983) Journal of Algorithms, 4 (2), pp. 150-162; Knoke, D., Yang, S., (2008) Social Network Analysis, 154. , Sage; Ervin Knuth, D., (1997) The Art of Computer Programming, 3. , Pearson Education; Krause, J., Croft, D.P., James, R., Social network theory in the behavioural sciences: Potential applications (2007) Behavioral Ecology and Sociobiology, 62 (1), pp. 15-27; Lohmann, N., Correcting deadlocking service choreographies using a simulation-based graph edit distance (2008) BPM, 8, pp. 132-147. , Springer; Mislove, A., Measurement and analysis of online social networks (2007) Proceedings of the 7th ACM SIGCOMM Conference on Internet Measurement. ACM, pp. 29-42; Rege, A., A temporal assessment of cyber intrusion chains using multidisciplinary frameworks and methodologies (2017) Cyber Situational Awareness, Data Analytics and Assessment (Cyber SA), 2017 International Conference On. IEEE, pp. 1-7; Riesen, K., Structural pattern recognition with graph edit distance (2015) Advances in Computer Vision and Pattern Recognition, Cham",,,,"Institute of Electrical and Electronics Engineers Inc.","2018 International Conference on Cyber Situational Awareness, Data Analytics and Assessment, CyberSA 2018","11 June 2018 through 12 June 2018",,143200,,9781538645659,,,"English","Int. Conf. Cyber Situational Aware., Data Anal. Assess., CyberSA",Conference Paper,"Final","",Scopus,2-s2.0-85059985619
"Song C., Pons A., Yen K.","57193648202;56715125700;7101628316;","AA-HMM: An anti-adversarial Hidden Markov model for network-based intrusion detection",2018,"Applied Sciences (Switzerland)","8","12","2421","","",,3,"10.3390/app8122421","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057532717&doi=10.3390%2fapp8122421&partnerID=40&md5=e04cf79db6c985f47d53965b55ed1f78","Department of Electrical and Computer Engineering, Florida International University, Miami, FL  33174, United States","Song, C., Department of Electrical and Computer Engineering, Florida International University, Miami, FL  33174, United States; Pons, A., Department of Electrical and Computer Engineering, Florida International University, Miami, FL  33174, United States; Yen, K., Department of Electrical and Computer Engineering, Florida International University, Miami, FL  33174, United States","In the field of network intrusion, malware usually evades anomaly detection by disguising malicious behavior as legitimate access. Therefore, detecting these attacks from network traffic has become a challenge in this an adversarial setting. In this paper, an enhanced Hidden Markov Model, called the Anti-Adversarial Hidden Markov Model (AA-HMM), is proposed to effectively detect evasion pattern, using the DynamicWindow and Threshold techniques to achieve adaptive, anti-adversarial, and online-learning abilities. In addition, a concept called Pattern Entropy is defined and acts as the foundation of AA-HMM.We evaluate the effectiveness of our approach employing two well-known benchmark data sets, NSL-KDD and CTU-13, in terms of the common performance metrics and the algorithm's adaptation and anti-adversary abilities. © 2017 by the authors.","Adaptability; Adversarial setting; Anti-Adversarial Hidden Markov Model (AA-HMM); Dynamic window (DW); Evasion patterns; Network intrusion detection; Pattern entropy (PE); Threshold (TH)",,,,,,"Sommer, R., Paxson, V., Outside the Closed World-On Using Machine Learning for Network Intrusion Detection (2010) Proceedings of the IEEE Symposium on Security and Privacy, , Berkeley/Oakland, CA, USA, 16-19 May; Linden, G., Smith, B., York, J., Amazon.com recommendations: Item-to-item collaborative filtering (2003) IEEE Internet Comput, 7, pp. 76-80; Gomez-Uribe, C.A., Hunt, N., The Netflix Recommender System: Algorithms, Business Value, and Innovation (2016) ACM Trans. Manag. Inf. Syst, 6, p. 13; Khan, N.H., Adnan, A., Urdu Optical Character Recognition Systems: Present Contributions and Future Directions (2018) IEEE Access, 6, pp. 46019-46046; Chen, K., Zhao, T., Yang, M., Liu, L., Tamura, A., Wang, R., Utiyama, M., Sumita, E., A Neural Approach to Source Dependence Based Context Model for Statistical Machine Translation (2018) IEEE Access, 6, pp. 266-280; Hsia, J.H., Chen, M.S., Language-model-based detection cascade for efficient classification of image-based spam e-mail (2009) Proceedings of the 2009 IEEE international conference on Multimedia and Expo ICME'09, pp. 1182-1185. , New York, NY, USA, 28 June-3 July; Zhang, F., Chan, P.P., Biggio, B., Yeung, D.S., Roli, F., Adversarial Feature Selection Against Evasion Attacks (2016) IEEE Trans. Cybern, 46, pp. 766-777; Polychronakis, M., Anagnostakis, K.G., Markatos, E.P., Real-world Polymorphic Attack Detection using Network-level Emulation (2008) Proceedings of the 4th AnnualWorkshop on Cyber Security and Information Intelligence Research: Developing Strategies to Meet the Cyber Security and Information Intelligence Challenges Ahead, , Oak Ridge, TN, USA, 12-14 May; Kaur, H., Singh, G., Minhas, J., A Review of Machine Learning based Anomaly Detection Techniques (2013) Int. J. Comput. Appl. Technol. Res, 2, pp. 185-187; Bhuyan, M.H., Bhattacharyya, D.K., Kalita, J.K., Network Anomaly Detection: Methods, Systems and Tools (2014) IEEE Commun. Surv. Tutor, 16, pp. 303-336; Kuncheva, L.I., (2004) Combining Pattern Classifiers: Methods and Algorithms, , Wiley: Hoboken, NJ, USA; Kuncheva, L.I., Diversity in multiple classifier systems (2005) Inf. Fusion, 6, pp. 3-4; Weng, F., Jiang, Q., Shi, L., Wu, N., An Intrusion Detection System Based on the Clustering Ensemble (2007) Proceedings of the InternationalWorkshop on Anti-Counterfeiting, pp. 121-124. , Security and Identification (ASID), Xiamen, China, 16-18 April; Hodo, E., Bellekens, X., Hamilton, A., Tachtatzis, C., Atkinson, R., (2017) Shallow and Deep Networks Intrusion Detection System: A Taxonomy and Survey; Shankar, V., Chang, S., Performance of Caffe on QCT Deep Learning Reference Architecture-A Preliminary Case Study (2017) Proceedings of the IEEE 4th International Conference on Cyber Security and Cloud Computing (CSCloud), pp. 35-39. , New York, NY, USA, 26-28 June; Khreich, W., Granger, E., Sabourin, R., Miri, A., Combining Hidden Markov Models for Improved Anomaly Detection (2009) Proceedings of the IEEE International Conference on Communications, pp. 1-6. , Dresden, Germany, 14-18 June; Hu, J., Yu, X., Qiu, D., Chen, H.H., A simple and efficient hidden Markov model scheme for host-based anomaly intrusion detection (2009) IEEE Netw, 23, pp. 42-47; Hurley, T., Perdomo, J.E., Perez-Pons, A., HMM-Based Intrusion Detection System for Software Defined Networking (2016) Proceedings of the 15th IEEE International Conference on Machine Learning and Applications (ICMLA), pp. 617-621. , Anaheim, CA, USA, 18-20 December; Jain, R., Abouzakhar, N.S., Hidden Markov Model based anomaly intrusion detection (2012) Proceedings of the International Conference for Internet Technology and Secured Transactions, pp. 528-533. , London, UK, 10-12 December; Song, X., Chen, G., Li, X., A Weak Hidden Markov Model based intrusion detection method for wireless sensor networks (2010) Proceedings of the International Conference on Intelligent Computing and Integrated Systems, pp. 887-889. , Guilin, China, 22-24 October; Ren, H., Ye, Z., Li, Z., Anomaly detection based on a dynamic Markov model (2017) Inf. Sci, 411, pp. 52-65; Ahmadian, R.A., Rasoolzadegan, A., Javan, J.A., A systematic review on intrusion detection based on the Hidden Markov Model (2018) Stat. Anal. Data Min. ASA Data Sci. J, 11, pp. 111-134; Ariu, D., Tronci, R., Giacinto, G., HMMPayl: An intrusion detection system based on Hidden Markov Model (2011) Comput. Secur, 30, pp. 221-241; Russell, S.J., Norvig, P., (2009) Artificial Intelligence: A Modern Approach, , 3rd ed. Pearson: Kuala Lumpur, Malaysia; Tan, P.N., Steinbach, M., Kumar, V., (2006) Introduction to Data Mining, , Pearson: London, UK; Rabiner, L.R., A Tutorial on Hidden Markov Model and Selected Applications in Speech Recognition (1989) Proc. IEEE, 77, pp. 257-286; Zhao, F., Zhao, J., Niu, X., Luo, S., Xin, Y., A Filter Feature Selection Algorithm Based on Mutual Information for Intrusion Detection (2018) Appl. Sci, 8, p. 1535; Hindy, H., Brosset, D., Bayne, E., Seeam, A., Tachtatzis, C., Atkinson, R., Bellekens, X., (2018) A Taxonomy and Survey of Intrusion Detection System Design Techniques, Network Threats and Datasets; https://cran.r-project.org/web/packages/HMM/HMM.pdf, (accessed on 11 October 2018); Lowd, D., Meek, C., Adversarial learning Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining, pp. 641-647. , Chicago, IL, USA, 21-24 August 200; Nelson, B., Rubinstein, B.I., Huang, L., Joseph, A.D., Lee, S.J., Rao, S., Tygar, J.D., Query strategies for evading convex-inducing classifiers (2012) J. Mach. Learn. Res, 13, pp. 1293-1332; Churbanov, A., Winters-Hilt, S., Implementing EM and Viterbi algorithms for Hidden Markov Model in linear memory (2008) BMC Bioinform, 9, p. 224; McHugh, J., Testing Intrusion Detection Systems: A Critique of the 1998 and 1999 DARPA Intrusion Detection System Evaluations as Performed by Lincoln Laboratory (2000) ACM Trans. Inf. Syst. Secur, 3, pp. 262-294; http://www.unb.ca/cic/datasets/nsl.html, (accessed on 11 October 2018); Tang, T.A., Mhamdi, L., McLernon, D., Zaidi, S.A.R., Ghogho, M., Deep Learning Approach for Network Intrusion Detection in Software Defined Networking (2016) Proceedings of the International Conference on Wireless Networks and Mobile Communications (WINCOM), , Fez, Morocco, 26-29 October; Niyaz, Q., Sun, W., Javaid, A.Y., Alam, M., A Deep Learning Approach for Network Intrusion Detection System (2015) Proceedings of the 9th EAI International Conference on Bio-inspired Information and Communications Technologies, pp. 21-26. , BICT'15, New York, NY, USA, 3-5 December; Garcia, S., Grill, M., Stiborek, J., Zunino, A., An empirical comparison of botnet detection methods (2014) Comput. Secur. J, 45, pp. 100-123; Dhanabal, L., Shantharajah, S.P., A Study on NSL-KDD Data set for Intrusion Detection System Based on Classification Algorithms (2015) Int. J. Adv. Res. Comput. Commun. Eng, 4, pp. 446-452; Song, C., Perez-Pons, A., Yen, K.K., Building a Platform for Software-Defined Networking Cybersecurity Applications (2016) Proceedings of the 15th IEEE International Conference on Machine Learning and Applications (ICMLA), pp. 482-487. , Anaheim, CA, USA, 18-20 December","Song, C.; Department of Electrical and Computer Engineering, United States; email: ysong024@fiu.edu",,,"MDPI AG",,,,,20763417,,,,"English","Appl. Sci.",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85057532717
"Anderson T., Chang C.-Y., Martinez S.","57202248801;22833548500;7202228052;","Maximizing Algebraic Connectivity of Constrained Graphs in Adversarial Environments",2018,"2018 European Control Conference, ECC 2018",,,"8550531","125","130",,,"10.23919/ECC.2018.8550531","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059814001&doi=10.23919%2fECC.2018.8550531&partnerID=40&md5=04222531c5829928a0e025df1b16057b","Department of Mechanical and Aerospace Engineering, University of California, San Diego, CA, United States","Anderson, T., Department of Mechanical and Aerospace Engineering, University of California, San Diego, CA, United States; Chang, C.-Y., Department of Mechanical and Aerospace Engineering, University of California, San Diego, CA, United States; Martinez, S., Department of Mechanical and Aerospace Engineering, University of California, San Diego, CA, United States","This paper aims to maximize algebraic connectivity of networks via topology design under the presence of constraints and an adversary. We are concerned with three problems. First, we formulate the concave-maximization topology design problem of adding edges to an initial graph, which introduces a nonconvex binary decision variable, in addition to subjugation to general convex constraints on the feasible edge set. Unlike previous approaches, our method is justifiably not greedy and is capable of accommodating these additional constraints. We also study a scenario in which a coordinator must selectively protect edges of the network from a chance of failure due to a physical disturbance or adversarial attack. The coordinator needs to strategically respond to the adversary's action without presupposed knowledge of the adversary's feasible attack actions. We propose three heuristic algorithms for the coordinator to accomplish the objective and identify worst-case preventive solutions. Each algorithm is shown to be effective in simulation and their compared performance is discussed. © 2018 European Control Association (EUCA).",,"Algebra; Heuristic algorithms; Adversarial environments; Algebraic connectivity; Binary decision; Convex constraints; Initial graph; Nonconvex; Physical disturbance; Topology design; Topology",,,,,"Bhattacharya, S., Gupta, A., Basar, T., Jamming in mobile networks: A game-theoretic approach (2013) Numerical Algebra, Optimization, and Control, 3 (1), pp. 1-30; Boyd, S., Convex optimization of graph Laplacian eigenvalues (2006) Proc. Int. Congress of Mathematicians, 3, pp. 1311-1319; Boyd, S., Vandenberghe, L., (2004) Convex Optimization, , Cambridge University Press; De Abreu, N., Old and new results on algebraic connectivity of graphs (2006) Linear Algebra and Its Applications, 423, pp. 53-73; Ding, X., Jiang, T., Old and new results on algebraic connectivity of graphs (2010) The Annals of Applied Probability, 20 (6), pp. 2086-2117; Fiedler, M., Algebraic connectivity of graphs (1973) Czechoslovak Mathematical Journal, 23 (98), pp. 298-305; Ghosh, A., Boyd, S., Growing well-connected graphs (2006) IEEE Int. Conf. on Decision and Control, pp. 6605-6611. , San Diego, USA; Godsil, C.D., Royle, G.F., (2001) Algebraic Graph Theory, Volume 207 of Graduate Texts in Mathematics, , Springer, New York; Goemans, M., Williamson, D., Improved approximation algorithms for maximum cut and satisfiability problems using semidefinite programming (1995) Journal of the Association for Computing Machinery, 42 (6), pp. 1115-1145; Merris, R., Laplacian graph eigenvectors (1998) Linear Algebra and Its Applications, 278 (1-3), pp. 221-236; Urschel, J., Xu, J., Hu, X., Zikatanov, L., A cascadic multigrid algorithm for computing the fiedler vector of graph laplacians (2015) Journal of Computational Mathematics, 33 (2), pp. 209-226; Vandenberghe, L., Boyd, S., Semidefinite programming (1996) SIAM Review, 38 (1), pp. 49-95; Yang, P., Freeman, R.A., Gordon, G.J., Lynch, K.M., Srinivasa, S.S., Sukthankar, R., Decentralized estimation and control of graph connectivity for mobile sensor networks (2010) Automatica, 46 (2), pp. 390-396",,,"European Control Association (EUCA)","Institute of Electrical and Electronics Engineers Inc.","16th European Control Conference, ECC 2018","12 June 2018 through 15 June 2018",,143041,,9783952426982,,,"English","Eur. Control Conf., ECC",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85059814001
"Bose A.J., Aarabi P.","57209182963;35581281600;","Adversarial attacks on face detectors using neural net based constrained optimization",2018,"2018 IEEE 20th International Workshop on Multimedia Signal Processing, MMSP 2018",,,"8547128","","",,40,"10.1109/MMSP.2018.8547128","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059991801&doi=10.1109%2fMMSP.2018.8547128&partnerID=40&md5=471717b33dff8317aa528c80de97d594","University of Toronto, Department of Electrical and Computer Engineering, Canada","Bose, A.J., University of Toronto, Department of Electrical and Computer Engineering, Canada; Aarabi, P., University of Toronto, Department of Electrical and Computer Engineering, Canada","Adversarial attacks involve adding, small, often imperceptible, perturbations to inputs with the goal of getting a machine learning model to misclassifying them. While many different adversarial attack strategies have been proposed on image classification models, object detection pipelines have been much harder to break. In this paper, we propose a novel strategy to craft adversarial examples by solving a constrained optimization problem using an adversarial generator network. Our approach is fast and scalable, requiring only a forward pass through our trained generator network to craft an adversarial sample. Unlike in many attack strategies we show that the same trained generator is capable of attacking new images without explicitly optimizing on them. We evaluate our attack on a trained Faster R-CNN face detector on the cropped 300-W face dataset where we manage to reduce the number of detected faces to 0.5% of all originally detected faces. In a different experiment, also on 300-W, we demonstrate the robustness of our attack to a JPEG compression based defense typical JPEG compression level of 75% reduces the effectiveness of our attack from only 0.5% of detected faces to a modest 5.0%. © 2018 IEEE.","Adversarial Attacks; Deep Learning; Face Detection; Object Detection","Constrained optimization; Deep learning; Image compression; Multimedia signal processing; Object detection; Object recognition; Adversarial Attacks; Attack strategies; Classification models; Constrained optimi-zation problems; Face detector; JPEG compression; Machine learning models; Novel strategies; Face recognition",,,,,"Schmidhuber, J., Deep learning in neural networks: An overview (2015) Neural Networks, 61, pp. 85-117; Esteva, A., Kuprel, B., Novoa, R.A., Ko, J., Swetter, S.M., Blau, H.M., Thrun, S., Dermatologist-level classification of skin cancer with deep neural networks (2017) Nature, 542 (7639), pp. 115-118; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519. , ACM; Baluja, S., Fischer, I., (2017) Adversarial Transformation Networks: Learning to Generate Adversarial Examples; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387. , IEEE; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium on, pp. 39-57. , IEEE; Girshick, R., (2015) Fast R-cnn; Belhumeur, P.N., Jacobs, D.W., Kriegman, D.J., Kumar, N., Localizing parts of faces using a consensus of exemplars (2013) IEEE Transactions on Pattern Analysis and Machine Intelligence, 35 (12), pp. 2930-2940; Zhu, X., Ramanan, D., Face detection, pose estimation, and landmark localization in the wild (2012) Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, pp. 2879-2886. , IEEE; Le, V., Brandt, J., Lin, Z., Bourdev, L., Huang, T.S., Interactive facial feature localization (2012) European Conference on Computer Vision, pp. 679-692. , Springer; Messer, K., Matas, J., Kittler, J., Luettin, J., Maitre, G., Xm2vtsdb: The extended m2vts database (1999) Second International Conference on Audio and Video-based Biometric Person Authentication, 964, pp. 965-966; Phillips, P.J., Flynn, P.J., Scruggs, T., Bowyer, K.W., Chang, J., Hoffman, K., Marques, J., Worek, W., Overview of the face recognition grand challenge (2005) Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on, 1, pp. 947-954. , IEEE; Das, N., Shanbhogue, M., Chen, S.-T., Hohman, F., Chen, L., Kounavis, M.E., Chau, D.H., (2017) Keeping the Bad Guys Out: Protecting and Vaccinating Deep Learning with Jpeg Compression; Dziugaite, G.K., Ghahramani, Z., Roy, D.M., (2016) A Study of the Effect of Jpg Compression on Adversarial Images; Akhtar, N., Mian, A., (2018) Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey; Xiao, C., Li, B., Zhu, J.-Y., He, W., Liu, M., Song, D., (2018) Generating Adversarial Examples with Adversarial Networks; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., Adversarial examples for semantic segmentation and object detection (2017) International Conference on Computer Vision, , IEEE; Girshick, R., Donahue, J., Darrell, T., Malik, J., Rich feature hierarchies for accurate object detection and semantic segmentation (2014) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 580-587; Cśaji, B.C., Approximation with artificial neural networks (2001) Faculty of Sciences, Etvs Lornd University, Hungary, 24, p. 48; Olah, C., Satyanarayan, A., Johnson, I., Carter, S., Schubert, L., Ye, K., Mordvintsev, A., The building blocks of interpretability (2018) Distill, 3 (3), p. e10; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., Imagenet: A large-scale hierarchical image database (2009) Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pp. 248-255. , IEEE; Yang, S., Luo, P., Loy, C.-C., Tang, X., Wider face: A face detection benchmark (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 5525-5533; Kingma, D., Ba, J., (2014) Adam: A Method for Stochastic Optimization; Gross, R., Matthews, I., Cohn, J., Kanade, T., Baker, S., Multi-pie (2010) Image and Vision Computing, 28 (5), pp. 807-813",,,,"Institute of Electrical and Electronics Engineers Inc.","20th IEEE International Workshop on Multimedia Signal Processing, MMSP 2018","29 August 2018 through 31 August 2018",,143192,,9781538660706,,,"English","IEEE Int. Workshop Multimed. Signal Process., MMSP",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85059991801
"Apruzzese G., Colajanni M.","57196326506;7003997441;","Evading botnet detectors based on flows and random forest with adversarial samples",2018,"NCA 2018 - 2018 IEEE 17th International Symposium on Network Computing and Applications",,,"8548327","","",,17,"10.1109/NCA.2018.8548327","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059979517&doi=10.1109%2fNCA.2018.8548327&partnerID=40&md5=00351de7301f779dceebc697b90153b7","University of Modena and Reggio Emilia, Department of Engineering Enzo Ferrari, Modena, Italy","Apruzzese, G., University of Modena and Reggio Emilia, Department of Engineering Enzo Ferrari, Modena, Italy; Colajanni, M., University of Modena and Reggio Emilia, Department of Engineering Enzo Ferrari, Modena, Italy","Machine learning is increasingly adopted for a wide array of applications, due to its promising results and autonomous capabilities. However, recent research efforts have shown that, especially within the image processing field, these novel techniques are susceptible to adversarial perturbations. In this paper, we present an analysis that highlights and evaluates experimentally the fragility of network intrusion detection systems based on machine learning algorithms against adversarial attacks. In particular, our study involves a random forest classifier that utilizes network flows to distinguish between botnet and benign samples. Our results, derived from experiments performed on a public real dataset of labelled network flows, show that attackers can easily evade such defensive mechanisms by applying slight and targeted modifications to the network activity generated by their controlled bots. These findings pave the way for future techniques that aim to strengthen the performance of machine learning-based network intrusion detection systems. © 2018 IEEE.","Adversarial samples; botnet; flow inspection; intrusion detection; machine learning; random forest","Artificial intelligence; Botnet; Computer crime; Decision trees; Image processing; Intrusion detection; Learning systems; Autonomous capability; Defensive mechanism; Network activities; Network intrusion detection systems; Novel techniques; Random forest classifier; Random forests; Recent researches; Learning algorithms",,,,,"Jordan, M.I., Mitchell, T.M., Machine learning: Trends, perspectives, and prospects (2015) Science; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, , IEEE; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Srndic, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Joint European Conference on Machine Learning and Knowledge Discovery in Databases, , Springer; Papernot, N., McDaniel, P., Sinha, A., Wellman, M., (2016) Towards the Science of Security and Privacy in Machine Learning; Su, J., Vargas, D.V., Kouichi, S., (2017) One Pixel Attack for Fooling Deep Neural Networks; Apruzzese, G., Colajanni, M., Ferretti, L., Guido, A., Marchetti, M., On the effectiveness of machine and deep learning for cybersecurity (2018) International Conference on Cyber Conflicts (CyCon), 2018 NATO. NATO; Silva, S.S., Silva, R.M., Pinto, R.C., Salles, R.M., Botnets: A survey (2013) Computer Networks; Gardiner, J., Nagaraja, S., On the security of machine learning in malware c&c detection: A survey (2016) ACM Computing Surveys (CSUR), 49 (3), p. 59; Stevanovic, M., Pedersen, J.M., An analysis of network traffic classification for botnet detection (2015) Cyber Situational Awareness, Data Analytics and Assessment (CyberSA), 2015 International Conference on, , IEEE; Apruzzese, G., Marchetti, M., Colajanni, M., Zoccoli, G.G., Guido, A., Identifying malicious hosts involved in periodic communications (2017) Network Computing and Applications (NCA), 2017 IEEE 16th International Symposium on, , IEEE; https://www.symantec.com/security-center/threat-report, Internet Security Threat Report 2018visited in Jun. 2018; Sommer, R., Paxson, V., Outside the closed world: On using machine learning for network intrusion detection (2010) Security and Privacy (SP), 2010 IEEE Symposium on, , IEEE; Perdisci, R., Corona, I., Giacinto, G., Early detection of malicious flux networks via large-scale passive dns traffic analysis (2012) IEEE Transactions on Dependable and Secure Computing; Antonakakis, M., Perdisci, R., Lee, W., Vasiloglou, N., Dagon, D., Detecting malware domains at the upper dns hierarchy (2011) USENIX Security Symposium, 11, pp. 1-16; Stevanovic, M., Pedersen, J.M., An efficient flow-based botnet detection using supervised machine learning (2014) Computing, Networking and Communications (ICNC), 2014 International Conference on, , IEEE; Anderson, H.S., Woodbridge, J., Filar, B., Deepdga: Adversarially-tuned domain generation and detection (2016) Proceedings of the 2016 ACM Workshop on Artificial Intelligence and Security, , ACM; Choudhury, S., Bhowal, A., Comparative analysis of machine learning algorithms along with classifiers for network intrusion detection (2015) Smart Technologies and Management for Computing, Communication, Controls, Energy and Materials (ICSTM), 2015 International Conference on, , IEEE; Bilge, L., Balzarotti, D., Robertson, W., Kirda, E., Kruegel, C., Disclosure: Detecting botnet command and control servers through large-scale netflow analysis (2012) ACSAC; Pierazzi, F., Apruzzese, G., Colajanni, M., Guido, A., Marchetti, M., Scalable architecture for online prioritisation of cyber threats (2017) IEEE CyCon; Gardiner, J., Nagaraja, S., On the security of machine learning in malware c&c detection: A survey (2016) ACM Computing Surveys (CSUR); Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I., Tygar, J., Adversarial machine learning (2011) Proceedings of the 4th ACM Workshop on Security and Artificial Intelligence, , ACM; Xu, W., Qi, Y., Evans, D., Automatically evading classifiers (2016) Proceedings of the 2016 Network and Distributed Systems Symposium; Garcia, S., Grill, M., Stiborek, J., Zunino, A., An empirical comparison of botnet detection methods (2014) Computers &Security; Apruzzese, G., Pierazzi, F., Colajanni, M., Marchetti, M., Detection and threat prioritization of pivoting attacks in large networks (2017) IEEE Transactions on Emerging Topics in Computing",,,"Akamai Technologies, Inc.;IEEE Computers Society;IEEE Technical Committee on Distributed Processing (TCDP);International Research Institute on Autonomic Network Computing","Institute of Electrical and Electronics Engineers Inc.","17th IEEE International Symposium on Network Computing and Applications, NCA 2018","1 November 2018 through 3 November 2018",,143157,,9781538676592,,,"English","NCA - IEEE Int. Symp. Netw. Comput. Appl.",Conference Paper,"Final","",Scopus,2-s2.0-85059979517
"Wang S., Shi Y., Han Y.","57205363994;57204978397;55489219500;","Universal Perturbation Generation for Black-box Attack Using Evolutionary Algorithms",2018,"Proceedings - International Conference on Pattern Recognition","2018-August",,"8546023","1277","1282",,2,"10.1109/ICPR.2018.8546023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059774866&doi=10.1109%2fICPR.2018.8546023&partnerID=40&md5=727d24d4e0df14501e9194015a61d4ad","School of Computer Science and Technology, Tianjin University, Tianjin, China","Wang, S., School of Computer Science and Technology, Tianjin University, Tianjin, China; Shi, Y., School of Computer Science and Technology, Tianjin University, Tianjin, China; Han, Y., School of Computer Science and Technology, Tianjin University, Tianjin, China","Image classifiers based on deep neural networks (DNNs) are vulnerable to tiny, imperceptible perturbations. Maliciously generated adversarial examples can exploit the instability of DNNs and mislead it into outputting a wrong classification result. Prior works showed the transferability of adversarial perturbations between models and between images. In this work, we shed light on the combination of source/target misclassification, black-box attack, and universal perturbation by employing improved evolutionary algorithms. We additionally find that the use of adversarial initialization enhances the efficiency of evolutionary algorithms finding universal perturbations. Experiments demonstrate impressive misclassification rates and surprising transferability for the proposed attack method using different models trained on CIFAR-10 and CIFAR-100 datasets. Our attach method also shows robustness against defensive measures like adversarial training. © 2018 IEEE.",,"Deep neural networks; Pattern recognition; Attack methods; Black boxes; Classification results; Defensive measures; Image Classifiers; Misclassification rates; Misclassifications; Evolutionary algorithms",,,,,"Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R., Intriguing properties of neural networks (2013) CoRR, , abs/1312.6199; Papernot, N., McDaniel, P.D., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) 2016 IEEE European Symposium on Security and Privacy (EuroS&P, pp. 372-387; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2014) CoRR, , abs/1412.6572; Carlini, N., Wagner, D.A., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP, pp. 39-57; Miyato, T., Ichi Maeda, S., Koyama, M., Nakae, K., Ishii, S., (2015) Distributional smoothing with virtual adversarial training; Papernot, N., McDaniel, P.D., Goodfellow, I.J., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against deep learning systems using adversarial examples (2016) CoRR, , abs/1602.02697; Liu, Y., Chen, X., Liu, C.C., Song, D.X., Delving into transferable adversarial examples and black-box attacks (2016) CoRR, , abs/ 1611.02770; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR, pp. 86-94; Storn, R., Price, K.V., Differential evolution-A simple and efficient heuristic for global optimization over continuous spaces (1997) J. Global Optimization, 11, pp. 341-359; Whitley, D., (1993) A genetic algorithm tutorial; Kennedy, J., Eberhart, R., (1995) Particle swarm optimization, pp. 1942-1948; Krizhevsky, A., (2009) Learning multiple layers of features from tiny images; Baluja, S., Fischer, I., Adversarial transformation networks: Learning to generate adversarial examples (2017) CoRR, , abs/1703.09387; Clerc, M., Kennedy, J., The particle swarm-explosion, stability, and convergence in a multidimensional complex space (2002) IEEE Trans. Evolutionary Computation, 6, pp. 58-73; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2014) CoRR, , abs/1409.1556; Fawzi, A., Moosavi-Dezfooli, S.-M., Frossard, P., Soatto, S., Classification regions of deep neural networks (2017) CoRR, , abs/1705.09552",,,"International Association for Pattern Recognition (IAPR)","Institute of Electrical and Electronics Engineers Inc.","24th International Conference on Pattern Recognition, ICPR 2018","20 August 2018 through 24 August 2018",,143085,10514651,9781538637883,PICRE,,"English","Proc. Int. Conf. Pattern Recognit.",Conference Paper,"Final","",Scopus,2-s2.0-85059774866
"Zou H., Zhang H., Li X., Liu J., He Z.","57196343090;56080957700;54581247200;55705937000;16202583700;","Generation Textured Contact Lenses Iris Images Based on 4DCycle-GAN",2018,"Proceedings - International Conference on Pattern Recognition","2018-August",,"8546154","3561","3566",,3,"10.1109/ICPR.2018.8546154","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059748900&doi=10.1109%2fICPR.2018.8546154&partnerID=40&md5=5c64fb31a3363959b1b013c7411696f3","Beijing IrisKing Co. Ltd, China","Zou, H., Beijing IrisKing Co. Ltd, China; Zhang, H., Beijing IrisKing Co. Ltd, China; Li, X., Beijing IrisKing Co. Ltd, China; Liu, J., Beijing IrisKing Co. Ltd, China; He, Z., Beijing IrisKing Co. Ltd, China","With the development of iris recognition, many identity authentication applications began to use this inherent biometric ID. Despite the breakthroughs in the identification with iris recognition technology, one primary problem remains unsolved: The presentation spoof attack. In this paper, we present a novel algorithm 4DCycle-GAN for expanding the spoof iris image database by synthesizing fake iris images wearing textured contact lenses. The proposed 4DCycle-GAN follows the Cycle-Consistent Adversarial Networks (Cycle-GAN) framework which translating between one kind images (genuine iris images) and one other kind images (textured contact lenses iris images). The 4DCycle-GAN introduces two more discriminators to improve the Cycle-GAN at the defect of lack of diversity. The two new discriminators 'prefer' images generated by the generators, while the original discriminators in Cycle-GAN 'prefer' real captured images. These new added confrontations make the 4DCycle-GAN avoid generating a certain kind of contact lenses texture which is larger percentage of the training iris database. The synthesized textured contact lenses iris images are used for spoofing iris detection training to improve the robustness of classification algorithm. Both the Cycle-GAN and the 4DCycle-GAN synthesizing images can improve the spoof classification results. Moreover, by using the 4DCycle-GAN, the spoof classification results are distinctly improved for unrelated non-homologous database experiments. Extensive experimental results show that the proposed method can improve the anti-spoof ability of iris recognition system. © 2018 IEEE.",,"Biometrics; Classification (of information); Contact lenses; Database systems; Adversarial networks; Classification algorithm; Classification results; Identity authentication; Iris recognition; Iris recognition systems; Iris recognition technology; Novel algorithm; Image enhancement",,,,,"Jain, A., Bolle, R., Pankanti, S., Biometrics: Personal identification in networked society (2006) Springer Science & Business Media, 479; Cui, J., Wang, Y., Huang, J., Tan, T., Sun, Z., An iris image synthesis method based on pca and super-resolution (2004) Pattern Recognition, 2004. ICPR 2004. Proceedings of the 17th International Conference on, 4, pp. 471-474. , IEEE; Ma, L., Tan, T., Wang, Y., Zhang, D., Personal identification based on iris texture analysis (2003) IEEE Transactions on Pattern Analysis and Machine Intelligence, 25 (12), pp. 1519-1533; Sun, Z., Zhang, H., Tan, T., Wang, J., Iris image classification based on hierarchical visual codebook (2014) IEEE Transactions on Pattern Analysis and Machine Intelligence, 36 (6), pp. 1120-1133; Zhang, H., Sun, Z., Tan, T., Wang, J., Learning hierarchical visual codebook for iris liveness detection (2011) International Joint Conference on Biometrics, 1; Daugman, J., How iris recognition works (2004) IEEE Transactions on Circuits and Systems for Video Technology, 14 (1), pp. 21-30; He, X., Lu, Y., Shi, P., A fake iris detection method based on fft and quality assessment (2008) Pattern Recognition, 2008. CCPR'08. Chinese Conference On. IEEE, pp. 1-4; Zuo, J., Schmid, N.A., Chen, X., On generation and analysis of synthetic iris images (2007) IEEE Transactions on Information Forensics and Security, 2 (1), pp. 77-90; Zuo, J., Schmid, N.A., Chen, X., On performance comparison of real and synthetic iris images 2006 International Conference on Image Processing, Oct 2006, pp. 305-308; Makthal, S., Ross, A., Synthesis of iris images using markov random fields (2005) Signal Processing Conference, 2005 13th European. IEEE, pp. 1-4; Wei, Z., Tan, T., Sun, Z., Synthesis of large realistic iris databases using patch-based sampling (2008) Pattern Recognition, 2008. ICPR 2008. 19th International Conference On. IEEE, pp. 1-4; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, pp. 2672-2680; Kohli, N., Yadav, D., Vatsa, M., Singh, R., Noore, A., (2017) Synthetic iris presentation attack using idcgan, , arXiv preprint arXiv:1710.10565; Radford, A., Metz, L., Chintala, S., (2015) Unsupervised representation learning with deep convolutional generative adversarial networks, , arXiv preprint arXiv:1511.06434; Zhu, J.-Y., Park, T., Isola, P., Efros, A.A., (2017) Unpaired image-to-image translation using cycle-consistent adversarial networks, , arXiv preprint arXiv:1703.10593; Nguyen, T., Le, T., Vu, H., Phung, D., Dual discriminator generative adversarial nets (2017) Advances in Neural Information Processing Systems, pp. 2667-2677; Isola, P., Zhu, J.-Y., Zhou, T., Efros, A.A., Image-to-image translation with conditional adversarial networks (2017) CVPR; Mirza, M., Osindero, S., (2014) Conditional generative adversarial nets, , arXiv preprint arXiv:1411.1784; Qi, G.-J., (2017) Loss-sensitive generative adversarial networks on lipschitz densities, , arXiv preprint arXiv:1701.06264; Wang, J., Yang, J., Yu, K., Lv, F., Huang, T., Gong, Y., Localityconstrained linear coding for image classification (2010) Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference On. IEEE, pp. 3360-3367",,,"International Association for Pattern Recognition (IAPR)","Institute of Electrical and Electronics Engineers Inc.","24th International Conference on Pattern Recognition, ICPR 2018","20 August 2018 through 24 August 2018",,143085,10514651,9781538637883,PICRE,,"English","Proc. Int. Conf. Pattern Recognit.",Conference Paper,"Final","",Scopus,2-s2.0-85059748900
"Yu P., Song K., Lu J.","57205361840;57203343121;55547138819;","Generating Adversarial Examples with Conditional Generative Adversarial Net",2018,"Proceedings - International Conference on Pattern Recognition","2018-August",,"8545152","676","681",,9,"10.1109/ICPR.2018.8545152","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059737711&doi=10.1109%2fICPR.2018.8545152&partnerID=40&md5=65de040cdd3d34df6c02827a72684e7a","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China","Yu, P., School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; Song, K., School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; Lu, J., School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China","Recently, deep neural networks have significant progress and successful application in various fields, but they are found vulnerable to attack instances, e.g., adversarial examples. State-of-art attack methods can generate attack images by adding small perturbation to the source image. These attack images can fool the classifier but have little impact to human. Therefore, such attack instances are difficult to generate by searching the feature space. How to design an effective and robust generating method has become a spotlight. Inspired by adversarial examples, we propose two novel generative models to produce adaptive attack instances directly, in which conditional generative adversarial network is adopted and distinctive strategy is designed for training. Compared with the common method, such as Fast Gradient Sign Method, our models can reduce the generating cost and improve robustness and has about one fifth running time for producing attack instance. © 2018 IEEE.","adversarial examples; DNN attack; generative adversarial network","Deep neural networks; adversarial examples; Adversarial networks; Attack methods; DNN attack; Generating methods; Generative model; Small perturbations; Source images; Pattern recognition",,,,,"Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition, , arXiv preprint arXiv:1409. 1556; Girshick, R., Fast r-cnn (2015) Proceedings of the IEEE International Conference on Computer Vision, pp. 1440-1448; Cambria, E., White, B., Jumping NLP Curves: A Review of Natural Language Processing Research [Review Article] (2014) IEEE Computational Intelligence Magazine, 9, pp. 48-57; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., (2013) Intriguing Properties of Neural Networks, , arXiv preprint arXiv:1312. 6199; Hornik, K., Stinchcombe, M., White, H., Multilayer feedforward networks are universal approximators (1989) Neural Networks, 2, pp. 359-366; Goodfellow, I.J., Shlens, J., Szegedy, C., Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICML, pp. 1-10; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 770-778; Huang, G., Liu, Z., Maaten L, V.D., Weinberger, K.Q., Densely connected convolutional networks (2017) 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2261-2269; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) 2016 IEEE European Symposium on Security and Privacy (EuroS&P), pp. 372-387; Carlini, N., Mishra, P., Vaidya, T., Zhang, Y., Sherr, M., Shields, C., Hidden voice commands (2016) USENIX Security Symposium, pp. 513-530; Vaidya, T., Zhang, Y., Sherr, M., Shields, C., Cocaine noodles: Exploiting the gap between human and machine speech recognition (2015) Usenix Conference on Offensive Technologies, p. 16; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples, , arXiv preprint arXiv:1605. 07277; Tramèr, F., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2017) The Space of Transferable Adversarial Examples, , arXiv preprint arXiv:1704. 03453; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, pp. 2672-2680; Arjovsky, M., Chintala, S., Bottou, L., Wasserstein generative adversarial networks (2017) International Conference on Machine Learning, pp. 214-223; Mirza, M., Osindero, S., (2014) Conditional Generative Adversarial Nets, , arXiv preprint arXiv:1411. 1784; Chen, X., Duan, Y., Houthooft, R., Schulman, J., Sutskever, I., Abbeel, P., Infogan: Interpretable representation learning by information maximizing generative adversarial nets (2016) Advances in Neural Information Processing Systems, pp. 2172-2180; Odena, A., Olah, C., Shlens, J., (2016) Conditional Image Synthesis with Auxiliary Classifier Gans, , arXiv preprint arXiv:1610. 09585; LeCun, Y., Cortes, C., (2010) The Mnist Database of Handwritten Digits; Xiao, H., Rasul, K., Vollgraf, R., (2017) Fashion-MNIST: A Novel Image Dataset for Benchmarking Machine Learning Algorithms; Kingma, D.P., Ba, J., Adam: A method for stochastic optimization (2014) Computer Science; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint arXiv:1607. 02533; Sinha, A., Namkoong, H., Duchi, J., (2017) Certifiable Distributional Robustness with Principled Adversarial Training, , arXiv preprint arXiv:1710. 10571",,,"International Association for Pattern Recognition (IAPR)","Institute of Electrical and Electronics Engineers Inc.","24th International Conference on Pattern Recognition, ICPR 2018","20 August 2018 through 24 August 2018",,143085,10514651,9781538637883,PICRE,,"English","Proc. Int. Conf. Pattern Recognit.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85059737711
"Leemaster J., Vai M., Whelihan D., Whitman H., Khazan R.","6504244202;26435630100;7801390874;57201447249;56625232900;","Functionality and Security Co-design Environment for Embedded Systems",2018,"2018 IEEE High Performance Extreme Computing Conference, HPEC 2018",,,"8547516","","",,1,"10.1109/HPEC.2018.8547516","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059526164&doi=10.1109%2fHPEC.2018.8547516&partnerID=40&md5=8514283432fc2a7f2e7aaa9b8bf396fd","MIT Lincoln Laboratory, Lexington, MA, United States","Leemaster, J., MIT Lincoln Laboratory, Lexington, MA, United States; Vai, M., MIT Lincoln Laboratory, Lexington, MA, United States; Whelihan, D., MIT Lincoln Laboratory, Lexington, MA, United States; Whitman, H., MIT Lincoln Laboratory, Lexington, MA, United States; Khazan, R., MIT Lincoln Laboratory, Lexington, MA, United States","For decades, embedded systems, ranging from intelligence, surveillance, and reconnaissance (ISR) sensors to electronic warfare and electronic signal intelligence systems, have been an integral part of U.S. Department of Defense (DoD) mission systems. These embedded systems are increasingly the targets of deliberate and sophisticated attacks. Developers thus need to focus equally on functionality and security in both hardware and software development. For critical missions, these systems must be entrusted to perform their intended functions, prevent attacks, and even operate with resilience under attacks. The processor in a critical system must thus provide not only a root of trust, but also a foundation to monitor mission functions, detect anomalies, and perform recovery. We have developed a Lincoln Asymmetric Multicore Processing (LAMP) architecture, which mitigates adversarial cyber effects with separation and cryptography and provides a foundation to build a resilient embedded system. We will describe a design environment that we have created to enable the co-design of functionality and security for mission assurance. © 2018 IEEE.","Asymmetric multicore processing; Availability; Co-design; Mission assurance; Resilience; Secure processing; Security; Testbed","Availability; Electronic warfare; Hardware security; Military applications; Multicore programming; Software design; Testbeds; Asymmetric multicore; Co-designs; Mission assurances; Resilience; Security; Embedded systems",,,,,"Martinez, D.R., Bond, R.A., Vai, M., (2008) High Performance Embedded Computing Handbook: A Systems Perspective, , Boca Raton: CRC Press; Vai, M., Whelihan, D., Nahill, B., Utin, D., O'Melia, S., Khazan, R., Secure embedded systems (2016) Lincoln Laboratory Journal, 22 (1); Vai, M., Whelihan, D., Khazan, R., Next-generation embedded processors: An update (2018) GOMACTech Conference, , Miami; Vai, M., Whelihan, D., Leemaster, J., Mission Assurance: Beyond Secure Processing (2018) The 3rd IEEE International Workshop on Cyber Resilience Technologies, Their Benefits and Measurements; https://riscv.org, accessed 1 April, 2018; Costan, V., Lebedev, I., Devadas, S., (2018) Sanctum: Minimal Hardware Extensions for Strong Software Isolation, , https://eprint.iacr.org/2015/564.pdf, accessed 1 April; Whelihan, D., Vai, M., SHAMROCK: A synthesizable high assurance cryptography and key management coprocessor (2016) MILCOM; https://www.synopsys.com/dw/ipdir.php?ds=asip-designer, accessed April 23, 2018; Whelihan, D., Vai, M., Designing agility and resilience into embedded systems (2017) MILCOM; https://www.cbsnews.com/news/60-minutes-capturing-The-perdix-droneswarm, accessed 1 April, 2018; https://beaverworks.ll.mit.edu/CMS/bw/projectperdixcapstone, accessed 1 April, 2018; https://riscv.org/risc-v-cores, accessed 9 May, 2018; (2017) ASIP Designer TZSCALE Processorr Manual, , Synopsys Inc., Version L-2016.06; (2017) Chess Compiler User Manual, , Synopsys Inc September. Version N-2017.09; https://github.com/ucb-bar/riscv-boom, accessed 9 May, 2018",,,,"Institute of Electrical and Electronics Engineers Inc.","2018 IEEE High Performance Extreme Computing Conference, HPEC 2018","25 September 2018 through 27 September 2018",,143186,,9781538659892,,,"English","IEEE High Perform. Extrem. Comput. Conf., HPEC",Conference Paper,"Final","",Scopus,2-s2.0-85059526164
"Wang K., Wang L., Cui M.","57203863999;57070563900;57203865383;","Trajectory tracking and recovery attacks in VANET systems",2018,"International Journal of Communication Systems","31","17","e3797","","",,2,"10.1002/dac.3797","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053242694&doi=10.1002%2fdac.3797&partnerID=40&md5=d94fd6c7cb729f00b9b472ab17ce6a06","School of Software, Dalian University of Technology, Dalian, China; Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, Dalian, China; Police Information Technology Department of Liaoning Police College, Dalian, China","Wang, K., School of Software, Dalian University of Technology, Dalian, China, Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, Dalian, China, Police Information Technology Department of Liaoning Police College, Dalian, China; Wang, L., School of Software, Dalian University of Technology, Dalian, China, Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, Dalian, China; Cui, M., School of Software, Dalian University of Technology, Dalian, China","Investigating the mechanisms of various attacks in vehicular ad hoc networks (VANETs) provides fundamental basis to develop safeguard techniques for network security issues. As they develops, attacking strategies are also needed to be established for people to learn how to defend. Previous works failed to consider multiple victims recovery and minimum road side units (RSUs) deployment issues. In this paper, we approach the attacking strategy from an adversarial point of view and develop a trajectory tracking and recovering attack based on matrix completion (TTRA). By randomly sampling locations of vehicles, TTRA is capable of recovering locations of any user with tolerable deviation. After that, the problem of how to minimize the number of RSUs while tracking all vehicles in the whole region is also considered by converting this problem into set covering problem. A heuristic algorithm based on hierarchical clustering is proposed accordingly. To the best of our knowledge, this is the first attempt of recovering mobile users' trajectories by applying these novel techniques. Finally, simulation analysis is used to show the performance of the proposed scheme. Simulation results demonstrate the merits of the scheme in terms of tracking results, location error, and influences of sampling ratio, among others. © 2018 John Wiley & Sons, Ltd.","matrix completion; RSU deployment optimization; trajectory recovering attack; VANETs","Clustering algorithms; Computer system recovery; Heuristic algorithms; Location; Mobile telecommunication systems; Network security; Recovery; Trajectories; Deployment optimization; Hier-archical clustering; Matrix completion; Set covering problem; Simulation analysis; Trajectory tracking; VANETs; Vehicular Adhoc Networks (VANETs); Vehicular ad hoc networks",,,,,"Shakshuki, E.M., Kang, N., Sheltami, T.R., A secure intrusion-detection system for MANETs (2013) IEEE Trans Ind Electron, 60 (3), pp. 1089-1098; Zeadally, S., Hunt, R., Chen, Y.S., Irwin, A., Hassan, A., Vehicular ad hoc networks (VANETS): status, results, and challenges (2012) Telecommun Syst, 50 (4), pp. 217-241; Lu, R., Li, X., Luan, T.H., Liang, X., Shen, X., Pseudonym changing at social spots: an effective strategy for location privacy in VANETs (2012) IEEE Trans Veh Technol, 61 (1), pp. 86-96; Kenney, J.B., Dedicated short-range communications (DSRC) standards in the United States (2011) Proc IEEE, 99 (7), pp. 1162-1182; Gillani, S., Shahzad, F., Qayyum, A., Mehmood, R., A survey on security in vehicular ad hoc networks (2013) Communication Technologies for Vehicles, pp. 59-74. , Berlin Heidelberg, Springer; Chen, Y., Krumm, J., (2010) Probabilistic modeling of traffic lanes from GPS traces, pp. 81-88. , In Proceedings of the 18th SIGSPATIAL International Conference on Advances in Geographic Information Systems ACM;, San Jose, CA, USA; Dawson, J.Q., Munzner, T., McGrenere, J., A search-set model of path tracing in graphs (2015) Inf Vis, 14 (4), pp. 308-338; Alasmary, W., Valaee, S., (2013) Compressive sensing based vehicle information recovery in vehicular networks, pp. 700-705. , In 2013 9th International Wireless Communications and Mobile Computing Conference (IWCMC);, Sardinia, Italy; Wang, H., Zhu, Y., Zhang, Q., (2013) Compressive sensing based monitoring with vehicular networks, pp. 2823-2831. , In IEEE INFOCOM 2013;, Turin, Italy; Yan, T., Wang, G., (2012) Roadside infrastructure planning for vehicle trajectory collection, pp. 1-5. , In 2012 35th IEEE Sarnoff Symposium (SARNOFF);, Newark, NJ; Altman, R.M., Mixed hidden Markov models (2012) J Am Stat Assoc, 102 (477), pp. 201-210; Radenen, M., Artieres, T., Contextual hidden Markov models (2008) IEEE Int Conf Acoust Speech Signal Process, 22 (10), pp. 2113-2116; Fink, G.A., Hidden Markov models (2014) Markov Models for Pattern Recognition: From Theory to Applications, pp. 71-106. , London, Springer; Stützle, T., López-Ibánez, M., Pellegrini, P., Parameter adaptation in ant colony optimization (2012) Autonomous Search, pp. 191-215. , Berlin Heidelberg, Springer; Pedemonte, M., Nesmachnow, S., Cancela, H., A survey on parallel ant colony optimization (2011) Appl Soft Comput, 11 (8), pp. 5181-5197; Raya, M., Hubaux, J.P., A survey: ant colony optimization based recent research and implementation on several engineering domain (2012) Expert Syst Appl, 39 (4), pp. 4618-4627; Suh, C., Goela, N., Gastpar, M., (2012) Computation in multicast networks: Function alignment and converse theorems, pp. 1-12. , Allerton Conference;; Niu, B., Zhao, H.V., Jiang, H., A cooperation stimulation strategy in wireless multicast networks (2011) IEEE Trans Signal Process, 59, pp. 2355-2369; Feizi, S., Lucani, D.E., Sorensen, C.W., (2014) Tunable sparse network coding for multicast networks, pp. 1-6. , In IEEE 2014 International Symposium on Network Coding (NETCOD);, Aalborg, Denmark; Guette, G., Ducourthial, B., (2007) On the Sybil attack detection in VANET, pp. 1-6. , In IEEE Internatonal Conference on Mobile Adhoc and Sensor Systems, MASS 2007;, Pisa, Italy; Chen, C., Wang, X., Han, W., Zang, B., (2009) A robust detection of the Sybil attack in urban VANETs, pp. 270-276. , In 29th IEEE International Conference on Distributed Computing Systems Workshops;, Montreal, Canada; Biswas, S., Mi'sic, J., Mi'sic, V., (2012) DDoS attack on WAVE-enabled VANET through synchronization, pp. 1079-1084. , In IEEE Global Communications Conference (GLOBECOM);, Anaheim, CA; Pathre, A., Identification of malicious vehicle in VANET environment from DDoS attack (2013) J Glob Res Compu Sci, 4 (6), pp. 30-34; Chi, L., Wu, G., Xia, F., Yao, L., Enhancing efficiency of node compromise attacks in vehicular ad-hoc networks using connected dominating set (2013) IEEE Trans Wirel Commun, 18 (6), pp. 908-922; Kjargaard, B., Baun, M., Bhattacharya, S., Blunck, H., Nurmi, P., (2011) Energy-efficient trajectory tracking for mobile devices, pp. 307-320. , In Proceedings of the 9th International Conference on Mobile Systems, ApplicationsServices;, Bethesda, MD; Lin, C., Liu, K., Xu, B., Deng, J., Yu, C.W., Wu, G., VCLT: an accurate trajectory tracking attack based on crowdsourcing in VANETs (2015) Algorithms and Architectures for Parallel Processing (ICA3PP 2015), pp. 297-310. , Switzerland, Springer; Chi, L., Yanhong, Z., Houbing, S., Chang, W.Y., Guowei, W., OPPC: An optimal path planning charging scheme based on schedulability evaluation for WRSNs (2017) ACM Trans Embedded Comput Syst, 17 (1), pp. 1-25; Chi, L., Ding, H., Jing, D., Guowei, W., P2S: A primary and passer-by scheduling algorithm for on-demand charging architecture in wireless rechargeable sensor networks (2017) IEEE Trans Veh Technol, 66 (9), pp. 8047-8058; Chi, L., Jingzhe, Z., Chunyang, G., Houbing, S., Guowei, W., Mohammad, S.O., TSCA: A temporal-spatial real-time charging scheduling algorithm for on-demand architecture in wireless rechargeable sensor networks (2018) IEEE Trans Mob Comput, 17 (1), pp. 211-224; Chi, L., Guowei, W., Mohammad, S.O., Chang, W.Y., Clustering and splitting charging algorithms for large scaled wireless rechargeable sensor networks (2016) J Syst Software, 113, pp. 381-394; Kovvali, G.V., Alexiadis, V., Zhang, E.P., (2007) Video-based vehicle trajectory data collection, pp. 307-320. , In Transportation Research Board 86th Annual Meeting, ACM;, Washington, DC; Punzo, V., Borzacchiello, T.M., Ciuffo, B., On the assessment of vehicle trajectory data accuracy and application to the next generation simulation (NGSIM) program data (2011) Transp Res C Emerg Technol, 19 (6), pp. 1243-1262; Toledo, T., Koutsopoulos, H., Ahmed, K., (2007) Estimation of vehicle trajectories with locally weighted regression, pp. 161-169. , Transportation Research Record Journal of the Transportation Research Board, 1999, Transportation Research Board of the National Academies, Washington, D.C; Xin, W., Hourdos, J., Michalopoulos, P.G., (2008), Vehicle trajectory collection and processing methodology and its implementation. 08-2173;; Punzo, V., Borzacchiello, M.T., Ciuffo, B., (2009) Estimation of vehicle trajectories from observed discrete positions and next-generation simulation program (NGSIM) data, pp. 1-17. , In TRB 2009 Annual Meeting;; Ospina, E.C., Moreno, F.J., Guzmán, J.A., (2015) Trajectory reconstruction using personalized routing over a graph, 1648, p. 850072. , In Proceedings of the International Conference on Numerical Analysis and Applied Mathematics 2014 (ICNAAM-2014),, Rhodes, Greece, AIP Publishing; Morris, B.T., Tran, C., Scora, G., Trivedi, M.M., Barth, M.J., Real-time video-based traffic measurement and visualization system for energy/emissions (2012) IEEE Trans Intell Transp Syst, 13, pp. 1667-1678; Ji, H., Liu, C., Shen, Z., Xu, Y., (2010) Robust video denoising using low rank matrix completion, pp. 1791-1798. , In IEEE Computer Society Conference on Computer Vision and Pattern Recognition, CVPR;, San Francisco, CA; Cao, F., Cai, M., Tan, Y., Image interpolation via low-rank matrix completion and recovery (2015) IEEE Trans Circuits Syst Video Technol, 25, pp. 1261-1270; Cai, J.-F., Candès, E.J., Shen, Z., A singular value thresholding algorithm for matrix completion (2010) SIAM J Optim, 20, pp. 1956-1982; Poli, A.A., Cirillo, M.C., On the use of the normalized mean square error in evaluating dispersion model performance (1993) Atmos Environ A Gen Top, 27, pp. 2427-2434; Mirkin, B., (2005) Clustering for Data Mining: A Data Recovery Approach, , Chapman & Hall/CRC; http://sumo.sourceforge.net/, Accessed date: 2015-04-22; , pp. 2015-2104. , http://www.openstreetmap.org/, Accessed date","Wang, K.; School of Software, China; email: wangkunmuwewen007@gmail.com",,,"John Wiley and Sons Ltd",,,,,10745351,,IJCYE,,"English","Int J Commun Syst",Article,"Final","",Scopus,2-s2.0-85053242694
"Anwar F.M., Alanwar A., Srivastava M.B.","35184934500;57094966300;35599699800;","OpenClock: A Testbed for Clock Synchronization Research",2018,"IEEE International Symposium on Precision Clock Synchronization for Measurement, Control, and Communication, ISPCS","2018-September",,"8543080","","",,2,"10.1109/ISPCS.2018.8543080","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059761347&doi=10.1109%2fISPCS.2018.8543080&partnerID=40&md5=d51e4940eef5bf7fec4bd3eba5104440","University of California, Los Angeles, CA, United States","Anwar, F.M., University of California, Los Angeles, CA, United States; Alanwar, A., University of California, Los Angeles, CA, United States; Srivastava, M.B., University of California, Los Angeles, CA, United States","Clock synchronization protocols have always been tested and compared in controlled environments. The hardware variability of different platforms, and network variability in communication channels is often ignored. Most of the synchronization algorithms are not tested for faults, failures or adversarial attacks because it is hard to reproduce them on different devices. The presence of few clocks on a single device limits the use of one device to test multiple synchronization protocols at once. For fair comparison of multiple synchronization protocols, we assert that it is essential for their disciplinable clocks to be derived from the same clock hardware, and that they process the same network traffic. We propose OpenClock, a clock synchronization testbed that manages synchronization resources and provides multiple disciplinable clocks on a single platform. OpenClock features a rich set of clocks for modular and extensible design, and an attack simulator for testing algorithmic resilience. Users can leverage the attack capability to find vulnerabilities, and test the resilience of synchronization algorithms. We prototype OpenClock on an embedded platform and ×86 desktop. We evaluate variants of PTP and NTP protocols on the embedded platform under various clock parameters, disciplining mechanisms, and attack scenarios. © 2018 IEEE.",,"Hardware; Mechanical clocks; Testbeds; Attack capability; Attack scenarios; Clock parameters; Clock Synchronization; Controlled environment; Embedded platforms; Synchronization algorithm; Synchronization protocols; Synchronization",,,,,"Alanwar, A., Anwar, F.M., Zhang, Y.-F., Pearson, J., Hespanha, J., Srivastava, M.B., Cyclops: Pru programming framework for precise timing applications (2017) Precision Clock Synchronization for Measurement, Control, and Communication (ISPCS), 2017 IEEE International Symposium On. IEEE, pp. 1-6; Anwar, F.M., Srivastava, M.B., Precision time protocol over lr-wpan and 6lowpan (2017) Precision Clock Synchronization for Measurement, Control, and Communication (ISPCS), 2017 IEEE International Symposium On. IEEE, pp. 1-6; Anwar, F., D'Souza, S., Symington, A., Dongare, A., Rajkumar, R., Rowe, A., Srivastava, M., Timeline: An operating system abstraction for timeaware applications (2016) Real-Time Systems Symposium (RTSS), 2016 IEEE. IEEE, pp. 191-202; Cho, K.-T., Shin, K.G., Fingerprinting electronic control units for vehicle intrusion detection (2016) USENIX Security Symposium, pp. 911-927; Mills, D.L., Internet time synchronization: The network time protocol (1991) Communications, IEEE Transactions on, 39 (10); Lee, K., Eidson, J.C., Weibel, H., Mohl, D., Ieee 1588-standard for a precision clock synchronization protocol for networked measurement and control systems (2005) Conference on IEEE, 1588, p. 2; Cochran, R., Marinescu, C., Design and implementation of a ptp clock infrastructure for the linux kernel (2010) Precision Clock Synchronization for Measurement Control and Communication (ISPCS), 2010 International IEEE Symposium On. IEEE, pp. 116-121; Maroti, M., Kusy, B., Simon, G., Ledeczi, A., The flooding time synchronization protocol (2004) SenSys, Proceedings of the 2nd International Conference on Embedded Networked Sensor Systems; Marzullo, K., Owicki, S., Maintaining the time in a distributed system (1985) ACM SIGOPS Operating Systems Review, 19 (3), pp. 44-54",,,"IEEE;IEEE Instrumentation and Measurement Society","IEEE Computer Society","12th International IEEE Symposium on Precision Clock Synchronization for Measurement, Control, and Communication, ISPCS 2018","30 September 2018 through 5 October 2018",,142933,19490305,9781538642627,,,"English","IEEE Int. Symp. PreciS. Clock Synchronization Meas. Control Commun. ISPCS",Conference Paper,"Final","",Scopus,2-s2.0-85059761347
"Buchler N., La Fleur C.G., Hoffman B., Rajivan P., Marusich L., Lightner L.","24281028900;56026877700;15060115400;55220183600;26326440700;57216130609;","Cyber teaming and role specialization in a cyber security defense competition",2018,"Frontiers in Psychology","9","NOV","2133","","",,9,"10.3389/fpsyg.2018.02133","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056787566&doi=10.3389%2ffpsyg.2018.02133&partnerID=40&md5=b9fa066674cd07cb8aa37891e1997a7c","U.S. Army Research Laboratory, Adelphi, MD, United States; Industrial and Systems Engineering, University of Washington, Seattle, WA, United States; National CyberWatch Center, Largo, MD, United States","Buchler, N., U.S. Army Research Laboratory, Adelphi, MD, United States; La Fleur, C.G., U.S. Army Research Laboratory, Adelphi, MD, United States; Hoffman, B., U.S. Army Research Laboratory, Adelphi, MD, United States; Rajivan, P., Industrial and Systems Engineering, University of Washington, Seattle, WA, United States; Marusich, L., U.S. Army Research Laboratory, Adelphi, MD, United States; Lightner, L., National CyberWatch Center, Largo, MD, United States","A critical requirement for developing a cyber capable workforce is to understand how to challenge, assess, and rapidly develop human cyber skill-sets in realistic cyber operational environments. Fortunately, cyber team competitions make use of simulated operational environments with scoring criteria of task performance that objectively define overall team effectiveness, thus providing the means and context for observation and analysis of cyber teaming. Such competitions allow researchers to address the key determinants that make a cyber defense team more or less effective in responding to and mitigating cyber attacks. For this purpose, we analyzed data collected at the 12th annual Mid-Atlantic Collegiate Cyber Defense Competition (MACCDC, http://www.maccdc.org/), where eight teams were evaluated along four independent scoring dimensions: maintaining services, incident response, scenario injects, and thwarting adversarial activities. Data collected from the 13-point OAT (Observational Assessment of Teamwork) instrument by embedded observers and a cyber teamwork survey completed by all participants were used to assess teamwork and leadership behaviors and team composition and work processes, respectively. The scores from the competition were used as an outcome measure in our analysis to extract key features of team process, structure, leadership, and skill-sets in relation to effective cyber defense. We used Bayesian regression to relate scored performance during the competition to team skill composition, team experience level, and an observational construct of team collaboration. Our results indicate that effective collaboration, experience, and functional role-specialization within the teams are important factors that determine the success of these teams in the competition and are important observational predictors of the timely detection and effective mitigation of ongoing cyber attacks. These results support theories of team maturation and the development of functional team cognition applied to mastering cybersecurity. © 2018 Buchler, La Fleur, Hoffman, Rajivan, Marusich, Lightner.","Collaboration; Computer personnel selection; Cyber defense; Cybersecurity; Expertise; Skill composition; Team development; Teamwork",,,,,,"Beal, D.J., Cohen, R.R., Burke, M.J., McLendon, C.L., Cohesion and performance in groups: a meta-analytic clarification of construct relations (2003) J. Appl. Psychol, 88, pp. 989-1004; Besnard, D., Arief, B., Computer security impaired by legitimate users (2004) Comput. Secur, 23, pp. 253-264; Bishop, M., Conboy, H.M., Phan, H., Simidchieva, B.I., Avrunin, G.S., Clarke, L.A., 'Insider threat identification by process analysis,' (2014) SPW '14 Proceedings of the 2014 IEEE Security and Privacy Workshops, pp. 251-264. , Washington, DC; Buchler, N., Fitzhugh, S.M., Marusich, L.R., Ungvarsky, D.M., Lebiere, C., Gonzalez, C., Mission command in the age of network-enabled operations: social network analysis of information sharing and situation awareness (2016) Front. Pscyhol, 7, p. 937; Buchler, N., Hoffman, B., Collman, S., Marvel, L.M., Cuneo, J., Hoye, J., (2016) Measuring Team Effectiveness in Cyber-Defense Exercises: Multi-scale, multi-level Data Aggregation and Analysis, , U.S. Army Research Laboratory-Technical Report; Buchler, N., Rajivan, P., Marusich, L.R., Lightner, L., Gonzalez, C., Sociometrics and observational assessment of teaming and leadership in a cyber security defense competition (2018) J. Comput. Secur, 73, pp. 114-136; Burke, C.S., Stagl, K.C., Klein, C., Goodwin, G.F., Salas, E., Halpin, S.M., What type of leadership behaviors are functional in teams? (2006) A meta-analysis. Leadersh. Q, 17, pp. 288-307; Cannon-Bowers, J.A., Salas, E., Reflections on shared cognition (2001) J. Organ. Behav, 22, pp. 195-202; Cannon-Bowers, J.A., Salas, E., Converse, S.A., 'Shared mental models in expert team decision making,' (1993) Current Issues in Individual and Group Decision Making, pp. 221-246. , in ed N. J. Castellan, Jr. Hillsdale, NJ: Erlbaum; Chapman, P., Burket, J., Brumley, D., ""PicoCTF: a game-based computer security competition for high school students,"" (2014) USE-NIX Summit on Gaming, Games, Gamification in Security Education (3GSE 14); Cooke, N.J., Gorman, J.C., Myers, C.W., Duran, J.L., Interactive team cognition (2013) Cogn. Sci, 37, pp. 255-285; Costa, D.L., Albethsen, M.J., Collins, M.L., Perl, S.J., Silowash, G.J., Spooner, D.L., (2016) An Insider Threat Indicator Ontology, , https://resources.sei.cmu.edu/asset_files/TechnicalReport/2016_005_001_454627.pdf; D'Amico, A., Whitley, K., 'The real work of computer network defense analysts,' (2008) Mathematics and Visualization, VizSEC 2007, , eds J. R. Goodall, G. Conti, and K. L. Ma (Berlin; Heidelberg: Springer); D'Amico, A., Whitley, K., Tesone, D., OBrien, B., Roth, E., Achieving cyber defense situational awareness: a cognitive task analysis of information assurance analysts (2005) Proc. Hum. Factors Ergon. Soc. Annu. Meet, 49, pp. 229-233; (2016) DEFCON CTF Archive, , https://defcon.org/html/links/dc-ctf.html; Dekker, A.H., (2011) Analyzing C2 Structures and Self-synchronization with Simple Computational Models, , Defense Science and Technology Organisation (Australia) Joint Operations Division; Dodge, R.C., Carver, C., Ferguson, A.J., Phishing for user security awareness (2007) Comput. Secur, 26, pp. 73-80; Dunlap, C., Jr., (1998) ""Joint Vision 2010, A Red Team Assessment, , Washington, DC: National Defense University; Fulford, H., Doherty, N.F., The application of information security policies in large UK-based organizations: an exploratory investigation (2003) Inform. Manag. Comput. Secur, 11, pp. 106-114; Gersick, C.J.G., Davis-Sacks, M.L., 'Summary: task forces,' (1990) Groups that Work, pp. 146-154. , and Those That Don't): Creating Conditions for Effective Teamwork, ed J. R. Hackman (San Francisco, CA: Jossey-Bass; Gist, M.E., Locke, E.A., Taylor, M.S., Organizational behavior: Group structure, process, and effectiveness (1987) J. Manage, 13, pp. 237-257; Granasen, M., Andersson, D., Measuring team effectiveness in cyber-defense exercises: a cross-disciplinary case study (2016) J. Cogn. Technology, and Work, 18, pp. 121-143; Hackman, J.R., Hackman, R.J., (2002) Leading Teams: Setting the Stage for Great Performances, , Boston, MA: Harvard Business Press; Hackman, J.R., Katz, N., (2010) Group Behavior and Performance, , New York, NY: Wiley; Hackman, J.R., Morris, C.G., 'Group tasks, group interaction process, and group performance effectiveness: a review and proposed integration,' (1975) Advances in Experimental Social Psychology, 8, pp. 45-99. , ed L. Berkowitz, New York, NY: Academic Press; Henshel, D., Deckard, G., Lufkin, B., Buchler, N., Hoffman, B., Marvel, L., 'Predicting proficiency in a cyber defense team exercise,' (2016) MILCOM (Baltimore, , MD); Hoffman, L.J., Rosenberg, T., Dodge, R., Ragsdale, D., Exploring a national cybersecurity exercise for universities (2005) IEEE Secur. Privacy, 3, pp. 27-33; Hutchins, S.G., Kleinman, D.L., Hocevar, S.P., Kemple, W.G., Porter, G.R., (2001) Enables of Self-synchronization for Network-Centric Operations: Design of a Complex Command and Control Experiment, , Monterey, CA: Naval Postgraduate School; Jariwala, S., Champion, M., Rajivan, P., Cooke, N.J., 'Influence of team communication and coordination on the performance of teams at the iCTF competition,' (2012) Proceedings of the Human Factors and Ergonomics Society Annual Meeting, 56, pp. 458-462. , Santa Monica, CA: SAGE Publications; Kabanoff, B., O'Brien, G.E., The effects of task type and cooperation upon group products and performance (1979) Organ. Behav. Hum. Decis. Process, 23, pp. 163-181; Klimburg, A., (2012) National Cyber Security Framework Manual, , North Atlantic Treaty Organization Cooperative Cyber Defence Centre of Excellence (NATO CCD COE) Publications; Kozlowski, S.W., Bell, B.S., 'Work groups and teams in organizations,' (2003) Handbook of Psychology: Industrial and Organizational Psychology, 12, pp. 333-375. , eds W. C. Borman, D. R. Ilgen, and R. J. Klimoski (New York, NY: Wiley); Kruschke, J.K., Bayesian assessment of null values via parameter estimation and model comparison (2011) Perspect. Psychol. Sci, 6, pp. 299-312; Kruschke, J.K., (2015) Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan, , Waltham, MA: Academic Press, 2nd Edn; Kutner, M.H., Nachtsheim, C.J., Neter, J., (2004) Applied Linear Regression Models, , New York, NY: McGraw-Hill Irwin, 4th Edn; Malviya, A., Fink, G.A., Sego, L., Endicott-Popovsky, B., 'Situational awareness as a measure of performance in cyber security collaborative work,' (2011) Eighth International Conference on Information Technology: New Generations, pp. 937-942. , ITNG) (Las Vegas, NV: IEEE; Mauer, B., Stackpole, W., Johnson, D., ""Developing small team-based cyber security exercises,"" (2012) Proceedings of the International Conference on Security and Management (SAM), , http://scholarworks.rit.edu/other/301; McGrath, J.E., (1984) Groups, Interaction and Performance, , Englewood Cliffs, NJ: Prentice-Hall; Mirkovic, J., Reiher, P., Papadopoulous, C., Hussain, A., Shephard, M., Berg, M., Testing a collaborative DDoS defense in a red team/blue team exercise (2008) IEEE Trans. Comput, 57, pp. 1098-1112; Monge, P.R., Contractor, N.S., 'Emergence of communication networks,' (2001) The New Handbook of Organizational Communication: Advances in Theory, Research, and Methods, pp. 440-502. , London: Sage Publishing; (2017) White paper: Cybersecurity Games-Building Tomorrow's Workforce, , NIST; Ogee, A., Gavrila, R., Trimintzios, P., Stavropoulos, V., Zacharis, A., (2015) The 2015 Report on National International Cyber Security Exercises: Survey, Analysis Recommendations, , https://www.enisa.europa.eu/activities/Resilience-and-CIIP/cyber-crisis-cooperation/cce/cyber-exercises/latest-report-on-national-and-international-cyber-security-exercises, (Accessed October 17, 2016); Plummer, M., (2016) Rjags: Baysian Graphical Models using MCMC, , https://CRAN.R-project.org/package=rjags, R version 3.3.0; Rajendran, J., Jyothi, V., Karri, R., 'Blue team-red team approach to hardware trust assessment,' (2011) Proceedings of the 2011 IEEE 29th International Conference on Computer Design, pp. 285-288. , ICCD) (Amherst, MA; Rajivan, P., (2014) Information Pooling Bias in Collaborative Cyber Forensics, , Doctoral dissertation, Arizona State University; Rajivan, P., Champion, M., Cooke, N.J., Jariwala, S., Dube, G., Buchanan, V., 'Effects of teamwork versus group work on signal detection in cyber defense teams,' (2013) International Conference on Augmented Cognition, pp. 172-180. , Berlin; Heidelberg: Springer; Rajivan, P., Cooke, N.J., 'Impact of team collaboration on cybersecurity situation awareness,' (2017) Theory and Models for Cyber Situation Awareness, pp. 203-226. , Cham: Springer; Rasmussen, J., Brehmer, B., Leplat, J., ""Distributed decision making,"" (1991) Cognitive Models for Cooperative Work, p. 397. , Chichester, UK: John Wiley and Sons; Reason, J., (2017) The Human Contribution: Unsafe Acts, Accidents, and Heroic Recoveries, , London: CRC Press; (2016) SANS Netwars, , https://www.sans.org/netwars; Sharma, S., Sefchek, J., Teaching information systems security courses: a hands-on approach (2007) Comput. Secur, 26, pp. 290-299; Stevens-Adams, S., Carbajal, A., Silva, A., Nauer, K., Anderson, B., Reed, T., 'Enhanced training for cyber situational awareness,' (2013) Foundations of Augmented Cognition, pp. 90-99. , eds T. Ahram, W. Karwowski, and D. Schmorrow (Berlin; Heidelberg: Springer); Stewart, G.L., Barrick, M.R., Team structure and performance: assessing the mediating role of intrateam process and the moderating role of task type (2000) Acad. Manage, J, 43, pp. 135-148; Terreberry, S., The evolution of organizational environments (1968) Admin. Sci. Q, 12, pp. 590-613; Tuckman, B.W., Developmental sequence in small groups (1965) Psychol. Bull, 63, pp. 384-399; (2017) Data Breach Investigations Report, , http://www.verizonenterprise.com/verizon-insights-lab/dbir/, Accessed November 16, 2017; Weed, S.E., Mitchell, T.R., Moffitt, W., Leadership style, subordinate personality, and task type as predictors of performance and satisfaction with supervision (1976) J. Appl. Psychol, 61, pp. 58-66; Wegner, D.M., ""Transactive memory: a contemporary analysis of the group mind,"" (1987) Theories of Group Behavior: Springer Series in Social Psychology, pp. 185-208. , eds B. Mullen and G. R. Goethals (New York, NY: Springer); Werlinger, R., Hawkey, K., Botta, D., Beznosov, K., Security practitioners in context: Their activities and interactions with other stakeholders within organizations (2009) Int. J. Hum. Comput. Stud, 67, pp. 584-606; White, G.B., Williams, D., 'The collegiate cyber defense competition,' (2005) Proceedings of the 9th Colloquium for Information Systems Security Education (Atlanta, , GA)","Buchler, N.; U.S. Army Research LaboratoryUnited States; email: norbou.buchler.civ@mail.mil",,,"Frontiers Media S.A.",,,,,16641078,,,,"English","Front. Psychol.",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85056787566
"Guan Z., Bian L., Shang T., Liu J.","57191897502;57205204328;55697179700;55682417200;","When Machine Learning meets Security Issues: A survey",2018,"2018 International Conference on Intelligence and Safety for Robotics, ISR 2018",,,"8535799","158","165",,11,"10.1109/IISR.2018.8535799","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059102650&doi=10.1109%2fIISR.2018.8535799&partnerID=40&md5=f9c2285b7440d31cf8c51468f5020e06","School of Cyber Science and Technology, Beihang University, Beijing, China","Guan, Z., School of Cyber Science and Technology, Beihang University, Beijing, China; Bian, L., School of Cyber Science and Technology, Beihang University, Beijing, China; Shang, T., School of Cyber Science and Technology, Beihang University, Beijing, China; Liu, J., School of Cyber Science and Technology, Beihang University, Beijing, China","Machine learning is one of the most prevalent techniques in recent decades which has been widely applied in various fields. Among them, the applications that detect and defend potential adversarial attacks using machine learning method provide promising solutions in cybersecurity. At the same time, machine learning algorithms and systems are vulnerable to multiple security threats. In this paper, we revisit certain literatures and present a comprehensive survey from two respects, application of machine learning on cybersecurity and reliability and security of machine learning system. We then overview security issues of mobile AI devices and propose two notable focus, which are worthy in-depth studies in future. Researchers can regard this survey as a navigating reference in both machine learning and cybersecurity fields. © 2018 IEEE.","Cybersecurity; Defense; Machine learning; Threats","Artificial intelligence; Learning systems; Robotics; Surveys; Cyber security; Defense; In-depth study; Machine learning methods; Multiple securities; Security issues; Threats; Learning algorithms",,,,,"Devesa, J., Santos, I., Cantero, X., Penya, Y.K., Bringas, P.G., Automatic behaviour-based analysis and classification system for malware detection (2010) ICEIS (2), 2, pp. 395-399; Tahan, G., Rokach, L., Shahar, Y., Mal-id: Automatic malware detection using common segment analysis and meta-features (2012) Journal of Machine Learning Research, 13, pp. 949-979. , Apr; Sahoo, D., Liu, C., Hoi, S.C., (2017) Malicious URL Detection Using Machine Learning: A Survey, , arXiv preprint arXiv:1701. 07179; Zhou, Y., Inge, W.M., Malware detection using adaptive data compression (2008) Proceedings of the 1st ACM Workshop on Workshop on AISec, pp. 53-60. , ACM; Yakura, H., Shinozaki, S., Nishimura, R., Oyama, Y., Sakuma, J., Malware analysis of imaged binary samples by convolutional neural network with attention mechanism (2018) Proceedings of the Eighth ACM Conference on Data and Application Security and Privacy, pp. 127-134. , ACM; Raff, E., Nicholas, C., Malware classification and class imbalance via stochastic hashed LZJD (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 111-120. , ACM; Das, S., Nene, M.J., A survey on types of machine learning techniques in intrusion prevention systems (2017) Wireless Communications, Signal Processing and Networking (WiSPNET), 2017 International Conference on, pp. 2296-2299. , IEEE; Buczak, A.L., Guven, E., A survey of data mining and machine learning methods for cyber security intrusion detection (2016) IEEE Communications Surveys &Tutorials, 18 (2), pp. 1153-1176; Mishra, A., Gupta, B., Hybrid solution to detect and filter zero-day phishing attacks (2014) Proceedings of the Second International Conference on Emerging Research in Computing, Information, Communication and Applications, pp. 373-379; Gupta, B., Arachchilage, N.A., Psannis, K.E., Defending against phishing attacks: Taxonomy of methods, current issues and future directions (2018) Telecommunication Systems, 67 (2), pp. 247-267; Almomani, A., Gupta, B., Atawneh, S., Meulenberg, A., Almomani, E., A survey of phishing email filtering techniques (2013) IEEE Communications Surveys &Tutorials, 15 (4), pp. 2070-2090; Zuhair, H., Selamat, A., Phishing classification models: Issues and perspectives (2017) Open Systems (ICOS), 2017 IEEE Conference on, pp. 26-31. , IEEE; Siddiqui, S., Khan, M.S., Ferens, K., Kinsner, W., Detecting advanced persistent threats using fractal dimension based machine learning classification (2016) Proceedings of the 2016 ACM on International Workshop on Security and Privacy Analytics, pp. 64-69. , ACM; Ghafir, I., Prenosil, V., Hammoudeh, M., Han, L., Raza, U., Malicious ssl certificate detection: A step towards advanced persistent threat defence (2017) Proceedings of the International Conference on Future Networks and Distributed Systems, p. 27. , ACM; Chandran, S., Hrudya, P., Poornachandran, P., An efficient classification model for detecting advanced persistent threat (2015) Advances in Computing, Communications and Informatics (ICACCI), 2015 International Conference on, pp. 2001-2009. , IEEE; Brogi, G., Tong, V.V.T., Terminaptor: Highlighting advanced persistent threats through information flow tracking (2016) New Technologies, Mobility and Security (NTMS), 2016 8th IFIP International Conference on, pp. 1-5. , IEEE; Wang, X., Zheng, K., Niu, X., Wu, B., Wu, C., Detection of command and control in advanced persistent threat based on independent access (2016) Communications (ICC), 2016 IEEE International Conference on, pp. 1-6. , IEEE; Nychis, G., Sekar, V., Andersen, D.G., Kim, H., Zhang, H., An empirical evaluation of entropy-based traffic anomaly detection (2008) Proceedings of the 8th ACM SIGCOMM Conference on Internet Measurement, pp. 151-156. , ACM; Paredes-Oliva, I., Castell-Uroz, I., Barlet-Ros, P., Dimitropoulos, X., Sole-Pareta, J., Practical anomaly detection based on classifying frequent traffic patterns (2012) Computer Communications Workshops (INFOCOM WKSHPS), 2012 IEEE Conference on, pp. 49-54. , IEEE; Anisheh, S.M., Hassanpour, H., Designing an approach for network traffic anomaly detection (2012) International Journal of Computer Applications, 37 (3); Nguyen, T.T., Armitage, G., A survey of techniques for internet traffic classification using machine learning (2008) IEEE Communications Surveys &Tutorials, 10 (4), pp. 56-76; Paderes, R.E.O., A comparative review of biometric security systems (2015) Bio-Science and Bio-Technology (BSBT), 2015 8th International Conference on, pp. 8-11. , IEEE; Hassan, A.A., Bhram, A.M., Saleh, A.A., Applying a new functional model to improve the security of biometrie systems (2011) Communication Software and Networks (ICCSN), 2011 IEEE 3rd International Conference on, pp. 401-406. , IEEE; Arslan, B., Yorulmaz, E., Akca, B., Sagiroglu, S., Security perspective of biometric recognition and machine learning techniques (2016) Machine Learning and Applications (ICMLA), 2016 15th IEEE International Conference on, pp. 492-497. , IEEE; Arslan, B., Ulker, M., Sagiroglu, S., Machine learning methods used in evaluations of secure biometric system components (2017) Machine Learning and Applications (ICMLA), 2017 16th IEEE International Conference on, pp. 448-453. , IEEE; Bhamare, D., Salman, T., Samaka, M., Erbad, A., Jain, R., Feasibility of supervised machine learning for cloud security (2016) Information Science and Security (ICISS), 2016 International Conference on, pp. 1-5. , IEEE; Nenvani, G., Gupta, H., A survey on attack detection on cloud using supervised learning techniques (2016) Colossal Data Analysis and Networking (CDAN), Symposium on, pp. 1-5. , IEEE; Rocca, G.B., Castillo-Cara, M., Lévano, R.A., Herrera, J.V., Orozco-Barbosa, L., Citizen security using machine learning algorithms through open data (2016) Communications (LATINCOM), 2016 8th IEEE Latin-American Conference on, pp. 1-6. , IEEE; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 3-14. , ACM; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 15-26. , ACM; Muñoz-González, L., Towards poisoning of deep learning algorithms with back-gradient optimization (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 27-38. , ACM; Zantedeschi, V., Nicolae, M.-I., Rawat, A., Efficient defenses against adversarial attacks (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 39-49. , ACM; Halawa, H., Ripeanu, M., Beznosov, K., Coskun, B., Liu, M., An early warning system for suspicious accounts (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 51-52. , ACM; Bittner, D.M., Sarwate, A.D., Wright, R.N., Differentially private noisy search with applications to anomaly detection (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, p. 53. , ACM; Han, S., Generating look-alike names for security challenges (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 57-67. , ACM; Solanki, S., Krishnan, G., Sampath, V., Polakis, J., In (cyber) space bots can hear you speak: Breaking audio captchas using ots speech recognition (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 69-80. , ACM; Kumar, R.S.S., Wicker, A., Swann, M., Practical machine learning for cloud intrusion detection: Challenges and the way forward (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 81-90. , ACM; Liu, C., Li, B., Vorobeychik, Y., Oprea, A., Robust linear regression against training data poisoning (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 91-102. , ACM; Baracaldo, N., Chen, B., Ludwig, H., Safavi, J.A., Mitigating poisoning attacks on machine learning models: A data provenance based approach (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 103-110. , ACM; Raff, E., Sylvester, J., Nicholas, C., Learning the pe header, malware detection with minimal domain knowledge (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 121-132. , ACM; Hammer, H., Kongsgård, K.W., Bai, A., Yazidi, A., Nordbotten, N.A., Engelstad, P.E., Automatic security classification by machine learning for cross-domain information exchange (2015) Military Communications Conference, MILCOM 2015-2015 IEEE, pp. 1590-1595. , IEEE; Newell, A., Potharaju, R., Xiang, L., Nita-Rotaru, C., On the practicality of integrity attacks on document-level sentiment analysis (2014) Proceedings of the 2014 Workshop on Artificial Intelligent and Security Workshop, pp. 83-93. , ACM; Jannach, D., Karakaya, Z., Gedikli, F., Accuracy improvements for multi-criteria recommender systems (2012) Proceedings of the 13th ACM Conference on Electronic Commerce, pp. 674-689. , ACM; Kay, M., Patel, S.N., Kientz, J.A., How Good is 85%?: A survey tool to connect classifier evaluation to acceptability of accuracy (2015) Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems, pp. 347-356. , ACM; Yin, K.S., Khine, M.A., Network behavioral features for detecting remote access trojans in the early stage (2017) Proceedings of the 2017 VI International Conference on Network, Communication and Computing, pp. 92-96. , ACM; Brumen, B., Golob, I., Jaakkola, H., Welzer, T., Rozman, I., Early assessment of classification performance (2004) Proceedings of the Second Workshop on Australasian Information Security, Data Mining and Web Intelligence, and Software Internationalisation, 32, pp. 91-96. , Australian Computer Society, Inc; Corona, I., Giacinto, G., Roli, F., Adversarial attacks against intrusion detection systems: Taxonomy, solutions and open issues (2013) Information Sciences, 239, pp. 201-225; Liu, Q., Li, P., Zhao, W., Cai, W., Yu, S., Leung, V.C., A survey on security threats and defensive techniques of machine learning: A data driven view (2018) IEEE Access, 6, pp. 12103-12117; Biggio, B., Didaci, L., Fumera, G., Roli, F., Poisoning attacks to compromise face templates (2013) Biometrics (ICB), 2013 International Conference on, pp. 1-7. , IEEE; Biggio, B., Fumera, G., Roli, F., Didaci, L., Poisoning adaptive biometric systems (2012) Joint IAPR International Workshops on Statistical Techniques in Pattern Recognition (SPR) and Structural and Syntactic Pattern Recognition (SSPR), pp. 417-425. , Springer; Biggio, B., Fumera, G., Roli, F., Pattern recognition systems under attack: Design issues and research challenges (2014) International Journal of Pattern Recognition and Artificial Intelligence, 28 (7), p. 1460002; Zhu, X., Super-class Discriminant Analysis: A novel solution for heteroscedasticity (2013) Pattern Recognition Letters, 34 (5), pp. 545-551; Kloft, M., Laskov, P., Security analysis of online centroid anomaly detection (2012) Journal of Machine Learning Research, 13, pp. 3681-3724. , Dec; Wittel, G.L., Wu, S.F., On attacking statistical spam filters (2004) CEAS; Nelson, B., Misleading learners: Co-opting your spam filter (2009) Machine Learning in Cyber Trust, pp. 17-51. , Springer; Šrndic, N., Laskov, P., Detection of malicious pdf files based on hierarchical document structure (2013) Proceedings of the 20th Annual Network &Distributed System Security Symposium, pp. 1-16; Itkina, M., Wu, Y., Bahmani, B., Adversarial Attacks on Image Recognition; Maiorca, D., Corona, I., Giacinto, G., Looking at the bag is not enough to find the bomb: An evasion of structural methods for malicious pdf files detection (2013) Proceedings of the 8th ACM SIGSAC Symposium on Information, Computer and Communications Security, pp. 119-130. , ACM; Xu, W., Qi, Y., Evans, D., Automatically evading classifiers (2016) Proceedings of the 2016 Network and Distributed Systems Symposium; Kayacik, H.G., Zincir-Heywood, A.N., Heywood, M.I., Automatically evading IDS using GP authored attacks (2007) Computational Intelligence in Security and Defense Applications, 2007. CISDA 2007. IEEE Symposium on, pp. 153-160. , IEEE; Laskov, P., Practical evasion of a learning-based classifier: A case study (2014) Security and Privacy (SP), 2014 IEEE Symposium on, pp. 197-211. , IEEE; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519. , ACM; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium on, pp. 39-57. , IEEE; Gu, S., Rigazio, L., (2014) Towards Deep Neural Network Architectures Robust to Adversarial Examples, , arXiv preprint arXiv:1412. 5068; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Security and Privacy (SP), 2016 IEEE Symposium on, pp. 582-597. , IEEE; Carlini, N., Wagner, D., (2016) Defensive Distillation is Not Robust to Adversarial Examples, , arXiv preprint arXiv:1607. 04311; Shokri, R., Stronati, M., Song, C., Shmatikov, V., Membership inference attacks against machine learning models (2017) Security and Privacy (SP), 2017 IEEE Symposium on, pp. 3-18. , IEEE; Wu, X., Fredrikson, M., Jha, S., Naughton, J.F., A methodology for formalizing model-inversion attacks (2016) Computer Security Foundations Symposium (CSF), 2016 IEEE 29th, pp. 355-370. , IEEE; Pastro, I.D.V., Smart, N., Zakarias, S., Multiparty computation from somewhat homomorphic encryption (2012) Advances in Cryptology-Crypto; Varma, P.R.K., Raj, K.P., Raju, K.S., Android mobile security by detecting and classification of malware based on permissions using machine learning algorithms (2017) I-SMAC (IoT in Social, Mobile, Analytics and Cloud)(I-SMAC), 2017 International Conference on, pp. 294-299. , IEEE; Qiao, M., Sung, A.H., Liu, Q., Merging permission and API features for Android malware detection (2016) Advanced Applied Informatics (IIAI-AAI), 2016 5th IIAI International Congress on, pp. 566-571. , IEEE; Spreitzer, R., Moonsamy, V., Korak, T., Mangard, S., Systematic classification of side-channel attacks: A case study for mobile devices (2017) IEEE Communications Surveys &Tutorials; Artem, K., Vasyl, T., Structure and model of the smart house security system using machine learning methods (2017) Advanced Information and Communication Technologies (AICT), 2017 2nd International Conference on, pp. 105-108. , IEEE; Ali, W., Dustgeer, G., Awais, M., Shah, M.A., IoT based smart home: Security challenges, security requirements and solutions (2017) Automation and Computing (ICAC), 2017 23rd International Conference on, pp. 1-6. , IEEE; Blasco, J., Chen, T.M., Tapiador, J., Peris-Lopez, P., A survey of wearable biometric recognition systems (2016) ACM Computing Surveys (CSUR), 49 (3), p. 43; Al-Khateeb, H., Epiphaniou, G., Reviczky, A., Karadimas, P., Heidari, H., Proactive threat detection for connected cars using recursive Bayesian estimation (2017) IEEE Sensors Journal",,,,"Institute of Electrical and Electronics Engineers Inc.","2018 International Conference on Intelligence and Safety for Robotics, ISR 2018","24 August 2018 through 27 August 2018",,142623,,9781538655467,,,"English","Int. Conf. Intell. Saf. Robot., ISR",Conference Paper,"Final","",Scopus,2-s2.0-85059102650
"Czaja W., Fendley N., Pekala M., Ratto C., Wang I.-J.","6603938615;57205118791;7005118704;34969473500;7101648347;","Adversarial examples in remote sensing",2018,"GIS: Proceedings of the ACM International Symposium on Advances in Geographic Information Systems",,,,"408","411",,12,"10.1145/3274895.3274904","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058649828&doi=10.1145%2f3274895.3274904&partnerID=40&md5=d9f97a5d4802cfa17ac3e8da1c052b9c","University of Maryland, Department of Mathematics, College Park, MD, United States; Johns Hopkins University, Applied Physics Laboratory, Laurel, MD, United States","Czaja, W., University of Maryland, Department of Mathematics, College Park, MD, United States; Fendley, N., Johns Hopkins University, Applied Physics Laboratory, Laurel, MD, United States; Pekala, M., Johns Hopkins University, Applied Physics Laboratory, Laurel, MD, United States; Ratto, C., Johns Hopkins University, Applied Physics Laboratory, Laurel, MD, United States; Wang, I.-J., Johns Hopkins University, Applied Physics Laboratory, Laurel, MD, United States","This paper considers attacks against machine learning algorithms used in remote sensing applications. The remote sensing domain presents a suite of challenges that are not fully addressed by current research focused on natural image data. In this paper we present a new study of adversarial examples in the context of satellite image classification problems. Using a recently curated data set and associated classifier, we provide a preliminary analysis of adversarial examples in settings where the targeted classifier is permitted multiple observations of the same location over time. While our experiments to date are purely digital, our problem setup incorporates a number of practical considerations that an attacker would need to take into account when mounting physical attacks. © 2018 held by the owner/author(s).","Adversarial examples; Classification; Deep neural networks; Machine learning; Remote sensing","Artificial intelligence; Classification (of information); Deep neural networks; Geographic information systems; Information systems; Information use; Learning algorithms; Learning systems; Adversarial examples; Data set; Natural images; New study; Physical attacks; Preliminary analysis; Remote sensing applications; Satellite image classification; Remote sensing",,,,,"Athalye, A., Carlini, N., (2018) On The Robustness of The CVPR 2018 White-Box Adversarial Example Defenses, , arXiv preprint 2018; Athalye, A., Carlini, N., Wagner, D., (2018) Obfuscated Gradients Give A False Sense of Security: Circumventing Defenses to Adversarial Examples, , arXiv preprint 2018; Athalye, A., Sutskever, I., (2017) Synthesizing Robust Adversarial Examples, , arXiv preprint 2017; Brown, T.B., Mané, D., Roy, A., Abadi, M., Gilmer, J., (2017) Adversarial Patch, , arXiv preprint 2017; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) Proceedings of The 10th ACM Workshop on Artificial Intelligence and Security, pp. 3-14. , ACM; Chen, S.-T., Cornelius, C., Martin, J., Chau, D.H., (2018) Robust Physical Adversarial Attack on Faster R-CNN Object Detector, , arXiv preprint 2018; Christie, G., Fendley, N., Wilson, J., Mukherjee, R., (2017) Functional Map of The World, , arXiv preprint 2017; Czaja, W., Fendley, N., Pekala, M., Ratto, C., Wang, I.-J., (2018) Adversarial Examples in Remote Sensing, , 2018; (2013) IKONOS: Data Sheet, , https://dg-cms-uploads-production.s3.amazonaws.com/uploads/document/file/96/DG_IKONOS_DS.pdf, 2013. Online; accessed 11-May-2018; Evtimov, I., Eykholt, K., Fernandes, E., Kohno, T., Li, B., Prakash, A., Rahmati, A., Song, D., (2017) Robust Physical-World Attacks on Deep Learning Models, , arXiv preprint 2017; Faghri, F., Goodfellow, I., Gilmer, J., Metz, L., Raghu, M., Schoenholz, S., (2018) Adversarial Spheres, , 2018; Fawzi, A., Moosavi-Dezfooli, S.-M., Frossard, P., Robustness of classifiers: From adversarial to random noise (2016) Advances in Neural Information Processing Systems, pp. 1632-1640; Fawzi, A., Moosavi-Dezfooli, S.-M., Frossard, P., The Robustness of Deep Networks: A Geometrical Perspective (2017) IEEE Signal Processing Magazine, 34 (6), pp. 50-62. , 2017; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint 2014; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in The Physical World, , arXiv preprint 2016; Lu, J., Sibai, H., Fabry, E., Forsyth, D., (2017) No Need to Worry About Adversarial Examples in Object Detection in Autonomous Vehicles, , arXiv preprint 2017; Mnih, V., Hinton, G.E., Learning to detect roads in high-resolution aerial images (2010) European Conference on Computer Vision, , Springer; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., (2016) Practical Black-Box Attacks Against Deep Learning Systems Using Adversarial Examples, , arXiv preprint 2016; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387. , IEEE; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint 2013",,"Xiong L.Tamassia R.Banaei F.Guting F.H.Hoel E.","Amazon;Apple;Esri;et al.;HERE;Lyft","Association for Computing Machinery","26th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems, ACM SIGSPATIAL GIS 2018","6 November 2018 through 9 November 2018",,142516,,9781450358897,,,"English","GIS Proc. ACM Int. Symp. Adv. Geogr. Inf. Syst.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85058649828
[No author name available],[No author id available],"IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers, ICCAD",2018,"IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers, ICCAD",,,,"","",986,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058196342&partnerID=40&md5=39b0a049316583e47041590dad6530c6",,"","The proceedings contain 134 papers. The topics discussed include: a fast thermal-aware fixed-outline floorplanning methodology based on analytical models; analytical solution of Poisson's equation and its application to VLSI global placement; novel proximal group ADMM for placement considering fogging and proximity effects; towards provably-secure analog and mixed-signal locking against overproduction; efficient hardware acceleration of CNNs using logarithmic data representation with arbitrary log-base; scalable-effort ConvNets for multilevel classification; emerging reconfigurable nanotechnologies: can they support future electronics?; emerging reconfigurable nanotechnologies: can they support future electronics?; macro-aware row-style power delivery network design for better routability; assured deep learning: practical defense against adversarial attacks; and Tetris: re-architecting convolutional neural network computation for machine learning accelerators.",,,,,,,,,,"ACM;IEEE","Institute of Electrical and Electronics Engineers Inc.","37th IEEE/ACM International Conference on Computer-Aided Design, ICCAD 2018","5 November 2018 through 8 November 2018",,142394,10923152,9781450359504,DICDF,,"English","IEEE ACM Int. Conf. Comput. Des. Dig. Tech. Pap. ICCAD",Conference Review,"Final","",Scopus,2-s2.0-85058196342
"Sai Manoj P.D., Amberkar S., Rafatirad S., Homayoun H.","57204081043;57204963808;14034730300;57203078254;","Efficient utilization of adversarial training towards robust machine learners and its analysis",2018,"IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers, ICCAD",,,"a78","","",,2,"10.1145/3240765.3267502","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058185993&doi=10.1145%2f3240765.3267502&partnerID=40&md5=9fb5ef269e6258ede522c541b8b87aa0","George Mason University, Fairfax, VA, United States","Sai Manoj, P.D., George Mason University, Fairfax, VA, United States; Amberkar, S., George Mason University, Fairfax, VA, United States; Rafatirad, S., George Mason University, Fairfax, VA, United States; Homayoun, H., George Mason University, Fairfax, VA, United States","Advancements in machine learning led to its adoption into numerous applications ranging from computer vision to security. Despite the achieved advancements in the machine learning, the vulnerabilities in those techniques are as well exploited. Adversarial samples are the samples generated by adding crafted perturbations to the normal input samples. An overview of different techniques to generate adversarial samples, defense to make classifiers robust is presented in this work. Furthermore, the adversarial learning and its effective utilization to enhance the robustness and the required constraints are experimentally provided, such as up to 97.65% accuracy even against CW attack. Though adversarial learning's effectiveness is enhanced, still it is shown in this work that it can be further exploited for vulnerabilities. © 2018 ACM.",,"Artificial intelligence; Computer aided design; Adversarial learning; Input sample; Machine learners; Learning systems",,,,,"Wess, M., Dinakarrao, S.M.P., Jantsch, A., Weighted quantizationregularization in DNNs for weight memory minimization towards HW implementation (2018) IEEE Transactions on Computer Aided Systems of Integrated Circuits and Systems; Ackerman, E., How Drive.ai Is Mastering Autonomous Driving with Deep Learning, , https://spectrum.ieee.org/cars-that-think/transportation/self-driving/how-driveai-is-mastering-autonomous-driving-with-deep-learning, accessed August 2018; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) International Conference on Neural Information Processing Systems; Demme, J., Maycock, M., Schmitz, J., Tang, A., Waksman, A., Sethumadhavan, S., Stolfo, S., On the feasibility of online malware detection with performance counters (2013) International Symposium on Computer Architecture; Chiappetta, M., Savas, E., Yilmaz, C., Real time detection of cache-based side-channel attacks using hardware performance counters (2016) Appl. Soft Comput., 49 (C). , Dec; Khasawneh, K.N., Ozsoy, M., Donovick, C., Abu-Ghazaleh, N., Ponomarev, D., (2018) EnsembleHMD: Accurate Hardware Malware Detectors with Specialized Ensemble Classifiers; Brasser, F., Hardware-assisted security: Understanding security vulnerabilities and emerging attacks for better defenses (2018) International Conference on Compilers, Architecture, and Synthesis for Embedded Systems (CASES); Sayadi, H., Patel, N., Manoj, P.D.S., Sasan, A., Rafatirad, S., Homayoun, H., Ensemble learning for hardware-based malware detection: A comprehensive analysis and classification (2018) ACM/EDAA/IEEE Design Automation Conference; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations (ICLR); Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations (ICLR); Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) IEEE European Symposium on Security and Privacy (Euro S&P); Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) International Conference on Learning Representations (ICLR); LeCun, Y., Cortes, C., Burges, C.J., (2018) Mnist Digit Dataset, , http://yann.lecun.com/exdb/mnist/, accessed August; Dalvi, N., Domingos, P., Mausam, S.S., Verma, D., Adversarial classification (2004) ACM SIGKDD International Conference on Knowledge Discovery and Data Mining; Lowd, D., Meek, C., Adversarial learning (2005) ACM SIGKDD International Conference on Knowledge Discovery in Data Mining; Matsumoto, T., Matsumoto, H., Yamada, K., Hoshino, S., (2002) Impact of Artificial Gummy Fingers on Fingerprint Systems, 26 (4); Nelson, B., Barreno, M., Chi, F.J., Joseph, A.D., Rubinstein, B.I.P., Saini, U., Sutton, C., Xia, K., Exploiting machine learning to subvert your spam filter (2008) Usenix Workshop on Large-Scale Exploits and Emergent Threats; Rubinstein, B.I., Nelson, B., Huang, L., Joseph, A.D., Lau, S.-H., Rao, S., Taft, N., Tygar, J.D., Antidote: Understanding and defending against poisoning of anomaly detectors (2009) ACM SIGCOMM Conference on Internet Measurement; Biggio, B., Nelson, B., Laskov, P., Poisoning attacks against support vector machines (2012) International Conference on Machine Learning; Xiao, H., Biggio, B., Brown, G., Fumera, G., Eckert, C., Roli, F., Is feature selection secure against training data poisoning (2015) International Conference on Machine Learning; Muñoz-González, L., Biggio, B., Demontis, A., Paudice, A., Wongrassamee, V., Lupu, E., Roli, F., Towards poisoning of deep learning algorithms with backgradient optimization (2017) ACM Workshop on Artificial Intelligence and Security; Shaham, U., Yamada, Y., Negahban, S., Understanding adversarial training: Increasing local stability of neural nets through robust optimization (2015) ArXiv E-prints; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2017) International Conference on Learning Representations; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., Boosting adversarial attacks with momentum (2017) Neural Information Processing Systems Conference; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) IEEE Symposium on Security and Privacy (S&P); Moosavi-Dezfooli, S., Fawzi, A., Frossard, P., (2015) Deepfool: A Simple and Accurate Method to Fool Deep Neural Networks, , CoRR abs/1511.04599; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy (SP); Hinton, G., Vinyals, O., Dean, J., Distilling the knowledge in a neural network (2015) ArXiv E-prints; Meng, D., Chen, H., Magnet: A two-pronged defense against adversarial examples (2017) ACM Conference on Computer and Communications Security (CCS); Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P.D., On the (statistical) detection of adversarial examples (2017) CoRR abs/1702.06280; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., On detecting adversarial perturbations (2017) International Conference on Learning Representations; (2018), https://github.com/zalandoresearch/fashion-mnist, Mnist fashion dataset accessed August; Papernot, N., (2018) Technical Report on the Cleverhans v2.1.0 Adversarial Examples Library, , arXiv preprint arXiv:1610.00768; (2018), https://github.com/keras-team/keras/blob/master/examples/mnist_mlp.py, Mnist model accessed August; Zhong, Z., Zheng, L., Kang, G., Li, S., Yang, Y., (2017) Random Erasing Data Augmentation, , arXiv preprint arXiv:1708.04896",,,"ACM;IEEE","Institute of Electrical and Electronics Engineers Inc.","37th IEEE/ACM International Conference on Computer-Aided Design, ICCAD 2018","5 November 2018 through 8 November 2018",,142394,10923152,9781450359504,DICDF,,"English","IEEE ACM Int. Conf. Comput. Des. Dig. Tech. Pap. ICCAD",Conference Paper,"Final","",Scopus,2-s2.0-85058185993
"Rouhani B.D., Samragh M., Javaheripi M., Javidi T., Koushanfar F.","56115057700;57195397854;57204963323;15725367600;6602459029;","DeepFense: Online accelerated defense against adversarial deep learning",2018,"IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers, ICCAD",,,"a134","","",,22,"10.1145/3240765.3240791","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058171369&doi=10.1145%2f3240765.3240791&partnerID=40&md5=03d758fc145d662bb84e814413466628","University of California San Diego, United States","Rouhani, B.D., University of California San Diego, United States; Samragh, M., University of California San Diego, United States; Javaheripi, M., University of California San Diego, United States; Javidi, T., University of California San Diego, United States; Koushanfar, F., University of California San Diego, United States","Recent advances in adversarial Deep Learning (DL) have opened up a largely unexplored surface for malicious attacks jeopardizing the integrity of autonomous DL systems. With the wide-spread usage of DL in critical and time-sensitive applications, including unmanned vehicles, drones, and video surveillance systems, online detection of malicious inputs is of utmost importance. We propose DeepFense, the first end-to-end automated framework that simultaneously enables efficient and safe execution of DL models. DeepFense formalizes the goal of thwarting adversarial attacks as an optimization problem that minimizes the rarely observed regions in the latent feature space spanned by a DL network. To solve the aforementioned minimization problem, a set of complementary but disjoint modular redundancies are trained to validate the legitimacy of the input samples in parallel with the victim DL model. DeepFense leverages hardware/software/algorithm co-design and customized acceleration to achieve just-in-time performance in resource-constrained settings. The proposed countermeasure is unsupervised, meaning that no adversarial sample is leveraged to train modular redundancies. We further provide an accompanying API to reduce the non-recurring engineering cost and ensure automated adaptation to various platforms. Extensive evaluations on FPGAs and GPUs demonstrate up to two orders of magnitude performance improvement while enabling online adversarial sample detection. © 2018 ACM.","adversarial attacks; deep learning; FPGA acceleration; model reliability; real-time computing","Aircraft detection; Computer aided design; Cost engineering; E-learning; Field programmable gate arrays (FPGA); Online systems; Program processors; Redundancy; Security systems; Unmanned vehicles; adversarial attacks; Minimization problems; Model reliability; Non recurring engineering; Performance improvements; Real time computing; Time sensitive applications; Video surveillance systems; Deep learning",,,,,"McDaniel, P., Papernot, N., Celik, Z.B., Machine learning in adversarial settings (2016) IEEE Security & Privacy, 14 (3), pp. 68-72; Deng, L., Yu, D., Deep learning: Methods and applications (2014) Foundations and TrendsR in Signal Processing, 7 (3-4), pp. 197-387; Knorr, E., (2015) How Paypal Beats the Bad Guys with Machine Learning; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy (SP), pp. 39-57. , IEEE; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint arXiv:1412.6572; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint arXiv:1607.02533; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Meng, D., Chen, H., Magnet: A two-pronged defense against adversarial examples (2017) ACM SIGSAC Conference on Computer and Communications Security, pp. 135-147. , ACM; Zantedeschi, V., Nicolae, M.-I., Rawat, A., Efficient defenses against adversarial attacks (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 39-49. , ACM; Shen, S., Jin, G., Gao, K., Zhang, Y., Ape-gan: Adversarial perturbation elimination with gan (2017) ICLR Submission, Available on OpenReview; Carlini, N., Wagner, D., (2017) Magnet and Efficient Defenses Against Adversarial Attacks Are Not Robust to Adversarial Examples, , arXiv preprint arXiv:1711.08478; Zhang, C., Li, P., Sun, G., Guan, Y., Xiao, B., Cong, J., Optimizing FPGA-based accelerator design for deep convolutional neural networks (2015) ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, , ACM; Chen, T., Du, Z., Sun, N., Wang, J., Wu, C., Chen, Y., Temam, O., Diannao: A small-footprint high-throughput accelerator for ubiquitous machine-learning (2014) ACM Sigplan Notices, 49 (4), pp. 269-284; Sharma, H., Park, J., Amaro, E., Thwaites, B., Kotha, P., Gupta, A., Kim, J.K., Esmaeilzadeh, H., Dnnweaver: From high-level deep network models to FPGA acceleration (2016) The Workshop on Cognitive Architectures; Samragh, M., Ghasemzadeh, M., Koushanfar, F., Customizing neural networks for efficient FPGA implementation (2017) Field-Programmable Custom Computing Machines (FCCM), , IEEE; Rouhani, B.D., Mirhoseini, A., Koushanfar, F., Deep3: Leveraging three levels of parallelism for efficient deep learning (2017) Proceedings of the 54th Annual Design Automation Conference 2017, p. 61. , ACM; Tropp, J., Gilbert, A.C., Signal recovery from random measurements via orthogonal matching pursuit (2007) IEEE Transactions on Information Theory, 53 (12), pp. 4655-4666; Diez, F.J., Parameter adjustment in bayes networks. the generalized noisy or-gate (1993) Uncertainty in Artificial Intelligence, pp. 99-105. , Elsevier, 1993; Rouhani, B.D., Songhori, E.M., Mirhoseini, A., Koushanfar, F., Ssketch: An automated framework for streaming sketch-based analysis of big data on FPGA (2015) Field-Programmable Custom Computing Machines (FCCM), , IEEE; Gu, S., Rigazio, L., (2014) Towards Deep Neural Network Architectures Robust to Adversarial Examples, , arXiv preprint arXiv:1412.5068; Shaham, U., Yamada, Y., Negahban, S., (2015) Understanding Adversarial Training: Increasing Local Stability of Neural Nets Through Robust Optimization, , arXiv preprint arXiv:1511.05432; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint arXiv:1312.6199; Miyato, T., Maeda, S.-I., Koyama, M., Nakae, K., Ishii, S., (2015) Distributional Smoothing with Virtual Adversarial Training, , arXiv preprint arXiv:1507.00677; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., (2016) Distillation As A Defense to Adversarial Perturbations Against Deep Neural Networks, pp. 582-597; Carlini, N., Wagner, D., (2016) Defensive Distillation Is Not Robust to Adversarial Examples, , arXiv preprint",,,"ACM;IEEE","Institute of Electrical and Electronics Engineers Inc.","37th IEEE/ACM International Conference on Computer-Aided Design, ICCAD 2018","5 November 2018 through 8 November 2018",,142394,10923152,9781450359504,DICDF,,"English","IEEE ACM Int. Conf. Comput. Des. Dig. Tech. Pap. ICCAD",Conference Paper,"Final","",Scopus,2-s2.0-85058171369
"Nixon K.W., Mao J., Shen J., Yang H., Li H.H., Chen Y.","55699116800;57190073248;57034553600;57203286881;57201321031;9737381600;","SPN dash: Fast detection of adversarial attacks on mobile via sensor pattern noise fingerprinting",2018,"IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers, ICCAD",,,"a132","","",,3,"10.1145/3240765.3240851","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058168638&doi=10.1145%2f3240765.3240851&partnerID=40&md5=5e2df3c5c30cc6f3e6c172300fe03c4a","Duke University, United States; Zhejiang University, United States","Nixon, K.W., Duke University, United States; Mao, J., Duke University, United States; Shen, J., Zhejiang University, United States; Yang, H., Duke University, United States; Li, H.H., Duke University, United States; Chen, Y., Duke University, United States","A concerning weakness of deep neural networks is their susceptibility to adversarial attacks. While methods exist to detect these attacks, they incur significant drawbacks, ignoring external features which could aid in the task of attack detection. In this work, we propose SPN Dash, a method for detection of adversarial attacks based on integrity of sensor pattern noise embedded in submitted images. Through experiment, we show that our SPN Dash method is capable of detecting the addition of adversarial noise with up to 94% accuracy for images of size 256×256. Analysis shows that SPN Dash is robust to image scaling techniques, as well as a small amount of image compression. This performance is on par with state of the art neural network-based detectors, while incurring an order of magnitude less computational and memory overhead. © 2018 ACM.",,"Computer aided design; Deep neural networks; Attack detection; External features; Fast detections; Image scaling; Memory overheads; Sensor pattern noise; State of the art; Image compression",,,,,"2017. Bixby Vision | Apps-The Official Samsung Galaxy Site. samsung.com/global/galaxy/apps/bixby/vision/; Bojinov, H., (2014) Mobile Device Identification Via Sensor Fingerprinting, , CoRR abs/1408.1416 2014 arxiv.org/abs/1408.1416; Chen, M., Determining image origin and integrity using sensor noise (2008) IEEE Trans on Inf Forensics and Sec, 3 (1), pp. 74-90. , https://doi.org/10.1109/Tifs.2007.916285, 2008; Cipriani, J., (2017) Google Lens: Everything to Know about the Pixel 2's AR Feature, , cnet.com/how-to/google-lens-everything-to-know-about-the-pixel-2-ar-feature/; Rosales Corripio, J., (2013) Source Smartphone Identification Using Sensor Pattern Noise and Wavelet Transform, p. 116. , digital-library.theiet.org/content/conferences/10.1049/ic.2013.0267; El Gamal, A., Modeling and Estimation of FPN Components in CMOS Image Sensors Photonics West '98 Elec Img, 3301. , [n. d.]SPIE, 10; Evtimov, I., (2017) Robust Physical-World Attacks on Machine Learning Models, , CoRR abs/1707.08945 2017 arxiv.org/abs/1707.08945; Ferrero, A., Campos, J., Pons, A., Correction of Photoresponse Nonuniformity for Matrix Detectors Based on Prior Compensation for Their Nonlinear Behavior (2006) Appl Opt, 45 (11), pp. 2422-2427. , 2006; Goljan, M., Fridrich, J., Filler, T., Large scale test of sensor fingerprint camera identification (2009) Media Forensics and Security, 7254, p. 72540I. , International Society for Optics and Photonics; Goodfellow, I., (2014) Generative Adversarial Nets, pp. 2672-2680. , papers.nips.cc/paper/5423-generative-adversarial-nets; Goodfellow, I., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint arXiv:1412.6572 2014; Hendrik Metzen, J., (2017) On Detecting Adversarial Perturbations, , adsabs. harvard.edu/abs/2017arXiv170204267H; Howard, A., (2017) Mobilenets: Efficient Convolutional Neural Networks for Mobile Vision Applications, , arXiv preprint arXiv:1704.04861 2017; Hyun, D.K., Detection of upscale-crop and partial manipulation in surveillance video based on sensor pattern noise (2013) Sensors (Basel), 13 (9), pp. 12605-12631. , https://doi.org/10.3390/s130912605, 2013; Irie, K., A model for measurement of noise in ccd digital-video cameras (2008) Meas Sci and Tech, 19 (4), p. 045207. , https://doi.org/Artn04520710.1088/0957-0233/19/4/045207, 2008; Jia, Y., (2014) Caffe: Convolutional Architecture for Fast Feature Embedding, , arXiv preprint arXiv:1408.5093 2014; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, 25. , Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger (Eds.). Curran Associates, Inc., 1097-1105. papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , Computing Research Repository abs/1607.02533 2016 arxiv. org/abs/1607.02533; Li, C.T., Source camera identification using enhanced sensor pattern noise (2010) IEEE Trans on Inf Forensics and Sec, 5 (2), pp. 280-287. , https://doi.org/10.1109/Tifs.2010.2046268, 2010; Li, X., Li, F., (2016) Adversarial Examples Detection in Deep Networks with Convolutional Filter Statistics, , Computing Research Repository abs/1612.07767 2016 arxiv.org/abs/1612.07767; Liu, Y., (2016) Delving into Transferable Adversarial Examples and Black-box Attacks, , arXiv preprint arXiv:1611.02770 2016; Lukas, J., Fridrich, J., Goljan, M., Digital camera identification from sensor pattern noise (2006) IEEE Trans on Inf Forensics and Sec, 1 (2), pp. 205-214. , https://doi.org/10.1109/Tifs.2006.873602, 2006; Luo, Y., (2015) Foveation-Based Mechanisms Alleviate Adversarial Examples, , Computing Research Repository abs/1511.06292 2015 arxiv.org/abs/1511.06292; Metzen, J., Genewein, T., Fischer, V., Bischoff, B., (2017) On Detecting Adversarial Perturbations, , arXiv preprint arXiv:1702.04267 2017; Papernot, N., (2017) Practical Black-Box Attacks Against Machine Learning, pp. 506-519. , https://doi.org/10.1145/3052973.3053009; Salama, K., El Gamal, A., Analysis of active pixel sensor readout circuit (2003) IEEE Trans on Circ and Sys I-Fundamental Theory and Applications, 50 (7), pp. 941-944. , https://doi.org/10.1109/Tsci.2003.813977, 2003; Sharif, M., (2016) Accessorize to A Crime: Real and Stealthy Attacks on Stateof-the-Art Face Recognition, pp. 1528-1540. , https://doi.org/10.1145/2976749; Song, C., (2017) A Multi-strength Adversarial Training Method to Mitigate Adversarial Attacks, , Computing Research Repository abs/1705.09764 2017 arxiv. org/abs/1705.09764",,,"ACM;IEEE","Institute of Electrical and Electronics Engineers Inc.","37th IEEE/ACM International Conference on Computer-Aided Design, ICCAD 2018","5 November 2018 through 8 November 2018",,142394,10923152,9781450359504,DICDF,,"English","IEEE ACM Int. Conf. Comput. Des. Dig. Tech. Pap. ICCAD",Conference Paper,"Final","All Open Access, Bronze",Scopus,2-s2.0-85058168638
"Rouhani B.D., Samragh M., Javaheripi M., Javidi T., Koushanfar F.","56115057700;57195397854;57204963323;15725367600;6602459029;","Assured deep learning: Practical defense against adversarial attacks",2018,"IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers, ICCAD",,,"a20","","",,,"10.1145/3240765.3274525","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058168500&doi=10.1145%2f3240765.3274525&partnerID=40&md5=6bfc27c26a8dd88bb928cb731047ae77","University of California San Diego, United States","Rouhani, B.D., University of California San Diego, United States; Samragh, M., University of California San Diego, United States; Javaheripi, M., University of California San Diego, United States; Javidi, T., University of California San Diego, United States; Koushanfar, F., University of California San Diego, United States","Deep Learning (DL) models have been shown to be vulnerable to adversarial attacks. In light of the adversarial attacks, it is critical to reliably quantify the confidence of the prediction in a neural network to enable safe adoption of DL models in autonomous sensitive tasks (e.g., unmanned vehicles and drones). This article discusses recent research advances for unsupervised model assurance against the strongest adversarial attacks known to date and quantitatively compare their performance. Given the widespread usage of DL models, it is imperative to provide model assurance by carefully looking into the feature maps automatically learned within Dl models instead of looking back with regret when deep learning systems are compromised by adversaries. © 2018 ACM.","adversarial deep learning; real-time defense; reconfigurable computing; unsupervised model assurance","Computer aided design; Network security; Reconfigurable architectures; Unmanned vehicles; Feature map; Real time; Recent researches; Reconfigurable computing; unsupervised model assurance; Deep learning",,,,,"Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium On. IEEE; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint arXiv:1312.6199; Meng, D., Chen, H., Magnet: A two-pronged defense against adversarial examples (2017) Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security. ACM; Shen, S., Jin, G., Gao, K., Zhang, Y., Ape-gan: Adversarial perturbation elimination with gan (2017) ICLR Submission, Available on OpenReview; Ma, X., Li, B., Wang, Y., Erfani, S.M., Wijewickrema, S., Houle, M.E., Schoenebeck, G., Bailey, J., (2018) Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality, , arXiv preprint arXiv:1801.02613; Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., Mc-Daniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses, , arXiv preprint arXiv:1705.07204; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., (2016) Distillation As A Defense to Adversarial Perturbations Against Deep Neural Networks; Gu, S., Rigazio, L., (2014) Towards Deep Neural Network Architectures Robust to Adversarial Examples, , arXiv preprint arXiv:1412.5068; Rouhani, B., Samragh, M., Javaheripi, M., Javidi, T., Koushanfar, F., (2018) Deepfense: Online Accelerated Defense Against Adversarial Deep Learning; Rouhani, B., Samragh, M., Javidi, T., Koushanfar, F., (2018) Safe Machine Learning and Defeating Adversarial Attacks; Tropp, J., Gilbert, A.C., Signal recovery from random measurements via orthogonal matching pursuit (2007) IEEE Transactions on Information Theory, 53 (12), pp. 4655-4666; Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., (2017) On the (Statistical) Detection of Adversarial Examples, , arXiv preprint arXiv:1702.06280; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts, , arXiv preprint arXiv:1703.00410; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint arXiv:1607.02533; Carlini, N., Wagner, D., (2017) Magnet and"" Efficient Defenses Against Adversarial Attacks"" Are Not Robust to Adversarial Examples, , arXiv preprint arXiv:1711.08478; Zantedeschi, V., Nicolae, M.-I., Rawat, A., Efficient defenses against adversarial attacks (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security. ACM",,,"ACM;IEEE","Institute of Electrical and Electronics Engineers Inc.","37th IEEE/ACM International Conference on Computer-Aided Design, ICCAD 2018","5 November 2018 through 8 November 2018",,142394,10923152,9781450359504,DICDF,,"English","IEEE ACM Int. Conf. Comput. Des. Dig. Tech. Pap. ICCAD",Conference Paper,"Final","",Scopus,2-s2.0-85058168500
"Liu Y., Costantini A., Bahar R.I., Sui Z., Ye Z., Lu S., Jenkins O.C.","57204972384;57204971383;57225366504;55568292600;55776496800;57204964191;35589011000;","Robust object estimation using generative-discriminative inference for secure robotics applications",2018,"IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers, ICCAD",,,"a75","","",,3,"10.1145/3240765.3243493","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058159046&doi=10.1145%2f3240765.3243493&partnerID=40&md5=7455346dcf0ad9548a56d22c0a5daf58","Brown University, School of Engineering, Providence, RI, United States; University of Michigan, Dept. of Computer Science and Engineering, Ann Arbor, MI, United States","Liu, Y., Brown University, School of Engineering, Providence, RI, United States; Costantini, A., Brown University, School of Engineering, Providence, RI, United States; Bahar, R.I., Brown University, School of Engineering, Providence, RI, United States; Sui, Z., University of Michigan, Dept. of Computer Science and Engineering, Ann Arbor, MI, United States; Ye, Z., University of Michigan, Dept. of Computer Science and Engineering, Ann Arbor, MI, United States; Lu, S., University of Michigan, Dept. of Computer Science and Engineering, Ann Arbor, MI, United States; Jenkins, O.C., University of Michigan, Dept. of Computer Science and Engineering, Ann Arbor, MI, United States","Convolutional neural networks (CNNs) are of increasing widespread use in robotics, especially for object recognition. However, such CNNs still lack several critical properties necessary for robots to properly perceive and function autonomously in uncertain, and potentially adversarial, environments. In this paper, we investigate factors for accurate, reliable, and resource-efficient object and pose recognition suitable for robotic manipulation in adversarial clutter. Our exploration is in the context of a three-stage pipeline of discriminative CNN-based recognition, generative probabilistic estimation, and robot manipulation. This pipeline proposes using a SAmpling Network Density filter, or SAND filter, to recover from potentially erroneous decisions produced by a CNN through generative probabilistic inference. We present experimental results from SAND filter perception for robotic manipulation in tabletop scenes with both benign and adversarial clutter. These experiments vary CNN model complexity for object recognition and evaluate levels of inaccuracy that can be recovered by generative pose inference. This scenario is extended to consider adversarial environmental modifications with varied lighting, occlusions, and surface modifications. © 2018 ACM.","DNN adversarial attack; robot perception; robust machine learning","Clutter (information theory); Computer aided design; Learning systems; Neural networks; Object recognition; Pipelines; Robots; Convolutional neural network; Critical properties; DNN adversarial attack; Probabilistic estimation; Probabilistic inference; Robot perception; Robotic manipulation; Robotics applications; Robotics",,,,,"Bojarski, M., Del Testa, D., Dworakowski, D., Firner, B., Flepp, B., Goyal, P., Jackel, L.D., Zieba, K., (2016) End to End Learning for Self-Driving Cars, , http://arxiv.org/abs/1604.07316, CoRR abs/1604.07316 2016 arXiv:1604.07316; Carlini, N., Wagner, D., (2016) Towards Evaluating the Robustness of Neural Networks, , arXiv preprint arXiv:1608.04644 2016; Chen, Y., Chao, T., Bai, S., Lin, Y., Chen, W., Hsu, W.H., Filter-invariant image classification on social media photos (2015) Proceedings of the 23rd ACM International Conference on Multimedia, pp. 855-858. , ACM; Ciocarlie, M., Hsiao, K., Gil Jones, E., Chitta, S., Bogdan Rusu, R., Sucan, I.A., Towards reliable grasping and manipulation in household environments (2014) Experimental Robotics, pp. 241-252. , Springer Berlin Heidelberg; Collet, A., Martinez, M., Srinivasa, S.S., The moped framework: Object recognition and pose estimation for manipulation (2011) The International Journal of Robotics Research, pp. 0278364911401765; Deng, J., Dong, W., Socher, R., Li, L., Li, K., Fei-Fei, L., Imagenet: A large-scale hierarchical image database (2009) Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pp. 248-255. , IEEE; Everingham, M., Van Gool, L., Williams, C.K., Winn, J., Zisserman, A., The pascal visual object classes (voc) challenge (2010) International Journal of Computer Vision, 88 (2), pp. 303-338. , 2010; Fischler, M.A., Bolles, R.C., Random sample consensus: A paradigm for model fitting with applications to image analysis and automated cartography (1987) Readings in Computer Vision, pp. 726-740. , Elsevier; Girshick, R., (2015) Fast R-CNN, , arXiv preprint arXiv:1504.08083 2015; Girshick, R., Donahue, J., Darrell, T., Malik, J., Rich feature hierarchies for accurate object detection and semantic segmentation (2014) Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on, pp. 580-587. , IEEE; Gordon, N.J., Salmond, D.J., Smith, A.F.M., Novel approach to nonlinear/non-Gaussian Bayesian state estimation (1993) IEE Proceedings F (Radar and Signal Processing), 140, pp. 107-113. , IET; Gualtieri, M., Ten Pas, A., Platt, R., Jr., (2017) Category Level Pick and Place Using Deep Reinforcement Learning, , http://arxiv.org/abs/1707.05615, CoRR abs/1707.05615 2017 arXiv:1707.05615; Gualtieri, M., Ten Pas, A., Saenko, K., Platt, R., High precision grasp pose detection in dense clutter (2016) 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 598-605. , https://doi.org/10.1109/IROS.2016.7759114; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Hinterstoisser, S., Lepetit, V., Ilic, S., Holzer, S., Bradski, G., Konolige, K., Navab, N., (2012) Model Based Training, Detection and Pose Estimation of Texture-Less 3D Objects in Heavily Cluttered Scenes, , 2012; Huang, L., Yang, Y., Deng, Y., Yu, Y., (2015) Densebox: Unifying Landmark Localization with End to End Object Detection, , arXiv preprint arXiv:1509.04874 2015; Huang, S., Papernot, N., Goodfellow, I., Duan, Y., Abbeel, P., (2017) Adversarial Attacks on Neural Network Policies, , arXiv preprint arXiv:1702.02284 2017; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint arXiv:1607.02533 2016; Lai, K., Bo, L., Fox, D., Unsupervised feature learning for 3d scene labeling (2014) Robotics and Automation (ICRA), 2014 IEEE International Conference on, pp. 3050-3057. , IEEE; Lai, K., Bo, L., Ren, X., Fox, D., A large-scale hierarchical multi-view rgb-d object dataset (2011) Robotics and Automation (ICRA), 2011 IEEE International Conference on, pp. 1817-1824. , IEEE; Long, J., Shelhamer, E., Darrell, T., Fully convolutional networks for semantic segmentation (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3431-3440; Morris, D.D., (2018) A Pyramid CNN for Dense-Leaves Segmentation, , arXiv preprint arXiv:1804.01646 2018; Narayanan, V., Likhachev, M., Discriminatively-guided deliberative perception for pose estimation of multiple 3d object instances (2016) Proceedings of Robotics: Science and Systems, , https://doi.org/10.15607/RSS.2016.XII.023, AnnArbor, Michigan; Kohli, N., Silberman, P., Hoiem, D., Fergus, R., Indoor segmentation and support inference from rgbd images (2012) ECCV; Panda, P., Roy, K., (2018) Explainable Learning: Implicit Generative Modelling during Training for Adversarial Robustness, , arXiv preprint arXiv:1807.02188 2018; Papazov, C., Haddadin, S., Parusel, S., Krieger, K., Burschka, D., Rigid 3D geometry matching for grasping of known objects in cluttered scenes (2012) The International Journal of Robotics Research, pp. 0278364911436019; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519. , ACM; Redmon, J., Divvala, S., Girshick, R., Farhadi, A., (2015) You only Look Once: Unified, Real-time Object Detection, , arXiv preprint arXiv:1506.02640 2015; Ren, S., He, K., Girshick, R., Sun, J., Faster r-cnn: Towards real-time object detection with region proposal networks (2015) Advances in Neural Information Processing Systems, pp. 91-99; Sermanet, P., Eigen, D., Zhang, X., Mathieu, M., Fergus, R., LeCun, Y., (2013) Overfeat: Integrated Recognition, Localization and Detection Using Convolutional Networks, , arXiv preprint arXiv:1312.6229 2013; Shrivastava, A., Gupta, A., Girshick, R.B., (2016) Training Region-based Object Detectors with Online Hard Example Mining, , http://arxiv.org/abs/1604.03540, CoRR abs/1604.03540 2016 arXiv:1604.03540; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition, , arXiv preprint arXiv:1409.1556 2014; Moll Mark Sucan, I.A., Kavraki, L.E., The open motion planning library (2012) IEEE Robotics & Automation Magazine, 19 (4), pp. 72-82. , https://doi.org/10.1109/MRA.2012.2205651, December 2012 http://ompl.kavrakilab.org; Sui, Z., Zhou, Z., Zeng, Z., Chadwicke Jenkins, O., SUM: Sequential scene understanding and manipulation (2017) 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 3281-3288. , https://doi.org/10.1109/IROS.2017.8206164; Sui, Z., Ye Zhou, Z., Chadwicke Jenkins, O., (2018) Never Mind the Bounding Boxes, Here's the SAND Filters, , arXiv preprint arXiv:1808.04969 2018; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint arXiv:1312.6199 2013; Ten, P., Marcus, G.A., Saenko, K., Platt, R., Grasp pose detection in point clouds The International Journal of Robotics Research, , [n. d.]. ([n. d.]), 0278364917735594; Ten Pas, A., Platt, R., Localizing handle-like grasp affordances in 3d point clouds (2016) Experimental Robotics. Springer, pp. 623-638; Ulicny, M., Lundstrom, J., Byttner, S., Robustness of deep convolutional neural networks for image recognition (2016) International Symposium on Intelligent Computing Systems, pp. 16-30. , Springer; Varley, J., Weisz, J., Weiss, J., Allen, P., Generating multi-fingered robotic grasps via deep learning (2015) 2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 4415-4420. , https://doi.org/10.1109/IROS.2015.7354004; Xiang, Y., Schmidt, T., Narayanan, V., Fox, D., Posecnn: A convolutional neural network for 6d object pose estimation in cluttered scenes (2018) Robotics: Science and Systems (RSS), , 2018; Xie, S., Girshick, R., Dollar, P., Tu, Z., He, K., Aggregated residual transformations for deep neural networks (2017) Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on, pp. 5987-5995. , IEEE; Zheng, S., Song, Y., Leung, T., Goodfellow, I., Improving the robustness of deep neural networks via stability training (2016) Proceedings of the Ieee Conference on Computer Vision and Pattern Recognition, pp. 4480-4488",,,"ACM;IEEE","Institute of Electrical and Electronics Engineers Inc.","37th IEEE/ACM International Conference on Computer-Aided Design, ICCAD 2018","5 November 2018 through 8 November 2018",,142394,10923152,9781450359504,DICDF,,"English","IEEE ACM Int. Conf. Comput. Des. Dig. Tech. Pap. ICCAD",Conference Paper,"Final","",Scopus,2-s2.0-85058159046
"Wang S., Wang X., Zhao P., Wen W., Kaeli D., Chin P., Lin X.","57204970785;57202379318;57201580783;55301112800;7003340827;52463367400;57205018638;","Defensive dropout for hardening deep neural networks under adversarial attacks",2018,"IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers, ICCAD",,,"a71","","",,18,"10.1145/3240765.3264699","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058155012&doi=10.1145%2f3240765.3264699&partnerID=40&md5=bc9c5a352ffe97d7dbe15b8393981cfe","Northeastern University, United States; Boston University, United States; Florida International University, United States","Wang, S., Northeastern University, United States; Wang, X., Boston University, United States; Zhao, P., Northeastern University, United States; Wen, W., Florida International University, United States; Kaeli, D., Northeastern University, United States; Chin, P., Boston University, United States; Lin, X., Northeastern University, United States","Deep neural networks (DNNs) are known vulnerable to adversarial attacks. That is, adversarial examples, obtained by adding delicately crafted distortions onto original legal inputs, can mislead a DNN to classify them as any target labels. This work provides a solution to hardening DNNs under adversarial attacks through defensive dropout. Besides using dropout during training for the best test accuracy, we propose to use dropout also at test time to achieve strong defense effects. We consider the problem of building robust DNNs as an attacker-defender two-player game, where the attacker and the defender know each others' strategies and try to optimize their own strategies towards an equilibrium. Based on the observations of the effect of test dropout rate on test accuracy and attack success rate, we propose a defensive dropout algorithm to determine an optimal test dropout rate given the neural network model and the attacker's strategy for generating adversarial examples. We also investigate the mechanism behind the outstanding defense effects achieved by the proposed defensive dropout. Comparing with stochastic activation pruning (SAP), another defense method through introducing randomness into the DNN model, we find that our defensive dropout achieves much larger variances of the gradients, which is the key for the improved defense effects (much lower attack success rate). For example, our defensive dropout can reduce the attack success rate from 100% to 13.89% under the currently strongest attack i.e., C&W attack on MNIST dataset. © 2018 ACM.",,"Computer aided design; Game theory; Hardening; Network security; Stochastic models; Stochastic systems; Testing; Mnist dataset; Neural network model; Target labels; Test accuracy; Test time; Two-player games; Deep neural networks",,,,,"Athalye, A., Carlini, N., Wagner, D., (2018) Obfuscated Gradients Give A False Sense of Security: Circumventing Defenses to Adversarial Examples, , arXiv preprint arXiv:1802.00420 2018; Nitin Bhagoji, A., Cullina, D., Mittal, P., (2017) Dimensionality Reduction As A Defense Against Evasion Attacks on Machine Learning Classifiers, , arXiv preprint arXiv:1704.02654 2017; Bouthillier, X., Konda, K., Vincent, P., Memisevic, R., (2015) Dropout As Data Augmentation, , arXiv preprint arXiv:1506.08700 2015; Carlini, N., Mishra, P., Vaidya, T., Zhang, Y., Sherr, M., Shields, C., Wagner, D., Zhou, A., Hidden voice commands (2016) USENIX Security Symposium, pp. 513-530; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium on, pp. 39-57. , IEEE; Chen, P., Sharma, Y., Zhang, H., Yi, J., Hsieh, C., (2017) EAD: Elastic-net Attacks to Deep Neural Networks Via Adversarial Examples, , arXiv preprint arXiv:1709.04114 2017; Collobert, R., Weston, J., A unified architecture for natural language processing: Deep neural networks with multitask learning (2008) Proceedings of the 25th International Conference on Machine Learning, pp. 160-167. , ACM; Dhillon, G.S., Azizzadenesheli, K., Bernstein, J.D., Kossaifi, J., Khanna, A., Lipton, Z.C., Anandkumar, A., Stochastic activation pruning for robust adversarial defense (2018) International Conference on Learning Representations, , https://openreview.net/forumid=H1uR4GZRZ; Dhillon, G.S., Azizzadenesheli, K., Lipton, Z.C., Bernstein, J., Kossaifi, J., Khanna, A., Anandkumar, A., (2018) Stochastic Activation Pruning for Robust Adversarial Defense, , arXiv preprint arXiv:1803.01442 2018; Karolina, D.G., Ghahramani, Z., Roy, D.M., (2016) A Study of the Effect of Jpg Compression on Adversarial Images, , arXiv preprint arXiv:1608.00853 2016; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts, , arXiv preprint arXiv:1703.00410 2017; Goodfellow, I., Bengio, Y., Courville, A., Bengio, Y., (2016) Deep Learning, 1. , MIT press Cambridge; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint arXiv:1412.6572 2014; Guo Mayank Rana, C., Cissé, M., Van Der Maaten, L., (2017) Countering Adversarial Images Using Input Transformations, , arXiv preprint arXiv:1711.00117 2017; Hinton, G., Deng, L., Yu, D., Dahl, G.E., Mohamed, A., Jaitly, N., Senior, A., Sainath, T.N., Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups (2012) IEEE Signal Processing Magazine, 29 (6), pp. 82-97. , 2012; Hinton, G.E., Srivastava, N., Krizhevsky, A., Sutskever, I., Salakhutdinov, R.R., (2012) Improving Neural Networks by Preventing Coadaptation of Feature Detectors, , arXiv preprint arXiv:1207.0580 2012; Karpathy, A., Fei-Fei, L., Deep visual-semantic alignments for generating image descriptions (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3128-3137; Kingma, D.P., Ba, J., (2015) Adam: A Method for Stochastic Optimization, , http://arxiv.org/abs/1412.6980, 2015 ICLR arXiv preprint arXiv:1412.6980 2015 arXiv:1412.6980; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images, , 2009; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint arXiv:1607.02533 2016; LeCun, Y., Boser, B., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W., Jackel, L.D., Backpropagation applied to handwritten zip code recognition (1989) Neural Computation, 1 (4), pp. 541-551. , 1989; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradientbased learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324. , 1998; Liu, Y., Wei, L., Luo, B., Xu, Q., Fault injection attack on deep neural network (2017) Proceedings of the 36th International Conference on Computer-Aided Design, pp. 131-138. , IEEE Press; Livnat, A., Papadimitriou, C., Pippenger, N., Feldman, M.W., Sex, mixability, and modularity (2010) Proceedings of the National Academy of Sciences, 107 (4), pp. 1452-1457. , 2010; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 427-436; Papernot, N., Carlini, N., Goodfellow, I., Feinman, R., Faghri, F., Matyasko, A., Hambardzumyan, K., Sheatsley, R., (2016) Cleverhans v2 0.0: An Adversarial Machine Learning Library, , arXiv preprint arXiv:1610.00768 2016; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387. , IEEE; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Security and Privacy (SP), 2016 IEEE Symposium on, pp. 582-597. , IEEE; Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., Dropout: A simple way to prevent neural networks from overfitting (2014) The Journal of Machine Learning Research, 15 (1), pp. 1929-1958. , 2014; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint arXiv:1312.6199 2013; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses, , arXiv preprint arXiv:1705.07204 2017; Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2018) Ensemble Adversarial Training: Attacks and Defenses, , 2018 ICLR arXiv preprint arXiv:1705.07204 2018; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., (2017) Mitigating Adversarial Effects Through Randomization, , arXiv preprint arXiv:1711.01991 2017; Yann, L., Corinna, C., Christopher, J.B., (1998) The MNIST Database of Handwritten Digits, , http://yhann.lecun.com/exdb/mnist, 1998",,,"ACM;IEEE","Institute of Electrical and Electronics Engineers Inc.","37th IEEE/ACM International Conference on Computer-Aided Design, ICCAD 2018","5 November 2018 through 8 November 2018",,142394,10923152,9781450359504,DICDF,,"English","IEEE ACM Int. Conf. Comput. Des. Dig. Tech. Pap. ICCAD",Conference Paper,"Final","All Open Access, Bronze, Green",Scopus,2-s2.0-85058155012
"Salem M., Taheri S., Yuan J.S.","57205624503;57194897616;57199894791;","Anomaly Generation Using Generative Adversarial Networks in Host-Based Intrusion Detection",2018,"2018 9th IEEE Annual Ubiquitous Computing, Electronics and Mobile Communication Conference, UEMCON 2018",,,"8796769","683","687",,11,"10.1109/UEMCON.2018.8796769","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071597538&doi=10.1109%2fUEMCON.2018.8796769&partnerID=40&md5=ae44557ba814883300c3f60faf27aac4","Dept of Computer Engineering, University of Central Florida, Orlando, FL, United States","Salem, M., Dept of Computer Engineering, University of Central Florida, Orlando, FL, United States; Taheri, S., Dept of Computer Engineering, University of Central Florida, Orlando, FL, United States; Yuan, J.S., Dept of Computer Engineering, University of Central Florida, Orlando, FL, United States","Generative adversarial networks have been able to generate striking results in various domains. This generation capability can be general while the networks gain deep understanding regarding the data distribution. In many domains, this data distribution consists of anomalies and normal data, with the anomalies commonly occurring relatively less, creating datasets that are imbalanced. The capabilities that generative adversarial networks offer can be leveraged to examine these anomalies and help alleviate the challenge that imbalanced datasets propose via creating synthetic anomalies. This anomaly generation can be specifically beneficial in domains that have costly data creation processes as well as inherently imbalanced datasets. One of the domains that fits this description is the host-based intrusion detection domain. In this work, ADFA-LD dataset is chosen as the dataset of interest containing system calls of small foot-print next generation attacks. The data is first converted into images, and then a Cycle-GAN is used to create images of anomalous data from images of normal data. The generated data is combined with the original dataset and is used to train a model to detect anomalies. By doing so, it is shown that the classification results are improved, with the AUC rising from 0.55 to 0.71, and the anomaly detection rate rising from 17.07% to 80.49%. The results are also compared to SMOTE, showing the potential presented by generative adversarial networks in anomaly generation. © 2018 IEEE.","Anomaly Generation; Cycle-GAN; Generative Adversarial Networks; Host-based intrusion detection system (HIDS); Low foot print attacks","Intrusion detection; Mobile telecommunication systems; Ubiquitous computing; Adversarial networks; Anomaly Generation; Cycle-GAN; Host-based intrusion detection system; Low foot print attacks; Anomaly detection",,,,,"Goodfellow, I.J., (2014) Generative Adversarial Networks, , Jun; Fiore, U., De Santis, A., Perla, F., Zanetti, P., Palmieri, F., Using generative adversarial networks for improving classification effectiveness in credit card fraud detection (2017) Inf. Sci. (Ny), , Dec; Douzas, G., Bacao, F., Effective data generation for imbalanced learning using conditional generative adversarial networks (2018) Expert Syst. Appl, 91, pp. 464-471. , Jan; Hu, J., Host-based anomaly intrusion detection (2010) Handbook of Information and Communication Security, pp. 235-255. , Berlin, Heidelberg: Springer Berlin Heidelberg; Haider, W., Hu, J., Yu, X., Xie, Y., Integer data zero-watermark assisted system calls abstraction and normalization for host based anomaly detection systems (2015) 2015 IEEE 2nd International Conference on Cyber Security and Cloud Computing, pp. 349-355; Creech, G., Hu, J., Generation of a new IDS test dataset: Time to retire the KDD collection (2013) 2013 IEEE Wireless Communications and Networking Conference (WCNC), pp. 4487-4492; Creech, G., Hu, J., (2014) Developing A High-accuracy Cross Platform Host-Based Intrusion Detection System Capable of Reliably Detecting Zero-day Attacks, , PhD thesis, Univ. New South Wales; Zhu, J.-Y., Park, T., Isola, P., Efros, A.A., (2017) Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks, , Mar; An Implementation of CycleGan Using TensorFlow, , https://github.com/vanhuyz/CycleGAN-TensorFlow, [Accessed: 09-Aug-2018]",,"Chakrabarti S.Saha H.N.","Columbia University;IEEE New York Section;IEEE Region 1;IEEE USA;Institute of Engineering and Management (IEM);University of Engineering and Management (UEM)","Institute of Electrical and Electronics Engineers Inc.","9th IEEE Annual Ubiquitous Computing, Electronics and Mobile Communication Conference, UEMCON 2018","8 November 2018 through 10 November 2018",,150821,,9781538676936,,,"English","IEEE Annu. Ubiquitous Comput., Electron. Mob. Commun. Conf., UEMCON",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85071597538
"Matovu R., Serwadda A.","57193153070;56824295100;","Gaming the Gamer: Adversarial Fingerprinting of Gaming Apps using Smartphone Accelerometers",2018,"2018 9th IEEE Annual Ubiquitous Computing, Electronics and Mobile Communication Conference, UEMCON 2018",,,"8796715","489","496",,,"10.1109/UEMCON.2018.8796715","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071548151&doi=10.1109%2fUEMCON.2018.8796715&partnerID=40&md5=7b86ad42ee6e0e4592d67a88a8cc4dd7","Texas Tech University, Lubbock, TX  79409, United States","Matovu, R., Texas Tech University, Lubbock, TX  79409, United States; Serwadda, A., Texas Tech University, Lubbock, TX  79409, United States","A wide range of mobile applications continuously access motion and orientation sensor data to learn patterns for their operations. This unfeterred access to rich streams of data from multiple sensors raises the question of whether sensitive personal information might be inferred by these sensor-oriented applications. In this paper, we demonstrate a previously unexplored privacy threat that could be posed by a rogue background mobile app accessing sensor data on a smartphone. The core driving mechanism behind the attack is that the unique GUI components of different apps cause unique sensor data patterns during routine usage of the apps. This in turn makes it possible to fingerprint a specific app and identify it based on its associated sensor signature. Using the most popular mobile gaming apps as a case study, we show the attack to attain up to 75% in one attempt and about 93% in the three attempts. The paper further questions the idea of apps having access to motion and orientation sensor data without asking for permission from the end-users. © 2018 IEEE.","Accelerometer; Adversarial Fingerprinting; Gyroscope.","Accelerometers; Gyroscopes; Smartphones; Ubiquitous computing; Adversarial Fingerprinting; Driving mechanism; Mobile applications; Mobile gaming; Multiple sensors; Orientation sensors; Personal information; Privacy threats; Mobile telecommunication systems",,,,,"Kwapisz, J.R., Weiss, G.M., Moore, S.A., Activity recognition using cell phone accelerometers (2011) ACM SigKDD Explorations Newsletter, 12 (2), pp. 74-82; Anguita, D., Ghio, A., Oneto, L., Parra, X., Reyes-Ortiz, J.L., A public domain dataset for human activity recognition using smartphones (2013) ESANN; https://www.google.com/fit/, last accessed in August 2018 Google fit; (2018) Fitbit, , https://www.fitbit.com/; Roth, J., Liu, X., Metaxas, D., On continuous user authentication via typing behavior (2014) IEEE Transactions on Image Processing, 23 (10), pp. 4611-4624; Serwadda, A., Phoha, V.V., Poudel, S., Hirshfield, L.M., Bandara, D., Bratt, S.E., Costa, M.R., Fnirs: A new modality for brain activitybased biometric authentication (2015) Biometrics Theory, Applications and Systems (BTAS), 2015 IEEE 7th International Conference On. IEEE, pp. 1-7; Das, A., Borisov, N., Caesar, M., Tracking mobile web users through motion sensors: Attacks and defenses (2016) NDSS; Dey, S., Roy, N., Xu, W., Choudhury, R.R., Nelakuditi, S., Accelprint: Imperfections of accelerometers make smartphones trackable (2014) NDSS; Owusu, E., Han, J., Das, S., Perrig, A., Zhang, J., Accessory: Password inference using accelerometers on smartphones (2012) Proceedings of the Twelfth Workshop on Mobile Computing Systems & Applications. ACM, p. 9; Miluzzo, E., Varshavsky, A., Balakrishnan, S., Choudhury, R.R., Tapprints: Your finger taps have fingerprints (2012) Proceedings of the 10th International Conference on Mobile Systems, Applications, and Services. ACM, pp. 323-336; Your Phone's Motion Sensors Can Give Away Pins and Passwords, , https://www.engadget.com/2017/04/12/phone-motion-sensor-pinvulnerability/, last accessed in August 2018; Han, J., Owusu, E., Nguyen, L.T., Perrig, A., Zhang, J., Accomplice: Location inference using accelerometers on smartphones (2012) Communication Systems and Networks (COMSNETS), 2012 Fourth International Conference On. IEEE, pp. 1-9; Activitymanager-android Developers, , https://developer.android.com/reference/android/app/ActivityManager#getRecentTasks(int,%20int), last accessed in August 2018; Different Apps Are Used by Different Age Groups, , http://nicolebrashear.com/different-apps-are-used-by-different-age-groups/, last accessed in August 2018; Brain Games and Brain Training, , https://www.lumosity.com, last accessed in August 2018; Intent-Android Developers, , https://developer.android.com/reference/android/content/Intent.html, last accessed in August 2018; Google Play, , https://play.google.com/store, last accessed in August 2018; This is How Many Apps You're Really Using on Your Smartphone, , http://fortune.com/2015/09/24/apps-smartphone-facebook/, last accessed in August 2018; Kononenko, I., Simec, E., Robnik-Sikonja, M., Overcoming the myopia of inductive learning algorithms with relieff (1997) Applied Intelligence, 7 (1), pp. 39-55",,"Chakrabarti S.Saha H.N.","Columbia University;IEEE New York Section;IEEE Region 1;IEEE USA;Institute of Engineering and Management (IEM);University of Engineering and Management (UEM)","Institute of Electrical and Electronics Engineers Inc.","9th IEEE Annual Ubiquitous Computing, Electronics and Mobile Communication Conference, UEMCON 2018","8 November 2018 through 10 November 2018",,150821,,9781538676936,,,"English","IEEE Annu. Ubiquitous Comput., Electron. Mob. Commun. Conf., UEMCON",Conference Paper,"Final","",Scopus,2-s2.0-85071548151
"Yang D.Y., Xiong J., Li X., Yan X., Raiti J., Wang Y., Wu H., Zhong Z.","57210813942;57210814671;57193574443;57216093978;55225616200;53867328700;55649971900;57210822327;","Building Towards Invisible Cloak: Robust Physical Adversarial Attack on YOLO Object Detector",2018,"2018 9th IEEE Annual Ubiquitous Computing, Electronics and Mobile Communication Conference, UEMCON 2018",,,"8796670","368","374",,3,"10.1109/UEMCON.2018.8796670","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071522794&doi=10.1109%2fUEMCON.2018.8796670&partnerID=40&md5=8ffc20df53ef998b7913cc76a96b52e9","Global Innovation Exchange Institute, Tsinghua University, China; GIX, University of Washangton, Bellevue, WA, United States; Electrical Engineering, University of Washington, Seattle, WA, United States; Department of Microelectronics and Nanoelectronics, Tsinghua University, Beijing, China; X-Lab, Baidu USA, Sunnyvale, CA, United States","Yang, D.Y., Global Innovation Exchange Institute, Tsinghua University, China; Xiong, J., GIX, University of Washangton, Bellevue, WA, United States; Li, X., Global Innovation Exchange Institute, Tsinghua University, China; Yan, X., Global Innovation Exchange Institute, Tsinghua University, China; Raiti, J., Electrical Engineering, University of Washington, Seattle, WA, United States; Wang, Y., Global Innovation Exchange Institute, Tsinghua University, China; Wu, H., Department of Microelectronics and Nanoelectronics, Tsinghua University, Beijing, China; Zhong, Z., X-Lab, Baidu USA, Sunnyvale, CA, United States","Deep learning based object detection algorithms like R-CNN, SSD, YOLO have been applied to many scenarios, including video surveillance, autonomous vehicle, intelligent robotics et al. With more and more application and autonomy left to deep learning based artificial intelligence, humans want to ensure that the machine does the best for them under their control. However, deep learning algorithms are known to be vulnerable to carefully crafted input known as adversarial examples which makes it possible for an attacker to fool an AI system. In this work, we explored the mechanism behind the YOLO object detector and proposed an optimization method to craft adversarial examples to attack the YOLO model. The experiment shows that this white box attack method is effective and has a success rate of 100% in crafting digital adversarial examples to fool the YOLO model. We also proposed a robust physical adversarial sticker generation method based on an extended Expectation Over Transformation (EOT) method(a method to craft adversarial example in the physical world). We conduct experiments to find the most effective approach to generate adversarial stickers. We tested the stickers both digitally as a watermark and physically showing it on an electronic screen on the front surface of a person. Our result shows that the sticker attack as a watermark has a success rate of 90% and 45% on photos taken indoors and on random 318 pictures from ImageNet. Our physical attack also has a success rate of 72% on photos taken indoors. We shared our project source code on the Github and our work is reproducible. © 2018 IEEE.","Adversarial Example; Artificial Intelligence; Neural network; Object Detector; Physical Attack; Security","Artificial intelligence; Deep learning; Learning algorithms; Mobile telecommunication systems; Neural networks; Security systems; Ubiquitous computing; Adversarial Example; Effective approaches; Intelligent robotics; Object detection algorithms; Object detectors; Optimization method; Physical attacks; Security; Object detection",,,,,"Athalye, A., Engstrom, L., Ilyas, A., Kwok, K., Synthesizing Robust Adversarial Examples; Carlini, N., David, W., Towards Evaluating the Robustness of Neural Networks.; Chen, S., Cornelius, C., Martin, J., Horng Chau, D., Robust Physical Adversarial Attack on Faster R-CNN Object Detector; Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Xiao, C., Prakash, A., Song, D., Robust Physical-world Attacks on Deep Learning Models; Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Song, D., Kohno, T., Rahmati, A., Tramer, F., Note on Attacking Object Detectors with Adversarial Stickers; Girshick, R., Donahue, J., Darrell, T., Malik, J., Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and Harnessing Adversarial Examples; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial Examples in the Physical World; Liu, J., Yu, F., Funkhouser, T., Interactive 3d Modeling with A Generative Adversarial Network; Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., Fu, C., Berg, A.C., SSD: Single Shot MultiBox Detector, 9905, pp. 21-37; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical Black-box Attacks Against Machine Learning; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., The Limitations of Deep Learning in Adversarial Settings; Redmon, J., Divvala, S., Girshick, R., Farhadi, A., You only Look Once: Unified, Real-time Object Detection; Ren, S., He, K., Girshick, R., Sun, J., Faster R-CNN: Towards Real-time Object Detection with Region Proposal Networks; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security-CCS'16, pp. 1528-1540. , ACM Press; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Adversarial Generative Nets: Neural Network Attacks on State-of-the-art Face Recognition",,"Chakrabarti S.Saha H.N.","Columbia University;IEEE New York Section;IEEE Region 1;IEEE USA;Institute of Engineering and Management (IEM);University of Engineering and Management (UEM)","Institute of Electrical and Electronics Engineers Inc.","9th IEEE Annual Ubiquitous Computing, Electronics and Mobile Communication Conference, UEMCON 2018","8 November 2018 through 10 November 2018",,150821,,9781538676936,,,"English","IEEE Annu. Ubiquitous Comput., Electron. Mob. Commun. Conf., UEMCON",Conference Paper,"Final","",Scopus,2-s2.0-85071522794
"Gérault D., Lafourcade P., Minier M., Solnon C.","57164065200;8985736300;23028425100;8727556200;","Revisiting AES related-key differential attacks with constraint programming",2018,"Information Processing Letters","139",,,"24","29",,16,"10.1016/j.ipl.2018.07.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049745245&doi=10.1016%2fj.ipl.2018.07.001&partnerID=40&md5=7ddc7286ea4ee19c1e7c22a97ff6bf47","Université Clermont Auvergne, LIMOS, UMR 6158F-63173, France; Université de Lorraine, LORIA, UMR 7503F-54506, France; Université de Lyon, INSA-Lyon, LIRIS, CNRS UMR5205F-69621, France","Gérault, D., Université Clermont Auvergne, LIMOS, UMR 6158F-63173, France; Lafourcade, P., Université Clermont Auvergne, LIMOS, UMR 6158F-63173, France; Minier, M., Université de Lorraine, LORIA, UMR 7503F-54506, France; Solnon, C., Université de Lyon, INSA-Lyon, LIRIS, CNRS UMR5205F-69621, France","The Advanced Encryption Standard (AES) is one of the most studied symmetric encryption schemes. During the last years, several attacks have been discovered in different adversarial models. In this paper, we focus on related-key differential attacks, where the adversary may introduce differences in plaintext pairs and also in keys. We show that Constraint Programming (CP) can be used to model these attacks, and that it allows us to efficiently find all optimal related-key differential characteristics for AES-128, AES-192 and AES-256. In particular, we improve the best related-key differential for the whole AES-256 and give the best related-key differential on 10 rounds of AES-192, which is the differential trail with the longest path. Those results allow us to improve existing related-key distinguishers, basic related-key attacks and q-multicollisions on AES-256. © 2018 Elsevier B.V.","AES; Analysis of algorithms; Constraint programming; Related-key attacks","Computer programming; Constraint theory; Data privacy; Advanced Encryption Standard; Analysis of algorithms; Constraint programming; Differential attacks; Differential characteristic; Multicollisions; Related key attacks; Symmetric encryption schemes; Cryptography",,,,,"Biham, E., New types of cryptoanalytic attacks using related keys (extended abstract) (1993) Advances in Cryptology, EUROCRYPT ‘93, LNCS, 765, pp. 398-409. , Springer; Knudsen, L.R., Rijmen, V., Known-key distinguishers for some block ciphers (2007) Advances in Cryptology, ASIACRYPT 2007, LNCS, 4833, pp. 315-324. , Springer; Fouque, P., Jean, J., Peyrin, T., Structural evaluation of AES and chosen-key distinguisher of 9-round AES-128 (2013) Advances in Cryptology, CRYPTO 2013, Part I, LNCS, 8042, pp. 183-203. , Springer; Biryukov, A., Khovratovich, D., Nikolic, I., Distinguisher and related-key attack on the full AES-256 (2009) Advances in Cryptology, CRYPTO 2009, LNCS, 5677, pp. 231-249. , Springer; Gerault, D., Minier, M., Solnon, C., Constraint programming models for chosen key differential cryptanalysis (2016) Principles and Practice of Constraint Programming, CP 2016, LNCS, 9892, pp. 584-601. , Springer; Kim, J., Hong, S., Preneel, B., Related-key rectangle attacks on reduced AES-192 and AES-256 (2007) Fast Software Encryption, FSE 2007, LNCS, 4593, pp. 225-241. , Springer; Biryukov, A., Khovratovich, D., Related-key cryptanalysis of the full AES-192 and AES-256 (2009) Advances in Cryptology, ASIACRYPT 2009, LNCS, 5912, pp. 1-18. , Springer; Biham, E., Shamir, A., Differential cryptoanalysis of Feal and N-hash (1991) Advances in Cryptology, EUROCRYPT ‘91, LNCS, 547, pp. 1-16. , Springer; Biryukov, A., Nikolic, I., Automatic search for related-key differential characteristics in byte-oriented block ciphers: application to aes, camellia, Khazad and others (2010) Advances in Cryptology, EUROCRYPT 2010, LNCS, 6110, pp. 322-344. , Springer; Gérault, D., Lafourcade, P., Minier, M., Solnon, C., Revisiting aes related-key differential attacks with constraint programming (2017), http://eprint.iacr.org/2017/139, Cryptology ePrint Archive, Report 2017/139; Gerault, D., Lafourcade, P., Minier, M., Solnon, C., Combining solvers to solve a cryptanalytic problem (2017), http://www.gerault.net/CP17_DP.pdf, CP/ICLP/SAT Doctoral Program – part of the conference CP 2017, available at; Nicolic, I., Cryptanalysis and Design of Symmetric Primitives (2011), Ph.D. thesis University of Luxembourg Luxembourg, Luxembourg","Minier, M.; Université de Lorraine, France; email: Marine.Minier@loria.fr",,,"Elsevier B.V.",,,,,00200190,,IFPLA,,"English","Inf. Process. Lett.",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85049745245
"Zhang R., Zhu Q.","57164157500;24767254400;","A Game-Theoretic Approach to Design Secure and Resilient Distributed Support Vector Machines",2018,"IEEE Transactions on Neural Networks and Learning Systems","29","11","8307266","5512","5527",,17,"10.1109/TNNLS.2018.2802721","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043359654&doi=10.1109%2fTNNLS.2018.2802721&partnerID=40&md5=b48f74e6376151c2f4b2ccb5922370fe","Department of Electrical and Computer Engineering, New York University, Brooklyn, NY  11201, United States","Zhang, R., Department of Electrical and Computer Engineering, New York University, Brooklyn, NY  11201, United States; Zhu, Q., Department of Electrical and Computer Engineering, New York University, Brooklyn, NY  11201, United States","Distributed support vector machines (DSVMs) have been developed to solve large-scale classification problems in networked systems with a large number of sensors and control units. However, the systems become more vulnerable, as detection and defense are increasingly difficult and expensive. This paper aims to develop secure and resilient DSVM algorithms under adversarial environments in which an attacker can manipulate the training data to achieve his objective. We establish a game-theoretic framework to capture the conflicting interests between an adversary and a set of distributed data processing units. The Nash equilibrium of the game allows predicting the outcome of learning algorithms in adversarial environments and enhancing the resilience of the machine learning through dynamic distributed learning algorithms. We prove that the convergence of the distributed algorithm is guaranteed without assumptions on the training data or network topologies. Numerical experiments are conducted to corroborate the results. We show that the network topology plays an important role in the security of DSVM. Networks with fewer nodes and higher average degrees are more secure. Moreover, a balanced network is found to be less vulnerable to attacks. © 2012 IEEE.","Adversarial machine learning; distributed support vector machines (DSVMs); game theory; networked systems; resilience; security","Artificial intelligence; Game theory; Heuristic algorithms; Learning systems; Network security; Networked control systems; Personnel training; Support vector machines; Topology; Vectors; distributed support vector machines (DSVMs); Games; Networked systems; resilience; Security; Training data; Learning algorithms",,,,,"Zhang, R., Zhu, Q., Secure and resilient distributed machine learning under adversarial environments (2015) Proc. 18th Int. Conf. Inf. Fusion, pp. 644-651. , Jul; Suykens, J.A.K., Vandewalle, J., Least squares support vector machine classifiers (1999) Neural Process. Lett., 9 (3), pp. 293-300. , Jun; Sculley, D., Wachman, G.M., Relaxed online SVMs for spam filtering (2007) Proc. 30th Annu. Int. ACM SIGIR Conf. Res. Develop. Inf. Retr., pp. 415-422; Osuna, E., Freund, R., Girosi, F., Training support vector machines: An application to face detection (1997) Proc. IEEE Comput. Vis. Pattern Recognit., Jun., pp. 130-136; Radhika, Y., Shashi, M., Atmospheric temperature prediction using support vector machines (2009) Int. J. Comput. Theory Eng., 1 (1), pp. 1793-1801; Barreno, M., Nelson, B., Joseph, A.D., Tygar, J.D., The security of machine learning (2010) Mach. Learn., 81 (2), pp. 121-148; Nelson, B., Misleading learners: Co-opting your spam filter (2009) Machine Learning in Cyber Trust, pp. 17-51. , Boston, MA, USA: Springer; Brückner, M., Scheffer, T., Nash equilibria of static prediction games (2009) Proc. Adv. Neural Inf. Process. Syst., pp. 171-179; Brückner, M., Scheffer, T., Stackelberg games for adversarial prediction problems (2011) Proc. 17th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, pp. 547-555; Erdogmus, N., Marcel, S., Spoofing in 2d face recognition with 3D masks and anti-spoofing with Kinect (2013) Proc. IEEE 6th Int. Conf. Biometrics, Theory, Appl. Syst. (BTAS), Oct., pp. 1-6; Flouri, K., Beferull-Lozano, B., Tsakalides, P., Training a SVM-based classifier in distributed sensor networks (2006) Proc. 14th Eur. Signal Process. Conf., pp. 1-5; Tsang, I.W., Kwok, J.T., Cheung, P.-M., Core vector machines: Fast SVM training on very large data sets (2005) J. Mach. Learn. Res., 6, pp. 363-392. , Apr; Papadonikolakis, M., Bouganis, C.-S., Novel cascade FPGA accelerator for support vector machines classification (2012) IEEE Trans. Neural Netw. Learn. Syst., 23 (7), pp. 1040-1052. , Jul; Do, T.-N., Poulet, F., Classifying one billion data with a new distributed SVM algorithm (2006) Proc. RIVF, pp. 59-66; Meligy, A., Al-Khatib, M., A grid-based distributed SVM data mining algorithm (2009) Eur. J. Sci. Res., 27 (3), pp. 313-321; Kavitha, T., Sridharan, D., Security vulnerabilities in wireless sensor networks: A survey (2010) J. Inf. Assurance Security, 5 (1), pp. 31-44; Wang, L., Singhal, A., Jajodia, S., Toward measuring network security using attack graphs (2007) Proc. ACM Workshop Quality Protection, pp. 49-54; Anderson, R., Why information security is hard-an economic perspective (2001) Proc. 17th Annu. Comput. Security Appl. Conf. (ACSAC), pp. 358-365; Forero, P.A., Cano, A., Giannakis, G.B., Consensus-based distributed support vector machines (2010) J. Mach. Learn. Res., 11, pp. 1663-1707. , Jan; Frénay, B., Verleysen, M., Classification in the presence of label noise: A survey (2014) IEEE Trans. Neural Netw. Learn. Syst., 25 (5), pp. 845-869. , May; Moreno-Torres, J.G., Raeder, T., Alaiz-Rodríguez, R., Chawla, N.V., Herrera, F., A unifying view on dataset shift in classification (2012) Pattern Recognit., 45 (1), pp. 521-530; Mei, S., Zhu, X., Using machine teaching to identify optimal training-set attacks on machine learners (2015) Proc. 29th AAAI Conf. Artif. Intell., pp. 2871-2877; Rndic, N., Laskov, P., Practical evasion of a learning-based classifier: A case study (2014) Proc. IEEE Symp. Security Privacy (SP), May, pp. 197-211; Communication theory of secrecy systems (1949) Bell Labs Tech. J., 28 (4), pp. 656-715. , C. E, Shannon, Oct; Eckstein, J., Yao, W., Augmented Lagrangian and alternating direction methods for convex optimization: A tutorial and some illustrative computational results (2012) RUTCOR, Res. Rep., 32, p. 3; Dalvi, N., Adversarial classification (2004) Proc. 10th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, pp. 99-108; Kantarcioglu, M., Xi, B., Clifton, C., Classifier evaluation and attribute selection against active adversaries (2011) Data Mining Knowl. Discovery, 22 (1-2), pp. 291-335; Rota, B.S., Biggio, B., Pillai, I., Pelillo, M., Roli, F., Randomized prediction games for adversarial machine learning (2017) IEEE Trans. Neural Netw. Learn. Syst., 28 (11), pp. 2466-2478. , Nov; Lye, K.-W., Wing, J.M., Game strategies in network security (2005) Int. J. Inf. Secur., 4 (1-2), pp. 71-86; Michiardi, P., Molva, R., Game theoretic analysis of security in mobile ad hoc networks (2002) Inst. Eurécom, Biot, France, Tech. Rep, , Apr; Boyd, S., Parikh, N., Chu, E., Peleato, B., Eckstein, J., Distributed optimization and statistical learning via the alternating direction method of multipliers (2011) Found. Trends Mach. Learn., 3 (1), pp. 1-122. , Jan; Frank, A., Asuncion, A., (2010) UCI Machine Learning Repository, , School Inf. Comput. Sci., University of California, Berkeley, Berkeley, CA, USA, Tech. Rep. 213; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324. , Nov; Moreno-Torres, J.G., Sáez, J.A., Herrera, F., Study on the impact of partition-induced dataset shift on k-fold cross-validation (2012) IEEE Trans. Neural Netw. Learn. Syst., 23 (8), pp. 1304-1312. , Aug; Davtalab, R., Dezfoulian, M.H., Mansoorizadeh, M., Multi-level fuzzy min-max neural network classifier (2014) IEEE Trans. Neural Netw. Learn. Syst., 25 (3), pp. 470-482. , Mar; Shao, L., Wu, D., Li, X., Learning deep and wide: A spectral method for learning deep networks (2014) IEEE Trans. Neural Netw. Learn. Syst., 25 (12), pp. 2303-2308. , Dec; Tang, J., Deng, C., Huang, G.-B., Extreme learning machine for multilayer perceptron (2016) IEEE Trans. Neural Netw. Learn. Syst., 27 (4), pp. 809-821. , Apr; Chang, X., Yu, Y.-L., Yang, Y., Xing, E.P., Semantic pooling for complex event analysis in untrimmed videos (2017) IEEE Trans. Pattern Anal. Mach. Intell., 39 (8), pp. 1617-1632. , Aug; Yan, Y., Nie, F., Li, W., Gao, C., Yang, Y., Xu, D., Image classification by cross-media active learning with privileged information (2016) IEEE Trans. Multimedia, 18 (12), pp. 2494-2502. , Dec; Li, W., Duan, L., Xu, D., Tsang, I.W., Learning with augmented features for supervised and semi-supervised heterogeneous domain adaptation (2013) IEEE Trans. Pattern Anal. Mach. Intell., 36 (6), pp. 1134-1148. , Jun; Duan, L., Xu, D., Tsang, I.W.-H., Luo, J., Visual event recognition in videos by learning from Web data (2012) IEEE Trans. Pattern Anal. Mach. Intell., 34 (9), pp. 1667-1680. , Sep; Duan, L., Xu, D., Tsang, I.W., Domain adaptation from multiple sources: A domain-dependent regularization approach (2012) IEEE Trans. Neural Netw. Learn. Syst., 23 (3), pp. 504-518. , Mar; Duan, L., Tsang, I.W., Xu, D., Domain transfer multiple kernel learning (2012) IEEE Trans. Pattern Anal. Mach. Intell., 34 (3), pp. 465-479. , Mar; Xu, H., Caramanis, C., Mannor, S., Robustness and regularization of support vector machines (2009) J. Mach. Learn. Res., 10, pp. 1485-1510. , Jul; Nikaido, H., On von neumann's minimax theorem (1954) Pacific J. Math., 4, pp. 65-72. , Apr; Basar, T., Olsder, G.J., (1999) Dynamic Noncooperative Game Theory, 23. , Philadelphia, PA, USA: SIAM","Zhang, R.; Department of Electrical and Computer Engineering, United States; email: rz885@nyu.edu",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,2162237X,,,"29993612","English","IEEE Trans. Neural Networks Learn. Sys.",Article,"Final","All Open Access, Bronze, Green",Scopus,2-s2.0-85043359654
"G. Quijano E., Ríos Insua D., Cano J.","57192557829;55665270900;57191681162;","Critical networked infrastructure protection from adversaries",2018,"Reliability Engineering and System Safety","179",,,"27","36",,8,"10.1016/j.ress.2016.10.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006810398&doi=10.1016%2fj.ress.2016.10.015&partnerID=40&md5=8c737f9b02c714b1bd8e2d5397313b56","Department of Computer Science and Statistics, Rey Juan Carlos University, Camino del Molino s/n, Office B107, Fuenlabrada, Madrid  28943, Spain; Instituto de Ciencias Matemáticas, ICMAT-CSIC, Spain","G. Quijano, E., Department of Computer Science and Statistics, Rey Juan Carlos University, Camino del Molino s/n, Office B107, Fuenlabrada, Madrid  28943, Spain; Ríos Insua, D., Instituto de Ciencias Matemáticas, ICMAT-CSIC, Spain; Cano, J., Department of Computer Science and Statistics, Rey Juan Carlos University, Camino del Molino s/n, Office B107, Fuenlabrada, Madrid  28943, Spain","We use the adversarial risk analysis (ARA) framework to deal with the protection of a critical networked infrastructure from the attacks of intelligent adversaries. We deploy an ARA model for each relevant element (node, link, hotspot in link) in the network, using a Sequential Defend–Attack–Defend template as a reference. Such ARA models are related by resource constraints and result aggregation over various sites, for both the Defender and the Attacker. As a case study, we consider the protection of a section of the Spanish railway network from a potential terrorist attack. © 2016 Elsevier Ltd","Adversarial risk analysis; Critical infrastructure protection; Network; Railway transport; Sequential Defend–Attack–Defend model","Networks (circuits); Railroads; Risk analysis; Risk assessment; Terrorism; Adversarial risk analysis; Critical infrastructure protection; Hot spot; Infrastructure protection; Potential terrorist; Railway network; Railway transport; Resource Constraint; Critical infrastructures",,,,,"http://www3.weforum.org/docs/WEF_Global_Risks_2015_Report15.pdf; Ezell, B.C., Bennett, S.P., von Winterfeldt, D., Sokolowski, J., Collins, A.J., Probabilistic risk analysis and terrorism risk (2010) Risk Anal, 30 (4), pp. 575-589; Wein, L.M., Forum-Homeland, O.R., Security: from mathematical models to policy implementation (2009) Oper Res, 57 (4), pp. 801-811; Lewis, T.G., Critical infrastructure protection in homeland security: defending a networked nation (2006), John Wiley & Sons New Jersey; Brown, G., Carlyle, M., Salmerón, J., Wood, K., Defending critical infrastructure (2006) Interfaces, 36 (6), pp. 530-544; Haimes, Y., Longstaff, T., The role of risk analysis in the protection of critical infrastructures against terrorism (2002) Risk Anal, 22 (3), pp. 439-444; Enders, W., Sandler, T., The political economy of terrorism (2011), 2nd edition Cambridge University Press New York; (2007), http://dx.doi.org/10.17226/11836., Interim Report on Methodological Improvements to the Department of Homeland Security's Biological Agent Risk Analysis. Washington, DC: The National Academies Press; Hausken, K., Zhuang, J., Governments’ and terrorists’ defense and attack in a T-period game (2011) Decis Anal, 8 (1), pp. 46-70; Shan, X., Zhuang, J., Subsidizing to disrupt a terrorism supply chain–a four-player game (2014) J Oper Res Soc, 65 (7), pp. 1108-1119; Hargreaves-Heap, S.P., Varoufakis, Y., Game theory: a critical introduction (2004), 2nd edition Routledge London; Ríos Insua, D., Ríos, J., Banks, D., Adversarial risk analysis (2009) J Am Stat Assoc, 104 (486), pp. 841-854; Hausken, K., Levitin, G., Review of systems defense and attack models (2012) Int J Perform Eng, 8 (4), pp. 355-366; Dziubiński, M., Goyal, S., Network design and defence (2013) Game Econ Behav, 79, pp. 30-43; Parnell, G.S., Smith, C.M., Moxley, F.I., Intelligent adversary risk analysis: a bioterrorism risk management model (2010) Risk Anal, 30 (1), pp. 32-48; Ríos, J., Ríos Insua, D., Adversarial risk analysis for counterterrorism modeling (2012) Risk Anal, 32 (5), pp. 894-915; Haberfeld, M.R., (2009), von Hassell A. A New Understanding of terrorism: case studies, trajectories and lessons learned, humanities, social sciences and law. New York: Springer;; http://www.bbc.com/news/world-europe-34092544; Shachter, R.D., Evaluating influence diagrams (1986) Oper Res, 34 (6), pp. 871-882; Kleijnen, J.P.C., Sargent, R.G., A methodology for fitting and validating metamodels in simulation (2000) Eur J Oper Res, 120 (1), pp. 14-29; French, S., (2000), Ríos Insua D. Statistical decision theory. London: Arnold;; http://www.bbc.com/news/world-europe-14563948; http://www.bbc.com/news/world-europe-19091753; http://nypost.com/2014/09/26/spain-morocco-arrest-9-in-isis-terror-cell/; http://elpais.com/elpais/2015/06/30/inenglish/1435665322_643214.html; http://www.dailymail.co.uk/news/article-3223565/; Keeney, G.L., von Winterfeldt, D., Identifying and structuring the objectives of terrorists (2010) Risk Anal, 30 (12), pp. 1803-1816; Keeney, R.L., Modeling values for anti-terrorism analysis (2007) Risk Anal, 27 (3), pp. 585-596; Riera Font, A., Ripoll Penalva, A., Mateu Sbert, J., Estimación del valor estadístico de la vida en España: Una aplicación del método de salarios hedónicos (2007) Hacienda Pública Esp, 2 (181), pp. 29-48; Buesa Blanco, M., Valiño Castro, A., Heijs, J., Baumert, T., (2005), González Gómez J. Evaluación del coste directo de los atentados terroristas del 11-M para la economía de la Comunidad de Madrid. Documento de trabajo no. 51. Technical report. Instituto de Análisis Industrial y Financiero, UCM;; Dyer, J.S., Sarin, R.K., Relative risk aversion (1982) Manag Sci, 28 (8), pp. 875-886; Farquhar, P.H., State of the art—utility assessment methods (1984) Manag Sci, 30 (11), pp. 1283-1300; Viscusi, W.K., Aldy, J.E., The value of a statistical life: a critical review of market estimates throughout the world (2003) J Risk Uncertain, 27 (1), pp. 5-76; Viscusi, W.K., Valuing risks of death from terrorism and natural disasters (2009) J Risk Uncertain, 38 (3), pp. 191-213; Müller, P., Ríos Insua, D., Issues in Bayesian analysis of neural network models (1998) Neural Comput, 10 (3), pp. 749-770; Cybenko, G., Approximation by superpositions of a sigmoidal function (1989) Math Control Signals Syst, 2 (4), pp. 303-314; Goldberg, D.E., Genetic algorithms in search, optimization, and machine learning (1989), Addison-Wesley Reading, MA; Alpern, S., Morton, A., Papadaki, K., Patrolling games (2011) Oper Res, 59 (5), pp. 1246-1257; Brown, M., Saisubramanian, S., Varakantham, P.R., Tambe, M., (2014), STREETS: game-theoretic traffic patrolling with exploration and exploitation. In: Innovative applications in artificial intelligence (IAAI), twenty eighth AAAI conference on artificial intelligence, AAAI-14. Research Collection School of Information Systems, Québec, Canada;; Zoroa, N., Fernández-Sáez, M.J., Zoroa, P., Patrolling a perimeter (2012) Eur J Oper Res, 222 (3), pp. 571-582; Salmerón, J., Wood, K., Baldick, R., Analysis of electric grid security under terrorist threat (2004) IEEE Trans Power Syst, 19 (2), pp. 905-912; Holmgren, Å.J., Using graph models to analyze the vulnerability of electric power networks (2006) Risk Anal, 26 (4), pp. 955-969","Cano, J.; Department of Computer Science and Statistics, Camino del Molino s/n, Office B107, Spain; email: javier.cano@urjc.es",,,"Elsevier Ltd",,,,,09518320,,RESSE,,"English","Reliab Eng Syst Saf",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85006810398
"Miller D.J., Wang Y., Kesidis G.","55494841200;57204765980;7003540724;","Anomaly detection of attacks (ADA) on DNN classifiers at test time",2018,"IEEE International Workshop on Machine Learning for Signal Processing, MLSP","2018-September",,"8517069","","",,4,"10.1109/MLSP.2018.8517069","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057066178&doi=10.1109%2fMLSP.2018.8517069&partnerID=40&md5=a2bcb19fb3d0f91eb928741e0eafc740","School of EECS, Pennsylvania State University, University Park, PA  16802, United States","Miller, D.J., School of EECS, Pennsylvania State University, University Park, PA  16802, United States; Wang, Y., School of EECS, Pennsylvania State University, University Park, PA  16802, United States; Kesidis, G., School of EECS, Pennsylvania State University, University Park, PA  16802, United States","A significant threat to wide deployment of machine learning-based classifiers is adversarial learning attacks, especially at test-time. Recently there has been significant development in defending against such attacks. Several such works seek to robustify the classifier to make «correct» decisions on perturbed patterns. We argue it is often operationally more important to detect the attack, rather than to «correctly classify» in the face of it (Classification can proceed if no attack is detected). We hypothesize that, even if human-imperceptible, adversarial perturbations are machine-detectable. We propose a purely unsupervised anomaly detector (AD), based on suitable (null hypothesis) density models for the different layers of a deep neural net and a novel decision statistic built upon the Kullback-Leibler divergence. This paper addresses: 1) when is it appropriate to aim to «correctly classify» a perturbed pattern?; 2) What is a good AD detection statistic, one which exploits all likely sources of anomalousness associated with a test-time attack? 3) Where in a deep neural net (DNN) (in an early layer, a middle layer, or at the penultimate layer) will the most anomalous signature manifest? Tested on MNIST and CIFAR-10 image databases under three prominent attack strategies, our approach outperforms previous detection methods, achieving strong ROC AUC detection accuracy on two attacks and substantially better accuracy than previously reported on the third (strongest) attack. © 2018 IEEE.","Adversarial learning; Anomaly detection; Deep neural networks; Kullback-Leibler divergence; Test-time attacks","Neural networks; Signal processing; Adversarial learning; Anomaly detection; Attack strategies; Decision statistics; Detection accuracy; Detection statistic; Kullback Leibler divergence; Test time; Deep neural networks",,,,,"Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I.P., Tygar, J.D., Adversarial machine learning (2011) Proc. 4th ACM Workshop on Artificial Intelligence and Security (AISec); Miller, B., Kantchelian, A., Afroz, S., Bachwani, R., Dauber, E., Huang, L., Tschantz, M.C., Tygar, J.D., Adversarial active learning (2014) Proc. Workshop on Artificial Intelligence and Security (AISec); Xiao, H., Biggio, B., Nelson, B., Xiao, H., Eckert, C., Roli, F., Support vector machines under adversarial label contamination (2015) Neurocomputing, 160 (C), pp. 53-62. , July; Tamer, F., Zhang, F., Juels, A., Reiter, M., Ristenpart, T., Stealing machine learning models via prediction apis (2016) USENIX Security Symp; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Proc. 1st IEEE European Symp. on S&P; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR; Carlini, N., Mishra, P., Vaidya, T., Zhang, Y., Sherr, M., Shields, C., Wagner, D., Zhou, W., Hidden voice commands (2016) Proc. 25th USENIX Security Symp., , Austin, TX. Aug; Miller, D.J., Hu, X., Qiu, Z., Kesidis, G., Adversarial learning: A critical review and active learning study (2017) Proc. IEEE MLSP, , Tokyo, Sept; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symp. on S&P; Papernot, N., Practical black-box attacks against machine learning (2017) ACM Asia Conference on Computer and Communications Security; Demontis, A., Melis, M., Biggio, B., Maiorca, D., Arp, D., Rieck, K., Corona, I., Roli, F., (2017) Yes, Machine Learning Can Be More Secure! A Case Study on Android Malware Detection, , https://arxiv.org/abs/1704.08996, Apr. 28; Wang, Q., Guo, W., Zhang, K., Ororbia, A., Xing, X., Giles, L., Liu, X., Adversary resistant deep neural networks with an application to malware detection (2017) KDD; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) IEEE Symp. on Security and Privacy; Feinman, R., Curtin, R., Shintre, S., Gardner, A., (2017) Detecting Adversarial Samples from Artifacts, , https://arxiv.org/abs/1703.00410v2, Mar. 1; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., On detecting adversarial perturbations (2017) Proc. Int'l Conf. on Learning Representations (ICLR); Grosse, K., Manoharan, P., Papernot, N., Backes, M., Mc-Daniel, P., (2017) On the (Statistical) Detection of Adversarial Examples, , https://arxiv.org/abs/1702.06280, Feb. 21; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection method (2017) Proc. ACM AISec, Dallas, , Nov; Miller, D.J., Wang, Y., Kesidis, G., (2017) When Not to Classify: Anomaly Detection of Attacks (ADA) on DNN Classifiers at Test Time, , http://arxiv.org/abs/1712.06646, Dec. 18; LeCun, Y., Cortes, C., Burges, C.J.C., The MNIST Database of Handwritten Digits, , http://yann.lecun.com/exdb/mnist/; The CIFAR-10 Dataset, , https://www.cs.toronto.edu/kriz/cifar.html; Schwarz, G., Estimating the dimension of a model (1978) The Annals of Statistics, 6 (2), pp. 461-464; Qiu, Z., Miller, D.J., Kesidis, G., Semisupervised and active learning with unknown or label-scarce categories (2016) IEEE TNNLS, , Jan; LeNet-5, Convolutional Neural Networks, , http://yann.lecun.com/exdb/lenet/",,"Pustelnik N.Tan Z.-H.Ma Z.Larsen J.","IEEE Signal Processing Society","IEEE Computer Society","28th IEEE International Workshop on Machine Learning for Signal Processing, MLSP 2018","17 September 2018 through 20 September 2018",,141793,21610363,9781538654774,,,"English","IEEE Int. Workshop Mach. Learn. Signal Process., MLSP",Conference Paper,"Final","",Scopus,2-s2.0-85057066178
"Seo E., Song H.M., Kim H.K.","57203160008;57188867446;7410133266;","GIDS: GAN based Intrusion Detection System for In-Vehicle Network",2018,"2018 16th Annual Conference on Privacy, Security and Trust, PST 2018",,,"8514157","","",,92,"10.1109/PST.2018.8514157","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063514589&doi=10.1109%2fPST.2018.8514157&partnerID=40&md5=c2656d920b1aed548a04e0d6e4e2425e","Korea University, Seoul, South Korea","Seo, E., Korea University, Seoul, South Korea; Song, H.M., Korea University, Seoul, South Korea; Kim, H.K., Korea University, Seoul, South Korea","A Controller Area Network (CAN) bus in the vehicles is an efficient standard bus enabling communication between all Electronic Control Units (ECU). However, CAN bus is not enough to protect itself because of lack of security features. To detect suspicious network connections effectively, the intrusion detection system (IDS) is strongly required. Unlike the traditional IDS for Internet, there are small number of known attack signatures for vehicle networks. Also, IDS for vehicle requires high accuracy because any false-positive error can seriously affect the safety of the driver. To solve this problem, we propose a novel IDS model for in-vehicle networks, GIDS (GAN based Intrusion Detection System) using deep-learning model, Generative Adversarial Nets. GIDS can learn to detect unknown attacks using only normal data. As experiment result, GIDS shows high detection accuracy for four unknown attacks. © 2018 IEEE.","Controller Area Network; generative Adversarial Nets; in-vehicle security; intrusion detection System","Computer crime; Control system synthesis; Controllers; Deep learning; Intrusion detection; Process control; Vehicles; Controller area network; Controller area networkbus; Electronic control units; generative Adversarial Nets; In-vehicle networks; Intrusion Detection Systems; Network connection; Vehicle security; Network security",,,,,"Song, H.M., Kim, H.R., Kim, H.K., Intrusion detection system based on the analysis of time intervals of can messages for in-vehicle network (2016) Information Networking (ICOIN). 2016 International Conference On., pp. 63-68. , IEEE; Lee, H., Jeong, S.H., Kim, H.K., Otids: A Novel Intrusion Detection System for In-vehicle Network by Using Remote Frame; Hoppe, T., Kiltz, S., Dittmann, J., Security threats to automotive can networks-practical examples and selected short-Term countermeasures (2008) Computer Safety, Reliability, and Security, pp. 235-248; Müter, M., Asaj, N., Entropy-based anomaly detection for in-vehicle networks (2011) Intelligent Vehicles Symposium (IV). 2011 IEEE, pp. 1110-1115. , IEEE; Marchetti, M., Stabili, D., Anomaly detection of can bus messages through analysis of sequences (2017) Intelligent Vehicles Symposium (IV). 2017 IEEE, pp. 1577-1583. , IEEE; Salman, N., Bresch, M., Design and Implementation of An Intrusion Detection System (Ids) for In-vehicle Networks; Zhang, M., Xu, B., Bai, S., Lu, S., Lin, Z., A deep learning method to detect web attacks using a specially designed cnn (2017) International Conference on Neural Information Processing., pp. 828-836. , Springer; Schlegl, T., Seeböck, P., Waldstein, S.M., Schmidt-Erfurth, U., Langs, G., Unsupervised anomaly detection with generative adversarial networks to guide marker discovery (2017) International Conference on Information Processing in Medical Imaging., pp. 146-157. , Springer; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, pp. 2672-2680",,"Deng R.H.Marsh S.Nurse J.Lu R.Sezer S.Miller P.Chen L.McLaughlin K.Ghorbani A.","IEEE","Institute of Electrical and Electronics Engineers Inc.","16th Annual Conference on Privacy, Security and Trust, PST 2018","28 August 2018 through 30 August 2018",,141864,,9781538674932,,,"English","Annu. Conf. Priv., Secur. Trust, PST",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85063514589
"Qiao Z., Dong M., Ota K., Wu J.","57204809378;25822274100;23467341400;56190095000;","Toward Intelligent Detection Modelling for Adversarial Samples in Convolutional Neural Networks",2018,"IEEE International Workshop on Computer Aided Modeling and Design of Communication Links and Networks, CAMAD","2018-September",,"8514982","","",,3,"10.1109/CAMAD.2018.8514982","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057252247&doi=10.1109%2fCAMAD.2018.8514982&partnerID=40&md5=66e9d5c48268e3dad89f0095b5fd8c15","School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Information and Electronic Engineering, Muroran Institute of Technology, Muroran, Japan","Qiao, Z., School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; Dong, M., Department of Information and Electronic Engineering, Muroran Institute of Technology, Muroran, Japan; Ota, K., Department of Information and Electronic Engineering, Muroran Institute of Technology, Muroran, Japan; Wu, J., School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China","Deep Neural Networks (DNNs) are hierarchical nonlinear architectures that have been widely used in artificial intelligence applications. However, these models are vulnerable to adversarial perturbations which add changes slightly and are crafted explicitly to fool the model. Such attacks will cause the neural network to completely change its classification of data. Although various defense strategies have been proposed, existing defense methods have two limitations. First, the discovery success rate is not very high. Second, existing methods depend on the output of a particular layer in a specific learning structure. In this paper, we propose a powerful method for adversarial samples using Large Margin Cosine Estimate(LMCE). By iteratively calculating the large-margin cosine uncertainty estimates between the model predictions, the results can be regarded as a novel measurement of model uncertainty estimation and is available to detect adversarial samples by training using a simple machine learning algorithm. Comparing it with the way in which adversar- ial samples are generated, it is confirmed that this measurement can better distinguish hostile disturbances. We modeled deep neural network attacks and established defense mechanisms against various types of adversarial attacks. Classifier gets better performance than the baseline model. The approach is validated on a series of standard datasets including MNIST and CIFAR -10, outperforming previous ensemble method with strong statistical significance. Experiments indicate that our approach generalizes better across different architectures and attacks. © 2018 IEEE.","Adversarial samples; CNN attacks and detec- tion; Large Margin Cosine Estimate","Deep neural networks; Iterative methods; Learning algorithms; Machinery; Network architecture; Network security; Neural networks; Classification of data; CNN attacks and detec- tion; Convolutional neural network; Different architectures; Intelligent detection; Large margins; Statistical significance; Uncertainty estimates; Uncertainty analysis",,,,,"Akhtar, N., Liu, J., Mian, A., Defense against universal adversarial perturbations (2018) Proc. of 2018 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , Salt Lake City, Utah, USA; Amodei, D., Ananthanarayanan, S., Anubhai, R., Bai, J., Battenberg, E., Case, C., Casper, J., Chen, G., Deep speech 2: End-to-end speech recognition in english and Mandarin (2016) International Conference on Machine Learning, pp. 173-182; Bahdanau, D., Chorowski, J., Serdyuk, D., Brakel, P., Bengio, Y., Endto-end attention-based large vocabulary speech recognition (2016) Acoustics, Speech and Signal Processing (ICASSP), 2016 IEEE International Conference on, pp. 4945-4949. , IEEE; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Srndíc, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 387-402. , Springer; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Proc. of 38th IEEE Symposium on Security and Privacy (SP), pp. 39-57. , San Jose, CA. IEEE; Dahl, G.E., Yu, D., Deng, L., Acero, A., Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition (2012) IEEE Transactions on Audio, Speech, and Language Processing, 20 (1), pp. 30-42; Dong, Y., Liao, F., Pang, T., Hu, X., Zhu, J., Boosting adversarial examples with momentum (2018) Proc. of 2018 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , Salt Lake City, Utah, USA; Evtimov, I., Eykholt, K., Fernandes, E., Kohno, T., Li, B., Prakash, A., Rahmati, A., Song, D., (2017) Robust Physical-world Attacks on Machine Learning Models; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts; Gal, Y., Ghahramani, Z., Dropout as A Bayesian approximation: Representing model uncertainty in deep learning (2016) International Conference on Machine Learning, pp. 1050-1059. , New York City, NY, USA; Gao, J., Wang, B., Qi, Y., Deepcloak: Masking deep neural network models for robustness against adversarial samples (2017) Proc. of Sixth International Conference on Learning Representations (ICLR) Workshop; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Proc. of Advances in Neural Information Processing Systems, 27. , NIPS; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) Proc. of International Conference on Learning Representations (ICLR), , San Diego, USA; Grosse, K., Papernot, N., Manoharan, P., Backes, M., McDaniel, P., (2016) Adversarial Perturbations Against Deep Neural Networks for Malware Classification; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2017) Proc. of 2017 International Conference on Learning Representations (ICLR), pp. 1378-1387. , Toulon, France; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial machine learning at scale (2017) Proc. of 2017 International Conference on Learning Representations (ICLR), , Toulon, France; LeCun, Y., Boser, B., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W., Jackel, L.D., Backpropagation applied to handwritten zip code recognition (1989) Neural Computation, 1 (4), pp. 541-551; Lee, J.A., Verleysen, M., Nonlinear dimensionality reduction (2007) Springer Science & Business Media; Li, X., Li, F., Adversarial examples detection in deep networks with convolutional filter statistics (2017) Proc. of 2017 International Conference on Computer Vision (ICCV), , Venice, Italy; McAllister, R., Gal, Y., Kendall, A., Van Der Wilk, M., Shah, A., Cipolla, R., Weller, A.V., Concrete problems for autonomous vehicle safety: Advantages of Bayesian deep learning (2017) Proc. of International Joint Conferences on Artificial Intelligence, , Inc., Melbourne, Australia; Meng, D., Chen, H., Magnet: A two-pronged defense against adversarial examples (2017) Proc. of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pp. 135-147. , Dallas, USA. ACM; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) Proc. of 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , Honolulu, Hawaii, USA; Moosavi Dezfooli, S.M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proc. of 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Number EPFL-CONF-218057, , Las Vegas, Nevada; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Proc. of IEEE European Symposium on Security and Privacy (EuroS&P), pp. 372-387. , Saarbrcken, Germany, 2016. IEEE; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as A defense to adversarial perturbations against deep neural networks (2016) Proc. of 2016 IEEE Symposium on Security and Privacy (SP), pp. 582-597. , SAN JOSE, CA. IEEE; Prakash, A., Moran, N., Garber, S., DiLillo, A., Storer, J., Protecting jpeg images against adversarial attacks (2018) Proc. of IEEE Data Compression Conference; Rasmussen, C., Williams, C., (2005) Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning) the MIT Press, , Cambridge, MA, USA; Samangouei, P., Kabkab, M., Chellappa, R., Defense-gan: Protecting classifiers against adversarial attacks using generative models (2018) Proc. of Sixth International Conference on Learning Representations (ICLR), , Vancouver, CA; Sankaranarayanan, S., Jain, A., Chellappa, R., Lim, S.-N., Regularizing deep networks using efficient layerwise adversarial training (2018) Proc. of 2018 AAAI Conference on Artificial Intelligence, , New Orleans, Louisiana, USA; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to A crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proc. of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540. , Vienna, Austria. ACM; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) Proc. of International Conference on Learning Representations (ICLR), , Banff, Canada; Wang, H., Wang, Y., Zhou, Z., Ji, X., Li, Z., Gong, D., Zhou, J., Liu, W., Cosface: Large margin cosine loss for deep face recognition (2018) Proc. of IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 5265-5274. , Salt Lake City, Utah, USA; Wu, J., Dong, M., Ota, K., Li, J., Guan, Z., Fcss: Fog computing based content-aware filtering for security services in information centric social networks IEEE Transactions on Emerging Topics in Computing, , in press; Wu, J., Dong, M., Ota, K., Li, J., Guan, Z., Big data analysis-based secure cluster management for optimized control plane in software-defined networks (2018) IEEE Transactions on Network and Service Management, 15 (1), pp. 27-38; Wu, J., Ota, K., Dong, M., Li, J., Wang, H., Big data analysis based security situational awareness for smart grid IEEE Transactions on Big Data, , in press; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A.L., Protecting jpeg images against adversarial attacks (2017) Proc. of 2017 International Conference on Computer Vision (ICCV), , Venice, Italy; Xu, W., Evans, D., Qi, Y., Feature squeezing: Detecting adversarial examples in deep neural networks (2018) Proc. of 2018 Network and Distributed Systems Security Symposium (NDSS), , San Diego, California",,,,"Institute of Electrical and Electronics Engineers Inc.","23rd IEEE International Workshop on Computer Aided Modeling and Design of Communication Links and Networks, CAMAD 2018","17 September 2018 through 19 September 2018",,141880,23784873,9781538661512,,,"English","IEEE Int. Workshop Comput. Aided Model. Des. Commun. Links Networks, CAMAD",Conference Paper,"Final","",Scopus,2-s2.0-85057252247
"Guo S., Wu M., Wang C.","56709114700;57190030064;55647141100;","Adversarial symbolic execution for detecting concurrency-related cache timing leaks",2018,"ESEC/FSE 2018 - Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering",,,,"377","388",,16,"10.1145/3236024.3236028","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056530498&doi=10.1145%2f3236024.3236028&partnerID=40&md5=62034e3099275022ef02baf41c606d93","Virginia Tech, Blacksburg, VA, United States; University of Southern California, Los Angeles, CA, United States","Guo, S., Virginia Tech, Blacksburg, VA, United States; Wu, M., Virginia Tech, Blacksburg, VA, United States; Wang, C., University of Southern California, Los Angeles, CA, United States","The timing characteristics of cache, a high-speed storage between the fast CPU and the slowmemory, may reveal sensitive information of a program, thus allowing an adversary to conduct side-channel attacks. Existing methods for detecting timing leaks either ignore cache all together or focus only on passive leaks generated by the program itself, without considering leaks that are made possible by concurrently running some other threads. In this work, we show that timing-leak-freedom is not a compositional property: A program that is not leaky when running alone may become leaky when interleaved with other threads. Thus, we develop a new method, named adversarial symbolic execution, to detect such leaks. It systematically explores both the feasible program paths and their interleavings while modeling the cache, and leverages an SMT solver to decide if there are timing leaks. We have implemented our method in LLVM and evaluated it on a set of real-world ciphers with 14,455 lines of C code in total. Our experiments demonstrate both the efficiency of our method and its effectiveness in detecting side-channel leaks. © 2018 Association for Computing Machinery.","cache; concurrency; Side-channel attack; symbolic execution; timing","C (programming language); Model checking; Timing circuits; cache; Compositional properties; concurrency; Interleavings; Sensitive informations; Symbolic execution; timing; Timing characteristics; Side channel attack",,,,,"https://botan.randombit.net/, Botan; https://www.psc.edu/hpn-ssh, High Performance SSH/SCP - HPN-SSH; https://gnupg.org/software/libgcrypt/index.html, Libgcrypt; http://www.libtom.net/LibTomCrypt/, LibTomCrypt; http://www.openssh.com/, OpenSSH; https://github.com/openssl/openssl/tree/OpenSSL-0-9-7-stable, OpenSSL; Agosta, G., Barenghi, A., Pelosi, G., A code morphing methodology to automate power analysis countermeasures (2012) ACM/IEEE Design Automation Conference, Pages 77-82; Antonopoulos, T., Gazzillo, P., Hicks, M., Koskinen, E., Terauchi, T., Wei, S., Decomposition instead of self-composition for proving the absence of timing channels (2017) ACM SIGPLAN Conference on Programming Language Design and Implementation, pp. 362-375; Aronis, S., Jonsson, B., Lang, M., Sagonas, K., Optimal dynamic partial order reduction with observers (2018) International Conference on Tools and Algorithms for Construction and Analysis of Systems, pp. 229-248; Bang, L., Aydin, A., Phan, Q., Pasareanu, C.S., Bultan, T., String analysis for side channels with segmented oracles. (2016) ACMSIGSOFT Symposium on Foundations of Software Engineering, pp. 193-204; Barthe, G., Kopf, B., Mauborgne, L., Ochoa, M., Leakage resilience against concurrent cache attacks (2014) International Conference on Principles of Security and Trust, pp. 140-158; Basu, T., Chattopadhyay, S., Testing cache side-channel leakage (2017) IEEE International Conference on Software Testing, Verification and Validation, pp. 51-60; Galip Bayrak, A., Regazzoni, F., Brisk, P., Standaert, F., Ienne, P., A first step towards automatic application of power analysis countermeasures (2011) ACM/IEEE Design Automation Conference, pp. 230-235; Bergan, T., Grossman, D., Ceze, L., Symbolic execution of multithreaded programs from arbitrary program contexts (2014) ACM SIGPLAN Conference on Object Oriented Programming, Systems, Languages, and Applications, pp. 491-506; Bloem, R., Gros, H., Iusupov, R., Konighofer, B., Mangard, S., Winter, J., Formal verification of masked hardware implementations in the presence of glitches (2018) Annual International Conference on the Theory and Applications of Cryptographic Techniques (EUROCRYPT), pp. 321-353; Blot, A., Yamamoto, M., Terauchi, T., Compositional synthesis of leakage resilient programs (2017) International Conference on Principles of Security and Trust, pp. 277-297; Brennan, T., Saha, S., Bultan, T., Symbolic path cost analysis for side-channel detection (2018) International Conference on Software Engineering, pp. 424-425; Bucur, S., Ureche, V., Zamfir, C., Candea, G., Parallel symbolic execution for automated real-world software testing (2011) European Conference on Computer Systems, pp. 183-198; Bultan, T., Yu, F., Alkhalaf, M., Aydin, A., (2017) String Analysis for Software Verification and Security, , Springer; Cadar, C., Dunbar, D., Dawson, R., Engler. klee: Unassisted and automatic generation of high-coverage tests for complex systems programs (2008) USENIX Symposium on Operating Systems Design and Implementation, pp. 209-224; Chattopadhyay, S., Directed automated memory performance testing (2017) International Conference on Tools and Algorithms for Construction and Analysis of Systems, pp. 38-55; Chattopadhyay, S., Beck, M., Rezine, A., Zeller, A., Quantifying the information leak in cache attacks via symbolic execution (2017) ACM-IEEE International Conference on Formal Methods and Models for System Design, pp. 25-35; Chen, J., Feng, Y., Dillig, I., Precise detection of side-channel vulnerabilities using quantitative cartesian hoare logic (2017) ACM SIGSAC Conference on Computer and Communications Security, pp. 875-890; Cheng, L., Yang, Z., Wang, C., Systematic reduction of gui test sequences (2017) IEEE/ACM International Conference on Automated Software Engineering, pp. 849-860; Chu, D., Jaffar, J., Maghareh, R., Precise cache timing analysis via symbolic execution (2016) IEEE Symposium on Real-Time and Embedded Technology and Applications, pp. 293-304; Ciortea, L., Zamfir, C., Bucur, S., Chipounov, V., Candea, G., Cloud9: A software testing service (2009) Operating Systems Review, 43 (4), pp. 5-10; Dellinger, M., Garyali, P., Ravindran, B., Chronos linux: A besteffort real-time multiprocessor linux kernel (2011) ACM/IEEE Design Automation Conference, pp. 474-479; Dhem, J., Koeune, F., Leroux, P., Mestre, P., Quisquater, J., Willems, J., A practical implementation of the timing attack (1998) International Conference on Smart Card Research and Applications, pp. 167-182; Dinu, D., Le Corre, Y., Khovratovich, D., Perrin, L., Grosschadl, J., Biryukov, A., Triathlon of lightweight block ciphers for the internet of things (2015) Cryptology, , ePrint Archive, Report 2015/209; Doychev, G., Feld, D., Kopf, B., Mauborgne, L., Reineke, J., Cacheaudit: A tool for the static analysis of cache side channels (2013) USENIX Security Symposium, pp. 431-446; Eldib, H., Wang, C., Synthesis of masking countermeasures against side channel attacks (2014) International Conference on Computer Aided Verification, pp. 114-130; Eldib, H., Wang, C., Schaumont, P., SMT-based verification of software countermeasures against side-channel attacks (2014) International Conference on Tools and Algorithms for Construction and Analysis of Systems, pp. 62-77; Eldib, H., Wang, C., Taha, M., Schaumont, P., Qms: Evaluating the side-channel resistance of masked software from source code (2014) ACM/IEEE Design Automation Conference, pp. 209:1-6; Eldib, H., Wu, M., Wang, C., Synthesis of fault-attack countermeasures for cryptographic circuits (2016) International Conference on Computer Aided Verification, pp. 343-363; Flanagan, C., Godefroid, P., Dynamic partial-order reduction for model checking software (2005) ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages, pp. 110-121; Gandolfi, K., Mourtel, C., Olivier, F., Electromagnetic analysis: Concrete results (2001) International Conference on Cryptographic Hardware and Embedded Systems, pp. 251-261; Genkin, D., Shamir, A., Tromer, E., Rsa key extraction via lowbandwidth acoustic cryptanalysis (2014) Annual International Cryptology Conference (CRYPTO), pp. 444-461; Gruss, D., Lettner, J., Schuster, F., Ohrimenko, O., Haller, I., Costa, M., Strong and efficient cache side-channel protection using hardware transactional memory (2017) USENIX Security Symposium, pp. 217-233; Guo, S., Kusano, M., ChaoWang, Conc-ise: Incremental symbolic execution of concurrent software (2016) IEEE/ACM International Conference on Automated Software Engineering, pp. 531-542; Guo, S., Kusano, M., Wang, C., Yang, Z., Gupta, A., Assertion guided symbolic execution of multithreaded programs (2015) ACM SIGSOFT Symposium on Foundations of Software Engineering, pp. 854-865; Guo, S., MengWu, ChaoWang, Symbolic execution of programmable logic controller code (2017) ACM SIGSOFT Symposium on Foundations of Software Engineering; Kahlon, V., Wang, C., Gupta, A., Monotonic partial order reduction: An optimal symbolic partial order reduction technique (2009) International Conference on Computer Aided Verification, pp. 398-413; Paul, C., Kocher, Timing attacks on implementations of diffie-hellman, rsa, dss, and other systems (1996) Annual International Cryptology Conference (CRYPTO), pp. 104-113; Kocher, P.C., Jaffe, J., Jun, B., Differential power analysis (1999) Annual International Cryptology Conference (CRYPTO), pp. 388-397; Kong, J., Aciicmez, O., Seifert, J., Zhou, H., Architecting against software cache-based side-channel attacks (2013) IEEE Trans. Computers, 62 (7), pp. 1276-1288; Kopf, B., Mauborgne, L., Ochoa, M., Automatic quantification of cache side-channels (2012) International Conference on Computer Aided Verification, pp. 564-580; Kusano, M., Wang, C., Assertion guided abstraction: A cooperative optimization for dynamic partial order reduction (2014) IEEE/ACM International Conference on Automated Software Engineering, pp. 175-186; Lattner, C., Adve, V.S., Llvm: A compilation framework for lifelong program analysis & transformation (2004) IEEE/ACM International Symposium on Code Generation and Optimization, pp. 75-88; Li, X., Mitra, T., Roychoudhury, A., Accurate timing analysis by modeling caches, speculation and their interaction (2003) ACM/IEEE Design Automation Conference, pp. 466-471; Li, Y., Suhendra, V., Liang, Y., Mitra, T., Roychoudhury, A., Timing analysis of concurrent programs running on shared cache multi-cores (2009) IEEE Real-Time Systems Symposium, pp. 57-67; Mangard, S., Oswald, E., Popp, T., (2007) Power Analysis Attacks -revealing the Secrets of Smart Cards; Mitra, T., Teich, J., Thiele, L., Time-critical systems design: A survey (2018) IEEE Design & Test, 35 (2), pp. 8-26; Moss, A., Oswald, E., Page, D., Tunstall, M., Compiler assisted masking (2012) International Conference on Cryptographic Hardware and Embedded Systems, pp. 58-75; De Mulder, E., Eisenbarth, T., Schaumont, P., Identifying and eliminating side-channel leaks in programmable systems (2018) IEEE Design & Test, 35 (1), pp. 74-89; Pasareanu, C.S., Phan, Q., Malacaria, P., Multi-run sidechannel analysis using symbolic execution and max-SMT (2016) IEEE Computer Security Foundations Symposium, pp. 387-400; Phan, Q., Bang, L., Pasareanu, C.S., Malacaria, P., Bultan, T., Synthesis of adaptive side-channel attacks (2017) IEEE Computer Security Foundations Symposium, pp. 328-342; Quisquater, J., Samyde, D., (2001) ElectroMagnetic Analysis (EMA): Measures and Counter-measures for Smart Cards, pp. 200-210; Sousa, M., Dillig, I., Cartesian hoare logic for verifying k-safety properties (2016) ACM SIGPLAN Conference on Programming Language Design and Implementation, pp. 57-69; Stefan, D., Buiras, P., Yang, E.Z., Levy, A., Terei, D., Russo, A., Mazieres, D., In european symposium on research in computer security (2013) Eliminating Cache-based Timing Attacks with Instruction-based Scheduling, pp. 718-735; Sung, C., Paulsen, B., ChaoWang, Canal: A cache timing analysis framework via llvm transformation (2018) IEEE/ACM International Conference on Automated Software Engineering; Touzeau, V., Maiza, C., Monniaux, D., Reineke, J., Ascertaining uncertainty for efficient exact cache analysis (2017) International Conference on Computer Aided Verification, pp. 22-40; Wang, C., Schaumont, P., Security by compilation: An automated approach to comprehensive side-channel resistance (2017) ACM SIGLOG News, 4 (2), pp. 76-89; ChaoWang, Yang, Z., Kahlon, V., Gupta, A., Peephole partial order reduction (2008) International Conference on Tools and Algorithms for Construction and Analysis of Systems, pp. 382-396; Wang, S., Wang, P., Liu, X., Zhang, D., Wu, D., Cached: Identifying cache-based timing channels in production software (2017) USENIX Security Symposium, pp. 235-252; Wu, M., Guo, S., Schaumont, P., Wang, C., Eliminating timing side-channel leaks using program repair (2018) International Symposium on Software Testing and Analysis; Yi, Q., Yang, Z., Guo, S., Wang, C., Liu, J., Zhao, C., Eliminating path redundancy via postconditioned symbolic execution (2018) IEEE Trans. Software Eng., 44 (1), pp. 25-43; Yu, T., Zaman, T.S., Wang, C., Descry: Reproducing system-level concurrency failures (2017) ACM SIGSOFT Symposium on Foundations of Software Engineering, pp. 694-704; Zhang, J., Gao, P., Song, F., Wang, C., Scinfer: Refinement-based verification of software countermeasures against side-channel attacks (2018) International Conference on Computer Aided Verification; Zhang, N., Kusano, M., ChaoWang, Dynamic partial order reduction for relaxed memory models (2015) ACM SIGPLAN Conference on Programming Language Design and Implementation, pp. 250-259","Guo, S.; Virginia TechUnited States","Garci A.Pasareanu C.S.Leavens G.T.","ACM SIGSOFT","Association for Computing Machinery, Inc","26th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2018","4 November 2018 through 9 November 2018",,142072,,9781450355735,,,"English","ESEC/FSE - Proc. ACM Jt. Meet. Eur. Softw. Eng. Conf. Symp. Found. Softw. Eng.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85056530498
"Chen L., Hou S., Ye Y., Xu S.","56571903100;56572013400;23037530700;12241233400;","Droideye: Fortifying security of learning-based classifier against adversarial android malware attacks",2018,"Proceedings of the 2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2018",,,"8508284","782","789",,19,"10.1109/ASONAM.2018.8508284","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057300822&doi=10.1109%2fASONAM.2018.8508284&partnerID=40&md5=e6c483ea39d3707480da844dc8625f47","Department of Computer Science and Electrical Engineering, West Virginia University, United States; Department of Computer Science, University of Texas at San Antonio, United States","Chen, L., Department of Computer Science and Electrical Engineering, West Virginia University, United States; Hou, S., Department of Computer Science and Electrical Engineering, West Virginia University, United States; Ye, Y., Department of Computer Science and Electrical Engineering, West Virginia University, United States; Xu, S., Department of Computer Science, University of Texas at San Antonio, United States","To combat the evolving Android malware attacks, systems using machine learning techniques have been successfully deployed for Android malware detection. In these systems, based on different feature representations, various kinds of classifiers are constructed to detect Android malware. Unfortunately, as classifiers become more widely deployed, the incentive for defeating them increases. In this paper, we first extract a set of features from the Android applications (apps) and represent them as binary feature vectors; with these inputs, we then explore the security of a generic learning-based classifier for Android malware detection in the presence of adversaries. To harden the evasion, we first present count featurization to transform the binary feature space into continuous probabilities encoding the distribution in each class (either benign or malicious). To improve the system security while not compromising the detection accuracy, we further introduce softmax function with adversarial parameter to find the best trade-off between security and accuracy for the classifier. Accordingly, we develop a system named DroidEye which integrates our proposed method for Android malware detection. Comprehensive experiments on the real sample collection from Comodo Cloud Security Center are conducted to validate the effectiveness of DroidEye against adversarial Android malware attacks. Our proposed secure-learning paradigm is also applicable for other detection tasks, such as spammer detection in social media. © 2018 IEEE.",,"Android (operating system); Computer crime; Economic and social effects; Feature extraction; Learning systems; Malware; Probability distributions; Android applications; Binary feature vector; Continuous probabilities; Detection accuracy; Feature representation; Learning paradigms; Machine learning techniques; Spammer detections; Mobile security",,,,,"Barreno, M., Nelson, B., Joseph, A.D., Tygar, J.D., The security of machine learning (2010) Machine Learning; Biggio, B., Fumera, G., Roli, F., Multiple classifier systems for robust classifier design in adversarial environments (2010) IJMLC; Bishop, C.M., (2006) Pattern Recognition and Machine Learning; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) S&P; Chen, L., Hou, S., Ye, Y., Securedroid: Enhancing security of machine learning-based detection against adversarial android malware attacks (2017) ACSAC; Chen, L., Ye, Y., Secmd: Make machine learning more secure against adversarial malware attacks (2017) AI; Chen, L., Ye, Y., Bourlai, T., Adversarial machine learning in malware detection: Arms race between evasion attack and defense (2017) EISIC; Demontis, A., Melis, M., Biggio, B., Maiorca, D., Arp, D., Rieck, K., Corona, I., Roli, F., Yes, machine learning can be more secure! a case study on android malware detection (2017) TDSC; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR; Hou, S., Saas, A., Chen, L., Ye, Y., Deep4maldroid: A deep learning framework for android malware detection based on linux kernel system call graphs (2016) WIW; Hou, S., Saas, A., Ye, Y., Chen, L., Droiddelver: An android malware detection system using deep belief network based on API call blocks (2016) WAIM; Hou, S., Ye, Y., Song, Y., Abdulhayoglu, M., HinDroid: An intelligent android malware detection system based on structured heterogeneous information network (2017) KDD; Kolcz, A., Teo, C.H., Feature weighting for improved classifier robustness (2009) CEAS; Lecuyer, M., Spahn, R., Geambasu, R., Huang, T., Sen, S., Pyramid: Enhancing selectivity in big data protection with count featurization (2017) S&P; Li, B., Vorobeychik, Y., Feature cross-substitution in adversarial classification (2014) NIPS; Li, B., Vorobeychik, Y., Chen, X., A general retraining framework for scalable adversarial classification (2016) NIPS Workshop; Lueg, C., (2017), https://www.gdatasoftware.com/blog/2017/04/29712-8-400-new-android-malware-samples-every-day; Nokland, A., (2015) Improving Back-Propagation by Adding An Adversarial Gradient, , In arXiv:1510.04189; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) EuroS&P; Papernot, N., McDaniel, P., Sinha, A., Wellman, M., Towards the science of security and privacy in machine learning (2016) ArXiv; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) S&P; Reisinger, D., (2013), https://www.cnet.com/news/android-ios-combine-for-91-percent-of-market/; Srivastava, A., König, A.C., Bilenko, M., Time adaptive sketches (ada-sketches) for summarizing data streams (2016) SIGMOD; Wu, W., Hung, S., DroidDolphin: A dynamic Android malware detection framework using big data and machine learning (2014) RACS; Wu, Y., Ren, T., Mu, L., Importance reweighting using adversarial-collaborative training (2016) NIPS Workshop; Xu, W., Evans, D., Qi, Y., (2017) Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks, , In arXiv:1704.01155; Ye, Y., Chen, L., Hou, S., Hardy, W., Li, X., DeepAM: A heterogeneous deep learning framework for intelligent malware detection (2018) KAIS; Ye, Y., Li, T., Adjeroh, D., Iyengar, S.S., A survey on malware detection using data mining techniques (2017) ACM CSUR, 50 (3); Ye, Y., Li, T., Jiang, Q., Han, Z., Wan, L., Intelligent file scoring system for malware detection from the gray list (2009) KDD; Zhang, F., Chan, P.P.K., Biggio, B., Yeung, D.S., Roli, F., Adversarial feature selection against evasion attacks (2015) IEEE Transactions on Cybernetics","Chen, L.; Department of Computer Science and Electrical Engineering, United States; email: lgchen@mix.wvu.edu","Tagarelli A.Reddy C.Brandes U.",,"Institute of Electrical and Electronics Engineers Inc.","10th IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2018","28 August 2018 through 31 August 2018",,141485,,9781538660515,,,"English","Proc. IEEE/ACM Int. Conf. Adv. Soc. Networks Anal. Mining, ASONAM",Conference Paper,"Final","",Scopus,2-s2.0-85057300822
"Yu Y., Liu X., Chen Z.","57204720620;57204729794;57188708618;","Attacks and defenses towards machine learning based systems",2018,"ACM International Conference Proceeding Series",,,"a175","","",,1,"10.1145/3207677.3277988","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056877653&doi=10.1145%2f3207677.3277988&partnerID=40&md5=606c8a6177b41d5fb4b3bbd710f77261","Jiangnan Institute of Computing Technology, Wuxi, China; National Research Center of Parallel Computer Engineering and Technology, Wuxi, China","Yu, Y., Jiangnan Institute of Computing Technology, Wuxi, China; Liu, X., Jiangnan Institute of Computing Technology, Wuxi, China; Chen, Z., National Research Center of Parallel Computer Engineering and Technology, Wuxi, China","Recent research1 has shown that machine learning models are venerable to attacks by adversaries almost at all phases of machine learning pipeline, such as positioning attacks on training data, attacks on the learning algorithm, input attacks based on carefully crafted adversarial samples, model steal and model inversion attack etc. Input samples that are maliciously created can affect the learning process of a ML system by either slowing the learning process, or affecting the performance of the learned model or causing the system make error. So, understanding the security of machine learning algorithms and systems is emerging as an important research area among computer security and machine learning researchers and practitioners. We present a survey on this emerging area: firstly, we define the processing pipeline of a generic machine learning system, then, we identify the attacks in different points of the pipeline and its potential defense solution. Finally, the research work of this paper is summarized and the further research directions are proposed. © 2018 Association for Computing Machinery. ACM.","Adversarial samples; Data positioning; Escape attack; Machine learning; Model inversion","Artificial intelligence; Engineering research; Learning systems; Pipelines; Security of data; Data positioning; Defense solutions; Escape attack; Learning process; Machine learning models; Model inversion; Recent researches; Training data; Learning algorithms",,,,,"Biggio, B., Nelson, B., Laskov, P., Poisoning attacks against support vector machines (2012) International Conference on Machine Learning (ICML); Kearns, M., Li, M., Learning in the presence of malicious errors (1993) SIAM Journal on Computing, 22 (4), pp. 807-837; https://www.theguardian.com/technology/2016/mar/26/microsoft-deeply-sorry-for-offensive-tweets-by-ai-chatbot; Ling, H., Joseph, A.D., Nelson, B., Adversarial machine learning (2011) Proceedings of The 4th ACM Workshop on Security and Artificial Intelligence; Rubinstein, B.I.P., Nelson, B., Ling, H., Antidote: Understanding and defending against poisoning of anomaly detectors (2009) Proceedings of The 9th ACM SIGCOMM Internet Measurement Conference, pp. 1-14. , Chicago, Nov 4-6; Barreno, M., Nelson, B., Sears, R., Joseph, A.D., Tygar, J.D., Can machine learning be secure? (2006) Proceedings of The 2006 ACM Symposium on Information, Computer and Communications Security, pp. 16-25. , ACM; Biggio, B., Fumera, G., Roli, F., Multiple classifier systems for robust classifier design in adversarial environments (2010) International Journal of Machine Learning and Cybernetics; Biggio, B., Corona, I., Fumera, G., Bagging classifiers for fighting poisoning attacks in adversarial classification tasks [C] (2011) LNCS 6713: Proceeding of The 10th International Workshop on Multiple Classifier Systems, pp. 350-359; CLOUD AI, , https://cloud.google.com/products/machine-learning; Amazon Machine Learning, , https://aws.amazon.com/machine-learning/; BigML, , https://bigml.com; Papernot, N., Abadi, M., Goodfellow, I., Talwar, K., Semi-supervised knowledge transfer for deep learning from private training data (2017) International Conference on Learning Representations; Hunt, T., Song, C., Shokri, R., Shmatikov, V., Witchel, E., (2018) Chiron: Privacy-Preserving Machine Learning as A Service; Ohrimenko, O., Schuster, F., Fournet, C., Mehta, A., Nowozin, S., Vaswani, K., Costa, M., (2016) Oblivious Multi-Party Machine Learning on Trusted Processors; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses, , arXiv preprint; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2016) Intriguing Properties of Neural Networks, , https://arxiv.org/pdf/1312.6199v4.pdf; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proceedings of The 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540. , New York, NY, USA; Grosse, K., Papernot, N., Manoharan, P., (2016) Adversarial Perturbations Against Deep Neural Networks for Malware Classification; Rajpurkar, P., Zhang, J., Lopyrev, K., Liang, P., (2016) Squad: 100,000+ Questions for Machine Comprehension of Text, , arXiv preprint; Evtimov, I., (2017) Robust Physical-World Attacks on Deep Learning Models; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., On detecting adversarial perturbations (2017) Proceedings of 5th International Conference on Learning Representations (ICLR); Lu, J., Issaranon, T., Forsyth, D., SafeTyNet: Detecting and rejecting adversarial examples robustly (2017) ICCV; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Security and Privacy (SP), 2016 IEEE Symposium on, pp. 582-597; Huang, R., Xu, B., Schuurmans, D., Szepesvári, C., (2015) Learning with A Strong Adversary, , arXiv preprint; Tramer, Stealing ML models via prediction APIs (2016) UsenixSEC'16, , https://arxiv.org/abs/1609.02943; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) ACM Asia Conference on Computer and Communications Security (ASIACCS); Shokri, R., Stronati, M., Song, C., Shmatikov, V., Membership inference attacks against machine learning models (2017) Security and Privacy (SP), 2017 IEEE Symposium on, pp. 3-18. , IEEE, 2017; Abadi, M., Chu, A., Goodfellow, I., McMahan, H.B., Mironov, I., Talwar, K., Zhang, L., Deep learning with differential privacy (2016) Proceedings of The 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 308-318. , ACM; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387. , IEEE; Fredrikson, Model inversion attacks that exploit confidence information and basic countermeasures (2015) ACM CCS'15; Erkin, Z., Veugen, T., Toft, T., Lagendijk, R.L., Generating private recommendations efficiently using homomorphic encryption and data packing (2012) IEEE Transactions on Information Forensics and Security, 7 (3), pp. 1053-1066; Gilad-Bachrach, R., Dowlin, N., Laine, K., Cryptonets: Applying neural networks to encrypted data with high throughput and accuracy (2016) Proceedings of The 33rd International Conference on Machine Learning, pp. 201-210. , New York, Jun 19- 24; Xie, P., Bilenko, M., Finley, T., (2014) Crypto-Nets: Neural Networks over Encrypted Data[DB/OL], , https://arxiv.org/pdf/1412.6181, 2017-09-01; Erlingsson, U., Pihur, V., Korolova, A., Rappor: Randomized aggregatable privacy-preserving ordinal response (2014) 2014 ACM SIGSAC Conference on Computer and Communications Security, , Scottsdale; https://www.anquanke.com/post/id/98300; Gu, T., Dolan-Gavitt, B., Garg, S., Badnets: Identifying Vulnerabilities in The Machine Learning Model Supply Chain; Chen, X., Liu, C., Li, B., Lu, K., Song, D., (2017) Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning; Carlini, N., Wagner, D., (2017) Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods, , AISEC","Yu, Y.; Jiangnan Institute of Computing TechnologyChina; email: yuych830305@163.com","Emrouznejad A.","Association for Science and Engineering (ASciE)","Association for Computing Machinery","2nd International Conference on Computer Science and Application Engineering, CSAE 2018","22 October 2018 through 24 October 2018",,141755,,9781450365123,,,"English","ACM Int. Conf. Proc. Ser.",Conference Paper,"Final","",Scopus,2-s2.0-85056877653
"Tondi B.","55389019900;","Pixel-domain adversarial examples against CNN-based manipulation detectors",2018,"Electronics Letters","54","21",,"1220","1222",,9,"10.1049/el.2018.6469","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054906209&doi=10.1049%2fel.2018.6469&partnerID=40&md5=91e44c4ced54ba91710c934e66459484","UNISI, University of Siena, Siena, Italy","Tondi, B., UNISI, University of Siena, Siena, Italy","An attack method against convolutional neural network (CNN) detectors, which minimises the distortion in the pixel domain, is proposed. By focusing on CNN models developed for manipulation detection, experiments show that, while the small perturbations introduced by existing methods tend to be cancelled out when the adversarial examples are rounded to pixels, thus making the attack ineffective, the proposed approach can generate pixel-domain adversarial images which succeed in inducing a wrong decision with very small distortions. © The Institution of Engineering and Technology 2018.",,"Image coding; Neural networks; Attack methods; CNN models; Convolutional Neural Networks (CNN); Pixel domain; Small perturbations; Pixels",,,,,"Szegedy, C., Zaremba, W., Sutskever, I., (2013) Intriguing Properties of Neural Networks, , arXiv preprint; Marra, F., Gragnaniello, D., Verdoliva, L., On the vulnerability of deep learning to adversarial attacks for camera model identification (2018) Signal Process., Image Commun., 65, pp. 240-248; Böhme, R., Kirchner, M., Counter-forensics: Attacking image forensics (2012) Digital Image Forensics, pp. 327-366. , Sencar, H.T, Memon, N. Eds Springer, New York, NY, USA; Chen, Z., Tondi, B., Li, X., A gradient-based pixel-domain attack against SVM detection of global image manipulations (2017) IEEE Int. Workshop on Information Forensics and Security, , Rennes, France, December; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint; Papernot, N., McDaniel, P., Jha, S., The limitations of deep learning in adversarial settings (2016) IEEE European Symp. Security & Privacy, pp. 372-387. , Saarbrücken, Germany, March; Rauber, J., Brendel, W., Bethge, M., (2017) Foolbox V0. 8.0: A Python Toolbox to Benchmark The Robustness of Machine Learning Models, , arXiv preprint; Bayar, B., Stamm, M.C., A deep learning approach to universal image manipulation detection using a new convolutional layer (2016) ACM Workshop on Info. Hiding & Multimedia Security, pp. 5-10. , Vigo, Spain, June; Barni, M., Costanzo, A., Nowroozi, E., Cnn-based detection of generic contrast adjustment with jpeg post-processing To Be Presented to ICIP 2018, , arXiv preprint; Dang-Nguyen, D.-T., Pasquini, C., Conotter, V., Raise: A raw images dataset for digital image forensics (2015) ACM Multimedia Systems, pp. 219-224. , Portland, OR, USA, March","Tondi, B.; UNISI, Italy; email: benedettatondi@gmail.com",,,"Institution of Engineering and Technology",,,,,00135194,,ELLEA,,"English","Electron. Lett.",Article,"Final","All Open Access, Bronze",Scopus,2-s2.0-85054906209
"Zhao P., Wang Y., Liu S., Lin X.","57201580783;36555062200;55444335000;57205018638;","An ADMM-based universal framework for adversarial attacks on deep neural networks",2018,"MM 2018 - Proceedings of the 2018 ACM Multimedia Conference",,,,"1065","1073",,12,"10.1145/3240508.3240639","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058214859&doi=10.1145%2f3240508.3240639&partnerID=40&md5=2d19d3c1e529ef3643c8739c680e8666","Department of ECE, Northeastern University, United States; IBM Research AI, United States","Zhao, P., Department of ECE, Northeastern University, United States; Wang, Y., Department of ECE, Northeastern University, United States; Liu, S., IBM Research AI, United States; Lin, X., Department of ECE, Northeastern University, United States","Deep neural networks (DNNs) are known vulnerable to adversarial attacks. That is, adversarial examples, obtained by adding delicately crafted distortions onto original legal inputs, can mislead a DNN to classify them as any target labels. In a successful adversarial attack, the targeted mis-classification should be achieved with the minimal distortion added. In the literature, the added distortions are usually measured by L 0 , L 1 , L 2 , and L ∞ norms, namely, L 0 , L 1 , L 2 , and L ∞ attacks, respectively. However, there lacks a versatile framework for all types of adversarial attacks. This work for the first time unifies the methods of generating adversarial examples by leveraging ADMM (Alternating Direction Method of Multipliers), an operator splitting optimization approach, such that L 0 , L 1 , L 2 , and L ∞ attacks can be effectively implemented by this general framework with little modifications. Comparing with the state-of-the-art attacks in each category, our ADMM-based attacks are so far the strongest, achieving both the 100% attack success rate and the minimal distortion. © 2018 Association for Computing Machinery.","ADMM (Alternating Direction Method of Multipliers); Adversarial attacks; Deep neural networks","Adversarial attacks; Alternating direction method of multipliers; Minimal distortion; Operator-splitting; Optimization approach; State of the art; Target labels; Deep neural networks",,,,,"Athalye, A., Carlini, N., Wagner, D., (2018) Obfuscated Gradients Give A False Sense of Security: Circumventing Defenses to Adversarial Examples, , arXiv preprint 2018; Bhagoji, A.N., Cullina, D., Mittal, P., (2017) Dimensionality Reduction as A Defense Against Evasion Attacks on Machine Learning Classifiers, , arXiv preprint 2017; Boyd, S., Parikh, N., Chu, E., Peleato, B., Eckstein, J., Distributed optimization and statistical learning via the alternating direction method of multipliers (2011) Foundations and Trends® in Machine Learning, 3 (1), pp. 1-122. , 2011; Carlini, N., Mishra, P., Vaidya, T., Zhang, Y., Sherr, M., Shields, C., Wagner, D., Zhou, W., Hidden Voice Commands (2016) USENIX Security Symposium, pp. 513-530; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium on, pp. 39-57. , IEEE; Chen, P.-Y., Sharma, Y., Zhang, H., Yi, J., Hsieh, C.-J., (2017) EAD: Elastic-Net Attacks to Deep Neural Networks Via Adversarial Examples, , arXiv preprint 2017; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., ImageNet: A large-scale hierarchical image database (2009) Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on., pp. 248-255. , IEEE; Dhillon, G.S., Azizzadenesheli, K., Lipton, Z.C., Bernstein, J., Kossaifi, J., Khanna, A., Anandkumar, A., (2018) Stochastic Activation Pruning for Robust Adversarial Defense, , arXiv preprint 2018; Dziugaite, G.K., Ghahramani, Z., Roy, D.M., (2016) A Study of The Effect of Jpg Compression on Adversarial Images, , arXiv preprint 2016; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts, , arXiv preprint 2017; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint 2014; Guo, C., Rana, M., Cissé, M., Van Der Maaten, L., (2017) Countering Adversarial Images Using Input Transformations, , arXiv preprint 2017; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of The IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Hinton, G., Deng, L., Yu, D., Dahl, G.E., Mohamed, A.-R., Jaitly, N., Senior, A., Sainath, T.N., Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups (2012) IEEE Signal Processing Magazine, 29 (6), pp. 82-97. , 2012; Hong, M., Luo, Z.-Q., On the linear convergence of the alternating direction method of multipliers (2017) Mathematical Programming, 162 (1), pp. 165-199. , https://doi.org/10.1007/s10107-016-1034-2, 01 Mar 2017; Kingma, D.P., Ba, J., (2015) Adam: A Method for Stochastic Optimization, , http://arxiv.org/abs/1412.6980, 2015 ICLR arXiv preprint 2015; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images, , Master's thesis, Department of Computer Science, University of Toronto 2009; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in The Physical World, , arXiv preprint 2016; Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324. , https://doi.org/10.1109/5.726791, Nov 1998; Makantasis, K., Karantzalos, K., Doulamis, A., Doulamis, N., Deep supervised learning for hyperspectral data classification through convolutional neural networks (2015) Geoscience and Remote Sensing Symposium (IGARSS), 2015 IEEE International, pp. 4959-4962. , IEEE; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Proceedings of The IEEE Conference on Computer Vision and Pattern Recognition, pp. 427-436; Papernot, N., Goodfellow, I., Sheatsley, R., Feinman, R., McDaniel, P., (2016) Cleverhans V1.0.0: An Adversarial Machine Learning Library, , arXiv preprint 2016; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387. , IEEE; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Security and Privacy (SP), 2016 IEEE Symposium on, pp. 582-597. , IEEE; Parikh, N., Boyd, S., Proximal algorithms (2014) Foundations and Trends® in Optimization, 1 (3), pp. 127-239. , 2014; Silver, D., Huang, A., Maddison, C.J., Guez, A., Sifre, L., Van Den Driessche, G., Schrittwieser, J., Lanctot, M., Mastering the game of Go with deep neural networks and tree search (2016) Nature, 529 (7587), pp. 484-489. , 2016; Su, J., Vargas, D.V., Kouichi, S., (2017) One Pixel Attack for Fooling Deep Neural Networks, , arXiv preprint 2017; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z.-N., Rethinking the inception architecture for computer vision (2016) 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2818-2826. , 2016; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint 2013; Taigman, Y., Yang, M., Ranzato, M., Wolf, L., DeepFace: Closing the gap to human-level performance in face verification (2014) Proceedings of The IEEE Conference on Computer Vision and Pattern Recognition, pp. 1701-1708; Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2018) Ensemble Adversarial Training: Attacks and Defenses, , 2018 ICLR arXiv preprint 2018; Wang, H., Banerjee, A., Bregman alternating direction method of multipliers (2014) Advances in Neural Information Processing Systems, 27, pp. 2816-2824. , http://papers.nips.cc/paper/5612-bregman-alternating-direction-method-of-multipliers.pdf, Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Wein-berger (Eds.). Curran Associates, Inc; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., (2017) Mitigating Adversarial Effects Through Randomization, , arXiv preprint 2017",,,"ACM SIGMM","Association for Computing Machinery, Inc","26th ACM Multimedia conference, MM 2018","22 October 2018 through 26 October 2018",,142036,,9781450356657,,,"English","MM - Proc. ACM Multimed. Conf.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85058214859
"Yin M., Li X., Zhang Y., Wang S.","57202283732;7501701944;7601315649;55364979300;","When deep fool meets deep prior: Adversarial attack on super-resolution network",2018,"MM 2018 - Proceedings of the 2018 ACM Multimedia Conference",,,,"1930","1938",,6,"10.1145/3240508.3240603","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058208532&doi=10.1145%2f3240508.3240603&partnerID=40&md5=c53b04645856ce57d2588312baa6fe5a","Tsinghua University, China; City University of Hong Kong, Hong Kong","Yin, M., Tsinghua University, China; Li, X., Tsinghua University, China; Zhang, Y., Tsinghua University, China; Wang, S., City University of Hong Kong, Hong Kong","This paper investigates the vulnerability of the deep prior used in deep learning based image restoration. In particular, the image super-resolution, which relies on the strong prior information to regularize the solution space and plays important roles in the image pre-processing for future viewing and analysis, is shown to be vulnerable to the well-designed adversarial examples. We formulate the adversarial example generation process as an optimization problem, and given super-resolution model three different types of attack are designed based on the subsequent tasks: (i) style transfer attack; (ii) classification attack; (iii) caption attack. Another interesting property of our design is that the attack is hidden behind the super-resolution process, such that the utilization of low resolution images is not significantly influenced. We show that the vulnerability to adversarial examples could bring risks to the pre-processing modules such as super-resolution deep neural network, which is also of paramount significance for the security of the whole system. Our results also shed light on the potential security issues of the pre-processing modules, and raise concerns regarding the corresponding countermeasures for adversarial examples. © 2018 Association for Computing Machinery.","Adversarial attack; Caption; Deep prior; Image classification; Style transfer; Super-resolution","Image classification; Image reconstruction; Network security; Optical resolving power; Adversarial attack; Caption; Deep prior; Style transfer; Super resolution; Deep neural networks",,,,,"Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium on, pp. 39-57. , IEEE; Chen, H., Zhang, H., Chen, P.-Y., Yi, J., Hsieh, C.-J., (2017) Show-and-Fool: Crafting Adversarial Examples for Neural Image Captioning, , arXiv preprint 2017; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., ImageNet: A large-scale hierarchical image database (2009) Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on., pp. 248-255. , IEEE; Dong, C., Loy, C.C., He, K., Tang, X., Image super-resolution using deep convolutional networks (2016) IEEE Transactions on Pattern Analysis and Machine Intelligence, 38 (2), pp. 295-307. , 2016; Gatys, L.A., Ecker, A.S., Bethge, M., (2015) A Neural Algorithm of Artistic Style, , arXiv preprint 2015; Girshick, R., (2015) Fast R-Cnn, , arXiv preprint 2015; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint 2014; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of The IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Johnson, J., Alahi, A., Fei-Fei, L., Perceptual losses for real-time style transfer and super-resolution (2016) European Conference on Computer Vision, pp. 694-711. , Springer; Kim, J., Lee, J.K., Lee, K.M., Deeply-recursive convolutional network for image super-resolution (2016) Proceedings of The IEEE Conference on Computer Vision and Pattern Recognition, pp. 1637-1645; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Ledig, C., Theis, L., Huszár, F., Caballero, J., Cunningham, A., Acosta, A., Aitken, A., Wang, Z., (2016) Photo-Realistic Single Image Super-Resolution Using A Generative Adversarial Network, , arXiv preprint 2016; Lin, C.-Y., Rouge: A package for automatic evaluation of summaries (2004) Text Summarization Branches Out, , 2004; Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Dollár, P., Lawrence Zitnick, C., Microsoft coco: Common objects in context (2014) European Conference on Computer Vision, pp. 740-755. , Springer; Dezfooli, S.M.M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387. , IEEE; Papineni, K., Roukos, S., Ward, T., Zhu, W.-J., BLEU: A method for automatic evaluation of machine translation (2002) Proceedings of The 40th Annual Meeting on Association for Computational Linguistics, pp. 311-318. , Association for Computational Linguistics; Rozsa, A., Rudd, E.M., Boult, T.E., Adversarial diversity and hard positive generation (2016) Proceedings of The IEEE Conference on Computer Vision and Pattern Recognition Workshops, pp. 25-32; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proceedings of The 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540. , ACM; Shi, W., Caballero, J., Huszár, F., Totz, J., Aitken, A.P., Bishop, R., Rueckert, D., Wang, Z., Real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network (2016) Proceedings of The IEEE Conference on Computer Vision and Pattern Recognition, pp. 1874-1883; Sutskever, I., Vinyals, O., Le, Q.V., Sequence to sequence learning with neural networks (2014) Advances in Neural Information Processing Systems, pp. 3104-3112; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint 2013; Tabacof, P., Tavares, J., Valle, E., (2016) Adversarial Images for Variational Autoencoders, , arXiv preprint 2016; Vedantam, R., Lawrence Zitnick, C., Parikh, D., CiDer: Consensus-based image description evaluation (2015) Proceedings of The IEEE Conference on Computer Vision and Pattern Recognition, pp. 4566-4575; Vinyals, O., Toshev, A., Bengio, S., Erhan, D., Show and tell: A neural image caption generator (2015) Computer Vision and Pattern Recognition (CVPR), 2015 IEEE Conference on, pp. 3156-3164. , IEEE; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., Adversarial examples for semantic segmentation and object detection (2017) International Conference on Computer Vision, , IEEE; Xu, K., Ba, J., Kiros, R., Cho, K., Courville, A., Salakhudinov, R., Zemel, R., Bengio, Y., Show, attend and tell: Neural image caption generation with visual attention (2015) International Conference on Machine Learning, pp. 2048-2057; Xu, X., Chen, X., Liu, C., Rohrbach, A., Darell, T., Song, D., (2017) Can You Fool AI with Adversarial Examples on A Visual Turing Test?, , arXiv preprint 2017; Yuan, X., He, P., Zhu, Q., Bhat, R.R., Li, X., (2017) Adversarial Examples: Attacks and Defenses for Deep Learning, , arXiv preprint 2017; Zhang, Y., Zhang, Y., Zhang, J., Dai, Q., CCR: Clustering and collaborative representation for fast single image super-resolution (2016) IEEE Transactions on Multimedia, 18 (3), pp. 405-417. , 2016; Zhang, Y., Zhang, Y., Zhang, J., Xu, D., Fu, Y., Wang, Y., Ji, X., Dai, Q., Collaborative representation cascade for single-image super-resolution (2017) IEEE Transactions on Systems, Man, and Cybernetics: Systems, , 2017; Zhao, Z., Dua, D., Singh, S., (2017) Generating Natural Adversarial Examples, , arXiv preprint 2017",,,"ACM SIGMM","Association for Computing Machinery, Inc","26th ACM Multimedia conference, MM 2018","22 October 2018 through 26 October 2018",,142036,,9781450356657,,,"English","MM - Proc. ACM Multimed. Conf.",Conference Paper,"Final","",Scopus,2-s2.0-85058208532
[No author name available],[No author id available],"Proceedings of the ACM Conference on Computer and Communications Security",2018,"Proceedings of the ACM Conference on Computer and Communications Security",,,,"","",2198,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056910035&partnerID=40&md5=722ef1ebba6f6de9f24094966ef90901",,"","The proceedings contain 146 papers. The topics discussed include: towards fine-grained network security forensics and diagnosis in the SDN era; vNIDS: towards elastic security with safe and efficient virtualization of network intrusion detection systems; voting: you can't have privacy without individual verifiability; securify: practical security analysis of smart contracts; large-scale and language-oblivious code authorship identification; fraud de-anonymization for fun and profit; unveiling hardware-based data prefetcher, a hidden source of information leakage; ohm's law in data centers: a voltage side channel for timing power attacks; screaming channels: when electromagnetic side channels meet radio transceivers; utility-aware synthesis of differentially private and attack-resilient location traces; and prime and prejudice: primality testing under adversarial conditions.",,,,,,,,,,"ACM SIGSAC","Association for Computing Machinery","25th ACM Conference on Computer and Communications Security, CCS 2018","15 October 2018",,141172,15437221,9781450356930,,,"English","Proc ACM Conf Computer Commun Secur",Conference Review,"Final","",Scopus,2-s2.0-85056910035
"Kneib M., Huth C.","57204720174;56830246400;","Scission: Signal characteristic-based sender identification and intrusion detection in automotive networks",2018,"Proceedings of the ACM Conference on Computer and Communications Security",,,,"787","800",,60,"10.1145/3243734.3243751","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056897929&doi=10.1145%2f3243734.3243751&partnerID=40&md5=56177e5935b6d02d8235226f786fed1a","Bosch Engineering GmbH, Abstatt, Germany; Robert Bosch GmbH, Renningen, Germany","Kneib, M., Bosch Engineering GmbH, Abstatt, Germany; Huth, C., Robert Bosch GmbH, Renningen, Germany","Increased connectivity increases the attack vector. This also applies to connected vehicles in which vulnerabilities not only threaten digital values but also humans and the environment. Typically, attackers try to exploit the Controller Area Network (CAN) bus, which is the most widely used standard for internal vehicle communication. Once an Electronic Control Unit (ECU) connected to the CAN bus is compromised, attackers can manipulate messages at will. The missing sender authentication by design of the CAN bus enables adversarial access to vehicle functions with severe consequences. In order to address this problem, we propose Scission, an Intrusion Detection System (IDS) which uses fingerprints extracted from CAN frames, enabling the identification of sending ECUs. Scission utilizes physical characteristics from analog values of CAN frames to assess whether it was sent by the legitimate ECU. In addition, to detect comprised ECUs, the proposed system is able to recognize attacks from unmonitored and additional devices. We show that Scission is able to identify the sender with an average probability of 99.85 %, during the evaluation on two series production cars and a prototype setup. Due to the robust design of the system, the evaluation shows that all false positives were prevented. Compared to previous approaches, we have significantly reduced hardware costs and increased identification rates, which enables a broad application of this technology. © 2018 Association for Computing Machinery.","Automotive Security; Controller Area Network; Intrusion Detection; Sender Identification","Control system synthesis; Controllers; Intrusion detection; Network security; Process control; Vehicles; Automotive Security; Controller area network; Controller area networkbus; Electronic control units; Intrusion Detection Systems; Physical characteristics; Signal characteristic; Vehicle communications; Vehicle to vehicle communications",,,,,"Axelsson, S., (2000) Intrusion Detection Systems: A Survey and Taxonomy; Bottou, L., Large-scale machine learning with stochastic gradient descent (2010) Proceedings of COMPSTAT’2010, pp. 177-186. , Yves Lechevallier and Gilbert Saporta (Eds.). Physica-Verlag HD, Heidelberg; Checkoway, S., McCoy, D., Kantor, B., Anderson, D., Shacham, H., Savage, S., Koscher, K., Kohno, T., Comprehensive experimental analyses of automotive attack surfaces (2011) Proceedings of The 20th USENIX Conference on Security (SEC’11), p. 6. , USENIX Association, Berkeley, CA, USA; Cho, K.-T., Shin, K.G., Fingerprinting electronic control units for vehicle intrusion detection (2016) 25th USENIX Security Symposium (USENIX Security 16), pp. 911-927. , https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/cho, USENIX Association, Austin, TX; Cho, K.-T., Shin, K.G., Viden: Attacker identification on in-vehicle networks (2017) Proceedings of The 2017 ACM SIGSAC Conference on Computer and Communications Security (CCS’17), pp. 1109-1123. , https://doi.org/10.1145/3133956.3134001, ACM, New York, NY, USA; Choi, W., Jo, H.J., Woo, S., Chun, J.Y., Park, J., Lee, D.H., Identifying ECUs using inimitable characteristics of signals in controller area networks (2018) IEEE Transactions on Vehicular Technology, 67 (6), pp. 4757-4770. , 2018; Fischler, M.A., Bolles, R.C., Random sample consensus: A paradigm for model fitting with applications to image analysis and automated cartography (1981) Commun. ACM, 24 (6), pp. 381-395. , https://doi.org/10.1145/358669.358692, June 1981; (2018) TR-02102-1 Cryptographic Mechanisms: Recommendations and Key Lengths, , Federal Office for Information Security; Gama, J., Žliobaite, I., Bifet, A., Pechenizkiy, M., Bouchachia, A., A survey on concept drift adaptation (2014) ACM Computing Surveys (CSUR), 46 (4), p. 44. , 2014; Bosch, R., (1991) CAN Specification V2.0, , GmbH; Bosch, R., (2012) CAN with Flexible Data-Rate Specification Version 1.0, , GmbH; Groza, B., Murvay, S., Efficient protocols for secure broadcast in controller area networks (2013) IEEE Transactions on Industrial Informatics, 9 (4), pp. 2034-2042. , https://doi.org/10.1109/TII.2013.2239301, Nov 2013; Hartwich, F., (2012) CAN with Flexible Data-Rate; Higbee, A., (2007) Hack Your Car for Boost and Power! DEF CON 15 Hacking Conference; Hoppe, T., Kiltz, S., Dittmann, J., Adaptive dynamic reaction to automotive IT security incidents using multimedia car environment (2008) 2008 The Fourth International Conference on Information Assurance and Security, pp. 295-298. , ACM, New York, NY, USA; Hoppe, T., Kiltz, S., Dittmann, J., Security threats to automotive can networks - Practical examples and selected short-term countermeasures (2008) Computer Safety, Reliability, and Security, pp. 235-248. , Michael D. Harrison and Mark-Alexander Sujan (Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg; Hoppe, T., Kiltz, S., Dittmann, J., Applying intrusion detection to automotive it-early insights and remaining challenges (2009) Journal of Information Assurance and Security (JIAS), 4 (6), pp. 226-235. , 2009; Huber, P.J., (1992) Robust Estimation of A Location Parameter, pp. 492-518. , https://doi.org/10.1007/978-1-4612-4380-9_35, Springer New York, New York, NY; Igelnik, B., Igelnik, B., Zurada, J.M., (2013) Efficiency and Scalability Methods for Computational Intellect, , 1st ed.). IGI Global, Hershey, PA, USA; Illera, A.G., Dude, WTF in my car? (2013) DEF CON 21 Hacking Conference; (2005) MCP2515 Stand-Alone CAN Controller With SPI Interface, , Microchip Technology Inc. Revision D; (2007) MCP2551 High-Speed CAN Transceiver, , Microchip Technology Inc. Revision E; Islinger, T., Mori, Y., Ringing suppression in CAN FD networks (2016) CAN Newsletter; Jagielski, M., Oprea, A., Biggio, B., Liu, C., Nita-Rotaru, C., Li, B., Manipulating machine learning: Poisoning attacks and countermeasures for regression learning (2018) 2018 IEEE Symposium on Security and Privacy (SP), pp. 19-35. , https://doi.org/10.1109/SP.2018.00057, IEEE, New York, NY; Jungk, B., Automotive security state of the art and future challenges (2016) 2016 International Symposium on Integrated Circuits (ISIC), pp. 1-4. , IEEE, New York, NY; Kononenko, I., Estimating attributes: Analysis and extensions of RELIEF (1994) Machine Learning: ECML-94, pp. 171-182. , Francesco Bergadano and Luc De Raedt (Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg; Koscher, K., Czeskis, A., Roesner, F., Patel, S., Kohno, T., Checkoway, S., McCoy, D., Savage, S., Experimental security analysis of a modern automobile (2010) 2010 IEEE Symposium on Security and Privacy, pp. 447-462. , https://doi.org/10.1109/SP.2010.34, IEEE, New York, NY; Liao, H.-J., Lin, C.-H.R., Lin, Y.-C., Tung, K.-Y., Review: Intrusion detection system: A comprehensive review (2013) J. Netw. Comput. Appl., 36 (1), pp. 16-24. , https://doi.org/10.1016/j.jnca.2012.09.004, Jan. 2013; Lin, C.W., Sangiovanni-Vincentelli, A., Cyber-security for the controller area network (CAN) communication protocol (2012) 2012 International Conference on Cyber Security, pp. 1-7. , https://doi.org/10.1109/CyberSecurity.2012.7, IEEE, New York, NY; Miller, C., Valasek, C., (2013) Adventures in Automotive Networks and Control Units, pp. 260-264; Miller, C., Valasek, C., Remote exploitation of an unaltered passenger vehicle (2015) Black Hat USA, 2015, p. 91. , 2015; Mori, H., Suzuki, Y., Maeda, N., Obata, H., Kishigami, T., Novel ringing suppression circuit to increase the number of connectable ECUs in a linear passive star CAN (2012) International Symposium on Electromagnetic Compatibility - EMC Europe, pp. 1-6. , https://doi.org/10.1109/EMCEurope.2012.6396876, IEEE, New York, NY; Murvay, P.S., Groza, B., Source identification using signal characteristics in controller area networks (2014) IEEE Signal Processing Letters, 21 (4), pp. 395-399. , https://doi.org/10.1109/LSP.2014.2304139, April 2014; Müter, M., Groll, A., Freiling, F.C., A structured approach to anomaly detection for in-vehicle networks (2010) 2010 Sixth International Conference on Information Assurance and Security, pp. 92-98. , https://doi.org/10.1109/ISIAS.2010.5604050, IEEE, New York, NY; (2016) Specification of Module Secure Onboard Communication, , AUTOSAR Development Partnership; Sagong, S.U., Ying, X., Clark, A., Bushnell, L., Poovendran, R., Cloaking the clock: Emulating clock skew in controller area networks (2018) Proceedings of The 9th ACM/IEEE International Conference on Cyber-Physical Systems (ICCPS’18), pp. 32-42. , https://doi.org/10.1109/ICCPS.2018.00012, IEEE Press, Piscataway, NJ, USA; Sagstetter, F., Lukasiewycz, M., Steinhorst, S., Wolf, M., Bouard, A., Harris, W.R., Jha, S., Chakraborty, S., Security challenges in automotive hardware/software architecture design (2013) Proceedings of The Conference on Design, Automation and Test in Europe (DATE’13), pp. 458-463. , http://dl.acm.org/citation.cfm?id=2485288.2485398, EDA Consortium, San Jose, CA, USA; Schweppe, H., Roudier, Y., Weyl, B., Apvrille, L., Scheuermann, D., CAR2X communication: Securing the last meter - A cost-effective approach for ensuring trust in CAR2X applications using in-vehicle symmetric cryptography (2011) 2011 IEEE Vehicular Technology Conference (VTC Fall), pp. 1-5. , https://doi.org/10.1109/VETECF.2011.6093081, IEEE, New York, NY; Smith, T.C., Frank, E., (2016) Statistical Genomics: Methods and Protocols, pp. 353-378. , http://dx.doi.org/10.1007/978-1-4939-3578-9_17, Springer, New York, NY, Chapter Introducing Machine Learning Concepts with WEKA; Van Herrewege, A., Singelee, D., Verbauwhede, I., (2011) CA-NAuth - A Simple, Backward Compatible Broadcast Authentication Protocol for CAN Bus; (2003) Common High Speed Physical Layer Problems, , Inc. Vector CANtech; Wolf, M., Weimerskirch, A., Wollinger, T., State of the art: Embedding security in vehicles (2007) EURASIP Journal on Embedded Systems, 1 (19), p. 074706. , https://doi.org/10.1155/2007/74706, 2007. Jun 2007; Ziermann, T., Wildermann, S., Teich, J., Can+: A new backward-compatible Controller Area Network (CAN) protocol with up to 16ÃU higher data rates (2009) 2009 Design, Automation Test in Europe Conference Exhibition, pp. 1088-1093. , https://doi.org/10.1109/DATE.2009.5090826, IEEE, New York, NY",,,"ACM SIGSAC","Association for Computing Machinery","25th ACM Conference on Computer and Communications Security, CCS 2018","15 October 2018",,141172,15437221,9781450356930,,,"English","Proc ACM Conf Computer Commun Secur",Conference Paper,"Final","",Scopus,2-s2.0-85056897929
"McKnight C., Goldberg I.","57204718333;23396529800;","Style counsel: Seeing the (Random) forest for the trees in adversarial code stylometry",2018,"Proceedings of the ACM Conference on Computer and Communications Security",,,,"138","142",,1,"10.1145/3267323.3268951","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056882475&doi=10.1145%2f3267323.3268951&partnerID=40&md5=0d0714effe4b683dadbbe58f5da9c5b4","Magnet Forensics, Canada; University of Waterloo, Canada","McKnight, C., Magnet Forensics, Canada; Goldberg, I., University of Waterloo, Canada","The results of recent experiments have suggested that code stylometry can successfully identify the author of short programs from among hundreds of candidates with up to 98% precision. This potential ability to discern the programmer of a code sample from a large group of possible authors could have concerning consequences for the open-source community at large, particularly those contributors that may wish to remain anonymous. Recent international events have suggested the developers of certain anti-censorship and anti-surveillance tools are being targeted by their governments and forced to delete their repositories or face prosecution. In light of this threat to the freedom and privacy of individual programmers around the world, we devised a tool, Style Counsel, to aid programmers in obfuscating their inherent style and imitating another, overt, author's style in order to protect their anonymity from this forensic technique. Our system utilizes the implicit rules encoded in the decision points of a random forest ensemble in order to derive a set of recommendations to present to the user detailing how to achieve this obfuscation and mimicry attack. © 2018 Copyright held by the owner/author(s).",,"Codes (symbols); Computer privacy; Decision trees; Decision points; Forensic Techniques; Large groups; Open source communities; Potential ability; Random forests; Stylometry; Surveillance tools; Open systems",,,,,"Brennan, M., Afroz, S., Greenstadt, R., Adversarial stylometry: Circumventing authorship recognition to preserve privacy and anonymity (2012) ACM Transactions on Information and System Security, 15 (3), pp. 1-22. , https://doi.org/10.1145/2382448.2382450, (2012); Budington, B., (2015) China Uses Unencrypted Websites to Hijack Browsers in GitHub Attack, , https://www.eff.org/deeplinks/2015/04/china-Uses-Unencrypted-Websites-to-Hijack-Browsers-in-Github-Attack, [Online; Accessed July 2018]; Caliskan-Islam, A., Harang, R., Liu, A., Narayanan, A., Voss, C., Yamaguchi, F., Greenstadt, R., De-anonymizing programmers via code stylometry (2015) 24th USENIX Security Symposium (USENIX Security 15), pp. 255-270. , https://doi.org/10.1145/2665943.2665958, (2015); (2014) Young IT Professional Detained for Developing Software to Scale GFW of China, , https://chinachange.org/2014/11/12/young-It-Professional-Detained-for-Developing-Software-to-Scale-Gfw-of-China/, [Online; Accessed July 2018]; Frantzeskou, G., Stamatatos, E., Gritzalis, S., Chaski, C.E., Howald, B.S., Identifying authorship by byte-level N-grams: The source code author profile (SCAP) method (2007) International Journal of Digital Evidence, 6 (1), pp. 1-18. , (2007); Kacmarcik, G., Gamon, M., Obfuscating document stylometry to preserve author anonymity (2006) Proceedings of the COLING/ACL on Main Conference Poster Sessions - (2006), pp. 444-451. , https://doi.org/10.3115/1273073.1273131; Kerckhoffs, A., La Cryptographie Militaire (1883) Journal des Sciences Militaires, 9 (1883), pp. 5-83; Marczak, B., Weaver, N., Dalek, J., Ensafi, R., Fiflield, D., Mckune, S., Rey, A., Paxson, V., (2015) China's Great Cannon, , https://citizenlab.ca/2015/04/chinas-Great-Cannon/, Technical Report [Accessed Aug 2018]; McDonald, A.W.E., Afroz, S., Caliskan, A., Stolerman, A., Greenstadt, R., Use fewer instances of the letter ""i"": Toward writing style anonymization (2012) Privacy Enhancing Technologies, 7384, pp. 299-318. , Springer; McKnight, C., (2018) StyleCounsel: Seeing the (Random) Forest for the Trees in Adversarial Code Stylometry, , https://uwspace.uwaterloo.ca/handle/10012/12856, Master's thesis. University of Waterloo; McKnight, C., Goldberg, I., Style counsel: Seeing the (Random) forest for the trees in adversarial code stylometry (2018) Technical Report 2018-08. CACR, , http://cacr.uwaterloo.ca/techreports/2018/cacr2018-08.pdf; O'Brien, D., (2015) Speech that Enables Speech: China Takes Aim at its Coders, , https://www.eff.org/deeplinks/2015/08/speech-Enables-Speech-China-Takes-Aim-Its-Coders, [Online; Accessed July 2018]; Orman, H., The morris worm: A fifteen-year perspective (2003) IEEE Security & Privacy, 99 (5), pp. 35-43. , (2003); (2015) Chinese Developers Forced to Delete Softwares by Police, , https://en.greatfire.org/blog/2015/aug/chinese-Developers-Forced-Delete-Softwares-Police, Percy [Online; Accessed July 2018]; Simko, L., Zettlemoyer, L., Kohno, T., Recognizing and imitating programmer style: Adversaries in program authorship attribution (2018) PoPETs, 2018 (1), pp. 127-144. , (2018); (2012) Programmer and Activist Interrogated at the Border, , https://privacysos.org/blog/programmer-and-Activist-Interrogated-at-the-Border/, [Online; Accessed July 2018]; Spafford, E.H., The internet worm program: An analysis (1989) ACM SIGCOMM Computer Communication Review, 19 (1), pp. 17-57. , (1989)",,,"ACM SIGSAC","Association for Computing Machinery","17th ACM Workshop on Privacy in the Electronic Society, WPES 2018, held in conjunction with the 25th ACM Conference on Computer and Communications Security, CCS 2018","15 October 2018",,141180,15437221,9781450359894,,,"English","Proc ACM Conf Computer Commun Secur",Conference Paper,"Final","",Scopus,2-s2.0-85056882475
"Ye G., Tang Z., Fang D., Zhu Z., Feng Y., Xu P., Chen X., Wang Z.","57193613039;15822992800;8975043000;57200340512;55387599700;56672326500;8317069000;35111811300;","Yet another text CAPTCHA solver: A generative adversarial network based approach",2018,"Proceedings of the ACM Conference on Computer and Communications Security",,,,"332","348",,50,"10.1145/3243734.3243754","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056867234&doi=10.1145%2f3243734.3243754&partnerID=40&md5=8d439e3241b96067a3e883eaa157c406","Northwest University, China; Peking University, China; Lancaster University, United Kingdom","Ye, G., Northwest University, China; Tang, Z., Northwest University, China; Fang, D., Northwest University, China; Zhu, Z., Peking University, China; Feng, Y., Peking University, China; Xu, P., Northwest University, China; Chen, X., Northwest University, China; Wang, Z., Lancaster University, United Kingdom","Despite several attacks have been proposed, text-based CAPTCHAs1 are still being widely used as a security mechanism. One of the reasons for the pervasive use of text captchas is that many of the prior attacks are scheme-specific and require a labor-intensive and time-consuming process to construct. This means that a change in the captcha security features like a noisier background can simply invalid an earlier attack. This paper presents a generic, yet effective text captcha solver based on the generative adversarial network. Unlike prior machine-learning-based approaches that need a large volume of manually-labeled real captchas to learn an effective solver, our approach requires significantly fewer real captchas but yields much better performance. This is achieved by first learning a captcha synthesizer to automatically generate synthetic captchas to learn a base solver, and then fine-tuning the base solver on a small set of real captchas using transfer learning. We evaluate our approach by applying it to 33 captcha schemes, including 11 schemes that are currently being used by 32 of the top-50 popular websites including Microsoft, Wikipedia, eBay and Google. Our approach is the most capable attack on text captchas seen to date. It outperforms four state-of-the-art text-captcha solvers by not only delivering a significant higher accuracy on all testing schemes, but also successfully attacking schemes where others have zero chance. We show that our approach is highly efficient as it can solve a captcha within 0.05 second using a desktop GPU. We demonstrate that our attack is generally applicable because it can bypass the advanced security features employed by most modern text captcha schemes. We hope. © 2018 Association for Computing Machinery.","Deep learning; Generative adversarial networks; Text-based CAPTCHAs; Transfer learning","Deep learning; Network security; Security systems; Adversarial networks; CAPTCHAs; Labor intensive; Security features; Security mechanism; State of the art; Testing schemes; Transfer learning; Electronic mail filters",,,,,"Are You A Human, , https://www.areyouahuman.com/; Nucaptcha, , www.nucaptcha.com/; Athanasopoulos, E., Antonatos, S., Enhanced captchas: Using animation to tell humans and computers apart (2006) IFIP International Conference on Communications and Multimedia Security, pp. 97-108; Audet, C., Mesh, J.E.D., Jr., Mesh adaptive direct search algorithms for constrained optimization (2006) Siam Journal on Optimization, 17 (1), pp. 188-217; Barreno, M., Nelson, B., Sears, R., Joseph, A.D., Tygar, J.D., Can machine learning be secure? (2006) ACM Symposium on Information, Computer and Communications Security, pp. 16-25; Bigham, J.P., Cavender, A.C., Evaluating existing audio captchas and an interface optimized for non-visual use (2009) Sigchi Conference on Human Factors in Computing Systems, pp. 1829-1838; Bursztein, E., How We Broke The Nucaptcha Video Scheme and What We Proposed to Fix It, , https://elie.net/blog/security/how-we-broke-the-nucaptcha-video-scheme-and-what-we-propose-to-fix-it; Bursztein, E., Aigrain, J., Moscicki, A., Mitchell, J.C., The end is nigh: Generic solving of text-based captchas (2014) USENIX WOOT; Bursztein, E., Bethard, S., DecapTCHA: Breaking 75% of ebay audio captchas (2009) Usenix Conference on Offensive Technologies, p. 8; Bursztein, E., Martin, M., Mitchell, J., Text-based captcha strengths and weaknesses (2011) CCS, pp. 125-138; Chellapilla, K., Larson, K., Simard, P.Y., Czerwinski, M., Computers beat humans at single character recognition in reading based human interaction proofs (hips) (2005) Conference on Email & Anti-Spam; Chow, R., Golle, P., Jakobsson, M., Wang, L., Wang, X., Making captchas clickable (2008) Proceedings of The 9th Workshop on Mobile Computing Systems and Applications, pp. 91-94. , ACM; Elson, J., Douceur, J.R., Howell, J., Saul, J., Asirra:a captcha that exploits interest-aligned manual image categorization (2007) ACM Conference on Computer and Communications Security, CCS 2007, pp. 366-374. , Alexandria, Virginia, Usa, October; Pix2Pix: Image-to-Image Translation with Conditional Adversarial Networks, , https://github.com/phillipi/pix2pix, et al., I; Gao, H., Tang, M., Liu, Y., Zhang, P., Liu, X., Research on the security of microsoftars two-layer captcha (2017) IEEE Transactions on Information Forensics & Security, 12 (7), pp. 1671-1685; Gao, H., Wei, W., Wang, X., Liu, X., Yan, J., The robustness of hollow captchas (2013) ACM Sigsac Conference on Computer & Communications Security, pp. 1075-1086; Gao, H., Yan, J., Cao, F., Zhang, Z., Lei, L., Tang, M., Zhang, P., Li, J., A simple generic attack on text captchas (2016) NDSS; Gao, S., (2014) An Evolutionary Study of Dynamic Cognitive Game Captchas: Automated Attacks and Defenses, , Dissertations & Theses Gradworks; George, D., Lehrach, W., Kansky, K., Llczaro-Gredilla, M., Laan, C., Marthi, B., Lou, X., Wang, H., A generative vision model that trains with high data efficiency and breaks text-based captchas (2017) Science, p. eaag2612; Gold, C., Holub, A., Sollich, P., Bayesian approach to feature selection and parameter tuning for support vector machine classifiers (2005) Neural Networks, 18 (5), pp. 693-701; Goodfellow, I.J., Bulatov, Y., Ibarz, J., Arnoud, S., Shet, V., Multi-digit number recognition from street view imagery using deep convolutional neural networks (2014) International Conference on Learning Representations (ICLR); Goodfellow, I.J., Pougetabadie, J., Mirza, M., Xu, B., Wardefarley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial networks (2014) Advances in Neural Information Processing Systems, 3, pp. 2672-2680; Goodfellow, I.J., Shlens, J., Szegedy, C., Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICML, pp. 1-10; Gossweiler, R., Kamvar, M., Baluja, S., What’s up captcha?:a captcha based on image orientation (2009) International Conference on World Wide Web, WWW 2009, pp. 841-850. , Madrid, Spain, April; Greg, M., Malik, J., Recognizing objects in adversarial cultter: Breaking a visual captcha (2003) IEEE Computer Society Conferene on Computer Vision and Pattern Recognition; He, K., Gkioxari, G., Dollár, P., Girshick, R., Mask, R.-C.N.N., (2017) IEEE International Conference on Computer Vision (ICCV), pp. 2980-2988; He, K., Zhang, X., Ren, S., Sun, J., Deep Residual Learning for Image Recognition, pp. 770-778; Hecht-Nielsen, R., (1989) Theory of The Backpropagation Neural Network, , Harcourt Brace & Co; Hernandezcastro, C.J., Ribagorda, A., Saez, Y., Side-channel attack on labeling captchas (2009) Computer Science; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I.P., Tygar, J.D., Adversarial machine learning (2011) IEEE Internet Computing, 15 (5), pp. 4-6; Isola, P., Zhu, J.-Y., Zhou, T., Efros, A.A., (2016) Image-to-Image Translation with Conditional Adversarial Networks, , arxiv; Strong Captcha Guidelines V1. 2, , J, W; Jiang, Z., Zhao, J., Li, X.-Y., Han, J., Xi, W., Rejecting the attack: Source authentication for wi-fi management frames using csi information (2013) IEEE INFOCOM, pp. 2544-2552; Kingma, D.P., Ba, J., ADaM: A method for stochastic optimization (2014) Computer Science; Krol, K., Parkin, S., Sasse, M.A., Better the devil you know: A user study of two captchas and a possible replacement technology (2016) NDSS Workshop on Usable Security; Le, T.A., Baydin, A.G., Zinkov, R., Wood, F., Using synthetic data to train neural networks is model-based reasoning (2017) International Joint Conference on Neural Networks, pp. 3514-3521; Lea, C., Vidal, R., Reiter, A., Hager, G.D., Temporal convolutional networks: A unified approach to action segmentation (2016) European Conference on Computer Vision, pp. 47-54; Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proceedings of The IEEE, 86 (11), pp. 2278-2324; Li, J., Monroe, W., Shi, T., Jean, S., Ritter, A., Jurafsky, D., Adversarial Learning for Neural Dialogue Generation; Meutzner, H., Kolossa, D., Reducing the cost of breaking audio captchas by active and semi-supervised learning (2014) International Conference on Machine Learning and Applications, pp. 67-73; Miyato, T., Maeda, S., Koyama, M., Nakae, K., Ishii, S., (2015) Distributional Smoothing by Virtual Adversarial Examples, , arXiv; Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D., Riedmiller, M., (2013) Playing Atari with Deep Reinforcement Learning, , arXiv; Mohamed, M., Sachdeva, N., Georgescu, M., Gao, S., Saxena, N., Zhang, C., Kumaraguru, P., Chen, W.B., A three-way investigation of a game-captcha:automated attacks, relay attacks and usability (2014) ACM Symposium on Information, Computer and Communications Security, pp. 195-206; Mohameda, M., Gaob, S., Sachdevac, N., Saxena, N., Zhangd, C., Kumaraguruc, P., Oorschote, P.C.V., On the security and usability of dynamic cognitive game captchas (2017) Journal of Computer Security, pp. 1-26; Ogilvie, W.F., Petoumenos, P., Wang, Z., Leather, H., Fast automatic heuristic construction using active learning (2014) International Workshop on Languages and Compilers for Parallel Computing, pp. 146-160; Ogilvie, W.F., Petoumenos, P., Wang, Z., Leather, H., Minimizing the cost of iterative compilation with active learning (2017) Proceedings of The 2017 International Symposium on Code Generation and Optimization, pp. 245-256. , CGO’17; Osadchy, M., Hernandez-Castro, J., Gibson, S., Dunkelman, O., Plerez-Cabo, D., No bot expects the deepcaptcha! Introducing immutable adversarial examples, with applications to captcha generation (2017) IEEE Transactions on Information Forensics & Security PP, 99, p. 1; Pan, S.J., Yang, Q., A survey on transfer learning (2010) IEEE Transactions on Knowledge & Data Engineering, 22 (10), pp. 1345-1359; Rosenberg, I., Shabtai, A., Rokach, L., Elovici, Y., (2017) Generic Black-Box End-to-End Attack Against Rnns and Other Api Calls Based Malware Classifiers, , arXiv; Schlaikjer, A., A dual-use speech captcha: Aiding visually impaired web users while providing transcriptions of audio streams (2010) LTI; Shahzad, M., Liu, A.X., Samuel, A., Behavior based human authentication on touch screen devices using gestures and signatures (2017) IEEE Transactions on Mobile Computing, 16 (10), pp. 2726-2741; Shrivastava, A., Pfister, T., Tuzel, O., Susskind, J., Wang, W., Webb, R., Learning from simulated and unsupervised images through adversarial training (2017) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2014) Computer Science; Sivakorn, S., Polakis, I., Keromytis, A.D., I am robot: (deep) learning to break semantic image captchas (2016) IEEE European Symposium on Security and Privacy, pp. 388-403; Stark, F., Hazirbas, C., Triebel, R., Cremers, D., Captcha recognition with active deep learning (2015) German Conference on Pattern Recognition Workshop; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2015) Computer Science, pp. 2818-2826; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2013) Computer Science; Tam, J., Simsa, J., Hyde, S., Ahn, L.V., Breaking audio captchas (2008) Conference on Neural Information Processing Systems, pp. 1625-1632. , Vancouver, British Columbia, Canada, December; Von Ahn, L., Blum, M., Hopper, N.J., Langford, J., (2003) CAPTCHA: Using Hard AI Problems for Security, , Springer Berlin Heidelberg; Von Ahn, L., Blum, M., Langford, J., Telling humans and computers apart automatically (2004) Communications of The Acm, 47 (2), pp. 56-60; Xu, W., Qi, Y., Evans, D., Automatically evading classifiers: A case study on pdf malware classifiers (2016) Network and Distributed System Security Symposium; Xu, Y., Reynaga, G., Chiasson, S., Frahm, J.-M., Monrose, F., Van Oorschot, P.C., Security analysis and related usability of motion-based captchas: Decoding codewords in motion (2014) IEEE Transactions on Dependable and Secure Computing, 11 (5), pp. 480-493; Yan, J., Ahmad, A.S.E., Breaking visual captchas with naive pattern recognition algorithms (2007) Computer Security Applications Conference, 2007. ACSAC 2007. Twenty-Third Annual, pp. 279-291; Yan, J., Ahmad, A.S.E., A low-cost attack on a microsoft captcha (2008) ACM Conference on Computer and Communications Security, CCS 2008, pp. 543-554. , Alexandria, Virginia, Usa, October; Yosinski, J., Clune, J., Bengio, Y., Lipson, H., How transferable are features in deep neural networks? (2014) Advances in Neural Information Processing Systems, pp. 3320-3328; Yu, L., Zhang, W., Wang, J., Yu, Y., Seqgan: Sequence Generative Adversarial Nets with Policy Gradient; Zhu, J.-Y., Park, T., Isola, P., Efros, A.A., (2017) Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks, , arXiv preprint","Tang, Z.; Northwest UniversityChina; email: zytang@nwu.edu.cn",,"ACM SIGSAC","Association for Computing Machinery","25th ACM Conference on Computer and Communications Security, CCS 2018","15 October 2018",,141172,15437221,9781450356930,,,"English","Proc ACM Conf Computer Commun Secur",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85056867234
"Bayatbabolghani F., Blanton M.","57191288110;11339505700;","Secure multi-party computation",2018,"Proceedings of the ACM Conference on Computer and Communications Security",,,,"2157","2159",,6,"10.1145/3243734.3264419","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056855668&doi=10.1145%2f3243734.3264419&partnerID=40&md5=68411c4fde8e46731dbed4ae301277cc","School of Information, University of California, Berkeley, United States; Department of Computer Science and Engineering, University at Buffalo, The State University of New York, United States","Bayatbabolghani, F., School of Information, University of California, Berkeley, United States; Blanton, M., Department of Computer Science and Engineering, University at Buffalo, The State University of New York, United States","Secure multi-party computation (SMC) is an emerging topic which has been drawing growing attention during recent decades. There are many examples which show importance of SMC constructions in practice, such as privacy-preserving decision making and machine learning, auctions, private set intersection, and others. In this tutorial, we provide a comprehensive coverage of SMC techniques, starting from precise definitions and fundamental techniques. Consequently, a significant portion of the tutorial focuses on recent advances in general SMC constructions. We cover garbled circuit evaluation (GCE) and linear secret sharing (LSS) which are commonly used for secure two-party and multi-party computation, respectively. The coverage includes both standard adversarial models: semi-honest and malicious. For GCE, we start with the original Yao’s garbled circuits construction [30] for semi-honest adversaries and consequently cover its recent optimizations such as the “free XOR,” the garbled row reduction, the half-gates optimization, and the use of AES NI techniques. We follow with a discussion of techniques for making GCE resilient to malicious behavior, which includes the cut-and-choose approach and additional techniques to deter known attacks in the presence of malicious participants. In addition, we include the-state-of-the-art protocols for oblivious transfer (OT) and OT extension in the presence of semi-honest and malicious users. For LSS, we start from standard solutions for the semi-honest adversarial model including [5, 28] and consequently move to recent efficient constructions for semi-honest and malicious adversarial models. The coverage includes different types of corruption thresholds (with and without honest majority), which imply different guarantees with respect to abort. © 2018 Copyright held by the owner/author(s).",,"Decision making; Learning systems; Efficient construction; Linear secret sharing; Malicious participant; Multiparty computation; Precise definition; Secure multi-party computation; Semi-honest adversaries; State-of-the art protocols; Cryptography",,,,,"Asharov, G., Lindell, Y., Rabin, T., Perfectly-Secure Multiplication for Any t < n/3 (2011) CRYPTO, pp. 240-258; Asharov, G., Lindell, Y., Schneider, T., Zohner, M., More Efficient Oblivious Transfer and Extensions for Faster Secure Computation (2013) ACM Conference on Computer and Communications Security (CCS), pp. 535-548; Asharov, G., Lindell, Y., Schneider, T., Zohner, M., More Efficient Oblivious Transfer Extensions with Security for Malicious Adversaries (2015) EUROCRYPT, pp. 673-701; Bellare, M., Hoang, V., Keelveedhi, S., Rogaway, P., Efficient Garbling from a Fixed-Key Blockcipher (2013) IEEE Symposium on Security and Privacy (S&P), pp. 478-492; Blakley, G.R., Safeguarding Cryptographic Keys (1979) National Computer Conference, 48, pp. 313-317; Bogdanov, D., Laur, S., Willemson, J., Sharemind: A Framework for Fast Privacy-Preserving Computations (2008) European Symposium on Research in Computer Security (ESORICS), pp. 192-206; Damgård, I., Geisler, M., Krøigaard, M., Nielsen, J.B., Asynchronous Multiparty Computation: Theory and Implementation (2009) International Workshop on Public Key Cryptography (PKC), pp. 160-179; Damgård, I., Ishai, Y., Krøigaard, M., Perfectly Secure Multiparty Computation and the Computational Overhead of Cryptography (2010) EUROCRYPT, pp. 445-465; Damgård, I., Keller, M., Larraia, E., Pastro, V., Scholl, P., Smart, N.P., Practical Covertly Secure MPC for Dishonest Majority–Or: Breaking the SPDZ Limits (2013) European Symposium on Research in Computer Security (ESORICS), pp. 1-18; Damgård, I., Nielsen, J.B., Scalable and Unconditionally Secure Multiparty Computation (2007) CRYPTO, pp. 572-590; Damgård, I., Pastro, V., Smart, N., Zakarias, S., Multiparty Computation from Somewhat Homomorphic Encryption (2012) CRYPTO, pp. 643-662; Gennaro, R., Rabin, M., Rabin, T., Simplified VSS and Fast-Track Multiparty Computations with Applications to Threshold Cryptography (1998) ACM Symposium on Principles of Distributed Computing (PODC), pp. 101-111; Goldreich, O., Micali, S., Wigderson, A., Proofs that Yield Nothing but their Validity or All Languages in NP Have Zero-Knowledge Proof Systems (1991) J. ACM, 38 (3), pp. 690-728. , 1991; Goldwasser, S., Micali, S., Wigderson, A., How to Play Any Mental Game, or a Completeness Theorem for Protocols with an Honest Majority (1987) ACM Symposium on The Theory of Computing (STOC), pp. 218-229; Holzer, A., Franz, M., Katzenbeisser, S., Veith, H., Secure Two-Party Computations in ANSI C (2012) AMC Conference on Computer and Communications Security (CCS), pp. 772-783; Ishai, Y., Kilian, J., Nissim, K., Petrank, E., Extending Oblivious Transfers Efficiently (2003) CRYPTO, pp. 145-161; Keller, M., Pastro, V., Rotaru, D., Overdrive: Making SPDZ Great Again (2018) EUROCRYPT, pp. 158-189; Kiraz, M., (2008) Secure and Fair Two-Party Computation, , Ph.D. Dissertation. Technische Universiteit Eindhoven; Kiraz, M., Schoenmakers, B., A Protocol Issue for the Malicious Case of Yao’s Garbled Circuit Construction (2006) Symposium on Information Theory in The Benelux, pp. 283-290; Kolesnikov, V., Schneider, T., Improved Garbled Circuit: Free XOR Gates and Applications (2008) International Colloquium on Automata, Languages, and Programming (ICALP), pp. 486-498; Kreuter, B., Shelat, A., Shen, C.H., Billion-Gate Secure Computation with Malicious Adversaries (2012) USENIX Security Symposium, pp. 285-300; Lindell, Y., Fast Cut-and-Choose Based Protocols for Malicious and Covert Adversaries (2013) CRYPTO, pp. 1-17; Lindell, Y., Pinkas, B., An Efficient Protocol for Secure Two-Party Computation in the Presence of Malicious Adversaries (2007) EUROCRYPT, pp. 52-78; Liu, C., Wang, X.S., Nayak, K., Huang, Y., Shi, E., ObliVM: A Programming Framework for Secure Computation (2015) IEEE Symposium on Security and Privacy (S&P), pp. 359-376; Mohassel, P., Franklin, M., Efficiency Tradeoffs for Malicious Two-Party Computation (2006) International Workshop on Public Key Cryptography (PKC), pp. 458-473; Naor, M., Pinkas, B., Efficient Oblivious Transfer Protocols (2001) ACM-SIAM Symposium on Discrete Algorithms (SODA), pp. 448-457; Pinkas, B., Schneider, T., Smart, N.P., Williams, S.C., Secure Two-Party Computation is Practical (2009) ASIACRYPT, pp. 250-267; Shamir, A., How to Share a Secret (1979) Commun. ACM, 22 (11), pp. 612-613. , 1979; Shelat, A., Shen, C., Two-Output Secure Computation with Malicious Adversaries (2011) EUROCRYPT, pp. 386-405; Yao, A.C., How to Generate and Exchange Secrets (1986) IEEE Symposium on Foundations of Computer Science (FOCS), pp. 162-167; Zahur, S., Evans, D., Obliv-C: A Language for Extensible Data-Oblivious Computation (2015) IACR Cryptology ePrint Archive Report 2015/1153, , 2015; Zahur, S., Rosulek, M., Evans, D., Two Halves Make a Whole: Reducing Data Transfer in Garbled Circuits Using Half Gates (2015) EUROCRYPT, pp. 220-250; Zhang, Y., Blanton, M., Bayatbabolghani, F., Enforcing Input Correctness via Certification in Garbled Circuit Evaluation (2017) European Symposium on Research in Computer Security (ESORICS), pp. 552-569; Zhang, Y., Steele, A., Blanton, M., PICCO: A General-Purpose Compiler for Private Distributed Computation (2013) ACM Conference on Computer and Communications Security (CCS), pp. 813-826",,,"ACM SIGSAC","Association for Computing Machinery","25th ACM Conference on Computer and Communications Security, CCS 2018","15 October 2018",,141172,15437221,9781450356930,,,"English","Proc ACM Conf Computer Commun Secur",Conference Paper,"Final","",Scopus,2-s2.0-85056855668
"Kiffer L., Rajaraman R., Shelat A.","57200413635;7007065740;18038835700;","A better method to analyze blockchain consistency",2018,"Proceedings of the ACM Conference on Computer and Communications Security",,,,"729","744",,47,"10.1145/3243734.3243814","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056853010&doi=10.1145%2f3243734.3243814&partnerID=40&md5=f9be87ecc57d0031993ddfd9dd25bc0d","Northeastern University, United States","Kiffer, L., Northeastern University, United States; Rajaraman, R., Northeastern University, United States; Shelat, A., Northeastern University, United States","The celebrated Nakamoto consensus protocol [16] ushered in several new consensus applications including cryptocurrencies. A few recent works [7, 17] have analyzed important properties of blockchains, including most significantly, consistency, which is a guarantee that all honest parties output the same sequence of blocks throughout the execution of the protocol. To establish consistency, the prior analysis of Pass, Seeman and Shelat [17] required a careful counting of certain combinatorial events that was difficult to apply to variations of Nakamoto. The work of Garay, Kiayas, and Leonardas [7] provides another method of analyzing the blockchain under the simplifying assumption that the network was synchronous. The contribution of this paper is the development of a simple Markov-chain based method for analyzing consistency properties of blockchain protocols. The method includes a formal way of stating strong concentration bounds as well as easy ways to concretely compute the bounds. We use our new method to answer a number of basic questions about consistency of blockchains: • Our new analysis provides a tighter guarantee on the consistency property of Nakamoto’s protocol, including for parameter regimes which [17] could not consider; • We analyze a family of delaying attacks first presented in [17], and extend them to other protocols; • We analyze how long a participant should wait before considering a high-value transaction “confirmed”; • We analyze the consistency of CliqueChain, a variation of the Chainweb [14] system; • We provide the first rigorous consistency analysis of GHOST [20] and also analyze a folklore “balancing""-attack. In each case, we use our framework to experimentally analyze the consensus bounds for various network delay parameters and adversarial computing percentages. We hope our techniques enable authors of future blockchain proposals to provide a more rigorous analysis of their schemes. © 2018 Copyright held by the owner/author(s).",,"Markov processes; Concentration bounds; Consensus protocols; Consistency analysis; Consistency property; Network delays; Parameter regimes; Rigorous analysis; Simplifying assumptions; Blockchain",,,,,"Apostolaki, M., Zohar, A., Vanbever, L., (2016) Hijacking Bitcoin: Routing Attacks on Cryptocurrencies, , arXiv preprint 2016; Chen, J., Micali, S., (2016) Algorand, , https://arxiv.org/abs/1607.01341; Chernoff, H., A measure of the asymptotic efficiency for tests of a hypothesis based on the sum of observations (1952) Annals of Mathematical Statistics, 23 (1952), pp. 493-509; Chung, K.-M., Lam, H., Liu, Z., Mitzenmacher, M., Chernoff-Hoeffding bounds for Markov chains: Generalized and simplified (2012) 29th International Symposium on Theoretical Aspects of Computer Science (STACS 2012), pp. 124-135; Decker, C., Wattenhofer, R., Information propagation in the bitcoin network (2013) Peer-to-Peer Computing (P2P), 2013 IEEE Thirteenth International Conference on, pp. 1-10. , IEEE; Eyal, I., Sirer, E.G., Majority is not enough: Bitcoin mining is vulnerable (2014) International Conference on Financial Cryptography and Data Security, pp. 436-454. , Springer; Garay, J.A., Kiayias, A., Leonardos, N., The bitcoin backbone protocol: Analysis and applications (2015) EUROCRYPT, (2), pp. 281-310; Garay, J.A., Kiayias, A., Leonardos, N., The bitcoin backbone protocol with chains of variable difficulty (2017) Advances in Cryptology - CRYPTO 2017 - 37th Annual International Cryptology Conference, pp. 291-323. , Santa Barbara, CA, USA, August 20-24, 2017, Proceedings, Part I; Gilad, Y., Hemo, R., Micali, S., Vlachos, G., Zeldovich, N., Algorand: Scaling Byzantine agreements for cryptocurrencies (2017) SOSP’17; Hoeffding, W., On the distribution of the number of successes in independent trials (1956) Annals of Mathematical Statistics, 27 (1956), pp. 713-721; Kiayias, A., Panagiotakos, G., Speed-security tradeoffs in blockchain protocols (2015) IACR Cryptology ePrint Archive, 2015, p. 1019. , 2015; Kiayias, A., Panagiotakos, G., On trees, chains and fast transactions in the blockchain (2016) IACR Cryptology ePrint Archive, 2016, p. 545. , 2016; Lewenberg, Y., Sompolinsky, Y., Zohar, A., Inclusive block chain protocols (2015) International Conference on Financial Cryptography and Data Security, pp. 528-547. , Springer; Martino, Q., (2018) Chainweb: A Proof-of-Work Parallel-Chain Architecture for Massive Throughput, , Popejoy; Mitzenmacher, M., Upfal, E., (2005) Probability and Computing: Randomized Algorithms and Probabilistic Analysis, , Cambridge University Press, New York, NY, USA; Nakamoto, S., (2008) Bitcoin: A Peer-to-Peer Electronic Cash System; Pass, R., Seeman, L., Shelat, A., Analysis of the blockchain protocol in asynchronous networks (2017) Annual International Conference on The Theory and Applications of Cryptographic Techniques, pp. 643-673. , Springer; Pass, R., Shi, E., The sleepy model of consensus (2017) ASI-ACRYPT’2017; Sompolinsky, Y., Lewenberg, Y., Zohar, A., Spectre: A fast and scalable cryptocurrency protocol (2016) IACR Cryptology ePrint Archive 2016, p. 1159. , 2016; Sompolinsky, Y., Zohar, A., Secure high-rate transaction processing in bitcoin (2015) International Conference on Financial Cryptography and Data Security, pp. 507-527. , Springer; Sompolinsky, Y., Zohar, A., Phantom: A scalable blockdag protocol (2018) Cryptology ePrint Archive, , https://eprint.iacr.org/2018/104, Report 2018/104",,,"ACM SIGSAC","Association for Computing Machinery","25th ACM Conference on Computer and Communications Security, CCS 2018","15 October 2018",,141172,15437221,9781450356930,,,"English","Proc ACM Conf Computer Commun Secur",Conference Paper,"Final","",Scopus,2-s2.0-85056853010
"Nasr M., Shokri R., Houmansadr A.","57191968336;16022842700;55665568400;","Machine learning with membership privacy using adversarial regularization",2018,"Proceedings of the ACM Conference on Computer and Communications Security",,,,"634","646",,91,"10.1145/3243734.3243855","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056846596&doi=10.1145%2f3243734.3243855&partnerID=40&md5=f566cded812e381f9377c132b36847da","University of Massachusetts Amherst, United States; National University of Singapore, Singapore","Nasr, M., University of Massachusetts Amherst, United States; Shokri, R., National University of Singapore, Singapore; Houmansadr, A., University of Massachusetts Amherst, United States","Machine learning models leak significant amount of information about their training sets, through their predictions. This is a serious privacy concern for the users of machine learning as a service. To address this concern, in this paper, we focus on mitigating the risks of black-box inference attacks against machine learning models. We introduce a mechanism to train models with membership privacy, which ensures indistinguishability between the predictions of a model on its training data and other data points (from the same distribution). This requires minimizing the accuracy of the best black-box membership inference attack against the model. We formalize this as a min-max game, and design an adversarial training algorithm that minimizes the prediction loss of the model as well as the maximum gain of the inference attacks. This strategy, which can guarantee membership privacy (as prediction indistinguishability), acts also as a strong regularizer and helps generalizing the model. We evaluate the practical feasibility of our privacy mechanism on training deep neural networks using benchmark datasets. We show that the min-max strategy can mitigate the risks of membership inference attacks (near random guess), and can achieve this with a negligible drop in the model’s prediction accuracy (less than 4%). © 2018 Copyright held by the owner/author(s).","Adversarial process; Data privacy; Indistinguishability; Inference attacks; Machine learning; Membership privacy; Min-max game","Artificial intelligence; Deep neural networks; Forecasting; Inference engines; Learning algorithms; Learning systems; Amount of information; Indistinguishability; Inference attacks; Machine learning models; Min-max; Prediction accuracy; Privacy mechanisms; Training algorithms; Data privacy",,,,,"Abadi, M., Chu, A., Goodfellow, I., Brendan McMahan, H., Mironov, I., Talwar, K., Zhang, L., Deep learning with differential privacy (2016) Proceedings of The 2016 ACM SIGSAC Conference on Computer and Communications Security, , ACM; Alvim, M.S., Chatzikokolakis, K., Kawamoto, Y., Palamidessi, C., Information leakage games (2017) International Conference on Decision and Game Theory for Security, , Springer; Arjovsky, M., Chintala, S., Bottou, L., (2017) Wasserstein Gan, , arXiv preprint 2017; Avriel, M., (2003) Nonlinear Programming: Analysis and Methods, , Courier Corporation; Backes, M., Berrang, P., Humbert, M., Manoharan, P., Membership privacy in MicroRNA-based studies (2016) Proceedings of The 2016 ACM SIGSAC Conference on Computer and Communications Security, , ACM; Bassily, R., Smith, A., Thakurta, A., Private empirical risk minimization: Efficient algorithms and tight error bounds (2014) Foundations of Computer Science (FOCS), 2014 IEEE 55th Annual Symposium on, , IEEE; Bishop, C.M., (2006) Pattern Recognition and Machine Learning (Information Science and Statistics), , Springer-Verlag, Berlin, Heidelberg; Bonawitz, K., Ivanov, V., Kreuter, B., Marcedone, A., Brendan McMahan, H., Patel, S., Ramage, D., Seth, K., Practical secure aggregation for privacy-preserving machine learning (2017) Proceedings of The 2017 ACM SIGSAC Conference on Computer and Communications Security, , ACM; Carlini, N., Liu, C., Kos, J., Erlingsson, Ú., Song, D., (2018) The Secret Sharer: Measuring Unintended Neural Network Memorization & Extracting Secrets, , arXiv preprint 2018; Chaudhuri, K., Monteleoni, C., Sarwate, A.D., Differentially private empirical risk minimization (2011) Journal of Machine Learning Research, , 2011; Dai, Z., Yang, Z., Yang, F., Cohen, W.W., Salakhutdinov, R.R., Good semi-supervised learning that requires a bad gan (2017) Advances in Neural Information Processing Systems; Daskalakis, C., Ilyas, A., Syrgkanis, V., Zeng, H., (2017) Training GANs with Optimism, , arXiv preprint 2017; Dinur, I., Nissim, K., Revealing information while preserving privacy (2003) Proceedings of The Twenty-Second ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems, , ACM; Dumoulin, V., Belghazi, I., Poole, B., Mastropietro, O., Lamb, A., Arjovsky, M., Courville, A., (2016) Adversarially Learned Inference, , arXiv preprint 2016; Dwork, C., McSherry, F., Nissim, K., Smith, A., Calibrating noise to sensitivity in private data analysis (2006) Theory of Cryptography Conference, , Springer; Dwork, C., Roth, A., The algorithmic foundations of differential privacy (2014) Foundations and Trends® in Theoretical Computer Science, , 2014; Dwork, C., Smith, A., Steinke, T., Ullman, J., (2017) Exposed! A Survey of Attacks on Private Data, , 2017; Dwork, C., Smith, A., Steinke, T., Ullman, J., Vadhan, S., Robust traceability from trace amounts (2015) Foundations of Computer Science (FOCS), 2015 IEEE 56th Annual Symposium on, , IEEE; Fredrikson, M., Jha, S., Ristenpart, T., Model inversion attacks that exploit confidence information and basic countermeasures (2015) Proceedings of The 22nd ACM SIGSAC Conference on Computer and Communications Security, , ACM; Gilad-Bachrach, R., Dowlin, N., Laine, K., Lauter, K., Naehrig, M., Wernsing, J., Cryptonets: Applying neural networks to encrypted data with high throughput and accuracy (2016) International Conference on Machine Learning; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems; Hardt, M., Recht, B., Singer, Y., (2015) Train Faster, Generalize Better: Stability of Stochastic Gradient Descent, , arXiv preprint 2015; Homer, N., Szelinger, S., Redman, M., Duggan, D., Tembe, W., Muehling, J., Pearson, J.V., Craig, D.W., Resolving individuals contributing trace amounts of DNA to highly complex mixtures using high-density SNP genotyping microarrays (2008) PLoS Genetics, , 2008; Hsu, J., Roth, A., Ullman, J., Differential privacy for the analyst via private equilibrium computation (2013) Proceedings of The Forty-Fifth Annual ACM Symposium on Theory of Computing, , ACM; Huang, G., Liu, Z., Weinberger, K.Q., Van Der Maaten, L., Densely connected convolutional networks (2017) Proceedings of The IEEE Conference on Computer Vision and Pattern Recognition; Hunt, T., Song, C., Shokri, R., Shmatikov, V., Witchel, E., (2018) Chiron: Privacy-Preserving Machine Learning as A Service, , arXiv preprint 2018; Jia, J., Gong, N.Z., (2018) AttriGuard: A Practical Defense Against Attribute Inference Attacks Via Adversarial Machine Learning, , arXiv preprint 2018; Kingma, D.P., Ba, J., (2014) Adam: A Method for Stochastic Optimization, , arXiv preprint 2014; Kozinski, M., Simon, L., Jurie, F., (2017) An Adversarial Regu-Larisation for Semi-Supervised Training of Structured Output Neural Networks, , arXiv preprint 2017; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images, , 2009; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems; Li, N., Qardaji, W., Su, D., Wu, Y., Yang, W., Membership privacy: A unifying framework for privacy definitions (2013) Proceedings of The 2013 ACM SIGSAC Conference on Computer & Communications Security, , ACM; Lindell, Y., Pinkas, B., Privacy preserving data mining (2000) Annual International Cryptology Conference, , Springer; Manshaei, M.H., Zhu, Q., Alpcan, T., Bacsar, T., Hubaux, J.-P., Game theory meets network security and privacy (2013) ACM Computing Surveys (CSUR), , 2013; Miyato, T., Maeda, S.-I., Koyama, M., Ishii, S., (2017) Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning, , arXiv preprint 2017; Miyato, T., Maeda, S.-I., Koyama, M., Nakae, K., Ishii, S., (2015) Distributional Smoothing with Virtual Adversarial Training, , arXiv preprint 2015; Mohassel, P., Zhang, Y., SecureML: A system for scalable privacy-preserving machine learning (2017) Security and Privacy (SP), 2017 IEEE Symposium on, , IEEE; Odena, A., (2016) Semi-Supervised Learning with Generative Adversarial Networks, , arXiv preprint 2016; Ohrimenko, O., Schuster, F., Fournet, C., Mehta, A., Nowozin, S., Vaswani, K., Costa, M., Oblivious multi-party machine learning on trusted processors (2016) USENIX Security Symposium; Papernot, N., Song, S., Mironov, I., Raghunathan, A., Talwar, K., Erlingsson, Ú., (2018) Scalable Private Learning with PATE, , arXiv preprint 2018; Pyrgelis, A., Troncoso, C., De Cristofaro, E., (2017) Knock Knock, Who’S There? Membership Inference on Aggregate Location Data, , arXiv preprint 2017; Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., Chen, X., Improved techniques for training gans (2016) Advances in Neural Information Processing Systems, pp. 2234-2242; Sankararaman, S., Obozinski, G., Jordan, M.I., Halperin, E., Genomic privacy and limits of individual detection in a pool (2009) Nature Genetics, , 2009; Shokri, R., Privacy games: Optimal user-centric data obfuscation (2015) Proceedings on Privacy Enhancing Technologies, , 2015; Shokri, R., Stronati, M., Song, C., Shmatikov, V., Membership inference attacks against machine learning models (2017) Security and Privacy (SP), 2017 IEEE Symposium on; Shokri, R., Theodorakopoulos, G., Troncoso, C., Hubaux, J.-P., Le Boudec, J.-Y., Protecting location privacy: Optimal strategy against localization attacks (2012) Proceedings of The 2012 ACM Conference on Computer and Communications Security, , ACM; Tramèr, F., Zhang, F., Juels, A., Reiter, M.K., Ristenpart, T., Stealing machine learning models via prediction apis (2016) USENIX Security; Wang, B., Gong, N.Z., (2018) Stealing Hyperparameters in Machine Learning, , arXiv preprint 2018; Wang, R., Li, Y.F., Wang, X., Tang, H., Zhou, X., Learning your identity and disease from research papers: Information leaks in genome wide association study (2009) Proceedings of The 16th ACM Conference on Computer and Communications Security, , ACM; Wei, L., Liu, Y., Luo, B., Li, Y., Xu, Q., (2018) I Know What You See: Power Side-Channel Attack on Convolutional Neural Network Accelerators, , arXiv preprint 2018; Yeom, S., Giacomelli, I., Fredrikson, M., Jha, S., (2018) Privacy Risk in Machine Learning: Analyzing The Connection to Overfitting, , arXiv preprint 2018; Zhang, T., Solving large scale linear prediction problems using stochastic gradient descent algorithms (2004) Proceedings of The Twenty-First International Conference on Machine Learning, , ACM",,,"ACM SIGSAC","Association for Computing Machinery","25th ACM Conference on Computer and Communications Security, CCS 2018","15 October 2018",,141172,15437221,9781450356930,,,"English","Proc ACM Conf Computer Commun Secur",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85056846596
"Patton C., Shrimpton T.","57195494610;23398363600;","Partially specified channels the TLS 1.3 record layer without Elision",2018,"Proceedings of the ACM Conference on Computer and Communications Security",,,,"1415","1428",,8,"10.1145/3243734.3243789","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056845372&doi=10.1145%2f3243734.3243789&partnerID=40&md5=5c37e6ad399a19b588ebd66e838b82b0","University of Florida, United States","Patton, C., University of Florida, United States; Shrimpton, T., University of Florida, United States","We advance the study of secure stream-based channels (Fischlin et al., CRYPTO’15) by considering the multiplexing of many data streams over a single channel, an essential feature of real world protocols such as TLS. Our treatment adopts the definitional perspective of Rogaway and Stegers (CSF’09), which offers an elegant way to reason about what standardizing documents actually provide: a partial specification of a protocol that admits a collection of compliant, fully realized implementations. We formalize partially specified channels as the component algorithms of two parties communicating over a channel. Each algorithm has an oracle that provides specification details; the algorithms abstract the things that must be explicitly specified, while the oracle abstracts the things that need not be. Our security notions, which capture a variety of privacy and integrity goals, allow the adversary to respond to these oracle queries; security relative to these notions implies that the channel withstands attacks in the presence of worst-case (i.e., adversarial) realizations of the specification details. We apply this framework to a formal treatment of the TLS 1.3 record and, in doing so, show that its security hinges crucially upon details left unspecified by the standard. © 2018 Copyright held by the owner/author(s). Publication rights licensed to the Association for Computing Machinery.","Cryptographic standards; Partially specified protocols; Provable security; Stream-based channels; TLS 1.3","Specifications; Data stream; Essential features; Partial specifications; Provable security; Real-world; Security notion; Single channels; Stream-based; Seebeck effect",,,,,"Albrecht, M.R., Degabriele, J.P., Hansen, T.B., Paterson, K.G., A Surfeit of SSH Cipher Suites (2016) Proceedings of The 23rd ACM SIGSAC Conference on Computer and Communications Security, pp. 1480-1491. , ACM; Albrecht, M.R., Paterson, K.G., Watson, G.J., Plaintext Recovery Attacks Against SSH (2009) Proceedings of The 30th IEEE Symposium on Security and Privacy, pp. 16-26. , IEEE; AlFardan, N.J., Paterson, K.G., Lucky Thirteen: Breaking the TLS and DTLS Record Protocols (2013) 2013 IEEE Symposium on Security and Privacy, pp. 526-540. , IEEE; Andreeva, E., Bogdanov, A., Luykx, A., Mennink, B., Mouha, N., Yasuda, K., How to Securely Release Unverified Plaintext in Authenticated Encryption (2014) Advances in Cryptology – ASIACRYPT 2014, pp. 105-125. , Springer Berlin Heidelberg; Badertscher, C., Matt, C., Maurer, U., Rogaway, P., Tackmann, B., Augmented Secure Channels and the Goal of the TLS 1.3 Record Layer (2015) Provable Security, pp. 85-104. , Springer International Publishing; Barwell, G., Page, D., Stam, M., Rogue Decryption Failures: Reconciling AE Robustness Notions (2015) Proceedings of The 15th IMA International Conference on Cryptography and Coding, pp. 94-111. , Springer International Publishing; Bellare, M., Kohno, T., Namprempre, C., Breaking and Provably Repairing the SSH Authenticated Encryption Scheme: A Case Study of the Encode-then-Encrypt-and-MAC Paradigm (2004) ACM Trans. Inf. Syst. Secur., 7 (2), pp. 206-241. , 2004; Bellare, M., Namprempre, C., Authenticated Encryption: Relations among notions and analysis of the generic composition paradigm (2000) Cryptology ePrint Archive, , https://eprint.iacr.org/2000/025, Report; Bellare, M., Rogaway, P., Encode-Then-Encipher Encryption: How to Exploit Nonces or Redundancy in Plaintexts for Efficient Cryptography (2000) Advances in Cryptology — ASIACRYPT 2000, pp. 317-330. , Springer Berlin Heidelberg; Bellare, M., Rogaway, P., The Security of Triple Encryption and a Framework for Code-based Game-playing Proofs (2006) Proceedings of The 24th Annual International Conference on The Theory and Applications of Cryptographic Techniques, pp. 409-426. , Springer-Verlag; Bellare, M., Tackmann, B., The Multi-user Security of Authenticated Encryption: AES-GCM in TLS (2016) Advances in Cryptology – CRYPTO 2016, pp. 247-276. , Springer Berlin Heidelberg; Bhargavan, K., Lavaud, A.D., Fournet, C., Pironti, A., Strub, P.Y., Triple Handshakes and Cookie Cutters: Breaking and Fixing Authentication over TLS (2014) Proceedings of The 35th IEEE Symposium on Security and Privacy, pp. 98-113. , IEEE; Boldyreva, A., Degabriele, J.P., Paterson, K.G., Stam, M., Security of Symmetric Encryption in the Presence of Ciphertext Fragmentation (2012) Advances in Cryptology – EUROCRYPT 2012, pp. 682-699. , Springer Berlin Heidelberg; Boldyreva, A., Degabriele, J.P., Paterson, K.G., Stam, M., On Symmetric Encryption with Distinguishable Decryption Failures (2014) Fast Software Encryption, pp. 367-390. , Springer Berlin Heidelberg; Degabriele, J.P., Paterson, K., Watson, G., Provable Security in the Real World (2011) IEEE Security & Privacy, 9 (3), pp. 33-41. , 2011; Degabriele, J.P., Paterson, K.G., On the (in)Security of IPsec in MAC-then-encrypt Configurations (2010) Proceedings of The 17th ACM Conference on Computer and Communications Security, pp. 493-504. , ACM; Delignat-Lavaud, A., Fournet, C., Kohlweiss, M., Protzenko, J., Rastogi, A., Swamy, N., Zanella-Beguelin, S., Zinzindohoue, J.K., Implementing and Proving the TLS 1.3 Record Layer (2017) Proceedings of The 38th IEEE Symposium on Security and Privacy (SP), pp. 463-482. , IEEE; Fischlin, M., Günther, F., Marson, G.A., Paterson, K.G., Data Is a Stream: Security of Stream-Based Channels (2015) Advances in Cryptology – CRYPTO 2015, pp. 545-564. , Springer Berlin Heidelberg; Fischlin, M., Günther, F., Marson, G.A., Paterson, K.G., Data Is a Stream: Security of Stream-Based Channels (2017) Cryptology ePrint Archive, , https://eprint.iacr.org/2017/1191, Report 2017/1191; QUIC, A Multiplexed Stream Transport Over UDP, , https://www.chromium.org/quic, n. d. accessed 13 Feb 2018; Hoang, V.T., Krovetz, T., Rogaway, P., Robust Authenticated-Encryption AEZ and the Problem That It Solves (2015) Advances in Cryptology – EUROCRYPT 2015, pp. 15-44. , Springer Berlin Heidelberg; Kent, S., Seo, K., (2005) Security Architecture for The Internet Protocol, , http://www.rfc-editor.org/rfc/rfc4301.txt, RFC 4301. RFC Editor. http://www.rfc-editor.org/rfc/rfc4301.txt; Krawczyk, H., Cryptographic Extraction and Key Derivation: The HKDF Scheme (2010) Advances in Cryptology – CRYPTO 2010, pp. 631-648. , Springer Berlin Heidelberg; McGrew, D., (2008) An Interface and Algorithms for Authenticated Encryption, , http://www.rfc-editor.org/rfc/rfc5116.txt, RFC 5116. RFC Editor. http://www.rfc-editor.org/rfc/rfc5116.txt; Namprempre, C., Rogaway, P., Shrimpton, T., Reconsidering Generic Composition (2014) Advances in Cryptology – EUROCRYPT 2014, pp. 257-274. , Springer Berlin Heidelberg; Paterson, K.G., AlFardan, N.J., Plaintext-Recovery Attacks Against Datagram TLS (2012) 19th Annual Network and Distributed System Security Symposium, NDSS; Paterson, K.G., Ristenpart, T., Shrimpton, T., Tag Size does Matter: Attacks and Proofs for the TLS Record Protocol (2011) Advances in Cryptology – ASIACRYPT 2011, pp. 372-389. , Springer Berlin Heidelberg; Patton, C., Shrimpton, T., Partially specified channels: The TLS 1.3 record layer without elision (2018) Cryptology ePrint Archive, , https://eprint.iacr.org/2018/634, Report; (2018) The Transport Layer Security (TLS) Protocol Version 1.3. Internet-Draft Draft-Ietf-Tls-Tls13-23, , http://www.ietf.org/internet-drafts/draft-ietf-tls-tls13-23.txt, IETF Secretariat. https://tools.ietf.org/html/draft-ietf-tls-tls13-23; Rescorla, E., (2018) The Transport Layer Security (TLS) Protocol Version 1.3, , RFC 8446. RFC Editor; Rescorla, E., Tschofenig, H., Modadugu, N., (2017) The Datagram Transport Layer Security (DTLS) Protocol Version 1.3. Internet-Draft Draft-Ietf-Tls-Dtls13-22, , http://www.ietf.org/internet-drafts/draft-ietf-tls-dtls13-22, IETF Secretariat. txthttps://tools.ietf.org/html/draft-ietf-tls-dtls13-22; Rogaway, P., Authenticated-encryption with Associated-data (2002) Proceedings of The 9th ACM Conference on Computer and Communications Security, pp. 98-107. , ACM; Rogaway, P., Stegers, T., Authentication without Elision (2009) 2009 22nd IEEE Computer Security Foundations Symposium, pp. 26-39. , IEEE; Smyth, B., Pironti, A., Truncating TLS Connections to Violate Beliefs in Web Applications (2013) Presented as Part of The 7th USENIX Workshop on Offensive Technologies, , USENIX; Vaudenay, S., Security Flaws Induced by CBC Padding — Applications to SSL, IPSEC, WTLS.. (2002) Advances in Cryptology — EUROCRYPT 2002, pp. 534-545. , Springer Berlin Heidelberg; Ylonen, T., Lonvick, C., (2006) The Secure Shell (SSH) Protocol Architecture, , http://www.rfc-editor.org/rfc/rfc4251.txt, RFC 4251. RFC Editor. http://www.rfc-editor.org/rfc/rfc4251.txt",,,"ACM SIGSAC","Association for Computing Machinery","25th ACM Conference on Computer and Communications Security, CCS 2018","15 October 2018",,141172,15437221,9781450356930,,,"English","Proc ACM Conf Computer Commun Secur",Conference Paper,"Final","",Scopus,2-s2.0-85056845372
"Hoang V.T., Tessaro S., Thiruvengadam A.","55398944800;13405791300;55599163600;","The multi-user security of GCM, revisited: Tight bounds for nonce randomization",2018,"Proceedings of the ACM Conference on Computer and Communications Security",,,,"1429","1440",,11,"10.1145/3243734.3243816","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056826998&doi=10.1145%2f3243734.3243816&partnerID=40&md5=26efe70d545ffd001b69ed1559ed782f","Department of Computer Science, Florida State University, United States; Department of Computer Science, University of California Santa Barbara, United States","Hoang, V.T., Department of Computer Science, Florida State University, United States; Tessaro, S., Department of Computer Science, University of California Santa Barbara, United States; Thiruvengadam, A., Department of Computer Science, University of California Santa Barbara, United States","Multi-user (mu) security considers large-scale attackers (e.g., state actors) that given access to a number of sessions, attempt to compromise at least one of them. Mu security of authenticated encryption (AE) was explicitly considered in the development of TLS 1.3. This paper revisits the mu security of GCM, which remains to date the most widely used dedicated AE mode. We provide new concrete security bounds which improve upon previous work by adopting a refined parameterization of adversarial resources that highlights the impact on security of (1) nonce re-use across users and of (2) re-keying. As one of the main applications, we give tight security bounds for the nonce-randomization mechanism adopted in the record protocol of TLS 1.3 as a mitigation of large-scale multi-user attacks. We provide tight security bounds that yield the first validation of this method. In particular, we solve the main open question of Bellare and Tackmann (CRYPTO’16), who only considered restricted attackers which do not attempt to violate integrity, and only gave non-tight bounds. © 2018 Association for Computing Machinery.",,"Cryptography; Random processes; Authenticated encryption; Concrete securities; Multi-user; Re-keying; Record protocols; Tight bound; Tight security bounds; Authentication",,,,,"Baugher, M., McGrew, D., Naslund, M., Carrara, E., Norrman, K., The Secure Real-time Transport Protocol (SRTP) (2004) Internet-Draft. Internet Engineering Task Force, , https://tools.ietf.org/html/rfc3711; Bellare, M., Bernstein, D.J., Tessaro, S., Hash-Function Based PRFs: AMAC and Its Multi-User Security (2016) EUROCRYPT 2016, Part I (LNCS), 9665, pp. 566-595. , https://doi.org/10.1007/978-3-662-49890-3_22, Marc Fischlin and Jean-Sébastien Coron (Eds.),. Springer, Heidelberg; Bellare, M., Boldyreva, A., Micali, S., Public-Key Encryption in a Multi-user Setting: Security Proofs and Improvements (2000) EUROCRYPT 2000 (LNCS), 1807, pp. 259-274. , Bart Preneel (Ed.),. Springer, Heidelberg; Bellare, M., Hoang, V.T., Identity-Based Format-Preserving Encryption (2017) ACM CCS, 17, pp. 1515-1532. , Bhavani M. Thuraisingham, David Evans, Tal Malkin, and Dongyan Xu (Eds.). ACM Press; Bellare, M., Tackmann, B., The Multi-user Security of Authenticated Encryption: AES-GCM in TLS 1.3 (2016) CRYPTO 2016, Part I (LNCS), 9814, pp. 247-276. , https://doi.org/10.1007/978-3-662-53018-4_10, Matthew Robshaw and Jonathan Katz (Eds.),. Springer, Heidelberg; Biham, E., How to Decrypt or Even Substitute DES-Encrypted Messages in 228 Steps (2002) Inf. Process. Lett., pp. 117-124. , 2002; Bose, P., Hoang, V.T., Tessaro, S., Revisiting AES-GCM-SIV: Multi-user Security, Faster Key Derivation, and Better Bounds (2018) EUROCRYPT 2018; Chen, S., Steinberger, J.P., Tight Security Bounds for Key-Alternating Ciphers (2014) EUROCRYPT 2014 (LNCS), 8441, pp. 327-350. , https://doi.org/10.1007/978-3-642-55220-5_19, Phong Q. Nguyen and Elisabeth Oswald (Eds.),. Springer, Heidelberg; Goldwasser, S., Bellare, M., Lecture notes on cryptography (1999) Summer Course “Cryptography and Computer Security, , at MIT. 1999; Hoang, V.T., Tessaro, S., Key-Alternating Ciphers and Key-Length Extension: Exact Bounds and Multi-user Security (2016) CRYPTO 2016, Part I (LNCS), 9814, pp. 3-32. , https://doi.org/10.1007/978-3-662-53018-4_1, Matthew Robshaw and Jonathan Katz (Eds.),. Springer, Heidelberg; Hoang, V.T., Tessaro, S., The Multi-user Security of Double Encryption (2017) EUROCRYPT 2017, Part II (LNCS), pp. 381-411. , Jean-Sébastien Coron and Jesper Buus Nielsen (Eds.),. Springer, Heidelberg,10211; Iwata, T., Ohashi, K., Minematsu, K., Breaking and Repairing GCM Security Proofs (2012) CRYPTO 2012 (LNCS), 7417, pp. 31-49. , Reihaneh Safavi-Naini and Ran Canetti (Eds.),. Springer, Heidelberg; Luykx, A., Mennink, B., Paterson, K.G., Analyzing Multi-key Security Degradation (2017) ASIACRYPT 2017, Part II (LNCS), pp. 575-605. , Tsuyoshi Takagi and Thomas Peyrin (Eds.),. Springer, Heidelberg,10625; Maurer, U.M., Indistinguishability of Random Systems (2002) EUROCRYPT 2002 (LNCS), 2332, pp. 110-132. , Lars R. Knudsen (Ed.),. Springer, Heidelberg; McGrew, D.A., Generation of Deterministic Initialization Vectors (IVs) and Nonces (2013) Internet-Draft Draft-Mcgrew-Iv-Gen-03, , https://datatracker.ietf.org/doc/html/draft-mcgrew-iv-gen-03WorkinProgress, ternet Engineering Task Force; McGrew, D.A., Fluhrer, S.R., Attacks on Additive Encryption of Redundant Plaintext and Implications on Internet Security (2001) SAC 2000 (LNCS), 2012, pp. 14-28. , Douglas R. Stinson and Stafford E. Tavares (Eds.),. Springer, Heidelberg; McGrew, D.A., Viega, J., The Security and Performance of the Galois/Counter Mode (GCM) of Operation (2004) INDOCRYPT 2004 (LNCS), 3348, pp. 343-355. , Anne Canteaut and Kapalee Viswanathan (Eds.),. Springer, Heidelberg; Mouha, N., Luykx, A., Multi-key Security: The Even-Mansour Construction Revisited (2015) CRYPTO 2015, Part I (LNCS), 9215, pp. 209-223. , https://doi.org/10.1007/978-3-662-47989-6_10, Rosario Gennaro and Matthew J. B. Robshaw (Eds.),. Springer, Heidelberg; Patarin, J., The “Coefficients H” Technique (Invited Talk) (2009) SAC 2008 (LNCS), 5381, pp. 328-345. , Roberto Maria Avanzi, Liam Keliher, and Francesco Sica (Eds.),. Springer, Heidelberg; Rescorla, E., (2018) The Transport Layer Security (TLS) Protocol Version 1.3, , https://tools.ietf.org/html/draft-ietf-tls-tls13-28Work, ternet-Draft. Internet Engineering Task Force. Progress; Rogaway, P., Shrimpton, T., A Provable-Security Treatment of the Key-Wrap Problem (2006) EUROCRYPT 2006 (LNCS), 4004, pp. 373-390. , Serge Vaudenay (Ed.),. Springer, Heidelberg; Salowey, J., Choudhury, A., McGrew, D.A., AES Galois Counter Mode (GCM) Cipher Suites for TLS (2008) RFC, 5288, pp. 1-8. , 2008; Tessaro, S., Optimally Secure Block Ciphers from Ideal Primitives (2015) ASIACRYPT 2015, Part II (LNCS), 9453, pp. 437-462. , https://doi.org/10.1007/978-3-662-48800-3_18, Tetsu Iwata and Jung Hee Cheon (Eds.),. Springer, Heidelberg",,,"ACM SIGSAC","Association for Computing Machinery","25th ACM Conference on Computer and Communications Security, CCS 2018","15 October 2018",,141172,15437221,9781450356930,,,"English","Proc ACM Conf Computer Commun Secur",Conference Paper,"Final","",Scopus,2-s2.0-85056826998
"Dixit V.H., Doupé A., Shoshitaishvili Y., Zhao Z., Ahn G.-J.","57201064200;36189698400;55489057600;56028068100;7005252334;","AIM-SDN: Aacking information mismanagement in SDN-datastores",2018,"Proceedings of the ACM Conference on Computer and Communications Security",,,,"664","676",,12,"10.1145/3243734.3243799","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056824448&doi=10.1145%2f3243734.3243799&partnerID=40&md5=77e7b8bf75fd532701008d2c9765560b","Arizona State University, Samsung Research, United States","Dixit, V.H., Arizona State University, Samsung Research, United States; Doupé, A., Arizona State University, Samsung Research, United States; Shoshitaishvili, Y., Arizona State University, Samsung Research, United States; Zhao, Z., Arizona State University, Samsung Research, United States; Ahn, G.-J., Arizona State University, Samsung Research, United States","Network Management is a critical process for an enterprise to con-gure and monitor the network devices using cost eective methods. It is imperative for it to be robust and free from adversarial or accidental security aws. With the advent of cloud computing and increasing demands for centralized network control, conventional management protocols like SNMP appear inadequate and newer techniques like NMDA and NETCONF have been invented. However, unlike SNMP which underwent improvements concentrating on security, the new data management and storage techniques have not been scrutinized for the inherent security aws. In this paper, we identify several vulnerabilities in the widely used critical infrastructures which leverage the Network Management Datastore Architecture design (NMDA). Software Dened Networking (SDN), a proponent of NMDA, heavily relies on its datastores to program and manage the network. We base our research on the security challenges put forth by the existing datastore’s design as implemented by the SDN controllers. The vulnerabilities identied in this work have a direct impact on the controllers like OpenDayLight, Open Network Operating System and their proprietary implementations (by CISCO, Ericsson, RedHat, Brocade, Juniper, etc). Using our threat detection methodology, we demonstrate how the NMDA-based implementations are vulnerable to attacks which compromise availability, integrity, and condentiality of the network. We nally propose defense measures to address the security threats in the existing design and discuss the challenges faced while employing these countermeasures. © 2018 Copyright held by the owner/author(s).",,"Digital storage; Distributed computer systems; Internet protocols; Network management; Architecture designs; Centralized networks; Defense measures; Management protocols; Security challenges; Security threats; Storage technique; Threat detection; Information management",,,,,"(2018) YANG Data Models in The Industry: Current State of Aairs, , http://www.claise.be/2018/03/yang-data-models-in-the-industrycurrent-stte-of-aairs-march-2018/, March; Berde, P., Gerola, M., Hart, J., Higuchi, Y., Kobayashi, M., Koide, T., Lantz, B., Parulkar, G., ONOS: Towards an open, distributed SDN OS (2014) Proceedings of The Third Workshop on Hot Topics in Software Dened Networking (HotSDN’14), pp. 1-6. , https://doi.org/10.1145/2620728.2620744, ACM, New York, NY, USA; Bierman, A., Bjorklund, M., Watsen, K., (2017) RESTCONF Protocol, , 2017; Case, J.D., Fedor, M., Schostall, M.L., Davin, J., (1990) Simple Network Management Protocol, , SNMPv1: RFC-1067. 1990; Dhawan, M., Poddar, R., Mahajan, K., Mann, V., Sphinx: Detecting security attacks in software-dened networks (2015) Proceedings of The Network and Distributed System Security Symposium 2015; Enns, R., (2006) Network Conguration Protocol (NETCONF), , 2006; Software-Dened Networking (SDN): Layers and Architecture Terminology, , Internet Research Task Force. RFC-7426; Simple Network Management Protocol, , SNMPv3: RFC-3418; (1993) Simple Network Management Protocol, , SNMPv2: RFC-1452. April 1993; (2006) Using The NETCONF Conguration Protocol over Secure SHell (SSH), , RFC-4742. 2006; (2009) NETCONF over Transport Layer Security (TLS), , RFC-5539. 2009; Hizver, J., Taxonomic modeling of security threats in software dened networking (2015) BlackHat Conference, pp. 1-16; Hong, S., Xu, L., Wang, H., Gu, G., Poisoning network visibility in software-dened networks: New attacks and countermeasures (2015) Proceedings of The Network and Distributed System Security Symposium 2015; Jain, S., Kumar, A., Mandal, S., Ong, J., Poutievski, L., Singh, A., Venkata, S., Zhu, M., B4: Experience with a globally-deployed software dened WAN (2013) ACM SIGCOMM Computer Communication Review, 43, pp. 3-14. , ACM; Jo, H., Nam, J., Shin, S., Nosarmor: Building a secure network operating system (2018) Security and Communication Networks, p. 2018; Kang, M.S., Gligor, V.D., Sekar, V., Spiffy: Inducing cost-detectability tradeos for persistent link-flooding attacks (2016) Proceedings of The Network and Distributed System Security Symposium 2016; Kim, H., Feamster, N., Improving network management with software dened networking (2013) IEEE Communications Magazine, 51 (2), pp. 114-119; Klöti, R., Kotronis, V., Smith, P., OpenFlow: A security analysis (2013) 2013 21st IEEE International Conference on Network Protocols (ICNP), pp. 1-6; Lee, S., Yoon, C., Lee, C., Shin, S., Yegneswaran, V., Porras, P., Delta: A security assessment framework for software-dened networks (2017) Proceedings of The Network and Distributed System Security Symposium 2017; Lee, S., Yoon, C., Shin, S., The smaller, the shrewder: A simple malicious application can kill an entire SDN environment (2016) Proceedings of The 2016 ACM International Workshop on Security in Software Dened Networks & Network Function Virtualization, pp. 23-28. , ACM; Malhotra, A., Cohen, I.E., Brakke, E., Goldberg, S., Attacking the network time protocol (2016) Proceedings of The Network and Distributed System Security Symposium 2016; McKeown, N., Anderson, T., Balakrishnan, H., Parulkar, G., Peterson, L., Rexford, J., Shenker, S., Turner, J., OpenFlow: Enabling innovation in campus networks (2008) ACM SIGCOMM Computer Communication Review, 38 (2), pp. 69-74. , 2008; Medved, J., Varga, R., Tkacik, A., Gray, K., Opendaylight: Towards a Model-Driven SDN Controller architecture (2014) Proceeding of IEEE International Symposium on A World of Wireless, Mobile and Multimedia Networks 2014, pp. 1-6. , https://doi.org/10.1109/WoWMoM.2014.6918985; Nadeau, T.D., Gray, K., (2013) SDN: Software Dened Networks: An Authoritative Review of Network Programmability Technologies, , O’Reilly Media, Inc; SDN Open Network Operating Sysyem, , Open Networking Foundation Project; OpenContrail Silicon Valley Meetup, , OpenContrail; (2013) Linux Foundation Collaborative Project, , SDN OpenDaylight; User Stories - OpenDayLight, , The Linux Foundation Projects; Röpke, C., Holz, T., SDN rootkits: Subverting network operating systems of software-dened networks (2015) Research in Attacks, Intrusions, and Defenses, pp. 339-356. , Herbert Bos, Fabian Monrose, and Gregory Blanc (Eds.). Springer International Publishing, Cham; Scott-Hayward, S., O’Callaghan, G., Sezer, S., SDN security: A survey (2013) Future Networks and Services (SDN4FNS), 2013 IEEE SDN For, pp. 1-7. , IEEE; Shafer, P., Bjorklund, M., Wilton, R., Schönwälder, J., Watsen, K., (2018) Network Management Datastore Architecture: RFC-8342, , Network 2018; Shin, S., Yegneswaran, V., Porras, P., Gu, G., Avant-guard: Scalable and vigilant switch ow management in software-dened networks (2013) Proceedings of The 2013 ACM SIGSAC Conference on Computer & Communications Security, pp. 413-424. , ACM; (2014) Mininet, , http://mininet.org; Wang, H., Xu, L., Gu, G., Floodguard: A dos attack prevention extension in software-dened networks (2015) Dependable Systems and Networks (DSN), 2015 45th Annual IEEE/IFIP International Conference on, pp. 239-250. , IEEE; Xu, L., Huang, J., Hong, S., Zhang, J., Gu, G., Attacking the brain: Races in the SDN control plane (2017) 26th {USENIX} Security Symposium ({USENIX} Security 17), pp. 451-468. , {USENIX} Association; Xu, T., Gao, D., Dong, P., Foh, C.H., Zhang, H., Mitigating the table-overow attack in software-dened networking (2017) IEEE Transactions on Network and Service Management, 14 (4), pp. 1086-1097. , https://doi.org/10.1109/TNSM.2017.2758796; Yan, Q., Yu, F.R., Gong, Q., Li, J., Software-dened networking (SDN) and distributed denial of service (DDoS) attacks in cloud computing environments: A survey, some research issues, and challenges (2016) IEEE Communications Surveys Tutorials, 18 (1), pp. 602-622; Yoon, C., Lee, S., Kang, H., Park, T., Shin, S., Yegneswaran, V., Porras, P., Gu, G., Flow wars: Systemizing the attack surface and defenses in software-dened networks (2017) IEEE/ACM Transactions on Networking, 25 (6), pp. 3514-3530. , https://doi.org/10.1109/TNET.2017.2748159",,,"ACM SIGSAC","Association for Computing Machinery","25th ACM Conference on Computer and Communications Security, CCS 2018","15 October 2018",,141172,15437221,9781450356930,,,"English","Proc ACM Conf Computer Commun Secur",Conference Paper,"Final","",Scopus,2-s2.0-85056824448
"Zhu Q., Rass S.","24767254400;15823011700;","Game theory meets network security a tutorial",2018,"Proceedings of the ACM Conference on Computer and Communications Security",,,,"2163","2165",,12,"10.1145/3243734.3264421","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056816871&doi=10.1145%2f3243734.3264421&partnerID=40&md5=595fec73caf67d302cbf0c977bc782c0","New York University, Brooklyn, NY, United States; Universitaet Klagenfurt, Klagenfurt, Austria","Zhu, Q., New York University, Brooklyn, NY, United States; Rass, S., Universitaet Klagenfurt, Klagenfurt, Austria","The increasingly pervasive connectivity of today’s information systems brings up new challenges to security. Traditional security has accomplished a long way toward protecting well-defined goals such as confidentiality, integrity, availability, and authenticity. However, with the growing sophistication of the attacks and the complexity of the system, the protection using traditional methods could be cost-prohibitive. A new perspective and a new theoretical foundation are needed to understand security from a strategic and decision-making perspective. Game theory provides a natural framework to capture the adversarial and defensive interactions between an attacker and a defender. It provides a quantitative assessment of security, prediction of security outcomes, and a mechanism design tool that can enable security-by-design and reverse the attacker’s advantage. This tutorial provides an overview of diverse methodologies from game theory that includes games of incomplete information, dynamic games, mechanism design theory to offer a modern theoretic underpinning of a science of cybersecurity. The tutorial will also discuss open problems and research challenges that the CCS community can address and contribute with an objective to build a multidisciplinary bridge between cybersecurity, economics, game and decision theory. © 2018 Copyright held by the owner/author(s).","Decision theory; Defense strategy; Game theory; Mechanism design; Network security; Security economics","Availability; Decision making; Decision theory; Game theory; Machine design; Defense strategy; Incomplete information; Mechanism design; Mechanism design theories; Pervasive connectivity; Quantitative assessments; Security Economics; Theoretical foundations; Network security",,,,,"Casey, W., Morales, J.A., Wright, E., Zhu, Q., Mishra, B., Compliance signaling games: Toward modeling the deterrence of insider threats (2016) Computational and Mathematical Organization Theory, 22 (3), pp. 318-349; Casey, W.A., Zhu, Q., Morales, J.A., Mishra, B., Compliance control: Managed vulnerability surface in social-technological systems via signaling games (2015) Proceedings of The 7th ACM CCS International Workshop on Managing Insider Security Threats, pp. 53-62. , ACM; Chen, J., Touati, C., Zhu, Q., A dynamic game analysis and design of infrastructure network protection and recovery (2017) ACM SIGMETRICS Performance Evaluation Review, 45 (2), p. 128; Chen, J., Zhu, Q., Interdependent network formation games with an application to critical infrastructures (2016) American Control Conference (ACC), 2016, pp. 2870-2875. , IEEE; Chen, J., Zhu, Q., Security as a Service for Cloud-Enabled Internet of Controlled Things under Advanced Persistent Threats: A Contract Design Approach (2017) IEEE Transactions on Information Forensics and Security; Chen, J., Zhu, Q., Security as a service for cloud-enabled internet of controlled things under advanced persistent threats: A contract design approach (2017) IEEE Transactions on Information Forensics and Security, 12 (11), pp. 2736-2750; Chen, J., Zhu, Q., Security investment under cognitive constraints: A gestalt nash equilibrium approach (2018) Information Sciences and Systems (CISS), 2018 52nd Annual Conference on, pp. 1-6. , IEEE; Clark, A., Zhu, Q., Poovendran, R., Basar, T., Deceptive routing in relay networks (2012) Decision and Game Theory for Security, pp. 171-185. , Springer; Farhang, S., Manshaei, M.H., Esfahani, M.N., Zhu, Q., A dynamic Bayesian security game framework for strategic defense mechanism design (2014) Decision and Game Theory for Security, pp. 319-328. , Springer; Fung, C.J., Zhu, Q., Facid: A trust-based collaborative decision framework for intrusion detection networks (2016) Ad Hoc Networks, 53, pp. 17-31; Hayel, Y., Zhu, Q., Attack-aware cyber insurance for risk sharing in computer networks (2015) Decision and Game Theory for Security, pp. 22-34. , Springer; Hayel, Y., Zhu, Q., Resilient and secure network design for cyber attack-induced cascading link failures in critical infrastructures (2015) Information Sciences and Systems (CISS), 2015 49th Annual Conference on, pp. 1-3. , IEEE; Hayel, Y., Zhu, Q., Epidemic protection over heterogeneous networks using evolutionary poisson games (2017) IEEE Transactions on Information Forensics and Security, 12 (8), pp. 1786-1800; Horák, K., Zhu, Q., Bošansky, B., Manipulating adversary?s belief: A dynamic game approach to deception by design for proactive network security (2017) International Conference on Decision and Game Theory for Security, pp. 273-294. , Springer; Huang, L., Chen, J., Zhu, Q., A large-scale markov game approach to dynamic protection of interdependent infrastructure networks (2017) International Conference on Decision and Game Theory for Security, pp. 357-376. , Springer; Huang, L., Zhu, Q., Adaptive strategic cyber defense for advanced persistent threats in critical infrastructure networks (2018) ACM SIGMETRICS Performance Evaluation Review; Huang, L., Zhu, Q., Analysis and computation of adaptive defense strategies against advanced persistent threats for cyber-physical systems (2018) International Conference on Decision and Game Theory for Security; Jajodia, S., Ghosh, A.K., Swarup, V., Wang, C., Wang, X.S., (2011) Moving Target Defense: Creating Asymmetric Uncertainty for Cyber Threats, 54. , Springer Science & Business Media; Maleki, H., Valizadeh, S., Koch, W., Bestavros, A., Van Dijk, M., Markov modeling of moving target defense games (2016) Proceedings of The 2016 ACM Workshop on Moving Target Defense, pp. 81-92. , ACM; Manshaei, M.H., Zhu, Q., Alpcan, T., Bacsar, T., Hubaux, J.-P., Game theory meets network security and privacy (2013) ACM Computing Surveys (CSUR), 45 (3), p. 25; Miao, F., Zhu, Q., Pajic, M., Pappas, G.J., A hybrid stochastic game for secure control of cyber-physical systems (2018) Automatica, 93, pp. 55-63; Pawlick, J., Colbert, E., Zhu, Q., (2017) A Game-Theoretic Taxonomy and Survey of Defensive Deception for Cybersecurity and Privacy, , arXiv preprint; Pawlick, J., Colbert, E., Zhu, Q., (2018) Modeling and Analysis of Leaky Deception Using Signaling Games with Evidence, , arXiv preprint; Pawlick, J., Farhang, S., Zhu, Q., Flip the cloud: Cyber-physical signaling games in the presence of advanced persistent threats (2015) Decision and Game Theory for Security, pp. 289-308. , Springer; Pawlick, J., Zhu, Q., (2015) Deception by Design: Evidence-Based Signaling Games for Network Defense, , arXiv preprint; Pawlick, J., Zhu, Q., A Stackelberg game perspective on the conflict between machine learning and data obfuscation (2016) Information Forensics and Security (WIFS), 2016 IEEE International Workshop on, pp. 1-6. , IEEE; Pawlick, J., Zhu, Q., (2017) A Mean-Field Stackelberg Game Approach for Obfuscation Adoption in Empirical Risk Minimization, , arXiv preprint; Pawlick, J., Zhu, Q., Proactive defense against physical denial of service attacks using poisson signaling games (2017) International Conference on Decision and Game Theory for Security, pp. 336-356. , Springer; Pawlick, J., Zhu, Q., Strategic trust in cloud-enabled cyber-physical systems with an application to glucose control (2017) IEEE Transactions on Information Forensics and Security, 12 (12), pp. 2906-2919; Rass, S., Alshawish, A., Abid, M.A., Schauer, S., Zhu, Q., De Meer, H., Physical intrusion games–optimizing surveillance by simulation and game theory (2017) IEEE Access, 5, pp. 8394-8407; Wang, W., Zhu, Q., On the detection of adversarial attacks against deep neural networks (2017) Proceedings of The 2017 Workshop on Automated Decision Making for Active Cyber Defense, pp. 27-30. , ACM; Xu, Z., Zhu, Q., A cyber-physical game framework for secure and resilient multi-agent autonomous systems (2015) Decision and Control (CDC), 2015 IEEE 54th Annual Conference on, pp. 5156-5161. , IEEE; Xu, Z., Zhu, Q., Cross-layer secure cyber-physical control system design for networked 3d printers (2016) American Control Conference (ACC), 2016, pp. 1191-1196. , IEEE; Xu, Z., Zhu, Q., A Game-Theoretic Approach to Secure Control of Communication-Based Train Control Systems Under Jamming Attacks (2017) Proceedings of The 1st International Workshop on Safe Control of Connected and Autonomous Vehicles, pp. 27-34. , ACM; Xu, Z., Zhu, Q., Secure and practical output feedback control for cloud-enabled cyber-physical systems (2017) Communications and Network Security (CNS), 2017 IEEE Conference on, pp. 416-420. , IEEE; Yuan, Y., Zhu, Q., Sun, F., Wang, Q., Basar, T., Resilient control of cyberphysical systems against denial-of-service attacks (2013) Resilient Control Systems (ISRCS), 2013 6th International Symposium on, pp. 54-59. , IEEE; Zhang, R., Zhu, Q., Attack-Aware Cyber Insurance of Interdependent Computer Networks; Zhang, R., Zhu, Q., A game-theoretic defense against data poisoning attacks in distributed support vector machines (2017) Decision and Control (CDC), 2017 IEEE 56th Annual Conference on, pp. 4582-4587. , IEEE; Zhang, R., Zhu, Q., A game-theoretic approach to design secure and resilient distributed support vector machines (2018) IEEE Transactions on Neural Networks and Learning Systems; Zhang, R., Zhu, Q., Hayel, Y., A Bi-Level Game Approach to Attack-Aware Cyber Insurance of Computer Networks (2017) IEEE Journal on Selected Areas in Communications, 35 (3), pp. 779-794; Zhang, R., Zhu, Q., Hayel, Y., A bi-level game approach to attack-aware cyber insurance of computer networks (2017) IEEE Journal on Selected Areas in Communications, 35 (3), pp. 779-794; Zhang, T., Zhu, Q., Strategic defense against deceptive civilian GPS spoofing of unmanned aerial vehicles (2017) International Conference on Decision and Game Theory for Security, pp. 213-233. , Springer; Zhu, Q., Basar, T., Dynamic policy-based ids configuration (2009) Decision and Control, 2009 Held Jointly with The 2009 28th Chinese Control Conference. CDC/CCC 2009. Proceedings of The 48th IEEE Conference on, pp. 8600-8605. , IEEE; Zhu, Q., Basar, T., Game-theoretic approach to feedback-driven multi-stage moving target defense (2013) International Conference on Decision and Game Theory for Security, pp. 246-263. , Springer; Zhu, Q., Basar, T., Game-theoretic methods for robustness, security, and resilience of cyberphysical control systems: Games-in-games principle for optimal cross-layer resilient control systems (2015) Control Systems, IEEE, 35 (1), pp. 46-65; Zhu, Q., Bushnell, L., Basar, T., Game-theoretic analysis of node capture and cloning attack with multiple attackers in wireless sensor networks (2012) Decision and Control (CDC), 2012 IEEE 51st Annual Conference on, pp. 3404-3411. , IEEE; Zhu, Q., Clark, A., Poovendran, R., Basar, T., Deceptive routing games (2012) Decision and Control (CDC), 2012 IEEE 51st Annual Conference on, pp. 2704-2711. , IEEE; Zhu, Q., Clark, A., Poovendran, R., Basar, T., Deployment and exploitation of deceptive honeybots in social networks (2013) Decision and Control (CDC), 2013 IEEE 52nd Annual Conference on, pp. 212-219. , IEEE; Zhu, Q., Fung, C., Boutaba, R., Basar, T., A game-theoretical approach to incentive design in collaborative intrusion detection networks (2009) Game Theory for Networks, 2009. GameNets’ 09. International Conference on, pp. 384-392. , IEEE; Zhu, Q., Fung, C., Boutaba, R., Basar, T., Guidex: A game-theoretic incentive-based mechanism for intrusion detection networks (2012) Selected Areas in Communications, IEEE Journal on, 30 (11), pp. 2220-2230; Zhu, Q., Gunter, C.A., Basar, T., Tragedy of anticommons in digital right management of medical records (2012) HealthSec; Zhu, Q., Li, H., Han, Z., Basar, T., A stochastic game model for jamming in multi-channel cognitive radio systems (2010) ICC, pp. 1-6; Zhu, Q., Rass, S., On multi-phase and multi-stage game-theoretic modeling of advanced persistent threats (2018) IEEE Access, 6, pp. 13958-13971; Zhu, Q., Tembine, H., Basar, T., Heterogeneous learning in zero-sum stochastic games with incomplete information (2010) Decision and Control (CDC), 2010 49th IEEE Conference on, pp. 219-224. , IEEE; Zhu, Q., Tembine, H., Basar, T., Network security configurations: A nonzero-sum stochastic game approach (2010) American Control Conference (ACC), 2010, pp. 1059-1064. , IEEE; Zhu, Q., Tembine, H., Basar, T., Hybrid learning in stochastic games and its applications in network security (2013) Reinforcement Learning and Approximate Dynamic Programming for Feedback Control, pp. 305-329; Zhu, Q., Yuan, Z., Song, J.B., Han, Z., Basar, T., Dynamic interference minimization routing game for on-demand cognitive pilot channel (2010) Global Telecommunications Conference (GLOBECOM 2010), 2010 IEEE, pp. 1-6. , IEEE; Zhu, Q., Yuan, Z., Song, J.B., Han, Z., Basar, T., Interference aware routing game for cognitive radio multi-hop networks (2012) Selected Areas in Communications, IEEE Journal on, 30 (10), pp. 2006-2015; Zhuang, J., Bier, V.M., Alagoz, O., Modeling secrecy and deception in a multiple-period attacker–defender signaling game (2010) European Journal of Operational Research, 203 (2), pp. 409-418",,,"ACM SIGSAC","Association for Computing Machinery","25th ACM Conference on Computer and Communications Security, CCS 2018","15 October 2018",,141172,15437221,9781450356930,,,"English","Proc ACM Conf Computer Commun Secur",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85056816871
"Biggio B., Roli F.","23090165100;57194734588;","Wild patterns: Ten years after the rise of adversarial machine learning half-day tutorial",2018,"Proceedings of the ACM Conference on Computer and Communications Security",,,,"2154","2156",,10,"10.1145/3243734.3264418","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056816195&doi=10.1145%2f3243734.3264418&partnerID=40&md5=318fef09d36e2f492b248e43e478bbd0","University of Cagliari, Italy; Pluribus One, Italy","Biggio, B., University of Cagliari, Italy, Pluribus One, Italy; Roli, F., University of Cagliari, Italy, Pluribus One, Italy","Deep neural networks and machine-learning algorithms are pervasively used in several applications, ranging from computer vision to computer security. In most of these applications, the learning algorithm has to face intelligent and adaptive attackers who can carefully manipulate data to purposely subvert the learning process. As these algorithms have not been originally designed under such premises, they have been shown to be vulnerable to well-crafted, sophisticated attacks, including training-time poisoning and test-time evasion attacks (also known as adversarial examples). The problem of countering these threats and learning secure classifiers in adversarial settings has thus become the subject of an emerging, relevant research field known as adversarial machine learning. The purposes of this tutorial are: (a) to introduce the fundamentals of adversarial machine learning to the security community; (b) to illustrate the design cycle of a learning-based pattern recognition system for adversarial tasks; (c) to present novel techniques that have been recently proposed to assess performance of pattern classifiers and deep learning algorithms under attack, evaluate their vulnerabilities, and implement defense strategies that make learning algorithms more robust to attacks; and (d) to show some applications of adversarial machine learning to pattern recognition tasks like object recognition in images, biometric identity recognition, spam and malware detection. © 2018 Copyright held by the owner/author(s).","Adversarial examples; Adversarial machine learning; Deep learning; Evasion attacks; Training data poisoning","Artificial intelligence; C (programming language); Computer vision; Deep learning; Deep neural networks; Malware; Object recognition; Pattern recognition systems; Security of data; Adversarial examples; Defense strategy; Evasion attacks; Identity recognition; Malware detection; Pattern classifier; Security community; Training data; Learning algorithms",,,,,"Athalye, A., Carlini, N., Wagner, D.A., Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples (2018) ICML (JMLR Workshop and Conference Proceedings), 80, pp. 274-283. , JMLR.org; Barreno, M., Nelson, B., Sears, R., Joseph, A.D., Tygar, J.D., Can machine learning be secure? (2006) Proc. ACM Symp. Information, Computer and Comm. Sec. (ASIACCS’06)., pp. 16-25. , ACM, New York, NY, USA; Bendale, A., Boult, T.E., Towards Open Set Deep Networks (2016) IEEE Conference on Computer Vision and Pattern Recognition, pp. 1563-1572; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndic, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Machine Learning and Knowledge Discovery in Databases (ECML PKDD), Part III (LNCS), 8190, pp. 387-402. , Hendrik Blockeel, Kristian Kersting, Siegfried Nijssen, and Filip Železný (Eds.),. Springer Berlin Heidelberg; Biggio, B., Fumera, G., Roli, F., Security Evaluation of Pattern Classifiers Under Attack (2014) IEEE Transactions on Knowledge and Data Engineering, 26 (4), pp. 984-996. , April 2014; Biggio, B., Nelson, B., Laskov, P., Poisoning attacks against support vector machines (2012) 29th Int’L Conf. on Machine Learning, pp. 1807-1814. , John Langford and Joelle Pineau (Eds.). Int’l Conf. on Machine Learning (ICML; Biggio, B., Roli, F., Wild Patterns: Ten Years After the Rise of Adversarial Machine Learning (2018) Pattern Recognition, 84 (2018), pp. 317-331; Carlini, N., Wagner, D.A., Towards Evaluating the Robustness of Neural Networks (2017) IEEE Symposium on Security and Privacy. IEEE Computer Society, pp. 39-57; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B., Tygar, J.D., Adversarial Machine Learning (2011) 4th ACM Workshop on Artificial Intelligence and Security (AISec 2011), pp. 43-57. , Chicago, IL, USA; Jagielski, M., Oprea, A., Biggio, B., Liu, C., Nita-Rotaru, C., Li, B., Manipulating Machine Learning: Poisoning Attacks and Countermeasures for Regression Learning (2018) IEEE Symposium on Security and Privacy (SP’18). IEEE CS, pp. 931-947. , https://doi.org/10.1109/SP.2018.00057; Koh, P.W., Liang, P., Understanding Black-box Predictions via Influence Functions (2017) International Conference on Machine Learning (ICML); Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical Black-Box Attacks Against Machine Learning (2017) Proceedings of The 2017 ACM on Asia Conference on Computer and Communications Security (ASIA CCS’17), pp. 506-519. , ACM, New York, NY, USA; Rubinstein, B.I.P., Nelson, B., Huang, L., Joseph, A.D., Lau, S.-H., Rao, S., Taft, N., Tygar, J.D., ANTIDOTE: Understanding and defending against poisoning of anomaly detectors (2009) Proceedings of The 9th ACM SIGCOMM Internet Measurement Conference (IMC’09), pp. 1-14. , ACM, New York, NY, USA; Smutz, C., Stavrou, A., Malicious PDF Detection Using Metadata and Structural Features (2012) Proceedings of The 28th Annual Computer Security Applications Conference (ACSAC’12), pp. 239-248. , ACM, New York, NY, USA; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations, , http://arxiv.org/abs/1312.6199; Šrndic, N., Laskov, P., Practical Evasion of a Learning-Based Classifier: A Case Study (2014) Proc. 2014 IEEE Symp. Security and Privacy (SP’14)., pp. 197-211. , IEEE CS, Washington, DC, USA; Xiao, H., Biggio, B., Brown, G., Fumera, G., Eckert, C., Roli, F., Is Feature Selection Secure against Training Data Poisoning? (2015) JMLR W&CP - Proc. 32nd Int’L Conf. Mach. Learning (ICML), 37, pp. 1689-1698. , Francis Bach and David Blei (Eds.); Xu, W., Qi, Y., Evans, D., Automatically Evading Classifiers (2016) Proc. 23rd Annual Network & Distributed System Security Symposium (NDSS)., , The Internet Society",,,"ACM SIGSAC","Association for Computing Machinery","25th ACM Conference on Computer and Communications Security, CCS 2018","15 October 2018",,141172,15437221,9781450356930,,,"English","Proc ACM Conf Computer Commun Secur",Conference Paper,"Final","",Scopus,2-s2.0-85056816195
"Du Y., Fang M., Yi J., Cheng J., Tao D.","57196119744;55445603900;36095116600;14057685600;7102600334;","Towards query efficient black-box attacks: An input-free perspective",2018,"Proceedings of the ACM Conference on Computer and Communications Security",,,,"13","24",,6,"10.1145/3270101.3270106","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056737742&doi=10.1145%2f3270101.3270106&partnerID=40&md5=32981b61aa726b4d49eeb2ddc2687467","Centre for Artificial Intelligence, FEIT, University of Technology, Sydney, Australia; Guangdong Key Lab of Robotics and Intelligent System, Shenzhen Institutes of Advanced Technology, CAS, China; UBTECH Sydney AI Centre, School of IT, FEIT, University of Sydney, Australia; Tencent AI Lab, Shenzhen, China; JD AI Research, Beijing, China; Chinese University of Hong Kong, Hong Kong","Du, Y., Centre for Artificial Intelligence, FEIT, University of Technology, Sydney, Australia, Guangdong Key Lab of Robotics and Intelligent System, Shenzhen Institutes of Advanced Technology, CAS, China, UBTECH Sydney AI Centre, School of IT, FEIT, University of Sydney, Australia; Fang, M., Tencent AI Lab, Shenzhen, China; Yi, J., JD AI Research, Beijing, China; Cheng, J., Chinese University of Hong Kong, Hong Kong; Tao, D., UBTECH Sydney AI Centre, School of IT, FEIT, University of Sydney, Australia","Recent studies have highlighted that deep neural networks (DNNs) are vulnerable to adversarial attacks, even in a black-box scenario. However, most of the existing black-box attack algorithms need to make a huge amount of queries to perform attacks, which is not practical in the real world. We note one of the main reasons for the massive queries is that the adversarial example is required to be visually similar to the original image, but in many cases, how adversarial examples look like does not matter much. It inspires us to introduce a new attack called input-free attack, under which an adversary can choose an arbitrary image to start with and is allowed to add perceptible perturbations on it. Following this approach, we propose two techniques to significantly reduce the query complexity. First, we initialize an adversarial example with a gray color image on which every pixel has roughly the same importance for the target model. Then we shrink the dimension of the attack space by perturbing a small region and tiling it to cover the input image. To make our algorithm more effective, we stabilize a projected gradient ascent algorithm with momentum, and also propose a heuristic approach for region size selection. Through extensive experiments, we show that with only 1,701 queries on average, we can perturb a gray image to any target class of ImageNet with a 100% success rate on InceptionV3. Besides, our algorithm has successfully defeated two real-world systems, the Clarifai food detection API and the Baidu Animal Identification API. © 2018 Association for Computing Machinery.","Adversarial learning; Black-box attack; Input-free attack; Neural network; Region attack","Artificial intelligence; Deep neural networks; Heuristic methods; Ion beams; Neural networks; Adversarial learning; Animal identification; Black boxes; Heuristic approach; Input-free attack; Projected gradient; Real-world system; Region attack; Computer crime",,,,,"Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Isard, M., TensorFlow: A system for large-scale machine learning (2016) Proceedings of The 12th USENIX Conference on Operating Systems Design and Implementation, pp. 265-283. , USENIX Association; Barreno, M., Nelson, B., Joseph, A.D., Tygar, J.D., The security of machine learning (2010) Machine Learning, 81 (2), pp. 121-148. , 2010; Barreno, M., Nelson, B., Sears, R., Joseph, A.D., Doug Tygar, J., Can machine learning be secure? (2006) Proceedings of The 2006 ACM Symposium on Information, Computer and Communications Security, pp. 16-25. , ACM; Brendel, W., Rauber, J., Bethge, M., (2017) Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models, , arXiv preprint 2017; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy (SP), pp. 39-57. , IEEE; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) Proceedings of The 10th ACM Workshop on Artificial Intelligence and Security, pp. 15-26. , ACM; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., Imagenet: A large-scale hierarchical image database (2009) IEEE Conference on Computer Vision and Pattern Recognition, pp. 248-255. , IEEE; Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., Li, J., (2018) Boosting Adversarial Attacks with Momentum, , arXiv preprint 2018; Engstrom, L., Tsipras, D., Schmidt, L., Madry, A., (2017) A Rotation and A Translation Suffice: Fooling CNNs with Simple Transformations, , arXiv preprint 2017; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint 2014; Hayes, J., Danezis, G., (2017) Machine Learning as An Adversarial Service: Learning Black-Box Adversarial Examples, , arXiv preprint 2017; Ilyas, A., Engstrom, L., Athalye, A., Lin, J., (2018) Black-Box Adversarial Attacks with Limited Queries and Information, , arXiv preprint 2018; Liu, Y., Chen, X., Liu, C., Song, D., (2016) Delving into Transferable Adversarial Examples and Black-Box Attacks, , arXiv preprint 2016; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , arXiv preprint 2017; Dezfooli, S.M.M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Proceedings of The IEEE Conference on Computer Vision and Pattern Recognition, pp. 427-436; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of The 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519. , ACM; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2016) IEEE European Symposium on Security and Privacy (EuroS&P), pp. 372-387. , IEEE; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Bernstein, M., Imagenet large scale visual recognition challenge (2015) International Journal of Computer Vision, 115 (3), pp. 211-252. , 2015; Salimans, T., Ho, J., Chen, X., Sidor, S., Sutskever, I., (2017) Evolution Strategies as A Scalable Alternative to Reinforcement Learning, , arXiv preprint 2017; Su, J., Vargas, D.V., Kouichi, S., (2017) One Pixel Attack for Fooling Deep Neural Networks, , arXiv preprint 2017; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of The IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) ICLR. Citeseer.; Tu, C.-C., Ting, P., Chen, P.-Y., Liu, S., Zhang, H., Yi, J., Hsieh, C.-J., Cheng, S.-M., (2018) AutoZOOM: Autoencoder-Based Zeroth Order Optimization Method for Attacking Black-Box Neural Networks, , arXiv preprint 2018; Wierstra, D., Schaul, T., Glasmachers, T., Sun, Y., Peters, J., Schmidhuber, J., Natural evolution strategies (2014) Journal of Machine Learning Research, 15 (1), pp. 949-980. , 2014",,,"ACM SIGSAC","Association for Computing Machinery","11th ACM Workshop on Artificial Intelligence and Security, AISec 2018, co-located with CCS 2018","19 October 2018",,141187,15437221,9781450360043,,,"English","Proc ACM Conf Computer Commun Secur",Conference Paper,"Final","",Scopus,2-s2.0-85056737742
"Mulamba D., Amarnath A., Bezawada B., Ray I.","55550036800;57204686164;23501198800;7004434646;","A secure hash commitment approach for moving target defense of security-critical services",2018,"Proceedings of the ACM Conference on Computer and Communications Security",,,,"59","68",,,"10.1145/3268966.3268969","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056736187&doi=10.1145%2f3268966.3268969&partnerID=40&md5=29c1934a29a8f56c5c43e4ac7dc7b2af","Computer Science Department, Colorado State University, Fort Collins, CO, United States","Mulamba, D., Computer Science Department, Colorado State University, Fort Collins, CO, United States; Amarnath, A., Computer Science Department, Colorado State University, Fort Collins, CO, United States; Bezawada, B., Computer Science Department, Colorado State University, Fort Collins, CO, United States; Ray, I., Computer Science Department, Colorado State University, Fort Collins, CO, United States","Protection of security-critical services, such as access-control reference monitors, is an important requirement in the modern era of distributed systems and services. The threat arises from hosting the service on a single server for a lengthy period of time, which allows the attacker to periodically enumerate the vulnerabilities of the service with respect to the server's coniguration and launch targeted attacks on the service. In our work, we design and implement an eicient solution based on the moving łtargetž defense strategy, to protect security-critical services against such active adversaries. Speciically, we focus on implementing our solution for protecting the reference monitor service that enforces access control for users requesting access to sensitive resources. The key intuition of our approach is to increase the level of diiculty faced by the attacker to compromise a service by periodically moving the security-critical service among a group of heterogeneous servers. For this approach to be practically feasible, the movement of the service should be eicient and random, i.e., the attacker should not have a-priori information about the choice of the next server hosting the service. Towards this, we describe an eicient Byzantine fault-tolerant leader election protocol that achieves the desired security and performance objectives. We built a prototype implementation that moves the access control service randomly among a group of ifty servers within a time range of 250-440 ms. We show that our approach tolerates Byzantine behavior of servers, which ensures that a server under adversarial control has no additional advantage of being selected as the next active server. © 2018 Association for Computing Machinery.","Access Control; Byzantine Fault-tolerance; Moving Target Defense; Secure One-way Hash Functions","Access control; Decentralized control; Fault tolerance; Fault tolerant computer systems; Hash functions; Access control services; Byzantine fault tolerance; Design and implements; Heterogeneous servers; Moving target defense; One way hash functions; Prototype implementations; Security and performance; Network security",,,,,"(2000) OpenSLP: Service Location Protocol, , http://www.openslp.org/, accessed: 2017-02-26. 2000; Abraham, I., Devadas, S., Dolev, D., Nayak, K., Ren, L., (2017) Eicient Synchronous Byzantine Consensus, , arXiv preprint 2017; Achleitner, S., Porta, T.L., McDaniel, P., Sugrim, S., Krishnamurthy, S.V., Chadha, R., Cyber Deception: Virtual Networks to Defend Insider Reconnaissance (2016) Int. Workshop on Managing Insider Security Threats., pp. 57-68. , ACM; Ahmed, N.O., Bhargava, B., Maylies: A Moving Target Defense Framework for Distributed Systems (2016) Proc. of ACM Workshop on Moving Target Defense., pp. 59-64; Antonatos, S., Akritidis, P., Markatos, E.P., Anagnostakis, K.G., Defending against hitlist worms using network address space randomization (2007) Computer Networks, 51 (12), pp. 3471-3490. , 2007; Augustine, J., Pandurangan, G., Robinson, P., Fast byzantine agreement in dynamic networks (2013) Proc. of ACM PODC., pp. 74-83; Awerbuch, B., Scheideler, C., Robust random number generation for peer-to-peer systems (2009) Theor. Computer Science, 410 (6-7), pp. 453-466. , 2009; Castro, M., Liskov, B., Practical Byzantine fault tolerance (1999) OSDI, 99, pp. 173-186; Clement, A., Wong, E., Alvisi, L., Dahlin, M., Marchetti, M., Making Byzantine Fault Tolerant Systems Tolerate Byzantine Faults (2009) Proc. of The 6th USENIX NSDI., pp. 153-168; Copeland, C., Zhong, H., (2016) Tangaroa: A Byzantine Fault Tolerant Raft, , 2016; Correia, M., Neves, N.F., Verissimo, P., How to Tolerate Half Less One Byzantine Nodes in Practical Distributed Systems (2004) Proceedings of The 23rd IEEE International Symposium on Reliable Distributed Systems (SRDS'04), pp. 174-183. , http://dl.acm.org/citation.cfm?id=1032662.1034362, IEEE Computer Society, Washington, DC, USA; (2017) U.S. Homeland Security Cyber Security R&D Center: Moving Target Defense (MTD) Program, , https://www.dhs.gov/science-and-technology/csdmtd, 2017; Duan, S., Li, Y., Levitt, K., Cost sensitive moving target consensus (2016) Proc. of The IEEE Int. Symp. on Network Computing and Applications (NCA)., pp. 272-281; Evans, D., Nguyen-Tuong, A., Knight, J., Efectiveness of moving target defenses (2011) Moving Target Defense, pp. 29-48. , Springer; Garcia, M., Bessani, A., Gashi, I., Neves, N., Obelheiro, R., Analysis of Operating System Diversity for Intrusion Tolerance (2014) Softw. Pract. Exper., 44 (6), pp. 735-770. , https://doi.org/10.1002/spe.2180, June 2014; Han, Y., Lu, W., Xu, S., Characterizing the power of moving target defense via cyber epidemic dynamics (2014) Proc. of The ACM Symp. and Bootcamp on The Science of Security., 10. , In; John, A., Gopal, P., Peter, R., Fast Byzantine Leader Election in Dynamic Networks (2015) Proc. of DISC., pp. 276-291; Lamport, L., Shostak, R.E., Pease, M.C., The Byzantine Generals Problem (1982) ACM Trans. Program. Lang. Syst., 4 (3), pp. 382-401. , 1982; Miller, A., Xia, Y., Croman, K., Shi, E., Song, D., The honey badger of BFT protocols (2016) Proc. of ACM CCS., pp. 31-42; Mulamba, D., Ray, I., Resilient Reference Monitor for Distributed Access Control via Moving Target Defense (2017) Proc. of DBSec. 20ś40; Newell, A., Obenshain, D., Tantillo, T., Nita-Rotaru, C., Amir, Y., Increasing network resiliency by optimally assigning diverse variants to routing nodes (2013) 2013 43rd Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN), pp. 1-12. , https://doi.org/10.1109/DSN.2013.6575305; Nikolaou, S., Van Renesse, R., Turtle consensus: Moving target defense for consensus (2015) Proc. of The 16th Annual Middleware Conference., pp. 185-196. , ACM; Ongaro, D., Ousterhout, J., (2015) Raft Consensus Algorithm, , 2015; Pedersen, T.P., Non-Interactive and Information-Theoretic Secure Veriiable Secret Sharing (1991) Proc. of Crypto., pp. 129-140; Ramuhalli, P., Halappanavar, M., Coble, J., Dixit, M., Towards a theory of autonomous reconstitution of compromised cyber-systems (2013) Proc. of Int. IEEE Conf. on Technologies for Homeland Security (HST)., pp. 577-583; Rodriguez, L., Curtis, D., Choudhury, S., Oler, K., Nordquist, P., Chen, P.-Y., Ray, I., Action Recommendation for Cyber Resilience (2015) Proc. of The 22nd ACM CCS., pp. 1620-1622; Wagner, N., Sahin, C.Ş., Winterrose, M., Riordan, J., Pena, J., Hanson, D., Streilein, W.W., Towards automated cyber decision support: A case study on network segmentation for security (2016) Proc. IEEE Symp. Series on Computational Intelligence (SSCI)., pp. 1-10; Wang, S., Zhou, A., Yang, M., Sun, L., Hsu, C.-H., Service Composition in Cyber-Physical-Social Systems (2017) IEEE Trans. on Emerging Topics in Computing, , 2017; Winterrose, M.L., Carter, K.M., Wagner, N., Streilein, W.W., (2014) Adaptive Attacker Strategy Development Against Moving Target Cyber Defenses, , arXiv preprint 2014; Zhuang, R., DeLoach, S.A., Ou, X., Towards a theory of moving target defense (2014) Proc. of The First ACM Workshop on Moving Target Defense., pp. 31-40","Ray, I.; Computer Science Department, United States; email: Indrajit.Ray@colostate.edu",,"ACM SIGSAC","Association for Computing Machinery","5th ACM Workshop on Moving Target Defense, MTD 2018, held in conjunction with the 25th ACM Conference on Computer and Communications Security, ACM CCS 2018","15 October 2018",,141186,15437221,9781450360036,,,"English","Proc ACM Conf Computer Commun Secur",Conference Paper,"Final","",Scopus,2-s2.0-85056736187
[No author name available],[No author id available],"Proceedings of the ACM Conference on Computer and Communications Security",2018,"Proceedings of the ACM Conference on Computer and Communications Security",,,,"","",102,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056729635&partnerID=40&md5=523964b5b3fa66ae50d2ee49df6eb759",,"","The proceedings contain 9 papers. The topics discussed include: all you need is love’: evading hate speech detection’; towards query efficient black-box attacks: an input-free perspective; stochastic substitute training: a gray-box approach to craft adversarial examples against gradient obfuscation defenses; adaptive grey-box fuzz-testing with Thompson sampling; toward smarter vulnerability discovery using machine learning; FeatNet: large-scale fraud device detection by network representation learning with rich features; integration of static and dynamic code stylometry analysis for programmer de-anonymization; and towards evaluating the security of real-world deployed image CAPTCHAs.",,,,,,,,,,"ACM SIGSAC","Association for Computing Machinery","11th ACM Workshop on Artificial Intelligence and Security, AISec 2018, co-located with CCS 2018","19 October 2018",,141187,15437221,9781450360043,,,"English","Proc ACM Conf Computer Commun Secur",Conference Review,"Final","",Scopus,2-s2.0-85056729635
"Gröndahl T., Pajola L., Juuti M., Conti M., Asokan N.","57195726882;57196020265;57015052800;15019127200;7004299259;","All you need is “love”: Evading hate speech detection",2018,"Proceedings of the ACM Conference on Computer and Communications Security",,,,"2","12",,60,"10.1145/3270101.3270103","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056726309&doi=10.1145%2f3270101.3270103&partnerID=40&md5=48b720daddfece5c46b62783e83fe113","Aalto University, Finland; University of Padua, Italy","Gröndahl, T., Aalto University, Finland; Pajola, L., Aalto University, Finland; Juuti, M., Aalto University, Finland; Conti, M., University of Padua, Italy; Asokan, N., Aalto University, Finland","With the spread of social networks and their unfortunate use for hate speech, automatic detection of the latter has become a pressing problem. In this paper, we reproduce seven state-of-the-art hate speech detection models from prior work, and show that they perform well only when tested on the same type of data they were trained on. Based on these results, we argue that for successful hate speech detection, model architecture is less important than the type of data and labeling criteria. We further show that all proposed detection techniques are brittle against adversaries who can (automatically) insert typos, change word boundaries or add innocuous words to the original hate speech. A combination of these methods is also effective against Google Perspective – a cutting-edge solution from industry. Our experiments demonstrate that adversarial training does not completely mitigate the attacks, and using character-level features makes the models systematically more attack-resistant than using word-level features. Copyright © 2018 held by the owner/author(s). Publication rights licensed to ACM.",,"Artificial intelligence; Speech; Attack resistants; Automatic Detection; Character level; Cutting edges; Model architecture; Proposed detection techniques; Speech detection; State of the art; Speech recognition",,,,,"Badjatiya, P., Gupta, S., Gupta, M., Varma, V., Deep Learning for Hate Speech Detection in Tweets (2017) Proceedings of The 26th International Conference on World Wide Web Companion, pp. 759-760; Brennan, M., Afroz, S., Greenstadt, R., Adversarial stylometry: Circumventing authorship recognition to preserve privacy and anonymity (2011) ACM Transactions on Information and System Security, 15 (3), pp. 121-1222; Brennan, M., Greenstadt, R., Practical Attacks Against Authorship Recognition Techniques (2009) Proceedings of The Twenty-First Conference on Innovative Applications of Artificial Intelligence, pp. 60-65. , K. Haigh and N. Rychtyckyj, Eds; Brown, A., What is hate speech? Part1: The myth of hate (2017) Law and Philosophy, 36 (4), pp. 419-468; Burnap, P., Williams, M.L., Cyber hate speech on twitter: An application of machine classification and statistical modeling for policy and decision making (2015) Policy & Internet, 7 (2), pp. 223-242; Chen, Y., Zhou, Y., Zhu, S., Xu, H., Detecting offensive language in social media to protect adolescent online safety (2012) Proceedings of The 2012 International Conference on Privacy, Security, Risk and Trust and of The 2012 International Conference on Social Computing, PAS-SAT/SocialCom’12, pp. 71-80. , Amsterdam; Davidson, T., Warmslay, D., Macy, M., Weber, I., Automated Hate Speech Detection and the Problem of Offensive Language (2017) Proceedings of The 11th Conference on Web and Social Media, pp. 512-515; Dinakar, K., Jones, B., Havasi, C., Lieberman, H., Picard, R., Common sense reasoning for detection, prevention, and mitigation of cyberbullying (2012) ACM Transactions on Interactive Intelligen Systems, 2 (3), pp. 181-1830; Gitari, N.D., Zuping, Z., Damien, H., Long, J., A lexicon-based approach for hate speech detection (2015) International Journal of Multimedia and Ubiquitous Engineering, 10 (4), pp. 215-230; Goldberg, Y., A primer on neural network models for natural language processing (2016) Journal of Artificial Intelligence Research, 57 (1), pp. 345-420; Hosseini, H., Kannan, S., Zhang, B., Poovendran, R., Deceiving Google’s Perspective API Built for Detecting Toxic Comments (2017) CoRR, , abs/1702.08138; Howard, J., Ruder, S., Fine-tuned language models for text classification (2018) CoRR, , abs/1801.06146; Kumar, S., Shah, N., False information on web and social media: A survey (2018) CoRR, , abs/1804.08559; Lowd, D., Meek, C., Good word attacks on statistical spam filters (2005) CEAS; Marpaung, J., Sain, M., Lee, H.-J., Survey on malware evasion techniques: State of the art and challenges (2012) 14th International Conference on Advanced Communication Technology, pp. 744-749; Mehdad, Y., Tetreault, J., Do characters abuse more than words? (2016) 17th Annual Meeting of The Special Interest Group on Discourse and Dialogue, pp. 299-303; Merity, S., Xiong, C., Bradbury, J., Socher, R., Pointer Sentinel Mixture Models (2017) Proceedings of The International Conference on Learning Representations; Michel, J.-B., Shen, Y.K., Aiden, A.P., Veres, A., Gray, M.K., Team, T.G.B., Pickett, J.P., Aiden, E.L., Quantitative Analysis of Culture Using Millions of Digitized Books (2011) Science, 6014 (331), pp. 176-182; Mikolov, T., Chen, K., Corrado, G., Dean, J., (2013) Efficient Estimation of Word Representations in Vector Space, , ArXiv e-prints; Nobata, C., Tetreault, J., Thomas, A., Mehdad, Y., Chang, Y., Abusive language detection in online user content Proceedings of The 25th International Conference on World Wide Web; Pennington, J., Socher, R., Manning, C.D., Glove: Global vectors for word representation (2014) Empirical Methods in Natural Language Processing (EMNLP), pp. 1532-1543; Perea, M., Nabeitia, J.A.D., Carreiras, M., R34d1ng w0rd5 w1th numb3r5 (2008) Journal of Experimental Psychology: Human Perception and Performance, 34, pp. 237-241; Rayner, K., White, S., Johnson, R., Liversedge, S., Raeding wrods with jubmled lettres: There is a cost (2006) Psychological Science, 17 (3), pp. 192-193; Schmidt, A., Wiegand, M., A Survey on Hate Speech Detection using Natural Language Processing (2017) Proceedings of The Fifth International Workshop on Natural Language Processing for Social Media, pp. 1-10; Stern, H., Mason, J., Shepherd, M., (2004) A Linguistics-Based Attack on Person-Alised Statistical E-Mail Classifiers, , Tech. rep., Dalhousie University; Warner, W., Hirschberg, J., Detecting hate speech on the world wide web (2012) Proceedings of The Second Workshop on Language in Social Media, LSM âĂŹ12, pp. 19-26; Waseem, Z., Hovy, D., Hateful symbols or hateful people? Predictive features for hate speech detection on twitter (2016) Proceedings of The NAACL Student Research Workshop, pp. 88-93; Wulczyn, E., Thain, N., Dixon, L., Ex Machina: Personal Attacks Seen at Scale (2017) Proceedings of The 26th International Conference on World Wide Web, pp. 1391-1399; Zhang, Z., Robinson, D., Tepper, J., Detecting Hate Speech on Twitter Using a Convolution-GRU Based Deep Neural Network (2018) Proceedings of ESWC, pp. 745-760; Zhou, Y., Jorgensen, Z., Inge, W.M., Combating good word attacks on statistical spam filters with multiple instance learning (2007) 19th IEEE International Conference on Tools with Artificial Intelligence(ICTAI 2007), 2, pp. 298-305",,,"ACM SIGSAC","Association for Computing Machinery","11th ACM Workshop on Artificial Intelligence and Security, AISec 2018, co-located with CCS 2018","19 October 2018",,141187,15437221,9781450360043,,,"English","Proc ACM Conf Computer Commun Secur",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85056726309
"Zhao B., Wu X., Cheng Z.-Q., Liu H., Jie Z., Feng J.","56669080300;56313464300;57191902796;56461595300;56938059900;36439415700;","Multi-view image generation from a single-view",2018,"MM 2018 - Proceedings of the 2018 ACM Multimedia Conference",,,,"383","391",,54,"10.1145/3240508.3240536","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055122799&doi=10.1145%2f3240508.3240536&partnerID=40&md5=fb7b1b408f533c618763f89d785d2008","Southwest Jiaotong University, Chengdu, China; Tencent YouTu Lab, Hefei, China; Tencent AI Lab, Shenzhen, China; National University of Singapore, Singapore","Zhao, B., Southwest Jiaotong University, Chengdu, China, National University of Singapore, Singapore; Wu, X., Southwest Jiaotong University, Chengdu, China; Cheng, Z.-Q., Southwest Jiaotong University, Chengdu, China; Liu, H., Tencent YouTu Lab, Hefei, China; Jie, Z., Tencent AI Lab, Shenzhen, China; Feng, J., National University of Singapore, Singapore","How to generate multi-view images with realistic-looking appearance from only a single view input is a challenging problem. In this paper, we attack this problem by proposing a novel image generation model termed VariGANs, which combines the merits of the variational inference and the Generative Adversarial Networks (GANs). It generates the target image in a coarse-to-fine manner instead of a single pass which suffers from severe artifacts. It first performs variational inference to model global appearance of the object (e.g., shape and color) and produces coarse images of different views. Conditioned on the generated coarse images, it then performs adversarial learning to fill details consistent with the input and generate the fine images. Extensive experiments conducted on two clothing datasets, MVC and DeepFashion, have demonstrated that the generated images with the proposed VariGANs are more plausible than those generated by existing approaches, which provide more consistent global appearance as well as richer and sharper details. © 2018 Association for Computing Machinery.","Deep learning; Generative adversarial networks; Image generation","Adversarial learning; Adversarial networks; Coarse to fine; Global appearances; Image generations; Multi-view image; Target images; Variational inference; Deep learning",,,,,"Chang, B., Zhang, Q., Pan, S., Meng, L., Generating handwritten Chinese characters using cycleGAN (2018) WACV; Chen, T., Zhu, Z., Shamir, A., Hu, S.-M., Cohen-Or, D., 3-Sweep: Extracting editable objects from a single photo (2013) ACM Transactions on Graphics, , 2013; Chen, X., Duan, Y., Houthooft, R., Schulman, J., Sutskever, I., Abbeel, P., (2016) InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets, , 2016; Donahue, J., Krähenbähl, P., Darrell, T., (2016) Adversarial Feature Learning, , 2016; Dosovitskiy, A., Springenberg, J.T., Tatarchenko, M., Brox, T., Learning to generate chairs, tables and cars with convolutional networks (2015) CVPR; Dumoulin, V., Belghazi, I., Poole, B., Mastropietro, O., Lamb, A., Arjovsky, M., Courville, A., (2017) Adversarially Learned Inference, , 2017; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) NIPS; Gregor, K., Danihelka, I., Graves, A., Rezende, D.J., Wierstra, D., Draw: A recurrent neural network for image generation (2015) ICML; Hinton, G.E., Krizhevsky, A., Wang, S.D., Transforming auto-encoders (2011) ICANN; Isola, P., Zhu, J.-Y., Zhou, T., Efros, A.A., (2016) Image-to-Image Translation with Conditional Adversarial Networks, , 2016; Kholgade, N., Simon, T., Efros, A., Sheikh, Y., 3D object manipulation in a single photograph using stock 3D models (2014) ACM Transactions on Graphics, , 2014; Kingma, D.P., Welling, M., Auto-encoding variational bayes (2014) ICLR; Kulkarni, T.D., Whitney, W., Kohli, P., Tenenbaum, J.B., Deep convolutional inverse graphics network (2015) NIPS; Liu, K.-H., Chen, T.-Y., Chen, C.-S., MVC: A dataset for view-invariant clothing retrieval and attribute prediction (2016) ICMR; Liu, Z., Luo, P., Qiu, S., Wang, X., Tang, X., DeepFashion: Powering robust clothes recognition and retrieval with rich annotations (2016) CVPR; Mirza, M., Osindero, S., (2014) Conditional Generative Adversarial Nets, , 2014; Odena, A., (2016) Semi-Supervised Learning with Generative Adversarial Networks, , 2016; Odena, A., Olah, C., Shlens, J., (2016) Conditional Image Synthesis With Auxiliary Classifier GANs, , 2016; Park, E., Yang, J., Yumer, E., Ceylan, D., Berg, A.C., Transformation-grounded image generation network for novel 3D view synthesis (2017) CVPR; Pathak, D., Krahenbuhl, P., Donahue, J., Darrell, T., Efros, A.A., Context encoders: Feature learning by inpainting (2016) CVPR; Reed, S., Akata, Z., Yan, X., Logeswaran, L., Schiele, B., Lee, H., Generative adversarial text-to-image synthesis (2016) ICML; Rezende, D.J., Ali Eslami, S.M., Mohamed, S., Battaglia, P.W., Jaderberg, M., Heess, N., Unsupervised learning of 3D structure from images (2016) NIPS; Rezende, D.J., Mohamed, S., Wierstra, D., Stochastic backpropagation and approximate inference in deep generative models (2014) ICML; Ronneberger, O., Fischer, P., Brox, T., U-Net: Convolutional networks for biomedical image segmentation (2015) MICCAI; Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., Chen, X., (2016) Improved Techniques for Training GANs, , 2016; Sohn, K., Lee, H., Yan, X., Learning structured output representation using deep conditional generative models (2015) NIPS; Wang, B., Yang, Y., Xu, X., Hanjalic, A., Shen, H.T., Adversarial cross-modal retrieval (2017) ACM MM, pp. 154-162; Wang, Z., Bovik, A.C., Sheikh, H.R., Simoncelli, E.P., Image quality assessment: From error visibility to structural similarity (2004) IEEE Transactions on Image Processing, 13 (4), pp. 600-612. , 2004; Wu, J., Xue, T., Lim, J.J., Tian, Y., Tenenbaum, J.B., Torralba, A., Freeman, W.T., Single image 3D interpreter network (2016) ECCV; Xiong, W., Luo, W., Ma, L., Liu, W., Luo, J., Learning to generate time-lapse videos using multi-stage dynamic generative adversarial networks (2018) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Yan, X., Yang, J., Sohn, K., Lee, H., Attribute2Image: Conditional image generation from visual attributes (2016) ECCV; Yan, X., Yang, J., Yumer, E., Guo, Y., Lee, H., Perspective transformer nets: Learning single-view 3D object reconstruction without 3D supervision (2016) NIPS; Yoo, D., Kim, N., Park, S., Paek, A.S., Kweon, I.S., (2016) Pixel-Level Domain Transfer, , 2016; Zhang, H., Xu, T., Li, H., Zhang, S., Huang, X., Wang, X., Metaxas, D., (2016) StackGAN: Text to Photo-Realistic Image Synthesis with Stacked Generative Adversarial Networks, , 2016; Zhao, B., Chang, B., Jie, Z., Sigal, L., Modular generative adversarial networks (2018) ECCV; Zheng, Y., Chen, X., Cheng, M.-M., Zhou, K., Hu, S.-M., Mitra, N.J., Interactive images: Cuboid proxies for smart image manipulation (2012) ACM Transactions on Graphics, , 2012; Zhou, T., Tulsiani, S., Sun, W., Malik, J., Efros, A.A., View synthesis by appearance flow (2016) ECCV; Zhou, Y., Berg, T.L., Learning temporal transformations from time-lapse videos (2016) ECCV; Zhu, J.-Y., Krähenbühl, P., Shechtman, E., Efros, A.A., Generative visual manipulation on the natural image manifold (2016) ECCV","Wu, X.; Southwest Jiaotong UniversityChina; email: wuxiaohk@home.swjtu.edu.cn",,"ACM SIGMM","Association for Computing Machinery, Inc","26th ACM Multimedia conference, MM 2018","22 October 2018 through 26 October 2018",,142036,,9781450356657,,,"English","MM - Proc. ACM Multimed. Conf.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85055122799
"Wu M., Li Y.","57204643877;56036047900;","Adversarial mRMR against Evasion Attacks",2018,"Proceedings of the International Joint Conference on Neural Networks","2018-July",,"8489246","","",,2,"10.1109/IJCNN.2018.8489246","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056553088&doi=10.1109%2fIJCNN.2018.8489246&partnerID=40&md5=77ee705f5ffe3c8cbaf15e3e96ea10de","School of Computer Science and Technology, Nanjing University of Posts and Telecommunications, Nanjing, China","Wu, M., School of Computer Science and Technology, Nanjing University of Posts and Telecommunications, Nanjing, China; Li, Y., School of Computer Science and Technology, Nanjing University of Posts and Telecommunications, Nanjing, China","Machine learning (ML) algorithms provide a good solution for many security sensitive applications, they themselves, however, face the threats of adversary attacks. As a key problem in machine learning, how to design robust feature selection algorithms against these attacks becomes a hot issue. The current researches on defending evasion attacks mainly focus on wrapped adversarial feature selection algorithm, i.e., WAFS, which is dependent on the classification algorithms, and time cost is very high for large-scale data. Since mRMR (minimum Redundancy and Maximum Relevance) algorithm is one of the most popular filter algorithms for feature selection without considering any classifier during feature selection process. In this paper, we propose a novel adversary-aware feature selection algorithm under filter model based on mRMR, named FAFS. The algorithm, on the one hand, takes the correlation between a single feature and a label, and the redundancy between features into account; on the other hand, when selecting features, it not only considers the generalization ability in the absence of attack, but also the robustness under attack. The performance of four algorithms, i.e., mRMR, TWFS (Traditional Wrapped Feature Selection algorithm), WAFS, and FAFS is evaluated on spam filtering and PDF malicious detection in the Perfect Knowledge attack scenarios. The experiment results show that FAFS has a better performance under evasion attacks with less time complexity, and comparable classification accuracy. © 2018 IEEE.","adversarial feature selection; evasion attacks; filter model; mRMR","Artificial intelligence; Classification (of information); Distributed computer systems; Learning algorithms; Learning systems; Redundancy; Classification accuracy; Classification algorithm; evasion attacks; Feature selection algorithm; Filter model; Generalization ability; mRMR; Robust feature selection; Feature extraction",,,,,"Biggio, B., Akhtar, Z., Fumera, G., Marcialis, G.L., Roli, F., Security evaluation of biometric authentication systems under real spoofing attacks (2012) IET Biometrics, 1 (1), pp. 11-24; Newsome, J., Karp, B., Song, D., Paragraph: Thwarting signature learning by training maliciously (2006) Recent Advances in Intrusion Detection (Lecture Notes in Computer Science)., pp. 81-105. , Berlin, Germany: Springer; Moore, D., Shannon, C., Brown, D.J., Voelker, G.M., Savage, S., Inferring internet denial-of-service activity (2006) ACM Trans. Comput. Syst, 24 (2), pp. 115-139; Lowd, D., Meek, C., Good word attacks on statistical spam filters (2005) Proc. 2nd Conf. Email Anti-Spam, , Palo Alto, CA, USA; Biggio, B., Security evaluation of support vector machines in adversarial environments (2014) Support Vector Machines Applications, pp. 105-153. , Y. Ma and G. Guo, Eds. Cham, Switzerland: Springer; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B., Tygar, J.D., Adversarial machine learning (2011) Proc. 4th ACM Workshop Artif. Intell. Security, pp. 43-57. , Chicago, IL, USA; Biggio, B., Fumera, G., Roli, F., Security evaluation of pattern classifiers under attack (2014) IEEE Trans. Knowl. Data Eng, 26 (4), pp. 984-996. , Apr; Zhang, F., Patrick, C., Biggio, B., Adversarial feature selection against evasion attacks (2016) IEEE Transactions on Cybernetics, 46 (3), p. 766; Biggio, B., Evasion attacks against machine learning at test time (2013) Machine Learning and Knowledge Discovery in Databases (LNCS 8190), pp. 387-402. , H. Blockeel, K. Kersting, S. Nijssen, and F. Železný, Eds. Berlin, Germany: Springer; Dalvi, N., Adversarial classification (2004) Proceedings of 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 99-108. , Seattle; Bi, W., Shi, Y., Lan, Z., Transferred feature selection (2009) Proceedings of 9th IEEE International Conference on Data Mining Workshops, pp. 416-421. , Miami; Peng, H., Long, F., Ding, C., Feature selection based on mutual information criteria of max-dependency, max-relevance, and minredundancy (2005) IEEE Trans. Pattern Anal. Mach. Intell, 27 (8), pp. 1226-1238. , Aug; Le Thi, H.A., Vo, X.T., Dinh, T.P., Robust feature selection for svms under uncertain data (2013) Advances in Data Mining, Apps, and Theoretical Aspects, pp. 151-165. , Berlin, Germany: Springer; Li, B., Vorobeychik, Y., Feature cross-substitution in adversarial classification (2014) Proc. Adv. Neural Inf. Process. Syst., pp. 2087-2095. , Montreal, QC, Canada; Wang, F., Liu, W., Chawla, S., On sparse feature attacks in adversarial learning (2014) Proc. IEEE Int. Conf. Data Min. (ICDM), pp. 1013-1018. , Shenzhen, China; Barreno, M., Nelson, B., Joseph, A.D., The security of machine learning (2010) Machine Learning, 81 (2), pp. 121-148; Peng, H., Long, F., Ding, C., Feature selection based on mutual information: Criteria of max-dependency, max-relevance, and min-redundancy (2005) IEEE Transactions on Pattern Analysis & Machine Intelligence, 27 (8), pp. 1226-1238; Kolcz, A., Teo, C.H., Feature weighting for improved classifier robustness (2009) Proc. 6th Conf. Email Anti-Spam, , Mountain View, CA, USA; Biggio, B., Fumera, G., Roli, F., Evade hard multiple classifier systems (2009) Supervised and Unsupervised Ensemble Methods and Their Applications (Studies in Computational Intelligence), 245, pp. 15-38. , O. Okun and G. Valentini, Eds. Berlin, Germany: Springer; Nelson, B., Rubinstein, B.I.P., Huang, L., Classifier evasion: Models and open problems (2010) PSDML, pp. 92-98; Sculley, D., Wachman, G.M., Relaxed online svms for spam filtering (2007) Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. ACM, pp. 415-422; (2012) SpamBayes Homepage, , http://spambayes.sourceforge.net, last accessed Jun; Cormack, G.V., TREC 2007 spam track overview (2007) Proc. 16th Text Retrieval Conf. (TREC), pp. 123-131; Fan, R.E., Chang, K.W., Hsieh, C.J., Liblinear: A library for large linear classification[j] (2008) Journal of Machine Learning Research, 9, pp. 1871-1874. , (Aug); Kohavi, R., John, G.H., Wrappers for feature subset selection (1997) Artif. Intell, 97 (1), pp. 273-324; Guyon, I., Elisseeff, A., An introduction to variable and feature selection (2003) J. Mach. Learn. Res, 3, pp. 1157-1182. , Mar; Wittel, G.L., Wu, S.F., On attacking statistical spam filters (2004) Proceedings of the Conference on Email and Anti-Spam (CEAS), , Mountain View, CA, USA; Maiorca, D., Corona, I., Giacinto, G., Looking at the bag is not enough to find the bomb: An evasion of structural methods for malicious pdf files detection (2013) Proc. 8th ACM SIGSAC Symp. Inf. Comput. Commun. Security (ASIACCS), pp. 119-130. , Hangzhou, China",,,,"Institute of Electrical and Electronics Engineers Inc.","2018 International Joint Conference on Neural Networks, IJCNN 2018","8 July 2018 through 13 July 2018",,141067,,9781509060146,85OFA,,"English","Proc Int Jt Conf Neural Networks",Conference Paper,"Final","",Scopus,2-s2.0-85056553088
"Worzyk N., Kramer O.","57144662600;34875208500;","Adversarials -1: Defending by Attacking",2018,"Proceedings of the International Joint Conference on Neural Networks","2018-July",,"8489630","","",,2,"10.1109/IJCNN.2018.8489630","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056512969&doi=10.1109%2fIJCNN.2018.8489630&partnerID=40&md5=6157e22bbc0d9874c37c071568cadef9","University of Oldenburg Oldenburg, Science University of Oldenburg Oldenburg, Germany","Worzyk, N., University of Oldenburg Oldenburg, Science University of Oldenburg Oldenburg, Germany; Kramer, O., University of Oldenburg Oldenburg, Science University of Oldenburg Oldenburg, Germany","Although neural networks are very successful in the domain of image processing, they are vulnerable to adversarial images-slightly perturbed images, which a human cannot distin- guish from the original image. However, for the neural network, the perturbation leads to a different classification of the image.A lot of research was done on adversarial attacks, and on defenses against those attacks. In this paper, we propose a new defense by applying adversarial attacks to adversarial images. The new type of adversarial images is called a d v -1 and by observing the properties of the different transitions-from original to adversarial images, and from adversarial to a d v -1 images-we are able to detect adversarial images with a high accuracy, even for unknown attacks. Furthermore we are able to identify the attack, used to create the adversarial image in the first place. Regarding classification, depending on the used attack, our approach reaches correct classification accuracies, comparable to other defenses. © 2018 IEEE.","Adver- sarial classification; adversarial detection; adversarial images","Neural networks; adversarial images; Classification accuracy; High-accuracy; Original images; Unknown attacks; Image processing",,,,,"Athalye, A., Sutskever, I., (2017) Synthesizing Robust Adversarial Examples, , arXiv preprint arXiv: 1707. 07397; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium on, pp. 39-57. , IEEE; Chen, P.-Y., Sharma, Y., Zhang, H., Yi, J., Hsieh, C.-J., (2017) EAD: Elastic-Net Attacks to Deep Neural Networks Via Adversarial Examples, , ArXiv e-prints, Sept; Evtimov, I., Eykholt, K., Fernandes, E., Kohno, T., Li, B., Prakash, A., Rahmati, A., Song, D., (2017) Robust Physical-world Attacks on Machine Learning Models, , arXiv preprint arXiv: 1707. 08945; Gong, Z., Wang, W., Ku, W.-S., (2017) Adversarial and Clean Data Are Not Twins, , arXiv preprint arXiv: 1704. 04960; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint arXiv: 1412. 6572; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint arXiv: 1607. 02533; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Machine Learning at Scale, , arXiv preprint arXiv: 1611. 01236; LeCun, Y., (1998) The Mnist Database of Handwritten Digits, , http://yann.LeCun.com/exdb/mnist/; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , arXiv preprint arXiv: 1706. 06083; Miyato, T., Maeda, S.-I., Koyama, M., Nakae, K., Ishii, S., (2015) Distributional Smoothing with Virtual Adversarial Training, , arXiv preprint arXiv: 1507. 00677; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Papernot, N., Goodfellow, I., Sheatsley, R., Feinman, R., McDaniel, P., (2016) Cleverhans v1. 0. 0: An Adversarial Machine Learning Library, , arXiv preprint arXiv: 1610. 00768; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387. , IEEE; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Security and Privacy (SP), 2016 IEEE Symposium on, pp. 582-597. , IEEE; Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Duchesnay, E., Scikit-learn: Machine learning in Python (2011) Journal of Machine Learning Research, 12, pp. 2825-2830; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Fei-Fei, L., Imagenet large scale visual recognition challenge (2015) International Journal of Computer Vision (IJCV), 115 (3), pp. 211-252; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint arXiv: 1312. 6199; Tabacof, P., Valle, E., Exploring the space of adversarial images (2016) Neural Networks (IJCNN), 2016 International Joint Conference on, pp. 426-433. , IEEE; Worzyk, N., Kramer, O., Properties of adv1-adversarials of adversarials (2018) ESANN, , in print",,,,"Institute of Electrical and Electronics Engineers Inc.","2018 International Joint Conference on Neural Networks, IJCNN 2018","8 July 2018 through 13 July 2018",,141067,,9781509060146,85OFA,,"English","Proc Int Jt Conf Neural Networks",Conference Paper,"Final","",Scopus,2-s2.0-85056512969
"Correia-Silva J.R., Berriel R.F., Badue C., De Souza A.F., Oliveira-Santos T.","57204644579;57148116200;55884747400;55425796800;36814134400;","Copycat CNN: Stealing Knowledge by Persuading Confession with Random Non-Labeled Data",2018,"Proceedings of the International Joint Conference on Neural Networks","2018-July",,"8489592","","",,29,"10.1109/IJCNN.2018.8489592","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056506880&doi=10.1109%2fIJCNN.2018.8489592&partnerID=40&md5=2fc74cc311be6490a27cad027a407178","Universidade Federal Do Espírito, B-Santo, Brazil","Correia-Silva, J.R., Universidade Federal Do Espírito, B-Santo, Brazil; Berriel, R.F., Universidade Federal Do Espírito, B-Santo, Brazil; Badue, C., Universidade Federal Do Espírito, B-Santo, Brazil; De Souza, A.F., Universidade Federal Do Espírito, B-Santo, Brazil; Oliveira-Santos, T., Universidade Federal Do Espírito, B-Santo, Brazil","In the past few years, Convolutional Neural Networks (CNNs) have been achieving state-of-the-art performance on a variety of problems. Many companies employ resources and money to generate these models and provide them as an API, therefore it is in their best interest to protect them, i.e., to avoid that someone else copy them. Recent studies revealed that stateof-the-art CNNs are vulnerable to adversarial examples attacks, and this weakness indicates that CNNs do not need to operate in the problem domain (PD). Therefore, we hypothesize that they also do not need to be trained with examples of the PD in order to operate in it.Given these facts, in this paper, we investigate if a target blackbox CNN can be copied by persuading it to confess its knowledge through random non-labeled data. The copy is two-fold: I) the target network is queried with random data and its predictions are used to create a fake dataset with the knowledge of the network; and ii) a copycat network is trained with the fake dataset and should be able to achieve similar performance as the target network.This hypothesis was evaluated locally in three problems (facial expression, object, and crosswalk classification) and against a cloud-based API. In the copy attacks, images from both nonproblem domain and PD were used. All copycat networks achieved at least 93.7% of the performance of the original models with non-problem domain data, and at least 98.6% using additional data from the PD. Additionally, the copycat CNN successfully copied at least 97.3% of the performance of the Microsoft Azure Emotion API. Our results show that it is possible to create a copycat CNN by simply querying a target network as black-box with random non-labeled data. © 2018 IEEE.","adversarial examples; convolutional neural network; deep neural network; security","Classification (of information); Convolution; Neural networks; Windows operating system; Additional datum; adversarial examples; Convolutional neural network; Facial Expressions; Original model; security; State of the art; State-of-the-art performance; Deep neural networks",,,,,"Tramèr, F., Zhang, F., Juels, A., Reiter, M.K., Ristenpart, T., Stealing machine learning models via prediction apis (2016) USENIX Security Symposium, pp. 601-618; Shi, Y., Sagduyu, Y., Grushin, A., How to steal a machine learning classifier with deep learning (2017) IEEE International Symposium on Technologies for Homeland Security (HST). IEEE, pp. 1-5; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations (ICLR); Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations (ICLR); Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-Box Attacks Using Adversarial Samples, , arXiv preprint arXiv: 1605. 07277 May; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) IEEE Symposium on Security and Privacy (SP), pp. 582-597; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security. ACM, pp. 506-519; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2017) Int. Conf. On Learning Representations (ICLR); Zantedeschi, V., Nicolae, M.-I., Rawat, A., Efficient defenses against adversarial attacks (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security. ACM, pp. 39-49; Liao, F., Liang, M., Dong, Y., Pang, T., Zhu, J., Hu, X., (2017) Defense Against Adversarial Attacks Using High-Level Representation Guided Denoiser, , arXiv preprint arXiv: 1712. 02976 Dec; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , June; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-Scale Image Recognition, , arXiv preprint arXiv: 1409. 1556 Sep; Yosinski, J., Clune, J., Bengio, Y., Lipson, H., How transferable are features in deep neural networks? (2014) Advances in Neural Information Processing Systems (NIPS), 27, pp. 3320-3328. , Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger, Eds; Glorot, X., Bengio, Y., Understanding the difficulty of training deep feedforward neural networks (2010) Proceedings of the 13th Int. Conf. On Artificial Intelligence and Statistics, pp. 249-256; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Fei-Fei, L., Imagenet large scale visual recognition challenge (2015) International Journal of Computer Vision (IJCV), 115 (3), pp. 211-252; Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Dollár, P., Zitnick, C.L., Microsoft COCO: Common objects in context (2014) European Conference on Computer Vision (ECCV), pp. 740-755; Ekman, P., Friesen, W.V., Constants across cultures in the face and emotion (1971) Journal of Personality and Social Psychology, 17 (2), p. 124; Lucey, P., Cohn, J.F., Kanade, T., Saragih, J., Ambadar, Z., Matthews, I., The extended cohn-kanade dataset (ck+): A complete dataset for action unit and emotion-specified expression (2010) Computer Vision and Pattern Recognition Workshops (CVPRW), 2010 IEEE Computer Society Conference On. IEEE, pp. 94-101; Martinez, A.M., Benavente, R., The ar face database (1998) CVC Technical Report, (24); Yin, L., Wei, X., Sun, Y., Wang, J., Rosato, M.J., A 3D facial expression database for facial behavior research (2006) 7th Int. Conf. On Automatic Face and Resture Recognition (FGR), pp. 211-216; Lyons, M., Akamatsu, S., Kamachi, M., Gyoba, J., Coding facial expressions with gabor wavelets (1998) Automatic Face and Gesture Recognition, 1998. Proceedings. Third IEEE International Conference On. IEEE, pp. 200-205; Pantic, M., Valstar, M., Rademaker, R., Maat, L., Web-based database for facial expression analysis (2005) IEEE International Conference on Multimedia and Expo (ICME). IEEE, p. 5; Langner, O., Dotsch, R., Bijlstra, G., Wigboldus, D.H., Hawk, S.T., Van Knippenberg, A., Presentation and validation of the Radboud Faces Database (2010) Cognition and Emotion, 24 (8), pp. 1377-1388; Lundqvist, D., Flykt, A., Hman, A.Ö., The karolinska directed emotional faces (kdef) (1998) CD ROM from Department of Clinical Neuroscience, Psychology Section, Karolinska Institutet, pp. 91-630; Zavarez, M.V., Berriel, R.F., Oliveira-Santos, T., Cross-database facial expression recognition based on fine-tuned deep convolutional network (2017) 2017 30th SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI), pp. 405-412. , Oct; Parkhi, O.M., Vedaldi, A., Zisserman, A., Deep face recognition (2015) BMVC, 1 (3), p. 6; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images, , Master's thesis, University of Toronto, Dept. Of Comp. Sci., Toronto, Canada; Coates, A., Ng, A., Lee, H., An analysis of single-layer networks in unsupervised feature learning (2011) Proceedings of the 14th Int. Conf. On Artificial Intelligence and Statistics, pp. 215-223; Berriel, R.F., Lopes, A.T., De Souza, A.F., Oliveira-Santos, T., Deep learning-based large-scale automatic satellite crosswalk classification (2017) IEEE Geoscience and Remote Sensing Letters, 14 (9), pp. 1513-1517; Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadarrama, S., Darrell, T., Caffe: Convolutional architecture for fast feature embedding (2014) Proceedings of the 22nd ACM International Conference on Multimedia, pp. 675-678",,,,"Institute of Electrical and Electronics Engineers Inc.","2018 International Joint Conference on Neural Networks, IJCNN 2018","8 July 2018 through 13 July 2018",,141067,,9781509060146,85OFA,,"English","Proc Int Jt Conf Neural Networks",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85056506880
"Huang Y., Wang S.-H.","57216166085;57204647323;","Adversarial Manipulation of Reinforcement Learning Policies in Autonomous Agents",2018,"Proceedings of the International Joint Conference on Neural Networks","2018-July",,"8489741","","",,5,"10.1109/IJCNN.2018.8489741","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056495454&doi=10.1109%2fIJCNN.2018.8489741&partnerID=40&md5=6daa33d6a3b52b93a1ab9929677765f6","McAfee LLC, Hillsboro, Oregon  97124, United States; Intel Corporation, Hillsboro, Oregon  97124, United States","Huang, Y., McAfee LLC, Hillsboro, Oregon  97124, United States; Wang, S.-H., Intel Corporation, Hillsboro, Oregon  97124, United States","Machine learning classifiers are known to be vul- nerable to intentional perturbation of inputs, namely adversarial examples. There are extensive studies of adversarial machine learning in the context of computer vision with high dimen- sional inputs. In this work, we show that adversarial attacks are also effective in targeting reinforcement learning policies based on low-dimensional sensory inputs in autonomous agent controls. Our results show that the two adversarial example crafting techniques significantly degrade test performance of the trained reinforcement learning policies. In addition, we compare adversarial examples with random noise on the effectiveness of the attacks. Furthermore, we study the importance of the input features, in terms of the impact of performance in adversarial attacks. © 2018 IEEE.",,"Artificial intelligence; Reinforcement learning; Autonomous agent control; Input features; Low dimensional; Random noise; Sensory input; Test performance; Autonomous agents",,,,,"Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.A., Veness, J., Bellemare, M.G., Graves, A., Hassabis, D., Human level control through deep reinforcement learning (2015) Nature, 518, pp. 529-533; Silver, D., Huang, A., Maddison, C.J., Guez, A., Sifre, L., Driessche, G., Schrittwieser, J., Hassabis, D., Mastering the game of go with deep neural networks and tree search (2016) Nature, 529, pp. 484-489; Shaley-Shwartz, S., Shammah, S., Shashua, A., Safe multi-agent reinforcement learning for autonomous driving (2016) Proc of Neural Information Processing Systems (NIPS); Sallab, A., Abdou, M., Perot, E., Yogamani, S., Deep reinforcement learning framework for autonomous driving (2017) Autonomous Vehicles and Machines, pp. 70-76; Barreno, N., Nelson, B., Sears, R., Joseph, A.D., Tygar, J.D., Can machine learning be secure (2006) Proc of ACM Symposium on Information, Computer and Communication Security; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I.P., Tygar, J.D., Adversarial machine learning (2011) Proc of ACM Workshop on Artificial Intelligence and Security; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Rndi, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Machine Learning and Knowledge Discovery in Databases, pp. 387-402; Szegedy, C., Zaremba, W., Sutskever, I., Erhan, D., Goodfellow, I., Fengus, R., Intriguing properties of neural networks (2013) Proc of International Conference on Learning Representations (ICLR); Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) Proc of ICLR; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial examples in the physical world (2017) Proc of ICLR; Dong, Y., Liao, F., Pang, T., Suan, H., Zhu, D.J., Hu, S., Li, J., (2018) Boosting Adversarial Attacks with Momentum; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Proc of IEEE European Symposium on Security & Privacy; Miyato, T., Maeda, S., Koyama, M., Nakae, K., Ishii, S., Distributional smoothing with virtual adversarial training (2016) Proc of ICLR; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Proc of IEEE Symposium on Security and Privacy; Chen, P., Sharma, Y., Zhang, H., Yi, J., Hsieh, C., (2018) EAD: Elastic-Net Attacks to Deep Neural Networks Via Adversarial Examples; Moosavi-Dezfooli, S., Fawzi, A., Frossard, P., (2016) DeepFool: A Simple and Accurate Method to Fool Deep Neural Networks; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks; Sabour, S., Cao, Y., Faghri, F., Fleet, D.J., Adversarial manipulation of deep representations (2016) Proc of ICLR; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proc of ACM SIGSAC Conf on Computer and Communications Security; Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Xiao, C., Prakash, A., Song, D., Robust physical-world attacks on deep learning models (2018) Proc of Conference on Computer Vision and Pattern Recognition; Papernot, N., McDaniel, P., Wu, X., Iha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Proc of IEEE Symposium on Security & Privacy; Carlini, N., Wagner, D., (2017) Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods; Huang, S., Papernot, N., Goodfellow, I., Duan, Y., Abbeel, P., Adversarial attacks on neural network policies (2017) Proc of ICLR; Sutton, R.S., Barto, A.G., (2017) Reinforcement Learning: An Introduction, , Second Edition, MIT Press; Schulman, J., Levine, S., Moritz, P., Jordan, M.I., Abbeel, P., Trust region policy optimization (2015) Proc of International Conference on Machine Learning (ICML); Behzadan, V., Munir, A., Vulnerability of deep reinforcement learning to policy induction attacks (2017) Proc of Intl Conf on Machine Learning and Data Mining; Kos, J., Song, D., Delving into adversarial attacks to deep policies (2017) Proc of ICLR; Lin, Y., Hong, Z., Liao, Y., Shih, M., Liu, M., Sun, M., Tactics of adversarial attack on deep reinforcement learning agents (2017) Proc of Intl Joint Conf on Artificial Intelligence; Amodei, D., Olah, C., Steinhardt, J., Christiano, P., Schulman, J., Man, D., (2016) Concrete Problems in AI Safety; Lau, B., (2018) Using Keras and Deep Deterministic Policy Gradient to Play TORCS, , https://yanpanlau.github.io/2016/10/11/Torcs-Keras.html, Feb 1; Loiacono, D., Cardamone, L., Lanzi, P.L., (2013) Simulated Car Racing Championship Competition Software Manual; Brockman, G., Cheung, V., Pettersson, L., Schneider, J.S., Schulman, J., Tang, J., Zaremba, W., (2016) OpenAI Gym; Lillicrap, T.P., Hunt, J.J., Pritzel, A., Heess, N., Erez, T., Tassa, Y., Silver, D., Wierstra, D., Continuous control with deep reinforcement learning (2016) Proc of ICLR; Silver, D., Lever, G., Heess, N., Degris, T., Wierstra, D., Riedmiller, M., Deterministic policy gradient algorithms (2014) Proc of ICML; Papernot, N., Carlini, N., Goodfellow, I., Feinman, R., Faghri, F., Matyasko, A., Hambardzumyan, K., Lin, Y., (2017) Cleverhans v2. 0. 0: An Adversarial Machine Learning Library; Weese, M., Martinez, W., Megahed, F.M., Jones-Farmer, L.A., Statistical learning methods applied to process monitoring: An overview and perspective (2016) Journal of Quality Technology, 48, pp. 4-27",,,,"Institute of Electrical and Electronics Engineers Inc.","2018 International Joint Conference on Neural Networks, IJCNN 2018","8 July 2018 through 13 July 2018",,141067,,9781509060146,85OFA,,"English","Proc Int Jt Conf Neural Networks",Conference Paper,"Final","",Scopus,2-s2.0-85056495454
"Frederickson C., Moore M., Dawson G., Polikar R.","57193713130;57214387039;57204648267;7003651287;","Attack Strength vs. Detectability Dilemma in Adversarial Machine Learning",2018,"Proceedings of the International Joint Conference on Neural Networks","2018-July",,"8489495","","",,9,"10.1109/IJCNN.2018.8489495","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056489592&doi=10.1109%2fIJCNN.2018.8489495&partnerID=40&md5=f3ee73d5500c14f85534f6ecbc91b0e1","Rowan University, United States","Frederickson, C., Rowan University, United States; Moore, M., Rowan University, United States; Dawson, G., Rowan University, United States; Polikar, R., Rowan University, United States","As the prevalence and everyday use of machine learning algorithms, along with our reliance on these algorithms grow dramatically, so do the efforts to attack and undermine these algorithms with malicious intent, resulting in a growing interest in adversarial machine learning. A number of approaches have been developed that can render a machine learning algorithm ineffective through poisoning or other types of attacks. Most attack algorithms typically use sophisticated optimization approaches, whose objective function is designed to cause maximum damage to accuracy or performance of the algorithm with respect to some task. In this effort, we show that while such an objective function is indeed brutally effective in causing maximum damage on an embedded feature selection task, it often results in an attack mechanism that can be easily detected with an embarrassingly simple novelty or outlier detection algorithm. We then propose an equally simple yet elegant solution by adding a regularization term to the attacker's objective function that penalizes outlying attack points. © 2018 IEEE.",,"Artificial intelligence; Damage detection; Learning systems; Attack mechanism; Detectability; Embedded feature selections; Objective functions; Optimization approach; Outlier detection algorithm; Regularization terms; Learning algorithms",,,,,"Boyan, J., Freitag, D., Joachims, T., A machine learning architecture for optimizing web search engines (1996) AAAI Workshop on Internet Based Information Systems, pp. 1-8; Miralles-Pechuán, L., Ponce, H., Martínez-Villaseñor, L., A novel methodology for optimizing display advertising campaigns using genetic algorithms (2018) Electronic Commerce Research and Applications, 27, pp. 39-51; Ziegler, C.-N., Lausen, G., Schmidt-Thieme, L., Taxonomy-driven computation of product recommendations (2004) Proceedings of the Thirteenth ACM International Conference on Information and Knowledge Management. ACM, pp. 406-415; Maes, S., Tuyls, K., Vanschoenwinkel, B., Manderick, B., Credit card fraud detection using Bayesian and neural networks (2002) 1st International Naiso Congress on Neuro Fuzzy Technologies, pp. 261-270; Chi, H.-M., Ersoy, O.K., Moskowitz, H., Ward, J., Modeling and optimizing a vendor managed replenishment system using machine learning and genetic algorithms (2007) European Journal of Operational Research, 180 (1), pp. 174-193; Berk, R., (2012) Criminal Justice Forecasts of Risk: A Machine Learning Approach, , Springer Science & Business Media; Gadepally, V.N., Greenfield, K.B., Campbell, W.M., Campbell, J.P., Reuther, A.I., Hancock, B.J., (2016) Recommender Systems for the Department of Defense and the Intelligence Community, , MIT Lincoln Laboratory Lexington United States, Tech. Rep; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I., Tygar, J., Adversarial machine learning (2011) Proceedings of the 4th ACM Workshop on Security and Artificial Intelligence. ACM, pp. 43-58; Biggio, B., Roli, F., (2017) Wild Patterns: Ten Years after the Rise of Adversarial Machine Learning, , arXiv preprint; Dalvi, N., Domingos, P., Mausam Sanghai, S., Verma, D., Adversarial classification (2004) 2004 ACM SIGKDD International Conference on Knowledge Discovery and Data Mining-KDD '04, p. 99; Kearns, M., Li, M., Learning in the presence of malicious errors (1993) SIAM Journal on Computing, 22 (4), pp. 807-837; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint arXiv: 1412. 6572; Barreno, M., Nelson, B., Sears, R., Joseph, A.D., Tygar, J.D., Can machine learning be secure? (2006) Proceedings of the 2006 ACM Symposium on Information, Computer and Communications Security. ACM, pp. 16-25; Biggio, B., Nelson, B., Laskov, P., (2012) Poisoning Attacks Against Support Vector Machines, , arXiv preprint arXiv: 1206. 6389; Muñoz-González, L., Biggio, B., Demontis, A., Paudice, A., Wongrassamee, V., Lupu, E.C., Roli, F., Towards poisoning of deep learning algorithms with back-gradient optimization (2017) 10th ACM Workshop on Artificial Intelligence and Security. ACM, pp. 27-38; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Srndíc, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Machine Learning and Knowledge Discovery in Databases, 8190, pp. 387-402. , Springer Berlin Heidelberg; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., (2016) Practical Black-box Attacks Against Deep Learning Systems Using Adversarial Examples, , arXiv preprint arXiv: 1602. 02697; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and Harnessing Adversarial Examples (2015) Iclr 2015, pp. 1-11; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Proceedings-2016 IEEE Symposium on Security and Privacy, SP 2016, pp. 582-597; Biggio, B., Pillai, I., Rota Bulò, S., Ariu, D., Pelillo, M., Roli, F., Is data clustering in adversarial settings secure? (2013) 2013 ACM Workshop on Artificial Intelligence and Security. ACM, pp. 87-98; Xiao, H., Biggio, B., Brown, G., Fumera, G., Eckert, C., Roli, F., Is feature selection secure against training data poisoning? (2015) International Conference on Machine Learning, pp. 1689-1698; Clavier, C., Secret external encodings do not prevent transient fault analysis (2007) International Workshop on Cryptographic Hardware and Embedded Systems, pp. 181-194. , Springer; Lichman, M., (2013) UCI Machine Learning Repository; Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Duchesnay, E., Scikit-learn: Machine learning in Python (2011) Journal of Machine Learning Research, 12, pp. 2825-2830; Schölkopf, B., Williamson, R.C., Smola, A.J., Shawe-Taylor, J., Platt, J.C., Support vector method for novelty detection (2000) Advances in Neural Information Processing Systems, pp. 582-588; Liu, F.T., Ting, K.M., Zhou, Z.-H., Isolation forest (2008) 8th IEEE International Conference on Data Mining. IEEE, pp. 413-422; Breunig, M.M., Kriegel, H.-P., Ng, R.T., Sander, J., Lof: Identifying density-based local outliers (2000) ACM Sigmod Record, 29 (2), pp. 93-104. , ACM; Cao, X., Gong, N.Z., Mitigating Evasion AAacks to Deep Neural Networks Via Region-based Classification, , arXiv preprint; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts, , arXiv preprint; Gong, Z., Wang, W., Ku, W.-S., (2017) Adversarial and Clean Data Are Not Twins, , arXiv preprint; Hendrycks, D., Gimpel, K., Early methods for detecting adversarial images (2017) ICLR 2017 Workshop Track; Ororbia, A.G., Giles, C.L., Kifer, D., (2016) Unifying Adversarial Training Algorithms with Flexible Deep Data Gradient Regularization, , arXiv preprint; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , arXiv preprint; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2017) ICLR, 2017; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Proceedings-2016 IEEE Symposium on Security and Privacy, SP 2016, pp. 582-597; Papernot, N., McDaniel, P., (2017) Extending Defensive Distillation, pp. 1-11. , arXiv preprint; Roesch, M., Snort: Lightweight intrusion detection for networks (1999) LISA '99: 13th Systems Administration Conference, pp. 229-238; Nelson, B., Barreno, M., Chi, F.J., Joseph, A.D., Rubinstein, B.I., Saini, U., Sutton, C., Xia, K., Exploiting machine learning to subvert your spam filter (2008) Proceedings of the First Workshop on Largescale Exploits and Emerging Threats (LEET)",,,,"Institute of Electrical and Electronics Engineers Inc.","2018 International Joint Conference on Neural Networks, IJCNN 2018","8 July 2018 through 13 July 2018",,141067,,9781509060146,85OFA,,"English","Proc Int Jt Conf Neural Networks",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85056489592
"Min F., Qiu X., Wu F.","57204634062;9235334300;55700771400;","Adversarial attack? Don't panic",2018,"Proceedings - 2018 4th International Conference on Big Data Computing and Communications, BIGCOM 2018",,,"8488630","90","95",,,"10.1109/BIGCOM.2018.00021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056474183&doi=10.1109%2fBIGCOM.2018.00021&partnerID=40&md5=5b7224f2632b7594d2645a0270976072","Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, China","Min, F., Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, China; Qiu, X., Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, China; Wu, F., Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, China","Deep learning is playing a more and more important role in our daily life and scientific research such as autonomous systems, intelligent life and data mining. However, numerous studies have showed that deep learning with superior performance on many tasks may suffer from subtle perturbations constructed by attacker purposely, called adversarial perturbations, which are imperceptible to human observers but completely effect deep neural network models. The emergence of adversarial attacks has led to questions about neural networks. Therefore, machine learning security and privacy are becoming an increasingly active research area. In this paper, we summarize the prevalent methods for the generating adversarial attacks according to three groups. We elaborated on their ideas and principles of generation. We further analyze the common limitations of these methods and implement statistical experiments of the last layer output on CleverHans to reveal that the detection of adversarial samples is not as difficult as it seems and can be achieved in some relatively simple manners. © 2018 IEEE.","Adversarial attacks; Adversarial generation algorithms; Deep learning; Easy detection","Data mining; Deep learning; Deep neural networks; Adversarial attacks; Autonomous systems; Generation algorithm; Human observers; Neural network model; Scientific researches; Security and privacy; Statistical experiments; Big data",,,,,"Krizhevsky, Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Barreno, M., Nelson, B., Sears, R., Joseph, A.D., Tygar, J.D., Can machine learning be secure? (2006) Proceedings of the 2006 ACM Symposium on Information, Computer and Communications Security, pp. 16-25. , ACM; Yuan, X., He, P., Zhu, Q., Bhat, R.R., Li, X., (2017) Adversarial Examples: Attacks and Defenses for Deep Learning, , arXiv preprint arXiv; Akhtar, N., Mian, A., (2018) Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey, , arXiv preprint arXiv; Szegedy, C., (2013) Intriguing Properties of Neural Networks, , arXiv preprint arXiv; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint arXiv; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Machine Learning at Scale, , arXiv preprint arXiv; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint arXiv; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387. , IEEE; Moosavi Dezfooli, S.M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , no. EPFL-CONF-218057; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., (2017) Universal Adversarial Perturbations, , arXiv preprint; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium on, pp. 39-57. , IEEE; Dong, Y., Boosting Adversarial Attacks with Momentum; Gardner, J.R., (2015) Deep Manifold Traversal: Changing Labels with Convolutional Features, , arXiv preprint arXiv; Tanay, T., Griffin, L., (2016) A Boundary Tilting Persepective on the Phenomenon of Adversarial Examples, , arXiv preprint arXiv; Papernot, N., (2016) Cleverhans v2.0.0: An Adversarial Machine Learning Library, , arXiv preprint arXiv; Abadi, M., (2016) Tensorflow: Large-scale Machine Learning on Heterogeneous Distributed Systems, , arXiv preprint arXiv; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts, , arXiv preprint arXiv; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Security and Privacy (SP), 2016 IEEE Symposium on, pp. 582-597. , IEEE; Gong, Z., Wang, W., Ku, W.-S., (2017) Adversarial and Clean Data Are Not Twins, , arXiv preprint arXiv",,,,"Institute of Electrical and Electronics Engineers Inc.","4th International Conference on Big Data Computing and Communications, BIGCOM 2018","7 August 2018 through 9 August 2018",,140704,,9781538680216,,,"English","Proc. - Int. Conf. Big Data Comput. Commun., BIGCOM",Conference Paper,"Final","",Scopus,2-s2.0-85056474183
"Shi Y., Han Y.","57204978397;55489219500;","Schmidt: Image Augmentation for Black-Box Adversarial Attack",2018,"Proceedings - IEEE International Conference on Multimedia and Expo","2018-July",,"8486449","","",,6,"10.1109/ICME.2018.8486449","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061447901&doi=10.1109%2fICME.2018.8486449&partnerID=40&md5=e7151eaeadbd0f165f8c03028024a13c","School of Computer Science and Technology, Tianjin University, Tianjin, China","Shi, Y., School of Computer Science and Technology, Tianjin University, Tianjin, China; Han, Y., School of Computer Science and Technology, Tianjin University, Tianjin, China","Despite achieving great success in multimedia analysis, especially in image recognition, deep neural networks (DNNs) can be easily fooled by maliciously crafted adversarial examples. Attacker who generates adversarial examples can even launch black-box adversarial attack by querying the target DNN model, without access to its internal structure or training set. In this work, we develop Schmidt Augmentation, an image augmentation method better probes decision boundaries of the black-box model. Schmidt Augmentation helps attackers achieve higher accuracy decrease on MNIST and CIFAR-10 datasets. We also shed light on the harshest circumstance that attacker only has access to samples of the target DNN by providing a labeling method based on semi-supervised learning instead of querying the target model. © 2018 IEEE.","adversarial example; adversarial machine learning; image augmentation; substitute model","Image recognition; Learning algorithms; Machine learning; Supervised learning; adversarial example; Augmentation methods; Decision boundary; image augmentation; Internal structure; Labeling methods; Multi-media analysis; Semi- supervised learning; Deep neural networks",,,,,"Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) CVPR, pp. 427-436; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium On. IEEE, pp. 372-387; Biggio, B., Fumera, G., Russu, P., Didaci, L., Roli, F., Adversarial biometric recognition: A review on biometric system security from the adversarial machinelearning perspective (2015) IEEE Signal Processing Magazine, 32 (5), pp. 31-41; Evtimov, I., Eykholt, K., Fernandes, E., Kohno, T., Li, B., Prakash, A., Rahmati, A., Song, D., (2017) Robust Physical-world Attacks on Deep Learning Models, , arXiv preprint 1707. 08945; Carlini, N., Wagner, D.A., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP), pp. 39-57; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2017) ICLR Workshop; Papernot, N., McDaniel, P.D., Goodfellow, I.J., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) AsiaCCS; Papernot, N., McDaniel, P.D., Goodfellow, I.J., (2016) Transferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples, , CoRR abs/1605. 07277; Zhu, X., Ghahramani, Z., (2002) Learning from Labeled and Unlabeled Data with Label Propagation; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proceedings of the IEEE, 86 (11), pp. 2278-2324; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R., (2013) Intriguing Properties of Neural Networks, , CoRR abs/1312. 6199; Singh Sethi, T., Kantardzic, M., Data driven exploratory attacks on black box classifiers in adversarial domains (2018) Neurocomputing, 289, pp. 129-143; Wang, L., Hu, X., Yuan, B., Lu, J., Active learning via query synthesis and nearest neighbour search (2015) Neurocomputing, 147, pp. 426-434; Van Der Maaten, L., Hinton, G., Visualizing data using t-sne (2008) JMLR, 9, pp. 2579-2605. , Nov; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) ICLR; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) CVPR, pp. 770-778; Huang, G., Liu, Z., Weinberger, K.Q., Densely connected convolutional networks (2017) CVPR, pp. 2261-2269",,,"Acer;Adobe;et al.;InterDigital;Qualcomm;Tencent","IEEE Computer Society","2018 IEEE International Conference on Multimedia and Expo, ICME 2018","23 July 2018 through 27 July 2018",,140885,19457871,9781538617373,,,"English","Proc. IEEE Int. Conf. Multimedia Expo",Conference Paper,"Final","",Scopus,2-s2.0-85061447901
"Papadis N., Borst S., Walid A., Grissa M., Tassiulas L.","57195963896;7005829058;25723889900;57188694948;36562504600;","Stochastic Models and Wide-Area Network Measurements for Blockchain Design and Analysis",2018,"Proceedings - IEEE INFOCOM","2018-April",,"8485982","2546","2554",,35,"10.1109/INFOCOM.2018.8485982","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056184044&doi=10.1109%2fINFOCOM.2018.8485982&partnerID=40&md5=21fcab7b67a570ac5a2d4233daf0819d","Department of Electrical Engineering and Yale Institute for Network Science, Yale University, New Haven, CT  06520, United States; Nokia Bell Labs, Murray Hill, NJ  07974, United States","Papadis, N., Department of Electrical Engineering and Yale Institute for Network Science, Yale University, New Haven, CT  06520, United States; Borst, S., Nokia Bell Labs, Murray Hill, NJ  07974, United States; Walid, A., Nokia Bell Labs, Murray Hill, NJ  07974, United States; Grissa, M., Nokia Bell Labs, Murray Hill, NJ  07974, United States; Tassiulas, L., Department of Electrical Engineering and Yale Institute for Network Science, Yale University, New Haven, CT  06520, United States","The Blockchain paradigm provides a popular mechanism for establishing trust and consensus in distributed environments. While Blockchain technology is currently primarily deployed in crypto-currency systems like Bitcoin, the concept is also expected to emerge as a key component of the Internet-of-Things (IoT), enabling novel applications in digital health, smart energy, asset tracking and smart transportation. As Blockchain networks evolve to industrial deployments with large numbers of geographically distributed nodes, the block transfer and processing delays arise as a critical issue which may create greater potential for forks and vulnerability to adversarial attacks. Motivated by these issues, we develop stochastic network models to capture the Blockchain evolution and dynamics and analyze the impact of the block dissemination delay and hashing power of the member nodes on Blockchain performance in terms of the overall block generation rate and required computational power for launching a successful attack. The results provide useful insight in crucial design issues, e.g., how to adjust the 'difficulty-of-work' in the presence of delay so as to achieve a target block generation rate or appropriate level of immunity from adversarial attacks. We employ a combination of analytical calculations and simulation experiments to investigate both stationary and transient performance features, and demonstrate close agreement with measurements on a wide-area network testbed running the Ethereum protocol. © 2018 IEEE.",,"Blockchain; Electronic money; Internet of things; Stochastic models; Stochastic systems; Analytical calculation; Computational power; Distributed environments; Industrial deployment; Internet of thing (IOT); Smart transportations; Stochastic network models; Transient performance; Wide area networks",,,,,"Bahack, L., (2013) Theoretical Bitcoin Attacks with Less Than Half of the Computational Power, , https://arxiv.org/pdf/1312.7013.pdf; Bamert, T., Decker, C., Elsen, L., Welten, S., Wattenhofer, R., Have A snack, pay with Bitcoin (2013) Proc. 13th IEEE Int. Conf. Peer-to-Peer Comput; Berman, M., Chase, J.S., Landweber, L., Nakao, A., Ott, M., Raychaudhuri, D., Ricci, R., Seskar, I., GENI: A federated testbed for innovative network experiments (2014) Computer Networks, 61, pp. 5-23; https://coinmarketcap.com/, Cap; Christidis, K., Devetsikiotis, M., Blockchains and smart contracts for the Internet-of-Things (2016) IEEE Access, 4, pp. 2292-2303; Decker, C., Wattenhofer, R., Information propagation in the Bitcoin network (2013) Proc. 13th IEEE Int. Conf. Peer-to-Peer Comput; Ethereum Network Status, , https://ethstats.net/, Accessed: 07/27/2017; Eyal, I., Sirer, E.G., Majority is not enough: Bitcoin mining is vulnerable (2013) Financial Cryptography and Data Security, pp. 436-454. , Springer; GENI: Global Environment for Networking Innovation, , http://www.geni.net, Accessed: 07/27/2017; Geth, , https://github.com/ethereum/go-ethereum/, Accessed: 07/27/2017; Göbel, J., Keeler, H.P., Krzesinski, A.E., Taylor, P.G., Bitcoin Blockchain dynamics: The selfish-mine strategy in the presence of propagation delay (2016) Perf. Eval., 104, pp. 23-41; Karame, G.O., Androulaki, E., Capkun, S., Two bitcoins at the price of one Double-spending attacks on fast payments in Bitcoin (2012) Proc. Conf. Comp. Commun. Security; Kraft, D., Difficulty control for Blockchain-based consensus systems (2016) Peer-to-Peer Netw. Appl., 9, pp. 397-413; Linn, L.A., Koo, M.B., Blockchain for health data and its potential use in health IT and health care related Research (2016) Use of Blockchain for Healthcare and Research Workshop; Nakamoto, S., (2008) Bitcoin: A Peer-to-peer Electronic Cash System, , https://bitcoin.org/bitcoin.pdf; Rosenfeld, M., (2014) Analysis of Hashrate-based Double-spending, , https://arxiv.org/pdf/1402.2009.pdf; Sompolinsky, Y., Zohar, A., Accelerating Bitcoin's transaction processing (2013) Fast Money Grows on Trees, Not Chains, , https://eprint.iacr.org/2013/881.pdf; Wood, G., Ethereum: A secure decentralised generalised transaction ledger (2014) Ethereum Project Yellow Paper, p. 151. , http://gavwood.com/paper.pdf",,,"Huawei Technologies","Institute of Electrical and Electronics Engineers Inc.","2018 IEEE Conference on Computer Communications, INFOCOM 2018","15 April 2018 through 19 April 2018",,140725,0743166X,9781538641286,PINFE,,"English","Proc IEEE INFOCOM",Conference Paper,"Final","",Scopus,2-s2.0-85056184044
"Liang Q., Modiano E.","55505746800;7006138684;","Network Utility Maximization in Adversarial Environments",2018,"Proceedings - IEEE INFOCOM","2018-April",,"8485973","594","602",,4,"10.1109/INFOCOM.2018.8485973","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056151585&doi=10.1109%2fINFOCOM.2018.8485973&partnerID=40&md5=e4054fe3158323e4a2eb491add726cb8","Laboratory for Information and Decision Systems, Massachusetts Institute of Technology, Cambridge, MA, United States","Liang, Q., Laboratory for Information and Decision Systems, Massachusetts Institute of Technology, Cambridge, MA, United States; Modiano, E., Laboratory for Information and Decision Systems, Massachusetts Institute of Technology, Cambridge, MA, United States","Stochastic models have been dominant in network optimization theory for over two decades, due to their analytical tractability. However, these models fail to capture non-stationary or even adversarial network dynamics which are of increasing importance for modeling the behavior of networks under malicious attacks or characterizing short-term transient behavior. In this paper, we consider the network utility maximization problem in adversarial network settings. In particular, we focus on the tradeoffs between total queue length and utility regret which measures the difference in network utility between a causal policy and an 'oracle' that knows the future within a finite time horizon. Two adversarial network models are developed to characterize the adversary's behavior. We provide lower bounds on the tradeoff between utility regret and queue length under these adversarial models, and analyze the performance of two control policies (i.e., the Drift-plus-Penalty algorithm and the Tracking Algorithm). © 2018 IEEE.",,"Site selection; Stochastic control systems; Stochastic systems; Adversarial environments; Adversarial networks; Analytical tractability; Finite time horizon; Network utility maximization; Penalty algorithm; Tracking algorithm; Transient behavior; Stochastic models",,,,,"Tassiulas, L., Ephremides, A., Stability properties of constrained queueing systems and scheduling policies for maximum throughput in multihop radio networks (1992) IEEE Transactions on Automatic Control, 37 (12), pp. 1936-1948; Neely, M.J., Modiano, E., Li, C.-P., Fairness and optimal stochastic control for heterogeneous networks (2008) IEEE/ACM Transactions on Networking (TON), 16 (2), pp. 396-409; Zou, Y., Zhu, J., Wang, X., Hanzo, L., A survey on wireless security: Technical challenges, recent advances, and future trends (2016) Proceedings of the IEEE, 104 (9), pp. 1727-1765; Neely, M.J., Stochastic network optimization with application to communication and queueing systems (2010) Synthesis Lectures on Communication Networks, 3 (1), pp. 1-211; Andrews, M., Zhang, L., Scheduling over A time-varying userdependent channel with applications to high speed wireless data (2002) The 43rd Annual IEEE Symposium on Foundations of Computer Science, 2002. Proceedings., pp. 293-302; Andrews, M., Zhang, L., Scheduling over nonstationary wireless channels with finite rate sets (2006) IEEE/ACM Transactions on Networking, 14 (5), pp. 1067-1077. , Oct; Cruz, R.L., A calculus for network delay. I. Network elements in isolation (1991) IEEE Transactions on Information Theory, 37 (1), pp. 114-131; Borodin, A., Kleinberg, J., Raghavan, P., Sudan, M., Williamson, D.P., Adversarial queuing theory (2001) Journal of the ACM (JACM), 48 (1), pp. 13-38; Andrews, M., Awerbuch, B., Fernández, A., Leighton, T., Liu, Z., Kleinberg, J., Universal-stability results and performance bounds for greedy contention-resolution protocols (2001) Journal of the ACM (JACM), 48 (1), pp. 39-69; Cholvi, V., Echagüe, J., Stability of fifo networks under adversarial models: State of the art (2007) Computer Networks, 51 (15), pp. 4460-4474; Andrews, M., Jung, K., Stolyar, A., Stability of the max-weight routing and scheduling protocol in dynamic networks and at critical loads (2007) Proceedings of the Thirty-ninth Annual ACM Symposium on Theory of Computing, Ser. STOC '07. ACM, pp. 145-154; Lim, S., Jung, K., Andrews, M., Stability of the max-weight protocol in adversarial wireless networks (2014) IEEE/ACM Trans. Netw., 22 (6), pp. 1859-1872. , Dec; Neely, M.J., Universal scheduling for networks with arbitrary traffic, channels, and mobility (2010) Decision and Control (CDC), 2010 49th IEEE Conference On. IEEE, pp. 1822-1829; Liang, Q., Modiano, E., (2016) Network Utility Maximization in Adversarial Environments, , https://arxiv.org/abs/1712.08672, Technical Report",,,"Huawei Technologies","Institute of Electrical and Electronics Engineers Inc.","2018 IEEE Conference on Computer Communications, INFOCOM 2018","15 April 2018 through 19 April 2018",,140725,0743166X,9781538641286,PINFE,,"English","Proc IEEE INFOCOM",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85056151585
"Rajaratnam K., Shah K., Kalita J.","57208001667;57216988841;57203217689;","Isolated and ensemble audio preprocessing methods for detecting adversarial examples against automatic speech recognition",2018,"Proceedings of the 30th Conference on Computational Linguistics and Speech Processing, ROCLING 2018",,,,"16","30",,6,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063434739&partnerID=40&md5=729d240c2d9b16df40dc00e1d04e0375","College University of Chicago, Chicago, IL, United States; College of Liberal Arts and Sciences, University of Florida, Gainesville, FL, United States; Department of Computer Science, University of Colorado, Springs, CO, United States","Rajaratnam, K., College University of Chicago, Chicago, IL, United States; Shah, K., College of Liberal Arts and Sciences, University of Florida, Gainesville, FL, United States; Kalita, J., Department of Computer Science, University of Colorado, Springs, CO, United States","An adversarial attack is an exploitative process in which minute alterations are made to natural inputs, causing the inputs to be misclassified by neural models. In the field of speech recognition, this has become an issue of increasing significance. Although adversarial attacks were originally introduced in computer vision, they have since infiltrated the realm of speech recognition. In 2017, a genetic attack was shown to be quite potent against the Speech Commands Model. Limited-vocabulary speech classifiers, such as the Speech Commands Model, are used in a variety of applications, particularly in telephony; as such, adversarial examples produced by this attack pose as a major security threat. This paper explores various methods of detecting these adversarial examples with combinations of audio preprocessing. One particular combined defense incorporating compressions, speech coding, filtering, and audio panning was shown to be quite effective against the attack on the Speech Commands Model, detecting audio adversarial examples with 93.5% precision and 91.2% recall. © 2018 The Association for Computational Linguistics and Chinese Language Processing.","Adversarial attack; Audio compression; Deep learning; Speech coding; Speech recognition","Computational linguistics; Speech processing; Automatic speech recognition; Neural models; Pre-processing method; Security threats; Speech commands; Speech recognition",,,,,"Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations; Alzantot, M., Balaji, B., Srivastava, M., Did you hear that? Adversarial examples against automatic speech recognition (2017) 31st Conference on Neural Information Processing Systems (NIPS); Carlini, N., Wagner, D., Audio adversarial examples: Targeted attacks on speech-to-text (2018) 1st IEEE Workshop on Deep Learning and Security; Aydemir, A.E., Temizel, A., Temizel, T.T., (2018) The Effects of JPEG and JPEG2000 Compression on Attacks Using Adversarial Examples, , arXiv preprint, no. 1803.10418; Graese, A., Rozsa, A., Boult, T.E., Assessing threat of adversarial examples on deep neural networks (2016) 15th IEEE International Conference on Machine Learning and Applications (ICMLA); Prakash, A., Moran, N., Garber, S., DiLillo, A., Storer, J., Deflecting adversarial attacks with pixel deflection (2018) IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR); Yang, Z., Li, B., Chen, P.-Y., Song, D., (2018) Towards Mitigating Audio Adversarial Perturbations, , https://openreview.net/forum?id=SyZ2nKJDz, [Online]; Lemmond, D., Fitzgibbons, R., (2018) Adversarial Examples in Audio, , CS4860 Final Project Report, University of Colorado, Colorado Springs Spring 2018; Valin, J.-M., Speex: A free codec for free speech (2006) Proceedings of Linux.conf.au, , https://arxiv.org/abs/1602.08668, [Online]; Valin, J.-M., Vos, K., Terriberry, T.B., (2012) Definition of the Opus Audio Codec, , RFC 6716; Schroeder, M.R., Atal, B.S., Code-excited linear prediction (CELP): High-quality speech at very low bit rates (1985) IEEE International Conference on Acoustics, Speech and Signal Processing, pp. 937-940; Xu, W., Evans, D., Qi, Y., Feature squeezing: Detecting adversarial examples in deep neural networks (2018) 2018 Network and Distributed System Security Symposium (NDSS'18), , Feb; Warden, P., (2018) Speech Commands: A Dataset for Limited-vocabulary Speech Recognition, , arXiv preprint, no. 1804.03209; Sainath, T.N., Parada, C., Convolutional neural networks for small-footprint keyword spotting (2015) Interspeech; Warren, R.L., Ramamoorthy, S., Ciganović, N., Zhang, Y., Wilson, T.M., Petrie, T., Wang, R.K., Fridberger, A., Minimal basilar membrane motion in low-frequency hearing (2016) Proceedings of the National Academy of Sciences, 113 (30). , Jul; He, W., Wei, J., Chen, X., Carlini, N., Song, D., Adversarial example defense: Ensembles of weak defenses are not strong (2017) 11th USENIX Workshop on Offensive Technologies, WOOT 2017",,"Lee C.-C.Yang C.-Z.Chien J.-T.Chiang C.-Y.Day M.-Y.Tsai R.T.-H.Lee H.-Y.Lu W.-H.Wu S.H.","Association for Computational Linguistics and Chinese Language Processing;Cyberon Corporation;et al.;Institute of Information Science, Academia Sinica;Most AI Biomedical Research Center;Research Center for Information Technology Innovation, Academia Sinica","The Association for Computational Linguistics and Chinese Language Processing (ACLCLP)","30th Conference on Computational Linguistics and Speech Processing, ROCLING 2018","4 October 2018 through 5 October 2018",,159806,,9789869576918,,,"English","Proc. Conf. Comput. Linguist. Speech Process., ROCLING",Conference Paper,"Final","",Scopus,2-s2.0-85063434739
"Yi P., Wang K., Huang C., Gu S., Zou F., Li J.","7005532157;57205321419;57207814423;57205324412;8865609200;56103299700;","Adversarial Attacks in Artificial Intelligence: A Survey [人工智能对抗攻击研究综述]",2018,"Shanghai Jiaotong Daxue Xuebao/Journal of Shanghai Jiaotong University","52","10",,"1298","1306",,4,"10.16183/j.cnki.jsjtu.2018.10.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059514258&doi=10.16183%2fj.cnki.jsjtu.2018.10.019&partnerID=40&md5=f68e6b560f199326e9d8d072fc011948","Shanghai Key Laboratory of Integrated Administration Technologies for Information Security, School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, 200240, China","Yi, P., Shanghai Key Laboratory of Integrated Administration Technologies for Information Security, School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, 200240, China; Wang, K., Shanghai Key Laboratory of Integrated Administration Technologies for Information Security, School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, 200240, China; Huang, C., Shanghai Key Laboratory of Integrated Administration Technologies for Information Security, School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, 200240, China; Gu, S., Shanghai Key Laboratory of Integrated Administration Technologies for Information Security, School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, 200240, China; Zou, F., Shanghai Key Laboratory of Integrated Administration Technologies for Information Security, School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, 200240, China; Li, J., Shanghai Key Laboratory of Integrated Administration Technologies for Information Security, School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, 200240, China","With the widespread use of artificial intelligence, artificial intelligence security has drawn public attention. The research on adversarial attacks in artificial intelligence has become a hotspot of artificial intelligence security. This paper first introduces the concept of adversarial attacks and the causes of adversarial attacks. The main reason is that the inconsistency between the model boundary and the real boundary leads to the existence of adversarial space. This paper review the works that design adversarial attacks, detect methods and defense methods agaisnt the attacks. The adversarial attacks including FGSM and JSMA attacks, the main idea of the attacks is to find the fast gradient direction of the model, adding perturbation according the direction and causing model misjudgment. Finally, some future research directions are proposed. © 2018, Shanghai Jiao Tong University Press. All right reserved.","Adversarial attack; Adversarial learning; Artificial intelligence; Artificial intelligence security; Deep learning","Deep learning; Adversarial attack; Adversarial learning; Boundary leads; Future research directions; Gradient direction; Hot spot; Artificial intelligence",,,,,"Lecun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), pp. 436-444; Goodfellow, I., Yoshua, B., Aaron, C., (2016) Deep Learning, , Boston: MIT Press; Wang, X., Yang, W., Jeffrey, W., Searching for prostate cancer by fully automated magnetic resonance imaging classification: Deep learning versus non-deep learning (2017) Scientific Reports, 7 (1), p. 15415; Xiong, H.Y., Alipanahi, B., The human splicing code reveals new insights into the genetic determinants of disease (2015) Science, 347 (6218), pp. 144-153; Webb, S., Deep learning for biology (2018) Nature, 554 (2), pp. 555-557; Branson, K., A deep (learning) dive into a cell (2018) Nature Methods, 15 (4), pp. 253-254; Deng, Y., Bao, F., Kong, Y., Deep direct reinforcement learning for financial signal representation and trading (2017) IEEE Transactions on Neural Networks and Learning Systems, 28 (3), pp. 653-664; He, Y., Zhao, N., Yin, H., Integrated networking, caching, and computing for connected vehicles: A deep reinforcement learning approach (2018) IEEE Transactions on Vehicular Technology, 67 (1), pp. 44-55; Zhao, D., Chen, Y., Lv, L., Deep reinforcement learning with visual attention for vehicle classification (2017) IEEE Transactions on Cognitive and Developmental Systems, 9 (4), pp. 356-367; Akhtar, N., Mian, A., Threat of adversarial attacks on deep learning in computer vision: a survey (2018) IEEE Access, 6 (2), pp. 14410-14430; Goodfellow, I., Shlens, J., Christian, S., Explaining and harnessing adversarial examples https://arxiv.org/abs/1412.6572, (2015-03-20)[2018-06-23]; Guo, C., Rana, M., Cisse, M., Countering adversarial images using input transformations https://arxiv.org/abs/1711.00117, (2018-01-25)[2018-06-23]; Sinha, A., Namkoong, H., Duchi, J., Certifying some distributional robustness with principled adversarial training https://arxiv.org/abs/1710.10571, (2018-05-01)[2018-06-23]; Song, Y., Kim, T., Nowozin, S., Pixel defend: Leveraging generative models to understand and defend against adversarial examples https://arxiv.org/abs/1710.10766, (2018-05-01)[2018-06-23]; Xie, C., Wang, J., Zhang, Z., Mitigating adversarial effects through randomization https://arxiv.org/abs/1711.01991, (2018-02-28)[2018-06-23]; Mcdaniel, P., Papernot, N., Celik, Z.B., Machine learning in adversarial settings (2016) IEEE Security & Privacy, 14 (3), pp. 68-72; Papernot, N., Mcdaniel, P., Jha, S., The limitations of deep learning in adversarial settings (2016) IEEE European Symposium on Security and Privacy (EuroS& P), pp. 372-387. , Saarbrucken, Germany: IEEE; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world https://arxiv.org/abs/1805.10997, (2018-05-28) [2018-06-23]; Tramer, F., Goodfellow, I., Boneh, D., Ensemble adversarial training: attacks and defenses https://arxiv.org/abs/1705.07204, (2017-05-19)[2018-06-23]; Moosavidezfooli, S., Fawzi, A., Frossard, P., DeepFool: A simple and accurate method to fool deep neural networks https://arxiv.org/abs/1511.04599, (2015-11-14)[2018-06-23]; Brendel, W., Rauber, J., Bethge, M., Decision-based adversarial attacks: Reliable attacks against blackbox machine learning models https://arxiv.org/abs/1712.04248, (2017-12-12)[2018-06-23]; Cisse, M., Adi, Y., Neverova, N., Houdini: Fooling deep structured prediction models https://arxiv.org/abs/1707.05373, (2017-07-17) [2018-06-23]; He, W., Li, B., Song, D., Decision boundary analysis of adversarial examples https://openreview.net/forum?id=BkpiPMbA-, (2018-02-16)[2018-06-23]; Zhao, Z., Dua, D., Singh, S., Generating natural adversarial examples https://arxiv.org/abs/1710.11342, (2017-10-31)[2018-06-23]; Xiao, C., Zhu, J., Li, B., Spatially transformed adversarial examples https://arxiv.org/abs/1801.02612, (2018-01-08) [2018-06-23]; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks https://arxiv.org/abs/1608.04644, (2016-08-16) [2018-06-23]; Papernot, N., Mcdaniel, P., Goodfellow, I., Practical black-box attacks against machine learning https://arxiv.org/abs/1602.02697, (2016-02-08)[2018-06-23]; Papernot, N., Goodfellow, I., Sheatsley, R., Cleverhans v1.0.0: An adversarial machine learning library https://arxiv.org/abs/1610.00768, (2016-10-03)[2018-06-23]; Tanay, T., Griffin, L., A boundary tilting persepective on the phenomenon of adversarial examples https://arxiv.org/abs/1608.07690, (2016-08-27)[2018-06-23]; Fawzi, A., Fawzi, O., Frossard, P., Fundamental limits on adversarial robustness http://www.alhusseinfawzi.info/papers/workshop_dl.pdf, (2015-04-27)[2018-06-23]; Tabacof, P., Valle, E., Exploring the space of adversarial images (2016) IEEE International Joint Conference on Neural Networks (IJCNN), pp. 2161-4407. , Vancouver, BC, Canada: IEEE; Lecun, Y., Boser, B., Denker, J.S., Backpropagation applied to handwritten zip code recognition (1989) Neural Computation, 1 (4), pp. 541-551; Deng, J., Dong, W., Socher, R., Imagenet: A large-scale hierarchical image database (2009) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 248-255. , Miami, USA: IEEE; Tramer, F., Papernot, N., Goodfellow, I., The space of transferable adversarial examples https://arxiv.org/abs/1704.03453, (2017-04-11)[2018-06-23]; Krotov, D., Hopfield, J.J., Dense associative memory is robust to adversarial inputs https://arxiv.org/abs/1701.00939, (2016-08-27)[2018-06-23]; Moosavi-Dezfooli, S.M., Fawzi, A., Fawzi, O., Universal adversarial perturbations https://arxiv.org/abs/1610.08401, (2016-10-26)[2018-06-23]; Dziugaite, G.K., Ghahramani, Z., Roy, D.M., A study of the effect of JPG compression on adversarial images https://arxiv.org/abs/1608.00853, (2016-08-02)[2018-06-23]; Das, N., Shanbhogue, M., Chen, S., Keeping the bad guys out: protecting and vaccinating deep learning with JPEG compression https://arxiv.org/abs/1705.02900, (2017-05-08)[2018-06-23]; Shin, R., Song, D., JPEG-resistant adversarial images https://machine-learning-and-security.github.io/papers/mlsec17_paper_54.pdf, (2017-08-14)[2018-06-23]; Akhtar, N., Liu, J., Mian, A., Defense against universal adversarial perturbations https://arxiv.org/abs/1711.05929, (2017-11-16)[2018-06-23]; Xie, C., Wang, J., Zhang, Z., Adversarial examples for semantic segmentation and object detection https://arxiv.org/abs/1703.08603, (2017-05-24)[2018-06-23]; Wang, Q., Guo, W., Zhang, K., Learning adversary-resistant deep neural networks https://arxiv.org/abs/1612.01401, (2016-12-05)[2018-06-23]; Gu, S., Rigazio, L., Towards deep neural network architectures robust to adversarial examples https://arxiv.org/abs/1412.5068, (2014-12-11)[2018-06-23]; Rifai, S., Vincent, P., Muller, X., Contractive auto-encoders: Explicit invariance during feature extraction (2011) ICML'11 Proceedings of the 28th International Conference on International Conference on Machine Learning, pp. 833-840. , Washington, USA: Omnipress; Ross, A., Doshivelez, F., Improving the adversarial robustness and interpretability of deep neural networks by regularizing their input gradients https://arxiv.org/abs/1711.09404, (2017-11-26)[2018-06-23]; Papernot, N., Mcdaniel, P., Wu, X.I., Distillation as a defense to adversarial perturbations against deep neural networks (2016) IEEE Symposium on Security and Privacy (SP), , San Jose, CA, USA: IEEE 2375-1207; Gao, J., Wang, B., Liu, Z., Masking deep neural network models for robustness against adversarial samples https://arxiv.org/abs/1702.06763, (2017-02-22)[2018-06-23]; Lee, H., Han, S., Lee, J., Generative adversarial trainer: defense to adversarial perturbations with GAN https://arxiv.org/abs/1705.03387, (2017-05-09)[2018-06-23]; Madry, A., Makelov, A., Schmidt, L., Towards deep learning models resistant to adversarial attacks https://arxiv.org/abs/1706.06083, (2017-06-19)[2018-06-23]; Ma, X., Li, B., Wang, Y., Characterizing adversarial subspaces using local intrinsic dimensionality https://arxiv.org/abs/1801.02613, (2018-01-08)[2018-06-23]; Sam, P., Kabkab, M., Chellappa, R., Defense-GAN: Protecting classifiers against adversarial attacks using generative models https://arxiv.org/abs/1805.06605, (2018-05-17)[2018-06-23]; Raghunathan, A., Steinhardt, J., Liang, P., Certified defenses against adversarial examples https://arxiv.org/abs/1801.09344, (2018-01-29)[2018-06-23]; Buckman, J., Roy, A., Goodfellow, I., Thermometer encoding: One hot way to resist adversarial examples https://openreview.net/forum?id=S18Su-CW, (2018-02-16)[2018-06-23]; Weng, X., Zahng, H., Chen, P., Evaluating the robustness of neural networks: An extreme value theory approach https://arxiv.org/abs/1801.10578, (2018-01-31)[2018-06-23]; Elsayed, G.F., Papernot, N., Goodfellow, I., Adversarial examples that fool both human and computer Vision https://arxiv.org/abs/1802.08195, (2018-02-22)[2018-06-23]","Li, J.; Shanghai Key Laboratory of Integrated Administration Technologies for Information Security, China; email: lijh888@sjtu.edu.cn",,,"Shanghai Jiao Tong University",,,,,10062467,,SCTPD,,"Chinese","Shanghai Jiaotong Daxue Xuebao",Review,"Final","",Scopus,2-s2.0-85059514258
"Deka D., Vishwanath S., Baldick R.","54895078300;35584593600;56350289900;","Topological vulnerability of power grids to disasters: Bounds, adversarial attacks and reinforcement",2018,"PLoS ONE","13","10","e0204815","","",,,"10.1371/journal.pone.0204815","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054898382&doi=10.1371%2fjournal.pone.0204815&partnerID=40&md5=13d1fad23bb7a5c31eb3ef17361a6777","Center for Non-Linear Studies, Los Alamos National Laboratory, Los Alamos, United States; Department of Electrical and Computer Engineering, University of Texas at Austin, Austin, United States","Deka, D., Center for Non-Linear Studies, Los Alamos National Laboratory, Los Alamos, United States; Vishwanath, S., Department of Electrical and Computer Engineering, University of Texas at Austin, Austin, United States; Baldick, R., Department of Electrical and Computer Engineering, University of Texas at Austin, Austin, United States","Natural disasters like hurricanes, floods or earthquakes can damage power grid devices and create cascading blackouts and islands. The nature of failure propagation and extent of damage, among other factors, is dependent on the structural features of the grid, that are distinct from that of random networks. This paper analyzes the structural vulnerability of real power grids to impending disasters and presents intuitive graphical metrics to quantify the extent of topological damage. We develop two improved graph eigen-value based bounds on the grid vulnerability. Further we study adversarial attacks aimed at weakening the grid's structural robustness and present three combinatorial algorithms to determine the optimal topological attack. Simulations on power grid networks and comparison with existing work show the improvements of the proposed measures and attack schemes. © 2018 Deka et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"article; disaster; quantitative analysis; reinforcement; simulation; algorithm; comparative study; computer simulation; electric power plant; natural disaster; theoretical model; Algorithms; Computer Simulation; Models, Theoretical; Natural Disasters; Power Plants",,,,,"Deka, D., Vishwanath, S., Baldick, R., Analytical models for power networks: The case of the Western US and ERCOT grids (2016) IEEE Transactions on Smart Grid, , Mar 22; Lavaei, J., Low, S.H., Zero duality gap in optimal power flow problem (2012) IEEE Transactions on Power Systems, 27 (1), pp. 92-107. , https://doi.org/10.1109/TPWRS.2011.2160974, Feb; Deka, D., Nagarajan, H., Backhaus, S., Optimal topology design for disturbance minimization in power grids (2017) InIEEE American Control Conference, , 2017 May; Kwasinski, A., Weaver, W.W., Chapman, P.L., Krein, P.T., Telecommunications power plant damage assessment for hurricane katrina-site survey and follow-up results (2009) IEEE Systems Journal, 3 (3), pp. 277-287. , https://doi.org/10.1109/JSYST.2009.2026783, Sep; Kantha, L., Time to replace the Saffir-Simpson hurricane scale? (2006) Eos, Transactions American Geophysical Union, 87 (1), pp. 3-6. , https://doi.org/10.1029/2006EO010003, Jan 3; Dobson, I., Carreras, B.A., Lynch, V.E., Newman, D.E., An initial model for complex dynamics in electric power system blackouts (2001) Proceedings of The Annual Hawaii International Conference on System Sciences, 3, p. 51. , Jan; Dobson, I., Carreras, B.A., Lynch, V.E., Newman, D.E., Complex systems analysis of series of blackouts: Cascading failure, critical points, and self-organization (2007) Chaos: An Interdisciplinary Journal of Nonlinear Science, 17 (2), p. 026103. , https://doi.org/10.1063/1.2737822, Jun; Bienstock, D., Verma, A., The nk problem in power grids: New models, formulations, and numerical experiments (2010) SIAM Journal on Optimization, 20 (5), pp. 2352-2380. , https://doi.org/10.1137/08073562X, Jun 3; Bernstein, A., Bienstock, D., Hay, D., Uzunoglu, M., Zussman, G., Power grid vulnerability to geographically correlated failures-analysis and control implications (2014) InINFOCOM, 2014 Proceedings IEEE, pp. 2634-2642. , Apr 27 . IEEE; Wang, Y., Baldick, R., Interdiction analysis of electric grids combining cascading outage and medium-term impacts (2014) IEEE Transactions on Power Systems, 29 (5), pp. 2160-2168. , https://doi.org/10.1109/TPWRS.2014.2300695, Sep; Prabha, K., Balu Neal, J., Lauby Mark, G., (1994) Power System Stability and Control, 7. , New York: McGraw-hill; Motter Adilson, E., Myers, S.A., Anghel, M., Nishikawa, T., Spontaneous synchrony in power-grid networks (2013) Nature Physics, 9 (3), pp. 191-197; Albert, R., Jeong, H., Barabási, A.L., Error and attack tolerance of complex networks (2000) Nature, 406 (6794), pp. 378-382. , https://doi.org/10.1038/35019019, Jul 27; PMID: 10935628; Motter, A.E., Lai, Y.C., Cascade-based attacks on complex networks (2002) Physical Review E, 66 (6), p. 065102. , https://doi.org/10.1103/PhysRevE.66.065102, Dec 20; Wang, J.W., Rong, L.L., Cascade-based attack vulnerability on the US power grid (2009) Safety Science, 47 (10), pp. 1332-1336. , https://doi.org/10.1016/j.ssci.2009.02.002, Dec 31; Wang, J.W., Rong, L.L., Robustness of the western United States power grid under edge attack strategies due to cascading failures (2011) Safety Science, 49 (6), pp. 807-812. , https://doi.org/10.1016/j.ssci.2010.10.003, Jul 31; Buldyrev, S.V., Parshani, R., Paul, G., Stanley, H.E., Havlin, S., Catastrophic cascade of failures in interdependent networks (2010) Nature, 464 (7291), pp. 1025-1028. , https://doi.org/10.1038/nature08932, Apr 15; PMID: 20393559; Parshani, R., Buldyrev, S.V., Havlin, S., Interdependent networks: Reducing the coupling strength leads to a change from a first to second order percolation transition (2010) Physical Review Letters; Yagan, O., Qian, D., Zhang, J., Cochran, D., Optimal allocation of interconnecting links in cyber-physical systems: Interdependence, cascading failures, and robustness (2012) IEEE Transactions on Parallel and Distributed Systems, 23 (9), pp. 1708-1720. , https://doi.org/10.1109/TPDS.2012.62, Sep; Sun, S., Wu, Y., Ma, Y., Wang, L., Gao, Z., Xia, C., Impact of degree heterogeneity on attack vulnerability of interdependent networks (2016) Scientific Reports, 6; Kong, Z., Yeh, E.M., Resilience to degree-dependent and cascading node failures in random geometric networks (2010) IEEE Transactions on Information Theory, 56 (11), pp. 5533-5546. , https://doi.org/10.1109/TIT.2010.2068910, Nov; Xiao, H., Yeh, E.M., Cascading link failure in the power grid: A percolation-based analysis InCommunica-Tions Workshops (ICC), 2011 IEEE International Conference on 2011, pp. 1-6. , Jun 5 . IEEE; Qi, J., Sun, K., Mei, S., An interaction model for simulation and mitigation of cascading failures (2015) IEEE Transactions on Power Systems, 30 (2), pp. 804-819. , https://doi.org/10.1109/TPWRS.2014.2337284, Mar; Wang, J., Robustness of complex networks with the local protection strategy against cascading failures (2013) Safety Science, 53, pp. 219-225. , https://doi.org/10.1016/j.ssci.2012.09.011, Mar 31; Hines, P., Cotilla-Sanchez, E., Blumsack, S., Do topological models provide good information about electricity infrastructure vulnerability? (2010) Chaos: An Interdisciplinary Journal of Nonlinear Science, 20 (3), p. 033122. , https://doi.org/10.1063/1.3489887, Sep; Wang, Y., Chen, C., Wang, J., Baldick, R., Research on resilience of power systems under natural disasters -A review (2016) IEEE Transactions on Power Systems, 31 (2), pp. 1604-1613. , https://doi.org/10.1109/TPWRS.2015.2429656, Mar; Miller, J.C., Hyman, J.M., Effective vaccination strategies for realistic social networks (2007) Physica A: Statistical Mechanics and Its Applications, 386 (2), pp. 780-785. , https://doi.org/10.1016/j.physa.2007.08.054, Dec 15; Boguná, M., Pastor-Satorras, R., Vespignani, A., Epidemic spreading in complex networks with degree correlations (2003) InProceedings of The XVIII Sitges Conference on Statistical Mechanics, Lecture Notes in Physics, , Springer, Berlin Jan 10; Sun, S., Li, R., Wang, L., Xia, C., Reduced synchronizability of dynamical scale-free networks with onion-like topologies (2015) Applied Mathematics and Computation, 252, pp. 249-256. , https://doi.org/10.1016/j.amc.2014.12.044, Feb 1; Parshani, R., Buldyrev, S.V., Havlin, S., Interdependent networks: Reducing the coupling strength leads to a change from a first to second order percolation transition (2010) Physical Review Letters, 105 (4), p. 048701. , https://doi.org/10.1103/PhysRevLett.105.048701, Jul 21; PMID: 20867893; Cotilla-Sanchez, E., Hines, P.D., Barrows, C., Blumsack, S., Comparing the topological and electrical structure of the North American electric power infrastructure (2012) IEEE Systems Journal, 6 (4), pp. 616-626. , https://doi.org/10.1109/JSYST.2012.2183033, Dec; Wang, Z., Scaglione, A., Thomas, R.J., Generating statistically correct random topologies for testing smart grid communication and control networks (2010) IEEE Transactions on Smart Grid, 1 (1), pp. 28-39. , https://doi.org/10.1109/TSG.2010.2044814, Jun; Deka, D., Vishwanath, S., Generative growth model for power grids InSignal-Image Technology & Internet-Based Systems (SITIS), 2013 International Conference on 2013, pp. 591-598. , Dec 2 . IEEE; Sun, S., Ma, Y., Wu, Y., Wang, L., Xia, C., Towards structural controllability of local-world networks (2016) Physics Letters A, 380 (22), pp. 1912-1917. , https://doi.org/10.1016/j.physleta.2016.03.048, May 20; Athay, T., Podmore, R., Virmani, S., A practical method for the direct analysis of transient stability (1979) IEEE Transactions on Power Apparatus and Systems, (2), pp. 573-584. , https://doi.org/10.1109/TPAS.1979.319407, Mar; Krishnamurthy, V., Kwasinski, A., Empirically validated availability model of information and communication technologies facilities under hurricane conditions (2014) InTelecommunications Energy Conference (INTELEC), 2014 IEEE 36th International, pp. 1-8. , Sep 28 . IEEE; Dvorkin, Y., Lubin, M., Backhaus, S., Chertkov, M., Uncertainty sets for wind power generation (2016) IEEE Transactions on Power Systems, 31 (4), pp. 3326-3327. , https://doi.org/10.1109/TPWRS.2015.2476664, Jul; Lee, D., Baldick, R., Short-term wind power ensemble prediction based on Gaussian processes and neural networks (2014) IEEE Transactions on Smart Grid, 5 (1), pp. 501-510. , https://doi.org/10.1109/TSG.2013.2280649, Jan; Schneider, C.M., Moreira, A.A., Andrade, J.S., Havlin, S., Herrmann, H.J., Mitigation of malicious attacks on networks (2011) Proceedings of The National Academy of Sciences, 108 (10), pp. 3838-3841. , https://doi.org/10.1073/pnas.1009440108, Mar 8; Grimmett, G., Stirzaker, D., (2001) Probability and Random Processes, , Oxford university press; May 31; Zhou, Q., Bialek, J.W., Approximate model of European interconnected system as a benchmark system to study effects of cross-border trades (2005) IEEE Transactions on Power Systems, 20 (2), pp. 782-788. , https://doi.org/10.1109/TPWRS.2005.846178, May; Approximate Model of European Interconnected System, , http://www.see.ed.ac.uk/jbialek/Europe%20load%20flow/; Durrett, R., (2006) Random Graph Dynamics, , Cambridge University Press; Stewart, G.W., Matrix Perturbation Theory; Golub, G.H., Van Loan, C.F., (2012) Matrix Computations, , JHU Press; Dec 27; Nemhauser, G.L., Wolsey, L.A., Fisher, M.L., An analysis of approximations for maximizing submodular set functions-I (1978) Mathematical Programming, 14 (1), pp. 265-294. , https://doi.org/10.1007/BF01588971, Dec 1","Deka, D.; Center for Non-Linear Studies, United States; email: deepjyoti@lanl.gov",,,"Public Library of Science",,,,,19326203,,POLNC,"30312307","English","PLoS ONE",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85054898382
"Kwon H., Kim Y., Park K.-W., Yoon H., Choi D.","57197769092;55699558400;22734573000;15061371300;8660876600;","Advanced ensemble adversarial example on unknown deep neural network classifiers",2018,"IEICE Transactions on Information and Systems","E101D","10",,"2485","2500",,6,"10.1587/transinf.2018EDP7073","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054704913&doi=10.1587%2ftransinf.2018EDP7073&partnerID=40&md5=e8db13fb0434755a830cb0ad5e21b6a9","School of Computing, Korea Advanced Institute of Science and Technology, South Korea; Department of Electrical Engineering, Korea Military Academy, South Korea; Department of Computer and Information Security, Sejong University, South Korea; Department of Medical Information, Kongju National University, South Korea","Kwon, H., School of Computing, Korea Advanced Institute of Science and Technology, South Korea; Kim, Y., Department of Electrical Engineering, Korea Military Academy, South Korea; Park, K.-W., Department of Computer and Information Security, Sejong University, South Korea; Yoon, H., School of Computing, Korea Advanced Institute of Science and Technology, South Korea; Choi, D., Department of Medical Information, Kongju National University, South Korea","Deep neural networks (DNNs) are widely used in many applications such as image, voice, and pattern recognition. However, it has recently been shown that a DNN can be vulnerable to a small distortion in images that humans cannot distinguish. This type of attack is known as an adversarial example and is a significant threat to deep learning systems. The unknown-target-oriented generalized adversarial example that can deceive most DNN classifiers is even more threatening. We propose a generalized adversarial example attack method that can effectively attack unknown classifiers by using a hierarchical ensemble method. Our proposed scheme creates advanced ensemble adversarial examples to achieve reasonable attack success rates for unknown classifiers. Our experiment results show that the proposed method can achieve attack success rates for an unknown classifier of up to 9.25% and 18.94% higher on MNIST data and 4.1% and 13% higher on CIFAR10 data compared with the previous ensemble method and the conventional baseline method, respectively. © 2018 The Institute of Electronics, Information and Communication Engineers.","Adversarial example; Ensemble adversarial example; Machine learning; Neural networks","Learning systems; Neural networks; Pattern recognition; Adversarial example; Attack methods; Baseline methods; Ensemble adversarial example; Ensemble methods; Hierarchical ensemble; Neural network classifier; Target oriented; Deep neural networks",,,,,"Schmidhuber, J., Deep learning in neural networks: An overview (2015) Neural Networks, 61, pp. 85-117; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) International Conference on Learning Representations; Hinton, G., Deng, L., Yu, D., Dahl, G.E., Mohamed, A., Jaitly, N., Senior, A., Kingsbury, B., Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups (2012) IEEE Signal Process. Mag., 29 (6), pp. 82-97; Arel, I., Rose, D.C., Coop, R., Destin: A scalable deep learning architecture with application to high-dimensional robust pattern recognition (2009) AAAI Fall Symposium: Biologically Inspired Cognitive Architectures; Oliveira, G.L., Valada, A., Bollen, C., Burgard, W., Brox, T., Deep learning for human part discovery in images (2016) 2016 IEEE International Conference on Robotics and Automation (ICRA), pp. 1634-1641. , IEEE; Collobert, R., Weston, J., A unified architecture for natural language processing: Deep neural networks with multitask learning (2008) Proc. 25th International Conference on Machine Learning, pp. 160-167. , ACM; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations; Zhang, F., Chan, P.P.K., Biggio, B., Yeung, D.S., Roli, F., Adversarial feature selection against evasion attacks (2016) IEEE Trans. Cybern., 46 (3), pp. 766-777; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP), pp. 39-57. , IEEE; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proc. IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) 2016 IEEE Symposium on Security and Privacy (SP), pp. 582-597. , IEEE; Meng, D., Chen, H., Magnet: A two-pronged defense against adversarial examples (2017) Proc. 2017 ACMSIGSAC Conference on Computer and Communications Security, pp. 135-147. , ACM; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proc. 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519. , ACM; LeCun, Y., Cortes, C., Burges, C.J.C., (2010) Mnist Handwritten Digit Database, AT&T Labs, , http://yann.lecun.com/exdb/mnist,2; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations; Liu, Y., Chen, X., Liu, C., Song, D., (2017) Delving into Transferable Ad Versarial Examples and Black-box Attacks, , ICLR, abs/1611.02770; Krizhevsky, A., Nair, V., Hinton, G., (2014) The cifar-10 Dataset, , http://www.cs.toronto.edu/kriz/cifar.html; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2017) ICLR Workshop; Dezfooli, S.M.M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) Proc. 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Number EPFLCONF-226156; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., Imagenet: A large-scale hierarchical image database (2009) IEEE Conference on Computer Vision and Pattern Recognition, 2009, CVPR 2009, pp. 248-255. , IEEE; Baluja, S., Fischer, I., (2017) Adversarial Transformation Networks: Learning to Generate Adversarial Examples, , arXiv preprint arXiv:1703.09387; Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Isard, M., Tensorflow: A system for large-scale machine learning (2016) OSDI, 16, pp. 265-283; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) ICLR 2015; Kingma, D., Ba, J., Adam: A method for stochastic optimization (2015) The International Conference on Learning Representations (ICLR); Sopyta, K., https://github.com/ksopyla, Github; Mishkin, D., Matas, J., (2015) All You Need Is a Good Init, , arXiv preprint arXiv:1511.06422; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, pp. 2672-2680; Carlini, N., Mishra, P., Vaidya, T., Zhang, Y., Sherr, M., Shields, C., Wagner, D., Zhou, W., Hidden voice commands (2016) USENIX Security Symposium, pp. 513-530; Zhang, G., Yan, C., Ji, X., Zhang, T., Zhang, T., Xu, W., Dolphinattack: Inaudible voice commands (2017) Proc. 2017 ACM SIGSAC Conference on Computer and Communications Security, pp. 103-117. , ACM; Kereliuk, C., Sturm, B.L., Larsen, J., Deep learning and music adversaries (2015) IEEE Trans. Multimedia, 17 (11), pp. 2059-2071; Rozsa, A., Günther, M., Rudd, E.M., Boult, T.E., Facial attributes: Accuracy and adversarial robustness (2017) Pattern Recognition Letters; Osadchy, M., Hernandez-Castro, J., Gibson, S., Dunkelman, O., Pérez-Cabo, D., No bot expects the deepcaptcha! introducing immutable adversarial examples, with applications to captcha generation (2017) IEEE Trans. Inf. Forensics Security, 12 (11), pp. 2640-2653; Kwon, H., Kim, Y., Yoon, H., Choi, D., Captcha image generation systems using generative adversarial networks (2018) IEICE Trans. Inf. & Syst., E101-D (2), pp. 543-546","Park, K.-W.; Department of Computer and Information Security, South Korea; email: woongbak@sejong.ac.kr",,,"Institute of Electronics, Information and Communication, Engineers, IEICE",,,,,09168532,,ITISE,,"English","IEICE Trans Inf Syst",Article,"Final","All Open Access, Bronze",Scopus,2-s2.0-85054704913
"Xie C.-H., Yang G.-H.","56784918600;7405751358;","Observer-based attack-resilient control for linear systems against FDI attacks on communication links from controller to actuators",2018,"International Journal of Robust and Nonlinear Control","28","15",,"4382","4403",,17,"10.1002/rnc.4236","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053349940&doi=10.1002%2frnc.4236&partnerID=40&md5=972e9f32999a65676e5579edb09eab02","College of Information Science and Engineering, Northeastern University, Shenyang, China; State Key Laboratory of Synthetical Automation for Process Industries, Northeastern University, Shenyang, China","Xie, C.-H., College of Information Science and Engineering, Northeastern University, Shenyang, China; Yang, G.-H., College of Information Science and Engineering, Northeastern University, Shenyang, China, State Key Laboratory of Synthetical Automation for Process Industries, Northeastern University, Shenyang, China","For the adversarial attacks on the communication links from the controller to the actuators, most of the existing attack-resilient control results focus on denial-of-service attacks. Unlike the existing results, this paper studies the observer-based attack-resilient control problem for linear systems with false data injection attacks and process disturbances. Due to limited resources, the malicious attacker is assumed to only manipulate a certain number of communication links from the controller to the actuators. A novel control architecture is proposed, which consists of an attack-resilient state observer, a controller gain scheme, and a supervisory switching strategy. The observer is developed based on the maximin strategy, and state estimation will be used to construct the controller. The switching strategy is designed to pick an appropriate controller gain and prevent the attack signals from entering the plant automatically. It is shown that the closed-loop system is stable with an attack-resilient performance. Finally, to verify the effectiveness of the proposed controller, simulation results on a linearized reduced-order aircraft system and an IEEE six-bus power system are provided. Copyright © 2018 John Wiley & Sons, Ltd.","attack-resilient control; cyber-physical systems; observer; supervisory switching strategy","Actuators; Closed loop systems; Cyber Physical System; Denial-of-service attack; Embedded systems; Linear systems; Network security; State estimation; Aircraft systems; Bus power system; Control architecture; False data injection attacks; observer; Process disturbances; Resilient control; Switching strategies; Controllers",,,,,"Pasqualetti, F., Dorfler, F., Bullo, F., Control-theoretic methods for cyberphysical security: geometric principles for optimal cross-layer resilient control systems (2015) IEEE Control Syst, 35 (1), pp. 110-127; Cárdenas, A.A., Amin, S., Sastry, S., (2008) Research challenges for the security of control systems, , In Proceedings of the 3rd Conference on Hot Topics in Security;, San Jose, CA; Mo, Y., Chabukswar, R., Sinopoli, B., Detecting integrity attacks on SCADA systems (2014) IEEE Trans Control Syst Technol, 22 (4), pp. 1396-1407; Wang, D., Wang, Z., Shen, B., Alsaadi, F.E., Hayat, T., Recent advances on filtering and control for cyber-physical systems under security and resource constraints (2016) J Franklin Inst, 353 (11), pp. 2451-2466; Zhang, H., Cheng, P., Shi, L., Chen, J., Optimal denial-of-service attack scheduling with energy constraint (2015) IEEE Trans Autom Control, 60 (11), pp. 3023-3028; Zhang, H., Cheng, P., Shi, L., Chen, J., Optimal DoS attack scheduling in wireless networked control system (2016) IEEE Trans Control Syst Technol, 24 (3), pp. 843-852; Liu, Y., Ning, P., Reiter, M., False data injection attacks against state estimation in electric power grids (2011) ACM Trans Inf Syst Secur, 14 (1), pp. 13-45; Pang, Z.-H., Liu, G.-P., Zhou, D., Hou, F., Sun, D., Two-channel false data injection attacks against output tracking control of networked systems (2016) IEEE Trans Ind Electron, 63 (5), pp. 3242-3251; Hao, J., Piechocki, R.J., Kaleshi, D., Chin, W.H., Fan, Z., Sparse malicious false data injection attacks and defense mechanisms in smart grids (2015) IEEE Trans Ind Informat, 11 (5), pp. 1-12; Zhu, M., Martínez, S., On the performance analysis of resilient networked control systems under replay attacks (2014) IEEE Trans Autom Control, 59 (3), pp. 804-808; Teixeira, A., Shames, I., Sandberg, H., Johansson, K.H., A secure control framework for resource-limited adversaries (2015) Automatica, 51, pp. 135-148; Ding, K., Dey, S., Quevedo, D.E., Shi, L., Stochastic game in remote estimation under DoS attacks (2017) IEEE Control Syst Lett, 1 (1), pp. 146-151; Ding, K., Li, Y., Quevedo, D.E., Dey, S., Shi, L., A multi-channel transmission schedule for remote state estimation under DoS attacks (2017) Automatica, 78, pp. 194-201; Mo, Y., Sinopoli, B., Secure estimation in the presence of integrity attacks (2015) IEEE Trans Autom Control, 60 (4), pp. 1145-1151; Shoukry, Y., Nuzzo, P., Puggelli, A., Sangiovanni-Vincentelli, A.L., Seshia, S.A., Tabuada, P., Secure state estimation for cyber physical systems under sensor attacks: a satisfiability modulo theory approach (2017) IEEE Trans Autom Control, 62 (10), pp. 4917-4932; An, L., Yang, G.-H., Secure state estimation against sparse sensor attacks with adaptive switching mechanism (2017) IEEE Trans Autom Control, , https://doi.org/10.1109/TAC.2017.2766759; Cardenas, A.A., Amin, S., Sastry, S., (2008) Secure control: Towards survivable cyber-physical systems, , In Proceedings of the 28th International Conference on Distributed Computing Systems Workshops;, Beijing, China; Fawzi, H., Tabuada, P., Diggavi, S., Secure estimation and control for cyber-physical systems under adversarial attacks (2014) IEEE Trans Autom Control, 59 (6), pp. 1454-1467; Feng, S., Tesi, P., Resilient control under denial-of-service: robust design (2017) Automatica, 79, pp. 42-51; Dolk, V.S., Tesi, P., De Persis, C., Heemels, W.M.H., Event-triggered control systems under denial-of-service attacks (2017) IEEE Trans Control Netw Syst, 4 (1), pp. 93-105; Lu, A.-Y., Yang, G.-H., Input-to-state stabilizing control for cyber-physical systems with multiple transmission channels under denial-of-service (2017) IEEE Trans Autom Control, , https://doi.org/10.1109/TAC.2017.2751999; Amin, S., Schwartz, G.A., Sastry, S.S., Security of interdependent and identical networked control systems (2013) Automatica, 49 (1), pp. 186-192; De Persis, C., Tesi, P., Input-to-state stabilizing control under denial-of-service (2015) IEEE Trans Autom Control, 60 (11), pp. 2930-2944; De Persis, C., Tesi, P., Networked control of nonlinear systems under denial-of-service (2016) Syst Control Lett, 96, pp. 124-131; Hu, J., Shen, J., Lee, D., Resilient stabilization of switched linear control systems against adversarial switching (2017) IEEE Trans Autom Control, 62 (8), pp. 3820-3834; D'Innocenzo, A., Smarra, F., Di Benedetto, M.D., Resilient stabilization of multi-hop control networks subject to malicious attacks (2016) Automatica, 71, pp. 1-9; Yuan, Y., Sun, F., Liu, H., Resilient control of cyber-physical systems against intelligent attacker: a hierarchal stackelberg game approach (2016) Int J Syst Sci, 47 (9), pp. 2067-2077; Jin, X., Haddad, W.M., Yucelen, T., An adaptive control architecture for mitigating sensor and actuator attacks in cyber-physical systems (2017) IEEE Trans Autom Control, 62 (11), pp. 6058-6064; Lu, A.-Y., Yang, G.-H., Event-triggered secure observer-based control for cyber-physical systems under adversarial attacks (2017) Inf Sci, 420, pp. 96-109; Xing, L., Wen, C., Zhu, Y., Su, H., Liu, Z., Output feedback control for uncertain nonlinear systems with input quantization (2016) Automatica, 65, pp. 191-202; Wu, Z.-G., Xu, Y., Pan, Y.-J., Su, H., Tang, Y., Event-triggered control for consensus problem in multi-agent systems with quantized relative state measurements and external disturbance (2018) IEEE Trans Circuit Syst I Reg Pap, , https://doi.org/10.1109/TCSI.2017.2777504; Wu, Z.-G., Xu, Y., Pan, Y.-J., Shi, P., Wang, Q., Event-triggered pinning control for consensus of multiagent systems with quantized information (2018) IEEE Trans Syst Man Cybern Syst, , https://doi.org/10.1109/TSMC.2017.2773634; Xie, C.-H., Yang, G.-H., Secure estimation for cyber-physical systems under adversarial actuator attacks (2017) IET Control Theory Appl, 11 (17), pp. 2939-2946; Chong, M.S., Wakaiki, M., Hespanha, J.P., (2015) Observability of linear systems under adversarial attacks, , In Proceedings of the American Control Conference;, Chicago, IL; Kalsi, K., Lian, J., Hui, S., Żak, S.H., Sliding-mode observers for systems with unknown inputs: a high-gain approach (2010) Automatica, 46 (2), pp. 347-353; Floquet, T., Edwards, C., Spurgeon, S.K., On sliding mode observers for systems with unknown inputs (2007) Int J Adapt Control Signal Process, 21 (8-9), pp. 638-656; Corless, M., Tu, J., State and input estimation for a class of uncertain systems (1998) Automatica, 34 (6), pp. 757-764; Filippov, A.F., (1988) Differential Equations with Discontinuous Right-Hand Sides, , Dordrecht, The Netherlands, Kluwer Academic Publishers; Khalil, H.K., (2002) Nonlinear Systems, , Upper Saddle River, NJ, Prentice Hall; Lewis, F.L., Vrabie, D., Syrmos, V.L., (2012) Optimal Control, , Hoboken, NJ, John Wiley & Sons; Xie, C.-H., Yang, G.-H., Model-free fault-tolerant control approach for uncertain state-constrained linear systems with actuator faults (2017) Int J Adapt Control Signal Process, 31 (2), pp. 223-239; Luo, B., Wu, H.-N., Huang, T., Liu, D., Data-based approximate policy iteration for affine nonlinear continuous-time optimal control design (2014) Automatica, 50 (12), pp. 3281-3290; Li, X.-J., Yang, G.-H., Neural-network-based adaptive decentralized fault-tolerant control for a class of interconnected nonlinear systems (2018) IEEE Trans Neural Netw Learn Syst, 29 (1), pp. 144-155; Siwakosit, W., Hess, R., Multi-input/multi-output reconfigurable flight control design (2001) J Guidance Control Dyn, 24 (6), pp. 1079-1088","Yang, G.-H.; College of Information Science and Engineering, China; email: yangguanghong@ise.neu.edu.cn",,,"John Wiley and Sons Ltd",,,,,10498923,,IJRCE,,"English","Int J Robust Nonlinear Control",Article,"Final","",Scopus,2-s2.0-85053349940
"Barni M., Santoyo-Garcia H., Tondi B.","7005442155;57188750553;55389019900;","An Improved Statistic for the Pooled Triangle Test Against PRNU-Copy Attack",2018,"IEEE Signal Processing Letters","25","10","8425718","1435","1439",,,"10.1109/LSP.2018.2863045","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051047309&doi=10.1109%2fLSP.2018.2863045&partnerID=40&md5=98378f72d06db1a1d09e8d299bee310b","Department of Information Engineering and Mathematical Sciences, University of Siena, Siena, 53100, Italy; Postgraduate Section, Mechanical Electrical Engineering School, National Polytechnic Institute of Mexico, Mexico, 07738, Mexico","Barni, M., Department of Information Engineering and Mathematical Sciences, University of Siena, Siena, 53100, Italy; Santoyo-Garcia, H., Postgraduate Section, Mechanical Electrical Engineering School, National Polytechnic Institute of Mexico, Mexico, 07738, Mexico; Tondi, B., Department of Information Engineering and Mathematical Sciences, University of Siena, Siena, 53100, Italy","We propose a new statistic to improve the pooled version of the triangle test used to combat the fingerprint-copy counterforensic attack against photoresponse nonuniformity based camera identification [1]. As opposed to the original version of the test, the new statistic exploits the one-tailed nature of the test, weighting differently positive and negative deviations from the expected value of the correlation between the image under analysis and the candidate images, i.e., those image suspected to have been used during the attack. The experimental results confirm the superior performance of the new test, especially when the conditions of the test are challenging ones, that is when the number of images used for the fingerprint-copy attack is large and the size of the image under test is small. © 1994-2012 IEEE.","Adversarial signal processing; camera fingerprint; forensics and counterforensics; sensor-based camera identification; triangle test","Cameras; Correlation methods; Palmprint recognition; Probability; Reliability; Signal processing; Camera identifications; Copy attacks; Counter-Forensics; Expected values; Forgery; Indexes; Negative deviations; Testing",,,,,"Goljan, M., Fridrich, J., Chen, M., Defending against fingerprint-copy attack in sensor-based camera identification (2011) IEEE Trans. Inf. Forensics Secur, 6 (1), pp. 227-236. , Mar; Chen, M., Fridrich, J., Goljan, M., Lukas, J., Determining image origin and integrity using sensor noise (2008) IEEE Trans. Inf. Forensics Secur, 3 (1), pp. 74-90. , Mar; Li, C.T., Source camera identification using enhanced sensor pattern noise (2010) IEEE Trans. Inf. Forensics Secur, 5 (2), pp. 280-287. , Jun; Chierchia, G., Poggi, G., Sansone, C., Verdoliva, L., A Bayesian-MRF approach for PRNU-based image forgery detection (2014) IEEE Trans. Inf. Forensics Secur, 9 (4), pp. 554-567. , Apr; Lukáš, J., Fridrich, J., Goljan, M., Detecting digital image forgeries using sensor pattern noise (2006) Proc. SPIE, 6072; Gloe, T., Kirchner, M., Winkler, A., Böhme, R., Can we trust digital image forensics? (2007) Proc. 15th ACM Int. Conf. Multimedia, pp. 78-86; Billingsley, P., (1986) Probability and Measure, , 2nd ed. Hoboken, NJ, USA: Wiley; Dang-Nguyen, D.-T., Pasquini, C., Conotter, V., Boato, G., Raise:Araw images dataset for digital image forensics (2015) Proc. 6th ACM Multimedia Syst. Conf, pp. 219-224; Mihcak, M.K., Kozintsev, I., Ramchandran, K., Spatially adaptive statistical modeling of wavelet image coefficients and its application to denoising (1999) Proc. IEEE Int. Conf. Acoust, 6, pp. 3253-3256. , Speech, Signal Process., Mar; Dabov, K., Foi, A., Katkovnik, V., Egiazarian, K., Image denoising by sparse 3-D transform-domain collaborative filtering (2007) IEEE Trans. Image Process, 16 (8), pp. 2080-2095. , Aug; Chierchia, G., Parrilli, S., Poggi, G., Sansone, C., Verdoliva, L., On the influence of denoising in PRNU based forgery detection (2010) Proc. 2nd ACM Workshop Multimedia Forensics, pp. 117-122. , Secur. Intell; Conotter, V., Boato, G., Analysis of sensor fingerprint for source camera identification (2011) Electron. Lett, 47 (25), pp. 1366-1367. , Dec; Rao, Q., Li, H., Luo, W., Huang, J., Anti-forensics of the triangle test by random fingerprint-copy attack (2013) Proc. Comput. Vis. Media Conf, pp. 1-6; Caldelli, R., Amerini, I., Novi, A., An analysis on attacker actions in fingerprint-copy attack in source camera identification (2011) Proc. IEEE Int. Workshop Inf. Forensics Secur, pp. 1-6. , Nov","Tondi, B.; Department of Information Engineering and Mathematical Sciences, Italy; email: benedettatondi@gmail.com",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,10709908,,ISPLE,,"English","IEEE Signal Process Lett",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85051047309
"Baracaldo N., Chen B., Ludwig H., Safavi A., Zhang R.","51460916900;56393403700;7201526338;57198886981;57199380853;","Detecting poisoning attacks on machine learning in IoT environments",2018,"Proceedings - 2018 IEEE International Congress on Internet of Things, ICIOT 2018 - Part of the 2018 IEEE World Congress on Services",,,"8473440","57","64",,23,"10.1109/ICIOT.2018.00015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055649917&doi=10.1109%2fICIOT.2018.00015&partnerID=40&md5=eb814662f236edaf1eb06ed44012c399","IBM Almaden Research Center, San Jose, CA, United States","Baracaldo, N., IBM Almaden Research Center, San Jose, CA, United States; Chen, B., IBM Almaden Research Center, San Jose, CA, United States; Ludwig, H., IBM Almaden Research Center, San Jose, CA, United States; Safavi, A., IBM Almaden Research Center, San Jose, CA, United States; Zhang, R., IBM Almaden Research Center, San Jose, CA, United States","Machine Learning (ML) plays an increasing role in Internet of Things (IoT), both in the Cloud and at the Edge, using trained models for applications from factory automation to environmental sensing. However, using ML in IoT environments presents unique security challenges. In particular, adversaries can manipulate the training data by tampering with sensors' measurements. This type of attack, known as a poisoning attack has been shown to significantly decrease overall performance, cause targeted misclassification or bad behavior, and insert ""backdoors"" and ""neural trojans"". Taking advantage of recently developed tamper-free provenance frameworks, we present a methodology that uses contextual information about the origin and transformation of data points in the training set to identify poisonous data. Our approach works with or without a trusted test data set. Using the proposed approach poisoning attacks can be effectively detected and mitigated in IoT environments with reliable provenance information. © 2018 IEEE.","Adversarial machine learning; AI; Artificial intelligence; Internet of things; IoT; Machine learning; Poisoning attacks; Provenance","Artificial intelligence; Factory automation; Learning systems; Malware; Metadata; Statistical tests; Contextual information; Environmental sensing; Internet of Things (IOT); Misclassifications; Poisoning attacks; Provenance; Security challenges; Training sets; Internet of things",,,,,"Barreno, M., Nelson, B., Joseph, A.D., Tygar, J., The security of machine learning (2010) Machine Learning, 81 (2), pp. 121-148; Nelson, B.A., (2010) Behavior of Machine Learning Algorithms in Adversarial Environments, , University of California, Berkeley; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I., Tygar, J.D., Adversarial machine learning (2011) Proc. of the 4th ACM Workshop on Security and Artificial Intelligence, Ser. AISec '11; Papernot, N., McDaniel, P., Sinha, A., Wellman, M., (2016) Towards the Science of Security and Privacy in Machine Learning, , arXiv preprint; Gu, T., Dolan-Gavitt, B., Garg, S., Badnets: Identifying vulnerabilities in the machine learning model supply chain (2017) CoRR, , [Online] arxiv.org/abs/1708.06733; Liu, Y., Ma, S., Aafer, Y., Lee, W.-C., Zhai, J., Wang, W., Zhang, X., (2017) Trojaning Attack on Neural Networks; Liu, Y., Xie, Y., Srivastava, A., Neural trojans (2017) Computer Design (ICCD), 2017 IEEE Int. Conf. On; Nelson, B., Barreno, M., Chi, F.J., Joseph, A.D., Rubinstein, B.I., Saini, U., Sutton, C., Xia, K., Misleading learners: Co-opting your spam filter (2009) Machine Learning in Cyber Trust, pp. 17-51. , Springer; Chakarov, A., Nori, A., Rajamani, S., Sen, S., Vijaykeerthy, D., (2016) Debugging Machine Learning Tasks, , arXiv preprint; Biggio, B., Nelson, B., Laskov, P., (2012) Poisoning Attacks Against Support Vector Machines, , arXiv preprint; Zhou, Y., Kantarcioglu, M., Thuraisingham, B., Xi, B., Adversarial support vector machine learning (2012) Proc. of the 18th ACM SIGKDD; Hasan, R., Sion, R., Winslett, M., The case of the fake Picasso: Preventing history forgery with secure provenance (2009) FAST, 9, pp. 1-14; Baracaldo, N., Bathen, L.A., Ozugha, R., Engel, S., And-Tata, R., Ludwig, H., Securing data provenance in internet of things (iot) systems (2017) Service-Oriented Computing - ICSOC 2016 Workshops, , Springer Berlin Heidelberg; Aman, M.N., Chua, K.C., Sikdar, B., Secure data provenance for the internet of things (2017) Proc. of the 3rd ACM Int. Workshop on IoT Privacy, Trust, and Security, Ser. IoTPTS '17, pp. 11-14; Wang, X., Zeng, K., Govindan, K., Mohapatra, P., Chaining for securing data provenance in distributed information networks (2012) MILCOM 2012, pp. 1-6; Gadelha, J., Kairos: An architecture for securing authorship and temporal information of provenance data in grid-enabled workflow management systems (2008) eScience'08; Lyle, J., Martin, A., Trusted computing and provenance: Better together (2010) Proc. of the 2nd Workshop on the Theory and Practice of Provenance, , Usenix; Appendix, , www.dropbox.com/sh/rmwdp1ji2h0a40i/AAAuoVNm0cxavRxEgY1N18cQa?dl=0, [Online]; Papernot, N., McDaniel, P., Sinha, A., Wellman, M., (2016) Towards the Science of Security and Privacy in Machine Learning, , arXiv preprint; Gardiner, J., Nagaraja, S., On the security of machine learning in malware c8c detection: A survey (2016) ACM Computing Surveys (CSUR), 49 (3), p. 59; Biggio, B., Fumera, G., Roli, F., Security evaluation of pattern classifiers under attack (2014) IEEE Transactions on Knowledge and Data Engineering; Baracaldo, N., Chen, B., Ludwig, H., Safavi, J.A., Mitigating poisoning attacks on machine learning models: A data provenance based approach (2017) Proc. of the 10th ACM Workshop on Artificial Intelligence and Security, Ser. AISec '17; Xu, H., Caramanis, C., Mannor, S., Robustness and regularization of support vector machines (2009) Journal of Machine Learning Research, 10 (JUL), pp. 1485-1510; Biggio, B., Nelson, B., Laskov, P., Support vector machines under adversarial label noise (2011) Asian Conference on Machine Learning, pp. 97-112; Mozaffari-Kermani, M., Sur-Kolay, S., Raghunathan, A., Jha, N.K., Systematic poisoning attacks on and defenses for machine learning in healthcare (2015) IEEE Journal of Biomedical and Health Informatics, 19 (6), pp. 1893-1905",,,"IEEE;IEEE Computer Society","Institute of Electrical and Electronics Engineers Inc.","3rd IEEE International Congress on Internet of Things, ICIOT 2018","2 July 2018 through 7 July 2018",,140204,,9781538672440,,,"English","Proc. - IEEE Int. Congr. Internet Things, ICIOT - Part IEEE World Congr. Serv.",Conference Paper,"Final","",Scopus,2-s2.0-85055649917
"Chan V.W.S.","7202654929;","Resilient Optical Networks1",2018,"International Conference on Transparent Optical Networks","2018-July",,"8473976","","",,1,"10.1109/ICTON.2018.8473976","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055500275&doi=10.1109%2fICTON.2018.8473976&partnerID=40&md5=638fdcd3068d97df275f100e1d22a85e","Claude E. Shannon Communication and Network Group, Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, United States","Chan, V.W.S., Claude E. Shannon Communication and Network Group, Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, United States","Networking resilience is the ability to provide and maintain an acceptable level of service, albeit potentially degraded from nominal, in the face of faults and challenges to normal, including adversarial attacks. This paper explores the concept of resilient optical networks and scopes the important issues to be addressed in a sensible architecture. The solution includes monitoring and probing to determine the states of potentially unreliable network substrates, assessment of resilient network operating regimes, isolation of compromised assets, deployment of mitigation measures that may require communication over unreliable substrates and suggestions for resilient architecture design and improvement. The architecture construct evolves around a robust control plane that uses cognitive techniques to assess network states and automatically reacts to the on-set of impairments and attacks involving all the network layers from the Physical Layer to the Application Layer. © 2018 IEEE.","network reconstitution; network security; optical network architecture; resilient networks","Fiber optic networks; Network layers; Network security; Robust control; Transparent optical networks; Application layers; Architecture designs; Level of Service; Mitigation measures; Operating regimes; Physical layers; Resilient networks; Unreliable network; Network architecture",,,,,"Feffer, A., (2015) Comprehensive Security Strategy for All-optical Networks, , MS Thesis MIT EECS; Wen, Y., Chan, V.W.S., Zheng, L., Efficient fault-diagnosis algorithms for all-optical WDM networks with probabilistic link failures (2005) Journal of Lightwave Technology, , Oct; Zhang, L., Chan, V., Scalable fast scheduling for optical flow switching using sampled entropy and mutual information broadcast (2014) IEEE/OSA JOCN, , Apr; Qian, M., (2012) Effects of Diversity Routing on TCP Performance in Networks with Stochastic Channels, , MS Thesis MIT; Zhang, J., Chapin, J.M., Chan, V.W.S., Failure of TCP congestion control under diversity routing (2011) Proc. WCNC, , Mar; Zhang, L., Chan, V.W.S., Optical flow switching with physical layer impairments-Modeling, algorithm, and control (2015) Proc. Globecom; Chan, V., Cognitive Optical Networks (2018) Proc. ICC, , May; Huang, H., Chan, V.W.S., Optical flow-switched transport layer protocol design and performance analysis (2014) Journal of Optical Communications and Networks, , Jul","Chan, V.W.S.; Claude E. Shannon Communication and Network Group, United States; email: chan@mit.edu",,"Apex Technologies;Hv Photonics;Nea Spec;Opto Sigma;Schaefer","IEEE Computer Society","20th International Conference on Transparent Optical Networks, ICTON 2018","1 July 2018 through 5 July 2018",,140131,21627339,9781538666043,,,"English","Int. Conf.Transparent Opt. Networks",Conference Paper,"Final","",Scopus,2-s2.0-85055500275
"Specht F., Otto J., Niggemann O., Hammer B.","57035139000;57193314355;15835261800;55791279400;","Generation of Adversarial Examples to Prevent Misclassification of Deep Neural Network based Condition Monitoring Systems for Cyber-Physical Production Systems",2018,"Proceedings - IEEE 16th International Conference on Industrial Informatics, INDIN 2018",,,"8472060","760","765",,5,"10.1109/INDIN.2018.8472060","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055496036&doi=10.1109%2fINDIN.2018.8472060&partnerID=40&md5=1db1a5055a9a68c954207e8b35d5944d","Fraunhofer IOSB-INA, Langenbruch 6, Lemgo, 32657, Germany; Barbara Hammer CITEC, Bielefeld University, Inspiration 1, Bielefeld, 33619, Germany","Specht, F., Fraunhofer IOSB-INA, Langenbruch 6, Lemgo, 32657, Germany; Otto, J., Fraunhofer IOSB-INA, Langenbruch 6, Lemgo, 32657, Germany; Niggemann, O., Fraunhofer IOSB-INA, Langenbruch 6, Lemgo, 32657, Germany; Hammer, B., Barbara Hammer CITEC, Bielefeld University, Inspiration 1, Bielefeld, 33619, Germany","Deep neural network based condition monitoring systems are used to detect system failures of cyber-physical production systems. However, a vulnerability of deep neural networks are adversarial examples. They are manipulated inputs, e.g. process data, with the ability to mislead a deep neural network into misclassification. Adversarial example attacks can manipulate the physical production process of a cyber-physical production system without being recognized by the condition monitoring system. Manipulation of the physical process poses a serious threat for production systems and employees. This paper introduces CyberProtect, a novel approach to prevent misclassification caused by adversarial example attacks. CyberProtect generates adversarial examples and uses them to retrain deep neural networks. This results in a hardened deep neural network with a significant reduced misclassification rate. The proposed countermeasure increases the classification rate from 20% to 82%, as proved by empirical results. © 2018 IEEE.",,"Condition monitoring; Cyber Physical System; Systems engineering; Classification rates; Condition monitoring systems; Misclassification rates; Misclassifications; Physical process; Production process; Production system; System failures; Deep neural networks",,,,,"Zimmermann, U., Bischoff, R., Grunwald, G., Plank, G., Reintsema, D., Communication, configuration, application: The three layer concept for plug-and-produce (2008) Proc. 5th International Conference on Informatics in Control, Automation and Robotics (ICINCO), pp. 255-262. , Funchal, Portugal May; Otto, J., Vogel-Heuser, B., Niggemann, O., Online parameter estimation for cyber-physical production systems based on mixed integer nonlinear programming, process mining and black-box optimization techniques (2018) Automatisierungstechnik, 66 (4), pp. 331-343; Reinhart, G., Krug, S., Huttner, S., Mari, Z., Riedelbauch, F., Schlogel, M., Automatic configuration (plug & produce) of industrial ethernet networks (2010) Proc. 9th IEEE/IAS International Conference on Industry Applications (INDUSCON), pp. 1-6. , Sao Paulo, Brazil, nov; Otto, J., Vogel-Heuser, B., Niggemann, O., Automatic parameter estimation for reusable software components of modular and reconfigurable cyber-physical production systems in the domain of discrete manufacturing (2018) IEEE Transactions on Industrial Informatics, 14 (1), pp. 275-282; Elhoseny, M., Hosny, A., Hassanien, A., Muhammad, K., Sangaiah, A., Secure automated forensic investigation for sustainable critical infrastructures compliant with green computing requirements (2017) IEEE Transactions on Sustainable Computing; Monostori, L., Kádár, B., Bauernhansl, T., Kondoh, S., Kumara, S., Reinhart, G., Sauer, O., Ueda, K., Cyber-physical systems in manufacturing (2016) International Academy for Production Engineering Annals, 65 (2), pp. 621-641; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) Proc. of the 2nd International Conference on Learning Representations (ICLR), , Banff, Canada, apr; Stouffer, K., Falco, J., Scarfone, K., Guide to industrial control systems (ics) security (2011) NIST Special Publication, 800 (82), p. 16; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) Proc. of the 3rd International Conference on Learning Representations (ICLR), , San Diego, USA. May; Yuan, X., He, P., Zhu, Q., Rana Bhat, R., Li, X., Adversarial examples: Attacks and defenses for deep learning (2017) Computing Research Repository, , (CoRR), abs/1712. 07107; Niggemann, O., Kroll, B., On the applicability of model based software development to cyber physical production systems (2014) Proc. of the 19th IEEE Emerging Technology and Factory Automation (ETFA), pp. 1-4; Hossain, D., Capi, G., Jindai, M., Kaneko, S., Pick-place of dynamic objects by robot manipulator based on deep learning and easy user interface teaching systems (2017) Industrial Robot: The International Journal of Robotics Research and Application, 44 (1), pp. 11-20; Jeschke, S., Brecher, C., Meisen, T., Özdemir, D., Eschert, T., (2017) Industrial Internet of Things and Cyber Manufacturing Systems, pp. 3-19. , Springer International Publishing; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Proc. of the 38th IEEE Symposium on Security and Privacy (SP), pp. 39-57. , May, San Jose, USA; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2016) Computing Research Repository, , (CoRR), abs/1607. 02533; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2016) Proc. of the 37th IEEE Symposium on Security and Privacy (SP)), pp. 372-387. , May, San Jose, USA; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) Proc. of the 10th ACM Workshop on Artificial Intelligence and Security (AISec), pp. 3-14. , Dallas, USA, nov; Papernot, N., McDaniel, P., Goodfellow, I., Transferability in machine learning: From phenomena to black-box attacks using adversarial samples (2016) Computing Research Repository, , (CoRR), abs/1605. 07277; Papernot, N., McDaniel, P., On the effectiveness of defensive distillation (2016) Computing Research Repository (CoRR), , abs/1607. 05113; Xu, W., Evans, D., Qi, Y., Feature squeezing: Detecting adversarial examples in deep neural networks (2017) Computing Research Repository (CoRR), , abs/1704. 01155; Xu, W., Evans, D., Qi, Y., Feature squeezing mitigates and detects carlini/Wagner adversarial examples (2017) Computing Research Repository (CoRR), , abs/1705. 10686; McCann, M., Johnston, A., (2008) Uci Ml Repository Secom Dataset, , [Online; accessed 2018-02-05]; Abadi, M., Tensorflow: A system for large-scale machine learning (2016) Proc. of the 12th USENIX Symposium on Operating Systems Design and Implementation (OSDI), 16, pp. 265-283. , Savannah, USA, nov; Kingma, D.P., Ba, J., Adam: A method for stochastic optimization (2014) Computing Research Repository (CoRR), , abs/1412. 6980; Goodfellow, I., Papernot, N., McDaniel, P., Cleverhans v2. 0. 0. : An adversarial machine learning library (2016) Computing Research Repository (CoRR), , abs/1610. 00768; Jones, E., Oliphant, T., Peterson, P., (2001) SciPy: Open Source Scientific Tools for Python, , [Online; accessed 2018-02-05]; John, D.H., Matplotlib: A 2d graphics environment (2007) Computing in Science and Engineering, 9 (3), pp. 90-95; Brinkrolf, J., Hammer, B., Interpretable machine learning with reject option (2018) Automatisierungstechnik, 66 (4), pp. 283-290",,,"IEEE Industrial Electronics Society (IES);INESC TE;New University of Lisboa;The Institute of Electrical and Electronics Engineers (IEEE)","Institute of Electrical and Electronics Engineers Inc.","16th IEEE International Conference on Industrial Informatics, INDIN 2018","18 July 2018 through 20 July 2018",,140136,,9781538648292,,,"English","Proc. - IEEE Int. Conf. Industr. Inf., INDIN",Conference Paper,"Final","",Scopus,2-s2.0-85055496036
"Warzynski A., Kolaczek G.","57204418868;6506706320;","Intrusion detection systems vulnerability on adversarial examples",2018,"2018 IEEE (SMC) International Conference on Innovations in Intelligent Systems and Applications, INISTA 2018",,,"8466271","","",,16,"10.1109/INISTA.2018.8466271","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055544788&doi=10.1109%2fINISTA.2018.8466271&partnerID=40&md5=51486b6bbb3318f4108de36ec88460aa","Faculty of Computer Science and Management, Wroclaw University of Science and Technology, 27 Wybrzeze Wyspianskiego st., Wrocław, 50-370, Poland","Warzynski, A., Faculty of Computer Science and Management, Wroclaw University of Science and Technology, 27 Wybrzeze Wyspianskiego st., Wrocław, 50-370, Poland; Kolaczek, G., Faculty of Computer Science and Management, Wroclaw University of Science and Technology, 27 Wybrzeze Wyspianskiego st., Wrocław, 50-370, Poland","Intrusion detection systems define an important and dynamic research area for cybersecurity. The role of Intrusion Detection System within security architecture is to improve a security level by identification of all malicious and also suspicious events that could be observed in computer or network system. One of the more specific research areas related to intrusion detection is anomaly detection. Anomaly-based intrusion detection in networks refers to the problem of finding untypical events in the observed network traffic that do not conform to the expected normal patterns. It is assumed that everything that is untypical/anomalous could be dangerous and related to some security events. To detect anomalies many security systems implements a classification or clustering algorithms. However, recent research proved that machine learning models might misclassify adversarial events, e.g. observations which were created by applying intentionally non-random perturbations to the dataset. Such weakness could increase of false negative rate which implies undetected attacks. This fact can lead to one of the most dangerous vulnerabilities of intrusion detection systems. The goal of the research performed was verification of the anomaly detection systems ability to resist this type of attack. This paper presents the preliminary results of tests taken to investigate existence of attack vector, which can use adversarial examples to conceal a real attack from being detected by intrusion detection systems. © 2018 IEEE.","Adversarial examples; Anomaly detection; intrusion detection systems","Chemical detection; Clustering algorithms; Computer crime; Computer networks; Intelligent systems; Learning systems; Network security; Adversarial examples; Anomaly detection; Anomaly detection systems; Anomaly-based intrusion detection; Intrusion Detection Systems; Machine learning models; Random perturbations; Security Architecture; Intrusion detection",,,,,"Smaha, S.E., Haystack: An intrusion detection system (1988) Fourth Aerospace Computer Security Applications Conference, pp. 37-44. , IEEE, Orlando, FL, USA; Bhuyan, M.H., Bhattacharyya, D.K., Kalita, J.K., Network anomaly detection : Methods, systems and tools (2014) IEEE Communications Surveys & Tutorial, 16 (1), pp. 303-336; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint arXiv:1312. 6199; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint arXiv:1412. 6572; Butti, L., Presentation: Wi-Fi Advanced Fuzzing, , http://www.blackhat.com/presentations/bh-europe-07/Butti/Presentation/bh-eu-07-Butti.pdf, last accessed 2017/05/30; Stolfo, S.J., Fan, W., Lee, W., Prodromidis, A., Chan, P.K., Cost-based modeling for fraud and intrusion detection: Results from the JAM project (2000) Proc. of the DARPA Information Survivability Conference and Exposition, 2, pp. 130-144. , USA: IEEE CS; Tavallaee, M., Bagheri, E., Lu, W., Ghorbani, A.A., A detailed analysis of the KDD CUP 99 data set (2009) Proc. of the 2nd IEEE International Conference on Computational Intelligence for Security and Defense Applications, pp. 53-58. , USA: IEEE Press; Revathi, S., Malathi, A., (2013) A Detailed Analysis on NSL-KDD Dataset Using Various Machine Learning Techniques for Intrusion Detection; (2009) NSL-KDD Data Set for Network-based Intrusion Detection Systems, , http://iscx.cs.unb.ca/NSL-KDD/, NSL-KDD, March; Brugger, T., Post KDD Cup '99 Dataset (Network Intrusion) Considered Harmful, , http://www.kdnuggets.com/news/2007/n18/4i.html, last, last accessed 2017/05/30; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Proceedings of the 1st IEEE European Symposium in Security and Privacy (EuroS&P); Grosse, K., Papernot, N., Manoharan, P., Backes, M., McDaniel, P., (2016) Adversarial Perturbations Against Deep Neural Networks for Malware Classification, , arXiv preprint arXiv:1606. 04435; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint arXiv:1607. 02533; Carlini, N., Mishra, P., Vaidya, T., Zhang, Y., Sherr, M., Shields, C., Wagner, D., Zhou, W., Hidden voice commands (2016) USENIX Security Symposium, pp. 513-530",,"Angelov P.Yildirim T.Iliadis L.Manolopoulos Y.",,"Institute of Electrical and Electronics Engineers Inc.","2018 IEEE International Conference on Innovations in Intelligent Systems and Applications, INISTA 2018","3 July 2018 through 5 July 2018",,139966,,9781538651506,,,"English","IEEE (SMC) Int. Conf. Innov. Intell. Syst. Appl., INISTA",Conference Paper,"Final","",Scopus,2-s2.0-85055544788
"Wehbe R., Williams R.K.","57196236649;54793876100;","Probabilistic Graph Security for Networked Multi-Robot Systems",2018,"Proceedings - IEEE International Conference on Robotics and Automation",,,"8460752","7646","7653",,6,"10.1109/ICRA.2018.8460752","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063123760&doi=10.1109%2fICRA.2018.8460752&partnerID=40&md5=46c45955ae8f8860f607c47d26d3bf87","Department of Electrical and Computer Engineering, Virginia Polytechnic Institute, State University, Blacksburg, VA, United States","Wehbe, R., Department of Electrical and Computer Engineering, Virginia Polytechnic Institute, State University, Blacksburg, VA, United States; Williams, R.K., Department of Electrical and Computer Engineering, Virginia Polytechnic Institute, State University, Blacksburg, VA, United States","In this paper, we develop a method for determining the probability of a multi-robot system (MRS) being secure when robot interactions are modeled as a probabilistic graph. To define the security of an MRS, we apply an existing control-theoretic notion of network attacks based on the left invertibility of a dynamical system. We then extend previous work by assuming probabilistic robot communication and sensing, modeling the effects of noise, failure, or adversarial influence on interactions in the network. The probabilistic graph security problem can then be seen as a variant of problems solved in the field of system reliability. This interpretation motivates the application of an efficient graphical representation of boolean functions known as binary decision diagrams (BDDs). Specifically, we use the canonical properties of a special type of BDD, the Reduced Order BDD, to generate a tree that can be efficiently traversed to compute the probability that a networked MRS is left invertible, and thus, secure. We then show how our adopted approach can be applied to systems that have interactions that change over time, e.g., for mobile multi-robot teams. Finally, we demonstrate the validity of our method by simulating a mobile MRS performing a rendezvous objective, while tracking its probability of security over time. © 2018 IEEE.",,"Binary decision diagrams; Boolean functions; Dynamical systems; Industrial robots; Multipurpose robots; Probability; Robot learning; Robotics; Binary decision diagrams (BDDs); Canonical properties; Control-theoretic notions; Graphical representations; Multirobot systems; Probabilistic graphs; Robot communication; Robot interactions; Network security",,,,,"Bevacqua, G., Cacace, J., Finzi, A., Lippiello, V., Mixed-initiative planning and execution for multiple drones in search and rescue missions (2015) ICAPS, pp. 315-323; Guizzo, E., Three engineers, hundreds of robots, one warehouse (2008) IEEE Spectrum, 45 (7), pp. 26-34; Tripicchio, P., Satler, M., Dabisias, G., Ruffaldi, E., Avizzano, C.A., Towards smart farming and sustainable agriculture with drones (2015) Intelligent Environments (IE), 2015 International Conference on, pp. 140-143. , IEEE; Pasqualetti, F., Dorfler, F., Bullo, F., Control-theoretic methods for cyberphysical security: Geometric principles for optimal cross-layer resilient control systems (2015) IEEE Control Systems, 35 (1), pp. 110-127; Amin, S., Cardenas, A.A., Sastry, S., Safe and secure networked control systems under denial-of-service attacks (2009) HSCC, 5469, pp. 31-45. , Springer; Xie, L., Mo, Y., Sinopoli, B., False data injection attacks in electricity markets (2010) Smart Grid Communications (SmartGridComm), 2010 First IEEE International Conference on, pp. 226-231. , IEEE; Mo, Y., Sinopoli, B., Secure control against replay attacks (2009) Communication, Control, and Computing, 2009. Allerton 2009. 47th Annual Allerton Conference on, pp. 911-918. , IEEE; Smith, R.S., A decoupled feedback structure for covertly appropriating networked control systems (2011) IFAC Proceedings Volumes, 44 (1), pp. 90-95; Pasqualetti, F., Bicchi, A., Bullo, F., Consensus computation in unreliable networks: A system theoretic approach (2012) IEEE Transactions on Automatic Control, 57 (1), pp. 90-104; Zikratov, I.A., Lebedev, I.S., Gurtov, A.V., Trust and reputation mechanisms for multi-agent robotic systems (2014) International Conference on Next Generation Wired/Wireless Networking, pp. 106-120. , Springer; Weerakkody, S., Liu, X., Son, S.H., Sinopoli, B., A graph-theoretic characterization of perfect attackability for secure design of distributed control systems (2017) IEEE Transactions on Control of Network Systems, 4 (1), pp. 60-70; Mahboubi, H., Asadi, M.M., Aghdam, A.G., Blouin, S., A computationally efficient connectivity measure for random graphs (2015) Global Communications Conference (GLOBECOM), 2015 IEEE, pp. 1-6. , IEEE; Asadi, M.M., Mahboubi, H., Aghdam, A.G., Blouin, S., Connectivity measures for random directed graphs with applications to underwater sensor networks (2015) Electrical and Computer Engineering (CCECE), 2015 IEEE 28th Canadian Conference on, pp. 208-212. , IEEE; Akers, S.B., Binary decision diagrams (1978) IEEE Transactions on Computers, (6), pp. 509-516; Bryant, R.E., Symbolic boolean manipulation with ordered binarydecision diagrams (1992) ACM Computing Surveys (CSUR), 24 (3), pp. 293-318; Hardy, G., Lucet, C., Limnios, N., K-terminal network reliability measures with binary decision diagrams (2007) IEEE Transactions on Reliability, 56 (3), pp. 506-515; Wilson, R.J., (1986) Introduction to Graph Theory, , New York, NY, USA: John Wiley &Sons, Inc; Lin, C.-T., Structural controllability (1974) IEEE Transactions on Automatic Control, 19 (3), pp. 201-208; Mazur, D., (2010) Combinatorics: A Guided Tour, Ser. MAA Textbooks. Mathematical Association of America, , https://books.google.com/books?id=yI4Jx5Obr08C; Kahn, J., Linial, N., Samorodnitsky, A., Inclusion-exclusion: Exact and approximate (1996) Combinatorica, 16 (4), pp. 465-477. , https://doi.org/10.1007/BF01271266, Dec; Locks, M.O., A minimizing algorithm for sum of disjoint products (1987) IEEE Transactions on Reliability, 36 (4), pp. 445-453; Ball, M.O., Computational complexity of network reliability analysis: An overview (1986) IEEE Transactions on Reliability, 35 (3), pp. 230-239; Friedman, S.J., Supowit, K.J., Finding the optimal variable ordering for binary decision diagrams (1987) Design Automation, 1987. 24th Conference on, pp. 348-356. , IEEE; Ball, M.O., Colbourn, C.J., Provan, J.S., Chapter 11 network reliability (1995) Handbooks in Operations Research and Management Science, 7, pp. 673-762. , http://www.sciencedirect.com/science/article/pii/S0927050705801288, network Models; Yang, P., Freeman, R.A., Gordon, G.J., Lynch, K.M., Srinivasa, S.S., Sukthankar, R., Decentralized estimation and control of graph connectivity for mobile sensor networks (2010) Automatica, 46 (2), pp. 390-396; Williams, R.K., Sukhatme, G.S., Constrained interaction and coordination in proximity-limited multiagent systems (2013) IEEE Transactions on Robotics, 29 (4), pp. 930-944; Somenzi, F., (1998) Cudd: Cu Decision Diagram Package Release 2.3. 0, , University of Colorado at Boulder",,,"Csiro;Department of Defence;DJI;et al.;Queensland University of Technology (QUT);Woodside","Institute of Electrical and Electronics Engineers Inc.","2018 IEEE International Conference on Robotics and Automation, ICRA 2018","21 May 2018 through 25 May 2018",,139796,10504729,9781538630815,PIIAE,,"English","Proc IEEE Int Conf Rob Autom",Conference Paper,"Final","",Scopus,2-s2.0-85063123760
"Abdelkader M., Lu Y., Jaleel H., Shamma J.S.","57197062034;57226849805;51461574600;7005188389;","Distributed Real Time Control of Multiple UAVs in Adversarial Environment: Algorithm and Flight Testing Results",2018,"Proceedings - IEEE International Conference on Robotics and Automation",,,"8460866","6659","6664",,6,"10.1109/ICRA.2018.8460866","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056862812&doi=10.1109%2fICRA.2018.8460866&partnerID=40&md5=861b01c71f683d4ef5fe56a202648ba8","King Abdullah University of Science and Technology (KAUST), Thuwal, 23955-6900, Saudi Arabia; Physical Sciences and Engineering Division (PSE), Saudi Arabia; Computer, Electrical and Mathematical Sciences and Engineering Division (CEMSE), Saudi Arabia","Abdelkader, M., King Abdullah University of Science and Technology (KAUST), Thuwal, 23955-6900, Saudi Arabia, Physical Sciences and Engineering Division (PSE), Saudi Arabia; Lu, Y., King Abdullah University of Science and Technology (KAUST), Thuwal, 23955-6900, Saudi Arabia, Computer, Electrical and Mathematical Sciences and Engineering Division (CEMSE), Saudi Arabia; Jaleel, H., King Abdullah University of Science and Technology (KAUST), Thuwal, 23955-6900, Saudi Arabia, Computer, Electrical and Mathematical Sciences and Engineering Division (CEMSE), Saudi Arabia; Shamma, J.S., King Abdullah University of Science and Technology (KAUST), Thuwal, 23955-6900, Saudi Arabia, Computer, Electrical and Mathematical Sciences and Engineering Division (CEMSE), Saudi Arabia","We present a complete design and implementation of a system that consists of multiple quadrotors playing capture the flag game. Our main contributions in this work include a custom built quadrotor platform, an efficient implementation of a distributed trajectory planning algorithm, and a WiFi based communication infrastructure. In our design, we equip the quadrotors with autopilot modules for low level control. Moreover, we install low power computing modules for implementing the distributed trajectory planning algorithm online. Furthermore, we develop a communication infrastructure to enable coordination among the quadrotors, which is required for computing a suboptimal control action in real time. The interactions among all the hardware and software components are managed at a higher level by Robot Operating System (ROS). To test the performance of the system, we select a motivating setup of capture the flag game, which is an adversarial game played between two teams of agents called attack and defense. The system is initially simulated in the Gazebo robot simulator with software in the loop. Finally, the complete system is tested and the flight testing results are presented. © 2018 IEEE.",,"Computer software; Optimal systems; Robotics; Adversarial environments; Communication infrastructure; Design and implementations; Efficient implementation; Hardware and software components; Robot operating systems (ROS); Software in the loops; Trajectory planning algorithm; Real time control",,,,,"D'Andrea, R., Guest editorial can drones deliver? (2014) IEEE Transactions on Automation Science and Engineering, 11 (3), pp. 647-648. , 2014; Tomic, T., Schmid, K., Lutz, P., Domel, A., Kassecker, M., Mair, E., Grixa, I.L., Burschka, D., Toward a fully autonomous uav: Research platform for indoor and outdoor urban search and rescue (2012) IEEE Robotics &Automation Magazine, 19 (3), pp. 46-56; Honkavaara, E., Saari, H., Kaivosoja, J., Pölönen, I., Hakala, T., Litkey, P., Mäkynen, J., Pesonen, L., Processing and assessment of spectrometric, stereoscopic imagery collected using a lightweight uav spectral camera for precision agriculture (2013) Remote Sensing, 5 (10), pp. 5006-5039; Gupte, S., Mohandas, P.I.T., Conrad, J.M., A survey of quadrotor unmanned aerial vehicles (2012) Southeastcon, pp. 1-6. , 2012 Proceedings of IEEE. IEEE; Flint, M., Polycarpou, M., Fernandez-Gaucherand, E., Cooperative path-planning for autonomous vehicles using dynamic programming (2002) Proceedings of the IFAC 15th Triennial World Congress, pp. 1694-1699; Dunbar, W.B., Murray, R.M., Model predictive control of coordinated multi-vehicle formations (2002) Decision and Control, 2002, Proceedings of the 41st IEEE Conference on, 4, pp. 4631-4636. , IEEE; Ferrari-Trecate, G., Galbusera, L., Marciandi, M.P.E., Scattolini, R., Model predictive control schemes for consensus in multi-agent systems with single-and double-integrator dynamics (2009) IEEE Transactions on Automatic Control, 54 (11), pp. 2560-2572; Müller, M.A., Reble, M., Allgöwer, F., Cooperative control of dynamically decoupled systems via distributed model predictive control (2012) International Journal of Robust and Nonlinear Control, 22 (12), pp. 1376-1397; Chasparis, G.C., Shamma, J.S., Lp-based multi-vehicle path planning with adversaries (2008) Cooperative Control of Distributed Multi-Agent Systems, pp. 261-279; Abdelkader, M., Jaleel, H., Shamma, J.S., A distributed framework for real time path planning in practical multiagent systems (2017) IFAC World Congress, , https://www.dropbox.com/sh/urqebc8jz6gk235/AAASpIi69Q37-KubSHf32Z8ra?dl=0, Toulouse, France, , to appear; D'Andrea, R., Babish, M., The roboflag testbed (2003) American Control Conference, 1, pp. 656-660. , 2003. Proceedings of the. IEEE, 2003; Quigley, M., Conley, K., Gerkey, B., Faust, J., Foote, T., Leibs, J., Wheeler, R., Ng, A.Y., Ros: An open-source robot operating system (2009) ICRA Workshop on Open Source Software, 3 (2-3), p. 5. , Kobe; Huang, H., Ding, J., Zhang, W., Tomlin, C.J., Automation-assisted capture-The-flag: A differential game approach (2015) IEEE Transactions on Control Systems Technology, 23 (3), pp. 1014-1028. , May",,,"Csiro;Department of Defence;DJI;et al.;Queensland University of Technology (QUT);Woodside","Institute of Electrical and Electronics Engineers Inc.","2018 IEEE International Conference on Robotics and Automation, ICRA 2018","21 May 2018 through 25 May 2018",,139796,10504729,9781538630815,PIIAE,,"English","Proc IEEE Int Conf Rob Autom",Conference Paper,"Final","",Scopus,2-s2.0-85056862812
"Kreuk F., Adi Y., Cisse M., Keshet J.","57204050284;57170476300;55252498700;8671885400;","Fooling end-to-end speaker verification with adversarial examples",2018,"ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings","2018-April",,"8462693","1962","1966",,58,"10.1109/ICASSP.2018.8462693","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054232540&doi=10.1109%2fICASSP.2018.8462693&partnerID=40&md5=a4a247510ad15fe165459d443e23be93","Bar-Ilan University, Israel; Facebook AI Research, Israel","Kreuk, F., Bar-Ilan University, Israel; Adi, Y., Bar-Ilan University, Israel; Cisse, M., Facebook AI Research, Israel; Keshet, J., Bar-Ilan University, Israel","Automatic speaker verification systems are increasingly used as the primary means to authenticate costumers. Recently, it has been proposed to train speaker verification systems using end-to-end deep neural models. In this paper, we show that such systems are vulnerable to adversarial example attacks. Adversarial examples are generated by adding a peculiar noise to original speaker examples, in such a way that they are almost indistinguishable, by a human listener. Yet, the generated waveforms, which sound as speaker A can be used to fool such a system by claiming as if the waveforms were uttered by speaker B. We present white-box attacks on a deep end-to-end network that was either trained on YOHO or NTIMIT. We also present two black-box attacks. In the first one, we generate adversarial examples with a system trained on NTIMIT and perform the attack on a system that trained on YOHO. In the second one, we generate the adversarial examples with a system trained using Mel-spectrum features and perform the attack on a system trained using MFCCs. Our results show that one can significantly decrease the accuracy of a target system even when the adversarial examples are generated with different system potentially using different features. © 2018 IEEE.","Adversarial examples; Automatic speaker verification",,,,,,"Kenny, P., Bayesian speaker verification with heavy-tailed priors (2010) Odyssey, p. 14; Dehak, N., Kenny, P.J., Dehak, R., Dumouchel, P., Ouellet, P., Front-end factor analysis for speaker verification (2011) IEEE Transactions on Audio, Speech, and Language Processing, 19 (4), pp. 788-798; Reynolds, D.A., Quatieri, T.F., Dunn, R.B., Speaker verification using adapted Gaussian mixture models (2000) Digital Signal Processing, 10 (1-3), pp. 19-41; Heigold, G., Moreno, I., Bengio, S., Shazeer, N., End-to-end text-dependent speaker verification (2016) ICASSP; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) NIPS; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) CVPR; Amodei, D., Deep speech 2: End-to-end speech recognition in english and Mandarin (2016) ICML; Graves, A., Fernández, S., Gomez, F., Schmidhuber, J., Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural networks (2006) ICML; Adi, Y., Keshet, J., Goldrick, M., Vowel duration measurement using deep neural networks (2015) MLSP. IEEE; Adi, Y., Keshet, J., Cibelli, E., Goldrick, M., Sequence segmentation using joint rnn and structured prediction models (2017) ICASSP; Bahdanau, D., Cho, K., Bengio, Y., (2014) Neural Machine Translation by Jointly Learning to Align and Translate; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Szegedy, C., (2013) Intriguing Properties of Neural Networks; Papernot, N., (2016) Practical Black-box Attacks Against Deep Learning Systems Using Adversarial Examples; Tabacof, P., Valle, E., Exploring the space of adversarial images (2016) IJCNN. IEEE; Shaham, U., Yamada, Y., Negahban, S., (2015) Understanding adversarial training: Increasing local stability of neural nets through robust optimization; Fawzi, A., Moosavi-Dezfooli, S., Frossard, P., Robustness of classifiers: From adversarial to random noise (2016) NIPS; Papernot, N., Distillation as a defense to adversarial perturbations against deep neural networks (2016) SP. IEEE; Cisse, M., Bojanowski, P., Grave, E., Dauphin, Y., Usunier, N., Parseval networks: Improving robustness to adversarial examples (2017) ICML; Cisse, M.M., Adi, Y., Neverova, N., Keshet, J., Houdini: Fooling deep structured visual and speech recognition models with adversarial examples (2017) NIPS; Wu, Z., OthersYamagishi, J., Kinnunen, T., Hanilçi, C., Sahidullah, M., Sizov, A., Evans, N., Todisco, M., Asvspoof: The automatic speaker verification spoofing and countermeasures challenge (2017) IEEE Journal of Selected Topics in Signal Processing, 11 (4), pp. 588-604; Hadid, A., Evans, N., Marcel, S., Fierrez, J., Biometrics systems under spoofing attack: An evaluation methodology and lessons learned (2015) IEEE Signal Processing Magazine, 32 (5), pp. 20-30; Snyder, D., Ghahremani, P., Povey, D., Garcia-Romero, D., Carmiel, Y., Khudanpur, S., Deep neural network-based speaker embeddings for end-to-end speaker verification (2016) SLT; Zhang, S.-X., Chen, Z., Zhao, Y., Li, J., Gong, Y., End-to-end attention based textdependent speaker verification (2016) SLT; Campbell, J.P., Testing with the yoho cd-rom voice verification corpus (1995) ICASSP; Jankowski, C., Kalyanswamy, A., Basson, S., Spitz, J., Ntimit: A phonetically balanced, continuous speech, telephone bandwidth speech database (1990) ICASSP; Griffin, D., Lim, J., Signal estimation from modified short-time fourier transform (1984) IEEE Transactions on Acoustics, Speech, and Signal Processing, 32 (2), pp. 236-243; Snyder, D., Garcia-Romero, D., Povey, D., Khudanpur, S., Deep neural network embeddings for text-independent speaker verification (2017) Proc. Interspeech",,,"The Institute of Electrical and Electronics Engineers Signal Processing Society","Institute of Electrical and Electronics Engineers Inc.","2018 IEEE International Conference on Acoustics, Speech, and Signal Processing, ICASSP 2018","15 April 2018 through 20 April 2018",,139797,15206149,9781538646588,IPROD,,"English","ICASSP IEEE Int Conf Acoust Speech Signal Process Proc",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85054232540
"Xie H., Lv K., Hu C.","57204009862;57195491777;7404569966;","An Effective Method to Generate Simulated Attack Data Based on Generative Adversarial Nets",2018,"Proceedings - 17th IEEE International Conference on Trust, Security and Privacy in Computing and Communications and 12th IEEE International Conference on Big Data Science and Engineering, Trustcom/BigDataSE 2018",,,"8456136","1777","1784",,3,"10.1109/TrustCom/BigDataSE.2018.00268","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054103132&doi=10.1109%2fTrustCom%2fBigDataSE.2018.00268&partnerID=40&md5=815aebf64b61d5d4bebcbcec90bc7e13","School of Software, Beijing Institute of Technology, Beijing, China","Xie, H., School of Software, Beijing Institute of Technology, Beijing, China; Lv, K., School of Software, Beijing Institute of Technology, Beijing, China; Hu, C., School of Software, Beijing Institute of Technology, Beijing, China","In practice, there are few available attack dataset. Although there are many methods that can be used to simulate cyberattacks for attack data, such as using specific tools, writing scripts to simulate the attack scenes, etc.. The disadvantages of those methods are also obvious. Tools developers and script authors need to know professional network security knowledge. As tools are implemented in different ways, users also need to have some expertise. What's more, it may take a long time to generate a large amount of attack data. In this paper, we present some of the existing network attack tools and proposed a method to generate attack data based on generative adversarial network. Using our method you do not need to have a professional network security knowledge, only use some basic network attack data one can generate a large number of attack data in a very short period of time. As network malicious activities become increasingly complex and diverse, network security analysts face serious challenges. Our method also can generate mixed features attack data by setting training data with different attack types. It has high performance. To test the performance of our method, we did a test and found that it took only 160 seconds to generate a million connection records in a PC with 3.7GHz, 4 core CPU and 8G memory. © 2018 IEEE.","attack data; generate attack data; generative adversarial network; simulated attack data","Big data; Computer crime; Data privacy; Adversarial networks; attack data; Different attacks; generate attack data; Large amounts; Malicious activities; Network attack; Simulated attacks; Network security",,,,,"Lee, W., Stolfo, S.J., Mok, K.W., A data mining framework for building intrusion detection models (1999) Security and Privacy, 1999. Proceedings of the 1999 IEEE Symposium On. IEEE, pp. 120-132; Netsniff-ng Toolkit, , http://netsniff-ng.org/, accessed February 4 2018; The Definition of Ddos, , https://www.us-cert.gov/ncas/tips/ST04-015, accessed February 4 2018; http://old.honeynet.org/papers/honeynet/, accessed February 4 2018; Cukier, M., Berthier, R., Panjwani, S., Tan, S., A statistical analysis of attack data to separate attacks (2006) Proceedings of the International Conference on Dependable Systems and Networks, Ser. DSN '06, pp. 383-392. , http://dx.doi.org/10.1109/DSN.2006.9, Washington, DC, USA: IEEE Computer Society; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems 27, pp. 2672-2680. , http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf, Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger, Eds. Curran Associates, Inc; Arjovsky, M., Chintala, S., Bottou, L., (2017) Wasserstein Gan, , arXiv preprint arXiv:1701. 07875; Provos, N., A virtual honeypot framework. (2004) USENIX Security Symposium, 173, pp. 1-14; http://old.honeynet.org/papers/stats/, accessed February 4 2018; (2018), http://lxr.linux.no/linux+v3.2.9/Documentation/networking/packetmmap.txt, accessed February 1; Yu, L., Zhang, W., Wang, J., Seqgan, Y.Y., (2016) Sequence Generative Adversarial Nets with Policy Gradient. Arxiv Preprint, 2 (3), p. 5. , arXiv preprint arXiv:1609. 05473; Arjovsky, M., Bottou, L., (2017) Towards Principled Methods for Training Generative Adversarial Networks, , arXiv preprint arXiv:1701. 04862; Collection of Generative Models, , https://github.com/wiseodd/generative-models, accessed February 4 2018; Mukkamala, S., Janoski, G., Sung, A., Intrusion detection using neural networks and support vector machines (2002) Neural Networks, 2002. IJCNN'02. Proceedings of the 2002 International Joint Conference on, 2, pp. 1702-1707. , IEEE; Kdd Cup 1999 Data, , http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html, accessed February 4 2018; List of Features, , http://kdd.ics.uci.edu/databases/kddcup99/kddcup.names, accessed February 5 2018; http://pandas.pydata.org/, accessed February 1 2018; Corrected Data, , http://kdd.ics.uci.edu/databases/kddcup99/corrected.gz, accessed February 1 2018",,,"Columbia University;IEEE;IEEE Computer Society;IEEE STC Smart Computing;IEEE TCSC;North America Chinese Talents Association","Institute of Electrical and Electronics Engineers Inc.","17th IEEE International Conference on Trust, Security and Privacy in Computing and Communications and 12th IEEE International Conference on Big Data Science and Engineering, Trustcom/BigDataSE 2018","31 July 2018 through 3 August 2018",,139357,,9781538643877,,,"English","Proc. - IEEE Int. Conf. Trust, Secur. Priv. Comput. Commun. IEEE Int. Conf. Big Data Sci. Eng., Trustcom/BigDataSE",Conference Paper,"Final","",Scopus,2-s2.0-85054103132
"Aditya K., Grzonkowski S., Lekhac N.","57210862271;15042271700;57199411126;","Enabling Trust in Deep Learning Models: A Digital Forensics Case Study",2018,"Proceedings - 17th IEEE International Conference on Trust, Security and Privacy in Computing and Communications and 12th IEEE International Conference on Big Data Science and Engineering, Trustcom/BigDataSE 2018",,,"8456041","1250","1255",,12,"10.1109/TrustCom/BigDataSE.2018.00172","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054097267&doi=10.1109%2fTrustCom%2fBigDataSE.2018.00172&partnerID=40&md5=1c61583563eea364ec5166aafd0a1444","Department of Computer Science, University of Auckland, Auckland, 1010, New Zealand; School of Computer Science, University College, Dublin, Ireland","Aditya, K., Department of Computer Science, University of Auckland, Auckland, 1010, New Zealand; Grzonkowski, S.; Lekhac, N., School of Computer Science, University College, Dublin, Ireland","Today, the volume of evidence collected per case is growing exponentially, to address this problem forensics investigators are looking for investigation process with tools built on new technologies like big data, cloud services, and Deep Learning (DL) techniques. Consequently, the accuracy of artifacts found also relies on the performance of techniques used, especially DL models. Recently, Deep Neural Nets (DNN) have achieved state of the art performance in the tasks of classification and recognition. In the context of digital forensics, DNN has been applied in the domains of cybercrime investigation such as child abuse investigations, malware classification, steganalysis and image forensics. However, the robustness of DNN models in the context of digital forensics is never studied before. Hence, in this research, we design and implement a domain-independent Adversary Testing Framework (ATF) to test security robustness of black-box DNN's. By using ATF, we also methodically test a commercially available DNN service used in forensic investigations and bypass the detection, where published methods fail in control settings. © 2018 IEEE.","Adversarial Attacks; Adversary Testing Framework; Deep Learning; Digital Forensics; Testing Forensics tools","Big data; Black-box testing; Computer crime; Computer forensics; Data privacy; Deep learning; Digital forensics; E-learning; Electronic crime countermeasures; Forensic engineering; Malware; Steganography; Adversarial Attacks; Classification and recognition; Cybercrime investigations; Forensics investigators; Forensics tool; Malware classifications; State-of-the-art performance; Testing framework; Deep neural networks",,,,,"Hitchcock, B., Le-Khac, N., Scanlon, M., Tiered forensic methodology model for digital field triage by non-digital evidence specialists (2016) Digital Investigation, 16 (29), pp. S75-S85. , March; Alabdulsalam, S., Schaefer, K., Kechadi, M.-T., Le-Khac, N., (2018) 2018 Internet of Things Forensics: Challenges and Case Study Advances in Digital Forensics XIV, pp. 53-66. , G. Peterson and S. Shenoi (Eds.), Springer, Heidelberg, Germany; Yang Teing, Y., Dehghantanha, A., Raymond Choo, K., (2017) CloudMe Forensics: A Case of Big Data Forensic Investigation, , https://doi.org/10.1002/cpe.4277, Wiley Publisher; Clemens, J., (2015) Automatic Classification of Object Code Using Machine Learning in DFRWS 2015 USA; Linke, A., Le-Khac, N., Control flow change in assembly as a classifier in malware analysis (2016) 4th IEEE International Symposium on Digital Forensics and Security, , AR, USA, April 2016; Usama, M., Qadir, J., Raza, A., Arif, H., Yau, K.-L.A., Elkhatib, Y., Hussain, A., Al-Fuqaha, A., (2017) Unsupervised Machine Learning for Networking: Techniques, Applications and Research Challenges, , ArXiv e-prints 1709. 06599; Bontemps, L., Van Loi, C., McDermott, J., Le-Khac, N., Collective anomaly detection based on long short-term memory recurrent neural networks (2016) Future Data and Security Engineering. FDSE 2016. Lecture Notes in Computer Science, , In: Dang T., Wagner R., Küng J., Thoai N., Takizawa M., Neuhold E. (eds), vol 10018. Springer, Cham; Van Barneveld, M., Le-Khac, N.-A., Kechadi, T., Performance evaluation of a natural language processing approach applied in white collar crime investigation future data and security engineering (2014) Lecture Notes in Computer Science, , vol 8860. Springer, Cham; An Le Khac, N., Markos, S., O'Neill, M., Brabazon, A., Kechadi, M., An investigation into data mining approaches for anti money laundering 2009 (2009) International Conference on Computer Engineering and Applications IPCSIT, 2. , IACSIT Press, Singapore; Zeng, J., Tan, S., Li, B., Huang, J., (2016) Large-scale JPEG Steganalysis Using Hybrid Deep-learning Framework in IS&T International Symposium on Electronic Imaging:Media Watermarking, Security, and Forensics, 3; 'Avino, D.D., Cozzolino, D., Poggi, G., Verdoliva, L., Autoencoder with recurrent neural networks for video forgery detection (2017) IS&T International Symposium on Electronic Imaging:Media Watermarking, Security, and Forensics, 3; Papernot, M., Nicolas Papernot, G., Mc-Daniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples, , arXiv preprint arXiv:1605. 07277; Akhtar, N., Mian, A., (2018) Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey, , ArXiv e-prints 1801. 00553; Barreno, M., Nelson, B., Sears, R., Joseph, A.D., Tygar, J.D., Can machine learning be secure? (2006) Proceedings of the 2006 ACM Symposium on Information, Computer and Communications Security, ACM, pp. 16-25; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I., Tygar, J., Adversarial machine learning (2011) 'Proceedings of the 4th ACM Workshop on Security and Articial Intelligence', ACM, pp. 43-58; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) 'Security and Privacy (SP), 2016 IEEE Symposium On', IEEE, pp. 582-597; Hosseini, H., Xiao, B., Clark, A., Poovendran, R., (2017) Attacking Automatic Video Analysis Algorithms: A Case Study of Google Cloud Video Intelligence API, , arXiv preprint arXiv:1708. 04301; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proceedings of ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540; Yang, C., Wu, Q., Li, H., Chen, Y., (2017) Generative Poisoning Attack Method Against Neural Networks, , ArXiv e-prints 1703. 01340; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses, , arXiv preprint arXiv:1705. 07204; Sundararajan, M., Taly, A., Yan, Q., (2017) Axiomatic Attribution for Deep Networks, , arXiv preprint:1703. 01365; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826; He, K., Zhang, X., Ren, S., Sun, J., (2015) Deep Residual Learning for Image Recognition, , arXiv preprint arXiv:1512. 03385; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition, , http://arxiv.org/abs/1409.1556, CoRR, abs/1409. 1556; Imagenet Adversarial Trained Models, , https://github.com/tensorflow/models/tree/master/research/adv_imagenet_models; Nitin Bhagoji, A., He, W., Li, B., Song, D., (2017) Exploring the Space of Black-box Attacks on Deep Neural Networks, , ArXiv e-prints, arXiv 1712. 09491; Faheem, M., Kechadi, M.-T., Le-Khac, N., The state of the art forensic techniques in mobile cloud environment: A survey (2015) Challenges and Current Trend International Journal of Digital Crime and Forensics, 7 (2), pp. 1-19",,,"Columbia University;IEEE;IEEE Computer Society;IEEE STC Smart Computing;IEEE TCSC;North America Chinese Talents Association","Institute of Electrical and Electronics Engineers Inc.","17th IEEE International Conference on Trust, Security and Privacy in Computing and Communications and 12th IEEE International Conference on Big Data Science and Engineering, Trustcom/BigDataSE 2018","31 July 2018 through 3 August 2018",,139357,,9781538643877,,,"English","Proc. - IEEE Int. Conf. Trust, Secur. Priv. Comput. Commun. IEEE Int. Conf. Big Data Sci. Eng., Trustcom/BigDataSE",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85054097267
"Tomsett R., Widdicombe A., Xing T., Chakraborty S., Julier S., Gurram P., Rao R., Srivastava M.","24779876300;57204013873;57193707997;35721531100;7003972937;20433620000;7403068733;35599699800;","Why the Failure? How Adversarial Examples Can Provide Insights for Interpretable Machine Learning",2018,"2018 21st International Conference on Information Fusion, FUSION 2018",,,"8455710","838","845",,8,"10.23919/ICIF.2018.8455710","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054094188&doi=10.23919%2fICIF.2018.8455710&partnerID=40&md5=c953398bd9494eddd1249df00f2db72e","IBM Research, IBM Emerging Technology, Hursley, United Kingdom; UCL, Dept of Computer Science, London, United Kingdom; UCLA, Electrical Computer Engineering Dept, Los Angeles, United States; IBM Research, Yorktown, United States; Army Reseach Laboratory, Booz Allen Hamilton, Adelphi, United States; Army Research Laboratory, Adelphi, United States; Electrical Computer Engineering Dept, UCLA, Computer Science Dept, Los Angeles, United States","Tomsett, R., IBM Research, IBM Emerging Technology, Hursley, United Kingdom; Widdicombe, A., UCL, Dept of Computer Science, London, United Kingdom; Xing, T., UCLA, Electrical Computer Engineering Dept, Los Angeles, United States; Chakraborty, S., IBM Research, Yorktown, United States; Julier, S., UCL, Dept of Computer Science, London, United Kingdom; Gurram, P., Army Reseach Laboratory, Booz Allen Hamilton, Adelphi, United States; Rao, R., Army Research Laboratory, Adelphi, United States; Srivastava, M., Electrical Computer Engineering Dept, UCLA, Computer Science Dept, Los Angeles, United States","Recent advances in Machine Learning (ML) have profoundly changed many detection, classification, recognition and inference tasks. Given the complexity of the battlespace, ML has the potential to revolutionise how Coalition Situation Understanding is synthesised and revised. However, many issues must be overcome before its widespread adoption. In this paper we consider two - interpretability and adversarial attacks. Interpretability is needed because military decision-makers must be able to justify their decisions. Adversarial attacks arise because many ML algorithms are very sensitive to certain kinds of input perturbations. In this paper, we argue that these two issues are conceptually linked, and insights in one can provide insights in the other. We illustrate these ideas with relevant examples from the literature and our own experiments. © 2018 ISIF","adversarial examples; adversarial machine learning; AI alignment; deep learning; explainable AI; internet of battlefield things; interpretability; interpretable machine learning","Artificial intelligence; Decision making; Information fusion; adversarial examples; Battlespace; Decision makers; Input perturbation; Interpretability; Ml algorithms; Situation understanding; Synthesised; Deep learning",,,,,"Goodfellow, I., Bengio, Y., Courville, A., (2016) Deep Learning, , http://www.deeplearningbook.org, MIT Press; Chakraborty, S., Preece, A., Alzantot, M., Xing, T., Braines, D., Srivastava, M., Deep learning for situational understanding 2017 20th International Conference on Information Fusion (Fusion), pp. 1-8; Kott, A., Swami, A., West, B.J., The internet of battle things (2016) Computer, 49 (12), pp. 70-75; Suri, N., Tortonesi, M., Michaelis, J., Budulas, P., Benincasa, G., Russell, S., Stefanelli, C., Winkler, R., Analyzing the applicability of internet of things to the battlefield environment (2016) Military Communications and Information Systems (ICMCIS), 2016 International Conference On. IEEE, pp. 1-8; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks; Yuan, X., He, P., Zhu, Q., Bhat, R.R., Li, X., (2017) Adversarial Examples: Attacks and Defenses for Deep Learning; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I., Tygar, J.D., Adversarial machine learning (2011) Proceedings of the 4th ACM Workshop on Security and Artificial Intelligence, Ser. AISec '11, pp. 43-58. , http://doi.acm.org/10.1145/2046684.2046692, New York, NY, USA: ACM; Chakraborty, S., Preece, A., Alzantot, M., Xing, T., Braines, D., Srivastava, M., Deep learning for situational understanding (2017) Information Fusion (FUSION), 2017 20th International Conference On. IEEE; Endsley, M.R., Toward a theory of situation awareness in dynamic systems (1995) Human Factors, 37 (1), pp. 32-64; Chakraborty, S., Tomsett, R., Raghavendra, R., Harborne, D., Alzantot, M., Cerutti, F., Srivastava, M., Gurram, P., Interpretability of deep learning models: A survey of results (2017) IEEE Smart World Congress; Miller, T., (2017) Explanation in Artificial Intelligence: Insights from the Social Sciences; Lipton, Z.C., (2016) The Mythos of Model Interpretability, , CoRR Abs/1606. 03490; Harborne, D., Willis, C., Tomsett, R., Preece, A., Integrating learning and reasoning services for explainable information fusion (2018) International Conference on Pattern Recognition and Artificial Intelligence, , (to appear); Doshi-Velez, F., Kim, B., (2017) Towards A Rigorous Science of Interpretable Machine Learning; Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proceedings of the IEEE, 86 (11), pp. 2278-2324; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images; Deng, J., Dong, W., Socher, R., Jia Li, L., Li, K., Fei-Fei, L., Imagenet: A large-scale hierarchical image database (2009) CVPR; Dhurandhar, A., Iyengar, V., Luss, R., Shanmugam, K., (2017) A Formal Framework to Characterize Interpretability of Procedures; Kapoor, A., Grauman, K., Urtasun, R., Darrell, T., Active learning with Gayesian processes for object categorization (2007) 2007 IEEE 11th International Conference on Computer Vision, pp. 1-8. , Oct; Guo, C., Pleiss, G., Sun, Y., Weinberger, K.Q., On calibration of modern neural networks (2017) Proceedings of the 34th International Conference on Machine Learning, Ser. Proceedings of Machine Learning Research, 70, pp. 1321-1330. , D. Precup and Y. W. Teh, Eds, 06-11 Aug; Niculescu-Mizil, A., Caruana, R., Predicting good probabilities with supervised learning (2005) Proceedings of the 22Nd International Conference on Machine Learning, Ser. ICML '05, pp. 625-632; Rasmussen, C.E., Williams, C.K.I., (2006) Gayesian Processes for Machine Learning, , The MIT Press; Humphrey, P.T., Masel, J., Outcome orientation: A misconception of probability that harms medical research and practice (2016) Perspectives in Biology and Medicine, 59 (2), pp. 147-155; Dalvi, N., Domingos, P., Mausam, Sanghai, S., Verma, D., Adversarial classification (2004) Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Ser. KDD '04, pp. 99-108; Lowd, D., Meek, C., Adversarial learning (2005) Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining, Ser. KDD '05, pp. 641-647; Biggio, B., Roli, F., (2017) Wild Patterns: Ten Years after the Rise of Adversarial Machine Learning; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Koh, P.W., Liang, P., (2017) Understanding Black-box Predictions Via Influence Functions; Kos, J., Fischer, I., Song, D., (2017) Adversarial Examples for Generative Models; Lin, Y.-C., Hong, Z.-W., Liao, Y.-H., Shih, M.-L., Liu, M.-Y., Sun, M., (2017) Tactics of Adversarial Attack on Deep Reinforcement Learning Agents; Evtimov, I., Eykholt, K., Fernandes, E., Kohno, T., Li, B., Prakash, A., Rahmati, A., Song, D., (2017) Robust Physical-world Attacks on Deep Learning Models; Sitawarin, C., Bhagoji, A.N., Mosenia, A., Mittal, P., Chiang, M., (2018) Rogue Signs: Deceiving Traffic Sign Recognition with Malicious Ads and Logos; Brown, T.B., Man, D., Roy, A., Abadi, M., Gilmer, J., (2017) Adversarial Patch; Athalye, A., Engstrom, L., Ilyas, A., Kwok, K., (2017) Synthesizing Robust Adversarial Examples; Lu, J., Sibai, H., Fabry, E., Forsyth, D., (2017) Standard Detectors Aren't (Currently) Fooled by Physical Adversarial Stop Signs; Google Vision API Demo, , https://cloud.google.com/vision/; IBM Watson Visual Recognition API Demo, , https://www.ibm.com/watson/services/visual-recognition/demo/; Microsoft Computer Vision API Demo, , https://azure.microsoft.com/en-gb/services/cognitiveservices/computer-vision/; Alzantot, M., Balaji, B., Srivastava, M., (2018) Did You Hear That. Adversarial Examples Against Automatic Speech Recognition; Zhang, R., Zhu, Q., Secure and resilient distributed machine learning under adversarial environments (2015) 2015 18th International Conference on Information Fusion (Fusion), pp. 644-651. , July; Zhang, R., Zhu, Q., A game-theoretic analysis of label flipping attacks on distributed support vector machines (2017) 2017 51st Annual Conference on Information Sciences and Systems (CISS), pp. 1-6. , March; Chen, Y., Su, L., Xu, J., (2017) Distributed Statistical Machine Learning in Adversarial Settings: Byzantine Gradient Descent; Ritter, S., Barrett, D.G.T., Santoro, A., Botvinick, M.M., Cognitive psychology for deep neural networks: A shape bias case study (2017) Proceedings of the 34th International Conference on Machine Learning, Ser. Proceedings of Machine Learning Research, 70, pp. 2940-2949. , D. Precup and Y. W. Teh, Eds. PMLR; Dong, Y., Su, H., Zhu, J., Bao, F., (2017) Towards Interpretable Deep Neural Networks by Leveraging Adversarial Examples; Ross, A.S., Doshi-Velez, F., (2017) Improving the Adversarial Robustness and Interpretability of Deep Neural Networks by Regularizing Their Input Gradients; Simonyan, K., Vedaldi, A., Zisserman, A., (2013) Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps, , Dec; Binder, A., Montavon, G., Bach, S., Müller, K., Samek, W., (2016) Layer-wise Relevance Propagation for Neural Networks with Local Renormalization Layers, , CoRR Abs/1604. 00825; Ribeiro, M.T., Singh, S., Guestrin, C., Why should i trust you: Explaining the predictions of any classifier (2016) Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, pp. 1135-1144; Montavon, G., Lapuschkin, S., Binder, A., Samek, W., Müller, K.-R., Explaining nonlinear classification decisions with deep taylor decomposition (2017) Pattern Recognition, 65, pp. 211-222; Carlini, N., Wagner, D., (2016) Towards Evaluating the Robustness of Neural Networks; Kindermans, P.-J., Hooker, S., Adebayo, J., Alber, M., Schutt, K.T., Dahne, S., Erhan, D., Kim, B., (2017) The (Un)reliability of Saliency Methods, , CoRR, vol. Abs/1711. 00867; Grosse, K., Pfaff, D., Smith, M.T., Backes, M., (2017) How Wrong Am I. Studying Adversarial Examples and Their Impact on Uncertainty in Gayesian Process Machine Learning Models; Rawat, M.-I.N.A., Wistuba, M., Harnessing model uncertainty for detecting adversarial examples (2017) NIPS Workshop on Bayesian Deep Learning; Bradshaw, J., De Matthews, A.G.G., Ghahramani, Z., (2017) Adversarial Examples, Uncertainty, and Transfer Testing Robustness in Gayesian Process Hybrid Deep Networks",,,"DarkTrace;ISIF;Systems and Technolgy Research (STR)","Institute of Electrical and Electronics Engineers Inc.","21st International Conference on Information Fusion, FUSION 2018","10 July 2018 through 13 July 2018",,139346,,9780996452762,,,"English","Int. Conf. Inf. Fusion, FUSION",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85054094188
"Agadakos I., Ciocarlie G.F., Copos B., Lepoint T., Lindqvist U., Locasto M.E., Michaelis J.R.","57192717947;56021579900;57190385043;54389471100;7003456067;14024637200;35409908000;","Risks and Benefits of Side-Channels in Battlefields",2018,"2018 21st International Conference on Information Fusion, FUSION 2018",,,"8455283","2290","2297",,2,"10.23919/ICIF.2018.8455283","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054071262&doi=10.23919%2fICIF.2018.8455283&partnerID=40&md5=5ecac1e4fb06f4f4bc74e6ec07511a3b","Stevens Institute of Technology, Hoboken, United States; SRI International, New York, United States; SRI International, Menlo Park, United States; U.S. Army Research Laboratory, Adelphi, United States","Agadakos, I., Stevens Institute of Technology, Hoboken, United States; Ciocarlie, G.F., SRI International, New York, United States; Copos, B., SRI International, Menlo Park, United States; Lepoint, T., SRI International, New York, United States; Lindqvist, U., SRI International, Menlo Park, United States; Locasto, M.E., SRI International, New York, United States; Michaelis, J.R., U.S. Army Research Laboratory, Adelphi, United States","As networked devices and applications make their way into our battlefields, their behaviors need to take into account these highly adversarial cyber-physical environments. On the dark side of the spectrum, undesired side-channels put our sensitive data at risk; hence, side-channel-protected devices and implementations should be promoted. On the bright side of the spectrum, side-channel analysis may be correlated with observed and hidden events, and enable causality inference and watermarking. This paper describes some unique risks and benefits that may be obtained from side-channel analyses in battlefields. © 2018 ISIF","causality inference; Side-channel analysis; side-channel attacks; watermarking","Digital watermarking; Information fusion; causality inference; Cyber physicals; Networked devices; Sensitive datas; Side-channel; Side-channel analysis; Side channel attack",,,,,"Abdelzaher, T., Ayanian, N., Basar, T., Diggavi, S., Diesner, J., Ganesan, D., Govindan, R., Veeravalli, V., Will distributed computing revolutionize peace the emergence of battlefield iot (2018) IEEE International Conference on Distributed Computing Systems (ICDCS); Agadakos, I., Chen, C., Campanelli, M., Anantharaman, P., Hasan, M., Copos, B., Lepoint, T., Lindqvist, U., Jumping the air gap: Modeling cyber-physical attack paths in the internet-of-things (2017) Proceedings of the 2017 Workshop on Cyber-Physical Systems Security and PrivaCy, CPS '17, pp. 37-48; Agadakos, I., Ciocarlie, G.F., Copos, B., Lepoint, T., Locasto, M., Lindqvist, U., Butterfly effect: Causality from chaos in the iot (2018) IoTSec; Abdullah Al Faruque, M., Rokka Chhetri, S., Canedo, A., Wan, J., Acoustic side-channel attacks on additive manufacturing systems (2016) Proceedings of the 7th International Conference on Cyber-Physical Systems, ICCPS '16, pp. 191-1910; Bacelar Almeida, J., Barbosa, M., Barthe, G., Dupressoir, F., Emmi, M., Verifying constant-time implementations (2016) USENIX Security Symposium, pp. 53-70. , USENIX Association; Anderson, R.J., (2010) Security Engineering: A Guide to Building Dependable Distributed Systems, , John Wiley & Sons; Andrea, I., Chrysostomou, C., Hadjichristofi, G.C., Internet of things: Security vulnerabilities and challenges (2015) ISCC, pp. 180-187. , IEEE Computer Society; Aumann, Y., Lindell, Y., Security against covert adversaries: Efficient protocols for realistic adversaries (2010) J. Cryptology, 23 (2), pp. 281-343; Barthe, G., Beläd, S., Dupressoir, F., Fouque, P., Grégoire, B., Strub, P., Verified proofs of higherorder masking (2015) EUROCRYPT (1), Volume 9056 of Lecture Notes in Computer Science, pp. 457-485. , Springer; Becker, G.T., Kasper, M., Moradi, A., Paar, C., Sidechannel based watermarks for integrated circuits (2010) HOST, pp. 30-35. , IEEE Computer Society; Beläd, S., Security of cryptosystems against power-analysis attacks (2015) (Sécurité des Cryptosystèmes Contre les Attaques Par Analyse de Courant)., , PhD thesis, école Normale Supérieure, Paris, France; Bossuet, L., Hely, D., Salware: Salutary hardware to design trusted ic (2013) Workshop on Trustworthy Manufacturing and Utilization of Secure Devices, TRUDEVICE 2013; Bühlmann, P., Wyner, A.J., Variable length markov chains (1999) The Annals of Statistics, 27 (2), pp. 480-513; Compton, M., Barnaghi, P., Bermudez, L., Garcia-Castro, R., Corcho, O., Cox, S., Graybeal, J., The ssn ontology of the w3c semantic sensor network incubator group (2012) Web Semantics: Science, Services and Agents on the World Wide Web, 17, pp. 25-32; Copos, B., Levitt, K., Bishop, M., Rowe, J., Is anybody home inferring activity from smart home network traffic (2016) Security and Privacy Workshops (SPW), 2016 IEEE, pp. 245-251. , IEEE; Durvaux, F., Gérard, B., Kerckhof, S., Koeune, F., Standaert, F., Intellectual property protection for integrated systems using soft physical hash functions (2012) WISA, Volume 7690 of Lecture Notes in Computer Science, pp. 208-225. , Springer; Junaid Farooq, M., Zhu, Q., Secure and reconfigurable network design for critical information dissemination in the internet of battlefield things (iobt) (2017) WiOpt, pp. 1-8. , IEEE; Ferrigno, J., Hlavác, M., When aes blinks: Introducing optical side channel (2008) IET Information Security, 2 (3), pp. 94-98; Freire, J., Koop, D., Santos, E., Silva, C.T., Provenance for computational tasks: A survey (2008) Computing in Science and Engineering, 10 (3); Gandolfi, K., Mourtel, C., Olivier, F., Electromagnetic analysis: Concrete results (2001) CHES, Volume 2162 of Lecture Notes in Computer Science, pp. 251-261. , Springer; Genkin, D., Shamir, A., Tromer, E., Rsa key extraction via low-bandwidth acoustic cryptanalysis (2014) CRYPTO (1), Volume 8616 of Lecture Notes in Computer Science, pp. 444-461. , Springer; Hameed, K., Haseeb, J., Tayyab, M., Junaid, M., Bin Maqsood, T., Naqvi, M., Secure provenance in wireless sensor networks-a survey of provenance schemes (2017) Proceedings of IEEE International Conference on Communication, Computing and Digital Systems (C-CODE), pp. 11-16; Hussein, J., Moreau, L., Sassone, V., Obscuring provenance confidential information via graph transformation (2015) Proceedings of IFIP International Conference on Trust Management, pp. 109-125; inverse. Fingerbank 2017; Ishai, Y., Prabhakaran, M., Sahai, A., Wagner, D.A., Private circuits II: Keeping secrets in tamperable circuits (2006) EUROCRYPT, Volume 4004 of Lecture Notes in Computer Science, pp. 308-327. , Springer; Joye, M., Basics of side-channel analysis (2009) Cryptographic Engineering, pp. 365-380. , Springer; Kerckhof, S., Durvaux, F., Standaert, F., Gérard, B., Intellectual property protection for FPGA designs withsoft physical hash functions: First experimental results (2013) Hardware-Oriented Security and Trust (HOST), 2013 IEEE International Symposium on, pp. 7-12. , IEEE; Kocher, P., Genkin, D., Gruss, D., Haas, W., Hamburg, M., Lipp, M., Mangard, S., Yarom, Y., (2018) Spectre Attacks: Exploiting Speculative Execution; Kocher, P.C., Timing attacks on implementations of diffie-hellman, rsa, dss, and other systems (1996) CRYPTO, Volume 1109 of Lecture Notes in Computer Science, pp. 104-113. , Springer; Kocher, P.C., Jaffe, J., Jun, B., Differential power analysis (1999) CRYPTO, Volume 1666 of Lecture Notes in Computer Science, pp. 388-397. , Springer; Kott, A., Swami, A., West, B., The internet of battlefield things (2015) Computer, 49 (12), pp. 70-75; (2017) Internet of Battlefield Things (IoBT) Collaborative Research Alliance (CRA), , U. S. Army Research Laboratory; Liang, X., Shetty, S., Tosh, D., Kamhoua, C., Kwiat, K., Njilla, L., Provchain: A blockchain-based data provenance architecture in cloud environment with enhanced privacy and availability (2017) Proceedings of the 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing, pp. 468-477; Lindqvist, U., Neumann, P.G., The future of the internet of things (2017) Commun. ACM, 60 (2), pp. 26-30; Lipp, M., Schwarz, M., Gruss, D., Prescher, T., Haas, W., Mangard, S., Kocher, P., Hamburg, M., (2018) Meltdown; Mangard, S., Oswald, E., Popp, T., (2007) Power Analysis Attacks-revealing the Secrets of Smart Cards, , Springer; Marchand, C., Bossuet, L., Jung, E., IP watermark verification based on power consumption analysis (2014) SoCC, pp. 330-335. , IEEE; Iot devices top a long list of 2017 security threats (2017) Medsphere; Miles, S., Groth, P., Branco, M., Moreau, L., The requirements of using provenance in e-science experiments (2008) IET Information Security, 10 (3); Missier, P., Belhajjame, K., Cheney, J., The w3c prov family of specifications for modelling provenance metadata (2013) Proceedings of the 16th International Conference on Extending Database Technology, pp. 773-776; Sheikh, U., Khan, A., Ahmed, B., Waheed, A., Hameed, A., Provenance inference techniques: Taxonomy, comparative analysis and design challenges (2018) Journal of Network and Computer Applications, , In-Press; Missier, P., Chirigati, F., Wei, Y., Koop, D., Dey, S., Provenance storage, querying, and visualization in pbase (2015) Proceedings of International Provenance and Annotation Workshop (IPAW), 8628, p. 239; Oh, S.R., Kim, Y.G., Security requirements analysis for the iot (2017) 2017 International Conference on Platform Technology and Service (PlatCon), pp. 1-6; Pornin, T., Constant-time Toolkit, 2018, , GitHub; Quisquater, J., Samyde, D., Electromagnetic analysis (ema): Measures and counter-measures for smart cards (2001) E-smart, Volume 2140 of Lecture Notes in Computer Science, pp. 200-210. , Springer; Reid, J., Manuel González Nieto, J., Tang, T., Senadji, B., Detecting relay attacks with timing-based protocols (2007) AsiaCCS, pp. 204-213. , ACM; Reparaz, O., Balasch, J., Verbauwhede, I., Dude, is my code constant time (2017) DATE, pp. 1697-1702. , IEEE; Rohatgi, P., Improved techniques for side-channel analysis (2009) Cryptographic Engineering, pp. 381-406. , Springer; Ron, D., Singer, Y., Tishby, N., Learning probabilistic automata with variable memory length (1994) Proceedings of the Seventh Annual Conference on Computational Learning Theory, pp. 35-46. , ACM; Sakiyama, K., Kasuya, M., Machida, T., Matsubara, A., Kuai, Y., Hayashi, Y., Mizuki, T., Nagata, M., Physical authentication using side-channel information (2016) Information and Communication Technology (ICoICT), 2016 4th International Conference on, pp. 1-6. , IEEE; Petrovich Skorobogatov, S., (2005) Semi-invasive Attacks: A New Approach to Hardware Security Analysis; Suri, N., Tortonesi, M., Michaelis, J., Budulas, P., Benincasa, G., Russell, S., Stefanelli, C., Winkler, R., Analyzing the applicability of internet of things to the battlefield environment (2016) Military Communications and Information Systems (ICMCIS), 2016 International Conference on, pp. 1-8. , IEEE; Vermesan, O., Friess, P., (2014) Internet of Things-from Research and Innovation to Market Deployment, , Aalborg: River Publishers; Weber, R.H., Internet of things-new security and privacy challenges (2010) Computer Law & Security Review, 26 (1), pp. 23-30; Ziener, D., Teich, J., Power signature watermarking of IP cores for FPGAS (2008) Signal Processing Systems, 51 (1), pp. 123-136",,,"DarkTrace;ISIF;Systems and Technolgy Research (STR)","Institute of Electrical and Electronics Engineers Inc.","21st International Conference on Information Fusion, FUSION 2018","10 July 2018 through 13 July 2018",,139346,,9780996452762,,,"English","Int. Conf. Inf. Fusion, FUSION",Conference Paper,"Final","",Scopus,2-s2.0-85054071262
"Ma L., Juefei-Xu F., Zhang F., Sun J., Xue M., Li B., Chen C., Su T., Li L., Liu Y., Zhao J., Wang Y.","55479591700;54911989900;57188876324;57204647388;56890437900;57188689924;57191225906;55749546700;56438149900;56911879800;35786932000;55978208400;","DeepGauge: Multi-granularity testing criteria for deep learning systems",2018,"ASE 2018 - Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering",,,,"120","131",,194,"10.1145/3238147.3238202","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056490436&doi=10.1145%2f3238147.3238202&partnerID=40&md5=fb27d226f969e544a090a66b0dd16408","Harbin Institute of Technology, China; Carnegie Mellon University, United States; Nanyang Technological University, Singapore; Kyushu University, Japan; University of Illinois at Urbana-Champaign, United States; Monash University, Australia","Ma, L., Harbin Institute of Technology, China, Nanyang Technological University, Singapore; Juefei-Xu, F., Carnegie Mellon University, United States; Zhang, F., Nanyang Technological University, Singapore; Sun, J., Kyushu University, Japan; Xue, M., Nanyang Technological University, Singapore; Li, B., University of Illinois at Urbana-Champaign, United States; Chen, C., Monash University, Australia; Su, T., Nanyang Technological University, Singapore; Li, L., Monash University, Australia; Liu, Y., Nanyang Technological University, Singapore; Zhao, J., Kyushu University, Japan; Wang, Y., Harbin Institute of Technology, China","Deep learning (DL) defines a new data-driven programming paradigm that constructs the internal system logic of a crafted neuron network through a set of training data. We have seen wide adoption of DL in many safety-critical scenarios. However, a plethora of studies have shown that the state-of-the-art DL systems suffer from various vulnerabilities which can lead to severe consequences when applied to real-world applications. Currently, the testing adequacy of a DL system is usually measured by the accuracy of test data. Considering the limitation of accessible high quality test data, good accuracy performance on test data can hardly provide confidence to the testing adequacy and generality of DL systems. Unlike traditional software systems that have clear and controllable logic and functionality, the lack of interpretability in a DL system makes system analysis and defect detection difficult, which could potentially hinder its real-world deployment. In this paper, we propose DeepGauge, a set of multi-granularity testing criteria for DL systems, which aims at rendering a multi-faceted portrayal of the testbed. The in-depth evaluation of our proposed testing criteria is demonstrated on two well-known datasets, five DL systems, and with four state-of-the-art adversarial attack techniques against DL. The potential usefulness of DeepGauge sheds light on the construction of more generic and robust DL systems. © 2018 Association for Computing Machinery.","Deep learning; Deep neural networks; Software testing; Testing criteria","Computer circuits; Deep learning; Deep neural networks; Neural networks; Petroleum reservoir evaluation; Safety engineering; Depth evaluations; High Quality Test; Multi-granularity; Programming paradigms; Real world deployment; State of the art; Testing adequacies; Testing criteria; Software testing",,,,,"Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Zheng, X., TensorFlow: A system for large-scale machine learning (2016) 12th USENIX Symposium on Operating Systems Design and Implementation (OSDI 16), pp. 265-283; Ammann, P., Offutt, J., (2008) Introduction to Software Testing, , 1 ed.). Cambridge University Press, New York, NY, USA; Artho, C., Gros, Q., Rousset, G., Banzai, K., Ma, L., Kitamura, T., Hagiya, M., Yamamoto, M., Model-based API testing of Apache zookeeper (2017) 2017 IEEE Int. Conf. on Software Testing, Verification and Validation (ICST 2017), pp. 288-298. , Tokyo, Japan; Athalye, A., Carlini, N., Wagner, D., Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples (2018) Proceedings of The 35th International Conference on Machine Learning, ICML 2018, , https://arxiv.org/abs/1802.00420; Baudry, B., Monperrus, M., The multiple facets of software diversity: Recent developments in year 2000 and beyond (2015) ACM Computing Surveys (CSUR), 48 (1), p. 16. , 2015; Brendel, W., Rauber, J., Bethge, M., Decision-based adversarial attacks: Reliable attacks against black-box machine learning models (2018) ICLR; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) Proceedings of The 10th ACM Workshop on Artificial Intelligence and Security, pp. 3-14. , ACM; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy, pp. 39-57; Chen, S., Xue, M., Fan, L., Hao, S., Xu, L., Zhu, H., Li, B., Automated poisoning attacks and defenses in malware detection systems: An adversarial machine learning approach (2018) Computers & Security, 73 (2018), pp. 326-344; Chollet, F., (2015) Keras, , https://github.com/fchollet/keras; Ciregan, D., Meier, U., Schmidhuber, J., Multi-column deep neural networks for image classification (2012) CVPR, pp. 3642-3649; Ciresan, D., Giusti, A., Gambardella, L.M., Schmidhuber, J., Deep neural networks segment neuronal membranes in electron microscopy images (2012) NIPS, pp. 2843-2851; Dhillon, G.S., Azizzadenesheli, K., Bernstein, J.D., Kossaifi, J., Khanna, A., Lipton, Z.C., Anandkumar, A., Stochastic activation pruning for robust adversarial defense (2018) ICLR; Dias Neto, A.C., Subramanyan, R., Vieira, M., Travassos, G.H., A survey on model-based testing approaches: A systematic review (2007) Proc. 1st ACM Int'L Workshop on Empirical Assessment of Software Engineering Languages and Technologies, pp. 31-36; (2009) Space Engineering - Software, , ECSS; Feldt, R., Torkar, R., Gorschek, T., Afzal, W., Searching for cognitively diverse tests: Towards universal test diversity metrics (2008) Proceedings of The 2008 IEEE International Conference on Software Testing Verification and Validation Workshop, pp. 178-186. , IEEE; Fraser, G., Arcuri, A., Whole test suite generation (2013) IEEE Trans. Softw. Eng., 39 (2), pp. 276-291. , https://doi.org/10.1109/TSE.2012.14, Feb. 2013; Galloway, A., Taylor, G.W., Moussa, M., Attacking binarized neural networks (2018) ICLR; Goodfellow, I., Papernot, N., (2017) The Challenge of Verification and Testing of Machine Learning; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR; (2016) A Google Self-Driving Car Caused A Crash for The First Time, , https://www.theverge.com/2016/2/29/11134344/google-self-driving-car-crash-report; Gopinath, D., Katz, G., Pasareanu, C.S., Barrett, C., DeepSafe: A data-driven approach for checking adversarial robustness in neural networks (2018) International Symposium on Automated Technology for Verification and Analysis (ATVA), , 2018; Guo, C., Rana, M., Cisse, M., Van Der Maaten, L., Countering adversarial images using input transformations (2018) ICLR; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) CVPR, pp. 770-778; He, W., Li, B., Song, D., Decision boundary analysis of adversarial examples (2018) ICLR; Hinton, G., Deng, L., Yu, D., Dahl, G.E., Mohamed, A.-R., Jaitly, N., Senior, A., Sainath, T.N., Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups (2012) IEEE Signal Processing Magazine, 29 (6), pp. 82-97. , 2012; Jia, Y., Harman, M., An analysis and survey of the development of mutation testing (2011) IEEE Trans. Softw. Eng., 37 (5), pp. 649-678. , Sept. 2011; Katz, G., Barrett, C.W., Dill, D.L., Julian, K., Kochenderfer, M.J., Reluplex: An efficient SMT solver for verifying deep neural networks (2017) International Conference on Computer Aided Verification (CAV), , 2017; Hayhurst Kelly, J., Veerhusen Dan, S., Chilenski John, J., Rierson Leanna, K., (2001) A Practical Tutorial on Modified Condition/Decision Coverage, , Technical Report; Kim, B., Wattenberg, M., Gilmer, J., Cai, C., Wexler, J., Viegas, F., Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (TCAV) (2018) International Conference on Machine Learning, pp. 2673-2682; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2017) ICLR, , 2017; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324. , 1998; Ma, L., Artho, C., Zhang, C., Sato, H., Gmeiner, J., Ramler, R., GRT: Program-analysis-guided random testing (T) (2015) Proceedings of The 2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE) (ASE'15), pp. 212-223. , https://doi.org/10.1109/ASE.2015.49, IEEE Computer Society, Washington, DC, USA; Ma, L., Zhang, F., Sun, J., Xue, M., Li, B., Juefei-Xu, F., Xie, C., Wang, Y., Deepmutation: Mutation testing of deep learning systems (2018) International Symposium on Software Reliability Engineering (ISSRE), , 2018; Ma, L., Zhang, F., Xue, M., Li, B., Liu, Y., Zhao, J., Wang, Y., (2018) Combinatorial Testing for Deep Learning Systems, , arXiv preprint 2018; Myers, G.J., Sandler, C., Badgett, T., (2011) The Art of Software Testing, , 3rd ed.). Wiley Publishing; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387. , IEEE; Pei, K., Cao, Y., Yang, J., Jana, S., Deepxplore: Automated whitebox testing of deep learning systems (2017) Proceedings of The 26th Symposium on Operating Systems Principles, pp. 1-18; Pei, K., Cao, Y., Yang, J., Jana, S., Towards practical verification of machine learning: The case of computer vision systems (2017) CoRR, , http://arxiv.org/abs/1712.01785, abs/1712.01785 2017; Pulina, L., Tacchella, A., An abstraction-refinement approach to verification of artificial neural networks (2010) International Conference on Computer Aided Verification, pp. 243-257. , Springer; Raghunathan, A., Steinhardt, J., Liang, P., Certified defenses against adversarial examples (2018) ICLR; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Fei-Fei, L., ImageNet large scale visual recognition challenge (2015) IJCV, 115 (3), pp. 211-252. , 2015; Samangouei, P., Kabkab, M., Chellappa, R., Defense-Gan: Protecting classifiers against adversarial attacks using generative models (2018) ICLR; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) ICLR, , 2015; Song, Y., Kim, T., Nowozin, S., Ermon, S., Kushman, N., PixelDefend: Leveraging generative models to understand and defend against adversarial examples (2018) ICLR; Su, T., Wu, K., Miao, W., Pu, G., He, J., Chen, Y., Su, Z., A survey on data-flow testing (2017) ACM Computing Surveys (CSUR), 50 (1), p. 35. , Article March 2017; Sun, Y., Huang, X., Kroening, D., (2018) Testing Deep Neural Networks, , ArXiv e-prints March 2018; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) ICLR; Tian, Y., Pei, K., Jana, S., Ray, B., DeepTest: Automated testing of deep-neural-network-driven autonomous cars (2018) International Conference on Software Engineering (ICSE), , ACM; Drachsler-Cohen, D., Swarat, P.T., Martin, C., Gehr, V.T., Mirman, M., AI2: Safety and robustness certification of neural networks with abstract interpretation (2018) IEEE Symposium on Security and Privacy (SP); Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2018) ICLR; Utting, M., Legeard, B., (2007) Practical Model-Based Testing: A Tools Approach, , Morgan Kaufmann Publishers Inc., San Francisco, CA, USA; Wicker, M., Huang, X., Kwiatkowska, M., Feature-guided black-box safety testing of deep neural networks (2018) International Conference on Tools and Algorithms for The Construction and Analysis of Systems (TACAS), , 2018; Witten, I.H., Frank, E., Hall, M.A., Pal, C.J., (2016) Data Mining: Practical Machine Learning Tools and Techniques, , Morgan Kaufmann; Xiao, C., Zhu, J.-Y., Li, B., He, W., Liu, M., Song, D., Spatially transformed adversarial examples (2018) ICLR; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., Mitigating adversarial effects through randomization (2018) ICLR; Xu, W., Evans, D., Qi, Y., Feature squeezing: Detecting adversarial examples in deep neural networks (2018) Network and Distributed System Security Symposium (NDSS); Zhang, F., Leitner, J., Milford, M., Upcroft, B., Corke, P., (2015) Towards Vision-Based Deep Reinforcement Learning for Robotic Motion Control, , 2015; Zhang, M., Zhang, Y., Zhang, L., Liu, C., Khurshid, S., (2018) DeepRoad: GAN-Based Metamorphic Autonomous Driving System Testing, , e-prints Feb. 2018; Zhao, Z., Dua, D., Singh, S., Generating natural adversarial examples (2018) ICLR; Zhou, B., Sun, Y., Bau, D., Torralba, A., (2018) Revisiting The Importance of Individual Units in CNNs Via Ablation, , arXiv preprint 2018; Zhu, H., Hall, P.A.V., May, J.H.R., Software unit test coverage and adequacy (1997) ACM Computing Survey, 29 (4), pp. 366-427. , Dec. 1997","Ma, L.; Harbin Institute of TechnologyChina; email: malei@hit.edu.cn","Kastner C.Huchard M.Fraser G.","Berger Levrault;et al.;Huawei;Inria;Mobioos;Toyota InfoTechnology Center","Association for Computing Machinery, Inc","33rd IEEE/ACM International Conference on Automated Software Engineering, ASE 2018","3 September 2018 through 7 September 2018",,140337,,9781450359375,,,"English","ASE - Proc. ACM/IEEE Int. Conf. Autom. Soft. Eng.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85056490436
"Wachter J., Rass S., König S.","57204427194;15823011700;57038100100;","Security from the adversary’s inertia–Controlling convergence speed when playing mixed strategy equilibria",2018,"Games","9","3","59","","",,2,"10.3390/g9030059","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055522043&doi=10.3390%2fg9030059&partnerID=40&md5=28b1c6fefcfd1699a35bb89fe4521195","System Security Group, Institute of Applied Informatics, Alpen-Adria-Universität Klagenfurt, Universitätsstrasse 65-67, Klagenfurt, 9020, Austria; Center for Digital Safety & Security, Austrian Institute of Technology, Giefinggasse 4, Vienna, 1210, Austria","Wachter, J., System Security Group, Institute of Applied Informatics, Alpen-Adria-Universität Klagenfurt, Universitätsstrasse 65-67, Klagenfurt, 9020, Austria; Rass, S., System Security Group, Institute of Applied Informatics, Alpen-Adria-Universität Klagenfurt, Universitätsstrasse 65-67, Klagenfurt, 9020, Austria; König, S., Center for Digital Safety & Security, Austrian Institute of Technology, Giefinggasse 4, Vienna, 1210, Austria","Game-theoretic models are a convenient tool to systematically analyze competitive situations. This makes them particularly handy in the field of security where a company or a critical infrastructure wants to defend against an attacker. When the optimal solution of the security game involves several pure strategies (i.e., the equilibrium is mixed), this may induce additional costs. Minimizing these costs can be done simultaneously with the original goal of minimizing the damage due to the attack. Existing models assume that the attacker instantly knows the action chosen by the defender (i.e., the pure strategy he is playing in the i-th round) but in real situations this may take some time. Such adversarial inertia can be exploited to gain security and save cost. To this end, we introduce the concept of information delay, which is defined as the time it takes an attacker to mount an attack. In this period it is assumed that the adversary has no information about the present state of the system, but only knows the last state before commencing the attack. Based on a Markov chain model we construct strategy policies that are cheaper in terms of maintenance (switching costs) when compared to classical approaches. The proposed approach yields slightly larger security risk but overall ensures a better performance. Furthermore, by reinvesting the saved costs in additional security measures it is possible to obtain even more security at the same overall cost. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Bounded rationality; Control of expenses; Game theory; Incomplete information; Information delay; Mixed strategy equilibrium; Perron-frobenius; Stochastic control; Switching costs",,,,,,"Rass, S., König, S., Schauer, S., On the Cost of Game Playing: How to Control the Expenses in Mixed Strategies (2017) Decision and Game Theory for Security, pp. 494-505. , Rass, S.; An, B.; Kiekintveld, C.; Fang, F.; Schauer, S. Eds.; Springer: New York, NY, USA, ISBN 978-3319687100; Dijk, M., Juels, A., Oprea, A., Rivest, R.L., FlipIt: The Game of “Stealthy Takeover” (2013) J. Cryptol., 26, pp. 655-713; Fudenberg, D., Levine, D.K., (1998) The Theory of Learning in Games, , MIT Press: London, UK; Chien, S., Sinclair, A., Convergence to approximate Nash equilibria in congestion games (2011) Games Econ. Behav., 71, pp. 315-327; Even-Dar, E., Kesselman, A., Mansour, Y., Convergence time to Nash equilibrium in load balancing (2007) ACM Trans. Algorithms, 3, p. 32; Even-Dar, E., Kesselman, A., Mansour, Y., Convergence Time to Nash Equilibria (2003) Lect. Notes Comput.Sci., pp. 502-513; Pal, S., La, R.J., Simple learning in weakly acyclic games and convergence to Nash equilibria (2015) Proceedings of the 53Rd Annual Allerton Conference on Communication, Control, and Computing, pp. 459-466. , Monticello, IL, USA, 29 September–2 October 2015; IEEE: Piscataway, NJ, USA; Zhu, Q., Başar, T., Game-Theoretic Approach to Feedback-Driven Multi-stage Moving Target Defense (2013) 4Th International Conference on Decision and Game Theory for Security, 8252, pp. 246-263. , GameSec 2013; Springer-Verlag, Inc.: New York, NY, USA; Rass, S., König, S., Password Security as a Game of Entropies (2018) Entropy, 20, p. 312; McDonald, S., Wagner, L., Using Simulated Annealing to Calculate the Trembles of Trembling Hand Perfection (2003) Proceedings of the 2003 Congress on Evolutionary Computation, , Canberra, Australia, 8–12 December; Hespanha, J.P., Prandini, M., Nash equilibria in partial-information games on Markov chains (2001) Proceedings of the 40Th IEEE Conference on Decision and Control, pp. 2102-2107. , Orlando, FL, USA, 4–7 December 2001; IEEE: Piscataway, NJ, USA; Anderson, R., Why information security is hard—An economic perspective (2001) Proceedings of the 17Th Annual Computer Security Applications Conference (ACSAC 2001), pp. 358-365. , New Orleans, LA, USA, 10–14 December; Lozovanu, D., Solomon, D., Zelikovsky, A., Multiobjective Games and Determining Pareto-Nash Equilibria (2005) Bul. Acad. Stiint. Republicii Mold. Mat., 49, pp. 115-122; Rios Insua, D., Rios, J., Banks, D., Adversarial Risk Analysis (2009) J. Am. Stat. Assoc., 104, pp. 841-854; Parzen, E., (2015) Stochastic Processes, , Dover Publications, Inc.: Mineola, NY, USA; Cinlar, E., (1975) Introduction to Stochastic Processes, , Springer-Varlag: New York, NY, USA; Lorek, P., (2007) Speed of Convergence to Stationarity for Stochastically Monotone Markov Chains, , Ph.D. Thesis, University of Wroclaw, Wroclaw, Poland; Sklar, A., Fonctions de répartition à n dimensions et leurs marges (1959) Publ. Inst. Stat. Univ. Paris, 8, pp. 229-231; Diaconis, P., Stroock, D., Geometric bounds for eigenvalues of Markov chains (1991) Ann. Probab., 1, pp. 36-61; Cotton, C., Li, C., Profiling, screening and criminal recruitment (2014) J. Public Econ. Theory, 17, pp. 964-985; Bier, V., Oliveros, S., Samuelson, L., Choosing what to protect: Strategic defensive allocation against an unknown attacker (2007) J. Public Econ. Theory, 9, pp. 563-587","Wachter, J.; System Security Group, Universitätsstrasse 65-67, Austria; email: jasmin.wachter@aau.at",,,"MDPI AG",,,,,20734336,,,,"English","Games",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85055522043
"Deka D., Backhaus S., Chertkov M.","54895078300;6701326910;35550581400;","Structure learning in power distribution networks",2018,"IEEE Transactions on Control of Network Systems","5","3","7862849","1061","1074",,74,"10.1109/TCNS.2017.2673546","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053813376&doi=10.1109%2fTCNS.2017.2673546&partnerID=40&md5=bc8d136b64762f88ffa089ea10ffbdcb","Theory Division and the Center for Nonlinear Systems, Los Alamos National Laboratory, Los Alamos, NM  87544, United States; MPA Division of LANL, Los Alamos, NM  87544, United States","Deka, D., Theory Division and the Center for Nonlinear Systems, Los Alamos National Laboratory, Los Alamos, NM  87544, United States; Backhaus, S., MPA Division of LANL, Los Alamos, NM  87544, United States; Chertkov, M., Theory Division and the Center for Nonlinear Systems, Los Alamos National Laboratory, Los Alamos, NM  87544, United States","Traditional power distribution networks suffer from a lack of real-time observability. This complicates development and implementation of new smart-grid technologies, such as those related to demand response, outage detection and management, and improved load monitoring. In this paper, inspired by proliferation of metering technology, we discuss topology estimation problems in structurally loopy but operationally radial distribution grids from measurements, for example, voltage data, which are either already available or can be made available with a relatively minor investment. The primary objective of this paper is to learn the operational layout of the grid. Further, the structure learning algorithm is extended to cases with missing data, where available observations are limited to a fraction of the grid nodes. The algorithms are computationally efficient - polynomial in time - which is proven theoretically and illustrated in numerical experiments on a number of test cases. The techniques developed can be applied to detect line failures in real time as well as to understand the scope of possible adversarial attacks on the grid. © 2014 IEEE.","Missing data; power distribution networks; power flows (PFs); structure/graph learning; voltage measurements","Electric network analysis; Learning algorithms; Voltage measurement; Computationally efficient; Missing data; Numerical experiments; Power distribution network; Power flows; Radial distributions; Smart Grid technologies; Structure learning algorithm; Electric load management",,,,,"Hoffman, R., Practical state estimation for electric distribution networks (2006) Proc. IEEE PES Power Syst. Conf. Expo., pp. 510-517; Liu, J., Xiao, Y., Li, S., Liang, W., Chen, C., Cyber security and privacy issues in smart grids (2012) IEEE Commun. Surveys Tut., 14 (4), pp. 981-997. , Oct.-Dec; http://www.powerstandards.com/PQube.php, PQube. Nov. 27, 2015; Sharon, Y., Annaswamy, A.M., Motto, A.L., Chakraborty, A., Topology identification in distribution network with limited measurements (2012) Proc. IEEE PES Innov. Smart Grid Technol.; Tremblay, M., Pater, R., Zavoda, F., Germain, M., (2010) Electrical Network Fault Location by Distributed Voltage Measurements, , https://www.google.ch/patents/US20100102824, U.S. Patent Appl. 12 450 667; Baran, M.E., Wu, F.F., Network reconfiguration in distribution systems for loss reduction and load balancing (1989) IEEE Trans. Power Del., 4 (2), pp. 1401-1407. , Apr; Turitsyn, K., Sulc, P., Backhaus, S., Chertkov, M., Options for control of reactive power by distributed photovoltaic generators (2011) Proc. IEEE, 99 (6), pp. 1063-1073. , Jun; Kim, J., Tong, L., On topology attack of a smart grid (2013) Proc. IEEE Power Energy Soc. Innov. Smart Grid Technol.; Deka, D., Baldick, R., Vishwanath, S., Attacking power grids with secure meters: The case for breakers and jammers (2014) Proc. IEEE Conf. Comput. Commun. Workshops, pp. 646-651; Deka, D., Baldick, R., Vishwanath, S., Optimal data attacks on power grids: Leveraging detection &measurement jamming (2015) Proc. IEEE Int. Conf. Smart Grid Commun., pp. 392-397; Deka, D., Baldick, R., Vishwanath, S., Jamming aided generalized data attacks: Exposing vulnerabilities in secure estimation (2016) Proc. IEEE 49th Hawaii Int. Conf. Syst. Sci., pp. 2556-2565; Wainwright, M.J., Jordan, M.I., Graphical models, exponential families, and variational inference (2008) Found. Trends Mach. Learn., 1 (1-2), pp. 1-305; Ravikumar, P., High-dimensional ising model selection using 1-regularized logistic regression (2010) Ann. Stat., 38 (3), pp. 1287-1319; Anandkumar, A., Tan, V., Willsky, A.S., High-dimensional graphical model selection: Tractable graph families and necessary conditions (2011) Proc. Adv. Neural Inf. Process. Syst., pp. 1863-1871; Netrapalli, P., Banerjee, S., Sanghavi, S., Shakkottai, S., Greedy learning of Markov network structure (2010) Proc. IEEE 48th Annu. Allerton Conf. Commun., Control Comput., pp. 1295-1302; Ravikumar, P., High-dimensional covariance estimation by minimizing 1-penalized log-determinant divergence (2011) Electron. J. Stat., 5, pp. 935-980; Kekatos, V., Giannakis, G.B., Baldick, R., (2013) Grid Topology Identification Using Electricity Prices; He, M., Zhang, J., A dependency graph approach for fault detection and localization towards secure smart grid (2011) IEEE Trans. Smart Grid, 2 (2), pp. 342-351. , Jun; Bolognani, S., Bof, N., Michelotti, D., Muraro, R., Schenato, L., Identification of power distribution network topology via voltage correlation analysis (2013) Proc. IEEE 52nd Annu. Conf. Dec. Control, pp. 1659-1664; Baran, M., Wu, F., Optimal sizing of capacitors placed on a radial distribution system (1989) IEEE Trans. Power Del., 4 (1), pp. 735-743. , Jan; Baran, M.E., Wu, F.F., Optimal capacitor placement on radial distribution systems (1989) IEEE Trans. Power Del., 4 (1), pp. 725-734. , Jan; Bolognani, S., Zampieri, S., On the existence and linear approximation of the power flow solution in power distribution networks (2016) IEEE Trans. Power Syst., 31 (1), pp. 163-172. , Jan; Miller, W., Inversion of a nonsingular submatrix of an incidence matrix (1963) IEEE Trans. Circuit Theory, CT-10 (1), pp. 132-132. , Mar; Turitsyn, K., Sulc, P., Backhaus, S., Chertkov, M., Local control of reactive power by distributed photovoltaic generators (2010) Proc. 1st IEEE Int. Conf. Smart Grid Commun, pp. 79-84. , Oct; Cormen, T.H., Leiserson, C.E., Rivest, R.L., Stein, C., (2001) Introduction to Algorithms, , Cambridge, MA, USA: MIT Press; Civanlar, S., Grainger, J., Yin, H., Lee, S., Distribution feeder reconfiguration for loss reduction (1988) IEEE Trans. Power Del., 3 (3), pp. 1217-1223. , Jul; Eminoglu, U., Hocaoglu, M.H., A new power flow method for radial distribution systems including voltage dependent load models (2005) Elect. Power Syst. Res., 76 (13), pp. 106-114; Su, C.-T., Chang, C.-F., Chiou, J.-P., Distribution network reconfiguration for loss reduction by ant colony search algorithm (2005) Elect. Power Syst. Res., 75 (23), pp. 190-199; http://www.dejazzer.com/reds.html; Abur, A., Exposito, A.G., (2004) Power System State Estimation: Theory and Implementation, , Boca Raton, FL, USA: CRC",,,,"Institute of Electrical and Electronics Engineers Inc.",,,,,23255870,,,,"English","IEEE Trans. Control Netw. Syst.",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85053813376
"Kwon H., Kim Y., Park K.-W., Yoon H., Choi D.","57197769092;55699558400;22734573000;15061371300;8660876600;","Friend-safe evasion attack: An adversarial example that is correctly recognized by a friendly classifier",2018,"Computers and Security","78",,,"380","397",,13,"10.1016/j.cose.2018.07.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052311348&doi=10.1016%2fj.cose.2018.07.015&partnerID=40&md5=c98db8decb4e7377cd6869052fb03e1a","School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, 34141, South Korea; Department of Electrical Engineering, Korea Military AcademySeoul  01819, South Korea; Department of Computer and Information Security, Sejong UniversitySeoul  05006, South Korea; Department of Medical Information, Kongju National University, Gongju-si, 32588, South Korea","Kwon, H., School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, 34141, South Korea; Kim, Y., Department of Electrical Engineering, Korea Military AcademySeoul  01819, South Korea; Park, K.-W., Department of Computer and Information Security, Sejong UniversitySeoul  05006, South Korea; Yoon, H., School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, 34141, South Korea; Choi, D., Department of Medical Information, Kongju National University, Gongju-si, 32588, South Korea","Deep neural networks (DNNs) have been applied in several useful services, such as image recognition, intrusion detection, and pattern analysis of machine learning tasks. Recently proposed adversarial examples-slightly modified data that lead to incorrect classification-are a severe threat to the security of DNNs. In some situations, however, an adversarial example might be useful, such as when deceiving an enemy classifier on the battlefield. In such a scenario, it is necessary that a friendly classifier not be deceived. In this paper, we propose a friend-safe adversarial example, meaning that the friendly machine can classify the adversarial example correctly. To produce such examples, a transformation is carried out to minimize the probability of incorrect classification by the friend and that of correct classification by the adversary. We suggest two configurations for the scheme: targeted and untargeted class attacks. We performed experiments with this scheme using the MNIST and CIFAR10 datasets. Our proposed method shows a 100% attack success rate and 100% friend accuracy with only a small distortion: 2.18 and 1.54 for the two respective MNIST configurations, and 49.02 and 27.61 for the two respective CIFAR10 configurations. Additionally, we propose a new covert channel scheme and a mixed battlefield application for consideration in further applications. © 2018 Elsevier Ltd","Adversarial Example; Covert Channel; Deep Neural Network; Evasion Attack; Machine Learning","Artificial intelligence; Image recognition; Intrusion detection; Learning systems; Adversarial Example; Covert channels; Evasion Attack; Pattern analysis; Deep neural networks",,,,,"Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Isard, M., Tensorflow: a system for large-scale machine learning (2016) Proceedings of the OSDI, 16, pp. 265-283; Barreno, M., Nelson, B., Joseph, A.D., Tygar, J., The security of machine learning (2010) Mach Learn, 81 (2), pp. 121-148; Biggio, B., Fumera, G., Roli, F., Security evaluation of pattern classifiers under attack (2014) IEEE Trans Knowl Data Eng, 26 (4), pp. 984-996; Biggio, B., Nelson, B., Laskov, P., Poisoning attacks against support vector machines (2012) Proceedings of the 29th international conference on international conference on machine learning, pp. 1467-1474. , Omnipress; Carlini, N., Mishra, P., Vaidya, T., Zhang, Y., Sherr, M., Shields, C., Wagner, D., Zhou, W., Hidden voice commands (2016) Proceedings of the USENIX security symposium, pp. 513-530; Carlini, N., Wagner, D., (2017) Adversarial examples are not easily detected: Bypassing ten detection methods. Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, , ACM; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Proceedings of the IEEE symposium on security and privacy (SP), pp. 39-57. , IEEE; Carlini, N., Wagner, D., Audio adversarial examples: Targeted attacks on speech-to-text (2018) Deep Learning and Security Workshop; Collobert, R., Weston, J., A unified architecture for natural language processing: deep neural networks with multitask learning (2008) Proceedings of the 25th international conference on machine learning, pp. 160-167. , ACM; Cortes, C., Vapnik, V., Support vector machine (1995) Mach Learn, 20 (3), pp. 273-297; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., Imagenet: a large-scale hierarchical image database (2009) Proceedings of the IEEE conference on computer vision and pattern recognition, 2009. CVPR 2009, pp. 248-255. , IEEE; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Proceedings of the advances in neural information processing systems, pp. 2672-2680; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International conference on learning representations; Hinton, G., Deng, L., Yu, D., Dahl, G.E., Mohamed, A.-R., Jaitly, N., Senior, A., Sainath, T.N., Deep neural networks for acoustic modeling in speech recognition: the shared views of four research groups (2012) IEEE Signal Process Mag, 29 (6), pp. 82-97; Kingma, D., Ba, J., Adam: a method for stochastic optimization (2015) Proceedings of the international conference on learning representations (ICLR); Kleinbaum, D.G., Klein, M., Introduction to logistic regression (2010) Logistic regression, pp. 1-39. , Springer; Krizhevsky, A., Nair, V., Hinton, G., (2014), http://www.cs.toronto.edu/kriz/cifar.html, The cifar-10 dataset. online; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2017) Proceedings of the ICLR workshop; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial machine learning at scale (2017) Proceedings of the international conference on learning representations (ICLR); Kwon, H., Yoon, H., Choi, D., Friend-Safe Adversarial Examples in an Evasion Attack on a Deep Neural Network. International Conference on Information Security and Cryptology (2017), Springer, Cham; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc IEEE, 86 (11), pp. 2278-2324; LeCun, Y., Cortes, C., Burges, C.J., Mnist handwritten digit database (2010), 2. , http://yann.lecun.com/exdb/mnist, AT&T Labs Available; McDaniel, P., Papernot, N., Celik, Z.B., Machine learning in adversarial settings (2016) IEEE Secur Privacy, 14 (3), pp. 68-72; Meng, D., Chen, H., Magnet: a two-pronged defense against adversarial examples (2017) Proceedings of the 2017 ACM SIGSAC conference on computer and communications security, pp. 135-147. , ACM; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: a simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2574-2582; Mozaffari-Kermani, M., Sur-Kolay, S., Raghunathan, A., Jha, N.K., Systematic poisoning attacks on and defenses for machine learning in healthcare (2015) IEEE J Biomed Health Inform, 19 (6), pp. 1893-1905; Odena, A., Olah, C., Shlens, J., Conditional image synthesis with auxiliary classifier gans (2017) Proceedings of the ICML; Oliveira, G.L., Valada, A., Bollen, C., Burgard, W., Brox, T., Deep learning for human part discovery in images (2016) Proceedings of the IEEE international conference on robotics and automation (ICRA), pp. 1634-1641. , IEEE; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia conference on computer and communications security, pp. 506-519. , ACM; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Proceedings of the 2016 IEEE European symposium on security and privacy (EuroS&P), pp. 372-387. , IEEE; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Proceedings of the IEEE symposium on security and Privacy (SP), pp. 582-597. , IEEE; Potluri, S., Diedrich, C., Accelerated deep neural networks for enhanced intrusion detection system (2016) Proceedings of the IEEE 21st international conference on emerging technologies and factory automation (ETFA), pp. 1-8. , IEEE; Schmidhuber, J., Deep learning in neural networks: an overview (2015) Neural Netw, 61, pp. 85-117; Silver, D., Huang, A., Maddison, C.J., Guez, A., Sifre, L., Van Den Driessche, G., Schrittwieser, J., Lanctot, M., Mastering the game of go with deep neural networks and tree search (2016) Nature, 529 (7587), pp. 484-489; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) Proceedings of the international conference on learning representations; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) Proceedings of the ICLR 2015; Smeets, M., Koot, M., Covert channels (2006), RPI University of Amsterdam MSc in System and Network Engineering; Strauss, T., (2017), 1709.03423 Ensemble methods as a defense to adversarial perturbations against deep neural networks. arXiv; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) Proceedings of the international conference on learning representations; Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., Ensemble adversarial training: attacks and defenses (2018) Proceedings of the international conference on learning representations (ICLR); Yang, C., (2017), 1703.01340 Generative poisoning attack method against neural networks. arXiv; Zhang, G., Yan, C., Ji, X., Zhang, T., Zhang, T., Xu, W., Dolphinattack: inaudible voice commands (2017) Proceedings of the ACM SIGSAC conference on computer and communications security, pp. 103-117. , ACM","Choi, D.; Department of Medical Information, South Korea; email: sunchoi@kongju.ac.kr",,,"Elsevier Ltd",,,,,01674048,,CPSED,,"English","Comput Secur",Article,"Final","",Scopus,2-s2.0-85052311348
"Ren X., Mo Y.","56337887100;26422460300;","Secure Detection: Performance Metric and Sensor Deployment Strategy",2018,"IEEE Transactions on Signal Processing","66","17","8404096","4450","4460",,6,"10.1109/TSP.2018.2853110","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049444227&doi=10.1109%2fTSP.2018.2853110&partnerID=40&md5=0230a3c28f347eeb96f3a4b6c0f26338","School of Electrical and Electronics Engineering, Nanyang Technological University, Singapore, 639798, Singapore; ACCESS Linnaeus Center, School of Electrical Engineering, Royal Institute of Technology, Stockholm, 114 28, Sweden","Ren, X., School of Electrical and Electronics Engineering, Nanyang Technological University, Singapore, 639798, Singapore, ACCESS Linnaeus Center, School of Electrical Engineering, Royal Institute of Technology, Stockholm, 114 28, Sweden; Mo, Y., School of Electrical and Electronics Engineering, Nanyang Technological University, Singapore, 639798, Singapore","This paper studies how to deploy sensors in the context of detection in adversarial environments. A fusion center is performing a binary hypothesis testing based on measurements from remotely deployed heterogeneous sensors. An attacker may compromise some of the deployed sensors, which send arbitrary measurements to the fusion center. The problems of interest are: to characterize the performance of the system under attack and, thus, develop a performance metric; and to deploy sensors within a cost budget, such that the proposed performance metric is maximized. In this paper, we first present a performance metric by formulating the detection in adversarial environments in a game theoretic way. A Nash equilibrium pair of the detection algorithm and attack strategy, with the deployed sensors given, is provided and the corresponding detection performance is adopted as the performance metric. We then show that the optimal sensor deployment can be determined approximately by solving a group of unbounded knapsack problems. We also show that the performance metric gap between the optimal sensor deployment and the optimal one with sensors being identical is within a fixed constant for any cost budget. The main results are illustrated by numerical examples. © 1991-2012 IEEE.","byzantine attacks; game; Secure detection; sensor deployment","Combinatorial optimization; Game theory; Signal processing; Adversarial environments; Binary Hypothesis Testing; Byzantine attacks; Detection performance; game; Heterogeneous sensors; Performance metrices; Sensor deployment; Budget control",,,,,"Rawat, A.S., Anand, P., Chen, H., Varshney, P.K., Collaborative spectrum sensing in the presence of Byzantine attacks in cognitive radio networks (2011) IEEE Trans. Signal Process., 59 (2), pp. 774-786. , Feb; Mo, Y., Sinopoli, B., Secure estimation in the presence of integrity attacks (2015) IEEE Trans. Autom. Control, 60 (4), pp. 1145-1151. , Apr; Teixeira, A., Sou, K.C., Sandberg, H., Johansson, K.H., Secure control systems: A quantitative risk management approach (2015) IEEE Control Syst., 35 (1), pp. 24-45. , Feb; Ren, X., Wu, J., Dey, S., Shi, L., Attack allocation on remote state estimation in multi-systems: Structural results and asymptotic solution (2018) Automatica, 87, pp. 184-194; Zhang, H., Cheng, P., Shi, L., Chen, J., Optimal DoS attack scheduling in wireless networked control system (2016) IEEE Trans.Control Syst. Technol., 24 (3), pp. 843-852. , May; Huber, P.J., A robust version of the probability ratio test (1965) Ann. Math. Statist., 36 (6), pp. 1753-1758; Kassam, S.A., Poor, H.V., Robust techniques for signal processing: A survey (1985) Proc. IEEE, 73 (3), pp. 433-481. , Mar; Huber, P.J., (2011) Robust Statistics, , New York, NY USA: Springer; Marano, S., Matta, V., Tong, L., Distributed detection in the presence of Byzantine attacks (2009) IEEE Trans. Signal Process., 57 (1), pp. 16-29. , Jan; Mo, Y., Hespanha, J.P., Sinopoli, B., Resilient detection in the presence of integrity attacks (2014) IEEE Trans. Signal Process., 62 (1), pp. 31-43. , Jan; Vamvoudakis, K.G., Hespanha, J.P., Sinopoli, B., Mo, Y., Detection in adversarial environments (2014) IEEE Trans. Autom. Control, 59 (12), pp. 3209-3223. , Dec; Yan, J., Ren, X., Mo, Y., Sequential detection in adversarial environment (2017) Proc. IEEE 56th Annu. Conf. Decis. Control, pp. 170-175. , Dec; Ren, X., Yan, J., Mo, Y., Binary hypothesis testing with byzantine sensors: Fundamental tradeoff between security and efficiency (2018) IEEE Trans. Signal Process., 66 (6), pp. 1454-1468. , Mar; Kerckhoffs, A., (1978) La Cryptographie Militaire, , Ann Arbor, MI USA: University Microfilms; Fellouris, G., Bayraktar, E., Lai, L., Efficient Byzantine sequential change detection (2018) IEEE Trans. Inf. Theory, 64 (5), pp. 3346-3360. , May; Fawzi, H., Tabuada, P., Diggavi, S., Secure estimation and control for cyber-physical systems under adversarial attacks (2014) IEEE Trans. Autom. Control, 59 (6), pp. 1454-1467. , Jun; Mishra, S., Shoukry, Y., Karamchandani, N., Diggavi, S.N., Tabuada, P., Secure state estimation against sensor attacks in the presence of noise (2017) IEEE Trans. Control Netw. Syst., 4 (1), pp. 49-59. , Mar; Chong, M.S., Wakaiki, M., Hespanha, J.P., Observability of linear systems under adversarial attacks (2015) Proc. IEEE Amer. Control Conf., pp. 2439-2444; Dembo, A., Zeitouni, O., (2009) Large Deviations Techniques and Applications, 38. , New York, NY, USA: Springer; Osborne, M.J., Rubinstein, A., (1994) A Course in Game Theory, , Cambridge MA USA: MIT Press; Rubinstein, R.Y., Kroese, D.P., (2016) Simulation and the Monte Carlo Method, , New York NY USA: Wiley; Kay, S.M., (1993) Fundamentals of Statistical Signal Processing: Detection Theory, 2. , Englewood Cliffs, NJ, USA: Prentice-Hall","Ren, X.; School of Electrical and Electronics Engineering, Singapore; email: xiaoqren@kth.se",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,1053587X,,ITPRE,,"English","IEEE Trans Signal Process",Article,"Final","",Scopus,2-s2.0-85049444227
"Kim J.-Y., Bu S.-J., Cho S.-B.","56526721100;57194697819;7404884741;","Zero-day malware detection using transferred generative adversarial networks based on deep autoencoders",2018,"Information Sciences","460-461",,,"83","102",,83,"10.1016/j.ins.2018.04.092","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047653335&doi=10.1016%2fj.ins.2018.04.092&partnerID=40&md5=d5924513cf666f6302e56d071c6f11b9","Department of Computer Science, Yonsei University, Seoul, South Korea","Kim, J.-Y., Department of Computer Science, Yonsei University, Seoul, South Korea; Bu, S.-J., Department of Computer Science, Yonsei University, Seoul, South Korea; Cho, S.-B., Department of Computer Science, Yonsei University, Seoul, South Korea","Detecting malicious software (malware) is important for computer security. Among the different types of malware, zero-day malware is problematic because it cannot be removed by antivirus systems. Existing malware detection mechanisms use stored malware characteristics, which hinders detecting zero-day attacks where altered malware is generated to avoid detection by antivirus systems. To detect malware including zero-day attacks robustly, this paper proposes a novel method called transferred deep-convolutional generative adversarial network (tDCGAN), which generates fake malware and learns to distinguish it from real malware. The data generated from a random distribution are similar but not identical to the real data: it includes modified features compared with real data. The detector learns various malware features using real data and modified data generated by the tDCGAN based on a deep autoencoder (DAE), which extracts appropriate features and stabilizes the GAN training. Before training the GAN, the DAE learns malware characteristics, produces general data, and transfers this capacity for stable training of the GAN generator. The trained discriminator passes down the ability to capture malware features to the detector, using transfer learning. We show that tDCGAN achieves 95.74% average classification accuracy which is higher than that of other models and increases the learning stability. It is also the most robust against modeled zero-day attacks compared to others. © 2018 Elsevier Inc.","Autoencoder; Generative adversarial network; Malicious software; Robustness to noise; Transferlearning; Zero-day attack","Computer worms; Feature extraction; Learning systems; Security of data; Adversarial networks; Auto encoders; Robustness to noise; Transferlearning; Zero day attack; Malware",,,,,"Ahmadi, M., Ulyanov, D., Semenov, S., Tromov, M., Giacinto, G., Novel feature extraction, selection and fusion for effective malware family classification (2016) Conf. Data and Application Security and Privacy, pp. 183-194; Akritidis, P., Anagnostakis, K., Markatos, E.P., Efficient content-based detection of zero-day worms (2005) IEEE Int. Conf. Commun., 2, pp. 837-843; Alexander, M., Christopher, O., Mike, T., Inceptionism: going deeper into neural networks (2015), http://googleresearch.blogspot.com/2015/06/inceptionism-going-deeper-into-neural.html, Accessed 17 June 2015; Annachhatre, C., Thomas, A.H., Mark, S., Hidden Markov models for malware classification (2015) J. Hacking Tech., 11, pp. 59-73; Arnold, A., Nallapati, R., Cohen, W., A comparative study of methods for transductive transfer learning (2007) IEEE Int. Conf. Data Mining, pp. 77-82; Berlin, K., David, S., Joshua, S., Malicious behavior detection using windows audit logs (2015) Artif. Intell. Secur., pp. 35-44; Cao, J., Fu, Q., Li, Q., Guo, D., Discovering hidden suspicious accounts in online social networks (2017) Inf. Sci., 394, pp. 123-140; Chen, Z., Yan, Q., Han, H., Wang, S., Peng, L., Wang, L., Yang, B., Machine Learning based mobile malware detection using highly imbalanced network traffic (2018) Inf. Sci., 433-434, pp. 346-364; Christodorescum, M., Jha, S., Seshia, S.A., Song, D., Bryant, R.E., Semantics-aware malware detection (2005) Secur. Privacy, pp. 32-46; Damodaran, A., Di Troia, F., Visaggio, C.A., Austin, T.H., Stamp, M., A Comparison of static, dynamic, and hybrid analysis for malware detection (2017) J. Comput. Virol. Hacking Tech., 13 (1), pp. 1-12; Dauphin, Y.N., Pascanu, R., Gulcehre, C., Cho, K., Ganguli, S., Bengio, Y., Identifying and attacking the saddle point problem in high-dimensional non-convex optimization (2014) Adv. Neural Inf. Process. Syst., pp. 2933-2941; David, S., Numaan, H., ATM malware on the rise (2017), https://blog.trendmicro.com/trendlabs-security-intelligence/atm-malware-on-the-rise, Accessed 08 Aug Seshia; Dean, D., Jr., Kuhn, D., Direct instruction vs. discovery: the long view (2007) Sci. Edu., 91, pp. 384-397; Denton, L.E., Chintala, S., Fergus, R., Deep generative image models using a laplacian pyramid of adversarial networks (2015) Adv. Neural Inf. Process. Syst., pp. 1486-1494; Dhammi, A., Singh, M., Behavior analysis of malware using machine learning (2015) IEEE Int. Conf. Contemp. Comput., pp. 481-486; Drew, J., Moore, T., Hahsler, M., Polymorphic malware detection using sequence classification methods (2016) Secur. Privacy Workshops, pp. 81-87; Garcia, F.C.C., Muga, I.I., Felix, P., (2016), Random forest for malware classification, arXiv preprint arXiv:., 1609.07770; Glorot, X., Bengio, Y., Understanding the difficulty of training deep feedforward neural networks (2010) Int. Conf. Artif. Intell. Stat., pp. 249-256; Goodfellow, I., Pouget-Abadie, J., Mirze, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Adv. Neural Inf. Process. Syst., pp. 2672-2680; Grace, M., Zhou, Y., Zhang, Q., Zou, S., Jiang, X., Riskranker: scalable and accurate zero-day android malware detection (2012) Proceeding International Conference on Mobile Systems, Applications, and Services, pp. 281-294; Huda, S., Miah, S., Hassan, M.M., Islam, R., Yearwood, J., Alrubaian, M., Almogren, A., Defending unknown attacks on cyber-physical systems by semi-supervised approach and available unlabeled data (2017) Inf. Sci., 379, pp. 211-228; Kim, D.J., Jiang, C.D.H., Memisevic, R., (2016), Generating images with recurrent adversarial networks, arXiv preprint arXiv:., 1602.05110; Kim, J.-Y., Bu, S.-J., Cho, S.-B., Malware detection using deep transferred generative adversarial networks (2017) ICONIP, In Int. Conf. on Neural Information Processing, pp. 556-564; Kingma, D., Ba, J., (2014), Adam: a method for stochastic optimization, arXiv preprint arXiv:., 1412.6980; Kong, D., Guanhua, Y., Discriminant malware distance learning on structural information for automated malware classification (2013) Conf. Knowledge discovery and Datamining, pp. 1357-1365; Krizhevsky, A., Hinton, G.E., Using very deep autoencoders for content-based image retrieval (2011) European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, pp. 489-494; Loffe, S., Szegedy, C., Batch normalization: accelerating deep network training by reducing internal covariate shift (2015) Int. Conf. Machine Learning, pp. 448-456; Lu, X., Matsuda, Y., Hori, C., Speech enhancement based on deep denoising autoencoder (2013) Interspeech, pp. 436-440; Maaten, L., Hinton, G., Visualizing data using t-SNE (2008) J. Mach. Learn. Res., 9, pp. 2579-2605; Mas' ud, M.Z., Sahib, S., Abdollah, M.F., Selamat, S.R., Yusof, R., Analysis of feature selection and machine learning classifier in android malware detection (2014) Information Science and Applications, 2014 Int. Conf. on IEEE, pp. 1-5; Mathieu, M., Couprie, C., Lecun, Y., (2015), Deep multi-scale video prediction beyond mean square error, arXiv preprint arXiv:., 1511.05440; Narayanan, B.N., Djaneye-Boundjou, O., Kebede, T.M., Performance analysis of machine learning and pattern recognition algorithms for malware classification (2016) Aerospace and Electronics Conf. and Ohio Innovation Summit, pp. 338-342; Nataraj, L., Karthikeyanm, S., Jacob, G., Manjunath, B.S., Malware images: visualization and automatic classification (2011) Conf. Visualizing for Cyber Security, pp. 1-7; Pascanu, R., Stokes, J.W., Sanossian, H., Marinescu, M., Thomas, A., Malware classification with recurrent network (2015) Acoust. Speech Signal Process., pp. 1916-1920; Radford, A., Metz, L., Chintala, S., (2015), Unsupervised representation learning with deep convolutional generative adversarial networks, arXiv preprint arXiv:., 1511.06434; Santos, I., Brezo, F., Ugarte-Pedrero, X., Bringas, P.G., Opcode sequences as representation of executables for data-mining-based unknown malware detection (2013) Inf. Sci., 231, pp. 64-82; Singh, K., guntuku, S.C., Thakur, A., Hota, C., Big data analytics frameword for peer-to-peer botnet detection using random forests (2017) Inf. Sci., 278, pp. 488-497; Springenberg, J.T., (2015), Unsupervised and semi-supervised learning with categorical generative adversarial networks, arXiv preprint arXiv:., 1511.06390; Vincent, P., Larochelle, H., Bengio, Y., Manzagol, P.A., Extracting and composing robust features with denoising autoencoders (2008) Int. Conf. on Machine Learning, pp. 1096-1103; Wang, Q., Guo, W., Zhang, K., Alexander, G., Ororbia, I.I., Xinyu, X., Lee Giles, C., Xue, L., Adversary resistant deep neural networks with an application to malware detection (2017) Int. Conf. Knowledge Discovery and Data Mining, pp. 1145-1153; Wang, Z., Bovil, A.C., Sheikh, H.R., Simoncelli, E.P., Image quality assessment: from error visibility to structural similarity (2004) IEEE Trans. Image Process., 13, pp. 600-612; Ye, Y., Chen, L., Hou, S., Hardy, W., Li, X., DeepAM: a heterogeneous deep learning framework for intelligent malware detection (2017) Knowl. Inf. Syst., pp. 1-21; Zhao, J., Mathieu, M., Lecun, Y., (2016), Energy-based generative adversarial network, arXiv preprint arXiv:., 1609.03126; Zeiler, M.D., Fergus, R., Visualizing and understanding convolutional networks (2014) European Conf. on Computer Vision, pp. 818-833","Cho, S.-B.; Department of Computer Science, South Korea; email: sbcho@yonsei.ac.kr",,,"Elsevier Inc.",,,,,00200255,,ISIJB,,"English","Inf Sci",Article,"Final","",Scopus,2-s2.0-85047653335
"Pal A., Arora C.","57201313045;35203020100;","Making Deep Neural Network Fooling Practical",2018,"Proceedings - International Conference on Image Processing, ICIP",,,"8451062","3428","3432",,,"10.1109/ICIP.2018.8451062","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062916459&doi=10.1109%2fICIP.2018.8451062&partnerID=40&md5=af369bf6d87156132d6508c7e15d5865","Department of Computer Science and Engineering, IIIT, Delhi, India","Pal, A., Department of Computer Science and Engineering, IIIT, Delhi, India; Arora, C., Department of Computer Science and Engineering, IIIT, Delhi, India","With the success of deep neural networks (DNNs), the robustness of such models under adversarial or fooling attacks has become extremely important. It has been shown that a simple perturbation of the image, invisible to a human observer, is sufficient to fool a deep network. Building on top of such work, methods have been proposed to generate adversarial samples which are robust to natural perturbations (camera noise, rotation, shift, scaling etc.). In this paper, we review multiple such fooling algorithms and show that the generated adversarial samples exhibit distributions largely different from the true distribution of the training samples, and thus are easily detectable by a simple meta classifier. We argue that for truly practical DNN fooling, not only should the adversarial samples be robust against various distortions, but must also follow the training set distribution and be undetectable from such meta classifiers. Finally we propose a new adversarial sample generation technique that outperforms commonly known methods when evaluated simultaneously on robustness and detectability. © 2018 IEEE.","Deep Network Fooling; Robustness of Adversarial Attacks","Classification (of information); Image processing; Deep Network Fooling; Detectability; Human observers; Meta-classifiers; Natural perturbations; Sample generations; Training sample; Training sets; Deep neural networks",,,,,"Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Fei-Fei, L., Imagenet large scale visual recognition challenge (2015) International Journal of Computer Vision; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Neural Information Processing Systems; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations; Sabour, S., Cao, Y., Faghri, F., Fleet, D.J., Adversarial manipulation of deep representations (2016) International Conference on Learning Representations; Moosavi-Dezfooli, S., Fawzi, A., Frossard, P., (2016) Deepfool: A Simple and Accurate Method to Fool Deep Neural Networks; Lyu, C., Huang, K., Liang, H., A unified gradient regularization family for adversarial examples (2015) IEEE International Conference on Data Mining; Akash, V., Maharaj, (2016) Improving the Adversarial Robustness of Convnets by Reduction of Input Dimensionality; Hinton, G., Vinyals, O., Dean, J., Distilling the knowledge in a neural network (2014) Neural Information Processing Systems(Workshop); Papernot, N., Drew McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2015) IEEE Symposium on Security and Privacy; Graese, A., Roza, A., Boult, T.E., Assessing threat of adversarial examples on deep neural networks (2016) Machine Learning and Applications (ICMLA), 2016 15th IEEE International Conference on; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium on; Deb, K., Pratap, A., Agarwal, S., Meyarivan, T., A fast and elitist multiobjective genetic algorithm: Nsga-II (2002) IEEE Transactions on Evolutionary Computation; Athalye, A., Sutskever, I., (2017) Synthesizing Robust Adversarial Examples; Hendrik Metzen, J., Genewein, T., Fischer, V., Bischoff, B., (2017) On Detecting Adversarial Perturbations; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on; Dong, Y., Liao, F., Pang, T., Su, H., Hu, X., Li, J., Zhu, J., Boosting adversarial attacks with momentum (2017) CoRR, , abs/1710. 06081; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations; Chen, P., Sharma, Y., Zhang, H., Yi, J., Hsieh, C., (2017) Ead: Elastic-net Attacks to Deep Neural Networks Via Adversarial Examples; Kingma, D., Ba, J., (2014) Adam: A Method for Stochastic Optimization; Kwatra, V., Schödl, A., Essa, I., Turk, G., Bobick, A., Graphcut textures: Image and video synthesis using graph cuts (2003) ACM Transactions on Graphics (ToG); Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition",,,"The Institute of Electrical and Electronics Engineers Signal Processing Society","IEEE Computer Society","25th IEEE International Conference on Image Processing, ICIP 2018","7 October 2018 through 10 October 2018",,143052,15224880,9781479970612,,,"English","Proc. Int. Conf. Image Process. ICIP",Conference Paper,"Final","",Scopus,2-s2.0-85062916459
"Chen C., Zhao X., Stamm M.C.","57189029493;57192545235;34870520200;","Mislgan: An Anti-Forensic Camera Model Falsification Framework Using A Generative Adversarial Network",2018,"Proceedings - International Conference on Image Processing, ICIP",,,"8451503","535","539",,12,"10.1109/ICIP.2018.8451503","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062913374&doi=10.1109%2fICIP.2018.8451503&partnerID=40&md5=58125f8051e734d4afbb32bd652fe554","Dept. of Electrical and Computer Engineering, Drexel University, Philadelphia, PA  19104, United States","Chen, C., Dept. of Electrical and Computer Engineering, Drexel University, Philadelphia, PA  19104, United States; Zhao, X., Dept. of Electrical and Computer Engineering, Drexel University, Philadelphia, PA  19104, United States; Stamm, M.C., Dept. of Electrical and Computer Engineering, Drexel University, Philadelphia, PA  19104, United States","Deep learning techniques have become popular for performing camera model identification. To expose weaknesses in these methods, we propose a new anti-forensic framework that utilizes a generative adversarial network (GAN) to falsify an image's source camera model. Our proposed attack uses the generator trained in the GAN to produce an image that can fool a CNN-based camera model identification classifier. Moreover, our proposed attack will only introduce a minimal amount of distortion to the falsified image that is not perceptible to human eyes. By conducting experiments on a large amount of data, we show that the proposed attack can successfully fool a state-of-art camera model identification CNN classifier with 98% probability and maintain high image quality. © 2018 IEEE.","Anti-forensics; Camera model identification; Convolutional neural networks; Generative adversarial network","Cameras; Crime; Deep learning; Image processing; Neural networks; Adversarial networks; Anti-Forensics; Camera model identifications; Convolutional neural network; Falsification frameworks; High image quality; Large amounts; Learning techniques; Digital forensics",,,,,"Stamm, M.C., Wu, M., Liu, K.J.R., Information forensics: An overview of the first decade (2013) IEEE Access, 1, pp. 167-200; Kee, E., Johnson, M.K., Farid, H., Digital image authentication from jpeg headers (2011) IEEE Transaction on Information Forensics and Security, 6 (3), pp. 1066-1075; Chen, M., Fridrich, J., Goljan, M., Lukás, J., Determining image origin and integrity using sensor noise (2008) IEEE Transactions on Information Forensics and Security, 3 (1), pp. 74-90; Thai, T.H., Cogranne, R., Retraint, F., Camera model identification based on the heteroscedastic noise model (2014) IEEE Transactions on Image Processing, 23 (1), pp. 250-263. , Jan; Cao, H., Kot, A.C., Accurate detection of demosaicing regularity for digital image forensics (2009) IEEE Transactions on Information Forensics and Security, 4 (4), pp. 899-910. , Dec; Swaminathan, A., Wu, M., Liu, K., Nonintrusive component forensics of visual sensors using output images (2007) IEEE Transaction on Information Forensics and Security, 2 (1), pp. 91-106; Chen, C., Stamm, M.C., Camera model identification framework using an ensemble of demosaicing features (2015) International Workshop on Information Forensics and Security. IEEE, pp. 1-6; Zhao, X., Stamm, M.C., Computationally efficient demosaicing filter estimation for forensic camera model identification (2016) International Conference on Image Processing. IEEE, pp. 151-155; Bayram, S., Sencar, H., Memon, N., Avcibas, I., Source camera identification based on cfa interpolation (2005) International Conference on Image Processing, 3, pp. III-69. , IEEE; Bondi, L., Baroffio, L., Gera, D., Bestagini, P., Delp, E.J., Tubaro, S., First steps toward camera model identification with convolutional neural networks (2017) IEEE Signal Processing Letters, 24 (3), pp. 259-263. , March; Bayar, B., Stamm, M.C., Augmented convolutional feature maps for robust cnn-based camera model identification (2017) International Conference on Image Processing. IEEE; Bondi, L., Lameri, S., Gera, D., Bestagini, P., Delp, E.J., Tubaro, S., Tampering detection and localization through clustering of camerabased cnn features (2017) Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), pp. 1855-1864. , IEEE, July; Tuama, A., Comby, F., Chaumont, M., Camera model identification with the use of deep convolutional neural networks (2016) International Workshop on Information Forensics and Security (WIFS). IEEE, pp. 1-6; Bayar, B., Stamm, M.C., Design principles of convolutional neural networks for multimedia forensics (2017) Electronic Imaging, 2017 (7), pp. 77-86; Mayer, O., Stamm, M.C., Learned forensic source similarity for unknown camera models (2018) Acoustics, Speech and Signal Processing (ICASSP), 2018 IEEE International Conference on. IEEE, pp. 1-4; Bayar, B., Stamm, M.C., Towards open set camera model identification using a deep learning framework (2018) Acoustics, Speech and Signal Processing (ICASSP), 2018 IEEE International Conference on. IEEE, pp. 1-4; Stamm, M.C., Tjoa, S.K., Lin, W.S., Liu, K.R., Anti-forensics of jpeg compression (2010) International Conference on Acoustics, Speech and Signal Processing. IEEE, pp. 1694-1697; Kirchner, M., Bohme, R., Hiding traces of resampling in digital images (2008) IEEE Transactions on Information Forensics and Security, 3 (4), pp. 582-592; Fontani, M., Barni, M., Hiding traces of median filtering in digital images (2012) Signal Processing Conference (EUSIPCO), Proceedings of the 20th European. IEEE, pp. 1239-1243; Wu, Z.-H., Stamm, M.C., Liu, K.R., Anti-forensics of median filtering (2013) International Conference on Acoustics, Speech and Signal Processing. IEEE, pp. 3043-3047; Stamm, M.C., Lin, W.S., Liu, K.R., Temporal forensics and antiforensics for motion compensated video (2012) IEEE Transactions on Information Forensics and Security, 7 (4), pp. 1315-1329; Sharma, S., Subramanyam, A.V., Jain, M., Mehrish, A., Emmanuel, S., Anti-forensic technique for median filtering using l1-l2 tv model (2016) 2016 IEEE International Workshop on Information Forensics and Security (WIFS), pp. 1-6. , Dec; Barni, M., Chen, Z., Tondi, B., Adversary-aware, data-driven detection of double jpeg compression: How to make counter-forensics harder (2016) International Workshop on Information Forensics and Security, pp. 1-6. , IEEE, Dec; Peng, A., Zeng, H., Lin, X., Kang, X., Countering anti-forensics of image resampling (2015) International Conference on Image Processing, pp. 3595-3599. , IEEE, Sept; Chuang, W.-H., Wu, M., Robustness of color interpolation identification against anti-forensic operations (2012) International Workshop on Information Hiding, pp. 16-30. , Springer; Stamm, M.C., Lin, W.S., Liu, K.R., Forensics vs. Anti-forensics: A decision and game theoretic framework (2012) International Conference on Acoustics, Speech and Signal Processing. IEEE, pp. 1749-1752; Valenzise, G., Tagliasacchi, M., Tubaro, S., Revealing the traces of jpeg compression anti-forensics (2013) IEEE Transactions on Information Forensics and Security, 8 (2), pp. 335-349. , Feb; Zeng, H., Qin, T., Kang, X., Liu, L., Countering anti-forensics of median filtering (2014) 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 2704-2708. , May; Chen, C., Zhao, X., Stamm, M.C., Detecting anti-forensic attacks on demosaicing-based camera model identification (2017) International Conference on Image Processing. IEEE; Gera, D., Wang, Y., Bondi, L., Bestagini, P., Tubaro, S., Delp, E.J., A counter-forensic method for cnn-based camera model identification (2017) Computer Vision and Pattern Recognition Workshops (CVPRW). IEEE, pp. 1840-1847. , July; Kim, D., Jang, H.U., Mun, S.M., Choi, S., Lee, H.K., Median filtered image restoration and anti-forensics using adversarial networks (2018) IEEE Signal Processing Letters, 25 (2), pp. 278-282. , Feb; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets Advances in Neural Information Processing Systems, p. 27; Ledig, C., Theis, L., Huszar, F., Caballero, J., Cunningham, A., Acosta, A., Aitken, A., Shi, W., Photo-realistic single image super-resolution using a generative adversarial network (2017) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , July; Denton, E.L., Chintala, S., Szlam, A., Fergus, R., Deep generative image models using a laplacian pyramid of adversarial networks Advances in Neural Information Processing Systems, p. 28; Radford, A., Metz, L., Chintala, S., (2015) Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks, , CoRR vol. abs/1511. 06434; Tuama, A., Comby, F., Chaumont, M., Camera model identification with the use of deep convolutional neural networks (2016) Information Forensics and Security (WIFS). IEEE, pp. 1-6; Bayar, B., Stamm, M.C., Constrained convolutional neural networks: A new approach towards general purpose image manipulation detection (2018) IEEE Transactions on Information Forensics and Security, 13 (11), pp. 2691-2706. , Nov; Gloe, T., Böhme, R., The 'dresden image database' for benchmarking digital image forensics (2010) Proceedings of the 2010 ACM Symposium on Applied Computing, Ser. SAC '10, pp. 1584-1590. , http://doi.acm.org/10.1145/1774088.1774427, New York, NY, USA: ACM",,,"The Institute of Electrical and Electronics Engineers Signal Processing Society","IEEE Computer Society","25th IEEE International Conference on Image Processing, ICIP 2018","7 October 2018 through 10 October 2018",,143052,15224880,9781479970612,,,"English","Proc. Int. Conf. Image Process. ICIP",Conference Paper,"Final","",Scopus,2-s2.0-85062913374
"Barni M., Costanzo A., Nowroozi E., Tondi B.","7005442155;54914277000;57200532119;55389019900;","Cnn-based detection of generic contrast adjustment with JPEG post-processing",2018,"Proceedings - International Conference on Image Processing, ICIP",,,"8451698","3803","3807",,24,"10.1109/ICIP.2018.8451698","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054923486&doi=10.1109%2fICIP.2018.8451698&partnerID=40&md5=eaff5cd1c1060561c7e4f5b0fbbf9524","Department of Information Engineering and Mathematics, University of Siena, Germany; CNIT - Consorzio Nazionale Interuniversitario per le Telecomunicazioni, Italy","Barni, M., Department of Information Engineering and Mathematics, University of Siena, Germany; Costanzo, A., CNIT - Consorzio Nazionale Interuniversitario per le Telecomunicazioni, Italy; Nowroozi, E., Department of Information Engineering and Mathematics, University of Siena, Germany; Tondi, B., Department of Information Engineering and Mathematics, University of Siena, Germany","Detection of contrast adjustments in the presence of JPEG post processing is known to be a challenging task. JPEG post processing is often applied innocently, as JPEG is the most common image format, or it may correspond to a laundering attack, when it is purposely applied to erase the traces of manipulation. In this paper, we propose a CNN-based detector for generic contrast adjustment, which is robust to JPEG compression. The proposed system relies on a patch-based Convolutional Neural Network (CNN), trained to distinguish pristine images from contrast adjusted images, for some selected adjustment operators of different nature. Robustness to JPEG compression is achieved by training the CNN with JPEG examples, compressed over a range of Quality Factors (QFs). Experimental results show that the detector works very well and scales well with respect to the adjustment type, yielding very good performance under a large variety of unseen tonal adjustments. © 2018 IEEE.","Adversarial learning; Adversarial multimedia forensics; Contrast manipulation detection; Cybersecurity; Deep learning for Multimedia Forensics","Deep learning; Neural networks; Adversarial learning; Contrast adjustment; Convolutional neural network; Cyber security; JPEG compression; Multimedia forensics; Post processing; Quality factors; Image compression",,,,,"Bohme, R., Kirchner, M., (2012) Counter-forensics: Attacking Image Forensics, , in Digital Image Forensics, H. T. Sencar and N. Memon, Eds. Springer Berlin / Heidelberg; Barni, M., Fernando, P.-G., Coping with the enemy: Advances in adversary-aware signal processing (2013) ICASSP 2013, IEEE International Conference on Acoustics, Speech and Signal Processing, Vancouver, pp. 8682-8686. , Canada, 26-31 May; Stamm, M.C., Liu, K.J.R., Forensic detection of image manipulation using statistical intrinsic fingerprints (2010) IEEE Transactions on Information Forensics and Security, 5 (3), pp. 492-506; Cao, G., Zhao, Y., Ni, R., Forensic estimation of gamma correction in digital images (2010) 2010 17th IEEE International Conference on Image Processing (ICIP). IEEE, pp. 2097-2100; Cao, G., Zhao, Y., Ni, R., Li, X., Contrast enhancement-based forensics in digital images (2014) IEEE Transactions on Information Forensics and Security, 9 (3), pp. 515-525; Cao, G., Zhao, Y., Ni, R., Tian, H., Antiforensics of contrast enhancement in digital images (2010) Proceedings of the 12th ACM Workshop on Multimedia and Security. ACM, pp. 25-34; Barni, M., Fontani, M., Tondi, B., A universal technique to hide traces of histogram-based image manipulations (2012) Proceedings of the on Multimedia and Security. ACM, pp. 97-104; Pan, X., Zhang, X., Lyu, S., Exposing image forgery with blind noise estimation (2011) Proceedings of the Thirteenth ACM Multimedia Workshop on Multimedia and Security. ACM, pp. 15-20; Rosa, A.D., Fontani, M., Massai, M., Piva, A., Barni, M., Second-order statistics analysis to cope with contrast enhancement counter-forensics (2015) IEEE Signal Processing Letters, 22 (8), pp. 1132-1136; Li, H., Luo, W., Qiu, X., Huang, J., Identification of various image operations using residualbased features (2016) IEEE Transactions on Circuits and Systems for Video Technology; Singh, N., Gupta, A., Analysis of contrast enhancement forensics in compressed and uncompressed images (2016) 2016 International Conference on Signal Processing and Communication (ICSC). IEEE, pp. 303-307; Barni, M., Nowroozi, E., Tondi, B., Higherorder, adversary-aware, double JPEG-detection via selected training on attacked samples (2017) 2017 25th European Signal Processing Conference (EUSIPCO), pp. 281-285. , Aug; Chen, J., Kang, X., Liu, Y., Wang, Z.J., Median filtering forensics based on convolutional neural networks (2015) IEEE Signal Processing Letters, 22 (11), pp. 1849-1853. , Nov; Bayar, B., Stamm, M.C., A deep learning approach to universal image manipulation detection using a new convolutional layer (2016) Proceedings of the 4th ACM Workshop on Information Hiding and Multimedia Security, pp. 5-10. , New York, NY, USA, , IHMMSec '16 ACM; Barni, M., Bondi, L., Bonettini, N., Bestagini, P., Costanzo, A., Maggini, M., Tondi, B., Tubaro, S., Aligned and non-aligned double JPEG detection using convolutional neural networks (2017) Journal of Visual Communication and Image Representation, 49, pp. 153-163; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition, , arXiv preprint arXiv:1409.1556; Zuiderveld, K., (1994) Contrast Limited Adaptive Histogram Equalization, Graphics Gems IV, Academic Press Professional, Inc, , San Diego, CA, USA; Dang-Nguyen, D.-T., Pasquini, C., Conotter, V., Boato, G., Raise: A raw images dataset for digital image forensics (2015) Proceedings of the 6th ACM Multimedia Systems Conference, pp. 219-224. , New York, NY, USA, , MMSys '15 , ACM; Chollet, F., (2015) Keras, , https://github.com/keras-team/keras",,,"The Institute of Electrical and Electronics Engineers Signal Processing Society","IEEE Computer Society","25th IEEE International Conference on Image Processing, ICIP 2018","7 October 2018 through 10 October 2018",,143052,15224880,9781479970612,,,"English","Proc. Int. Conf. Image Process. ICIP",Conference Paper,"Final","",Scopus,2-s2.0-85054923486
"Jillepalli A.A., De Leon D.C., Ashrafuzzaman M., Chakhchoukh Y., Johnson B.K., Sheldon F.T., Alves-Foss J., Tosic P.T., Haney M.A.","57191228392;8123569300;57203989108;34968921900;57203332803;7006468020;6602804877;6506371427;55453323800;","HESTIA: Adversarial Modeling and Risk Assessment for CPCS",2018,"2018 14th International Wireless Communications and Mobile Computing Conference, IWCMC 2018",,,"8450297","226","231",,6,"10.1109/IWCMC.2018.8450297","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053873254&doi=10.1109%2fIWCMC.2018.8450297&partnerID=40&md5=4cc5c7c2aee3d8777f738a817042b0d1","Center for Secure and Dependable Systems, University of IdahoID, United States; Department of Computer Science, University of IdahoID, United States; Department of Electrical and Computer Engineering, University of IdahoID, United States; Center for Advanced Energy Studies, University of IdahoID, United States","Jillepalli, A.A., Center for Secure and Dependable Systems, University of IdahoID, United States, Department of Computer Science, University of IdahoID, United States; De Leon, D.C., Center for Secure and Dependable Systems, University of IdahoID, United States, Department of Computer Science, University of IdahoID, United States; Ashrafuzzaman, M., Department of Computer Science, University of IdahoID, United States; Chakhchoukh, Y., Center for Secure and Dependable Systems, University of IdahoID, United States, Department of Electrical and Computer Engineering, University of IdahoID, United States; Johnson, B.K., Center for Secure and Dependable Systems, University of IdahoID, United States, Department of Electrical and Computer Engineering, University of IdahoID, United States; Sheldon, F.T., Department of Computer Science, University of IdahoID, United States; Alves-Foss, J., Center for Secure and Dependable Systems, University of IdahoID, United States, Department of Computer Science, University of IdahoID, United States; Tosic, P.T., Department of Computer Science, University of IdahoID, United States; Haney, M.A., Center for Secure and Dependable Systems, University of IdahoID, United States, Department of Computer Science, University of IdahoID, United States, Center for Advanced Energy Studies, University of IdahoID, United States","Due to the characteristics and connectivity of today's Cyber-Physical Control Systems (CPCS) and critical infrastructures, cyber-attacks on these systems are currently difficult to prevent in an efficient and sustainable manner. Prevention and mitigation need accurate identification and evaluation of: system vulnerabilities, likely threats and attacks, and applicable hardening measures. Furthermore, the ability to prioritize hardening measures based on accurate assessments of threat risk and consequence and mitigation availability, applicability, and cost is also needed. To address this challenge we created HESTIA: High-level and Extensible System for Training and Infrastructure risk Assessment. In this paper, we describe the latest architecture and working principles of HESTIA. When fully developed, the HESTIA process and tool-set will enable CPCS engineers to, iteratively: 1) specify a CPCS, 2) select applicable attacks and hardening measures from a library, 3) check specifications for consistency and applicability, and 4) merge attack and hardening specifications into a new CPCS model. In addition, we add support for device specification templates. HESTIA enables the discovery of attack-defend scenarios through simulation and the design of optimal hardening strategies for a given CPCS. This paper is a shortened and updated version of a journal article entitled An architecture for HESTIA to appear in the International Journal of Internet of Things and Cyber-Assurance. © 2018 IEEE.","Computational modeling; Control systems; Engines; Libraries; Risk management; Security; Training","Control systems; Engines; Hardening; Libraries; Mobile computing; Network security; Personnel training; Risk management; Specifications; Wireless telecommunication systems; Computational model; Device specification; Extensible systems; Identification and evaluation; International journals; Security; System vulnerability; Threats and attacks; Risk assessment",,,,,"Sun, C.-C., Liu, C.-C., Xie, J., Cyber-physical system security of a power grid: State-of-the-art (2016) Electronics, 5 (3). , http://www.mdpi.com/2079-9292/5/3/40; McLaughlin, S., Konstantinou, C., Wang, X., Davi, L., Sadeghi, A.-R., Maniatakos, M., Karri, R., The cybersecurity landscape in industrial control systems (2016) Proceedings of the IEEE, 104 (5), pp. 1039-1057; Whitehead, D.E., Owens, K., Gammel, D., Smith, J., Ukraine cyberinduced power outage: Analysis and practical mitigation strategies (2017) 2017 70th Annual Conference for Protective Relay Engineers (CPRE), pp. 1-8. , April; Mo, Y., Kim, T.H.-J., Brancik, K., Dickinson, D., Lee, H., Perrig, A., Sinopoli, B., Cyber-physical security of a smart grid infrastructure (2012) Proceedings of the IEEE, 100 (1), pp. 195-209. , January; France-Presse, A., (2017) Massive Power Failure Plunges 80% of Pakistan into Darkness, , www.theguardian.com/world/2015/jan/25/massive-power-failure-plunges-80-of-pakistan-into-darkness, Online. Visited: December 11, January 2015; Tan, S., De, D., Song, W.-Z., Yang, J., Das, S.K., Survey of security advances in smart grid: A data driven approach (2017) IEEE Communications Surveys Tutorials, 19 (1), pp. 397-422. , Firstquarter; Stouffer, K., Pillitteri, V., Lightman, S., Abrams, M., Hahn, A., (2018) Guide to Industrial Control Systems (ICS) Security, , https://nvlpubs.nist.gov/nistpubs/specialpublications/nist.sp.800-82r2.pdf, Online. Visited: January, May 2015; Jillepalli, A.A., De Conte, L.D., Chakhchoukh, Y., Ashrafuzzaman, M., Johnson, B.K., Sheldon, F.T., Alves-Foss, J., Haney, M.A., An architecture for HESTIA: High-level and extensible system for training and infrastructure risk assessment (2018) International Journal of Internet of Things and Cyber Assurance, , TBD TBD; Mahan, R.E., Fluckiger, J.D., Clements, S.L., Tews, C.W., Burnette, J.R., Goranson, C.A., Kirkham, H., (2011) Secure Data Transfer Guidance for Industrial Control and SCADA Systems, , http://www.pnl.gov/main/publications/external/technicalreports/PNNL-20776.pdf, Online. Visited: January 2018; Jillepalli, A.A., De Conte, L.D., Steiner, S., Sheldon, F.T., HERMES: A high-level policy language for high-granularity enterprisewide secure browser configuration management (2016) Proc. 2016 IEEE 07th Symposium Series on Computational Intelligence (SSCI-2016), , December; Jillepalli, A.A., De Conte, L.D., An architecture for a policyoriented web browser management system: HiFiPol: Browser (2016) Proc. 2016 IEEE 40th Annual Computer Software and Applications Conference (COMPSAC-2016), , June; Zhang, L., Modeling large scale complex cyber physical control systems based on system of systems engineering approach 20th International Conference on Automation and Computing, September 2014, pp. 55-60; Zhang, L., Formal specification for real time cyber physical systems using aspect-oriented approach (2011) Fifth International Conference on Theoretical Aspects of Software Engineering, pp. 213-216. , August; (2018) Making Security Measurable, , https://makingsecuritymeasurable.mitre.org/, Online. Visited: Jan; Jillepalli, A.A., Sheldon, F.T., De Conte, L.D., Haney, M.A., Abercrombie, R.K., Security management of cyber physical control systems using NIST SP 800-82r2 (2017) 13th International Wireless Communications and Mobile Computing Conference (IWCMC-2017), pp. 1864-1870. , June; Sheldon, F.T., Ali, A.R.K.M., Evaluating security controls based on key performance indicators and stakeholder mission Proceedings of the 4th Annual Workshop on Cyber Security and Information Intelligence Research (CSIIRW-2008), , https://doi.org/10.1145/1413140.1413188",,,"Frederick University","Institute of Electrical and Electronics Engineers Inc.","14th International Wireless Communications and Mobile Computing Conference, IWCMC 2018","25 June 2018 through 29 June 2018",,139084,,9781538620700,,,"English","Int. Wirel. Commun. Mob. Comput. Conf., IWCMC",Conference Paper,"Final","",Scopus,2-s2.0-85053873254
"Falco G., Viswanathan A., Caldera C., Shrobe H.","56979098300;7006598228;57201525342;57203684356;","A Master Attack Methodology for an AI-Based Automated Attack Planner for Smart Cities",2018,"IEEE Access","6",,"8449268","48360","48373",,33,"10.1109/ACCESS.2018.2867556","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052614180&doi=10.1109%2fACCESS.2018.2867556&partnerID=40&md5=58f45d2010db1792aa7841f917be34ec","Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA  02139, United States; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA  91109, United States","Falco, G., Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA  02139, United States; Viswanathan, A., Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA  91109, United States; Caldera, C., Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA  02139, United States; Shrobe, H., Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA  02139, United States","America's critical infrastructure is becoming 'smarter' and increasingly dependent on highly specialized computers called industrial control systems (ICS). Networked ICS components now called the industrial Internet of Things (IIoT) are at the heart of the 'smart city', controlling critical infrastructure, such as CCTV security networks, electric grids, water networks, and transportation systems. Without the continuous, reliable functioning of these assets, economic and social disruption will ensue. Unfortunately, IIoT are hackable and difficult to secure from cyberattacks. This leaves our future smart cities in a state of perpetual uncertainty and the risk that the stability of our lives will be upended. The Local government has largely been absent from conversations about cybersecurity of critical infrastructure, despite its importance. One reason for this is public administrators do not have a good way of knowing which assets and which components of those assets are at the greatest risk. This is further complicated by the highly technical nature of the tools and techniques required to assess these risks. Using artificial intelligence planning techniques, an automated tool can be developed to evaluate the cyber risks to critical infrastructure. It can be used to automatically identify the adversarial strategies (attack trees) that can compromise these systems. This tool can enable both security novices and specialists to identify attack pathways. We propose and provide an example of an automated attack generation method that can produce detailed, scalable, and consistent attack trees-the first step in securing critical infrastructure from cyberattack. © 2013 IEEE.","AI planning; attack trees; cyber audit tools; cyber risk; cybersecurity; IIoT; IoT; smart cities","Automation; Forestry; Integrated circuits; Intelligent control; Internet of things; Network security; Networked control systems; Public works; Risk assessment; Security of data; Smart city; Tools; AI planning; Attack tree; Audit tools; Cyber security; Fault-trees; IIoT; Critical infrastructures",,,,,"Arduin, P.-E., (2018) Insider Threats, , Hoboken, NJ, USA: Wiley; (2018) Ransomware Cyberattack Information, , https://www.atlantaga.gov/government/ransomware-cyberattack-information, Atlanta, GA, USA. Accessed: Jun. 2018; Bistarelli, S., Dall'Aglio, M., Peretti, P., Strategic games on defense trees (2006) Proc. Int. Workshop Formal Aspects Secur, , Trust. Berlin, Germany: Springer; Boddy, M., Gohde, J., Haigh, T., Harp, S., Course of action generation for cyber security using classical planning (2005) Proc. ICAPS, pp. 12-21; Byres, E.J., Franz, M., Miller, D., The use of attack trees in assessing vulnerabilities in SCADA systems (2004) Proc. Int. Infrastruct. Survivability Workshop, pp. 3-10; Cárdenas, A.A., Amin, S., Lin, Z.-S., Huang, Y.-L., Huang, C.-Y., Sastry, S., Attacks against process control systems: Risk assessment, detection, and response (2011) Proc. 6th ACM Symp. Inf., Comput. Commun. Secur., pp. 355-366; Chuang, T., (2018) SamSam Ransomware Virus Keeps CDOT Employees Offline for Fourth Day. DenverPost, , https://www.denverpost.com/2018/02/26/samsamransomware-virus-cdot/, Accessed: Jun. 2018; (2017) Cisco SmartCConnected City Operations Center: Unified Management for City Infrastructure, , Cisco, San Jose, CA, USA, 2014 Accessed: Nov. 3; DeLong, T.W., A fault tree manual (1970) Intern Training Center, Army Materiel Command, , Texarkana, TX, USA, Tech. Rep. 1; Evans, D., (2012) The Internet of Everything: How More Relevant and Valuable Connections Will Change the World, pp. 1-9. , Cisco, San Jose, CA, USA, Tech. Rep. 1; Gjendemsjø, M., (2013) Creating A Weapon of Mass Disruption: Attacking Programmable Logic Controllers, , M. S. thesis, Norwegian Univ. Sci. Technol., Trondheim, Norway Accessed: Dec. 13; Hoffmann, J., Simulated penetration testing: From Dijkstra' to turing testCC (2015) Proc. ICAPS, pp. 364-372; Hutchins, E., Cloppert, M., Amin, R., Intelligence-driven computer network defense informed by analysis of adversary campaigns and intrusion kill chains (2011) Leading Issues Inf. Warfare Secur. Res., 1 (1), p. 80; (2017) Kali Linux Tools Listing Penetration Testing Tools, , https://tools.kali.org/toolslisting, Accessed: Sep. 15 2017; (2017) Threat Landscape for Industrial Automation Systems in the Second Half of 2016, , https://ics-cert.kaspersky.com/reports/2017/03/28/threat-landscape-for-industrial-automation-systemsinthe-second-half-of-2016/, Kaspersky Lab ICS CERT. Accessed: Mar. 31 2017; Kearney, L., (2018) Atlanta Officials Reveal Worsening Effects of Cyber Attack, , https://www.reuters.com/article/us-usa-cyber-atlanta-budget/atlantaofficials-reveal-worsening-effectsof-cyber-attack-idUSKCN1J231M, Accessed: Jun. 27 2018; McGalliard, T., Opinion | How local governments can prevent cyberattacks (2018) NYTimes, , https://www.nytimes.com/2018/03/30/opinion/local-governmentcyberattack.html, Accessed: Jun. 27 2018; Mitnick, K.D., Simon, W.L., (2003) The Art of Deception: Controlling the Human Element of Security, , Hoboken, NJ, USA: Wiley; (2017) ATT&CK Matrix for Enterprise, , https://attack.mitre.org/wiki/ATT&CKMatrix, Accessed: Sep. 15 2017; CAPEC common attack pattern enumeration and classification (CAPEC) (2017) MITRE, , https://capec.mitre.org/, Accessed: Sep. 14 2017; Industry perspective on cyber resiliency lifecycle for executives (2017) MITRE, , http://www2.mitre.org/public/industry-perspective/lifecycle.html, Accessed: Nov. 3 2017; Nakhost, H., Müller, M., Monte-Carlo exploration for deterministic planning (2009) Proc. IJCAI, pp. 1766-1771; Nurse, J.R.C., Erola, A., Agraotis, I., Goldsmith, M., Creese, S., Smart insiders: Exploring the threat from insiders using the Internet-of-Things (2015) Proc. Int. Workshop Secure Internet Things (SIoT), pp. 5-14. , Sep; (2017) IoT Attack Surface Areas, , https://www.owasp.org/index.php/IoT_Attack_Surface_Areas, Accessed: Sep. 7 2017; Ralston, P.A.S., Graham, J.H., Hieb, J.L., Cyber security risk assessment for SCADA and DCS networks (2007) ISA Trans., 46 (4), pp. 583-594; Ramirez, R., Choucri, N., Improving interdisciplinary communication with standardized cyber security terminology: A literature review (2016) IEEE Access, 4, pp. 2216-2243; Arpan, R., Kim, D.S., Trivedi, K.S., Cyber security analysis using attack countermeasure trees (2010) Proc. 6th Annu. Workshop Cyber Secur. Inf. Intell. Res., , Apr., Oak Ridge, TN, USA; Salim, H.M., (2014) Cyber Safety: A Systems Thinking and Systems Theory Approach to Managing Cyber Security Risks, , Ph. D. dissertation, Compos. Inf. Syst. Lab., Massachusetts Inst. Technol., Cambridge, MA, USA; Sarraute, C., (2013) Automated Attack Planning., , https://arxiv.org/abs/1307.7808; Schneier, B., Attack trees (1999) Dr. Dobb's J., 24 (12), pp. 21-29; Shewhart, W.A., (1931) Economic Control of Quality of Manufactured Product, , Milwaukee, WI, USA: ASQ Quality Press; Shrobe, H.E., Computational vulnerability analysis for information survivability (2002) AI Mag., 23 (4), pp. 81-94; Slay, J., Miller, M., Lessons learned from the Maroochy water breach (2007) Proc. Int. Conf. Crit. Infrastruct. Protection, pp. 73-82. , Boston, MA, USA: Springer; Willison, R., Warkentin, M., Beyond deterrence: An expanded view of employee computer abuse (2013) MIS Quart., 37 (1), pp. 1-20; Wright, M., (2018) A Ransomware Attack Brought Atlanta to Its Knees and No One Seems to Care, , http://thehill.com/opinion/cybersecurity/381594-aransomware-attack-broughtatlanta-to-its-knees-and-no-one-seems-to, Accessed: Jun. 27 TheHill","Falco, G.; Computer Science and Artificial Intelligence Laboratory, United States; email: gfalco@mit.edu",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85052614180
"Nguyen H.H., Tieu N.-D.T., Nguyen-Son H.-Q., Nozick V., Yamagishi J., Echizen I.","55774055400;57202912968;55376316800;23397678200;7004695833;6602366829;","Modular convolutional neural network for discriminating between computer-generated images and photographic images",2018,"ACM International Conference Proceeding Series",,,"3230863","","",,11,"10.1145/3230833.3230863","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055290194&doi=10.1145%2f3230833.3230863&partnerID=40&md5=4f65be4762c535d77b4d974675bbb8da","SOKENDAI (The Graduate University for Advanced Studies), Kanagawa, Japan; National Institute of Informatics, Tokyo, Japan; Japanese-French Laboratory for Informatics (JFLI) (UMI 3527), Tokyo, Japan; University of Edinburgh, United Kingdom","Nguyen, H.H., SOKENDAI (The Graduate University for Advanced Studies), Kanagawa, Japan; Tieu, N.-D.T., SOKENDAI (The Graduate University for Advanced Studies), Kanagawa, Japan; Nguyen-Son, H.-Q., National Institute of Informatics, Tokyo, Japan; Nozick, V., Japanese-French Laboratory for Informatics (JFLI) (UMI 3527), Tokyo, Japan; Yamagishi, J., SOKENDAI (The Graduate University for Advanced Studies), Kanagawa, Japan, National Institute of Informatics, Tokyo, Japan, University of Edinburgh, United Kingdom; Echizen, I., SOKENDAI (The Graduate University for Advanced Studies), Kanagawa, Japan, National Institute of Informatics, Tokyo, Japan","Discriminating between computer-generated images (CGIs) and photographic images (PIs) is not a new problem in digital image forensics. However, with advances in rendering techniques supported by strong hardware and in generative adversarial networks, CGIs are becoming indistinguishable from PIs in both human and computer perception. This means that malicious actors can use CGIs for spoofing facial authentication systems, impersonating other people, and creating fake news to be spread on social networks. The methods developed for discriminating between CGIs and PIs quickly become outdated and must be regularly enhanced to be able to reduce these attack surfaces. Leveraging recent advances in deep convolutional networks, we have built a modular CGI–PI discriminator with a customized VGG-19 network as the feature extractor, statistical convolutional neural networks as the feature transformers, and a discriminator. We also devised a probabilistic patch aggregation strategy to deal with high-resolution images. This proposed method outperformed a state-of-the-art method and achieved accuracy up to 100%. © 2018 Association for Computing Machinery.","Computer-generated image; Convolutional neural network; Digital image forensics; Photographic image","Computer forensics; Computer hardware; Computer networks; Convolution; Image processing; Imaging systems; Neural networks; Photography; Authentication systems; Computer-generated images; Convolutional networks; Convolutional neural network; Digital image forensics; High resolution image; Photographic image; State-of-the-art methods; Discriminators",,,,,"Alexander, O., Rogers, M., Lambeth, W., Chiang, J.-Y., Ma, W.-C., Wang, C.-C., Debevec, P., The digital emily project: Achieving a photorealistic digital actor (2010) IEEE Computer Graphics and Applications, 30 (4), pp. 20-31. , 2010; Ba, J., Mnih, V., Kavukcuoglu, K., Multiple object recognition with visual attention (2015) International Conference on Learning Representations (ICLR); Chen, W., Shi, Y.Q., Xuan, G., Su, W., Computer graphics identification using genetic algorithm (2008) International Conference on Pattern Recognition, pp. 1-4. , IEEE; Chen, Z., Ke, Y., A Novel Photographic and Computer Graphic Composites Detection Method (2012) National Conference on Information Technology and Computer Science, , Atlantis Press; Conotter, V., Cordin, L., Detecting photographic and computer generated composites (2011) Image Processing: Algorithms and Systems IX, 7870. , ternational Society for Optics and Photonics, 78700A; Cortes, C., Vapnik, V., Support-vector networks (1995) Machine Learning, 20 (3), pp. 273-297. , 1995; Dang-Nguyen, D.-T., Pasquini, C., Conotter, V., Boato, G., Raise: A raw images dataset for digital image forensics (2015) Multimedia Systems Conference (MMSys), pp. 219-224. , ACM; Dirik, A.E., Bayram, S., Sencar, H.T., Memon, N., New features to identify computer generated images (2007) International Conference on Image Processing (ICIP), 4. , IEEE IV–433; Duda, R.O., Hart, P.E., Stork, D.G., (1973) Pattern Classification, 2. , Wiley New York; Fan, S., Wang, R., Zhang, Y., Guo, K., Classifying computer generated graphics and natural images based on image contour information (2012) Journal of Information & Computational Science, 9 (10), pp. 2877-2895. , 2012; Farid, H., Lyu, S., Higher-order wavelet statistics and their application to digital forensics (2003) Computer Vision and Pattern Recognition Workshop, 8, p. 94. , IEEE; Gallagher, A.C., Chen, T., Image authentication by detecting traces of demosaicing (2008) Computer Vision and Pattern Recognition Workshops, pp. 1-8. , IEEE; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems (NIPS), pp. 2672-2680; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I.P., Tygar, J.D., Adversarial machine learning (2011) Workshop on Security and Artificial Intelligence, pp. 43-58. , ACM; Ioffe, S., Szegedy, C., Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015) International Conference on Machine Learning (ICML), pp. 448-456; Johnson, J., Alahi, A., Fei-Fei, L., Perceptual losses for real-time style transfer and super-resolution (2016) European Conference on Computer Vision, pp. 694-711. , Springer; Karras, T., Aila, T., Laine, S., Lehtinen, J., Progressive growing of GANs for improved quality, stability, and variation (2018) International Conference on Learning Representations (ICLR); Khanna, N., Chiu, G.T.-C., Allebach, J.P., Delp, E.J., Forensic techniques for classifying scanner, computer generated and digital camera images (2008) International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 1653-1656. , IEEE; Ledig, C., Theis, L., Huszár, F., Caballero, J., Cunningham, A., Acosta, A., Aitken, A., Wang, Z., Photo-realistic single image super-resolution using a generative adversarial network (2016) Computing Research Repository (CoRR), , 2016; Li, W., Zhang, T., Zheng, E., Ping, X., Identifying photorealistic computer graphics using second-order difference statistics (2010) International Conference on Fuzzy Systems and Knowledge Discovery (FSKD), 5, pp. 2316-2319. , IEEE; Li, Z., Ye, J., Shi, Y.Q., Distinguishing computer graphics from photographic images using local binary patterns (2013) International Workshop on Digital Forensics and Watermarking (IWDW), pp. 228-241. , Springer; Lyu, S., Farid, H., How realistic is photorealistic? (2005) IEEE Transactions on Signal Processing, 53 (2), pp. 845-850. , 2005; Nair, V., Hinton, G.E., Rectified linear units improve restricted boltzmann machines (2010) International Conference on Machine Learning (ICML), pp. 807-814; Ng, T.-T., Chang, S.-F., An online system for classifying computer graphics images from natural photographs (2006) Security, Steganography, and Watermarking of Multimedia Contents VIII, 6072, p. 607211. , ternational Society for Optics and Photonics; Peng, F., Zhou, D.-L., Discriminating natural images and computer generated graphics based on the impact of CFA interpolation on the correlation of PRNU (2014) Digital Investigation, 11 (2), pp. 111-119. , 2014; Peng, F., Zhou, D.-L., Long, M., Sun, X.-M., Discrimination of natural images and computer generated graphics based on multi-fractal and regression analysis (2017) AEU-International Journal of Electronics and Communications, 71, pp. 72-81. , 2017; Rahmouni, N., Nozick, V., Yamagishi, J., Echizen, I., Distinguishing computer graphics from natural images using convolution neural networks (2017) Workshop on Information Forensics and Security (WIFS), , IEEE; Ruck, D.W., Rogers, S.K., Kabrisky, M., Oxley, M.E., Suter, B.W., The multilayer perceptron as an approximation to a Bayes optimal discriminant function (1990) IEEE Transactions on Neural Networks, 1 (4), pp. 296-298. , 1990; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Fei-Fei, L., ImageNet large scale visual recognition challenge (2015) International Journal of Computer Vision (IJCV), 115 (3), pp. 211-252. , 2015; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) International Conference on Learning Representations (ICLR); Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., Dropout: A simple way to prevent neural networks from overfitting (2014) The Journal of Machine Learning Research, 15 (1), pp. 1929-1958. , 2014; Suwajanakorn, S., Seitz, S.M., Kemelmacher-Shlizerman, I., Synthesizing obama: Learning lip sync from audio (2017) ACM Transactions on Graphics (TOG), 36 (4), p. 95. , 2017; Tan, D.Q., Shen, X.J., Qin, J., Chen, H.P., Detecting computer generated images based on local ternary count (2016) Pattern Recognition and Image Analysis, 26 (4), pp. 720-725. , 2016; Thies, J., Zollhöfer, M., Stamminger, M., Theobalt, C., Nießner, M., Face2Face: Real-time face capture and reenactment of RGB videos (2016) Computer Vision and Pattern Recognition (CVPR), pp. 2387-2395. , IEEE; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2018) International Conference on Learning Representations (ICLR); Wang, Y., Moulin, P., On discrimination between photorealistic and photographic images (2006) International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2, pp. II-II. , IEEE; Wu, R., Li, X., Yang, B., Identifying computer generated graphics via histogram features (2011) International Conference on Image Processing (ICIP), pp. 1933-1936. , IEEE; Zhang, R., Wang, R.-D., Ng, T.-T., Distinguishing photographic images and photorealistic computer graphics using visual vocabulary on local image edges (2011) International Workshop on Digital Forensics and Watermarking (IWDW), pp. 292-305. , Springer",,,"Universitat Hamburg","Association for Computing Machinery","13th International Conference on Availability, Reliability and Security, ARES 2018","27 August 2018 through 30 August 2018",,140147,,9781450364485,,,"English","ACM Int. Conf. Proc. Ser.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85055290194
"Boyd C., Davies G.T., Gjøsteen K., Raddum H., Toorani M.","57204716676;56126107500;8659107400;6506983745;6602606147;","Definitions for plaintext-existence hiding in cloud storage",2018,"ACM International Conference Proceeding Series",,,"3234515","","",,,"10.1145/3230833.3234515","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055273388&doi=10.1145%2f3230833.3234515&partnerID=40&md5=7cb4e64ca99e88fa2bf2112f031e87f0","Norwegian University of Science and Technology, Trondheim, Norway; Simula@UiB, Bergen, Norway; University of Bergen, Bergen, Norway","Boyd, C., Norwegian University of Science and Technology, Trondheim, Norway; Davies, G.T., Norwegian University of Science and Technology, Trondheim, Norway; Gjøsteen, K., Norwegian University of Science and Technology, Trondheim, Norway; Raddum, H., Simula@UiB, Bergen, Norway; Toorani, M., University of Bergen, Bergen, Norway","Cloud storage services use deduplication for saving bandwidth and storage. An adversary can exploit side-channel information in several attack scenarios when deduplication takes place at the client side, leaking information on whether a specific plaintext exists in the cloud storage. Generalising existing security definitions, we introduce formal security games for a number of possible adversaries in this domain, and show that games representing all natural adversarial behaviors are in fact equivalent. These results allow users and practitioners alike to accurately assess the vulnerability of deployed systems to this real-world concern. © 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.","Cloud storage; Information leakage; Side-channel analysis","Computer applications; Computer programming; Attack scenarios; Cloud storage services; Cloud storages; Deployed systems; Information leakage; Security definitions; Side-channel analysis; Side-channel information; Side channel attack",,,,,"Armknecht, F., Boyd, C., Davies, G.T., Gjøsteen, K., Toorani, M., Side channels in deduplication: Trade-offs between leakage and efficiency (2017) Proceedings of The 2017 ACM on Asia Conference on Computer and Communications Security, AsiaCCS 2017, pp. 266-274. , https://doi.org/10.1145/3052973.3053019, Abu Dhabi, United Arab Emirates, April 2-6, 2017. ACM; Bellare, M., Keelveedhi, S., Ristenpart, T., Message-locked encryption and secure deduplication (2013) Advances in Cryptology - EUROCRYPT 2013, 32nd Annual International Conference on The Theory and Applications of Cryptographic Techniques, 7881, pp. 296-312. , https://doi.org/10.1007/978-3-642-38348-9_18, Athens, Greece, May 26-30, 2013. Proceedings (Lecture Notes in Computer Science),. Springer; Duan, Y., Distributed key generation for encrypted deduplication: Achieving the strongest privacy (2014) Proceedings of The 6th Edition of The ACM Workshop on Cloud Computing Security, pp. 57-68. , https://doi.org/10.1145/2664168.2664169, CCSW’14, Scottsdale, Arizona, USA, November 7, 2014. ACM; Harnik, D., Pinkas, B., Shulman-Peleg, A., Side channels in cloud services: Deduplication in cloud storage (2010) IEEE Security & Privacy, 8 (6), pp. 40-47. , https://doi.org/10.1109/MSP.2010.187, 2010; Hovhannisyan, H., Lu, K., Yang, R., Qi, W., Wang, J., Wen, M., A novel deduplication-based covert channel in cloud storage service (2015) 2015 IEEE Global Communications Conference, GLOBECOM 2015, pp. 1-6. , https://doi.org/10.1109/GLOCOM.2014.7417228, San Diego, CA, USA, December 6-10, 2015. IEEE; Keelveedhi, S., Bellare, M., Ristenpart, T., Dupless: Server-aided encryption for deduplicated storage (2013) Proceedings of The 22th USENIX Security Symposium, pp. 179-194. , https://www.usenix.org/conference/usenixsecurity13/technical-sessions/presentation/bellare, Washington, DC, USA, August 14-16, 2013. USENIX Association; Li, M., Qin, C., Li, J., Lee, P.P.C., Cdstore: Toward reliable, secure, and cost-efficient cloud storage via convergent dispersal (2016) IEEE Internet Computing, 20 (3), pp. 45-53. , https://doi.org/10.1109/MIC.2016.45, 2016; Liu, J., Asokan, N., Pinkas, B., Secure deduplication of encrypted data without additional independent servers (2015) Proceedings of The 22nd ACM SIGSAC Conference on Computer and Communications Security, pp. 874-885. , https://doi.org/10.1145/2810103.2813623, Denver, CO, USA, October 12-6, 2015. ACM; Liu, J., Asokan, N., Pinkas, B., Secure deduplication of encrypted data without additional independent servers (2015) IACR Cryptology ePrint Archive 2015, p. 455. , http://eprint.iacr.org/2015/455, 2015; Liu, J., Duan, L., Li, Y., Asokan, N., Secure deduplication of encrypted data: Refined model and new constructions (2018) Topics in Cryptology - CT-RSA 2018 - The Cryptographers’ Track at The RSA Conference 2018, pp. 374-393. , https://doi.org/10.1007/978-3-319-76953-0_20, San Francisco, CA, USA, April 16-20, 2018, Proceedings; Mulazzani, M., Schrittwieser, S., Leithner, M., Huber, M., Weippl, E.R., Dark clouds on the horizon: Using cloud storage as attack vector and online slack space (2011) 20th USENIX Security Symposium, , http://static.usenix.org/events/sec11/tech/full_papers/Mulazzani6-24-11.pdf, San Francisco, CA, USA, August 8-12, 2011, Proceedings. USENIX Association; Pulls, T., More) side channels in cloud storage - linking data to users (2011) Privacy and Identity Management for Life - 7th IFIP WG 9.2, 375, pp. 102-115. , https://doi.org/10.1007/978-3-642-31668-5_8, 9.6/11.7, 11.4, 11.6/PrimeLife International Summer School, Trento, Italy, September 5-9, 2011, Revised Selected Papers (IFIP Advances in Information and Communication Technology),. Springer; Shin, Y.-J., Koo, D., Hur, J., A survey of secure data deduplication schemes for cloud storage systems (2017) ACM Comput. Surv., 49 (4), pp. 74:1-74:38. , https://doi.org/10.1145/3017428, 2017; Stanek, J., Sorniotti, A., Androulaki, E., Kencl, L., A secure data deduplication scheme for cloud storage (2014) Financial Cryptography and Data Security - 18th International Conference, FC 2014, Christ Church, Barbados, March 3-7, 2014, Revised Selected Papers (Lecture Notes in Computer Science), 8437, pp. 99-118. , https://doi.org/10.1007/978-3-662-45472-5_8, Springer; Storer, M.W., Greenan, K.M., Long, D.D.E., Miller, E.L., Secure data deduplication (2008) Proceedings of The 2008 ACM Workshop On Storage Security And Survivability, StorageSS 2008, pp. 1-10. , https://doi.org/10.1145/1456469.1456471, Alexandria, VA, USA, October 31, 2008. ACM",,,"Universitat Hamburg","Association for Computing Machinery","13th International Conference on Availability, Reliability and Security, ARES 2018","27 August 2018 through 30 August 2018",,140147,,9781450364485,,,"English","ACM Int. Conf. Proc. Ser.",Conference Paper,"Final","",Scopus,2-s2.0-85055273388
"Bagheri A., Simeone O., Rajendran B.","57197970135;23993347300;24469154400;","Adversarial Training for Probabilistic Spiking Neural Networks",2018,"IEEE Workshop on Signal Processing Advances in Wireless Communications, SPAWC","2018-June",,"8446003","","",,9,"10.1109/SPAWC.2018.8446003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053456439&doi=10.1109%2fSPAWC.2018.8446003&partnerID=40&md5=c538bab9e0d42f8a9afa0d27a4fbbcf2","ECE Department New Jersey Institute of Technology, Newark, NJ  07102, United States; Department of Informatics, King s College London, London, WC2R 2LS, United Kingdom","Bagheri, A., ECE Department New Jersey Institute of Technology, Newark, NJ  07102, United States; Simeone, O., Department of Informatics, King s College London, London, WC2R 2LS, United Kingdom; Rajendran, B., ECE Department New Jersey Institute of Technology, Newark, NJ  07102, United States","Classifiers trained using conventional empirical risk minimization or maximum likelihood methods are known to suffer dramatic performance degradations when tested over examples adversarially selected based on knowledge of the clas-sifier's decision rule. Due to the prominence of Artificial Neural Networks (ANNs) as classifiers, their sensitivity to adversarial examples, as well as robust training schemes, have been recently the subject of intense investigation. In this paper, for the first time, the sensitivity of spiking neural networks (SNNs), or third-generation neural networks, to adversarial examples is studied. The study considers rate and time encoding, as well as rate and first-to-spike decoding. Furthermore, a robust training mechanism is proposed that is demonstrated to enhance the performance of SNNs under white-box attacks. © 2018 IEEE.","adversarial examples; adversarial training; Generalized Linear Model (GLM); Spiking Neural Networks (SNNs)","Maximum likelihood; Neural networks; Wireless telecommunication systems; adversarial examples; Empirical risk minimization; Generalized linear model; Maximum likelihood methods; Performance degradation; Robust trainings; Spiking neural networks; Third generation; Signal processing",,,,,"Ranjan, R., Sankaranarayanan, S., Bansal, A., Bodla, N., Chen, J.-C., Patel, V.M., Castillo, C.D., Chellappa, R., Deep learning for understanding faces: Machines may be just as good, or better, than humans (2018) IEEE Signal Process. Mag., 35 (1), pp. 66-83; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) Int. Conf. on Learn. Repr. (ICLR); Fawzi, A., Moosavi-Dezfooli, S.-M., Frossard, P., The robustness of deep networks: A geometrical perspective (2017) IEEE Signal Process. Mag., 34 (6), pp. 50-62; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks; Paugam-Moisy, H., Bohte, S., Computing with spiking neuron networks (2012) Handbook of Natural Computing, pp. 335-376; Vincent, J., (2017) Intel Investigates Chips Designed Like Your Brain to Turn the AI Tide, , https://www.theverge.com/2017/9/26/16365390/intelinvestigates-chips-designed-like-your-brain-to-turn-the-ai-tide,Accessed:Sept.26; Smith, J.E., Research agenda: Spacetime computation and the neocortex (2017) IEEE Micro, 37 (1), pp. 8-14; Ponulak, F., Kasínski, A., Supervised learning in spiking neural networks with ReSuMe: Sequence learning, classification, and spike shifting (2010) Neural Comput, 22 (2), pp. 467-510; Sengupta, A., Ye, Y., Wang, R., Liu, C., Roy, K., (2018) Going Deeper in Spiking Neural Networks: VGG and Residual Architectures; Gardner, B., Grüning, A., Supervised learning in spiking neural networks for precise temporal encoding (2016) PloS One, 11 (8), pp. 1-28; Guo, S., Yu, Z., Deng, F., Hu, X., Chen, F., Hierarchical Bayesian inference and learning in spiking neural networks (2017) IEEE Trans. Cybern., PP (99), pp. 1-13; Rezende, D.J., Wierstra, D., Gerstner, W., Variational learning for recurrent spiking networks (2011) Adv Neural Inf Process Syst, pp. 136-144; Bagheri, A., Simeone, O., Rajendran, B., (2017) Training Probabilistic Spiking Neural Networks with First-to-spike Decoding; Stromatias, E., Soto, M., Serrano-Gotarredona, T., Linares-Barranco, B., An event-driven classifier for spiking neural networks fed with synthetic or dynamic vision sensor data (2017) Front Neurosci, 11, pp. 1-17; Masquelier, T., Thorpe, S.J., Unsupervised learning of visual features through spike timing dependent plasticity (2007) PLoS Comput. Biol., 3 (2), pp. 247-257; Kheradpisheh, S.R., Ganjtabesh, M., Thorpe, S.J., Masquelier, T., (2016) STDP-based Spiking Deep Neural Networks for Object Recognition; Pillow, J.W., Shlens, J., Paninski, L., Sher, A., Litke, A.M., Chichilnisky, E., Simoncelli, E.P., Spatio-temporal correlations and visual signaling in a complete neuronal population (2008) Nature, 454 (7207), p. 995; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World",,,,"Institute of Electrical and Electronics Engineers Inc.","19th IEEE International Workshop on Signal Processing Advances in Wireless Communications, SPAWC 2018","25 June 2018 through 28 June 2018",,139030,,9781538635124,,,"English","IEEE Workshop Signal Process. Adv. Wireless Commun. SPAWC",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85053456439
"Truong A., Kiyavash N., Rasoul Etesami S.","35238783600;13104840200;55845944700;","Adversarial Machine Learning: The Case of Recommendation Systems",2018,"IEEE Workshop on Signal Processing Advances in Wireless Communications, SPAWC","2018-June",,"8445767","","",,1,"10.1109/SPAWC.2018.8445767","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053453851&doi=10.1109%2fSPAWC.2018.8445767&partnerID=40&md5=563519bc7a3d23e820a34c5129d2a26d","Department of Industrial and Enterprise Systems Engineering, University of Illinois at Urbana-Champaign, Champaign, IL  61820, United States","Truong, A., Department of Industrial and Enterprise Systems Engineering, University of Illinois at Urbana-Champaign, Champaign, IL  61820, United States; Kiyavash, N., Department of Industrial and Enterprise Systems Engineering, University of Illinois at Urbana-Champaign, Champaign, IL  61820, United States; Rasoul Etesami, S., Department of Industrial and Enterprise Systems Engineering, University of Illinois at Urbana-Champaign, Champaign, IL  61820, United States","Learning with expert advice framework has drawn much attention in recent years especially in the context of recommendation systems. We consider two challenges that we face in broadly applying this framework in practice. One is the impact of adversarial attack strategies (malicious recommendations) and the other is lack of sufficient recommendation from quality experts (aka sleeping expert setting). In this paper, we discuss some recent results on understanding adversarial strategies and their effect on recommendation systems. In addition, in the sleeping expert setting, we discuss some novel designs for learning alaorithms and the analysis of their convergence properties. © 2018 IEEE.","adversarial strategy; Learning with expert advice; sleeping experts","Learning systems; Recommender systems; Sleep research; Wireless telecommunication systems; adversarial strategy; Attack strategies; Convergence properties; Expert advice; Expert setting; Novel design; sleeping experts; Signal processing",,,,,"Vovk, V.G., Aggregating strategies (1990) Proceedings of the Third Annual Workshop on Computational Learning Theory (COLT '90), pp. 371-386. , San Francisco, CA, USA; Littlestone, N., Warmuth, M.K., The weighted majority algorithm (1989) Proceedings of the 30th Annual Symposium on Foundations of Computer Science, pp. 212-261. , NC, Feb; Cesa-Bianchi, N., Freund, Y., Helmbold, D., Haussler, D., Schapire, R.E., Warmuth, M.K., How to use expert advice (1993) Proceedings of the Twenty-fifth Annual ACM Symposium on Theory of Computing (STOC '93), pp. 427-485. , New York, NY, USA, May; Cesa-Bianchi, N., Lugosi, G., (2006) Prediction, Learning, and Games, , Oakland: Cambridge University Press; Newsome, J., Karp, B., Song, D., Paragraph: Thwarting signature learning by training maliciously (2006) Proceedings of the 9th International Conference on Recent Advances in Intrusion Detection, pp. 81-105. , Berlin, Germany; Chung, S.P., Mok, A.K., Allergy attack against automatic signature generation (2006) Proceedings of the 9th International Conference on Recent Advances in Intrusion Detection, pp. 61-80. , Berlin, Germany; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I.P., Tygar, J.D., Adversarial machine learning (2011) Proceedings of the 4th ACM Workshop on Security and Artificial Intelligence, pp. 43-58. , New York, NY, USA; Kloft, M., Laskov, P., Security analysis of online centroid anomaly detection (2012) The Journal of Machine Learning Research, 13, pp. 3681-3724; Biggio, B., Nelson, B., Laskov, P., Poisoning attacks against support vector machines (2012) Proceedings of the 29th International Coference on International Conference on Machine Learning, pp. 1467-1474. , Edinburgh, Scotland; Kadloor, S., Kiyavash, N., Venkitasubramaniam, P., Mitigating timing based information leakage in shared schedulers (2012) 2012 Proceedings IEEE INFOCOM, pp. 1044-1052; Kiyavash, N., Coleman, T., Covert timing channels codes for communication over interactive traffic (2009) 2009 IEEE International Conference on Acoustics, Speech and Signal Processing, pp. 1485-1488; Kiyavash, N., Koushanfar, F., Coleman, T.P., Rodrigues, M., A timing channel spyware for the csma/ca protocol (2013) IEEE Transactions on Information Forensics and Security, 8 (3), pp. 477-487; Kadloor, S., Gong, X., Kiyavash, N., Venkitasubramaniam, P., Designing router scheduling policies: A privacy perspective (2012) IEEE Transactions on Signal Processing, 60 (4), pp. 2001-2012; Douceur, J.R., The sybil attack (2002) International Workshop on Peerto-Peer Systems, pp. 251-260. , London, UK; Resnick, P., Sami, R., The information cost of manipulationresistance in recommender systems (2008) Proceedings of the 2008 ACM Conference on Recommender Systems, pp. 147-154. , New York, NY, USA; Yu, H., Shi, C., Kaminsky, M., Gibbons, P.B., Xiao, F., Dsybil: Optimal sybil-resistance for recommendation systems (2009) Proceedings of the 2009 30th IEEE Symposium on Security and Privacy, pp. 283-298. , Washington, DC, USA; Blum, A., Mansour, Y., From external to internal regret (2007) The Journal of Machine Learning Research, 8, pp. 1307-1324. , Dec; Kleinberg, R.D., Niculescu-Mizil, A., Sharma, Y., Regret bounds for sleeping experts and bandits (2008) Proceedings of the 21st Annual Conference on Learning Theory-COLT 2008, pp. 425-436. , Helsinki, Finland; Kanade, V., McMahan, B., Bryan, B., Sleeping experts and bandits with stochastic action availability and adversarial rewards (2009) Proceedings of the Twelfth International Conference on Artificial Intelligence and Statistics, pp. 272-279. , Florida, USA; Freund, Y., Schapire, R.E., Singer, Y., Warmuth, M.K., Using and combining predictors that specialize (1997) Proceedings of the Twenty-Ninth Annual ACM Symposium on the Theory of Computing, pp. 334-343. , New York, NY, USA; Cover, T.M., Behavior of sequential predictors of binary sequences (1965) Proceedings of the 4th Prague Conference on Information Theory, Statistical Decision Functions, Random Processes, Prague, pp. 263-272; Gravin, N., Peres, Y., Sivan, B., Towards optimal algorithms for prediction with expert advice (2016) Proceedings of the Twenty-seventh Annual ACM-SIAM Symposium on Discrete Algorithms, pp. 528-547. , Philadelphia, PA, USA; Abernethy, J., Warmuth, M.K., Yellin, J., When random play is optimal against an adversary (2008) Proceedings of the 21th Annual Workshop on Computational Learning Theory (COLT 2008), , Helsinki, Findland; Truong, A., Kiyavash, N., Optimal adversarial strategies in learning with expert advice (2013) Proceedings of the 52th IEEE Conference on Decision and Control, , Florence, Italia, Dec; Truong, A., Etesami, S.R., Etesami, J., Kiyavash, N., Optimal attack strategies against predictors-learning from expert advice (2017) IEEE Transactions on Information Forensics and Security, 13, pp. 6-19; Blackwell, D., Discounted dynamic programming (1965) The Annals of Mathematical Statistics, 36, pp. 226-235; Bellman, R., (2003) Dynamic Programming, , Princeton University Press; Bertsekas, D.P., (2000) Dynamic Programming and Optimal Control, , 2nd ed. Athena Scientific; Feinberg, A., Shwartz, A., (2002) Handbook of Markov Decision Processes: Methods and Applications, , Kluwer; Lin, W., Kumar, P., Optimal control of a queueing system with two heterogeneous servers (1984) IEEE Transactions on Automatic Control, 29, pp. 696-703. , Aug; Walrand, J., A note on optimal control of a queuing system with two heterogeneous servers (1984) Systems and Control Letters, 4, pp. 131-134; Koole, G., A simple proof of the optimality of a threshold policy in a two-server queueing system (1995) Systems and Control Letters, 26, pp. 301-303. , Dec; Larsen, R., (1981) Control of Multiple Exponential Servers with Application to Computer Systems, , Ph. D. dissertation, University of Maryland at College Park, College Park, MD, USA; Puterman, M.L., Shin, M.C., Modified policy iteration algorithms for discounted markov decision problems (1978) Management Science, 24, pp. 1127-1137. , Jul; Van Nunen, J.A.E.E., A set of successive approximation methods for discounted markovian decision problems (1976) Zeitschrift für Operations Research, 20, pp. 203-208. , Oct; Truong, A., Kiyavash, N., Borkar, V., Convergence analysis for an online recommendation system (2011) Proceedings of the 50th IEEE Conference on Decision and Control and European Control Conference, pp. 3889-3894. , Orlando, Florida, US, Dec",,,,"Institute of Electrical and Electronics Engineers Inc.","19th IEEE International Workshop on Signal Processing Advances in Wireless Communications, SPAWC 2018","25 June 2018 through 28 June 2018",,139030,,9781538635124,,,"English","IEEE Workshop Signal Process. Adv. Wireless Commun. SPAWC",Conference Paper,"Final","",Scopus,2-s2.0-85053453851
"Li G., Xiaoxiao Wu S., Zhang S., Wai H.-T., Scaglione A.","55534065200;57203895658;36057765700;47062284700;7005577332;","Detecting and Localizing Adversarial Nodes Usig Neural Networks",2018,"IEEE Workshop on Signal Processing Advances in Wireless Communications, SPAWC","2018-June",,"8445849","","",,3,"10.1109/SPAWC.2018.8445849","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053439423&doi=10.1109%2fSPAWC.2018.8445849&partnerID=40&md5=f195c8780251b3f7e0fee3cb264f0ac5","Shenzhen University, College of Information Engineering, Shenzhen, China; Arizona State University, School of ECEE, Tempe, AZ, United States","Li, G., Shenzhen University, College of Information Engineering, Shenzhen, China; Xiaoxiao Wu, S., Shenzhen University, College of Information Engineering, Shenzhen, China; Zhang, S., Shenzhen University, College of Information Engineering, Shenzhen, China; Wai, H.-T., Arizona State University, School of ECEE, Tempe, AZ, United States; Scaglione, A., Arizona State University, School of ECEE, Tempe, AZ, United States","This work proposes a new method for securing the gossip algorithm for average consensus on communication networks. The gossip algorithm is appealing for its ability to harness distributed computational resources while adapting to arbitrarily connected networks without coordination overhead, however it is inherently vulnerable to the insider attack by adversarial node since each node locally updates its local states and passes information to its neighbors without supervision. In light of this, this work proposes new methods for detecting and localizing adversarial nodes using a neural network system. We show that our neural network-based method delivers a significantly improved detection and localization performance, compared to the state of the art. © 2018 IEEE.","average consensus; Gossip algorithm; insider attacks; neural networks","Neural networks; Signal processing; Wireless telecommunication systems; Average consensus; Connected networks; Detection and localization; Distributed computational resources; Gossip algorithms; Insider attack; Neural network systems; State of the art; Distributed computer systems",,,,,"Tsitsiklis, J., (1984) Problems in Decentralized Decision Making and Computation, , Ph. D. dissertation, Dept. of Electrical Engineering and Computer Science, M. I. T., Boston, MA; Boyd, S., Ghosh, A., Prabhakar, B., Shah, D., Randomized gossip algorithms (2006) IEEE Trans. Inf. Theory, 52 (6), pp. 2508-2530. , Jun; Dimakis, A., Kar, S., Moura, J., Rabbat, M., Scaglione, A., Gossip algorithms for distributed signal processing (2010) Proceedings of the IEEE, 98 (11), pp. 1847-1864. , Nov; DeGroot, M., Reaching a consensus (1974) Journal of American Statistcal Association, 69, pp. 118-121; Mobilia, M., Does a single zealot affect an infinite group of voters ? (2003) Physical Review Letters, , July; Gentz, R., Wai, H.-T., Scaglione, A., Leshem, A., Detection of datainjection attacks in decentralized learning (2015) Asilomar Conf; Gentz, R., Wu, S.X., Wai, H.T., Scaglione, A., Leshem, A., Data injection attacks in randomized gossiping (2016) IEEE Transactions on Signal and Information Processing over Networks, 2 (4), pp. 523-538; Sundaram, S., Gharesifard, B., (2016) Distributed Optimization under Adversarial Nodes; Kailkhura, B., Brahma, S., Varshney, P.K., Data falsification attacks on consensus-based detection systems (2017) IEEE Transactions on Signal and Information Processing over Networks, 3 (1), pp. 145-158; Cheng, W., Hüllermeier, E., Combining instance-based learning and logistic regression for multilabel classification (2009) Machine Learning, 76 (2-3), pp. 211-225; Zhang, M.L., Zhou, Z.H., A review on multi-label learning algorithms (2014) IEEE Transactions on Knowledge and Data Engineering, 26 (8), pp. 1819-1837; Garcia-Teodoro, P., Diaz-Verdejo, J., Maciá-Fernández, G., Vázquez, E., Anomaly-based network intrusion detection: Techniques, systems and challenges (2009) Computers & Security, 28 (1-2), pp. 18-28; Ahmed, M., Naser Mahmood, A., Hu, J., A survey of network anomaly detection techniques (2016) Journal of Network & Computer Applications, 60, pp. 19-31; Lee, S.C., Heinbuch, D.V., Training a neural-network based intrusion detector to recognize novel attacks (2001) Systems Man & Cybernetics Part A Systems & Humans IEEE Transactions on, 31 (4), pp. 294-299; Doboli, A., Discovery of malicious nodes in wireless sensor networks using neural predictors (2007) Wseas Transactions on Computers Research, 2; Stevanovic, D., Vlajic, N., An, A., Detection of malicious and nonmalicious website visitors using unsupervised neural network learning (2013) Applied Soft Computing, 13 (1), pp. 698-708; Palm, R.B., (2012) Prediction As A Candidate for Learning Deep Hierarchical Models of Data, , Master Thesis",,,,"Institute of Electrical and Electronics Engineers Inc.","19th IEEE International Workshop on Signal Processing Advances in Wireless Communications, SPAWC 2018","25 June 2018 through 28 June 2018",,139030,,9781538635124,,,"English","IEEE Workshop Signal Process. Adv. Wireless Commun. SPAWC",Conference Paper,"Final","",Scopus,2-s2.0-85053439423
"Kwon H., Kim Y., Park K.-W., Yoon H., Choi D.","57197769092;55699558400;22734573000;15061371300;8660876600;","Multi-Targeted Adversarial Example in Evasion Attack on Deep Neural Network",2018,"IEEE Access","6",,"8439941","46084","46096",,19,"10.1109/ACCESS.2018.2866197","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051789606&doi=10.1109%2fACCESS.2018.2866197&partnerID=40&md5=4e8be49cafd6acb0e803a4dc11512180","School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, 34141, South Korea; Department of Electrical Engineering, Korea Military Academy, Seoul, 01819, South Korea; Department of Computer and Information Security, Sejong University, Seoul, 05006, South Korea; Department of Medical Information, Kongju National University, Gongju, 32588, South Korea","Kwon, H., School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, 34141, South Korea; Kim, Y., Department of Electrical Engineering, Korea Military Academy, Seoul, 01819, South Korea; Park, K.-W., Department of Computer and Information Security, Sejong University, Seoul, 05006, South Korea; Yoon, H., School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, 34141, South Korea; Choi, D., Department of Medical Information, Kongju National University, Gongju, 32588, South Korea","Deep neural networks (DNNs) are widely used for image recognition, speech recognition, pattern analysis, and intrusion detection. Recently, the adversarial example attack, in which the input data are only slightly modified, although not an issue for human interpretation, is a serious threat to a DNN as an attack as it causes the machine to misinterpret the data. The adversarial example attack has been receiving considerable attention owing to its potential threat to machine learning. It is divided into two categories: targeted adversarial example and untargeted adversarial example. The untargeted adversarial example happens when machines misclassify an object into an incorrect class. In contrast, the targeted adversarial example attack causes machines to misinterpret the image as the attacker's desired class. Thus, the latter is a more elaborate and powerful attack than the former. The existing targeted adversarial example is a single targeted attack that allows only one class to be recognized. However, in some cases, a multi-targeted adversarial example can be useful for an attacker to make multiple models recognize a single original image as different classes. For example, an attacker can use a single road sign generated by a multi-targeted adversarial example scheme to make model A recognize it as a stop sign and model B recognize it as a left turn, whereas a human might recognize it as a right turn. Therefore, in this paper, we propose a multi-targeted adversarial example that attacks multiple models within each target class with a single modified image. To produce such examples, we carried out a transformation to maximize the probability of different target classes by multiple models. We used the MNIST datasets and TensorFlow library for our experiment. The experimental results showed that the proposed scheme for generating a multi-targeted adversarial example achieved a 100% attack success rate. © 2013 IEEE.","adversarial example; Deep neural network (DNN); evasion attack; machine learning","Artificial intelligence; Image recognition; Intrusion detection; Learning systems; Speech recognition; Traffic signs; Adversarial Example; Different class; Evasion Attack; Original images; Pattern analysis; Potential threats; Target class; Targeted attacks; Deep neural networks",,,,,"Abadi, M., TensorFlow: A system for large-scale machine learning (2016) Proc. OSDI, 16, pp. 265-283; Barreno, M., Nelson, B., Joseph, A.D., Tygar, J., The security of machine learning (2010) Mach. Learn., 81 (2), pp. 121-148; Biggio, B., Nelson, B., Laskov, P., Poisoning attacks against support vector machines (2012) Proc. 29th Int. Conf. Int. Conf. Mach. Learn, pp. 1467-1474; Bishop, C.M., (1995) Neural Networks for Pattern Recognition, , London, U.K.: Oxford Univ. Press; Carlini, N., Hidden voice commands (2016) Proc. USENIX Secur. Symp, pp. 513-530; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) Proc. 10th ACM Workshop Artif. Intell. Secur, pp. 3-14; Carlini, N., Wagner, D., (2017) MagNet and 'Efficient Defenses Against Adversarial Attacks' Are Not Robust to Adversarial Examples, , https://arxiv.org/abs/1711.08478; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Proc. IEEE Symp. Secur. Privacy (SP), pp. 39-57. , May; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., ImageNet: A large-scale hierarchical image database (2009) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 248-255. , Jun; Fawzi, A., Fawzi, O., Frossard, P., Analysis of classifiers' robustness to adversarial perturbations (2015) Mach. Learn., 107 (3), pp. 481-508; Fawzi, A., Moosavi-Dezfooli, S.-M., Frossard, P., The robustness of deep networks: A geometrical perspective (2017) IEEE Signal Process. Mag., 34 (6), pp. 50-62. , Nov; Goodfellow, I., Generative adversarial nets (2014) Proc. Adv. Neural Inf. Process. Syst, pp. 2672-2680; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , https://arxiv.org/abs/1412.6572; Hinton, G., Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups (2012) IEEE Signal Process. Mag., 29 (6), pp. 82-97. , Nov; Kereliuk, C., Sturm, B.L., Larsen, J., Deep learning and music adversaries (2015) IEEE Trans. Multimedia, 17 (11), pp. 2059-2071. , Nov; Kingma, D.P., Ba, J., (2014) Adam: A Method for Stochastic Optimization, , https://arxiv.org/abs/1412.6980; Krizhevsky, A., Nair, V., Hinton, G., (2014) The CIFAR-10 Dataset, , http://www.cs.toronto.edu/kriz/cifar.html; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , https://arxiv.org/abs/1607.02533; Kurakin, A., Goodfellow, I.J., Bengio, S., (2016) Adversarialmachine Learning at Scale, , https://arxiv.org/abs/1611.01236; Kwon, H., Kim, Y., Park, K.-W., Yoon, H., Choi, D., Friend-safe evasion attack: An adversarial example that is correctly recognized by a friendly classifier (2018) Comput. Secur; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324. , Nov; LeCun, Y., Cortes, C., Burges, C.J., (2010) MNIST Handwritten Digit Database. AT&T Labs., , http://yann.lecun.com/exdb/mnist; Meng, D., Chen, H., MagNet: A two-pronged defense against adversarial examples (2017) Proc. ACM SIGSAC Conf. Comput. Commun. Secur, pp. 135-147; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., DeepFool: Asimple and accurate method to fool deep neural networks (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 2574-2582. , Jun; Mosca, A., Magoulas, G.D., Hardening against adversarial examples with the smooth gradient method (2018) Soft Comput., 22 (10), pp. 3203-3213. , May; Mozaffari-Kermani, M., Sur-Kolay, S., Raghunathan, A., Jha, N.K., Systematic poisoning attacks on and defenses for machine learning in healthcare (2015) IEEE J. Biomed. Health Inform., 19 (6), pp. 1893-1905. , Nov; Narodytska, N., Kasiviswanathan, S., Simple black-box adversarial attacks on deep neural networks (2017) Proc. IEEEConf. Comput. Vis. Pattern Recognit. Workshops (CVPRW), pp. 1310-1318. , Jul; Oliveira, G.L., Valada, A., Bollen, C., Burgard, W., Brox, T., Deep learning for human part discovery in images (2016) Proc. IEEE Int. Conf. Robot. Autom. (ICRA), pp. 1634-1641. , May; Osadchy, M., Hernandez-Castro, J., Gibson, S., Dunkelman, O., Perez-Cabo, D., No bot expects the DeepCAPTCHA! Introducing immutable adversarial examples, with applications to CAPTCHA generation (2017) IEEE Trans. Inf. Forensics Security, 12 (11), pp. 2640-2653. , Nov; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proc. ACM Asia Conf. Comput. Commun. Secur, pp. 506-519; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Proc. IEEE Eur. Symp. Secur. Privacy (EuroS&P), pp. 372-387. , Mar; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Proc. IEEE Symp. Secur. Privacy (SP), pp. 582-597. , May; Potluri, S., Diedrich, C., Accelerated deep neural networks for enhanced intrusion detection system (2016) Proc. IEEE21stInt. Conf. Emerg. Technol. Factory Autom. (ETFA), pp. 1-8. , Sep; Rozsa, A., Giinther, M., Rudd, E.M., Boult, T.E., Facial attributes: Accuracy and adversarial robustness (2017) Pattern Recognit. Lett; Schmidhuber, J., Deep learning in neural networks: An overview (2015) Neural Netw., 61, pp. 85-117. , Jan; Shen, S., Jin, G., Gao, K., Zhang, Y., APE-GAN: Adversarial perturbation elimination with GAN (2017) ICLR Submission; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition, , https://arxiv.org/abs/1409.1556; Zander, S., Armitage, G., Branch, P., A survey of covert channels and countermeasures in computer network protocols (2007) IEEE Commun. Surveys Tuts., 9 (3), pp. 44-57. , 3rd Quart; Strauss, T., Hanselmann, M., Junginger, A., Ulmer, H., (2017) Ensemble Methods As A Defense to Adversarial Perturbations Against Deep Neural Networks, , https://arxiv.org/abs/1709.03423; Szegedy, C., (2013) Intriguing Properties of Neural Networks, , https://arxiv.org/abs/1312.6199; Tramer, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses, , https://arxiv.org/abs/1705.07204; Tramer, F., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2017) The Space of Transferable Adversarial Examples, , https://arxiv.org/abs/1704.03453; Zhang, F., Chan, P.P.K., Biggio, B., Yeung, D.S., Roli, F., Adversarial feature selection against evasion attacks (2016) IEEE Trans. Cybern., 46 (3), pp. 766-777. , Mar; Zhang, G., Yan, C., Ji, X., Zhang, T., Zhang, T., Xu, W., Dolphinattack: Inaudible voice commands (2017) Proc. ACM SIGSAC Conf. Comput. Commun. Secur, pp. 103-117","Choi, D.; Department of Medical Information, South Korea; email: sunchoi@kongju.ac.kr",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85051789606
"Marzi Z., Gopalakrishnan S., Madhow U., Pedarsani R.","56380560200;24491814400;7003746022;36574033500;","Sparsity-based Defense Against Adversarial Attacks on Linear Classifiers",2018,"IEEE International Symposium on Information Theory - Proceedings","2018-June",,"8437638","31","35",,10,"10.1109/ISIT.2018.8437638","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052468848&doi=10.1109%2fISIT.2018.8437638&partnerID=40&md5=66b017503b447f6c6266817f84706da8","University of California, Santa Barbara, United States","Marzi, Z., University of California, Santa Barbara, United States; Gopalakrishnan, S., University of California, Santa Barbara, United States; Madhow, U., University of California, Santa Barbara, United States; Pedarsani, R., University of California, Santa Barbara, United States","Deep neural networks represent the state of the art in machine learning in a growing number of fields, including vision, speech and natural language processing. However, recent work raises important questions about the robustness of such architectures, by showing that it is possible to induce classification errors through tiny, almost imperceptible, perturbations. Vulnerability to such 'adversarial attacks', or 'adversarial examples', has been conjectured to be due to the excessive linearity of deep networks. In this paper, we study this phenomenon in the setting of a linear classifier, and show that it is possible to exploit sparsity in natural data to combat \ell-{\infty} -bounded adversarial perturbations. Specifically, we demonstrate the efficacy of a sparsifying front end via an ensemble averaged analysis, and experimental results for the MNIST handwritten digit database. To the best of our knowledge, this is the first work to show that sparsity provides a theoretically rigorous framework for defense against adversarial attacks. © 2018 IEEE.",,"Information theory; Learning algorithms; Natural language processing systems; Network security; Classification errors; Deep networks; Ensemble-averaged; Front end; Handwritten digit; Linear classifiers; State of the art; Deep neural networks",,,,,"Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations (ICLR); Fawzi, A., Moosavi-Dezfooli, S.-M., Frossard, P., The robustness of deep networks: A geometrical perspective (2017) IEEE Signal Processing Magazine, 34 (6), pp. 50-62; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations (ICLR); Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2574-2582; Fawzi, A., Moosavi-Dezfooli, S.-M., Frossard, P., Soatto, S., Classification regions of deep neural networks (2017) ArXiv Preprint arXiv:1705.09552; Poole, B., Lahiri, S., Raghu, M., Sohl-Dickstein, J., Ganguli, S., Exponential expressivity in deep neural networks through transient chaos (2016) Advances in Neural Information Processing Systems (NIPS), pp. 3360-3368; Bhagoji, A.N., Cullina, D., Mittal, P., Dimensionality reduction as a defense against evasion attacks on machine learning classifiers (2017) ArXiv Preprint arXiv:1704.02654; Das, N., Shanbhogue, M., Chen, S.-T., Hohman, F., Chen, L., Kounavis, M.E., Chau, D.H., Keeping the bad guys out: Protecting and vaccinating deep learning with JPEG compression (2017) ArXiv Preprint arXiv:1705.02900; Makhzani, A., Frey, B., K-Sparse autoencoders (2014) International Conference on Learning Representations (ICLR); LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proceedings of the IEEE, 86 (11), pp. 2278-2324; Cohen, A., Daubechies, I., Feauveau, J.-C., Biorthogonal bases of compactly supported wavelets (1992) Communications on Pure and Applied Mathematics, 45 (5), pp. 485-560",,,"Huawei;IEEE;IEEE InformationTheory Society;NSF;Qualcomm","Institute of Electrical and Electronics Engineers Inc.","2018 IEEE International Symposium on Information Theory, ISIT 2018","17 June 2018 through 22 June 2018",,138713,21578095,9781538647806,PISTF,,"English","IEEE Int Symp Inf Theor Proc",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85052468848
"Guo W., He D., Cai N.","35792108400;55745564500;57203050178;","Network Error Correction Coding for Time-Varying Adversarial Errors in a Unicast Network",2018,"IEEE International Symposium on Information Theory - Proceedings","2018-June",,"8437833","836","840",,2,"10.1109/ISIT.2018.8437833","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052466667&doi=10.1109%2fISIT.2018.8437833&partnerID=40&md5=9a2e5625ee10ad006e55901ddb7ad1f9","Xidian University, Xi'an, 710071, China; ShanghaiTech University, Shanghai, 201210, China","Guo, W., Xidian University, Xi'an, 710071, China; He, D., Xidian University, Xi'an, 710071, China; Cai, N., ShanghaiTech University, Shanghai, 201210, China","We consider a unicast network with an adversary who is able to attack a proportion of edges, which is no more than p for 0 < p < 1. Based on the knowledge of the adversary, three cases of attacks are considered: 1) the adversary knows nothing about the source message; 2) the adversary knows the source message but does not know the transmitted codeword; 3) the adversary knows the transmitted codeword. Two classes of code schemes, deterministic code and stochastic code, are designed to assure reliable transmission against the adversarial attack. It is concluded that stochastic code does not provide any more benefit than the deterministic code against the attacking cases 1 and 3. However, when the attacking case 2 is considered, stochastic code would achieve a higher capacity than the deterministic code. © 2018 IEEE.","Network coding; Network error correction; Stochastic code; Time-varying attack","Codes (symbols); Coding errors; Error correction; Stochastic systems; Time varying networks; Classes of codes; Codeword; Network error correction; Reliable transmission; Stochastic code; Time varying; Unicast; Network coding",,,,,"Li, S.-Y.R., Yeung, R.W., Cai, N., Linear network coding (2003) IEEE Transactions on Information Theory, 49 (2), pp. 371-381. , Feb; Ho, T., Medard, M., Koetter, R., Karger, D.R., Effros, M., Shi, J., Leong, B., A random linear network coding approach to multicast (2006) IEEE Trans. Inf. Theory, 52 (10), pp. 4413-4430; Cai, N., Yeung, R.W., Network error correction, part i and II: Basic concepts, upper bounds and lower bounds (2006) Communications in Information and Systems, 6 (1), pp. 19-54; Kotter, R., Kschischang, F.R., Coding for errors and erasures in random network coding (2008) IEEE Transactions on Information Theory, 54 (8), pp. 3579-3591. , Jul; Kadhe, S., Sprintson, A., Zhang, Q., Bakshi, M., Jaggi, S., Reliable and secure communication over adversarial multipath networks: A survey (2015) 2015 10th International Conference on Information, Communications and Signal Processing (ICICS), , Singapore, Dec. 2-4; Dey, B.K., Jaggi, S., Langberg, M., Codes against online adversaries: Large alphabets (2013) IEEE Transactions on Information Theory, 59 (6), pp. 3304-3316. , June; Chen, Z., Jaggi, S., Langberg, M., The capacity of online (causal) qary error-erasure channels (2016) 2016 IEEE International Symposium on Information Theory, pp. 915-919. , July 10-15 Barcelona Spain; Jaggi, S., Langberg, M., Katti, S., Ho, T., Katabi, D., Medard, M., Effros, M., Resilient netowrk coding in the presence of Byzantine adversaries (2008) IEEE Transactions on Information Theory, 54 (6), pp. 2596-2603. , June; Wang, Q., Jaggi, S., Li, S.R., Binary error correcting network codes (2011) 2011 IEEE Information Theory Workshop, pp. 498-502; Csiszár, I., Körner, J., (2011) Information Theory: Coding Theorems for Discrete Memoryless Systems, , Cambridge Press, Cambridge",,,"Huawei;IEEE;IEEE InformationTheory Society;NSF;Qualcomm","Institute of Electrical and Electronics Engineers Inc.","2018 IEEE International Symposium on Information Theory, ISIT 2018","17 June 2018 through 22 June 2018",,138713,21578095,9781538647806,PISTF,,"English","IEEE Int Symp Inf Theor Proc",Conference Paper,"Final","",Scopus,2-s2.0-85052466667
"Zhang Y., Vatedka S., Jaggi S., Sarwate A.D.","57203623899;56609286700;35586878500;14008189100;","Quadratically Constrained Myopic Adversarial Channels",2018,"IEEE International Symposium on Information Theory - Proceedings","2018-June",,"8437457","611","615",,5,"10.1109/ISIT.2018.8437457","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052434831&doi=10.1109%2fISIT.2018.8437457&partnerID=40&md5=8958ea7d57d1702dec7fcc295c64a0c0","Chinese University of Hong Kong, Dept. of Information Engineering, Hong Kong; State University of New Jersey, Dept. of Electrical and Computer Engineering, Rutgers, United States","Zhang, Y., Chinese University of Hong Kong, Dept. of Information Engineering, Hong Kong; Vatedka, S., Chinese University of Hong Kong, Dept. of Information Engineering, Hong Kong; Jaggi, S., Chinese University of Hong Kong, Dept. of Information Engineering, Hong Kong; Sarwate, A.D., State University of New Jersey, Dept. of Electrical and Computer Engineering, Rutgers, United States","We study communication in the presence of a jamming adversary where quadratic power constraints are imposed on the transmitter and the jammer. The jamming signal is assumed to be a function of the codebook, and a noncausal but noisy observation of the transmitted codeword. For a certain range of the noise-to-signal ratios (NSRs) of the transmitter and the jammer, we are able to characterize the capacity of this channel under deterministic encoding. For the remaining NSR regimes, we determine the capacity under the assumption of a small amount of common randomness (at most \mathcal{O}(\log(n)) bits in one sub-regime, and at most \mathcal{O}(n) bits in the other sub-regime) available to the encoder-decoder pair. Our proof techniques include a novel myopic list-decoding result for achievability and a Plotkin-type push attack for the converse in a subregion of the NSRs, which may be of independent interest. A short video explaining our work is available at https://youtu.be/0015-W-xhLM. © 2018 IEEE.",,"Decoding; Signal encoding; Transmitters; Achievability; Common randomness; Encoder-decoder; Jamming signals; List decoding; Noise-to-signal ratios; Noisy observations; Power constraints; Jamming",,,,,"Blackwell, D., Breiman, L., Thomasian, A.J., The capacity of A class of channels under random coding (1960) Ann. Math. Statist., 31 (3), pp. 558-567; Blachman, N., On the capacity of bandlimited channel perturbed by statistically dependent interference (1962) IRE Trans. Inf. Theory, 8, pp. 48-55; Kabatiansky, G.A., Levenshtein, V.I., On bounds for packings on A sphere and in space (1978) Probl. Pered. Informatsii, 14 (1), pp. 3-25; Cohn, H., Zhao, Y., Sphere packing bounds via spherical codes (2014) Duke Math. J., 163 (10), pp. 1965-2002; Hughes, B., Narayan, P., Gaussian arbitrarily varying channels (1987) IEEE Trans. Inf. Theory, 33, pp. 267-284; Csiszár, I., Narayan, P., Capacity of the Gaussian arbitrarily varying channel (1991) IEEE Trans. Inf. Theory, 37, pp. 18-26; Sarwate, A., An AVC perspective on correlated jamming (2012) Proc. IEEE Int. Conf. Signal Proc. and Comm., , Bangalore, India; Haddadpour, F., Siavoshani, M., Bakshi, M., Jaggi, S., On AVCs with quadratic constraints (2013) IEEE Int. Symp. Inf. Theory; Médard, M., Capacity of correlated jamming channels (1997) Proc. Allerton Annual Conf. on Comm., Control and Computing, , Allerton, USA; Shafiee, S., Ulukus, S., Mutual information games in multi-user channels with correlated jamming (2009) IEEE Trans. Inf. Theory, 55, pp. 4598-4607; Baker, C., Chao, I.-F., Information capacity of channels with partially unknown noise. I. Finite-dimensional channels (1996) SIAM J. App. Math., 56, pp. 946-963; Dey, B.K., Jaggi, S., Langberg, M., Sufficiently myopic adversaries are blind (2015) IEEE Int. Symp. Inf. Theory, pp. 1164-1168. , https://arxiv.org/abs/1610.01287; Dey, B.K., Jaggi, S., Langberg, M., Sarwate, A.D., (2016) The Benefit of A 1-bit Jump-start, and the Necessity of Stochastic Encoding, in Jamming Channels, , http://arxiv.org/abs/1602.02384, Tech. Rep., February; Zhang, Y., Vatedka, S., Jaggi, S., Sarwate, A., (2018) Quadratically Constrained Myopic Adversarial Channels, , https://arxiv.org/abs/1801.05951; Sarwate, A.D., Gastpar, M., Rateless codes for AVC models (2010) IEEE Trans. Inf. Theory, 56 (7), pp. 3105-3114. , July; Li, T., Jaggi, S., Quadratically constrained channels with causal adversaries (2018) ISIT; Langberg, M., Private codes or succinct random codes that are (almost) perfect (2004) Proc. IEEE Symp. Found. Comp. Sci., , Rome, Italy",,,"Huawei;IEEE;IEEE InformationTheory Society;NSF;Qualcomm","Institute of Electrical and Electronics Engineers Inc.","2018 IEEE International Symposium on Information Theory, ISIT 2018","17 June 2018 through 22 June 2018",,138713,21578095,9781538647806,PISTF,,"English","IEEE Int Symp Inf Theor Proc",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85052434831
"Chen Y., Kar S., Moura J.M.F.","56940487400;18042324900;7102993409;","Attack Resilient Distributed Estimation: A Consensus+Innovations Approach",2018,"Proceedings of the American Control Conference","2018-June",,"8430980","1015","1020",,12,"10.23919/ACC.2018.8430980","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052608299&doi=10.23919%2fACC.2018.8430980&partnerID=40&md5=1d2fac9092917030b9a49acc87ec73cf","Carnegie Mellon University, Department of Electrical and Computer Engineering, Pittsburgh, PA  15217, United States","Chen, Y., Carnegie Mellon University, Department of Electrical and Computer Engineering, Pittsburgh, PA  15217, United States; Kar, S., Carnegie Mellon University, Department of Electrical and Computer Engineering, Pittsburgh, PA  15217, United States; Moura, J.M.F., Carnegie Mellon University, Department of Electrical and Computer Engineering, Pittsburgh, PA  15217, United States","This paper studies fully distributed parameter estimation under sensor attacks. A group of agents make measurements of a bounded parameter and a fraction of the agents' sensor measurements falls under integrity attack. When a sensor is under attack, its measurement can take any value as determined by the attacker. The agents exchange messages over a communication network to ensure that all agents are able to correctly estimate the parameter of interest. This paper presents a consensus+innovations algorithm for attack resilient distributed parameter estimation. The algorithm achieves the same level of resilience as the most resilient centralized estimator - if less than half of the agents' sensors are under attack, then all agents correctly estimate the parameter of interest, regardless of the topology of the inter-agent communication network, as long as it is connected. This paper illustrates the performance of the algorithm under adversarial attack through numerical simulations. © 2018 AACC.",,,,,,,"Stolpe, M., The internet of things: Opportunities and challenges for distributed data analysis (2016) ACM SIGKDD Explorations Newsletter, 18 (1), pp. 15-34. , Jun; Chen, Y., Kar, S., Moura, J.M.F., Cyber-physical systems: Dynamic sensor attacks and strong observability (2015) Proc. of the 40th IEEE International Conf. on Acoustics, Speech and Signal Processing (ICASSP), pp. 1752-1756. , Brisbane, Australia, Apr; Chen, Y., Kar, S., Moura, J.M.F., Dynamic attack detection in cyber-physical systems with side initial state information (2017) IEEE Trans. Autom. Control, 62 (9), pp. 4618-4624. , Sep; Pasqualetti, F., Dörfler, F., Bullo, F., Attack detection and identification in cyber-physical systems (2013) IEEE Trans. Autom. Control, 58 (11), pp. 2715-2729. , Nov; Fawzi, H., Tabuada, P., Diggavi, S., Secure estimation and control for cyber-physical systems under adversarial attacks (2014) IEEE Trans. Autom. Control, 59 (6), pp. 1454-1467. , Jun; Chen, Y., Kar, S., Moura, J.M.F., Cyber physical attacks with control objectives (2017) IEEE Trans. Autom. Control, (99), pp. 1-8. , Aug; Chen, Y., Kar, S., Moura, J.M.F., Optimal attack strategies subject to detection constraints against cyber-physical systems (2017) IEEE Trans. Control. Network. Systems, (99), pp. 1-12. , Mar; Vempaty, A., Tong, L., Varshney, P.K., Distributed inference with Byzantine data (2013) IEEE Signal Process. Mag, 30 (5), pp. 65-75. , Sep; Kailkhura, B., Han, Y.S., Brahma, S., Varshney, P.K., Distributed Bayesian detection in the presence of Byzantine data (2015) IEEE Trans. Signal Process, 63 (19), pp. 5250-5263. , Oct; Chen, Y., Kar, S., Moura, J.M.F., (2017) Distributed Estimation under Sensor Attacks, pp. 1-16. , Oct; Kar, S., Moura, J.M.F., Convergence rate analysis of distributed gossip (linear parameter) estimation: Fundamental limits and tradeoffs (2011) IEEE J. Select. Topics Signal Process, 5 (4), pp. 674-690. , Aug; Kar, S., Moura, J.M.F., Consensus+innovations distributed inference over networks (2013) IEEE Signal Process. Mag, 30 (3), pp. 99-109. , May; Kar, S., Moura, J.M.F., Ramanan, K., Distributed parameter estimation in sensor networks: Nonlinear observation models and imperfect communication (2012) IEEE Trans. Inf. Theory, 58 (6), pp. 3575-3605. , Jun; Kar, S., Moura, J.M.F., Poor, H.V., Distributed linear parameter estimation: Asymptotically efficient adaptive strategies (2013) SIAM Journal of Control and Optimization, 51 (3), pp. 2200-2229. , May; LeBlanc, H.J., Zhang, H., Koustsoukos, X., Sundaram, S., Resilient asymptotic consensus in robust networks (2015) IEEE J. Select. Areas in Comm, 31 (4), pp. 766-781. , Apr; Pasqualetti, F., Bicchi, A., Bullo, F., Consensus computation in unreliable networks: A system theoretic approach (2012) IEEE Trans. Autom. Control, 57 (1), pp. 90-104. , Jan; Sundaram, S., Hadjicostis, C.N., Distributed function calculation via linear iterative strategies in the presence of malicious agents (2011) IEEE Trans. Autom. Control, 56 (7), pp. 1495-1508. , Jul; Sundaram, S., Gharesifard, B., (2016) Distributed Optimization under Adversarial Nodes, pp. 1-13. , Jun; Bollobás, B., (1998) Modern Graph Theory, , New York, NY: Springer-Verlag; Shoukry, Y., Tabuada, P., Event-triggered state observers for sparse sensor noise/attack (2016) IEEE Trans. Autom. Control, 61 (8), pp. 2079-2091. , Aug; Lamport, L., Shostak, R., Pease, M., The Byzantine generals problem (1982) ACM Transactions on Programming Languages and Systems, 4 (3), pp. 382-401. , Jul; Teixeira, A., Pérez, D., Sandberg, H., Johansson, K.H., Attack models and scenarios for networked control systems (2012) Proc. 1st ACM International Conf. on High Confidence Networked Systems, pp. 55-64. , Beijing, China, Apr; Chen, Y., Kar, S., Moura, J.M.F., (2018) Resilient Distributed Estimation Through Adversary Detection, pp. 1-15. , Jan",,,"","Institute of Electrical and Electronics Engineers Inc.","2018 Annual American Control Conference, ACC 2018","27 June 2018 through 29 June 2018",,138710,07431619,9781538654286,PRACE,,"English","Proc Am Control Conf",Conference Paper,"Final","",Scopus,2-s2.0-85052608299
"Jia R., Konstantakopoulos I.C., Li B., Spanos C.","56438847100;56440284300;57188689924;7004447999;","Poisoning Attacks on Data-Driven Utility Learning in Games",2018,"Proceedings of the American Control Conference","2018-June",,"8431872","5774","5780",,4,"10.23919/ACC.2018.8431872","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052603738&doi=10.23919%2fACC.2018.8431872&partnerID=40&md5=924eab2c3fa0a9eee0722785e26e7d1b","University of California, Department of Electrical Engineering and Computer Sciences, Berkeley, United States","Jia, R., University of California, Department of Electrical Engineering and Computer Sciences, Berkeley, United States; Konstantakopoulos, I.C., University of California, Department of Electrical Engineering and Computer Sciences, Berkeley, United States; Li, B., University of California, Department of Electrical Engineering and Computer Sciences, Berkeley, United States; Spanos, C., University of California, Department of Electrical Engineering and Computer Sciences, Berkeley, United States","Game theory has been employed for modeling agents' decisions in various science and engineering fields. Game theoretic analysis often assumes that the utility function of each agent is known a priori, and yet this assumption does not hold for many real-world applications. The combination of Internet of Things (IoT) and advanced data analysis techniques has stimulated fruitful research on learning agents' utility functions from data. Just as many other data-driven methods, utility learning also suffers from potential security risks. Due to the great economic value of accurate forecasting of agents' behaviors, there are huge incentives for adversaries to attack utility learning methods by poisoning training datasets and mislead predictions to achieve malicious goals. In this paper, we introduce and analyze optimal poisoning attack strategies in order to understand adversarial actions and further encourage potential defenses. Moreover, we study how an adversary might disguise the attacks by mimicking normal actions. The proposed attack strategies are evaluated on both synthetic and real-world social energy game data, and the results show that the root mean squared error in predicting agents' actions increases by up to 67 % by adding only 5 % well-crafted poisoning training instances. © 2018 AACC.",,,,,,,"Bertsimas, D., Gupta, V., Paschalidis, I.C., Data-driven estimation in equilibrium using inverse optimization (2015) Mathematical Programming, 153 (2), pp. 595-633; Tsai, D., Molloy, T.L., Perez, T., Inverse two-player zero-sum dynamic games (2016) Control Conference (AuCC), 2016 Australian. IEEE, pp. 192-196; Kuleshov, V., Schrijvers, O., Inverse game theory (2015) Web and Internet Economics; Konstantakopoulos, I.C., Ratliff, L.J., Jin, M., Sastry, S.S., Spanos, C.J., A robust utility learning framework via inverse optimization (2017) IEEE Transactions on Control Systems Technology; Liu, Y., Chen, X., Liu, C., Song, D., (2016) Delving into Transferable Adversarial Examples and Black-box Attacks; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Li, B., Vorobeychik, Y., Feature cross-substitution in adversarial classification (2014) Advances in Neural Information Processing Systems, Ser. NIPS, pp. 2087-2095; Evtimov, I., Eykholt, K., Fernandes, E., Kohno, T., Li, B., Prakash, A., Rahmati, A., Song, D., (2017) Robust Physical-world Attacks on Machine Learning Models; Li, B., Vorobeychik, Y., Scalable optimization of randomized operational decisions in adversarial classification settings (2015) Proceedings of the Eighteenth International Conference on Artificial Intelligence and Statistics, pp. 599-607; Li, B., Wang, Y., Singh, A., Vorobeychik, Y., Data poisoning attacks on factorization-based collaborative filtering (2016) Advances in Neural Information Processing Systems, pp. 1885-1893; Biggio, B., Didaci, L., Fumera, G., Roli, F., Poisoning attacks to compromise face templates (2013) Biometrics (ICB), 2013 International Conference On. IEEE, pp. 1-7; Ratliff, L.J., Mazumdar, E., (2017) Risk-sensitive Inverse Reinforcement Learning Via Gradient Methods; Salant, S.W., Switzer, S., Reynolds, R.J., Losses from horizontal merger: The effects of an exogenous change in industry structure on cournot-nash equilibrium (1983) The Quarterly Journal of Economics, 98 (2), pp. 185-199; Rosen, J.B., Existence and uniqueness of equilibrium points for concave n-person games (1965) Econometrica, 33 (3), p. 520; Ratliff, L.J., Burden, S.A., Sastry, S.S., On the Characterization of Local Nash Equilibria in Continuous Games (2016) IEEE Trans. on Autom. Control, 61 (8), pp. 2301-2307; Ratliff, L.J., Dong, R., Ohlsson, H., Sastry, S.S., Incentive design and utility learning via energy disaggregation (2014) IFAC Proceedings Volumes, 47 (3), pp. 3158-3163; Shannon, C.E., Communication theory of secrecy systems (1949) Bell Labs Technical Journal, 28 (4), pp. 656-715; Xiao, H., Biggio, B., Brown, G., Fumera, G., Eckert, C., Roli, F., Is feature selection secure against training data poisoning (2015) International Conference on Machine Learning, pp. 1689-1698; Biggio, B., Nelson, B., Laskov, P., Poisoning attacks against support vector machines (2012) ICML; Welling, M., Teh, Y.W., Bayesian learning via stochastic gradient langevin dynamics (2011) Proceedings of the 28th International Conference on Machine Learning (ICML-11), pp. 681-688; Ratliff, L.J., Jin, M., Konstantakopoulos, I.C., Spanos, C., Sastry, S.S., Social game for building energy efficiency: Incentive design (2014) Communication, Control, and Computing (Allerton), 2014 52nd Annual Allerton Conference On. IEEE, pp. 1011-1018; Jin, M., Jia, R., Kang, Z., Konstantakopoulos, I.C., Spanos, C.J., Presencesense: Zero-training algorithm for individual presence detection based on power monitoring (2014) Proceedings of the 1st ACM Conference on Embedded Systems for Energy-Efficient Buildings. ACM, pp. 1-10; Tversky, A., Kahneman, D., The framing of decisions and the psychology of choice (1985) Environmental Impact Assessment, Technology Assessment, and Risk Analysis, pp. 107-129. , Springer","Jia, R.; University of California, United States; email: fruoxijia@berkeley.edu",,"","Institute of Electrical and Electronics Engineers Inc.","2018 Annual American Control Conference, ACC 2018","27 June 2018 through 29 June 2018",,138710,07431619,9781538654286,PRACE,,"English","Proc Am Control Conf",Conference Paper,"Final","",Scopus,2-s2.0-85052603738
"Mitra A., Sundaram S.","56080788000;15926451900;","Secure Distributed State Estimation of an LTI System over Time-Varying Networks and Analog Erasure Channels",2018,"Proceedings of the American Control Conference","2018-June",,"8431060","6578","6583",,14,"10.23919/ACC.2018.8431060","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052602491&doi=10.23919%2fACC.2018.8431060&partnerID=40&md5=3874312186df6d6f01ea5bf6223ac7d5","Purdue University, School of Electrical and Computer Engineering, United States","Mitra, A., Purdue University, School of Electrical and Computer Engineering, United States; Sundaram, S., Purdue University, School of Electrical and Computer Engineering, United States","We study the problem of collaboratively estimating the state of an LTI system monitored by a network of sensors (nodes), subject to the following important practical considerations: (i) certain sensors might be arbitrarily compromised by an adversary and (ii) the underlying communication graph governing the flow of information across sensors might be time-varying. We first analyze a scenario involving intermittent communication losses that preserve certain information flow patterns over bounded intervals of time. By equipping the sensors with adequate memory, we show that one can obtain a fully distributed, provably correct state estimation algorithm that accounts for arbitrary adversarial behavior, provided certain conditions are met by the network topology. We then argue that our approach can handle bounded communication delays as well. Next, we explore a case where each communication link stochastically drops packets based on an analog erasure channel model. For this setup, we propose state estimate update and information exchange rules, along with conditions on the network topology and packet drop probabilities, that guarantee mean-square stability despite arbitrary adversarial attacks. © 2018 AACC.",,,,,,,"Estrin, D., Govindan, R., Heidemann, J., Kumar, S., Next century challenges: Scalable coordination in sensor networks (1999) Proceedings of the Annual ACM/IEEE International Conference on Mobile Computing and Networking. ACM, pp. 263-270; Park, S., Martins, N.C., Design of distributed LTI observers for state omniscience (2016) IEEE Transactions on Automatic Control; Mitra, A., Sundaram, S., Distributed observers for LTI systems (2018) IEEE Transactions on Automatic Control; Wang, L., Morse, A., A distributed observer for a time-invariant linear system (2017) IEEE Transactions on Automatic Control; Fawzi, H., Tabuada, P., Diggavi, S., Secure estimation and control for cyber-physical systems under adversarial attacks (2014) IEEE Transactions on Automatic Control, 59 (6), pp. 1454-1467; Pasqualetti, F., Dörfler, F., Bullo, F., Attack detection and identification in cyber-physical systems (2013) IEEE Transactions on Automatic Control, 58 (11), pp. 2715-2729; Chong, M.S., Wakaiki, M., Hespanha, J.P., Observability of linear systems under adversarial attacks (2015) Proceedings of the American Control Conference, pp. 2439-2444; Bai, C.-Z., Pasqualetti, F., Gupta, V., Data-injection attacks in stochastic control systems: Detectability and performance tradeoffs (2017) Automatica, 82, pp. 251-260; Matei, I., Baras, J.S., Srinivasan, V., Trust-based multi-agent filtering for increased smart grid security (2012) Proceedings of the Mediterranean Conference on Control & Automation, pp. 716-721; Khan, U., Stankovic, A.M., Secure distributed estimation in cyber-physical systems (2013) Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing, pp. 5209-5213; Deghat, M., Ugrinovskii, V., Shames, I., Langbort, C., Detection of biasing attacks on distributed estimation networks (2016) Proceedings of the IEEE Conference on Decision and Control, pp. 2134-2139; Mitra, A., Sundaram, S., Secure distributed observers for a class of linear time invariant systems in the presence of Byzantine adversaries (2016) Proceedings of the IEEE Conference on Decision and Control, pp. 2709-2714; Saldana, D., Prorok, A., Sundaram, S., Campos, M.F., Kumar, V., Resilient consensus for time-varying networks of dynamic agents (2017) Proceedings of the American Control Conference, pp. 252-258; Dibaji, S.M., Ishii, H., Resilient consensus of second-order agent networks: Asynchronous update rules with delays (2017) Automatica, 81, pp. 123-132; Vaidya, N.H., Tseng, L., Liang, G., Iterative approximate Byzantine consensus in arbitrary directed graphs (2012) Proceedings of the ACM Symposium on Principles of Distributed Computing, pp. 365-374; Leblanc, H.J., Zhang, H., Koutsoukos, X., Sundaram, S., Resilient asymptotic consensus in robust networks (2013) IEEE Journal on Selected Areas in Communications, 31 (4), pp. 766-781; Sundaram, S., Gharesifard, B., Consensus-based distributed optimization with malicious nodes (2015) Proceedings of the Annual Allerton Conference on Communication, Control and Computing; Su, L., Vaidya, N., (2015) Byzantine Multi-agent Optimization: Part i; Dolev, D., Lynch, N.A., Pinter, S.S., Stark, E.W., Weihl, W.E., Reaching approximate agreement in the presence of faults (1986) Journal of the ACM (JACM), 33 (3), pp. 499-516; Mitra, A., Sundaram, S., (2018) Secure Distributed State Estimation of An LTI System over Time-varying Networks and Analog Erasure Channels; Mitra, A., Sundaram, S., (2018) Resilient Distributed State Estimation for LTI Systems; Sundaram, S., Hadjicostis, C.N., Distributed function calculation via linear iterative strategies in the presence of malicious agents (2011) IEEE Transactions on Automatic Control, 56 (7), pp. 1495-1508; Pasqualetti, F., Bicchi, A., Bullo, F., Consensus computation in unreliable networks: A system theoretic approach (2012) IEEE Transactions on Automatic Control, 57 (1), pp. 90-104; Elia, N., Remote stabilization over fading channels (2005) Systems & Control Letters, 54 (3), pp. 237-249; Hespanha, J.P., Naghshtabrizi, P., Xu, Y., A survey of recent results in networked control systems (2007) Proceedings of the IEEE, 95 (1), pp. 138-162",,,"","Institute of Electrical and Electronics Engineers Inc.","2018 Annual American Control Conference, ACC 2018","27 June 2018 through 29 June 2018",,138710,07431619,9781538654286,PRACE,,"English","Proc Am Control Conf",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85052602491
"Dadras S., Dadras S., Winstead C.","56875319200;24778187600;7004602618;","Reachable Set Analysis of Vehicular Platooning in Adversarial Environment",2018,"Proceedings of the American Control Conference","2018-June",,"8431759","5568","5575",,16,"10.23919/ACC.2018.8431759","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052586393&doi=10.23919%2fACC.2018.8431759&partnerID=40&md5=35fd69ca135b4aa1439fead0f4726956","Utah State University, Electrical and Computer Engineering Department, Logan, UT  84322, United States","Dadras, S., Utah State University, Electrical and Computer Engineering Department, Logan, UT  84322, United States; Dadras, S., Utah State University, Electrical and Computer Engineering Department, Logan, UT  84322, United States; Winstead, C., Utah State University, Electrical and Computer Engineering Department, Logan, UT  84322, United States","In this paper, we propose a method based on reachable set theory to investigate adversarial behavior in automated vehicle platoons. Vehicular platoons have been developed to increase highway throughput and safety, and to enhance driving comfort. The resulting deployment of cyber-physical technology in critical infrastructure is increasingly attractive to both hackers and security researchers. To ensure safety and privacy of vehicle occupants, it is essential to identify the vulnerabilities of platoon systems. In this paper, we study the attacker's capabilities under input constraints during two types of attack: motion modification and integral attacks. Using ellipsoidal techniques, we investigate the extent of an attacker's ability to manipulate the control variables and states of a platoon resulting in oscillatory motion or collision. The outcomes of our analysis are demonstrated by an example. © 2018 AACC.",,,,,,,"Kavathekar, P., Chen, Y., Vehicle platooning: A brief survey and categorization (2011) ASME 2011 International Design Engineering Technical Conferences and Computers and Information in Engineering Conference. American Society of Mechanical Engineers, pp. 829-845; Van Nunen, E., Kwakkernaat, R., Ploeg, J., Netten, B.D., Cooperative competition for future mobility (2012) IEEE Transactions on Intelligent Transportation Systems, 13 (3), pp. 1018-1025; Hedrick, J., (1999) Constant Spacing Strategies for Platooning in Automated Highway Systems; Sheikholeslam, S., Desoer, C.A., Longitudinal control of a platoon of vehicles (1990) American Control Conference, 1990. IEEE, pp. 291-296; Dadras, S., (2017) Path Tracking Using Fractional Order Extremum Seeking Controller for Autonomous Ground Vehicle, , https://doi.org/10.4271/2017-01-0094, SAE Technical Paper. SAE International, 03; Shladover, S.E., Desoer, C.A., Hedrick, J.K., Tomizuka, M., Walrand, J., Zhang, W.-B., McMahon, D.H., McKeown, N., Automated vehicle control developments in the path program (1991) IEEE Transactions on Vehicular Technology, 40 (1), pp. 114-130; Swaroop, D., (1997) String Stability of Interconnected Systems: An Application to Platooning in Automated Highway Systems, , California Partners for Advanced Transit and Highways (PATH); Rajamani, R., Tan, H.-S., Law, B.K., Zhang, W.-B., Demonstration of integrated longitudinal and lateral control for the operation of automated vehicles in platoons (2000) IEEE Transactions on Control Systems Technology, 8 (4), pp. 695-708; Shaw, E., Hedrick, J.K., String stability analysis for heterogeneous vehicle strings (2007) American Control Conference, 2007. ACC'07. IEEE, pp. 3118-3125; Kianfar, R., Falcone, P., Fredriksson, J., A control matching model predictive control approach to string stable vehicle platooning (2015) Control Engineering Practice, 45, pp. 163-173. , http://www.sciencedirect.com/science/article/pii/S0967066115300228; Litman, T., (2017) Autonomous Vehicle Implementation Predictions; Verburg, D.J., Der Van Knaap, M.A.C., Ploeg, J., Vehil: Developing and testing intelligent vehicles (2002) Intelligent Vehicle Symposium, 2002. IEEE, 2, pp. 537-544. , June; Malakorn, K.J., Park, B., Assessment of mobility, energy, and environment impacts of intellidrive-based cooperative adaptive cruise control and intelligent traffic signal control (2010) Sustainable Systems and Technology (ISSST), 2010 IEEE International Symposium On. IEEE, pp. 1-6; Kaur, M., Martin, J., Hu, H., Comprehensive view of security practices in vehicular networks (2016) Connected Vehicles and Expo (ICCVE), 2016 International Conference On. IEEE, pp. 19-26; Dadras, S., Winstead, C., (2018) Collaborative Attacks on Vehicular Platooning; Dadras, S., Gerdes, R.M., Sharma, R., Vehicular platooning in an adversarial environment (2015) Proceedings of the 10th ACM Symposium on Information, Computer and Communications Security, Ser. Asia CCS '15, pp. 167-178. , http://doi.acm.org/10.1145/2714576.2714619, New York, NY, USA: ACM; Dadras, S., Winstead, C., (2018) Insider Vs. Outsider Threats to Autonomous Vehicle Platooning; DeBruhl, B., Weerakkody, S., Sinopoli, B., Tague, P., Is your commute driving you crazy: A study of misbehavior in vehicular platoons (2015) Proceedings of the 8th ACM Conference on Security & Privacy in Wireless and Mobile Networks. ACM, p. 22; Dadras, S., Winstead, C., (2017) Cybersecurity of Autonomous Vehicle Platooning; Dadras, S., Dadras, S., Winstead, C., Identification of the attacker in cyber-physical systems with an application to vehicular platooning in adversarial environment (2018) 2018 American Control Conference (ACC), , June; Ghanavati, M., Chakravarthy, A., Menon, P., PDE-based analysis of automotive cyber-attacks on highways (2017) 2017 American Control Conference (ACC), pp. 1833-1838. , May; Ghanavati, M., Chakravarthy, A., Menon, P.P., Analysis of automotive cyber-attacks on highways using partial differential equation models (2017) IEEE Transactions on Control of Network Systems, (99), p. 1; Bokanowski, O., Forcadel, N., Zidani, H., Reachability and minimal times for state constrained nonlinear problems without any controllability assumption (2010) SIAM Journal on Control and Optimization, 48 (7), pp. 4292-4316; Mitchell, I.M., Bayen, A.M., Tomlin, C.J., A time-dependent Hamilton-jacobi formulation of reachable sets for continuous dynamic games (2005) IEEE Transactions on Automatic Control, 50 (7), pp. 947-957; Fisac, J.F., Chen, M., Tomlin, C.J., Sastry, S.S., Reach-avoid problems with time-varying dynamics, targets and constraints (2015) Proceedings of the 18th International Conference on Hybrid Systems: Computation and Control. ACM, pp. 11-20; Chen, M., Hu, Q., Mackin, C., Fisac, J.F., Tomlin, C.J., Safe platooning of unmanned aerial vehicles via reachability (2015) Decision and Control (CDC), 2015 IEEE 54th Annual Conference On. IEEE, pp. 4695-4701; Chen, M., Hu, Q., Fisac, J.F., Akametalu, K., Mackin, C., Tomlin, C.J., Reachability-based safety and goal satisfaction of unmanned aerial platoons on air highways (2017) Journal of Guidance, Control, and Dynamics; Dabadie, C., Kaynama, S., Tomlin, C.J., A practical reachabilitybased collision avoidance algorithm for sampled-data systems: Application to ground robots (2014) Intelligent Robots and Systems (IROS 2014), 2014 IEEE/RSJ International Conference On. IEEE, pp. 4161-4168; Ding, J., Sprinkle, J., Sastry, S.S., Tomlin, C.J., Reachability calculations for automated aerial refueling (2008) Decision and Control, 2008. CDC 2008. 47th IEEE Conference On. IEEE, pp. 3706-3712; Yanakiev, D., Kanellakopoulos, I., A simplified framework for string stability analysis in ahs (1996) PROCEEDINGS of the 13TH IFAC WORLD CONGRESS, pp. 177-182; Gagarinov, R., Kurzhanski, A., (2014) Ellipsoidal Toolbox; Kurzhanskii, A., Valyi, I., (1997) Ellipsoidal Calculus for Estimation and Control, , Nelson Thornes; Guernic, C.L., Girard, A., Reachability analysis of linear systems using support functions (2010) Nonlinear Analysis: Hybrid Systems, 4 (2), pp. 250-262. , http://www.sciencedirect.com/science/article/pii/S1751570X09000387, fIFACg World Congress 2008; Kurzhanski, A.B., Varaiya, P., On ellipsoidal techniques for reachability analysis. part i: External approximations (2002) Optimization Methods and Software, 17 (2), pp. 177-206; Chernousko, F.L., (1993) State Estimation for Dynamic Systems, , CRC Press; Zhou, Y., Baras, J.S., Reachable set approach to collision avoidance for uavs (2015) 2015 54th IEEE Conference on Decision and Control (CDC), pp. 5947-5952. , Dec",,,"","Institute of Electrical and Electronics Engineers Inc.","2018 Annual American Control Conference, ACC 2018","27 June 2018 through 29 June 2018",,138710,07431619,9781538654286,PRACE,,"English","Proc Am Control Conf",Conference Paper,"Final","",Scopus,2-s2.0-85052586393
"Ren X., Mo Y.","56337887100;26422460300;","Multiple Hypothesis Testing in Adversarial Environments: A Game-theoretic Approach",2018,"Proceedings of the American Control Conference","2018-June",,"8430768","967","972",,1,"10.23919/ACC.2018.8430768","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052583802&doi=10.23919%2fACC.2018.8430768&partnerID=40&md5=b8265c8ea798d2ecc07a872ba95111b9","Nanyang Technological University, School of Electrical and Electronics Engineering, Singapore","Ren, X., Nanyang Technological University, School of Electrical and Electronics Engineering, Singapore; Mo, Y., Nanyang Technological University, School of Electrical and Electronics Engineering, Singapore","This paper considers hypothesis testing using multiple sensors, among which some might be compromised and send arbitrary data. There exist no less than two hypotheses, which is an extension of the binary hypothesis testing in our recent work [1]. The exponent rate, under which the worst-case probability of detection error goes to zero, is adopted as the performance metric. The problem is formulated in a game theoretic way and an equilibrium pair of attack and detection strategies is given. We also provide a simplified equilibrium detection algorithm when the mean of Gaussian noises is to be determined. Two extensions are also studied and a Nash equilibrium is provided for each case using a similar methodology. In the first extension, composite hypothesis testing is studied, i.e., the distribution of observations under each hypothesis is not known exactly but is characterized by a (unknown) parameter. In the second one, heterogeneous sensors are used to collect measurements. © 2018 AACC.",,,,,,,"Yan, J., Ren, X., Mo, Y., Sequential Detection in Adversarial Environments, , http://yilinmo.github.io/papers/cdc17-1.html; Rawat, A.S., Anand, P., Chen, H., Varshney, P.K., Collaborative spectrum sensing in the presence of byzantine attacks in cognitive radio networks (2011) IEEE Transactions on Signal Processing, 59 (2), pp. 774-786; Mo, Y., Sinopoli, B., Secure estimation in the presence of integrity attacks (2015) IEEE Transactions on Automatic Control, 60 (4), pp. 1145-1151; Pajic, M., Lee, I., Pappas, G.J., Attack-resilient state estimation for noisy dynamical systems (2017) IEEE Transactions on Control of Network Systems, 4 (1), pp. 82-92; Han, D., Mo, Y., Xie, L., (2015) Convex Optimization Based State Estimation Against Sparse Integrity Attacks, , http://arxiv.org/abs/1511.07218, abs/1511. 07218; Huber, P.J., A robust version of the probability ratio test (1965) The Annals of Mathematical Statistics, 36 (6), pp. 1753-1758; Kassam, S.A., Poor, H.V., Robust techniques for signal processing: A survey (1985) Proceedings of the IEEE, 73 (3), pp. 433-481; Huber, P.J., (2011) Robust Statistics, , Springer; Marano, S., Matta, V., Tong, L., Distributed detection in the presence of byzantine attacks (2009) IEEE Transactions on Signal Processing, 57 (1), pp. 16-29; Mo, Y., Hespanha, J.P., Sinopoli, B., Resilient detection in the presence of integrity attacks (2014) IEEE Transactions on Signal Processing, 62 (1), pp. 31-43; Vamvoudakis, K.G., Hespanha, J.P., Sinopoli, B., Mo, Y., Detection in adversarial environments (2014) IEEE Transactions on Automatic Control, 59 (12), pp. 3209-3223; Ren, X., Yan, J., Mo, Y., Binary hypothesis testing with byzantine sensors: Fundamental trade-off between security and efficiency (2018) IEEE Transactions on Signal Processing, 66, pp. 1454-1468; Kerckhoffs, A., (1978) La Cryptographie Militaire, , University Microfilms; Dembo, A., Zeitouni, O., (2009) Large Deviations Techniques and Applications, 38. , Springer Science & Business Media; Chernoff, H., A measure of asymptotic efficiency for tests of a hypothesis based on the sum of observations (1952) The Annals of Mathematical Statistics, pp. 493-507; Ren, X., Mo, Y., Multiple Hypothesis Testing in Adversarial Environments: A Game-theoretic Approach, , http://yilinmo.github.io/papers/acc18.html, Tech. Rep; Osborne, M.J., Rubinstein, A., (1994) A Course in Game Theory, , MIT press",,,"","Institute of Electrical and Electronics Engineers Inc.","2018 Annual American Control Conference, ACC 2018","27 June 2018 through 29 June 2018",,138710,07431619,9781538654286,PRACE,,"English","Proc Am Control Conf",Conference Paper,"Final","",Scopus,2-s2.0-85052583802
"Dadras S., Dadras S., Winstead C.","56875319200;24778187600;7004602618;","Identification of the Attacker in Cyber-Physical Systems with an Application to Vehicular Platooning in Adversarial Environment",2018,"Proceedings of the American Control Conference","2018-June",,"8431648","5560","5567",,11,"10.23919/ACC.2018.8431648","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052574683&doi=10.23919%2fACC.2018.8431648&partnerID=40&md5=112f6df6c4514822beeba3c5de99cd76","Electrical and Computer Engineering Department, Utah State University, Logan, UT  84321, United States","Dadras, S., Electrical and Computer Engineering Department, Utah State University, Logan, UT  84321, United States; Dadras, S., Electrical and Computer Engineering Department, Utah State University, Logan, UT  84321, United States; Winstead, C., Electrical and Computer Engineering Department, Utah State University, Logan, UT  84321, United States","Cyber-Physical Systems (CPS) are systems with tight coupling between integration of physical, computational and networking components. Control systems play an important role to help these systems to adhere to their desired performance. Having a reliable and secure control system which can cope with high risk situations and various attacks is one of the bottlenecks for real world cyber-physical systems. It has been proven that using control modification attack, where the adversary modifies the sensor information or the control law, can disrupt the desired performance of the system. In this paper, a novel scheme is presented to detect and identify the attacker in control systems. The detection algorithm is the combination of the system identification method and machine learning technique which effectively recognizes the malicious actors. The proposed algorithm is efficient, viable, and simply adequate to address the challenges posed by complex cyber-physical systems. Finally, the efficiency of the presented method is verified with the case of platooning in an adversarial environment. © 2018 AACC.",,,,,,,"Mo, Y., Sinopoli, B., Secure control against replay attacks (2009) Communication, Control, and Computing, 2009. Allerton 2009. 47th Annual Allerton Conference on, pp. 911-918. , September. IEEE; Liu, Y., Ning, P., Reiter, M.K., False data injection attacks against state estimation in electric power grids (2011) ACM Transactions on Information and System Security (TISSEC), 14 (1), p. 13; Pasqualetti, F., Drfler, F., Bullo, F., Attack detection and identification in cyber-physical systems (2013) IEEE Transactions on Automatic Control, 58 (11), pp. 2715-2729; Smith, R.S., A decoupled feedback structure for covertly appropriating networked control systems (2011) IFAC Proceedings Volumes, 44 (1), pp. 90-95; Dadras, S., Gerdes, R.M., Sharma, R., Vehicular platooning in an adversarial environment (2015) Proceedings of the 10th ACM Symposium on Information, Computer and Communications Security, pp. 167-178. , April. ACM; Humayed, A., Lin, J., Li, F., Luo, B., Cyber-physical systems securityA survey (2017) IEEE Internet of Things Journal, 4 (6), pp. 1802-1831; Mo, Y., Weerakkody, S., Sinopoli, B., Physical authentication of control systems: Designing watermarked control inputs to detect counterfeit sensor outputs (2015) IEEE Control Systems, 35 (1), pp. 93-109; Nakahira, Y., Mo, Y., Dynamic state estimation in the presence of compromised sensory data (2015) Decision and Control (CDC), 2015 IEEE 54th Annual Conference on, pp. 5808-5813. , December. IEEE; Shoukry, Y., Puggelli, A., Nuzzo, P., Sangiovanni-Vincentelli, A.L., Seshia, S.A., Tabuada, P., Sound and complete state estimation for linear dynamical systems under sensor attacks using satisfiability modulo theory solving (2015) American Control Conference (ACC), 2015, pp. 3818-3823. , July. IEEE; Yong, S.Z., Zhu, M., Frazzoli, E., Resilient state estimation against switching attacks on stochastic cyber-physical systems (2015) Decision and Control (CDC), 2015 IEEE 54th Annual Conference on, pp. 5162-5169. , December. IEEE; Fawzi, H., Tabuada, P., Diggavi, S., Secure estimation and control for cyber-physical systems under adversarial attacks (2014) IEEE Transactions on Automatic Control, 59 (6), pp. 1454-1467; Pajic, M., Tabuada, P., Lee, I., Pappas, G.J., Attack-resilient state estimation in the presence of noise (2015) Decision and Control (CDC), 2015 IEEE 54th Annual Conference on, pp. 5827-5832. , December. IEEE; DeBruhl, B., Weerakkody, S., Sinopoli, B., Tague, P., Is your commute driving you crazy: A study of misbehavior in vehicular platoons (2015) Proceedings of the 8th ACM Conference on Security and Privacy in Wireless and Mobile Networks, p. 22. , June. ACM; Dadras, S., Winstead, C., (2017) Cybersecurity of Autonomous Vehicle Platooning; Dadras, S., Winstead, C., (2018) Insider Vs. Outsider Threats to Autonomous Vehicle Platooning; Dadras, S., Winstead, C., (2018) Collaborative Attacks on Vehicular Platooning; Dadras, S., Dadras, S., Winstead, C., Reachable Set Analysis of Vehicular Platooning in Adversarial Environment (2018) American Control Conference (ACC), 2018, , June. IEEE; Izbicki, M., Amini, S., Shelton, C.R., Mohsenian-Rad, H., Identification of destabilizing attacks in power systems (2017) American Control Conference (ACC), 2017, pp. 3424-3429. , May. IEEE; Dunn, D.D., (2015) Attacker-induced Traffic Flow Instability in A Stream of Automated Vehicles, , Utah State University; Van Overschee, P., De Moor, B., N4SID: Subspace algorithms for the identification of combined deterministic-stochastic systems (1994) Automatica, 30 (1), pp. 75-93; Tangirala, A.K., (2014) Principles of System Identification: Theory and Practice, , Crc Press",,,"","Institute of Electrical and Electronics Engineers Inc.","2018 Annual American Control Conference, ACC 2018","27 June 2018 through 29 June 2018",,138710,07431619,9781538654286,PRACE,,"English","Proc Am Control Conf",Conference Paper,"Final","",Scopus,2-s2.0-85052574683
"Shinohara T., Namerikawa T.","57192820329;6701872937;","Reach Set-based Attack Resilient State Estimation against Omniscient Adversaries",2018,"Proceedings of the American Control Conference","2018-June",,"8431213","5813","5818",,3,"10.23919/ACC.2018.8431213","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052561910&doi=10.23919%2fACC.2018.8431213&partnerID=40&md5=e7af8efec99ba29c1eb1617b28762753","Keio University, Department of System Design Engineering, 3-14-1 Hiyoshi, Kohoku-ku, Yokohama, Kanagawa, 223-8522, Japan","Shinohara, T., Keio University, Department of System Design Engineering, 3-14-1 Hiyoshi, Kohoku-ku, Yokohama, Kanagawa, 223-8522, Japan; Namerikawa, T., Keio University, Department of System Design Engineering, 3-14-1 Hiyoshi, Kohoku-ku, Yokohama, Kanagawa, 223-8522, Japan","We consider the problem of secure state estimation in an adversarial environment with the presence of bounded noises. We assume the adversary has the knowledge of the healthy measurements and system parameters. To countervail the dangerous attacker, the problem is given as a min-max optimization, that is, the system operator seeks an estimator which minimizes the worst-case estimation error due to the manipulation by the attacker. On the proposed estimator, the estimation error is bounded at all times even if the system removing an arbitrary set of 2l sensors is not observable, where l is the number of the compromised sensors. To this end, taking the reach set of the system into account, we first show the feasible set of the state can be represented as a union of polytopes, and the optimal estimate is given as the Chebyshev center of the union. Then, for calculating the optimal state estimate, we provide a convex optimization problem that utilizes the vertices of the union. Additionally, the upper bound of the worst-case estimation error is derived theoretically, and we also show a rigorous analytical bound under a certain condition. The attacked sensor identification algorithm is further provided. A simple numerical example finally shows to illustrate the effectiveness of the proposed estimator. © 2018 AACC.",,,,,,,"Kim, K.D., Kumar, P.R., Cyber-physical systems: A perspective at the centennial (2012) Proc. IEEE, 100, pp. 1287-1308. , Special Centennial Issue; Sztipanovits, J., Koutsoukos, X., Karsai, G., Kottenstette, N., Antsaklis, P., Gupta, V., Goodwine, B., Wang, S., Toward a science of cyber-physical system integration (2012) Proc. IEEE, 100 (1), pp. 29-44; Langner, R., Stuxnet: Dissecting a cyberwarfare weapon (2011) IEEE Secur. Privacy, 9 (3), pp. 49-51; Slay, J., Miller, M., Lesson learned from the Maroochy water branch (2007) Critical Infrastructure Protection, 253, pp. 73-82; Mo, Y., Chabukswar, R., Sinopoli, B., Detecting integrity attacks on SCADA systems (2014) IEEE Trans. Control Syst. Technol, 22 (4), pp. 1396-1407; Teixeira, A., Shames, I., Sandberg, H., Johansson, K.H., A secure control framework for resource-limited adversaries (2015) Automatica, 51, pp. 135-148; Mo, Y., Sinopoli, B., On the performance degradation of cyberphysical systems under stealthy integrity attacks (2016) IEEE Trans. Autom. Control, 61 (9), pp. 2618-2624; Shinohara, T., Namerikawa, T., Manipulative zero-stealthy attacks in cyber-physical systems: Existence space of feasible attack objectives (2017) Proc. 1st IEEE Conf. Control Technology and Applicat., pp. 1123-1128. , Kohala Coast, Hawaii; Shinohara, T., Namerikawa, T., On the vulnerabilities due to manipulative zero-stealthy attacks in cyber-physical systems (2017) SICE J. Control, Measurement, and Syst. Integration, 10 (6), pp. 563-570; Fawzi, H., Tabuada, P., Diggavi, S., Secure estimation and control for cyber-physical systems under adversarial attacks (2014) IEEE Trans. Autom. Control, 59 (6), pp. 1454-1467; Chong, M.S., Wakaiki, M., Hespanha, J.P., Observability of linear systems under adversarial attacks (2015) Proc. 2015 Amer. Control Conf., pp. 2439-2444. , Chicago, IL; Pajic, M., Lee, I., Pappas, G.J., Attack-resilient state estimation for noisy dynamical systems (2017) IEEE Trans. Control Netw. Syst, 4 (1), pp. 82-92; Pajic, M., Weimer, J., Bezzo, N., Sokolsky, O., Pappas, G.J., Lee, I., Design and implementation of attack-resilient cyber-physical systems (2017) IEEE Control Syst. Mag, 37 (2), pp. 66-81; Shoukry, Y., Nuzzo, P., Puggelli, A., Sangiovanni-Vincentelli, A.L., Seshia, S.A., Tabuada, P., Secure estimation for cyber physical systems under sensor attacks: A satisfiability modulo theory approach (2017) IEEE Trans. Autom. Control, 62 (10), pp. 4917-4932; Nakahira, Y., Mo, Y., Dynamic state estimation in the presence of compromised sensory data (2015) Proc. IEEE 54th Conf. Decision and Control, pp. 5808-5813. , Osaka, Japan; Mo, Y., Murray, R.M., Multi-dimensional state estimation in adversarial environment (2015) Proc. 34th Chinese Control Conf., pp. 4761-4766. , Hangzhou, China; Kerrigan, E.C., (2000) Robust Constraint Satisfaction: Invariant Sets and Predictive Control, , Ph. D. dissertation, Dept. Eng., Univ. Cambridge, Cambridge, U. K; Blanchini, F., Set invariance in control (1999) Automatica, 35, pp. 1747-1767; Amir, D., Chebyshev centers and uniform convexity (1978) Pacific J. Math, 77 (1), pp. 1-6; Boyd, S., Vandenberghe, L., (2004) Convex Optimization, , Cambridge University Press; Ziegler, G.M., (1995) Lectures on Polytopes. Graduate Texts in Mathematics, , Springer; Grant, M., Boyd, S., (2017) CVX: Matlab Software for Disciplined Convex Programming, Version 2. 1, , http://cvxr.com/cvx; Grant, M., Boyd, S., (2008) Graph Implementations for Nonsmooth Convex Programs in Recent Advances in Learning and Control, , ed. by V. Blondel, S. Boyd, and H. Kimura, Lecture notes in control and information sciences, Springer; Herceg, M., Kvasnica, M., Jones, C.N., Morari, M., Multiparametric toolbox 3. 0 (2013) Proc. European Control Conf., pp. 502-510. , Zürich, Switzerland; Mattingley, J., Boyd, S., Real-time convex optimization in signal processing (2010) IEEE Signal Process. Mag, 27 (3), pp. 50-61",,,"","Institute of Electrical and Electronics Engineers Inc.","2018 Annual American Control Conference, ACC 2018","27 June 2018 through 29 June 2018",,138710,07431619,9781538654286,PRACE,,"English","Proc Am Control Conf",Conference Paper,"Final","",Scopus,2-s2.0-85052561910
"Liu T., Liu Z., Liu Q., Wen W.","57201036884;57193625500;57202841899;55301112800;","Enhancing the robustness of deep neural networks from 'smart' compression",2018,"Proceedings of IEEE Computer Society Annual Symposium on VLSI, ISVLSI","2018-July",,"8429423","528","532",,1,"10.1109/ISVLSI.2018.00102","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052146275&doi=10.1109%2fISVLSI.2018.00102&partnerID=40&md5=601d1cbf151ea7563a0c7abc961ac7a3","Florida International University, United States","Liu, T., Florida International University, United States; Liu, Z., Florida International University, United States; Liu, Q., Florida International University, United States; Wen, W., Florida International University, United States","Deep neural network (DNN) is recently presenting the human-level performance on many applications like computer vision and natural language processing. However, such a promising solution is also subject to ever-increasing security challenges. Recent studies show that benign inputs polluted with intentionally created imperceptible perturbations, namely 'adversarial example', can easily mislead the decision making of DNN models. To mitigate adversarial attacks, many defense solutions are proposed accordingly, such as adversarial training, gradient masking etc. Orthogonal to those techniques, in this paper, we survey a family of 'smart' compression based countermeasures to protect the DNNs against adversarial attacks. These approaches systematically target several fundamental entities in data processing of DNN models, including the input feature compression through JPEG, color depth reduction or spatial smoothing, and model compression by parameter sharing mechanism. We summarize the pros and cons of enhancing the robustness of DNNs from compression techniques, and hope that compression, originally aiming at the input or DNN model size reduction, can also function as defense technique to better help secure DNN models. © 2018 IEEE.","Adversarial example; Compression; DNN; Robustness","Compaction; Decision making; Natural language processing systems; Network security; Robustness (control systems); VLSI circuits; Adversarial example; Compression techniques; Defense solutions; Defense techniques; Human-level performance; Model size reductions; Parameter sharing; Security challenges; Deep neural networks",,,,,"Hinton, G., Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups (2012) IEEE Signal Processing Magazine, 29 (6), pp. 82-97; Lecun, Y., Deep learning (2015) Nature, 521 (7553), p. 436; Szegedy, C., (2013) Intriguing Properties of Neural Networks, , arXiv preprint arXiv 1312.6199; Goodfellow, I.J., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint arXiv 1412.6572; Papernot, N., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Security and Privacy (SP) 2016 IEEE Symposium on, pp. 582-597. , IEEE; Xu, W., (2017) Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks, , arXiv preprint arXiv 1704.01155; Kurakin, A., (2016) Adversarial Examples in the Physical World, , arXiv preprint arXiv 1607.02533; Liu, Q., Security analysis and enhancement of model compressed deep learning systems under adversarial attacks (2018) Proceedings of the 23rd Asia and South Pacific Design Automation Conference, pp. 721-726. , IEEE Press; Liu, Q., Understanding adversarial attack and defense towards deep compressed neural networks (2018) Cyber Sensing International Society for Optics and Photonics 2018, p. 106300Q. , 10630; Krizhevsky, A., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Han, S., (2015) Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding, , arXiv preprint arXiv 1510.00149; Cao, Z., (2017) Hashnet: Deep Learning to Hash by Continuation, , arXiv preprint arXiv 1702.00758; Cheng, Y., An exploration of parameter redundancy in deep networks with circulant projections (2015) Proceedings of the IEEE International Conference on Computer Vision, pp. 2857-2865; Moosavi Dezfooli, S.M., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , no. EPFL-CONF-218057; Papernot, N., The limitations of deep learning in adversarial settings (2016) 2016 IEEE European Symposium on Security and Privacy (EuroS&P), pp. 372-387. , IEEE; Dziugaite, G.K., (2016) A Study of the Effect of Jpg Compression on Adversarial Images, , arXiv preprint arXiv 1608.00853; Das, N., (2017) Keeping the Bad Guys Out: Protecting and Vaccinating Deep Learning with Jpeg Compression, , arXiv preprint arXiv 1705.02900; Aydemir, A.E., (2018) The Effects of Jpeg and jpeg2000 Compression on Attacks Using Adversarial Examples, , arXiv preprint arXiv 1803 10418; Wallace, G.K., The jpeg still picture compression standard (1992) IEEE Transactions on Consumer Electronics, 38 (1), pp. xviii-xxxiv; Lecun, Y., (1998) The Mnist Database of Handwritten Digits, , http://yann.lecun.com/exdb/mnist/",,,"Hong Kong Polytechnic University","IEEE Computer Society","17th IEEE Computer Society Annual Symposium on VLSI, ISVLSI 2018","9 July 2018 through 11 July 2018",,138555,21593469,9781538670996,,,"English","Proc. IEEE Comput. Soc. Annu. Symp., on VLSI, ISVLSI",Conference Paper,"Final","",Scopus,2-s2.0-85052146275
"Song C., Cheng H.-P., Yang H., Li S., Wu C., Wu Q., Chen Y., Li H.","57191624268;57191620238;57203286881;56892908900;56892929800;7404602655;9737381600;57204886743;","MAT: A multi-strength adversarial training method to mitigate adversarial attacks",2018,"Proceedings of IEEE Computer Society Annual Symposium on VLSI, ISVLSI","2018-July",,"8429413","476","481",,7,"10.1109/ISVLSI.2018.00092","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052089435&doi=10.1109%2fISVLSI.2018.00092&partnerID=40&md5=a0a8a6d8b49b324c258e54a305ffad03","Department of Electrical and Computer Engineering, Duke University, Durham, NC, United States; Hewlett Packard Labs, Palo Alto, CA, United States; Air Force Research Lab, Rome, NY, United States","Song, C., Department of Electrical and Computer Engineering, Duke University, Durham, NC, United States; Cheng, H.-P., Department of Electrical and Computer Engineering, Duke University, Durham, NC, United States; Yang, H., Department of Electrical and Computer Engineering, Duke University, Durham, NC, United States; Li, S., Hewlett Packard Labs, Palo Alto, CA, United States; Wu, C., Department of Electrical and Computer Engineering, Duke University, Durham, NC, United States; Wu, Q., Air Force Research Lab, Rome, NY, United States; Chen, Y., Department of Electrical and Computer Engineering, Duke University, Durham, NC, United States; Li, H., Department of Electrical and Computer Engineering, Duke University, Durham, NC, United States","Some recent work revealed that deep neural networks (DNNs) are vulnerable to so-called adversarial attacks where input examples are intentionally perturbed to fool DNNs. In this work, we revisit the DNN training process that includes adversarial examples into the training dataset so as to improve DNN's resilience to adversarial attacks, namely, adversarial training. Our experiments show that different adversarial strengths, i.e., perturbation levels of adversarial examples, have different working ranges to resist the attacks. Based on the observation, we propose a multi-strength adversarial training method (MAT) that combines the adversarial training examples with different adversarial strengths to defend adversarial attacks. Two training structures-mixed MAT and parallel MAT-are developed to facilitate the tradeoffs between training time and hardware cost. Our results show that MAT can substantially minimize the accuracy degradation of deep learning systems to adversarial attacks on MNIST, CIFAR-10, CIFAR-100, and SVHN. The tradeoffs between training time, robustness, and hardware cost are also well discussed on a FPGA platform. © 2018 IEEE.","Adversarial attack; Adversarial example; Adversarial training; FPGA; Neural network","Commerce; Computer hardware; Field programmable gate arrays (FPGA); Hardware; Neural networks; VLSI circuits; Adversarial attack; Adversarial example; Fpga platforms; Training dataset; Training example; Training methods; Training process; Training time; Deep neural networks",,,,,"LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), pp. 436-444; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint arXiv; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) Proceedings of the International Conference on Learning Representations (ICLR); Papernot, N., McDaniel, P., Goodfellow, I.J., (2016) Transferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples, , arXiv preprint arXiv; Ulicny, M., Lundstrom, J., Byttner, S., Robustness of deep convolutional neural networks for image recognition (2016) International Symposium on Intelligent Computing Systems, pp. 16-30. , Springer; Papernot, N., McDaniel, P., Goodfellow, I.J., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519. , ACM; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial machine learning at scale (2017) Proceedings of the International Conference on Learning Representations (ICLR); Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP) 2017 IEEE Symposium on, pp. 39-57. , IEEE; Cisse, M., Bojanowski, P., Grave, E., Dauphin, Y., Usunier, N., Parseval networks: Improving robustness to adversarial examples (2017) International Conference on Machine Learning, pp. 854-863; Harel, J., Koch, C., Perona, P., Graph-based visual saliency (2007) Advances in Neural Information Processing Systems, pp. 545-552; Wang, Z., Bovik, A.C., Sheikh, H.R., Simoncelli, E.P., Image quality assessment: From error visibility to structural similarity (2004) IEEE Transactions on Image Processing, 13 (4), pp. 600-612",,,"Hong Kong Polytechnic University","IEEE Computer Society","17th IEEE Computer Society Annual Symposium on VLSI, ISVLSI 2018","9 July 2018 through 11 July 2018",,138555,21593469,9781538670996,,,"English","Proc. IEEE Comput. Soc. Annu. Symp., on VLSI, ISVLSI",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85052089435
"Liu C., Dong Q., Yu F., Chen X.","56393438200;57201132933;57203734488;54398338300;","ReRise: An adversarial example restoration system for neuromorphic computing security",2018,"Proceedings of IEEE Computer Society Annual Symposium on VLSI, ISVLSI","2018-July",,"8429412","470","475",,,"10.1109/ISVLSI.2018.00091","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052059937&doi=10.1109%2fISVLSI.2018.00091&partnerID=40&md5=873d58f966d088482d45f834701cfa65","Electrical and Computer Engineering, Clarkson University, United States; Electrical and Computer Engineering, George Mason University, United States; Exacloud Inc., United States","Liu, C., Electrical and Computer Engineering, Clarkson University, United States; Dong, Q., Electrical and Computer Engineering, George Mason University, United States, Exacloud Inc., United States; Yu, F., Electrical and Computer Engineering, George Mason University, United States; Chen, X., Electrical and Computer Engineering, George Mason University, United States","While the Deep Neural Network (DNN) has achieved remarkable success in advanced intelligent applications, the security issue becomes a significant concern due to the emerged adversarial attacks. State-of-The-Art defense against adversarial attacks involves adversarial example detection via multi-model cross verification, followed by adversarial example filtration. Although this has proven effective, the high computational overhead and considerable input data loss make this solution unsuitable for use. To overcome the above drawbacks, we propose a novel adversarial example restoration system to restore the adversarially perturbed input to its original state. It includes a restoration network based on a residual learning and a hardware implementation by leveraging neuromorphic technique to achieve an effective and efficient defense. Our proposed restoration system demonstrates a high restoration rate that outperforms the state-of-The-Art methods by ~40% with high image quality. The restoration system can be easily integrated into the existing neuromorphic computing systems. With a parallel structure reuse strategy, our restoration system has very slight computation overhead of 2.51% in area, 12.85% in speed, and 4.21% in energy. © 2018 IEEE.","Adversarial Attack; Neural Network; Neuromorphic Computing; Security","Deep neural networks; Hardware; Neural networks; Restoration; VLSI circuits; Adversarial Attack; Computation overheads; Computational overheads; Hardware implementations; Intelligent applications; Neuromorphic computing; Security; State-of-the-art methods; Network security",,,,,"Wang, F., Where does alphago go: From church-Turing thesis to AlphaGo Thesis and beyond (2016) Automatica Sinica; Li, L., Object bank: A high-level image representation for scene Classification & Semantic Feature Sparsification (2010) Neural Information Processing Systems; Goodfellow, I.J., (2014) Explaining and Harnessing Adversarial Examples, , arXiv:1412 6572; Moosavi, D., Deepfool: A simple and accurate method to fool DNNs (2016) Computer Vision and Pattern Recognition; Guo, C., (2017) Countering Adversarial Images Using Input Transformations, , arXiv:1711 00117; Papernot, N., (2016) Transferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples, , arXiv:1605 07277; Nadler, B., Statistical analysis of semi-supervised learning: The limit of Infinite Unlabelled Data (2009) Neural Information Processing Systems; Mao, X., Image restoration using very deep convolutional encoder-decoder Networks with Symmetric Skip Connections (2016) Neural Information Processing Systems; He, K., Identity mappings in deep residual networks (2016) European Conference on Computer Vision; Merolla, P., A digital neurosynaptic core using embedded crossbar Memory with 45pJ per Spike in 45nm (2011) Custom Integrated Circuits Conference; Liu, C., A spiking neuromorphic design with resistive crossbar (2015) Design Automation Conference; Papernot, N., The limitations of deep learning in adversarial settings (2016) Security and Privacy; Xie, C., Mitigating adversarial effects through randomization (2018) International Conference on Learning Representations; Dong, C., Accelerating the super-resolution convolutional neural network (2016) European Conference on Computer Vision; Merolla, P., A million spiking-neuron integrated circuit with a scalable Communication Network and Interface (2014) Science; Rastegari, M., Xnor-net: Imagenet classification using binary cnns (2016) European Conference on Computer Vision; Lin, D., Fixed point quantization of deep convolutional networks (2016) International Conference on Machine Learning; (2012) Proposal for Neuromorphic Hardware Using Spin Devices, , arxiv:1206 3227 S. et al. M; Liu, C., A memristor crossbar based computing enginee optimized for High Speed and Accuracy (2016) IEEE Computer Society Annual Symposium on VLSI; Bing, X., (2015) Empirical Evaluation of Rectified Activations in Convolutional Network, , arXiv:1505 00853; Russakovsky, O., Imagenet: Large scale visual recognition challenge (2015) Computer Vision",,,"Hong Kong Polytechnic University","IEEE Computer Society","17th IEEE Computer Society Annual Symposium on VLSI, ISVLSI 2018","9 July 2018 through 11 July 2018",,138555,21593469,9781538670996,,,"English","Proc. IEEE Comput. Soc. Annu. Symp., on VLSI, ISVLSI",Conference Paper,"Final","",Scopus,2-s2.0-85052059937
"Atakhodjaev I., Bosworth B.T., Grubel B.C., Kossey M.R., Villalba J., Cooper A.B., Dehak N., Foster A.C., Foster M.A.","57202629553;24342742000;57193081525;56593211200;36667707200;57193082759;16202714800;36731109600;7202971357;","Investigation of Deep Learning Attacks on Nonlinear Silicon Photonic PUFs",2018,"2018 Conference on Lasers and Electro-Optics, CLEO 2018 - Proceedings",,,"8426521","","",,5,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052568206&partnerID=40&md5=4fead3aca98df88a1270ababe58d2b7a","Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD  21218, United States","Atakhodjaev, I., Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD  21218, United States; Bosworth, B.T., Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD  21218, United States; Grubel, B.C., Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD  21218, United States; Kossey, M.R., Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD  21218, United States; Villalba, J., Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD  21218, United States; Cooper, A.B., Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD  21218, United States; Dehak, N., Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD  21218, United States; Foster, A.C., Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD  21218, United States; Foster, M.A., Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD  21218, United States","We demonstrate that nonlinear silicon photonic Physical Unclonable Functions (PUFs) are resistant to adversarial deep learning attacks. We find that this resistance is rooted in the optical nonlinearity of the silicon photonic PUF token. © 2018 OSA.",,,,,,,"Ruhrmair, U., Hilgers, C., Urban, S., Weiershauser, A., Dinter, E., Forster, B., Jirauschek, C., (2013) Optical PUFs Reloaded.; Maes, R., Verbauwhede, I., (2010) Physically Unclonable Functions: A Study on the State of the Art and Future Research Directions; Pappu, R., Recht, B., Taylor, J., Gershenfeld, N., Physical one-way functions (2002) Science, 297; Horstmeyer, R., Judkewitz, B., Vellekoop, I.M., Assawaworrarit, S., Yang, C., Physical key-protected one-time pad (2013) Scientific Reports, 3, p. 3543; Grubel, B.C., Bosworth, B.T., Kossey Sun, H.M.R., Cooper, A.B., Foster, M.A., Foster, A.C., Silicon photonic physical unclonable function (2017) Opt. Express, 25, pp. 12710-12721; Grubel, B.C., Bosworth, B.T., Kossey, M.R., Cooper, A.B., Foster, M.A., Foster, A.C., Information-Dense Nonlinear Photonic Physical Uncloneable Function; Ruhrmair, U., Sehnke, F., Solter, J., Dror, G., Devadas, J.S., Schmidhuber: Modeling attacks on physical unclonable functions (2010) ACM CCS; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521, pp. 436-444",,,"AdValue Photonics;American Elements;Class 5 Photonics;Coherent;et al.;GoFoton","Institute of Electrical and Electronics Engineers Inc.","2018 Conference on Lasers and Electro-Optics, CLEO 2018","13 May 2018 through 18 May 2018",,138552,,9781943580422,,,"English","Conf. Lasers Electro-Optics, CLEO - Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85052568206
"Anindya I.C., Kantarcioglu M.","57198882321;57203214848;","Adversarial anomaly detection using centroid-based clustering",2018,"Proceedings - 2018 IEEE 19th International Conference on Information Reuse and Integration for Data Science, IRI 2018",,,"8424680","1","8",,5,"10.1109/IRI.2018.00009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052294397&doi=10.1109%2fIRI.2018.00009&partnerID=40&md5=a051c5fbc0036b101ad6cd57474704b9","Department of Computer Science, University of Texas at Dallas, Richardson, TX, United States","Anindya, I.C., Department of Computer Science, University of Texas at Dallas, Richardson, TX, United States; Kantarcioglu, M., Department of Computer Science, University of Texas at Dallas, Richardson, TX, United States","As cyber attacks are growing with an unprecedented rate in the recent years, organizations are seeking an efficient and scalable solution towards a holistic protection system. As the adversaries are becoming more skilled and organized, traditional rule based detection systems have been proved to be quite ineffective against the continuously evolving cyber attacks. Consequently, security researchers are focusing on applying machine learning techniques and big data analytics to defend against cyber attacks. Over the recent years, several anomaly detection systems have been claimed to be quite successful against the sophisticated cyber attacks including the previously unseen zero-day attacks. But often, these systems do not consider the adversary's adaptive attacking behavior for bypassing the detection procedure. As a result, deploying these systems in active real-world scenarios fails to provide significant benefits in the presence of intelligent adversaries that are carefully manipulating the attack vectors. In this work, we analyze the adversarial impact on anomaly detection models that are built upon centroid-based clustering from game-theoretic aspect and propose adversarial anomaly detection technique for these models. The experimental results show that our game-theoretic anomaly detection models can withstand attacks more effectively compared to the traditional models. © 2018 IEEE.","Adversarial machine learning; Anomaly detection; Clustering; Mimicry attack","Artificial intelligence; Big data; Crime; Data integration; Game theory; Information use; Learning systems; Network security; Anomaly detection; Anomaly detection models; Anomaly detection systems; Clustering; Machine learning techniques; Mimicry attack; Real-world scenario; Rule based detection; Computer crime",,,,,"Hackers find 'Ideal testing ground' for attacks: Developing countries (2018) The New York Times, , https://goo.gl/tZzA89, Accessed on 04/11; What the Bangladesh SWIFT hack teaches about the future of cybersecurity and cyberwar (2018) Forbes Magazine, , https://goo.gl/N7uWeR, Accessed on 04/11; Leaked NSA tools, now infecting over 200,000 machines, will be weaponized for years (2018) CyberScoop, , https://goo.gl/BFFbq4, Accessed on 04/11; (2018) Internet Security Threat Report 2017, , https://www.symantec.com/content/dam/symantec/docs/reports/istr-22-2017-en.pdf, Accessed on 04/11; Dutrisac, J.G., Skillicorn, D.B., Hiding clusters in adversarial settings (2008) Proceedings of IEEE International Conference on Intelligence and Security Informatics, ISI, , Taipei, Taiwan; Biggio, B., Rieck, K., Ariu, D., Wressnegger, C., Corona, I., Giacinto, G., Roli, F., Poisoning behavioral malware clustering (2014) Proceedings of the Workshop on Artificial Intelligent and Security, AISec, , Scottsdale, USA; Portnoy, L., Eskin, E., Stolfo, S., Intrusion detection with unlabeled data using clustering (2001) Proceedings of ACM CSS Workshop on Data Mining Applied to Security (DMSA); Chandola, V., Banerjee, A., Kumar, V., Anomaly detection: A survey (2009) ACM Computing Surveys; Xu, W., Qi, Y., Evans, D., Automatically evading classifiers: A case study on PDF malware classifiers (2016) Proceedings of 23rd Annual Network and Distributed System Security Symposium (NDSS), , San Diego, USA; Tygar, J.D., Adversarial machine learning (2011) IEEE Internet Computing; Corona, I., Giacinto, G., Roli, F., Adversarial attacks against intrusion detection systems: Taxonomy, solutions and open issues (2013) Information Sciences; Newsome, J., Karp, B., Song, D.X., Paragraph: Thwarting signature learning by training maliciously (2006) Proceedings of Recent Advances in Intrusion Detection RAID, , Hamburg, Germany; Biggio, B., Nelson, B., Laskov, P., Poisoning attacks against support vector machines (2012) Proceedings of the 29th International Conference on Machine Learning (ICML), , Edinburgh, Scotland; Biggio, B., Fumera, G., Roli, F., Security evaluation of pattern classifiers under attack (2017) CoRR, , abs/1709.00609; Smutz, C., Stavrou, A., Malicious PDF detection using metadata and structural features (2012) Proceedings of 28th Annual Computer Security Applications Conference (ACSAC), , Orlando, USA; Patton, S., Yurcik, W., Doss, D., An achilles' heel in signature-based IDS: Squealing false positives in SNORT (2001) Proceedings of Recent Advances in Intrusion Detection RAID; Yurcik, W., Controlling intrusion detection systems by generating false positives: Squealing proof-of-concept (2002) Proceedings of 27th Annual IEEE Conference on Local Computer Networks (LCN), , Tampa, USA; Crosby, S.A., Wallach, D.S., Denial of service via algorithmic complexity attacks (2003) USENIX Security Symposium; Tsyrklevich, E., Attacking host intrusion prevention systems (2004) Black Hat USA; Hernacki, B., Bennett, J., Hoagland, J.A., An overview of network evasion methods (2005) Information Security Technical Report; Mutz, D., Kruegel, C., Robertson, W., Vigna, G., Kemmerer, R.A., Reverse engineering of network signatures (2005) Proceedings of the AusCERT Asia Pacific Information Technology Security Conference, , Gold Coast, Australia; Zhou, Y., Kantarcioglu, M., Thuraisingham, B.M., Xi, B., Adversarial support vector machine learning (2012) Proceedings of the 18th ACM International Conference on Knowledge Discovery and Data Mining (KDD), , Beijing, China; Zhou, Y., Kantarcioglu, M., Modeling adversarial learning as nested stackelberg games (2016) Proceedings of Pacific-Asia Conference on Advances in Knowledge Discovery and Data Mining (PAKDD), , Auckland, New Zealand; Wang, G., Wang, T., Zheng, H., Zhao, B.Y., Man vs machine: Practical adversarial detection of malicious crowdsourcing workers (2014) Proceedings of the 23rd USENIX Security Symposium, , San Diego, USA; Kloft, M., Laskov, P., Online anomaly detection under adversarial impact (2010) Proceedings of the 13th International Conference on Artificial Intelligence and Statistics (AISTATS), , Sardinia, Italy; Zimek, A., Schubert, E., Kriegel, H., A survey on unsupervised outlier detection in high-dimensional numerical data (2012) Statistical Analysis and Data Mining; Wold, S., Esbensen, K., Geladi, P., Principal component analysis (1987) Chemometrics and Intelligent Laboratory Systems; (2018) Cplex Optimizer, , https://www.ibm.com/analytics/data-science/prescriptive-analytics/cplex-optimizer, Accessed on 04/11; (2018) KDD Cup 1999 Data, , http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html, Accessed on 04/11; Lee, W., Stolfo, S.J., A framework for constructing features and models for intrusion detection systems (2000) ACM Transactions on Information and System Security; Shook, C.L., The application of cluster analysis in strategic management research: An analysis and critique (1996) Strategic Management Journal, pp. 441-458. , D. J. K. Jr",,,"Society for Information Reuse and Integration (SIRI)","Institute of Electrical and Electronics Engineers Inc.","19th IEEE International Conference on Information Reuse and Integration for Data Science, IRI 2018","7 July 2018 through 9 July 2018",,138431,,9781538626597,,,"English","Proc. - IEEE Int. Conf. Inf. Reuse Integr. Data Sci., IRI",Conference Paper,"Final","",Scopus,2-s2.0-85052294397
"Carlini N., Wagner D.","57194977162;7401982903;","Audio adversarial examples: Targeted attacks on speech-to-text",2018,"Proceedings - 2018 IEEE Symposium on Security and Privacy Workshops, SPW 2018",,,"8424625","1","7",,317,"10.1109/SPW.2018.00009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052231158&doi=10.1109%2fSPW.2018.00009&partnerID=40&md5=194a89d63ecafb9650a2ddfb563cb629","University of California, Berkeley, United States","Carlini, N., University of California, Berkeley, United States; Wagner, D., University of California, Berkeley, United States","We construct targeted audio adversarial examples on automatic speech recognition. Given any audio waveform, we can produce another that is over 99.9% similar, but transcribes as any phrase we choose (recognizing up to 50 characters per second of audio). We apply our white-box iterative optimization-based attack to Mozilla's implementation DeepSpeech end-to-end, and show it has a 100% success rate. The feasibility of this attack introduce a new domain to study adversarial examples. © 2018 IEEE.","Adversarial example; Neural network","Neural networks; Adversarial example; Audio waveforms; Automatic speech recognition; End to end; Iterative Optimization; Speech to texts; Targeted attacks; White box; Speech recognition",,,,,"Arnab, A., Miksik, O., Torr, P.H., (2017) On the Robustness of Semantic Segmentation Models to Adversarial Attacks, , arXiv preprint; Athalye, A., Engstrom, L., Ilyas, A., Kwok, K., (2017) Synthesizing Robust Adversarial Examples, , arXiv preprint; Athalye, A., Carlini, N., Wagner, D., (2018) Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples, , arXiv preprint; Barreno, M., Nelson, B., Sears, R., Joseph, A.D., Tygar, J.D., Can machine learning be secure? (2006) Proceedings of the 2006 ACM Symposium on Information, Computer and Communications Security, pp. 16-25. , ACM; Barreno, M., Nelson, B., Joseph, A.D., Tygar, J., The security of machine learning (2010) Machine Learning, 81 (2), pp. 121-148; Behzadan, V., Munir, A., (2017) Vulnerability of Deep Reinforcement Learning to Policy Induction Attacks, , arXiv preprint; Bengio, Y., Léonard, N., Courville, A., (2013) Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation, , arXiv preprint; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Srndic, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 387-402. , Springer; Carlini, N., Wagner, D., (2017) Magnet and ""efficient Defenses Against Adversarial Attacks"" Are Not Robust to Adversarial Examples, , arXiv preprint; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium On, pp. 39-57. , IEEE; Carlini, N., Mishra, P., Vaidya, T., Zhang, Y., Sherr, M., Shields, C., Wagner, D., Zhou, W., Hidden voice commands (2016) 25th USENIX Security Symposium (USENIX Security 16), , Austin, TX; Cisse, M., Adi, Y., Neverova, N., Keshet, J., (2017) Houdini: Fooling Deep Structured Prediction Models, , arXiv preprint; Gong, Y., Poellabauer, C., (2017) Crafting Adversarial Examples for Speech Paralinguistics Applications, , arXiv preprint; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint; Graves, A., Fernández, S., Gomez, F., Schmidhuber, J., Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural networks (2006) Proceedings of the 23rd International Conference on Machine Learning, pp. 369-376. , ACM; Grosse, K., Papernot, N., Manoharan, P., Backes, M., McDaniel, P., (2016) Adversarial Perturbations Against Deep Neural Networks for Malware Classification, , arXiv preprint; Hannun, A., Sequence modeling with ctc (2017) Distill, , https://distill.pub/2017/ctc; Hannun, A., Case, C., Casper, J., Catanzaro, B., Diamos, G., Elsen, E., Prenger, R., Coates, A., (2014) Deep Speech: Scaling Up End-to-end Speech Recognition, , arXiv preprint; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9 (8), pp. 1735-1780; Hu, W., Tan, Y., (2017) Generating Adversarial Malware Examples for Black-box Attacks Based on Gan, , arXiv preprint; Huang, S., Papernot, N., Goodfellow, I., Duan, Y., Abbeel, P., (2017) Adversarial Attacks on Neural Network Policies, , arXiv preprint; Ilyas, A., Engstrom, L., Athalye, A., Lin, J., (2017) Query-efficient Blackbox Adversarial Examples, , arXiv preprint; Jia, R., Liang, P., (2017) Adversarial Examples for Evaluating Reading Comprehension Systems, , arXiv preprint; Kereliuk, C., Sturm, B.L., Larsen, J., Deep learning and music adversaries (2015) IEEE Transactions on Multimedia, 17 (11), pp. 2059-2071; Kingma, D., Ba, J., (2014) Adam: A Method for Stochastic Optimization, , arXiv preprint; Kos, J., Fischer, I., Song, D., (2017) Adversarial Examples for Generative Models, , arXiv preprint; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint; Liu, Y., Chen, X., Liu, C., Song, D., (2016) Delving into Transferable Adversarial Examples and Black-box Attacks, , arXiv preprint; Lowd, D., Meek, C., Adversarial learning (2005) Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining, pp. 641-647. , ACM; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , arXiv preprint; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., (2016) Universal Adversarial Perturbations, , arXiv preprint; (2017) Project Deepspeech, , https://github.com/mozilla/DeepSpeech; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 427-436; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples, , arXiv preprint; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., (2016) Practical Black-box Attacks Against Deep Learning Systems Using Adversarial Examples, , arXiv preprint; Rozsa, A., Rudd, E.M., Boult, T.E., Adversarial diversity and hard positive generation (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, pp. 25-32; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540. , ACM; Smith, S.W., (1997) The Scientist and Engineer's Guide to Digital Signal Processing; Song, L., Mittal, P., (2017) Inaudible Voice Commands, , arXiv preprint; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2013) ICLR; Zhang, G., Yan, C., Ji, X., Zhang, T., Zhang, T., Xu, W., Dolphinatack: Inaudible voice commands (2017) CCS",,,,"Institute of Electrical and Electronics Engineers Inc.","2018 IEEE Symposium on Security and Privacy Workshops, SPW 2018","24 May 2018",,138430,,9780769563497,,,"English","Proc. - IEEE Symp. Secur. Priv. Workshops, SPW",Conference Paper,"Final","All Open Access, Bronze, Green",Scopus,2-s2.0-85052231158
"Gao J., Lanchantin J., Soffa M.L., Qi Y.","57203548636;57191491253;7003864328;8324721600;","Black-box generation of adversarial text sequences to evade deep learning classifiers",2018,"Proceedings - 2018 IEEE Symposium on Security and Privacy Workshops, SPW 2018",,,"8424632","50","56",,118,"10.1109/SPW.2018.00016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052223531&doi=10.1109%2fSPW.2018.00016&partnerID=40&md5=9cc2606853d6b0dcaaf84826f5947ec6","Department of Computer Science, University of Virginia, United States","Gao, J., Department of Computer Science, University of Virginia, United States; Lanchantin, J., Department of Computer Science, University of Virginia, United States; Soffa, M.L., Department of Computer Science, University of Virginia, United States; Qi, Y., Department of Computer Science, University of Virginia, United States","Although various techniques have been proposed to generate adversarial samples for white-box attacks on text, little attention has been paid to a black-box attack, which is a more realistic scenario. In this paper, we present a novel algorithm, DeepWordBug, to effectively generate small text perturbations in a black-box setting that forces a deep-learning classifier to misclassify a text input. We develop novel scoring strategies to find the most important words to modify such that the deep classifier makes a wrong prediction. Simple character-level transformations are applied to the highest-ranked words in order to minimize the edit distance of the perturbation. We evaluated DeepWordBug on two real-world text datasets: Enron spam emails and IMDB movie reviews. Our experimental results indicate that DeepWordBug can reduce the classification accuracy from 99% to 40% on Enron and from 87% to 26% on IMDB. Our results strongly demonstrate that the generated adversarial sequences from a deep-learning model can similarly evade other deep models. © 2018 IEEE.","Adversarial samples; Black box attack; Deep learning; Misclassification; Text classification; Word embedding","Classification (of information); Text processing; Black boxes; Classification accuracy; Learning classifiers; Learning models; Misclassifications; Realistic scenario; Text classification; Word embedding; Deep learning",,,,,"Zhang, X., Zhao, J., LeCun, Y., Character-level convolutional networks for text classification (2015) Advances in Neural Information Processing Systems, pp. 649-657; Miwa, M., Bansal, M., (2016) End-to-end Relation Extraction Using Lstms on Sequences and Tree Structures, , arXiv preprint; Wu, Y., Schuster, M., Chen, Z., Le, Q.V., Norouzi, M., Macherey, W., Krikun, M., Macherey, K., (2016) Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation, , arXiv preprint; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations (ICLR); Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium On, pp. 39-57. , IEEE; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) IEEE European Symposium on Security and Privacy (EuroS&P); Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , http://arxiv.org/abs/1412.6572, arXiv:1412.6572 [cs, stat], Dec [Online]; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., (2016) Practical Black-box Attacks Against Deep Learning Systems Using Adversarial Examples, , arXiv preprint; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) CVPR, , IEEE; Papernot, N., McDaniel, P., Swami, A., Harang, R., Crafting adversarial input sequences for recurrent neural networks (2016) Military Communications Conference, MILCOM 2016-2016 IEEE, pp. 49-54. , IEEE; Samanta, S., Mehta, S., (2017) Towards Crafting Text Adversarial Samples, , arXiv preprint; Rumelhart, D.E., Hinton, G.E., Williams, R.J., Learning representations by back-propagating errors (1988) Cognitive Modeling, 5 (3), p. 1; Socher, R., Perelygin, A., Wu, J., Chuang, J., Manning, C.D., Ng, A., Potts, C., Recursive deep models for semantic compositionality over a sentiment treebank (2013) Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pp. 1631-1642; Socher, R., Lin, C.C., Manning, C., Ng, A.Y., Parsing natural scenes and natural language with recursive neural networks (2011) Proceedings of the 28th International Conference on Machine Learning (ICML-11), pp. 129-136; Bahdanau, D., Cho, K., Bengio, Y., (2014) Neural Machine Translation by Jointly Learning to Align and Translate, , arXiv preprint; Hochreiter, S., Schmidhuber, J., (1997) Long Short-term Memory, 9 (8), pp. 1735-1780. , MIT Press; Levenshtein, V.I., Binary codes capable of correcting deletions, insertions, and reversals (1966) Soviet Physics Doklady, 10 (8), pp. 707-710; Maas, A.L., Daly, R.E., Pham, P.T., Huang, D., Ng, A.Y., Potts, C., Learning word vectors for sentiment analysis (2011) Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1, pp. 142-150. , Association for Computational Linguistics; Metsis, V., Androutsopoulos, I., Paliouras, G., Spam filtering with naive bayes-which naive bayes? (2006) CEAS, 17, pp. 28-69; Papernot, N., Goodfellow, I., Sheatsley, R., Feinman, R., McDaniel, P., (2016) Cleverhans v1.0.0: An Adversarial Machine Learning Library, , arXiv preprint; Liang, B., Li, H., Su, M., Bian, P., Li, X., Shi, W., (2017) Deep Text Classification Can Be Fooled, , arXiv preprint",,,,"Institute of Electrical and Electronics Engineers Inc.","2018 IEEE Symposium on Security and Privacy Workshops, SPW 2018","24 May 2018",,138430,,9780769563497,,,"English","Proc. - IEEE Symp. Secur. Priv. Workshops, SPW",Conference Paper,"Final","All Open Access, Bronze, Green",Scopus,2-s2.0-85052223531
[No author name available],[No author id available],"Proceedings - 2018 IEEE Symposium on Security and Privacy Workshops, SPW 2018",2018,"Proceedings - 2018 IEEE Symposium on Security and Privacy Workshops, SPW 2018",,,,"","",349,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052213065&partnerID=40&md5=ef799c74076a43c0787654e6723cc22f",,"","The proceedings contain 43 papers. The topics discussed include: audio adversarial examples: targeted attacks on speech-to-text; a deep learning approach to fast, format-agnostic detection of malicious web content; detecting homoglyph attacks with a Siamese neural network; machine learning DDoS detection for consumer Internet of things devices; adversarial examples for generative models; learning universal adversarial perturbations with generative models; black-box generation of adversarial text sequences to evade deep learning classifiers; exploring the use of autoencoders for botnets traffic representation; adversarial deep learning for robust detection of binary encoded malware; and extending detection with privileged information via generalized distillation.",,,,,,,,,,"","Institute of Electrical and Electronics Engineers Inc.","2018 IEEE Symposium on Security and Privacy Workshops, SPW 2018","24 May 2018",,138430,,9780769563497,,,"English","Proc. - IEEE Symp. Secur. Priv. Workshops, SPW",Conference Review,"Final","",Scopus,2-s2.0-85052213065
"Hayes J., Danezis G.","57192153560;57200734488;","Learning universal adversarial perturbations with generative models",2018,"Proceedings - 2018 IEEE Symposium on Security and Privacy Workshops, SPW 2018",,,"8424631","43","49",,38,"10.1109/SPW.2018.00015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052207907&doi=10.1109%2fSPW.2018.00015&partnerID=40&md5=4665b3872487b17f0016c58fafd7f3dc","University College London, United Kingdom","Hayes, J., University College London, United Kingdom; Danezis, G., University College London, United Kingdom","Neural networks are known to be vulnerable to adversarial examples, inputs that have been intentionally perturbed to remain visually similar to the source input, but cause a misclassification. It was recently shown that given a dataset and classifier, there exists so called universal adversarial perturbations, a single perturbation that causes a misclassification when applied to any input. In this work, we introduce universal adversarial networks, a generative network that is capable of fooling a target classifier when it's generated output is added to a clean sample from a dataset. We show that this technique improves on known universal adversarial attacks. © 2018 IEEE.","Adversarial examples; Adversarial training; Deep learning; Universal perturbations","Classification (of information); Adversarial examples; Adversarial networks; Generative model; Misclassifications; Universal perturbations; Deep learning",,,,,"Baluja, S., Fischer, I., Learning to attack: Adversarial transformation networks (2018) Proceedings of AAAI-2018; Buczak, A.L., Guven, E., A survey of data mining and machine learning methods for cyber security intrusion detection (2016) IEEE Communications Surveys & Tutorials, 18 (2), pp. 1153-1176; Carlini, N., Wagner, D., (2017) Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods, , arXiv preprint; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium On, pp. 39-57. , IEEE; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., (2017) Zeroth Order Optimization Based Black-box Attacks to Deep Neural Networks Without Training Substitute Models, , ArXiv e-prints, Aug; Demontis, A., Russu, P., Biggio, B., Fumera, G., Roli, F., (2017) On Security and Sparsity of Linear Classifiers for Adversarial Settings, , ArXiv e-prints, Aug; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint arXiv:1412.6572; Hamm, J., (2017) Machine Vs Machine: Defending Classifiers Against Learningbased Adversarial Attacks, , ArXiv e-prints, Nov; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; He, W., Wei, J., Chen, X., Carlini, N., Song, D., (2017) Adversarial Example Defenses: Ensembles of Weak Defenses Are Not Strong, , ArXiv e-prints, June; Huang, G., Liu, Z., Van der Maaten, L., Weinberger, K.Q., Densely connected convolutional networks (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Huang, S., Papernot, N., Goodfellow, I., Duan, Y., Abbeel, P., (2017) Adversarial Attacks on Neural Network Policies, , arXiv preprint; Kim, S.-J., Boyd, S., A minimax theorem with applications to machine learning, signal processing, and finance (2008) SIAM Journal on Optimization, 19 (3), pp. 1344-1367; Kos, J., Fischer, I., Song, D., (2017) Adversarial Examples for Generative Models, , ArXiv e-prints, Feb; Krizhevsky, A., (2009) Learning Multiple Layers of Features from Tiny Images; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint; Lane, T.D., (2000) Machine Learning Techniques for the Computer Security Domain of Anomaly Detection; Lin, W.-Y., Hu, Y.-H., Tsai, C.-F., Machine learning in financial crisis prediction: A survey (2012) IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews), 42 (4), pp. 421-436; Metzen, J.H., (2018) Universality, Robustness, and Detectability of Adversarial Perturbations under Adversarial Training; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., (2016) Universal Adversarial Perturbations, , arXiv preprint; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Mopuri, K.R., Garg, U., Babu, R.V., (2017) Fast Feature Fool: A Data Independent Approach to Universal Adversarial Perturbations, , arXiv preprint; Obermeyer, Z., Emanuel, E.J., Predicting the futurebig data, machine learning, and clinical medicine (2016) The New England Journal of Medicine, 375 (13), p. 1216; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples, , arXiv preprint; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., (2016) Practical Black-box Attacks Against Deep Learning Systems Using Adversarial Examples, , arXiv preprint; Pappas, T.N., Safranek, R.J., Perceptual Criteria for Image Quality Evaluation; Rosten, E., Drummond, T., Machine learning for high-speed corner detection (2006) Computer Vision-ECCV 2006, pp. 430-443; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Fei-Fei, L., Imagenet large scale visual recognition challenge (2015) International Journal of Computer Vision (IJCV), 115 (3), pp. 211-252; Shipp, M.A., Ross, K.N., Tamayo, P., Weng, A.P., Kutok, J.L., Aguiar, R.C., Gaasenbeek, M., Pinkus, G.S., Diffuse large b-cell lymphoma outcome prediction by gene-expression profiling and supervised machine learning (2002) Nature Medicine, 8 (1), pp. 68-74; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition, , arXiv preprint; Sivaraman, S., Trivedi, M.M., Active learning for on-road vehicle detection: A comparative study (2014) Machine Vision and Applications, pp. 1-13; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint; Trafalis, T.B., Ince, H., Support vector machine for regression and applications to financial forecasting (2000) Neural Networks, 2000. IJCNN 2000, Proceedings of the IEEE-INNS-ENNS International Joint Conference On, 6, pp. 348-353. , IEEE; Tramèr, F., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2017) The Space of Transferable Adversarial Examples, , arXiv preprint; Tramèr, F., Zhang, F., Juels, A., Reiter, M.K., Ristenpart, T., Stealing machine learning models via prediction apis (2016) USENIX Security Symposium, pp. 601-618; Wang, Z., Bovik, A.C., Mean squared error: Love it or leave it? a new look at signal fidelity measures (2009) IEEE Signal Processing Magazine, 26 (1), pp. 98-117; Wen, X., Shao, L., Xue, Y., Fang, W., A rapid learning algorithm for vehicle classification (2015) Information Sciences, 295, pp. 395-406; Ye, Q.-H., Qin, L.-X., Forgues, M., He, P., Kim, J.W., Peng, A.C., Simon, R., Chen, Y., Predicting hepatitis b virus-positive metastatic hepatocellular carcinomas using gene expression profiling and supervised machine learning (2003) Nature Medicine, 9 (4), p. 416; Zhang, F., Chan, P.P., Biggio, B., Yeung, D.S., Roli, F., Adversarial feature selection against evasion attacks (2016) IEEE Transactions on Cybernetics, 46 (3), pp. 766-777",,,,"Institute of Electrical and Electronics Engineers Inc.","2018 IEEE Symposium on Security and Privacy Workshops, SPW 2018","24 May 2018",,138430,,9780769563497,,,"English","Proc. - IEEE Symp. Secur. Priv. Workshops, SPW",Conference Paper,"Final","All Open Access, Bronze, Green",Scopus,2-s2.0-85052207907
"Kos J., Fischer I., Song D.","57203555102;54899111300;7402443870;","Adversarial examples for generative models",2018,"Proceedings - 2018 IEEE Symposium on Security and Privacy Workshops, SPW 2018",,,"8424630","36","42",,58,"10.1109/SPW.2018.00014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052199966&doi=10.1109%2fSPW.2018.00014&partnerID=40&md5=b6298c2ae52b0d1036cb1f1dcacde265","National University of Singapore, Singapore; Google Research, United States; University of California, Berkeley, United States","Kos, J., National University of Singapore, Singapore; Fischer, I., Google Research, United States; Song, D., University of California, Berkeley, United States","We explore methods of producing adversarial examples on deep generative models such as the variational autoencoder (VAE) and the VAE-GAN. Deep learning architectures are known to be vulnerable to adversarial examples, but previous work has focused on the application of adversarial examples to classification tasks. Deep generative models have recently become popular due to their ability to model input data distributions and generate realistic examples from those distributions. We present three classes of attacks on the VAE and VAE-GAN architectures and demonstrate them against networks trained on MNIST, SVHN and CelebA. Our first attack leverages classification-based adversaries by attaching a classifier to the trained encoder of the target generative model, which can then be used to indirectly manipulate the latent representation. Our second attack directly uses the VAE loss function to generate a target reconstruction image from the adversarial example. Our third attack moves beyond relying on classification or the standard loss for the gradient and directly optimizes against differences in source and target latent representations. We also motivate why an attacker might be interested in deploying such techniques against a target generative network. © 2018 IEEE.","Adversarial examples; Generative models; Vae; Vae gan","Network architecture; Adversarial examples; Auto encoders; Classification tasks; Generative model; Learning architectures; Loss functions; Reconstruction image; Vae gan; Deep learning",,,,,"Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, Ser. Asia CCS '17, pp. 506-519. , http://doi.acm.org/10.1145/3052973.3053009, New York, NY, USA: ACM, [Online]; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint; Nguyen, A.M., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2014) CoRR, ABS14121897; Kingma, D.P., Welling, M., (2013) Auto-encoding Variational Bayes, , arXiv preprint; Kulkarni, T.D., Whitney, W.F., Kohli, P., Tenenbaum, J., Deep convolutional inverse graphics network (2015) Advances in Neural Information Processing Systems, pp. 2539-2547; Oord, A.V.D., Kalchbrenner, N., Vinyals, O., Espeholt, L., Graves, A., Kavukcuoglu, K., (2016) Conditional Image Generation with Pixelcnn Decoders, , arXiv preprint; Kalchbrenner, N., Oord, A.V.D., Simonyan, K., Danihelka, I., Vinyals, O., Graves, A., Kavukcuoglu, K., (2016) Video Pixel Networks, , arXiv preprint; Dosovitskiy, A., Springenberg, J., Tatarchenko, M., Brox, T., Learning to generate chairs, tables and cars with convolutional networks (2016) IEEE Transactions on Pattern Analysis and Machine Intelligence, PP (99), p. 1; Van den Oord, A., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A., Kalchbrenner, N., Kavukcuoglu, K., Wavenet: A generative model for raw audio (2016) CoRR, ABS160903499. , http://arxiv.org/abs/1609.03499, [Online]; Larsen, A.B.L., Snderby, S.K., Larochelle, H., Winther, O., Autoencoding beyond pixels using a learned similarity metric (2016) Proceedings of the 33rd International Conference on Machine Learning, Ser. Proceedings of Machine Learning Research, 48, pp. 1558-1566. , http://proceedings.mlr.press/v48/larsen16.html, M. F. Balcan and K. Q. Weinberger, Eds., New York, New York, USA: PMLR, 20-22 Jun [Online]; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial examples in the physical world (2016) CoRR, ABS160702533; Moosavi-Dezfooli, S., Fawzi, A., Frossard, P., (2016) Deepfool: A Simple and Accurate Method to Fool Deep Neural Networks; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2015) Proceedings of the 1st IEEE European Symposium on Security and Privacy; Kingma, D., Ba, J., (2015) Adam: A Method for Stochastic Optimization; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP), pp. 39-57. , May; Huang, R., Xu, B., Schuurmans, D., Szepesvári, C., Learning with a strong adversary (2015) CoRR, ABS151103034; Sabour, S., Cao, Y., Faghri, F., Fleet, D.J., Adversarial manipulation of deep representations (2015) CoRR, ABS151105122. , http://arxiv.org/abs/1511.05122, [Online]; Tabacof, P., Tavares, J., Valle, E., (2016) Adversarial Images for Variational Autoencoders, , ArXiv e-prints, Dec; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems 27, pp. 2672-2680. , http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf, Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger, Eds. Curran Associates, Inc., [Online]; Toderici, G., O'Malley, S.M., Hwang, S.J., Vincent, D., Minnen, D., Baluja, S., Covell, M., Sukthankar, R., (2015) Variable Rate Image Compression with Recurrent Neural Networks, , arXiv preprint; Toderici, G., Vincent, D., Johnston, N., Hwang, S.J., Minnen, D., Shor, J., Covell, M., (2016) Full Resolution Image Compression with Recurrent Neural Networks, , arXiv preprint; Kingma, D.P., Mohamed, S., Rezende, D.J., Welling, M., Semisupervised learning with deep generative models (2014) Advances in Neural Information Processing Systems, pp. 3581-3589; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proceedings of the IEEE, 86 (11), pp. 2278-2324; Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., Ng, A.Y., (2011) Reading Digits in Natural Images with Unsupervised Feature Learning; Liu, Z., Luo, P., Wang, X., Tang, X., Deep learning face attributes in the wild (2015) Proceedings of International Conference on Computer Vision (ICCV); Abadi, M.A.A., (2015) TensorFlow: Large-scale Machine Learning on Heterogeneous Systems, , http://tensorflow.org/, software available from tensorflow.org. [Online]",,,,"Institute of Electrical and Electronics Engineers Inc.","2018 IEEE Symposium on Security and Privacy Workshops, SPW 2018","24 May 2018",,138430,,9780769563497,,,"English","Proc. - IEEE Symp. Secur. Priv. Workshops, SPW",Conference Paper,"Final","All Open Access, Bronze, Green",Scopus,2-s2.0-85052199966
"Dutta P.K., Ryan G., Zieba A., Stolfo S.J.","57203553346;57203547108;57203554817;7003816439;","Simulated user bots: Real time testing of insider threat detection systems",2018,"Proceedings - 2018 IEEE Symposium on Security and Privacy Workshops, SPW 2018",,,"8424654","228","236",,4,"10.1109/SPW.2018.00038","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052199415&doi=10.1109%2fSPW.2018.00038&partnerID=40&md5=e46454f0961302ec9f4a7940ead1bce4","Department of Computer Science, Columbia University, New York, NY  10027, United States","Dutta, P.K., Department of Computer Science, Columbia University, New York, NY  10027, United States; Ryan, G., Department of Computer Science, Columbia University, New York, NY  10027, United States; Zieba, A., Department of Computer Science, Columbia University, New York, NY  10027, United States; Stolfo, S.J., Department of Computer Science, Columbia University, New York, NY  10027, United States","The insider threat is one of the most serious security problems faced by modern organizations. High profile cases demonstrate the serious consequences of successful attacks. The problem has been studied for many years, leading to a number of technologies and products that have been deployed widely in government and commercial enterprises. A fundamental question is: how well do these systems work? How may they be tested? How expensive are widely deployed monitoring infrastructures in terms of computational cost? Measurement of real systems, which are dynamic in nature, encounter unknown configuration bugs and have sensitivities to the vagaries of human nature and adversarial behavior, requires a formal means to continuously test and evaluate deployed detection systems. We present a framework to deploy in situ simulated user bots (SUBs) that can emulate the actions of real users. By creating a user account and by running a host in the enterprise network, a SUB can be introduced into an enterprise system that runs at a realistic pace and does not interfere with normal operations. Infusing malicious behavior into the SUB should be detected by the insider threat monitoring infrastructure. The SUB framework can be controlled to explore the limits of deployed systems and to test the effectiveness of insider evasion tactics, especially low and slow behaviors. We demonstrate our framework in a synthetic ecosystem as well as in a live enterprise deployment. We created a synthetic environment of users based on data collected in a West Point cadet study. Various machine learning based intrusion detection algorithms are used to validate the ability of the SUB framework to generate both normal and malicious users. In a live University network, we launched a number of attacks on its intrusion detection system and showcased the ability to devise malicious users. In addition, we further deployed low and slow attacks that perform malicious actions over an extended period of time and demonstrate how even a large enterprise is ill equipped to combat such attacks. © 2018 IEEE.","Generative adversarial networks; Intrusion detection system monitoring; Machine learning; Machine learning and security; Simulated user bots","Artificial intelligence; Botnet; Computer crime; Learning systems; Network security; Program debugging; Real time systems; Adversarial networks; Commercial enterprise; Enterprise networks; Insider threat detections; Intrusion detection algorithms; Intrusion Detection Systems; Simulated user bots; Synthetic environments; Intrusion detection",,,,,"https://www.crunchbase.com/organization/observeit, [Online]; https://www.crunchbase.com/organization/niara-inc, [Online]; https://www.crunchbase.com/organization/alphasoc, [Online]; (2015) Market Guide for User and Entity Behavior Analytics, , https://www.gartner.com/doc/3134524/market-guide-user-entity-behavior, Sep. [Online]; Eberle, W., Graves, J., Holder, L., Insider threat detection using a graph-based approach (2010) Journal of Applied Security Research, 6 (1), pp. 32-81. , http://dx.doi.org/10.1080/19361610.2011.529413, [Online]; Kandias, M., Mylonas, A., Virvilis, N., Theoharidou, M., Gritzalis, D., (2010) An Insider Threat Prediction Model., pp. 26-37. , http://dx.doi.org/10.1007/978-3-642-15152-13, Berlin, Heidelberg: Springer Berlin Heidelberg, [Online]; Bowen, B.M., Prabhu, P., Kemerlis, V.P., Sidiroglou, S., Keromytis, A.D., Stolfo, S.J., Botswindler: Tamper resistant injection of believable decoys in vm-based hosts for crimeware detection (2010) Lecture Notes in Computer Science Recent Advances in Intrusion Detection, p. 118137; Bellard, F., (2005) Qemu, a Fast and Portable Dynamic Translator, p. 41. , http://dl.acm.org/citation.cfm?id=1247360.1247401, [Online]; https://github.com/sibson/vncdotool, [Online]; Gers, F., Learning to forget: Continual prediction with lstm IET Conference Proceedings, pp. 850-855. , http://digital-library.theiet.org/content/conferences/10.1049/cp19991218, (5), January 1999. [Online]; Bahrololum, M., Khaleghi, M., (2008) Anomaly Intrusion Detection System Using Gaussian Mixture Model, 1, pp. 1162-1167. , Nov; Reynolds, D., (2009) Gaussian Mixture Models., pp. 659-663. , http://dx.doi.org/10.1007/978-0-387-73003-5196, Boston, MA: Springer US, [Online]; Cortes, C., Vapnik, V., Support-vector networks (1995) Machine Learning, 20 (3), pp. 273-297. , http://dx.doi.org/10.1023/A:1022627411411, [Online]; Schölkopf, B., Platt, J.C., Shawe-Taylor, J.C., Smola, A.J., Williamson, R.C., Estimating the support of a high-dimensional distribution (2001) Neural Comput., 13 (7), pp. 1443-1471. , https://doi.org/10.1162/089976601750264965, Jul. [Online]; Ben-Gal, I., (2008) Bayesian Networks., , http://dx.doi.org/10.1002/9780470061572.eqr089, John Wiley & Sons, Ltd,. [Online]; Lee, W., Stolfo, S.J., Data mining approaches for intrusion detection (1998) USENIX Security Symposium., pp. 79-93. , San Antonio, TX; Lippmann, R., Fried, D., Graf, I., Haines, J., Kendall, K., Mcclung, D., Weber, D., Cunningham, R., Evaluating intrusion detection systems: The 1998 DARPA off-line intrusion detection evaluation Proceedings DARPA Information Survivability Conference and Exposition. DISCEX'00; Lippmann, R., Haines, J.W., Fried, D.J., Korba, J., Das, K., Analysis and results of the 1999 DARPA off-line intrusion detection evaluation (2000) Lecture Notes in Computer Science Recent Advances in Intrusion Detection, pp. 162-182; McHugh, J., Testing intrusion detection systems: A critique of the 1998 and 1999 DARPA intrusion detection system evaluations as performed by lincoln laboratory (2000) ACM Trans. Inf. Syst. Secur., 3 (4), pp. 262-294. , http://doi.acm.org/10.1145/382912.382923, Nov. [Online]; Greitzer, F.L., Moore, A.P., Cappelli, D.M., Andrews, D.H., Carroll, L.A., Hull, T.D., Combating the insider cyber threat (2008) IEEE Security & Privacy, 6 (1); Balenson, D., Tinnel, L., Benzel, T., (2015) Cybersecurity Experimentation of the Future, , University of Southern California, Tech. Rep., 07; Boggs, N., Zhao, H., Du, S., Stolfo, S.J., Synthetic data generation and defense in depth measurement of web applications (2014) Research in Attacks, Intrusions and Defenses Lecture Notes in Computer Science, pp. 234-254; Glasser, J., Lindauer, B., Bridging the gap: A pragmatic approach to generating insider threat data (2013) 2013 IEEE Security and Privacy Workshops; Alzantot, M., Chakraborty, S., Srivastava, M.B., Sensegen: A deep learning architecture for synthetic sensor data generation (2017) CoRR, ABS170108886. , http://arxiv.org/abs/1701.08886, [Online]; Ostinato Network Traffic Generator and Analyzer, , http://ostinato.org/, accessed: 2017-03-17; Iperf3, , http://software.es.net/iperf/, accessed: 2017-03-17; Netperf, , http://www.netperf.org/netperf/, accessed: 2017-03-17; Vishwanath, K.V., Vahdat, A., Swing: Realistic and responsive network traffic generation (2009) IEEE/ACM Transactions on Networking, 17 (3), pp. 712-725. , June; Li, T., Liu, J., Cluster-based spatiotemporal background traffic generation for network simulation (2014) ACM Trans. Model. Comput. Simul., 25 (1), pp. 41-425. , http://doi.acm.org/10.1145/2667222, Nov [Online]; Rossey, L.M., Cunningham, R.K., Fried, D.J., Rabek, J.C., Lippmann, R.P., Haines, J.W., Zissman, M.A., Lariat: Lincoln adaptable realtime information assurance testbed (2002) Proceedings, IEEE Aerospace Conference, 6, pp. 62678-62682. , 6-2671-2676 vol.6; Braje, T., Cyber ranges (2016) Lincoln Laboratory Journal, 22 (1), pp. 24-32. , November; Skaion Corporation, , http://www.skaion.com/, accessed: 2017-03-17; Ferguson, B., Tall, A., Olsen, D., National cyber range overview (2014) 2014 IEEE Military Communications Conference, pp. 123-128. , Oct; Salem, M.B., Stolfo, S.J., (2011) Modeling User Search Behavior for Masquerade Detection, pp. 181-200. , http://dx.doi.org/10.1007/978-3-642-23644-010, Berlin, Heidelberg: Springer Berlin Heidelberg, [Online]; Montgomery, A.L., Li, S., Srinivasan, K., Liechty, J.C., Modeling online browsing and path analysis using clickstream data (2004) Marketing Science, 23, pp. 579-595",,,,"Institute of Electrical and Electronics Engineers Inc.","2018 IEEE Symposium on Security and Privacy Workshops, SPW 2018","24 May 2018",,138430,,9780769563497,,,"English","Proc. - IEEE Symp. Secur. Priv. Workshops, SPW",Conference Paper,"Final","All Open Access, Bronze, Green",Scopus,2-s2.0-85052199415
"McCoyd M., Wagner D.","55634125300;7401982903;","Background class defense against adversarial examples",2018,"Proceedings - 2018 IEEE Symposium on Security and Privacy Workshops, SPW 2018",,,"8424639","96","102",,10,"10.1109/SPW.2018.00023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052193228&doi=10.1109%2fSPW.2018.00023&partnerID=40&md5=499dc21aabac1b45fda6ad6948193c0c","University of California, Berkeley, United States","McCoyd, M., University of California, Berkeley, United States; Wagner, D., University of California, Berkeley, United States","Adversarial examples allow crafted attacks against deep neural network classification of images. We propose a defense of expanding the training set with a single, large, and diverse class of background images, striving to 'fill' around the borders of the classification boundary. We find it AIDS detection of simple attacks on EMNIST, but not advanced attacks. We discuss several limitations of our examination. © 2018 IEEE.","Adversarial examples; Background class; Defense; EMNIST; Negative result","Classification (of information); Deep neural networks; Neural networks; Adversarial examples; Background class; Defense; EMNIST; Negative result; Network security",,,,,"Bendale, A., Boult, T.E., Towards open set deep networks (2016) CVPR, , [BB16]; Cohen, G., Afshar, S., Tapson, J., Van Schaik, A., EMNIST: An extension of MNIST to handwritten letters (2017) CoRR, , [CATvl7]; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy, , [CW17]; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR, , [GSS15]; Hosseini, H., Chen, Y., Kannan, S., Zhang, B., Poovendran, R., (2017) Blocking Transferability of Adversarial Examples in Black-Box Learning Systems, , [HCK+17]; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) ICLR, , [LCLS17]; Melis, M., Demontis, A., Biggio, B., Brown, G., Fumera, G., Roli, F., Is Deep Learning Safe for Robot Vision? Adversarial Examples against the iCub Humanoid (2017) ViPAR, , [MDB+17]; Nguyen, A., Yosinski, J., Clune, J., Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images (2015) CVPR, , [NYC15]; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Fei-Fei, L., Ima-genet large scale visual recognition challenge (2015) Int. J. Comput. Vision, 115 (3). , [RDS+15] December; Rumelhart, D.E., Hinton, G.E., Williams, R.J., Learning representations by back-propagating errors (1988) Neurocomputing: Foundations of Research, , [RHW88] In James A. Anderson and Edward Rosenfeld, editors MIT Press; Stallkamp, J., Schlipsing, M., Salmen, J., Igel, C., The German traffic sign recognition benchmark: A multi-class classification competition (2011) IEEE Int. Joint Conference on Neural Networks, , [SSSI11]; Shaham, U., Yamada, Y., Negahban, S., Understanding adversarial training: Increasing local stability of neural nets through robust optimization (2015) CoRR, , [SYN15]; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) ICLR, , [SZS+14]; Zeiler, M.D., ADADELTA: An adaptive learning rate method (2012) CoRR, , [Zeil2]",,,,"Institute of Electrical and Electronics Engineers Inc.","2018 IEEE Symposium on Security and Privacy Workshops, SPW 2018","24 May 2018",,138430,,9780769563497,,,"English","Proc. - IEEE Symp. Secur. Priv. Workshops, SPW",Conference Paper,"Final","All Open Access, Bronze",Scopus,2-s2.0-85052193228
"Chen L., Sultana S., Sahita R.","55616439900;37082162000;6504685393;","HeNet: A deep learning approach on Intel® processor trace for effective exploit detection",2018,"Proceedings - 2018 IEEE Symposium on Security and Privacy Workshops, SPW 2018",,,"8424641","109","115",,16,"10.1109/SPW.2018.00025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052191698&doi=10.1109%2fSPW.2018.00025&partnerID=40&md5=12d0047109763156ffa545055eade47c","Security and Privacy Lab, Intel Labs, Hillsboro, OR  97124, United States","Chen, L., Security and Privacy Lab, Intel Labs, Hillsboro, OR  97124, United States; Sultana, S., Security and Privacy Lab, Intel Labs, Hillsboro, OR  97124, United States; Sahita, R., Security and Privacy Lab, Intel Labs, Hillsboro, OR  97124, United States","This paper presents HeNet, a hierarchical ensemble neural network, applied to classify hardware-generated control flow traces for malware detection. Deep learning-based malware detection has so far focused on analyzing executable files and runtime API calls. Static code analysis approaches face challenges due to obfuscated code and adversarial perturbations. Behavioral data collected during execution is more difficult to obfuscate but recent research has shown successful attacks against API call based malware classifiers. We investigate control flow based characterization of a program execution to build robust deep learning malware classifiers. HeNet consists of a low-level behavior model and a top-level ensemble model. The low-level model is a per-application behavior model, trained via transfer learning on a time-series of images generated from control flow trace of an execution. We use Intel® Processor Trace enabled processor for low overhead execution tracing and design a lightweight image conversion and segmentation of the control flow trace. The top-level ensemble model aggregates the behavior classification of all the trace segments and detects an attack. The use of hardware trace adds portability to our system and the use of deep learning eliminates the manual effort of feature engineering. We evaluate HeNet against real-world exploitations of PDF readers. HeNet achieves 100% accuracy and 0% false positive on test set, and higher classification accuracy compared to classical machine learning algorithms. © 2018 IEEE.","Control flow; Deep learning; Hierarchical learning; Intel® processor trace; Supervised learning; Threat detection","Classification (of information); Computer crime; Hardware; Image segmentation; Learning algorithms; Malware; Supervised learning; Application behavior models; Behavior classification; Classification accuracy; Control flows; Hierarchical ensemble; Hierarchical learning; Static code analysis; Threat detection; Deep learning",,,,,"Behrends, R., Dillon, L.K., Fleming, S.D., Stirewalt, R.E.K., (2017) Internet Security Threat Report, , Symantec, Tech. Rep., April; Minihane, N., Moreno, F., Peterson, E., Samani, R., Schmugar, C., Sommer, D., Sun, B., (2017) Mcafee Labs Threat Report, , McAfee Labs, Tech. Rep., December; Raff, E., Barker, J., Sylvester, J., Brandon, R., Catanzaro, B., Nicholas, C., (2017) Malware Detection by Eating a Whole Exe, , ArXiv e-prints, oct; Dahl, G.E., Stokes, J.W., Deng, L., Yu, D., Large-scale malware classification using random projections and neural networks (2013) IEEE Intl. Conference on Acoustics, Speech and Signal Processing, pp. 3422-3426. , May; Raff, E., Sylvester, J., Nicholas, C., (2017) Learning the PE Header, Malware Detection with Minimal Domain Knowledge, , ArXiv e-prints, Sep; Davis, A., Wolff, M., Deep learning on disassembly data (2015) BlackHat USA; Saxe, J., Berlin, K., Deep neural network based malware detection using two dimensional binary program features (2015) Intl. Conference on Malicious and Unwanted Software (MALWARE), pp. 11-20. , Oct; Kim, G., Yi, H., Lee, J., Paek, Y., Yoon, S., Lstm-based systemcall language modeling and robust ensemble method for designing hostbased intrusion detection systems (2016) CoRR, ABS161101726; Huang, W., Stokes, J.W., (2016) MtNet: A Multi-Task Neural Network for Dynamic Malware Classification, pp. 399-418. , Springer International Publishing; Kolosnjaji, B., Zarras, A., Webster, G., Eckert, C., (2016) Deep Learning for Classification of Malware System Call Sequences, pp. 137-149; Grosse, K., Papernot, N., Manoharan, P., Backes, M., McDaniel, P.D., Adversarial perturbations against deep neural networks for malware classification (2016) CoRR, ABS160604435; Hu, W., Tan, Y., Black-box attacks against RNN based malware detection algorithms (2017) CoRR, ABS170508131; Rosenberg, I., Shabtai, A., Rokach, L., Elovici, Y., (2017) Generic Blackbox End-to-end Attack Against Rnns and Other Api Calls Based Malware Classifiers, , ArXiv e-prints, July; Abadi, M., Budiu, M., Erlingsson, U., Ligatti, J., Control-flow integrity principles, implementations, and applications (2009) ACM Trans. Inf. Syst. Secur., 13 (1), pp. 41-440; Karim, F., Majumdar, S., Darabi, H., Chen, S., LSTM fully convolutional networks for time series classification (2018) IEEE Access, 6, pp. 1662-1669; Wang, Z., Yan, W., Oates, T., Time series classification from scratch with deep neural networks: A strong baseline (2017) International Joint Conference on Neural Networks (IJCNN), pp. 1578-1585. , May; Pan, S.J., Yang, Q., A survey on transfer learning (2010) IEEE Transactions on Knowledge and Data Engineering, 22 (10), pp. 1345-1359; Yosinski, J., Clune, J., Bengio, Y., Lipson, H., How transferable are features in deep neural networks? (2014) Advances in Neural Information Processing Systems, pp. 3320-3328; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., Inception-v4, inception-resnet and the impact of residual connections on learning (2017) AAAI, pp. 4278-4284; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition, , arXiv preprint; Maaten, L.V.D., Hinton, G., Visualizing data using t-sne (2008) Journal of Machine Learning Research, 9 (NOV), pp. 2579-2605; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proceedings of the IEEE, 86 (11), pp. 2278-2324; Pascanu, R., Stokes, J.W., Sanossian, H., Marinescu, M., Thomas, A., Malware classification with recurrent networks (2015) IEEE Intl. Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 1916-1920. , April; Nataraj, L., Karthikeyan, S., Jacob, G., Manjunath, B., Malware images: Visualization and automatic classification (2011) Proceedings of the 8th International Symposium on Visualization for Cyber Security, p. 4. , ACM; Nataraj, L., Yegneswaran, V., Porras, P., Zhang, J., A comparative assessment of malware classification using binary texture analysis and dynamic analysis (2011) Proceedings of the 4th ACM Workshop on Security and Artificial Intelligence, pp. 21-30. , ACM; Chen, L., Comer, D.C., Priebe, C.E., Sussman, D., Tilton, J.C., Refinement of a method for identifying probable archaeological sites from remotely sensed data (2013) Mapping Archaeological Landscapes from Space, pp. 251-258. , Springer; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., (2016) Universal Adversarial Perturbations, , arXiv preprint; Carlini, N., Wagner, D., (2016) Towards Evaluating the Robustness of Neural Networks, , arXiv preprint; Carlini, N., Barresi, A., Payer, M., Wagner, D., Gross, T.R., Controlflow bending: on the effectiveness of control-flow integrity (2015) USENIX Security Symposium, pp. 161-176; Carlini, N., Wagner, D., ROP is still dangerous: Breaking modern defenses USENIX",,,,"Institute of Electrical and Electronics Engineers Inc.","2018 IEEE Symposium on Security and Privacy Workshops, SPW 2018","24 May 2018",,138430,,9780769563497,,,"English","Proc. - IEEE Symp. Secur. Priv. Workshops, SPW",Conference Paper,"Final","",Scopus,2-s2.0-85052191698
"Mauw S., Ramírez-Cruz Y., Trujillo-Rasua R.","6601991482;25723788600;36675983800;","Anonymising social graphs in the presence of active attackers",2018,"Transactions on Data Privacy","11","2",,"169","198",,8,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052381381&partnerID=40&md5=6dc4cd800c6c788cc4a8162aa218d506","CSC, University of Luxembourg, 6 av. de la Fonte, Esch-sur-Alzette, L-4364, Luxembourg; SnT, University of Luxembourg, 6 av. de la Fonte, Esch-sur-Alzette, L-4364, Luxembourg; School of Information Technology, Deakin University, 221 Burwood Hwy., Burwood, VIC  3125, Australia","Mauw, S., CSC, University of Luxembourg, 6 av. de la Fonte, Esch-sur-Alzette, L-4364, Luxembourg, SnT, University of Luxembourg, 6 av. de la Fonte, Esch-sur-Alzette, L-4364, Luxembourg; Ramírez-Cruz, Y., SnT, University of Luxembourg, 6 av. de la Fonte, Esch-sur-Alzette, L-4364, Luxembourg; Trujillo-Rasua, R., SnT, University of Luxembourg, 6 av. de la Fonte, Esch-sur-Alzette, L-4364, Luxembourg, School of Information Technology, Deakin University, 221 Burwood Hwy., Burwood, VIC  3125, Australia","The publication of social network graphs enables researchers to understand and investigate human behaviour. However, when such analyses can target single individuals rather than society as a whole, it is clear that privacy becomes a serious concern. This article addresses the challenge of publishing social graphs with proven privacy guarantees. In our adversarial model we consider an active attacker, who has the capability of altering the structure of the social graph before publication by creating new user profiles and establishing relations between them and the targeted network users. We aim to protect graphs satisfying (1, 1)-anonymity, the privacy property that char-acterises the weakest graphs in terms of resistance to active attacks. To that end, we introduce a class of perturbation methods based on edge additions that transform a (1, 1)-anonymous graph into a graph satisfying (k, ℓ)-anonymity for some k > 1 or some ℓ > 1. We prove the correctness of our approach and give a tight upper bound on the number of necessary edge additions. Experimental results, obtained on real-life graphs and a large collection of randomly generated graphs, show that our methods effectively prevent attacks from active adversaries with the capability of adding one node to the network, and additionally provide some level of protection against more capable attackers. We also conducted experiments on real-life social graphs which show that the outputs of state-of-the-art community detection algorithms on the anonymised graphs is similar to those obtained on the original graphs. © 2018, University of Skovde. All rights reserved.","(k, ℓ)-anonymity; Active attacks; Privacy; Social networks","Behavioral research; Data privacy; Perturbation techniques; Social networking (online); Active adversary; Active attack; Anonymous graphs; Community detection algorithms; Human behaviours; Network users; Perturbation method; State of the art; Graphic methods",,,,,"Backstrom, L., Dwork, C., Kleinberg, J., Wherefore art thou r3579x?: Anonymized social networks, hidden patterns, and structural steganography (2007) Proceedings of the 16Th International Conference on World Wide Web, pp. 181-190. , New York, NY, USA, ACM; Chester, S., Kapron, B.M., Ramesh, G., Srivastava, G., Thomo, A., Venkatesh, S., K-anonymization of social networks by vertex addition (2011) Proceedings II of the 15Th East-European Conference on Advances in Databases and Information Systems, pp. 107-116. , Vienna, Austria; Guimera, R., Danon, L., Diaz-Guilera, A., Giralt, F., Arenas, A., Self-similar community structure in a network of human interactions (2003) Physical Review E, 68 (6); Harary, F., Melter, R.A., On the metric dimension of a graph (1976) Ars Combinatoria, 2, pp. 191-1995; Hartung, S., Nichterlein, A., Niedermeier, R., Suchý, O., A refined complexity analysis of degree anonymization in graphs (2015) Information and Computation, 243, pp. 249-262; Hay, M., Miklau, G., Jensen, D., Towsley, D., Weis, P., Resisting structural re-identification in anonymized social networks (2008) Proceedings of the VLDB Endowment, 1 (1), pp. 102-114; Ji, S., Li, W., Mittal, P., Xin, H., Secgraph, R.B., A uniform and open-source evaluation system for graph data anonymization and de-anonymization (2015) Proceedings of the 24Th USENIX Security Symposium, pp. 303-318. , Washington DC, USA; Leskovec, J., Kleinberg, J., Faloutsos, C., Graphs over time: Densification laws, shrinking diameters and possible explanations (2005) Proceedings of the 11Th ACM SIGKDD International Conference on Knowledge Discovery in Data Mining, pp. 177-187. , Chicago, IL, USA; Leskovec, J., Sosič, R., Snap: A general-purpose network analysis and graph-mining library (2016) ACM Transactions on Intelligent Systems and Technology (TIST), 8 (1), p. 1; Liu, K., Terzi, E., Towards identity anonymization on graphs (2008) Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data, pp. 93-106. , Vancouver, Canada; Mauw, S., Trujillo-Rasua, R., Xuan, B., Counteracting active attacks in social network graphs (2016) Proceedings of Dbsec 2016, 9766, pp. 233-248. , LNCS; McAuley, J., Leskovec, J., Discovering social circles in ego networks (2014) ACM Transactions on Knowledge Discovery from Data, 8 (1), p. 4; Meyerson, A., Williams, R., On the complexity of optimal k-anonymity (2004) Proceedings of the 23Rd ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems, pp. 223-228. , New York, NY, USA; Narayanan, A., Shmatikov, V., De-anonymizing social networks (2009) Proceedings of the 30Th IEEE Symposium on Security and Privacy, pp. 173-187. , Washington, DC, USA; Panzarasa, P., Opsahl, T., Carley, K.M., Patterns and dynamics of users’ behavior and interaction: Network analysis of an online community (2009) Journal of the Association for Information Science and Technology, 60 (5), pp. 911-932; Papadopoulos, S., Kompatsiaris, Y., Vakali, A., Spyridonos, P., Community detection in social media (2012) Data Mining and Knowledge Discovery, 24 (3), pp. 515-554; Samarati, P., Protecting respondents’ identities in microdata release (2001) IEEE Transactions on Knowledge and Data Engineering, 13 (6), pp. 1010-1027; Slater, P.J., Leaves of trees (1975) Congressus Numerantium, 14; Sweeney, L., (2002) Uniqueness of Simple Demographics in the U.S. Population, , Technical report, Carnegie Mellon University, School of Computer Science, Data Privacy Laboratory; Trujillo-Rasua, R., Yero, I.G., K-metric antidimension: A privacy measure for social graphs (2016) Information Sciences, 328, pp. 403-417; van Rijsbergen, C.J., (1979) Information Retrieval. Butterworth-Heinemann, , Newton, MA, USA, 2nd edition; Varrette, S., Bouvry, P., Cartiaux, H., Georgatos, F., Management of an academic HPC cluster: The UL experience (2014) Proceedings of the 2014 International Conference on High Performance Computing & Simulation, pp. 959-967. , Bologna, Italy; Wei, P., Li, F., Zou, X., Jie, W., A two-stage deanonymization attack against anonymized social networks (2014) IEEE Transactions on Computers, 63 (2), pp. 290-303; Yang, J., Leskovec, J., Overlapping community detection at scale: A nonnegative matrix factorization approach (2013) Proceedings of the 6Th ACM International Conference on Web Search and Data Mining, pp. 587-596. , Rome, Italy; Yang, J., McAuley, J., Leskovec, J., Detecting cohesive and 2-mode communities indirected and undirected networks (2014) Proceedings of the 7Th ACM International Conference on Web Search and Data Mining, pp. 323-332. , New York, NY, USA; Haifeng, Y., Sybil defenses via social networks: A tutorial and survey (2011) SIGACT News, 42 (3), pp. 80-101; Haifeng, Y., Gibbons, P.B., Kaminsky, M., Xiao, F., Sybillimit: A near-optimal social network defense against sybil attacks (2008) Proceedings of the 2008 IEEE Symposium on Security and Privacy, pp. 3-17. , Oakland, CA, USA; Haifeng, Y., Kaminsky, M., Gibbons, P.B., Flaxman, A., Sybilguard: Defending against sybil attacks via social networks (2006) Proceedings of the 2006 Conference on Applications, Technologies, Architectures, and Protocols for Computer Communications, pp. 267-278. , Pisa, Italy; Zhou, B., Pei, J., Preserving privacy in social networks against neighborhood attacks (2008) Proceedings of the IEEE 24Th International Conference on Data Engineering, pp. 506-515. , Washington, DC, USA; Zou, L., Chen, L., Tamer Özsu, M., K-automorphism: A general framework for privacy preserving network publication (2009) Proceedings of the VLDB Endowment, 2 (1), pp. 946-957",,,,"University of Skovde",,,,,18885063,,,,"English","Trans. Data Priv.",Article,"Final","",Scopus,2-s2.0-85052381381
"Ahlawat P., Dave M.","55479897300;7006803538;","A cost-effective attack matrix based key management scheme with dominance key set for wireless sensor network security",2018,"International Journal of Communication Systems","31","12","e3713","","",,4,"10.1002/dac.3713","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050025309&doi=10.1002%2fdac.3713&partnerID=40&md5=300502933db8077eaa718722533745b8","Department of Computer Engineering, National Institute of Technology, Kurukshetra, Haryana, India","Ahlawat, P., Department of Computer Engineering, National Institute of Technology, Kurukshetra, Haryana, India; Dave, M., Department of Computer Engineering, National Institute of Technology, Kurukshetra, Haryana, India","To guarantee the proper functionality of wireless sensor network even in the presence of the potential threats, a well-designed key management scheme is very important. The assumptions about attackers critically influence the performance of security mechanisms. This paper investigates the problem of node capture from adversarial view point in which the adversary intelligently exploits the different vulnerabilities of the network to establish a cost-effective attack matrix. To counteract such attacks, the defender or the network designer constructs similar attack matrix. The defender will identify a set of critical nodes and use the key compromise relationship to assign a key dominance rank to each node of the network. The key dominance rank quantifies the possibility of attack on a particular node. It is used to determine the hash chain length. It is also used to improve the security of path key establishment as well as rekeying of the proposed scheme. The performance of the proposed scheme is analyzed with other existing schemes, and it is shown that it outperforms with increased resilience against node capture, reduced number of hash computations, reduced key compromise probability of proxy nodes, and reduced number of revoked links during rekeying process. Copyright © 2018 John Wiley & Sons, Ltd.","attack model; node capture; random key predistribution scheme; wireless sensor network","Cost effectiveness; Matrix algebra; Sensor nodes; Wireless sensor networks; Attack model; Hash computation; Key management schemes; Network designer; node capture; Potential threats; Random key predistribution; Security mechanism; Network security",,,,,"He, X., Neidermeier, M., Meer, H., Dynamic key management in wireless sensor network: a survey (2013) J Netw Comput Appl, 36, pp. 612-622; Aikyildiz, I.F., Su, W., Sankarasubramaniam, Y., Cayir, E., Wireless sensor networks: a survey (2002) Comput Netw, 38 (4), pp. 393-422; Zhang, J., Varadharajan, V., Wireless sensor network key management survey and taxonomy (2010) J Netw Comput Appl, 33 (2), pp. 63-75; Lin, C., Qiu, T., Obaidat, M.S., Yu, C.W., Yao, L., Wu, G., MREA: a minimum resource expenditure node capture attack in wireless sensor networks (2016) Security and Communication Networks, 9 (18), pp. 5502-5517; Ahlawat, P., Dave, M., A hybrid approach for path vulnerability matrix on random key predistribution for wireless sensor networks (2017) Wireless Pers Comm, 94 (4), pp. 3327-3353; Eschenauer, L., Gligor, V., A key-management scheme for distributed sensor networks (2002) . Proceedings of 9th ACM Conference on Computer and Communications Security, pp. 41-47; Chan, H., Perrig, A., Song, D., (2003) Random key predistribution schemes for sensor networks, pp. 197-213. , Proceedings of 2003 IEEE Symposium on Security and Privacy, California, USA; Du, W., Deng, J., Han, Y.S., Chen, S., Varshney, P.K., A key management scheme for wireless sensor networks using deployment knowledge (2004) INFOCOM 2004. Twenty-third Annual Joint Conference of the IEEE Computer and Communications Societies, 1. , IEEE, March; Gandino, F., Ferrero, R., Rebaudengo, M., A key distribution scheme for mobile wireless sensor networks: q- s-composite (2017) IEEE Trans Inform Forensic Secur, 12 (1), pp. 34-47; Choi, J., Bang, J., Kim, L., Ahn, M., Kwon, T., Location-based key management strong against insider threats in wireless sensor networks (2017) IEEE Syst J, 11 (2), pp. 494-502; Bechkit, W., Challal, Y., Bouadallah, A., A new class of hash chain based key predistribution scheme for WSN (2013) Comput Commun, 36 (3), pp. 243-255; Ehdaie, M., Alexiou, N., Ahmadian, M., Aref, M.R., Papadimitratos, P., 2D hash chain robust random key distribution scheme (2016) Inform Process Lett, 116 (5), pp. 367-372; Kůr, J., Matyáš, V., Švenda, P., Two improvements of random key predistribution for wireless sensor networks (2012) International Conference on Security and Privacy in Communication Systems, pp. 61-75. , Springer Berlin Heidelberg, September; Ibriq, J., Mahgoub, I., HIKES: hierarchical key establishment scheme for wireless sensor networks (2014) Int J Commun Syst, 27 (10), pp. 1825-1856; Hong, S., Lim, S., Analysis and attack models via unified modeling language in wireless sensor networks: a survey study (2010) Proc 2010 IEEE International Conference on Wireless Communications, Networking and Information Security (WCNIS), pp. 692-696; Hong, S., Lim, S., Song, J., Unified modeling language based analysis of security attacks in wireless sensor networks: a survey. KSII Trans Internet (2011) Inf Syst, 5 (5), pp. 805-821; Mishra, A., Turuk, A., (2011) Adversary information gathering model for node capture attack in wireless sensor networks, pp. 1-5. , International Conference on Devices and Communications, ICDeCom2011; Bonaci, T., Bushnell, L., Poovendran, R., Node capture attacks in wireless sensor networks: a system theoretic approach (2010) Proceedings of 49th IEEE conference on Decision and Control, pp. 6765-6772. , CDC 2010, IEEE; De, P., Liu, Y., Das, S., Deployment-aware modeling of node compromise spread in wireless sensor networks using epidemic theory (2009) ACM Trans Sensor Netw, 5 (3), pp. 1-33; Tague, P., (2009) Identifying, modeling, and mitigating attacks in wireless ad hoc and sensor networks, , Dissertation, University of Washington; Tague, P., Slater, D., Rogers, J., Poovendran, R., Evaluating the vulnerability of network traffic using joint security and routing analysis (2009) IEEE Trans Depend Secure Comput, 6 (2), pp. 111-123; Lin, C., Wu, G., Enhancing the attacking efficiency of the node capture attack in WSN: a matrix approach (2013) J Supercomput, 66 (2), pp. 989-1007; Wu, G., Chen, X., Obaidet, M.S., Lin, C., A high efficient node capture attack algorithm in wireless sensor network based on route minimum key set (2012) Secur Comm Network, 6, pp. 230-238; Lin, C., Wu, G., Qiu, T., Deng, J., A low cost node capture algorithm for wireless sensor networks (2015) Int J Commun Syst, 29 (7), pp. 1251-1268. , https://doi.org/10.1002/dac.3097; Lin, C., Wu, G., Xia, F., Yao, L., Enhancing efficiency of node compromise attacks in vehicular ad-hoc networks using connected dominating set (2013) Mobile Netw Appl, 18 (6), pp. 908-922; An, W., Ci, S., Lao, H., Vulnerability-constrained multiple minimum cost paths for multi-source wireless sensor networks (2014) Secur Comm Network, 9 (9), pp. 862-873. , https://doi.org/10.1002/sec.932; Chen, X., Makki, K., Yen, K., Pissinou, N., Attack distribution modeling and its applications in sensor network security (2007) EURASIP J Wireless Comm Network, 2008, pp. 1-11; Yu, C.-M., Li, C.-C., Lu, C.-S., Kuo, S.-Y., An application driven attack probability based deterministic pair-wise key predistribution scheme for non uniformly deployed sensor networks (2011) Int J Sensor Network, 9 (2), pp. 89-106; Ahlawat, P., Dave, M., An improved hybrid key management scheme for wireless sensor networks (2016) Fourth International Conference on Parallel, Distributed and Grid Computing (PDGC), pp. 253-258. , December; Biswas, S., Haque, M.M., Rashwand, S., Misic, J., Fast, seamless rekeying in wireless sensor networks (2009) Distributed Computing Systems Workshops, 2009. ICDCS Workshops' 09. 29th IEEE International Conference on, pp. 166-171. , IEEE, June; Ahlawat, P., Dave, M., A resilient and seamless rekeying scheme based on random key distribution for WSN (2017) Computer, Communications and Electronics (Comptelix), 2017 International Conference on, pp. 321-327. , IEEE, July; Li, G., Ling, H., Znati, T., Wu, W., A robust on-demand path-key establishment framework via random key predistribution for wireless sensor networks (2006) EURASIP J Wireless Comm Network, 2006 (1), pp. 1-10; Devanagavi, G.D., Nalini, N., Biradar, R.C., Secured routing in wireless sensor networks using fault-free and trusted nodes (2016) Int J Comm Syst, 29 (1), pp. 170-193; Sun, Y., Sun, J., Zhao, F., Hu, Z., Delay constraint multipath routing for wireless multimedia ad hoc networks (2016) Int J Comm Syst, 29, pp. 210-225; Shan, T.H., Liu, C.M., Enhancing the key pre-distribution scheme on wireless sensor networks (2008) Asia-Pacific Services Computing Conference, 2008. APSCC'08. IEEE, pp. 1127-1131. , IEEE, December; Bajestani, M.F., Payandeh, A., A novel key distribution scheme against storage-bounded adversaries using attack probabilities (2016) Turk J Electr Eng Comput Sci, 24 (3), pp. 1014-1021; Carrasco, A., Alcaraz, F., Barbancho, J., Larios, D.F., Luis Sevillano, J., Securing a wireless sensor network for human tracking: a review of solutions (2014) Int J Comm Syst, 27 (12), pp. 4384-4406; Swain, R.R., Dash, T., Khilar, P.M., An effective graph-theoretic approach towards simultaneous detection of fault (s) and cut (s) in wireless sensor networks (2017) Int J Comm Syst, 30 (13); Benenson, Z., Blaß, E.O., Freiling, F.C., Attacker models for wireless sensor networks (2010) it-Information Technology Methoden Und Innovative Anwendungen der Informatik Und Informationstechnik, 52 (6), pp. 320-324; Varga, A., The OMNET++ discrete event simulation system (2001) Proceedings of the European Simulation Multiconference, pp. 319-324. , Prague, Czech Republic, SCS—European Publishing House; Ozdemir, S., Khalil, Ö., Performance evaluation of key management schemes in wireless sensor networks (2012) Gazi Univ J Sci, 25 (2), pp. 465-476","Ahlawat, P.; Department of Computer Engineering, India; email: priyankaahlawat@nitkkr.ac.in",,,"John Wiley and Sons Ltd",,,,,10745351,,IJCYE,,"English","Int J Commun Syst",Article,"Final","",Scopus,2-s2.0-85050025309
"Baruah B., Dhal S.","57040812300;56205109200;","A two-factor authentication scheme against FDM attack in IFTTT based Smart Home System",2018,"Computers and Security","77",,,"21","35",,18,"10.1016/j.cose.2018.03.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046140029&doi=10.1016%2fj.cose.2018.03.004&partnerID=40&md5=f8bbc6ab8ccd196beea3692c030e5904","Department of Computer Science & Engineering, Indian Institute of Information Technology Guwahati, India","Baruah, B., Department of Computer Science & Engineering, Indian Institute of Information Technology Guwahati, India; Dhal, S., Department of Computer Science & Engineering, Indian Institute of Information Technology Guwahati, India","Smart Home is an emerging key-element of the advantages of Internet of Things (IoT), which facilitates an individual to have control over the smart devices of his house through the Internet. However, its control should be confined to the legitimate user only, which can refrain from malicious activities. Internet services like IFTTT (If This Then That) integrate heterogeneous Smart Home devices and allow the user to customize Smart Home configurations via IFTTT recipes. Earlier researches have suggested an attack scenario based on Feature-Distributed Malware (FDM), where the malware can compromise the victim's IFTTT account and as a result the attacker can manipulate the recipes from his own device. This paper proposes a secure IFTTT-based Smart Home framework by incorporating suitable captcha-based One Time Password (OTP) authentication scheme and Physical Unclonable Function (PUF). A suitable adversarial model has been used to evaluate the security of the framework. © 2018 Elsevier Ltd","IFTTT; IoT; Malware; Recipes; Smart Home","Authentication; Automation; Computer crime; Cryptography; Frequency division multiplexing; Intelligent buildings; Internet of things; Authentication scheme; IFTTT; Internet of Things (IOT); Malicious activities; Physical unclonable functions (PUF); Recipes; Smart homes; Two factor authentication; Malware",,,,,"Al-Fuqaha, A., Guizani, M., Mohammadi, M., Aledhari, M., Ayyash, M., Internet of things: A survey on enabling technologies, protocols, and applications (2015) IEEE Commun Surv Tutor, 17 (4), pp. 2347-2376; Barabosch, T., Gerhards-Padilla, E., Host-based code injection attacks: A popular technique used by malware (2014) Proceedings of the ninth international conference on malicious and unwanted software: The americas (MALWARE), pp. 8-17; Bhargavan, K., Lavaud, A.D., Fournet, C., Pironti, A., Strub, P.Y., Triple handshakes and cookie cutters: Breaking and fixing authentication over TLS (2014) Proceedings of the IEEE symposium on security and privacy, pp. 98-113; Burrows, M., Abadi, M., A logic of authentication (1990) ACM Trans Comput Syst, 8 (1), pp. 18-36; Choi, H., Kwon, H., Hur, J., A secure OTP algorithm using a smartphone application (2015) Proceedings of the seventh international conference on ubiquitous and future networks, pp. 476-481; Cooijmans, T., de Ruiter, J., Poll, E., Analysis of secure key storage solutions on android (2014) Proceedings of the forth ACM workshop on security and privacy in smartphones & mobile devices, pp. 11-20; Coppolino, L., D'Alessandro, V., D'Antonio, S., Lev, L., Romano, L., My smart home is under attack (2016) Proceedings of the IEEE eighteenth international conference on computational science and engineering, pp. 145-151; Fernandes, E., Rahmati, A., Jung, J., Prakash, A., (2017), 1707.00405 Decoupled-IFTTT: Constraining privilege in trigger-action platforms forthe internet of things, arXiv: [cs.CR]; Gong, L., Needham, R., Yahalom, R., Reasoning about belief in cryptographic protocols (1990) Proceedings of the IEEE computer society symposium on research in security and privacy, pp. 234-248; Herder, C., Yu, M.-D., Koushanfar, F., Devadas, S., Physical unclonable functions and applications: A tutorial (2014) Proc IEEE, 102 (8), pp. 1126-1141; https://ifttt.com, IFTTT; Jain, A., Prachi, Android security: Permission based attacks (2016) Proceedings of the third international conference on computing for sustainable global development, pp. 2754-2759; Jose, A.C., Malekian, R., Ye, N., Improving home automation security; integrating device fingerprinting into smart home (2016) IEEE Access, 4, pp. 5776-5787; Katzenbeisser, S., Kocabas, U., van der Leest, V., Sadeghi, A.-R., Schrijen, G.-J., Schröder, H., Wachsmann, C., Recyclable PUFs: Logically reconfigurable PUFs (2011) J Cryptogr Eng, 1, pp. 177-186; Kaur, A., Bhandari, A., Detection and mitigation of spoofing attacks by using SDN in LAN (2017) Proceedings of the sixth international conference on soft computing for problem solving, advances in intelligent systems and computing, 547, pp. 240-247; Kaur, N., Devgan, M., Bhushan, S., Robust login authentication using time-based OTP through secure tunnel (2016) Proceedings of the third international conference on computing for sustainable global development, pp. 3222-3226; Kitsos, P., Security in RFID and sensor networks (2016), Auerbach Publications; Kranch, M., Bonneau, J., Upgrading HTTPS in mid-air: An empirical study of strict transport security and key pinning (2015) Proceedings of the twenty-second network and distributed system security symposium; Kumar, H., Mercian, A., Banerjee, S., Russell, C., Sivaraman, V., Implementing geo-blocking and spoofing protection in multi-domain software defined interconnects (2017) Proceedings of the first international workshop on security and dependability of multi-domain infrastructures; Lee, K.-M., Teng, W.-G., Hou, T.-W., Point-n-press: An intelligent universal remote control system for home appliances (2016) IEEE Trans Autom Sci Eng, 13 (3), pp. 1308-1317; Maes, R., Verbauwhede, I., Towards hardware-intrinsic security (2010) Proceedings of the information security and cryptography, pp. 3-37; Marchand, C., Bossuet, L., Mureddu, U., Bochard, N., Cherkaoui, A., Fischer, V., Implementation and characterization of a physical unclonable function for IoT: A case study with the TERO-PUF (2018) IEEE Trans Comput Aided Des Integr Circ Syst, 37 (1), pp. 97-109; Min, B., Varadharajan, V., Design and analysis of a new feature-distributed malware (2014) Proceedings of the IEEE thirteenth international conference on trust, security and privacy in computing and communications, pp. 457-464; Min, B., Varadharajan, V., Feature-distributed malware attack: Risk and defence (2014) Proceedings of the nineteenth european symposium on research in computer security, pp. 457-474; Min, B., Varadharajan, V., Design and evaluation of feature distributed malware attacks against the internet of things (IoT) (2015) Proceedings of the Twentieth international conference on engineering of complex computer systems, pp. 80-89; M'Raihi, D., Machani, S., Pei, M., Rydell, J., TOTP: Time-based one-time password algorithm (2011) Proceedings of the internet engineering task force RFC 6238; Mukhopadhyay, D., PUFs as promising tools for security in internet of things (2016) IEEE Des Test, 33 (3), pp. 103-115; Mylonas, A., Dritsas, S., Tsoumas, B., Gritzalis, D., Smartphone security evaluation the malware attack case (2011) Proceedings of the international conference on security and cryptography, pp. 25-36; Pan, J., Fungo, C.C., An offensive containment strategy based on malware's attack patterns (2013) Proceedings of the international conference on machine learning and cybernetics, pp. 1631-1636; Pirscoveanu, R.S., Hansen, S.S., Larsen, T.M.T., Stevanovic, M., Pedersen, J.M., Czech, A., Analysis of malware behavior: Type classification using machine learning (2015) Proceedings of the international conference on cyber situational awareness, data analytics and assessment, pp. 1-7; Reimair, F., Kollmann, C., Marsalek, A., Emulating U2F authenticator devices (2016) Proceedings of the IEEE conference on communications and network security; Sahri, N., Okamura, K., Protecting DNS services from IP spoofing: SDN collaborative authentication approach (2016) Proceedings of the eleventh international conference on future internet technologies, pp. 83-89; Selvi, J., Bypassing HTTP strict transport security (2014), BlackHat Europe; Sood, A.K., Zeadally, S., Drive-by download attacks: A comparative study (2016) IT Profess, 18 (5), pp. 18-25; Srinivas, S., Balfanz, D., Tiffany, E., Czeskis, A., Universal 2nd factor (U2F) overview (2015) Proceedings of the FIDO alliance proposed standard; Srivastava, S., Sivasankar, M., On the generation of alphanumeric one time passwords (2016) Proceedings of the international conference on inventive computation technologies; Suresh, S., Sruthi, P.V., A review on smart home technology (2015) Proceedings of the online international conference on green engineering and technologies, pp. 1-3; Takkinen, L., Analysing security protocols with AVISPA (2006) Proceedings of the TKK t-110.7290 research seminar on network security; Tsui, E., Wang, W.M., Sabetzadeh, F., Enacting personal knowledge management & learning with web services interoperability tools (2014) Proceedings of the IEEE third international conference on cloud computing and intelligence systems, pp. 491-494; Zhou, M., Fortino, G., Shen, W., Mitsugi, J., Jobin, J., Bhattacharyya, R., Guest editorial special section on advances and applications of internet of things for smart automated systems (2016) IEEE Trans Autom Sci Eng, 13 (3), pp. 1225-1229","Baruah, B.; Department of Computer Science & Engineering, India; email: barnanabaruah12.13@gmail.com",,,"Elsevier Ltd",,,,,01674048,,CPSED,,"English","Comput Secur",Article,"Final","",Scopus,2-s2.0-85046140029
"Liu Y., Li C.","55872355100;55695985100;","Secure Distributed Estimation Over Wireless Sensor Networks Under Attacks",2018,"IEEE Transactions on Aerospace and Electronic Systems","54","4","8286913","1815","1831",,24,"10.1109/TAES.2018.2803578","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041507402&doi=10.1109%2fTAES.2018.2803578&partnerID=40&md5=41aa8e216e0e25ede040e1ab72041f94","College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, 310027, China","Liu, Y., College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, 310027, China; Li, C., College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, 310027, China","The problem of distributed estimation over wireless sensor networks in an adversarial environment with the presence of attacks on sensed and communicated information is considered. To tackle with this problem, a secure diffusion least-mean squares (S-dLMS) algorithm is proposed. The proposed S-dLMS can be considered as a hybrid system, which consists of a noncooperative LMS (nc-LMS) subsystem and a diffusion LMS (dLMS) subsystem. The nc-LMS subsystem is used to provide a reliable reference estimate, which is further used for constructing the threshold test to detect the trust neighbors of each node. Then, based on the detected secure network topology, the dLMS subsystem is performed by combining the received information from the trust neighbors. The performance of the proposed S-dLMS algorithm in the mean and mean-square senses is analyzed, and then an adaptive rule is suggested to select the threshold for detection. Finally, some simulations are performed to show the effectiveness of the proposed S-dLMS algorithm under fixed and time-varying attacks, respectively. © 2018 IEEE.","Attack; compromised communication; compromised sensor; detection; distributed estimation; security; wireless sensor networks (WSNs)","Data structures; Error detection; Estimation; Hybrid systems; Network security; Robustness (control systems); Sensors; Wireless telecommunication systems; attack; Distributed database; Distributed estimation; Security; Wireless communications; Wireless sensor networks",,,,,"Dimakis, A.G., Gossip algorithms for distributed signal processing (2010) Proc. IEEE, 98 (11), pp. 1847-1864. , Nov; Sayed, A.H., Diffusion strategies for adaptation and learning over networks (2013) IEEE Signal Process. Mag., 30 (3), pp. 155-171. , Mar; Shirazinia, A., Dey, S., Ciuonzo, D., Salvo Rossi, P., Massive MIMO for decentralized estimation of a correlated source (2016) IEEE Trans. Signal Process, 64 (10), pp. 2499-2512. , May; Sayed, A.H., Lopes, C.G., Adaptive processing over distributed networks (2007) IEICE Trans. Fundam. Electron., Commun. Comput. Sci., 90 (8), pp. 1504-1510. , Aug; Lopes, C.G., Sayed, A.H., Diffusion least-mean squares over adaptive networks: Formulation and performance analysis (2008) IEEE Trans. Signal Process, 56 (7), pp. 3122-3136. , Jul; Cattivelli, F.S., Sayed, A.H., Diffusion LMS strategies for distributed estimation (2010) IEEE Trans. Signal Process, 58 (3), pp. 1035-1048. , Mar; Takahashi, N., Yamada, I., Sayed, A.H., Diffusion least-mean squares with adaptive combiners: Formulation and performance analysis (2010) IEEE Trans. Signal Process, 58 (9), pp. 4795-4810. , Sep; Liu, Y., Li, C., Zhang, Z., Diffusion sparse least-mean squares over networks (2012) IEEE Trans. Signal Process, 60 (8), pp. 4480-4485. , Aug; Sayed, A.H., Tu, S.Y., Chen, J., Zhao, X., Towfic, Z.J., Diffusion strategies for adaptation and learning over networks (2013) IEEE Signal Process. Mag., 30 (3), pp. 155-171. , May; Cattivelli, F.S., Lopes, C.G., Sayed, A.H., Diffusion recursive least-squares for distributed estimation over adaptive networks (2008) IEEE Trans. Signal Process, 56 (5), pp. 1865-1877. , May; Liu, Z., Liu, Y., Li, C., Distributed sparse recursive least-squares over networks (2014) IEEE Trans. Signal Process, 62 (6), pp. 1386-1395. , Feb; Li, C., Shen, P., Liu, Y., Zhang, Z., Diffusion information theoretic learning for distributed estimation over network (2013) IEEE Trans. Signal Process, 61 (16), pp. 4011-4024. , Aug; Li, C., Huang, S., Liu, Y., Liu, Y.G., Distributed TLS over multitask networks with adaptive intertask cooperation (2016) IEEE Trans. Aerosp. Electron. Syst., 52 (6), pp. 3036-3052. , Dec; Wang, Y., Petar, M.D., Reaching Bayesian belief over networks in the presence of communication noise (2013) Proc. IEEE Glob. Conf. Signal Inf. Process, pp. 591-594; Wang, Y., Petar, M.D., Distributed Bayesian estimation of linear models with unknown observation covariances (2016) IEEE Trans. Signal Process, 64 (8), pp. 1962-1971. , Apr; Schizas, I.D., Mateos, G., Giannakis, G.B., Distributed LMS for consensus-based in-network adaptive processing (2009) IEEE Trans. Signal Process, 8 (6), pp. 2365-2381. , Jun; Lamport, L., Shostak, R., Pease, M., The byzantine generals problem (1982) ACM Trans. Program. Lang. Syst., 4 (3), pp. 382-401. , Jul; Vempaty, A., Tong, L., Varshney, P., Distributed inference with byzantine data: State of the art review on data falsification attacks (2013) IEEE Signal Process. Mag., 30 (5), pp. 65-75. , Sep; Kailkhura, B., Brahma, S., Han, Y.S., Varshney, P.K., Distributed detection in tree topologies with byzantines (2014) IEEE Trans. Signal Process, 62 (12), pp. 3208-3219. , Jun; Kailkhura, B., Han, Y., Brahma, S., Varshney, P., Distributed Bayesian detection in the presence of byzantine data (2015) IEEE Trans. Signal Process, 63 (19), pp. 5250-5263. , Jun; Zhang, J., Blum, R.S., Kaplan, L.M., Lu, X., Functional forms of optimum spoofing attacks for vector parameter estimation in quantized sensor networks (2017) IEEE Trans. Signal Process, 65 (3), pp. 705-720. , Feb; Wu, S.C., Liu, B., Bai, X., Hou, Y.G., Eavesdropping-based gossip algorithms for distributed consensus in wireless sensor networks (2015) IEEE Signal Process. Lett., 22 (9), pp. 1388-1391. , Sep; Vempaty, A., Ray, P., Varshney, P., False discovery rate based distributed detection in the presence of byzantines (2004) IEEE Trans. Aerosp. Electron. Syst., 50 (3), pp. 1826-1840. , Jul; Marano, S., Matta, V., Tong, L., Distributed detection in the presence of byzantine attacks (2009) IEEE Signal Process. Mag., 57 (1), pp. 16-29. , Jan; Salleh, H., Moravejosharieh, R., Overview of security issues in wireless sensor networks modares (2011) Proc. 3rd Int. Conf. Comput. Intell., Model. Simul., pp. 308-311; Kaligineedi, P., Khabbazian, M., Bhargava, V., Secure cooperative sensing techniques for cognitive radio systems (2008) Proc. IEEE Int. Conf. Commun., pp. 3406-3410. , May; Rawat, A., Anand, P., Chen, H., Varshney, P., Collaborative spectrum sensing in the presence of byzantine attacks in cognitive radio networks (2011) IEEE Trans. Signal Process, 59 (2), pp. 774-786. , Feb; Khan, U.A., Stanković, A.M., Secure distributed estimation in cyber-physical systems (2013) Proc. IEEE Int. Conf. Acoust., Speech, Signal Process, pp. 5209-5213; Fawzi, H., Tabuada, P., Diggavi, S., Secure estimation and control for cyber-physical systems under adversarial attacks (2014) IEEE Autom. Control, 59 (6), pp. 1454-1467. , Jun; Vukovic, O., Dan, G., Security of fully distributed power system state estimation: Detection and mitigation of data integrity attacks (2014) IEEE J. Sel. Areas Commun., 32 (7), pp. 1500-1508. , Jul; Zhang, J., Blum, R.S., Lu, X., Conus, D., Asymptotically optimum distributed estimation in the presence of attacks (2015) IEEE Trans. Signal Process, 63 (5), pp. 1086-1101. , Mar; Guo, X., Leong, A.S., Dey, S., Estimation in wireless sensor networks with security constraints (2017) IEEE Trans. Aerosp. Electron. Syst., 53 (2), pp. 544-561. , Apr; Lu, G., Chen, W., Huang, D., Distributed diffusion least mean square algorithm based on the reputation mechanism (in chin.) (2015) J. Electron. Inf. Technol., 37 (5), pp. 1234-1240. , May; Gentz, R., Wu, S., Wai, H.T., Scaglione, A., Leshem, A., Data injection attacks in randomized gossiping (2016) IEEE Trans. Signal Inf. Process. Netw., 2 (4), pp. 523-538. , Dec; Monticelli, A., (1999) State Estimation in Electric Power Systems, A Generalized Approach, , Norwell, MA, USA: Kluwer; Liu, Y., Ning, P., Reiter, M.K., False data injection attacks against state estimation in electric power grids (2009) Proc. 16th ACM Conf. Comput. Commun. Security, pp. 21-32. , Nov; Kim, T.T., Poor, H.V., Strategic protection against data injection attacks on power grids (2011) IEEE Trans. Smart Grid, 2 (2), pp. 326-333. , Jun; Liu, L., Esmalifalak, M., Ding, Q., Emesih, V.A., Han, Z., Detecting false data injection attacks on power grid by sparse optimization (2014) IEEE Trans. Smart Grid, 5 (2), pp. 612-621. , Mar; Zhao, X., Sayed, A.H., Distributed clustering and learning over networks (2015) IEEE Trans. Signal Process, 63 (13), pp. 3285-3300. , Jul; Ying, B., Sayed, A.H., Information exchange and learning dynamics over weaklyconnected adaptive networks (2016) IEEE Trans. Inf. Theory, 62 (3), pp. 1396-1414. , Mar; Blondel, V.D., Hendrickx, J.M., Olshevsky, A., Tsitsiklis, J.N., Convergence in multiagent coordination, consensus, and flocking (2005) Proc. Joint 44th IEEE Conf. Decis. Control Eur. Control Conf., pp. 2996-3000. , Seville, Spain, Dec; Sayed, A.H., (2014) Adaptation, Learning, and Optimization over Networks, 7 (4-5), pp. 311-801. , (Foundations and Trends in Machine Learning), Breda, The Netherlands: Now Publishers; Sayed, A.H., (2003) Fundamentals of Adaptive Filtering, , New York, NY, USA: Wiley","Liu, Y.; College of Information Science and Electronic Engineering, China; email: yingliu@zju.edu.cn",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,00189251,,IEARA,,"English","IEEE Trans. Aerosp. Electron. Syst.",Article,"Final","",Scopus,2-s2.0-85041507402
"Dibaji S.M., Ishii H., Tempo R.","56315860000;7402978689;57218889376;","Resilient randomized quantized consensus",2018,"IEEE Transactions on Automatic Control","63","8",,"2508","2522",,64,"10.1109/TAC.2017.2771363","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033702243&doi=10.1109%2fTAC.2017.2771363&partnerID=40&md5=cba819537a178986ac338799995b22ae","Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA  02139, United States; Department of Computer Science, Tokyo Institute of Technology, Yokohama, 226-8502, Japan; CNR-IEIIT, Politecnico di Torino, Torino, 10129, Italy","Dibaji, S.M., Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA  02139, United States; Ishii, H., Department of Computer Science, Tokyo Institute of Technology, Yokohama, 226-8502, Japan; Tempo, R., CNR-IEIIT, Politecnico di Torino, Torino, 10129, Italy","We consider the problem of multiagent consensus where some agents are subject to faults/attacks and might make updates arbitrarily. The network consists of agents taking integer-valued (i.e., quantized) states under directed communication links. The goal of the healthy normal agents is to form consensus in their state values, which may be disturbed by the non-normal, malicious agents. We develop update schemes to be equipped by the normal agents whose interactions are asynchronous and subject to nonuniform and time-varying time delays. In particular, we employ a variant of the so-called mean subsequence reduced algorithms, which have been long studied in computer science, where each normal agent ignores extreme values from its neighbors. We solve the resilient quantized consensus problems in the presence of totally/locally bounded adversarial agents and provide necessary and sufficient conditions in terms of the connectivity notion of graph robustness. Furthermore, it will be shown that randomization is essential both in quantization and in the updating times when normal agents interact in an asynchronous manner. The results are examined through a numerical example. © 1963-2012 IEEE.","Asynchronous communication; cyber security; distributed algorithms; fault tolerant systems; multi-agent systems; quantization","Computer control systems; Computer science; Control systems; Electronic mail; Intelligent agents; Quantization (signal); Robustness (control systems); Adversarial agent; Delays; Extreme value; Malicious agent; Normal agents; Quantized consensus; State values; Update schemes; Multi agent systems",,,,,"Aysal, T.C., Coates, M.J., Rabbat, M.G., Distributed average consensus with dithered quantization (2008) IEEE Trans. Signal Process., 56 (10), pp. 4905-4918. , Oct; Azadmanesh, M.H., Kiechafer, R.M., Asynchronous approximate agreement in partially connected networks (2002) Int. J. Parallel Distrib. Netw., 5 (1), pp. 26-34; Ben-Or, M., Another advantage of free choice: Completely asynchronous agreement protocols (1983) Proc. 2nd Annu. ACM Symp. Princ. Distrib. Comput., pp. 27-30; Cai, K., Ishii, H., Quantized consensus and averaging on gossip digraphs (2011) IEEE Trans. Autom. Control, 56 (9), pp. 2087-2100. , Sep; Cai, K., Ishii, H., Convergence time analysis of quantized gossip consensus on digraphs (2012) Automatica, 48 (9), pp. 2344-2351; Carli, R., Fagnani, F., Frasca, P., Zampieri, S., Gossip consensus algorithms via quantized communication (2010) Automatica, 46 (1), pp. 70-80; Chamie, M.E., Liu, J., Başar, T., Design and analysis of distributed averaging with quantized communication (2014) Proc. 53rd IEEE Conf. Decis. Control, pp. 3860-3865; Dibaji, S.M., Resilient Consensus OfMulti-Agent Networks in the Presence of Malicious Attacks, , Ph. D. thesis, Tokyo Inst. Technol., Tokyo, Japan 2016; Dibaji, S.M., Ishii, H., Resilient multi-agent consensus with asynchrony and delayed information (2015) Proc. 5th IFAC Workshop Distrib. Estimation Control Netw. Syst., pp. 28-33; Dibaji, S.M., Ishii, H., Consensus of second-ordermulti-agent systems in the presence of locally bounded faults (2015) Syst. Control Lett., 79, pp. 23-29; Dibaji, S.M., Ishii, H., Tempo, R., Resilient randomized quantized consensus (2016) Proc. Amer. Control Conf., pp. 5118-5123; Dibaji, S.M., Ishii, H., Tempo, R., Resilient randomized quantized consensus with delayed information (2016) Proc. 55th IEEE Conf. Decis. Control, pp. 3505-3510; Dibaji, S.M., Ishii, H., Resilient consensus of second-order agent networks: Asynchronous update rules over robust graphs (2017) Automatica, 81, pp. 123-132; Etesami, S.R., Başar, T., Convergence time for unbiased quantized consensus over static and dynamic networks (2016) IEEE Trans. Autom. Control, 61 (2), pp. 443-455. , Feb; Fischer, M.J., Lynch, N.A., Paterson, M.S., Impossibility of distributed consensus with one faulty process (1985) J. ACM, 32 (2), pp. 374-382; Frasca, P., Carli, R., Fagnani, F., Zampieri, S., Average consensus on networks with quantized communication (2009) Int. J. Robust Nonlinear Control, 19 (16), pp. 1787-1816; Gravelle, E., Martínez, S., Quantized distributed load balancing with capacity constraints (2014) Proc. 53rd IEEE Conf. Decis. Control, pp. 3866-3871; Ishii, H., Tempo, R., The PageRank problem, multiagent consensus, and web aggregation: A systems and control viewpoint (2014) IEEE Control Syst. Mag., 34 (3), pp. 34-53. , Jun; Kar, S., Moura, J.M.F., Distributed consensus algorithms in sensor networks: Quantized data and random link failures (2010) IEEE Trans. Signal Proc., 58 (3), pp. 1383-1400. , Mar; Kashyap, A., Başar, T., Srikant, R., Quantized consensus (2007) Automatica, 43 (7), pp. 1192-1203; Kikuya, Y., Dibaji, S.M., Ishii, H., Fault tolerant clock synchronization over unreliable channels in wireless sensor networks IEEE Trans. Control Netw. Syst., , to be published; Lavaei, J., Murray, R.M., Quantized consensus by means of gossip algorithm (2012) IEEE Trans. Autom. Control, 57 (1), pp. 19-32; LeBlanc, H.J., (2012) Resilient Cooperative Control of Networked Multi-agent Systems, , Ph. D. Dissertation, Dept. Elect. Eng. and Comp. Sci., Vanderbilt Univ., Nashville, TN; LeBlanc, H.J., Zhang, H., Koutsoukos, X., Sundaram, S., Resilient asymptotic consensus in robust networks (2013) IEEE J. Sel. Areas Commun., 31 (4), pp. 766-781; Li, T., Fu, M., Xie, L., Zhang, J.-F., Distributed consensus with limited communication data rate (2011) IEEE Trans. Autom. Control, 56 (2), pp. 279-292. , Feb; Lynch, N.A., (1996) Distributed Algorithms, , San Mateo, CA, USA: Morgan Kaufmann; Mesbahi, M., Egerstedt, M., (2010) Graph Theoretic Methods in Multiagent Networks, , Princeton, NJ, USA: Princeton Univ. Press; Motwani, R., Raghavan, P., (1995) Randomized Algorithms, , Cambridge, U. K.: Cambridge Univ. Press; Nedic, A., Olshevsky, A., Ozdaglar, A., Tsitsiklis, J.N., On distributed averaging algorithms and quantization effects (2009) IEEE Trans. Autom. Control, 54 (11), pp. 2506-2517. , Nov; Pasqualetti, F., Dorfler, F., Bullo, F., Attack detection and identification in cyber-physical systems (2013) IEEE Trans. Autom. Control, 58 (11), pp. 2715-2729. , Nov; Rabin, M., Randomized Byzantine generals (1983) Proc. 24th Annu. IEEE Symp. Found. Comput. Sci., pp. 403-409; Ravazzi, C., Frasca, P., Tempo, R., Ishii, H., Ergodic randomized algorithms and dynamics over networks (2015) IEEE Trans. Control Netw. Syst., 2 (1), pp. 78-87. , Mar; Ren, W., Cao, Y., (2011) Distributed Coordination of Multi-Agent Networks, , New York, NY, USA: Springer; Shahrivar, E.M., Pirani, M., Sundaram, S., Robustness and algebraic connectivity of random interdependent networks (2015) Proc. 5th IFAC Workshop Distrib. Estimation Control Netw. Syst., pp. 252-257; Tempo, R., Calafiore, G., Dabbene, F., (2013) Randomized Algorithms for Analysis and Control of Uncertain Systems, with Applications, , 2nd ed., New York, NY, USA: Springer; Tempo, R., Ishii, H., Monte Carlo and Las Vegas randomized algorithms for systems and control (2007) Eur. J. Control, 13, pp. 189-203; Tseng, L., Vaidya, N.H., Fault-tolerant consensus in directed graphs (2015) Proc. ACM Symp. Princ. Distrib. Comput., pp. 451-460; Vaidya, N., Tseng, L., Liang, G., Iterative approximate Byzantine consensus in arbitrary directed graphs (2012) Proc. ACM Symp. Princ. Distrib. Comput., pp. 365-374; Wannamaker, R.A., Lipshitz, S.P., Vanderkooy, J., Wright, J.N., A theory of nonsubtractive dither (2000) IEEE Trans. Signal Proc., 48 (2), pp. 499-516. , Feb; Zhang, H., Fata, E., Sundaram, S., A notion of robustness in complex networks (2015) IEEE Trans. Control Netw. Syst., 2 (3), pp. 310-320. , Sep; Zhao, J., Yagan, O., Gligor, V., On the strengths of connectivity and robustness in general random intersection graphs (2014) Proc. 53rd IEEE Conf. Decis. Control, pp. 3661-3668; Zhu, M., Martínez, S., On the convergence time of asynchronous distributed quantized averaging algorithms (2011) IEEE Trans. Autom. Control, 56 (2), pp. 386-390. , Feb","Ishii, H.; Department of Computer Science, Japan; email: ishii@c.titech.ac.jp",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,00189286,,IETAA,,"English","IEEE Trans Autom Control",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85033702243
"Li P., Liu Q., Zhao W., Wang D., Wang S.","57200645230;57001286200;7403942668;57194333339;56479668600;","Chronic poisoning against machine learning based IDSs using edge pattern detection",2018,"IEEE International Conference on Communications","2018-May",,"8422328","","",,3,"10.1109/ICC.2018.8422328","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051441602&doi=10.1109%2fICC.2018.8422328&partnerID=40&md5=d9ef197d721c6e1035a22db4d61a5f84","College of Computer, National University of Defense Technology, Changsha, Hunan, 410073, China","Li, P., College of Computer, National University of Defense Technology, Changsha, Hunan, 410073, China; Liu, Q., College of Computer, National University of Defense Technology, Changsha, Hunan, 410073, China; Zhao, W., College of Computer, National University of Defense Technology, Changsha, Hunan, 410073, China; Wang, D., College of Computer, National University of Defense Technology, Changsha, Hunan, 410073, China; Wang, S., College of Computer, National University of Defense Technology, Changsha, Hunan, 410073, China","In big data era, machine learning is one of fundamental techniques in intrusion detection systems (IDSs). Poisoning attack, which is one of the most recognized security threats towards machine learning- based IDSs, injects some adversarial samples into the training phase, inducing data drifting of training data and a significant performance decrease of target IDSs over testing data. In this paper, we adopt the Edge Pattern Detection (EPD) algorithm to design a novel poisoning method that attack against several machine learning algorithms used in IDSs. Specifically, we propose a boundary pattern detection algorithm to efficiently generate the points that are near to abnormal data but considered to be normal ones by current classifiers. Then, we introduce a Batch-EPD Boundary Pattern (BEBP) detection algorithm to overcome the limitation of the number of edge pattern points generated by EPD and to obtain more useful adversarial samples. Based on BEBP, we further present a moderate but effective poisoning method called chronic poisoning attack. Extensive experiments on synthetic and three real network data sets demonstrate the performance of the proposed poisoning method against several well-known machine learning algorithms and a practical intrusion detection method named FMIFS-LSSVM-IDS. © 2018 IEEE.","Chronic poisoning; Data drifting; Intrusion detection system; Machine learning","Artificial intelligence; Big data; Computer crime; Intrusion detection; Learning systems; Network security; Pattern recognition; Signal detection; Boundary patterns; Data drifting; Detection algorithm; Intrusion detection method; Intrusion Detection Systems; Poisoning attacks; Real network datum; Security threats; Learning algorithms",,,,,"Ambusaidi, M.A., He, X., Nanda, P., Tan, Z., Building an intrusion detection system using a filter-based feature selection algorithm (2016) IEEE Trans. Comput., 65 (10), pp. 2986-2998; Kishimoto, K., Yamaki, H., Takakura, H., Improving performance of anomaly-based ids by combining multiple classifiers (2011) Proc. of the SAINT'11, pp. 366-371; Nelson, B., Barreno, M., Chi, F.J., Joseph, A.D., Rubinstein, B.I.P., Saini, U., Sutton, C., Xia, K., (2009) Misleading Learners: Co-opting Your Spam Filter, Ser. Machine Learning in Cyber Trust, , Springer, Boston, MA; Biggio, B., Rieck, K., Ariu, D., Wressnegger, C., Corona, I., Giacinto, G., Roli, F., Poisoning behavioral malware clustering (2014) Proc. of the AISec'14, pp. 27-36. , New York, NY, USA: ACM; Hu, W., Tan, Y., (2017) Generating Adversarial Malware Examples for Black-box Attacks Based on Gan, , https://arxiv.org/abs/1702.05983, arXiv. org; Kloft, M., Laskov, P., Online anomaly detection under adversarial impact (2010) Proc. of the AISTATS'10, pp. 405-412; Rubinstein, B.I., Nelson, B., Huang, L., Joseph, A.D., Lau, S.-H., Rao, S., Taft, N., Tygar, J.D., Antidote: Understanding and defending against poisoning of anomaly detectors (2009) Proc. of the IMC'09, pp. 1-14. , NewYork, NY, USA: ACM; Barreno, M., Nelson, B., Sears, R., Joseph, A.D., Tygar, J.D., Can machine learning be secure? (2006) Proc. of the ASIACCS'06, pp. 16-25. , NewYork, NY, USA: ACM; Xu, W., Qi, Y., Evans, D., Automatically evading classifiers: A case study on pdf malware classifiers (2016) Proc. of the NDSS'16, pp. 1-15; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proc. of the ASIACCS'17, pp. 506-519. , New York, NY, USA: ACM; Moosavidezfooli, S.M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proc. of the CVPR'16, pp. 2574-2582; Biggio, B., Nelson, B., Laskov, P., Poisoning attacks against support vector machines (2012) Proc. of the ICML'12, pp. 1467-1474; Yang, C., Wu, Q., Li, H., Chen, Y., (2017) Generative Poisoning Attack Method Against Neural Networks, , https://arxiv.org/abs/1703.01340, arXiv. org; Zhao, M., An, B., Gao, W., Zhang, T., Efficient label contamination attacks against black-box learning models (2017) Proc. of the IJCAI'17, pp. 3945-3951; Rosenberg, I., Shabtai, A., Rokach, L., Elovici, Y., (2017) Generic Black-box End-to-end Attack Against Rnns and Other Api Calls Based Malware Classifiers, , https://arxiv.org/abs/1707.05970, arXiv. org; Tramèr, F., Zhang, F., Juels, A., Reiter, M.K., Ristenpart, T., (2016) Stealing Machine Learning Models Via Prediction Apis, , arXiv. org; Li, Y., Maguire, L., Selecting critical patterns based on local geometrical and statistical information (2011) IEEE Trans. Pattern Anal. Mach. Intell., 33 (6), pp. 1189-1201; Wang, S., Liu, Q., Zhu, E., Yin, J., Zhao, W., Mst-gen: An efficient parameter selection method for one-class extreme learning machine (2017) IEEE Trans. Cybern., 47 (10), pp. 3266-3279; Biggio, B., Fumera, G., Roli, F., Security evaluation of pattern classifiers under attack (2017) IEEE Trans. Knowl. Data Eng., 26 (4), pp. 984-996; Song, J., Takakura, H., Okabe, Y., Eto, M., Inoue, D., Nakao, K., Statistical analysis of honeypot data and building of kyoto 2006+ dataset for nids evaluation (2011) Proc. of the BADGERS'11, pp. 29-36. , NewYork, NY, USA: ACM",,,"Cisco;et al.;Huawei;National Instruments;Qualcomm;Sprint","Institute of Electrical and Electronics Engineers Inc.","2018 IEEE International Conference on Communications, ICC 2018","20 May 2018 through 24 May 2018",,138282,15503607,9781538631805,,,"English","IEEE Int Conf Commun",Conference Paper,"Final","",Scopus,2-s2.0-85051441602
"Liu Y., Xia Z., Yi P., Yao Y., Xie T., Wang W., Zhu T.","57203373772;57203370132;7005532157;57192649920;55621907800;57020942200;35079735800;","GENPass: A general deep learning model for password guessing with PCFG rules and adversarial generation",2018,"IEEE International Conference on Communications","2018-May",,"8422243","","",,14,"10.1109/ICC.2018.8422243","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051437441&doi=10.1109%2fICC.2018.8422243&partnerID=40&md5=0d67a9215856927b5842f9d11ea10b2e","Shanghai Key Laboratory of Integrated Administration Technologies for Information Security, School of Cyber Security, Shanghai Jiao Tong University, Shanghai, 200240, China; Department of Computer Science and Electrical Engineering, University of Maryland, Baltimore County, MD  21250, United States","Liu, Y., Shanghai Key Laboratory of Integrated Administration Technologies for Information Security, School of Cyber Security, Shanghai Jiao Tong University, Shanghai, 200240, China; Xia, Z., Shanghai Key Laboratory of Integrated Administration Technologies for Information Security, School of Cyber Security, Shanghai Jiao Tong University, Shanghai, 200240, China; Yi, P., Shanghai Key Laboratory of Integrated Administration Technologies for Information Security, School of Cyber Security, Shanghai Jiao Tong University, Shanghai, 200240, China; Yao, Y., Department of Computer Science and Electrical Engineering, University of Maryland, Baltimore County, MD  21250, United States; Xie, T., Department of Computer Science and Electrical Engineering, University of Maryland, Baltimore County, MD  21250, United States; Wang, W., Department of Computer Science and Electrical Engineering, University of Maryland, Baltimore County, MD  21250, United States; Zhu, T., Department of Computer Science and Electrical Engineering, University of Maryland, Baltimore County, MD  21250, United States","Password has become today's dominant method of authentication in social network. While the brute-force attack methods, such as HashCat and John the Ripper, are unpractical, the research then switches to the password guess. The state-of-the-art approaches, such as Markov Model and probabilistic context-free grammars(PCFG), are all based on statistical probability. These approaches have a low matching rate. The methods on neural network have been proved more accurate and practical for password guessing than traditional methods. However, a raw neural network model is not qualified for cross-sites attack since each data set has its own features. This paper proposes a general deep learning model for password guessing, called GENPass. GENPass can learn features from several data sets and ensure the output wordlist high accuracy in different data sets by using adversarial generation. The password generator of GENPass is PCFG+LSTM(PL), where LSTM is a kind of Recurrent Neural Network. We combine neural network with PCFG because we found people were used to set their passwords with meaningful strings. Compared with LSTM, PL increased the matching rate by 16%-30% in the cross-sites tests when learning from a single dataset. GENPass uses several PL models to learn datasets and generate passwords. The result shows that the matching rate of GENPass is 20% higher than that of simply mixing those datasets in the cross-sites test. © 2018 IEEE.",,"Authentication; Context free grammars; Deep learning; E-learning; Markov processes; Statistical tests; Brute-force attack; High-accuracy; Learning models; Neural network model; Password guessing; Probabilistic context free grammars; State-of-the-art approach; Statistical probability; Long short-term memory",,,,,"Yann, L., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), pp. 436-444; Silver, D., Huang, A., Maddison, C.J., Mastering the game of Go with deep neural networks and tree search (2016) Nature, 529 (7587), p. 484; Steube, J., https://hashcat.net/oclhashcat/; Peslyak, A., http://www.openwall.com/john/, John the Ripper; Ma, J., Yang, W., Luo, M., A study of probabilistic password models (2014) Security and Privacy. IEEE, pp. 689-704; Weir, M., Aggarwal, S., Medeiros, B.D., Password cracking using probabilistic context-free grammars (2009) Security and Privacy, 2009, IEEE Symposium On. IEEE, pp. 391-405; Lipton, Z.C., Berkowitz, J., Elkan, C., A critical review of recurrent neural networks for sequence learning (2015) Computer Science; Melicher, W., Ur, B., Segreti, S.M., Fast, lean and accurate: Modeling password guessability using neural networks (2016) Proceedings of USENIX Security; Hitaj, B., Gasti, P., Ateniese, G., (2017) PassGAN: A Deep Learning Approach for Password Guessing, , arXiv preprint arXiv:1709.00440; Yi, P., Zhu, T., Zhang, Q., Wu, Y., Pan, L., Puppet attack: A denial of service attack in advanced metering infrastructure network (2016) Journal of Network and Computer Applications, 59 (1), pp. 325-332; Zhu, T., Yu, M., (2006) A Dynamic Secure QoS Routing Protocol for Wireless Ad Hoc Networks. IEEE Sarnoff 2006, , Princeton, NJ, April; Yi, P., Zhu, T., Ma, J., Wu, Y., An intrusion prevention mechanism in mobile ad hoc networks (2013) Ad Hoc & Sensor Wireless Networks, 17 (3), pp. 269-292; Wang, X., Yi, P., Security framework for wireless communications in smart distribution grid (2011) IEEE Transactions on Smart Grid, 2 (4), pp. 809-818; Yi, P., Zhu, T., Zhang, Q., Wu, Y., Li, J., A denial of service attack in advanced metering infrastructure network (2014) ICC2014, , Australia; Yi, P., Zhu, T., Zhang, Q., Wu, Y., Li, J., Green firewall: An energy-efficient intrusion prevention mechanism in wireless sensor network (2012) GLOBECOM 2012, , USA, December; Li, Y., Zhu, T., Gait-based wi-fi signatures for privacy-preserving (2016) The 2016 ACM Symposium on InformAtion, Computer, and Communications Security, , Xi'an, China, April; Yi, P., Zhu, T., Liu, N., Wu, Y., Li, J., Cross-layer detection for black hole attack in wireless network (2012) Journal of Computational Information Systems, 8 (10), pp. 4101-4109; Zhu, T., Xiao, S., Yi, P., Towsley, D., Gong, W., A secure energy routing mechanism for sharing renewable energy in smart microgrid (2011) IEEE SmartGridComm2011, Brussels, Belgium, 17-20 October; Yi, P., Wu, Y., Liu, N., Wang, Z., Intrusion detection for wireless mesh networks using finite state machine (2010) China Communications, 7 (5), pp. 40-48; Yi, P., Wu, Y., Zou, F., Liu, N., A survey on security in wireless mesh networks (2010) IETE Technical Review, 27 (1), pp. 6-14; Zhu, T., Yu, M., (2006) A Secure Quality of Service Routing Protocol for Wireless Ad Hoc Networks. IEEE GLOBECOM 2006, , San Francisco, USA, November; Yi, P., Jiang, X., Wu, Y., Distributed intrusion detection for mobile ad hoc networks (2008) Journal of Systems Engineering and Electronics, 19 (3), pp. 851-859; Narayanan, A., Shmatikov, V., Fast dictionary attacks on passwords using time-space tradeoff (2005) ACM Conference on Computer and Communications Security, pp. 364-372; Li, Z., Han, W., Xu, W., A large-scale empirical analysis of Chinese web passwords (2014) Usenix Security, pp. 559-574; Wang, D., Zhang, Z., Wang, P., Targeted online password guessing: An underestimated threat (2016) ACM Sigsac Conference on Computer and Communications Security, pp. 1242-1254; Li, Y., Wang, H., Sun, K., A study of personal information in human-chosen passwords and its security implications (2016) Computer Communications, IEEE INFOCOM; Graves, A., Generating sequences with recurrent neural Networks (2013) Computer Science; Goodfellow, I.J., Pouget-Abadie, J., Mirza, M., Generative adversarial nets (2014) International Conference on Neural Information Processing Systems, pp. 2672-2680. , MIT Press; Xiang, Z., Zhao, J., LeCun, Y., Character-level convolutional networks for text classification (2015) Advances in Neural Information Processing Systems; Stuart, A., Ord, K., Kendall's advanced theory of statistics (1994) IDistribution Theory, Edward Arnold, 8 (7); MacKay, D.J.C., (2003) Information Theory, Inference, and Learning Algorithms, p. 34. , (First ed.). Cambridge University Press. p; https://www.Tensorflow.org; http://www.myspace.com/; http://www.phpbb.com/; http://www.rockyou.com/; http://www.linkedin.com/",,,"Cisco;et al.;Huawei;National Instruments;Qualcomm;Sprint","Institute of Electrical and Electronics Engineers Inc.","2018 IEEE International Conference on Communications, ICC 2018","20 May 2018 through 24 May 2018",,138282,15503607,9781538631805,,,"English","IEEE Int Conf Commun",Conference Paper,"Final","",Scopus,2-s2.0-85051437441
"Hu Y., Abuzainab N., Saad W.","57203372125;36182092800;57203259001;","Dynamic Psychological Game for Adversarial Internet of Battlefield Things Systems",2018,"IEEE International Conference on Communications","2018-May",,"8422729","","",,5,"10.1109/ICC.2018.8422729","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051432513&doi=10.1109%2fICC.2018.8422729&partnerID=40&md5=ea38f84cdeaa4457fd7e62d92ca70e1c","Wireless at VT, Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, United States","Hu, Y., Wireless at VT, Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, United States; Abuzainab, N., Wireless at VT, Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, United States; Saad, W., Wireless at VT, Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, United States","In this paper, a novel game-theoretic framework is introduced to analyze and enhance the security of adversarial Internet of Battlefield Things (IoBT) systems. In particular, a dynamic, psychological network interdiction game is formulated between a soldier and an attacker. In this game, the soldier seeks to find the optimal path to minimize the time needed to reach a destination, while maintaining a desired bit error rate (BER) performance by selectively communicating with certain IoBT devices. The attacker, on the other hand, seeks to find the optimal IoBT devices to attack, so as to maximize the BER of the soldier and hinder the soldier's progress. In this game, the soldier and attacker's first- order and second-order beliefs on each others' behavior are formulated to capture their psychological behavior. Using tools from psychological game theory, the soldier and attacker's intention to harm one another is captured in their utilities, based on their beliefs. A psychological forward induction-based solution is proposed to solve the dynamic game. This approach can find a psychological sequential equilibrium of the game, upon convergence. Simulation results show that, whenever the soldier explicitly intends to frustrate the attacker, the soldier's material payoff is increased by up to 15.6% compared to a traditional dynamic Bayesian game. © 2018 IEEE.",,"Bit error rate; Game theory; Bayesian game; Bit error rate (BER) performance; Forward induction; Game-theoretic; Network interdiction; Optimal paths; Second orders; Sequential equilibrium; Behavioral research",,,,,"Suri, N., Tortonesi, M., Michaelis, J., Budulas, P., Benincasa, G., Russell, S., Stefanelli, C., Winkler, R., Analyzing the applicability of internet of things to the battlefield environment (2016) Proc. of Military Communications and Information Systems (ICMCIS), , Brussels, Belgium, May; Park, T., Abuzainab, N., Saad, W., Learning how to communicate in the internet of things: Finite resources and heterogeneity (2016) IEEE Access, Special Issue on Optimization for Emerging Wireless Networks: IoT, 5G and Smart Grid Communication Networks, 4. , November; Dawy, Z., Saad, W., Ghosh, A., Andrews, J.G., Yaacoub, E., Toward massive machine type cellular communications (2017) IEEE Wireless Communications, 24, pp. 120-128. , February; Mozaffari, M., Saad, W., Bennis, M., Debbah, M., Mobile unmanned aerial vehicles (uavs) for energy-efficient internet of things communications (2017) IEEE Transactions on Wireless Communications, 16 (11), pp. 7574-7589. , November; Chen, M., Challita, U., Saad, W., Yin, C., Debbah, M., (2017) Machine Learning for Wireless Networks with Artificial Intelligence: A Tutorial on Neural Networks, , Oct; Chen, M., Mozaffari, M., Saad, W., Yin, C., Debbah, M., Hong, C.S., Caching in the sky: Proactive deployment of cache-enabled unmanned aerial vehicles for optimized quality-of-experience (2017) IEEE Journal on Selected Areas on Communications (JSAC), Special Issue on Human-In-The-Loop Mobile Networks, 35 (5), pp. 1046-1061. , May; Tortonesi, M., Morelli, A., Govoni, M., Michaelis, J., Suri, N., Stefanelli, C., Russell, S., Leveraging internet of things within the military network environment challenges and solutions (2016) Proc. of IEEE World Forum on Internet of Things (WF-IoT), , Reston, USA, Dec; Pratim, P.R., Towards an internet of things based architectural framework for defence (2015) Proc. of International Conference on Control, Instrumentation, Communication and Computational Technologies (ICCICCT), pp. 411-416. , Kumaracoil, India, Dec; Abuzainab, N., Saad, W., Dynamic connectivity game for adversarial internet of battlefield things systems (2018) IEEE Internet of Things Journal, , to appear; Sanjab, A., Saad, W., Başar, T., Prospect theory for enhanced cyberphysical security of drone delivery systems: A network interdiction game (2017) Proc. of IEEE International Conference on Communications (ICC), , Paris, France, Jul; Battigalli, P., Dufwenberg, M., Dynamic psychological games (2009) Journal of Economic Theory, pp. 1-35. , Jan; Battigalli, P., Dufwenberg, M., Smith, A., (2015) Frustration and Anger in Games, , CESifo Working Paper Series, Aug; Rossi, G., Tcheukam, A., Tembine, H., (2017) How Much Does Users' Psychology Matter in Engineering Mean-field-type Games; Powers, B., Smyrnakis, M., Tembine, H., (2017) Empathy in Bimatrix Games, , Aug; Simon, M.K., Alouini, M.S., (2005) Digital Communication over Fading Channels, 95; Wood, R.K., Deterministic network interdiction (1993) Mathematical and Computer Modelling, pp. 1-18; LTE System Toolbox, , https://www.mathworks.com/help/LTE/; Bianchi, G., Performance analysis of ieee 802. 11 distributed coordination function (2000) IEEE J. Select. Areas Commun, 18, pp. 535-547",,,"Cisco;et al.;Huawei;National Instruments;Qualcomm;Sprint","Institute of Electrical and Electronics Engineers Inc.","2018 IEEE International Conference on Communications, ICC 2018","20 May 2018 through 24 May 2018",,138282,15503607,9781538631805,,,"English","IEEE Int Conf Commun",Conference Paper,"Final","",Scopus,2-s2.0-85051432513
"Voelp M., Esteves-Verissimo P.","24465745800;7003870476;","Intrusion-tolerant autonomous driving",2018,"Proceedings - 2018 IEEE 21st International Symposium on Real-Time Computing, ISORC 2018",,,"8421157","130","133",,2,"10.1109/ISORC.2018.00026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051514266&doi=10.1109%2fISORC.2018.00026&partnerID=40&md5=6f8dff2265c2d7c95cf8bd00c28c7406","Critical and Extreme Security and Dependability Group (CritiX), SnT, University of Luxembourg, Luxembourg, L-2721, Luxembourg","Voelp, M., Critical and Extreme Security and Dependability Group (CritiX), SnT, University of Luxembourg, Luxembourg, L-2721, Luxembourg; Esteves-Verissimo, P., Critical and Extreme Security and Dependability Group (CritiX), SnT, University of Luxembourg, Luxembourg, L-2721, Luxembourg","Fully autonomous driving is one if not the killer application for the upcoming decade of real-Time systems. However, in the presence of increasingly sophisticated attacks by highly skilled and well equipped adversarial teams, autonomous driving must not only guarantee timeliness and hence safety. It must also consider the dependability of the software concerning these properties while the system is facing attacks. For distributed systems, fault-And-intrusion tolerance toolboxes already offer a few solutions to tolerate partial compromise of the system behind a majority of healthy components operating in consensus. In this paper, we present a concept of an intrusion-Tolerant architecture for autonomous driving. In such a scenario, predictability and recovery challenges arise from the inclusion of increasingly more complex software on increasingly less predictable hardware. We highlight how an intrusion tolerant design can help solve these issues by allowing timeliness to emerge from a majority of complex components being fast enough, often enough while preserving safety under attack through pre-computed fail safes. © 2018 IEEE.","Autonomous driving; Fault and intrusion tolerance; Real time systems","Interactive computer systems; Autonomous driving; Complex components; Complex software; Distributed systems; Fail safes; Intrusion tolerance; Intrusion tolerant; Killer-application; Real time systems",,,,,"End-To-end learning for self-driving cars (2016) NVIDIA, , arXiv 1604.07316; Chen, C., Seff, A., Kornhauser, A., Xiao, J., Deepdriving: Learning affordance for direct perception in autonomous driving (2015) Proceedings of 15th IEEE International Conference on Computer Vision (ICCV2015); Bechtel, M.G., McEllhiney, E., Yun, H., (2017) Deeppicar: A Low-cost Deep Neural Network-based Autonomous Car, , Kansas University, arXiv 1712.08644; Sabour, S., Frosst, N., Hinton, G.E., Dynamic routing between capsules (2017) 31st Conference on Neural Information Processing Systems (NIPS 2017), , Long Beach, CA, USA; Hayes, C., (2016) Driving Along at Full Speed for Autonomous Vehicles, , Jan; Lima, A., Rocha, F., Völp, M., Esteves-Verissimo, P., Towards safe and secure autonomous and cooperative vehicle ecosystems (2016) CPS-SPC, , ACM, Vienna, Austria Oct; Castro, M., Liskov, B., (1999) Practical Byzantine Fault Tolerance, pp. 173-186; Veronese, G.S., Correia, M., Bessani, A.N., Lung, L.C., Veríssimo, P., Efficient byzantine fault-Tolerance (2013) IEEE Trans. Computers, 62 (1), pp. 16-30; Sousa, P., Bessani, A.N., Correia, M., Neves, N.F., Verissimo, P., Highly available intrusion-Tolerant services with proactive-reactive recovery (2009) IEEE Trans. on Parallel & Distributed Systems, pp. 452-465; Borran, F., Schiper, A., A leader-free byzantine consensus algorithm (2010) Int. Conf. on Distributed Computing and Networking (ICDCN; Correia, M., Neves, N.F., Verissimo, P., Bft-To: Intrusion tolerance with less replicas (2013) The Computer Journal, 56 (6), pp. 693-715. , Jun; Verissimo, P., Casimiro, A., The timely computing base model and architecture (2002) IEEE Transactions on Computers, 51 (8), pp. 916-930. , Aug; Bak, S., Chivukula, D., Adekunle, O., Sun, M., Caccamo, M., Sha, L., The system-level simplex architecture for improved real-Time embedded system safety (2009) Real-Time and Embedded Technology and Applications Symposium (RTAS, pp. 99-107. , IEEE; Vivekanandan, P., Garcia, G., Yun, H., Keshmiri, S., A simplex architecture for intelligent and safe unmanned aerial vehicles (2016) International Conference on Embedded and Real-Time Computing Systems and Applications (RTCSA, , IEEE; Verissimo, P., Casimiro, A., Fetzer, C., The timely computing base: Timely actions in the presence of uncertain timeliness (2000) Proceedings of the 1st International Conference on Dependable Systems and Networks, New York, USA 2000, , June, Jun; Casimiro, A., Rufino, J., Marques, L., Calha, M., Verissimo, P., Applying architectural hybridization in networked embedded systems (2009) Proceedings of the 7th IFIP WG 10.2 International Workshop (SEUS 2009), Software Technologies for Embedded and Ubiquitous Systems, LNCS 5860, Sunggu Lee and Priya Narasimhan (Eds), , Newport Beach, CA, USA, November 2009 Nov; Almeida, C., Verissimo, P., Using light-weight groups to handle timing failures in quasi-synchronous systems (1998) Proceedings of the 19th IEEE Real-Time Systems Symposium, pp. 430-439. , Madrid, Spain December 2-4 1998; Pucella, R., Schneider, F.B., Independence from obfuscation: A semantic framework for diversity (2006) 19th IEEE Work. on Computer Security Foundations, pp. 230-241; Garcia, M., Bessani, A., Gashi, I., Neves, N., Obelheiro, R., Os diversity for intrusion tolerance: Myth or reality? (2011) 2011 IEEE/IFIP 41st International Conference on Dependable Systems Networks (DSN), pp. 383-394. , Jun",,,,"Institute of Electrical and Electronics Engineers Inc.","21st IEEE International Symposium on Real-Time Computing, ISORC 2018","29 May 2018 through 31 May 2018",,138284,,9781538658475,,,"English","Proc. - IEEE Int. Symp. Real-Time Comput., ISORC",Conference Paper,"Final","",Scopus,2-s2.0-85051514266
"Yifrach A., Mansour Y.","57203621067;7004528828;","Fair leader election for rational agents in asynchronous rings and networks",2018,"Proceedings of the Annual ACM Symposium on Principles of Distributed Computing",,,,"217","226",,7,"10.1145/3212734.3212767","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052462313&doi=10.1145%2f3212734.3212767&partnerID=40&md5=f9e97cff8098ac2215b45ae9c6d9f4c2","Tel-Aviv University, Tel-Aviv, Israel; Tel-Aviv University and Google Research, Tel-Aviv, Israel","Yifrach, A., Tel-Aviv University, Tel-Aviv, Israel; Mansour, Y., Tel-Aviv University and Google Research, Tel-Aviv, Israel","We study a game theoretic model where a coalition of processors might collude to bias the outcome of the protocol, where we assume that the processors always prefer any legitimate outcome over a non-legitimate one. We show that the problems of Fair Leader Election and Fair Coin Toss are equivalent, and focus on Fair Leader Election. Our main focus is on a directed asynchronous ring of n processors, where we investigate the protocol proposed by Abraham et al. [4] and studied in Afek et al. [5]. We show that in general the protocol is resilient only to sub-linear size coalitions. Specifically, we show that Ω(n log n) randomly located processors or Ω(3 n) adversarially located processors can force any outcome. We complement this by showing that the protocol is resilient to any adversarial coalition of size O(4 n). We propose a modification to the protocol, and show that it is resilient to every coalition of size Θ(n), by exhibiting both an attack and a resilience result. For every k ≥ 1, we define a family of graphs Gk that can be simulated by trees where each node in the tree simulates at most k processors. We show that for every graph in Gk, there is no fair leader election protocol that is resilient to coalitions of size k. Our result generalizes a previous result of Abraham et al. [4] that states that for every graph, there is no fair leader election protocol which is resilient to coalitions of size ⌈n 2 ⌉. © 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.","Asynchronous unidirectional ring; Fair coin toss; Fair leader election; Rational distributed agents","Distributed computer systems; Forestry; Game theory; Distributed agents; Fair coin toss; Game-theoretic model; Leader election; Leader election protocols; Rational agents; Unidirectional rings; Trees (mathematics)",,,,,"Abraham, I., Alvisi, L., Halpern, J.Y., Distributed computing meets game theory: Combining insights from two fields (2011) Acm Sigact News, 42 (2), pp. 69-76; Abraham, I., Dolev, D., Gonen, R., Halpern, J., Distributed computing meets game theory: Robust mechanisms for rational secret sharing and multiparty computation (2006) Proceedings of The Twenty-Fifth Annual ACM Symposium on Principles of Distributed Computing, pp. 53-62. , ACM; Abraham, I., Dolev, D., Halpern, J.Y., Lower bounds on implementing robust and resilient mediators (2008) Theory of Cryptography Conference, pp. 302-319. , Springer; Abraham, I., Dolev, D., Halpern, J.Y., Distributed protocols for leader election: A game-theoretic perspective (2013) International Symposium on Distributed Computing, pp. 61-75. , Springer; Afek, Y., Ginzberg, Y., Feibish, S.L., Sulamy, M., Distributed computing building blocks for rational agents (2014) Proceedings of The 2014 ACM Symposium on Principles of Distributed Computing, pp. 406-415. , ACM; Afek, Y., Rafaeli, S., Sulamy, M., (2017) Cheating by Duplication: Equilibrium Requires Global Knowledge, , arXiv preprint; Aiyer, A.S., Alvisi, L., Clement, A., Dahlin, M., Martin, J.-P., Porth, C., Bar fault tolerance for cooperative services (2005) ACM SIGOPS Operating Systems Review, 39, pp. 45-58. , ACM; Ajtai, M., Linial, N., The influence of large coalitions (1993) Combinatorica, 13 (2), pp. 129-145; Alon, N., Naor, M., Coin-flipping games immune against linear-sized coalitions (1993) SIAM Journal on Computing, 22 (2), pp. 403-417; Ben-Or, M., Linial, N., Collective coin flipping (1990) Randomness and Computation, 5, pp. 91-115; Boppana, R.B., Narayanan, B.O., Perfect-information leader election with optimal resilience (2000) SIAM Journal on Computing, 29 (4), pp. 1304-1320; Chang, E., Roberts, R., An improved algorithm for decentralized extrema-finding in circular configurations of processes (1979) Communications of The ACM, 22 (5), pp. 281-283; Clementi, A., Gualà, L., Proietti, G., Scornavacca, G., Rational fair consensus in the gossip model (2017) Parallel and Distributed Processing Symposium (IPDPS), 2017 IEEE International, pp. 163-171. , IEEE; Correia, M., Veronese, G.S., Neves, N.F., Verissimo, P., Byzantine consensus in asynchronous message-passing systems: A survey (2011) International Journal of Critical Computer-Based Systems, 2 (2), pp. 141-161; Dani, V., Movahedi, M., Rodriguez, Y., Saia, J., Scalable rational secret sharing (2011) Proceedings of The 30th Annual ACM SIGACT-SIGOPS Symposium on Principles of Distributed Computing, pp. 187-196. , ACM; Dolev, D., Klawe, M., Rodeh, M., An o (n log n) unidirectional distributed algorithm for extrema finding in a circle (1982) Journal of Algorithms, 3 (3), pp. 245-260; Fuchsbauer, G., Katz, J., Naccache, D., Efficient rational secret sharing in standard communication networks (2010) Theory of Cryptography Conference, pp. 419-436. , Springer; Dov Gordon, S., Katz, J., Rational secret sharing, revisited (2006) International Conference on Security and Cryptography for Networks, pp. 229-241. , Springer; Halpern, J., Teague, V., Rational secret sharing and multiparty computation (2004) Proceedings of The Thirty-Sixth Annual ACM Symposium on Theory of Computing, pp. 623-632. , ACM; Kol, G., Naor, M., Games for exchanging information (2008) Proceedings of The Fortieth Annual ACM Symposium on Theory of Computing, pp. 423-432. , ACM; Lysyanskaya, A., Triandopoulos, N., Rationality and adversarial behavior in multi-party computation (2006) Annual International Cryptology Conference, pp. 180-197. , Springer; Moscibroda, T., Schmid, S., Wattenhofer, R., When selfish meets evil: Byzantine players in a virus inoculation game (2006) Proceedings of The Twenty-Fifth Annual ACM Symposium on Principles of Distributed Computing, pp. 35-44. , ACM; Peleg, D., Distributed computing: A locality-sensitive approach (2000) SIAM; Peterson, G.L., An o (n log n) unidirectional algorithm for the circular extrema problem (1982) ACM Transactions on Programming Languages and Systems (TOPLAS), 4 (4), pp. 758-762; Russell, A., Zuckerman, D., Perfect information leader election in log* n+ o (1) rounds (2001) Journal of Computer and System Sciences, 63 (4), pp. 612-626; Saks, M., A robust noncryptographic protocol for collective coin flipping (1989) SIAM Journal on Discrete Mathematics, 2 (2), pp. 240-244; Sari, A., Akkaya, M., Fault tolerance mechanisms in distributed systems (2015) International Journal of Communications, Network and System Sciences, 8 (12), p. 471; Yifrach, A., Mansour, Y., (2018) Fair Leader Election for Rational Agents in Asynchronous Rings and Networks, , arXiv preprint; Zuckerman, D., Randomness-optimal sampling, extractors, and constructive leader election (1996) Proceedings of The Twenty-Eighth Annual ACM Symposium on Theory of Computing, pp. 286-295. , ACM",,,"ACM SIGACT;ACM SIGOPS","Association for Computing Machinery","37th ACM SIGACT-SIGOPS Symposium on Principles of Distributed Computing, PODC 2018","23 July 2018 through 27 July 2018",,138527,,9781450357951,85LRA,,"English","Proc Annu ACM Symp Princ Distrib Comput",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85052462313
"Smith J.M., Schuchard M.","57189687547;36669171700;","Routing Around Congestion: Defeating DDoS Attacks and Adverse Network Conditions via Reactive BGP Routing",2018,"Proceedings - IEEE Symposium on Security and Privacy","2018-May",,"8418626","599","617",,31,"10.1109/SP.2018.00032","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051049050&doi=10.1109%2fSP.2018.00032&partnerID=40&md5=6701e8a94670596b4a03897d6847d0bf","VolSec: UT Computer Security Lab, University of Tennessee, Knoxville, United States","Smith, J.M., VolSec: UT Computer Security Lab, University of Tennessee, Knoxville, United States; Schuchard, M., VolSec: UT Computer Security Lab, University of Tennessee, Knoxville, United States","In this paper, we present Nyx, the first system to both effectively mitigate modern Distributed Denial of Service (DDoS) attacks regardless of the amount of traffic under adversarial control and function without outside cooperation or an Internet redesign. Nyx approaches the problem of DDoS mitigation as a routing problem rather than a filtering problem. This conceptual shift allows Nyx to avoid many of the common shortcomings of existing academic and commercial DDoS mitigation systems. By leveraging how Autonomous Systems (ASes) handle route advertisement in the existing Border Gateway Protocol (BGP), Nyx allows the deploying AS to achieve isolation of traffic from a critical upstream AS off of attacked links and onto alternative, uncongested, paths. This isolation removes the need for filtering or de-prioritizing attack traffic. Nyx controls outbound paths through normal BGP path selection, while return paths from critical ASes are controlled through the use of specific techniques we developed using existing traffic engineering principles and require no outside coordination. Using our own realistic Internet-scale simulator, we find that in more than 98% of cases our system can successfully route critical traf?c around network segments under transit-link DDoS attacks; a new form of DDoS attack where the attack traf?c never reaches the victim AS, thus invaliding defensive filtering, throttling, or prioritization strategies. More significantly, in over 95% of those cases, the alternate path provides complete congestion relief from transit-link DDoS. Nyx additionally provides complete congestion relief in over 75% of cases when the deployer is being directly attacked. © 2018 IEEE.","BGP; DDoS; FRRP; internet; routing","Border Gateway Protocol; Gateways (computer networks); Internet; Multimedia services; Network security; Routing protocols; Telecommunication traffic; Autonomous systems; DDoS; Distributed denial of service attack; Filtering problems; FRRP; Network condition; routing; Traffic Engineering; Denial-of-service attack",,,,,"(2016) Mirai: What You Need to Know about the Botnet behind Recent Major DDoS Attacks, , https://tiny.utk.edu/orVeO, Symantec, accessed: 17 January 2017; (2016) Mirai Iot Botnet Blamed for Smashing Liberia off the Internet, , https://www.theregister.co.uk/2016/11/04/liberiaddos; Kang, M.S., Lee, S.B., Gligor, V.D., The crossfire attack (2013) IEEE Symposium on Security and Privacy; Studer, A., Perrig, A., The coremelt attack (2009) ESORICS; State of the Internet Security Report for q3 2017, , https://www.akamai.com/us/en/about/our-thinking/state-of-the-internet-report/global-state-of-the-internet-security-ddos-attack-reports.jsp, Akamai; Siris, V.A., Stavrakis, I., Provider-based deterministic packet marking against distributed DoS attacks (2007) J. Network and Computer Applications; Belenky, A., Ansari, N., On deterministic packet marking (2007) Computer Networks; Xiang, Y., Zhou, W., Guo, M., Flexible deterministic packet marking-An IP traceback system to find the real source of attacks (2009) IEEE Trans. Parallel Distrib. Syst.; Muthuprasanna, M., Manimaran, G., Distributed divide-and-conquer techniques for effective DDoS attack defenses (2008) ICDCS; Ma, M., Tabu marking scheme for IP traceback (2005) Parallel and Distributed Processing Symposium; Xiang, Y., Zhou, W., Protecting information infrastructure from ddos attacks by madf (2006) International Journal of High; Biggio, B., Machine learning under attack: Vulnerability exploitation and security measures (2016) Proceedings of the 4th ACM Workshop on Information Hiding and Multimedia Security, Ser. IH&38;MMSec '16, pp. 1-2. , http://doi.acm.org/10.1145/2909827.2930784, New York, NY, USA: ACM; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, Ser. Asia CCS '17, pp. 506-519. , http://doi.acm.org/10.1145/3052973.3053009, New York, NY, USA: ACM; Fayaz, S.K., Tobioka, Y., Sekar, V., Bailey, M., Bohatei: Flexible and elastic ddos defense (2015) Usenix Security, pp. 817-832; Zhang, X., Hsiao, H.-C., Hasker, G., Chan, H., Perrig, A., Andersen, D.G., SCION-scalability, control, and isolation on next-generation networks (2011) IEEE Symposium on Security and Privacy; Basescu, C., Reischuk, R.M., Szalachowski, P., Perrig, A., Zhang, Y., Hsiao, H.-C., Kubota, A., Urakawa, J., SIBRA: Scalable internet bandwidth reservation architecture (2016) Proceedings of Symposium on Network and Distributed System Security (NDSS), , http://www.scion-architecture.net/pdf/2016-SIBRA.pdf, Feb; Shin, S., Gu, G., Reddy, N., Lee, C.P., A large-scale empirical study of conficker (2012) IEEE Transactions on Information Forensics and Security, 7 (2), pp. 676-690; Khalimonenko, A., Kupreev, O., Kaspersky Labs q1 2017 Ddos Report, , https://securelist.com/ddos-attacks-in-q1-2017/78285; (2016) Dyn Analysis Summary of Friday October 21 Attack, , https://dyn.com/blog/dyn-analysis-summary-of-friday-october-21-attack; (2016) Dyn Analysis Summary of Friday October 21 Attack, , https://nakedsecurity.sophos.com/2016/09/29/why-a-massive-ddos-attack-on-a-blogger-has-internet-experts-worried; Hawkinson, T.B.J., (1996) Guidelines for Creation, Selection, and Registration of An Autonomous System (As), , https://tools.ietf.org/html/rfc1930, United States; Rekhter, Y., Li, T., (1995) A Border Gateway Protocol 4 (bgp-4), , United States; Huston, G., (2017) Bgp More Specifics: Routing Vandalism or Useful?, , https://blog.apnic.net/2017/06/26/bgp-specifics-routing-vandalism-useful; (2017) CAIDA AS Relationship Dataset, , http://www.caida.org/data/active/as-relationships/index.xml; Lepinski, M., Kent, S., (2012) An Infrastructure to Support Secure Internet Routing, , https://tools.ietf.org/html/rfc6480, United States; Schuchard, M., Geddes, J., Thompson, C., Hopper, N., Routing around decoys (2012) Proceedings of the 2012 ACM Conference on Computer and Communications Security, Ser. CCS '12, pp. 85-96. , http://doi.acm.org/10.1145/2382196.2382209, New York, NY, USA: ACM; Schuchard, M., Mohaisen, A., Foo Kune, D., Hopper, N., Kim, Y., Vasserman, E.Y., Losing control of the internet (2010) Proceedings of the 17th ACM Conference on Computer and Communications Security, , New York, New York, USA, ACM Press; Gill, P., Schapira, M., Goldberg, S., Let the market drive deployment: A strategy for transitioning to bgp security (2011) ACM SIGCOMM Computer Communication Review, 41 (4), pp. 14-25. , ACM; Labovitz, C., Iekel-Johnson, S., McPherson, D., Oberheide, J., Jahanian, F., Internet inter-domain traffic (2011) ACM SIGCOMM Computer Communication Review, 41 (4), pp. 75-86; World Bank Global Indicators, , http://data.worldbank.org/indicator; Peeringdb, , https://www.peeringdb.com; Global Internet Phenomena Report, , https://www.sandvine.com/trends/global-internet-phenomena; Iana Autonomous System (As) Numbers, , https://www.iana.org/assignments/as-numbers/as-numbers.xhtml; Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Duchesnay, E., Scikit-learn: Machine learning in python (2011) Journal of Machine Learning Research, 12, pp. 2825-2830; (2017) Mirai Scanner, , http://data.netlab.360.com/mirai-scanner/, Netlab360; Thomas, M., Mohaisen, A., Kindred domains: Detecting and clustering botnet domains using dns traffic (2014) Proceedings of the 23rd International Conference on World Wide Web, Ser. WWW '14 Companion, pp. 707-712. , http://doi.acm.org/10.1145/2567948.2579359, New York, NY, USA, ACM; RouteViews Dataset, , http://www.routeviews.org/, RouteViews; Mirkovic, J., Reiher, P., A taxonomy of DDoS attack and DDoS defense mechanisms (2004) ACM SIGCOMM Computer Communication; Yau, D.K.Y., Lui, J.C.S., Liang, F., Yam, Y., Defending against distributed denial-of-service attacks with max-min fair server-centric router throttles (2005) IEEE/ACM Trans. Netw.; Liu, X., Yang, X., Lu, Y., (2008) StopIt: Mitigating DoS Flooding Attacks from Multi-million Botnets; Mahajan, R., Bellovin, S.M., Floyd, S., Ioannidis, J., Paxson, V., Shenker, S., Controlling high bandwidth aggregates in the network (2002) Computer Communication Review; Ioannidis, J., Bellovin, S.M., Implementing pushback-router-based defense against DDoS attacks (2002) NDSS; Dixon, C., Anderson, T.E., Krishnamurthy, A., Phalanx-withstanding multimillion-node botnets (2008) NSDI; Chou, J.C.Y., Lin, B., Sen, S., Spatscheck, O., Proactive surge protection: A defense mechanism for bandwidth-based attacks (2009) IEEE/ACM Transactions on Networking, 17 (6), pp. 1711-1723; Von Ahn, L., Blum, M., Langford, J., Telling humans and computers apart automatically (2004) Communications of the ACM, 47 (2), pp. 56-60; Spyridopoulos, T., Karanikas, G., Tryfonas, T., Oikonomou, G., A game theoretic defence framework against DoS/DDoS cyber attacks (2013) Computers & Security; Bedi, H.S., Roy, S., Shiva, S., Game theory-based defense mechanisms against DDoS attacks on TCP/TCP-friendly flows (2011) Cyber Security (CICS); Zhou, W., Jia, W., Wen, S., Xiang, Y., Zhou, W., Detection and defense of application-layer DDoS attacks in backbone web traffic (2014) Future Generation Computer, 38, pp. 36-46. , Sep; Zhao, D., Traore, I., Sayed, B., Lu, W., Saad, S., Botnet detection based on traffic behavior analysis and flow intervals (2013) Computers & ⋯, 39, pp. 2-16; Senthilmahesh, P., Hemalatha, S., Rodrigues, P., Shanthakumar, A., (2013) Ddos Attacks Defense System Using Information Metrics; (2014) Why Microsoft and Sony Couldnt Stop Lizard Squad Attack Despite Warnings, , https://tiny.utk.edu/PutqC, IBTimes, accessed: 17 January 2017; Open Datapath, , https://www.opennetworking.org/projects/open-datapath, ONF",,,"","Institute of Electrical and Electronics Engineers Inc.","39th IEEE Symposium on Security and Privacy, SP 2018","21 May 2018 through 23 May 2018",,138182,10816011,9781538643525,,,"English","Proc. IEEE Symp. Secur. Privacy",Conference Paper,"Final","",Scopus,2-s2.0-85051049050
"Jagielski M., Oprea A., Biggio B., Liu C., Nita-Rotaru C., Li B.","57203204598;57206038548;23090165100;55873082700;6507281794;57188689924;","Manipulating Machine Learning: Poisoning Attacks and Countermeasures for Regression Learning",2018,"Proceedings - IEEE Symposium on Security and Privacy","2018-May",,"8418594","19","35",,189,"10.1109/SP.2018.00057","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050640069&doi=10.1109%2fSP.2018.00057&partnerID=40&md5=e6aec8e90a3b60d4d7b23f566b331811","Northeastern University, Boston, MA, United States; Univ. Cagliary, Cagliary, Italy; UC Berkeley, Berkeley, CA, United States","Jagielski, M., Northeastern University, Boston, MA, United States; Oprea, A., Northeastern University, Boston, MA, United States; Biggio, B., Univ. Cagliary, Cagliary, Italy; Liu, C., UC Berkeley, Berkeley, CA, United States; Nita-Rotaru, C., Northeastern University, Boston, MA, United States; Li, B., UC Berkeley, Berkeley, CA, United States","As machine learning becomes widely used for automated decisions, attackers have strong incentives to manipulate the results and models generated by machine learning algorithms. In this paper, we perform the first systematic study of poisoning attacks and their countermeasures for linear regression models. In poisoning attacks, attackers deliberately influence the training data to manipulate the results of a predictive model. We propose a theoretically-grounded optimization framework specifically designed for linear regression and demonstrate its effectiveness on a range of datasets and models. We also introduce a fast statistical attack that requires limited knowledge of the training process. Finally, we design a new principled defense method that is highly resilient against all poisoning attacks. We provide formal guarantees about its convergence and an upper bound on the effect of poisoning attacks when the defense is deployed. We evaluate extensively our attacks and defenses on three realistic datasets from health care, loan assessment, and real estate domains. © 2018 IEEE.","adversarial machine learning; poisoning attacks; robust linear regression","Artificial intelligence; Learning systems; Linear regression; Network security; Highly resilient; Linear regression models; Optimization framework; Poisoning attacks; Predictive modeling; Robust linear regression; Statistical attacks; Systematic study; Learning algorithms",,,,,"Alfeld, S., Zhu, X., Barford, P., Data poisoning attacks against autoregressive models (2016) AAAI; Barreno, M., Nelson, B., Sears, R., Joseph, A.D., Tygar, J.D., Can machine learning be secure? (2006) Proceedings of the 2006 ACM Symposium on Information, Computer and Communications Security, pp. 16-25. , ACM; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Srndić, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Machine Learning and Knowledge Discovery in Databases (ECML PKDD), Part III of LNCS, 8190, pp. 387-402. , H. Blockeel, K. Kersting, S. Nijssen, and F. Zelezńy, editors, Springer Berlin Heidelberg; Biggio, B., Fumera, G., Roli, F., Security evaluation of pattern classifiers under attack (2014) IEEE Transactions on Knowledge and Data Engineering, 26 (4), pp. 984-996. , April; Biggio, B., Nelson, B., Laskov, P., Poisoning attacks against support vector machines (2012) ICML; Biggio, B., Roli, F., Wild patterns: Ten years after the rise of adversarial machine learning (2018) ArXiv E-prints; Candes, E.J., Li, X., Ma, Y., Wright, J., Robust principal component analysis (2011) Journal of the ACM, 58 (3); Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Proc. IEEE Security and Privacy Symposium, S&P; Chen, X., Liu, C., Li, B., Lu, K., Song, D., Targeted backdoor attacks on deep learning systems using data poisoning (2017) ArXiv E-prints, , 1712.05526; Chen, Y., Caramanis, C., Mannor, S., (2013) Robust High Dimensional Sparse Regression and Matching Pursuit; Chen, Y., Caramanis, C., Mannor, S., Robust sparse regression under adversarial corruption (2013) Proc. International Conference on Machine Learning, ICML; Cretu-Ciocarlie, G.F., Stavrou, A., Locasto, M.E., Stolfo, S.J., Keromytis, A.D., Casting out demons: Sanitizing training data for anomaly sensors (2008) Proc. IEEE Security and Privacy Symposium, S&P; Csiszar, I., Tusnady, G., Information geometry and alternating minimization procedures (1984) Statistics and Decisions, 1, pp. 205-237; Dalvi, N., Domingos, P., Sanghai, S., Verma, D., Adversarial classification (2004) Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 99-108. , ACM; Faggella, D., (2016) Machine Learning Healthcare applications-2017 and beyond, , https://www.techemergence.com/machine-learning-healthcare-applications/; Feng, J., Xu, H., Mannor, S., Yan, S., Robust logistic regression and classification (2014) Advances in Neural Information Processing Systems, NIPS; Fischler, M.A., Bolles, R.C., Random sample consensus: A paradigm for model fitting with applications to image analysis and automated cartography (1981) Communications of the ACM, 24 (6), pp. 381-395; Fredrikson, M., Jha, S., Ristenpart, T., Model inversion attacks that exploit confidence information and basic countermeasures (2015) Proceedings of the 22nd ACM Conference on Computer and Communications Security, CCS; Fredrikson, M., Lantz, E., Jha, S., Lin, S., Page, D., Ristenpart, T., Privacy in pharmacogenetics: An end-to-end case study of personalized warfarin dosing (2014) USENIX Security, pp. 17-32; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Gu, T., Dolan-Gavitt, B., Garg, S., Badnets: Identifying vulnerabilities in the machine learning model supply chain (2017) NIPS Workshop on Machine Learning and Computer Security, , 1708.06733; Hao, S., Kantchelian, A., Miller, B., Paxson, V., Feamster, N., PREDATOR: Proactive recognition and elimination of domain abuse at time-ofregistration (2016) Proceedings of the 23rd ACM Conference on Computer and Communications Security, CCS; Harsha, P., (2016) Senate Committee Examines the ""dawn of Artificial Intelligence"", , http://cra.org/govaffairs/blog/2016/11/senate-committee-examines-dawn-artificial-intelligence/, Computing Research Policy Blog; Hastie, T., Tibshirani, R., Friedman, J., (2009) The Elements of Statistical Learning: Data Mining, Inference, and Prediction, , Springer; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I., Tygar, J., Adversarial machine learning (2011) Proceedings of the 4th ACM Workshop on Security and Artificial Intelligence, pp. 43-58. , ACM; Huber, P.J., Robust estimation of a location parameter (1964) Annals of Statistics, 53 (1), pp. 73-101; Huber, P.J., (2011) Robust Statistics, , Springer; House Prices: Advanced Regression Techniques, , https://www.kaggle.com/c/house-prices-advanced-regression-techniques, Kaggle. accessed 8 May 2017; Kan, W., (2013) Lending Club Loan Data, , https://www.kaggle.com/wendykan/lending-club-loan-data, accessed 8 May 2017; Kearns, M., Li, M., Learning in the presence of malicious errors (1993) SIAM Journal on Computing, 22 (4), pp. 807-837; Kloft, M., Laskov, P., Security analysis of online centroid anomaly detection (2012) The Journal of Machine Learning Research, 13 (1), pp. 3681-3724; Li, B., Wang, Y., Singh, A., Vorobeychik, Y., Data poisoning attacks on factorization-based collaborative filtering (2016) Advances in Neural Information Processing Systems, pp. 1885-1893; Liu, C., Li, B., Vorobeychik, Y., Oprea, A., Robust linear regression against training data poisoning (2017) Proc. Workshop on Artificial Intelligence and Security, AISec; Lowd, D., Meek, C., Adversarial learning (2005) Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining, pp. 641-647. , ACM; Mei, S., Zhu, X., The security of latent dirichlet allocation (2015) AISTATS; Mei, S., Zhu, X., Using machine teaching to identify optimal training-set attacks on machine learners (2015) 29th AAAI Conf. Artificial Intelligence (AAAI '15); Mozaffari Kermani, M., Sur-Kolay, S., Raghunathan, A., Jha, N.K., Systematic poisoning attacks on and defenses for machine learning in healthcare (2014) IEEE Journal of Biomedical and Health Informatics, 19 (6), pp. 1893-1905; Muñoz-González, L., Biggio, B., Demontis, A., Paudice, A., Wongrassamee, V., Lupu, E.C., Roli, F., Towards poisoning of deep learning algorithms with back-gradient optimization (2017) 10th ACM Workshop on Artificial Intelligence and Security, AISec '17, pp. 27-38. , B. M. Thuraisingham, B. Biggio, D. M. Freeman, B. Miller, and A. Sinha, editors, New York, NY, USA. ACM; Nelson, B., Barreno, M., Chi, F.J., Joseph, A.D., Rubinstein, B.I., Saini, U., Sutton, C., Xia, K., Exploiting machine learning to subvert your spam filter (2008) Proc. First USENIX Workshop on Large-Scale Exploits and Emergent Threats, LEET; Newell, A., Potharaju, R., Xiang, L., Nita-Rotaru, C., On the practicality of integrity attacks on document-level sentiment analysis (2014) Proc. Workshop on Artificial Intelligence and Security, AISec; Newsome, J., Karp, B., Song, D., Paragraph: Thwarting signature learning by training maliciously (2006) Recent Advances in Intrusion Detection, pp. 81-105. , Springer; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2017) Proc. IEEE European Security and Privacy Symposium, Euro S&P; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Proc. IEEE Security and Privacy Symposium, S&P; Perdisci, R., Dagon, D., Lee, W., Fogla, P., Sharif, M., Misleading worm signature generators using deliberate noise injection (2006) Proc. IEEE Security and Privacy Symposium, S&P; (2014) PharmGKB. Downloads-IWPC Data, , https://www.pharmgkb.org/downloads/, accessed 8 May 2017; Rubinstein, B.I., Nelson, B., Huang, L., Joseph, A.D., Hon Lau, S., Rao, S., Taft, N., Tygar, J.D., ANTIDOTE: Understanding and defending against poisoning of anomaly detectors (2009) Proc. 9th Internet Measurement Conference, IMC; Shokri, R., Stronati, M., Song, C., Shmatikov, V., Membership inference attacks against machine learning models (2017) Proc. IEEE Security and Privacy Symposium, S&P; Srndic, N., Laskov, P., (2009) Mimicus-Contagio Dataset, , https://github.com/srndic/mimicus, accessed 8 May 2017; Srndic, N., Laskov, P., Practical evasion of a learning-based classifier: A case study (2014) Proc. IEEE Security and Privacy Symposium, S&P; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2014) Intriguing Properties of Neural Networks; Tyler, D.E., Robust statistics: Theory and methods (2008) Journal of the American Statistical Association, 103 (482), pp. 888-889; Venkataraman, S., Blum, A., Song, D., Limits of learning-based signature generation with adversaries (2008) Network and Distributed System Security Symposium, NDSS, , Internet Society; Wang, G., Wang, T., Zheng, H., Zhao, B.Y., Man vs. Machine: Practical adversarial detection of malicious crowdsourcing workers (2014) 23rd USENIX Security Symposium (USENIX Security 14), , San Diego, CA. USENIX Association; Xiao, H., Biggio, B., Brown, G., Fumera, G., Eckert, C., Roli, F., Is feature selection secure against training data poisoning? (2015) Proc. 32nd International Conference on Machine Learning of ICML, 37, pp. 1689-1698; Xu, H., Caramanis, C., Mannor, S., Robust regression and Lasso (2010) IEEE Transactions on Information Theory, 56 (7), pp. 3561-3574",,,"","Institute of Electrical and Electronics Engineers Inc.","39th IEEE Symposium on Security and Privacy, SP 2018","21 May 2018 through 23 May 2018",,138182,10816011,9781538643525,,,"English","Proc. IEEE Symp. Secur. Privacy",Conference Paper,"Final","All Open Access, Bronze, Green",Scopus,2-s2.0-85050640069
"Hutson M.","57200192492;","Hackers easily fool artificial intelligences",2018,"Science","361","6399",,"215","",,6,"10.1126/science.361.6399.215","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050528561&doi=10.1126%2fscience.361.6399.215&partnerID=40&md5=8b6b5604683a201a688e787dfead4ca2","New York City, United States","Hutson, M., New York City, United States","Last week, at the International Conference on Machine Learning (ICML) in Stockholm, a group of researchers described a turtle they had 3D printed. Most people would say it looks just like a turtle, but an artificial intelligence (AI) algorithm that can normally recognize turtles saw it differently. Most of the time, it thought the turtle was a rifle. Similarly, it saw a 3D-printed baseball as an espresso. These are examples of ""adversarial attacks""—subtly altered images, objects, or sounds that fool AIs without setting off human alarm bells. Impressive advances in AI—particularly machine learning algorithms that can recognize sounds or objects after digesting vast training data sets—have spurred the growth of living room voice assistants and autonomous cars. But these AIs are surprisingly vulnerable to being spoofed. At the ICML meeting, adversarial attacks were a hot subject, with researchers reporting novel ways to trick AIs as well as new ways to defend them. Somewhat ominously, one of the conference's two best paper awards went to a study suggesting protected AIs aren't as secure as their developers might think. © 2017 The Authors, some rights reserved.",,"algorithm; artificial intelligence; data set; image analysis; machine learning; three-dimensional modeling; article; artificial intelligence; awards and prizes; baseball; human; human experiment; machine learning; nonhuman; scientist; sound; thinking; turtle; voice; Stockholm [Sweden]; Sweden; Testudines",,,,,,"Hutson, M.United States",,,"American Association for the Advancement of Science",,,,,00368075,,SCIEA,"30026208","English","Sci.",Article,"Final","",Scopus,2-s2.0-85050528561
"Das N., Shanbhogue M., Chen S.-T., Hohman F., Li S., Chen L., Kounavis M.E., Chau D.H.","57203386129;55436926400;55377234300;57194277192;57203390132;55616439900;6602570549;14035167900;","Shield: Fast, practical defense and vaccination for deep learning using JPEG compression",2018,"Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",,,,"196","204",,55,"10.1145/3219819.3219910","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051548544&doi=10.1145%2f3219819.3219910&partnerID=40&md5=4e9f6d612706f448135c08bebf61f8af","Georgia Institute of Technology, Atlanta, GA, United States; Intel Corporation, Hillsboro, OR, United States","Das, N., Georgia Institute of Technology, Atlanta, GA, United States; Shanbhogue, M., Georgia Institute of Technology, Atlanta, GA, United States; Chen, S.-T., Georgia Institute of Technology, Atlanta, GA, United States; Hohman, F., Georgia Institute of Technology, Atlanta, GA, United States; Li, S., Georgia Institute of Technology, Atlanta, GA, United States; Chen, L., Intel Corporation, Hillsboro, OR, United States; Kounavis, M.E., Intel Corporation, Hillsboro, OR, United States; Chau, D.H., Georgia Institute of Technology, Atlanta, GA, United States","The rapidly growing body of research in adversarial machine learning has demonstrated that deep neural networks (DNNs) are highly vulnerable to adversarially generated images. This underscores the urgent need for practical defense techniques that can be readily deployed to combat attacks in real-time. Observing that many attack strategies aim to perturb image pixels in ways that are visually imperceptible, we place JPEG compression at the core of our proposed Shield defense framework, utilizing its capability to effectively “compress away” such pixel manipulation. To immunize a DNN model from artifacts introduced by compression, Shield “vaccinates” the model by retraining it with compressed images, where different compression levels are applied to generate multiple vaccinated models that are ultimately used together in an ensemble defense. On top of that, Shield adds an additional layer of protection by employing randomization at test time that compresses different regions of an image using random compression levels, making it harder for an adversary to estimate the transformation performed. This novel combination of vaccination, ensembling, and randomization makes Shield a fortified multi-pronged defense. We conducted extensive, large-scale experiments using the ImageNet dataset, and show that our approaches eliminate up to 98% of gray-box attacks delivered by strong adversarial techniques such as Carlini-Wagner's L2 attack and DeepFool. Our approaches are fast and work without requiring knowledge about the model. © 2018 Copyright held by the owner/author(s). Publication rights licensed to the Association for Computing Machinery.","Adversarial machine learning; Deep learning; Ensemble defense; JPEG compression; Machine learning security","Artificial intelligence; Data mining; Deep learning; Deep neural networks; Network security; Pixels; Random processes; Vaccines; Attack strategies; Combat attacks; Compressed images; Defense techniques; Ensemble defense; Growing bodies; JPEG compression; Large scale experiments; Image compression",,,,,"Athalye, A., Carlini, N., Wagner, D., (2018) Obfuscated Gradients Give A False Sense of Security: Circumventing Defenses to Adversarial Examples, , arXiv preprint 2018; Athalye, A., Sutskever, I., (2017) Synthesizing Robust Adversarial Examples, , arXiv preprint 2017; Bhagoji, A.N., Cullina, D., Mittal, P., (2017) Dimensionality Reduction as A Defense Against Evasion Attacks on Machine Learning Classifiers, , arXiv preprint 2017; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium on, pp. 39-57. , IEEE; Chen, S.-T., Han, Y., Chau, D.H., Gates, C., Hart, M., Roundy, K.A., Predicting Cyber Threats with Virtual Security Products (2017) Proceedings of The 33rd Annual Computer Security Applications Conference, pp. 189-199. , ACM; Das, N., Shanbhogue, M., Chen, S.-T., Hohman, F., Chen, L., Kounavis, M.E., Chau, D.H., (2017) Keeping The Bad Guys Out: Protecting and Vaccinating Deep Learning with Jpeg Compression, , arXiv preprint 2017; Dziugaite, G.K., Ghahramani, Z., Roy, D.M., (2016) A Study of The Effect of JPG Compression on Adversarial Images, , arXiv preprint 2016; Evtimov, I., Eykholt, K., Fernandes, E., Kohno, T., Li, B., Prakash, A., Rahmati, A., Song, D., (2017) Robust Physical-World Attacks on Machine Learning Models, , arXiv preprint 2017; Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Song, D., Kohno, T., Rahmati, A., Tramer, F., (2017) Note on Attacking Object Detectors with Adversarial Stickers, , arXiv preprint 2017; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts, , arXiv preprint 2017; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2014) ICLR; Grosse, K., Papernot, N., Manoharan, P., Backes, M., McDaniel, P., (2016) Adversarial Perturbations Against Deep Neural Networks for Malware Classification, , arXiv preprint 2016; Gu, S., Rigazio, L., (2014) Towards Deep Neural Network Architectures Robust to Adversarial Examples, , arXiv preprint 2014; Guo, C., Rana, M., Cissé, M., Van Der Maaten, L., Countering Adversarial Images using Input Transformations (2018) International Conference on Learning Representations, , 2018; Hu, W., Tan, Y., (2017) Generating Adversarial Malware Examples for Black-Box Attacks Based on GAN, , arXiv preprint 2017; Huang, S., Papernot, N., Goodfellow, I., Duan, Y., Abbeel, P., (2017) Adversarial Attacks on Neural Network Policies, , arXiv preprint 2017; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Krotov, D., Hopfield, J.J., (2017) Dense Associative Memory Is Robust to Adversarial Inputs, , arXiv preprint 2017; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in The Physical World, , arXiv preprint 2016; Lin, Y.-C., Hong, Z.-W., Liao, Y.-H., Shih, M.-L., Liu, M.-Y., Sun, M., (2017) Tactics of Adversarial Attack on Deep Reinforcement Learning Agents, , arXiv preprint 2017; Luo, Y., Boix, X., Roig, G., Poggio, T., Zhao, Q., (2015) Foveation-Based Mechanisms Alleviate Adversarial Examples, , arXiv preprint 2015; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., On detecting adversarial perturbations (2017) ICLR; Dezfooli, S.M.M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) CVPR; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., DeepFool: A Simple and Accurate Method to Fool Deep Neural Networks (2016) CVPR; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical Black-Box Attacks Against Machine Learning (2017) Proceedings of The 2017 ACM on Asia Conference on Computer and Communications Security (ASIA CCS'17), pp. 506-519; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) IEEE Symposium on Security and Privacy, pp. 582-597; Papernot, N., McDaniel, P.D., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., The Limitations of Deep Learning in Adversarial Settings (2016) IEEE European Symposium on Security and Privacy, EuroS&P 2016, pp. 372-387. , Saarbrücken, Germany, March 21-24, 2016; Papernot, N., McDaniel, P.D., Swami, A., Harang, R.E., Crafting adversarial input sequences for recurrent neural networks (2016) 2016 IEEE Military Communications Conference, pp. 49-54. , MILCOM; Ranjan, R., Sankaranarayanan, S., Castillo, C.D., Chellappa, R., (2017) Improving Network Robustness Against Adversarial Attacks with Compact Convolution, , arXiv preprint 2017; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proceedings of The 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540. , ACM; Shin, R., Song, D., JPEG-resistant Adversarial Images (2017) NIPS 2017 Workshop on Machine Learning and Computer Security, , 2017; Strauss, T., Hanselmann, M., Junginger, A., Ulmer, H., (2017) Ensemble Methods as A Defense to Adversarial Perturbations Against Deep Neural Networks, , arXiv preprint 2017; Szegedy, C., Inc, G., Zaremba, W., Sutskever, I., Inc, G., Bruna, J., Erhan, D., Fergus, R., Intriguing properties of neural networks (2014) ICLR; Tamersoy, A., Roundy, K., Chau, D.H., Guilt by association: Large scale malware detection by mining file-relation graphs (2014) Proceedings of The 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 1524-1533. , ACM; Xu, W., Evans, D., Qi, Y., Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks (2018) Proceedings of The 2018 Network and Distributed Systems Security Symposium (NDSS)",,,"ACM SIGKDD;ACM SIGMOD","Association for Computing Machinery","24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD 2018","19 August 2018 through 23 August 2018",,138322,,9781450355520,,,"English","Proc. ACM SIGKDD Int. Conf. Knowl. Discov. Data Min.",Conference Paper,"Final","All Open Access, Bronze",Scopus,2-s2.0-85051548544
"Sun M., Tang F., Yi J., Wang F., Zhou J.","57195596004;57203285345;36095116600;56177292700;24785591700;","Identify susceptible locations in medical records via adversarial attacks on deep predictive models",2018,"Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",,,,"793","801",,22,"10.1145/3219819.3219909","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051524753&doi=10.1145%2f3219819.3219909&partnerID=40&md5=a6c9392463e847396fc12771a5544042","Computer Science and Engineering, Michigan State University, East Lansing, MI, United States; JD AI Research, Beijing, China; Department of Healthcare Policy and Research, Weill Cornell Medical School, New York, NY, United States","Sun, M., Computer Science and Engineering, Michigan State University, East Lansing, MI, United States; Tang, F., Computer Science and Engineering, Michigan State University, East Lansing, MI, United States; Yi, J., JD AI Research, Beijing, China; Wang, F., Department of Healthcare Policy and Research, Weill Cornell Medical School, New York, NY, United States; Zhou, J., Computer Science and Engineering, Michigan State University, East Lansing, MI, United States","The surging availability of electronic medical records (EHR) leads to increased research interests in medical predictive modeling. Recently many deep learning based predicted models are also developed for EHR data and demonstrated impressive performance. However, a series of recent studies showed that these deep models are not safe: they suffer from certain vulnerabilities. In short, a well-trained deep network can be extremely sensitive to inputs with negligible changes. These inputs are referred to as adversarial examples. In the context of medical informatics, such attacks could alter the result of a high performance deep predictive model by slightly perturbing a patient's medical records. Such instability not only reflects the weakness of deep architectures, more importantly, it offers a guide on detecting susceptible parts on the inputs. In this paper, we propose an efficient and effective framework that learns a time-preferential minimum attack targeting the LSTM model with EHR inputs, and we leverage this attack strategy to screen medical records of patients and identify susceptible events and measurements. The efficient screening procedure can assist decision makers to pay extra attentions to the locations that can cause severe consequence if not measured correctly. We conduct extensive empirical studies on a real-world urgent care cohort and demonstrate the effectiveness of the proposed screening. © 2018 Association for Computing Machinery.","Adversarial attack; Medical records; Predictive modeling","Data mining; Decision making; Deep learning; Long short-term memory; Medical computing; Adversarial attack; Deep architectures; Electronic medical record; Medical informatics; Medical record; Predictive modeling; Research interests; Screening procedures; Diagnosis",,,,,"Oren, E., Rajkomar, A., (2018) Scalable and Accurate Deep Learning for Electronic Health Records, , arXiv preprint 2018; Anderson, H.S., Kharkar, A., Filar, B., Roth, P., Evading machine learning malware detection (2017) Black Hat, , 2017; Anderson, H.S., Woodbridge, J., Filar, B., DeepDGA: Adversarially-Tuned Domain Generation and Detection (2016) Proceedings of The 2016 ACM Workshop on Artificial Intelligence and Security, pp. 13-21. , ACM; Baytas, I.M., Xiao, C., Zhang, X., Wang, F., Jain, A.K., Zhou, J., Patient subtyping via time-aware LSTM networks (2017) Proceedings of The 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 65-74. , ACM; Beck, A., Teboulle, M., A fast iterative shrinkage-thresholding algorithm for linear inverse problems (2009) SIAM Journal on Imaging Sciences, 2 (1), pp. 183-202. , 2009; Carlini, N., Katz, G., Barrett, C., Dill, D.L., (2017) Ground-Truth Adversarial Examples, , arXiv preprint 2017; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium on, pp. 39-57. , IEEE; Che, Z., Kale, D., Li, W., Bahadori, M.T., Liu, Y., Deep computational phenotyping (2015) Proceedings of The 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 507-516. , ACM; Che, Z., Purushotham, S., Khemani, R., Liu, Y., Interpretable deep models for icu outcome prediction (2016) AMIA Annual Symposium Proceedings, 2016, p. 371. , American Medical Informatics Association; Chen, P.-Y., Sharma, Y., Zhang, H., Yi, J., Hsieh, C.-J., (2017) EAD: Elastic-Net Attacks to Deep Neural Networks Via Adversarial Examples, , arXiv preprint 2017; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) Proceedings of The 10th ACM Workshop on Artificial Intelligence and Security, pp. 15-26. , ACM; Cho, K., Van Merriënboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., Bengio, Y., (2014) Learning Phrase Representations Using RNN Encoder-Decoder for Statistical Machine Translation, , arXiv preprint 2014; Choi, E., Bahadori, M.T., Schuetz, A., Stewart, W.F., Sun, J., Doctor ai: Predicting clinical events via recurrent neural networks (2016) Machine Learning for Healthcare Conference, pp. 301-318; Choi, E., Bahadori, M.T., Searles, E., Coffey, C., Thompson, M., Bost, J., Tejedor-Sojo, J., Sun, J., Multilayer representation learning for medical concepts (2016) Proceedings of The 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 1495-1504. , ACM; Gong, Z., (2018) Adversarial Algorithms in TensorFlow, , http://doi.org/10.5281/zenodo.1154272, 2018; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint 2014; Grosse, K., Papernot, N., Manoharan, P., Backes, M., McDaniel, P., Adversarial examples for malware detection (2017) European Symposium on Research in Computer Security, pp. 62-79. , Springer; Harutyunyan, H., Khachatrian, H., Kale, D.C., Galstyan, A., (2017) Multitask Learning and Benchmarking with Clinical Time Series Data, , arXiv preprint 2017; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9 (8), pp. 1735-1780. , 1997; Hsia, R.Y., Antwi, Y.A., Nath, J.P., Variation in charges for 10 common blood tests in California hospitals: A cross-sectional analysis (2014) BMJ Open, 4 (8), p. e005482. , 2014; Hu, W., Tan, Y., (2017) Generating Adversarial Malware Examples for Black-Box Attacks Based on GAN, , arXiv preprint 2017; Jia, R., Liang, P., (2017) Adversarial Examples for Evaluating Reading Comprehension Systems, , arXiv preprint 2017; Johnson, A.E.W., Pollard, T.J., Shen, L., Lehman Li-Wei, H., Feng, M., Ghassemi, M., Moody, B., Mark, R.G., MIMIC-III, a freely accessible critical care database (2016) Scientific Data, 3, p. 160035. , 2016; Li, J., Monroe, W., Jurafsky, D., (2016) Understanding Neural Networks Through Representation Erasure, , arXiv preprint 2016; Lipton, Z.C., Kale, D.C., Elkan, C., Wetzel, R., (2015) Learning to Diagnose with LSTM Recurrent Neural Networks, , arXiv preprint 2015; Liu, Y., Chen, X., Liu, C., Song, D., (2016) Delving into Transferable Adversarial Examples and Black-Box Attacks, , arXiv preprint 2016; Miotto, R., Li, L., Kidd, B.A., Dudley, J.T., Deep patient: An unsupervised representation to predict the future of patients from the electronic health records (2016) Scientific Reports, 6, p. 26094. , 2016; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., (2016) Universal Adversarial Perturbations, , arXiv preprint 2016; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of The IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Proceedings of The IEEE Conference on Computer Vision and Pattern Recognition, pp. 427-436; Nguyen, P., Tran, T., Wickramasinghe, N., Venkatesh, S., Deepr: A Convolutional Net for Medical Records (2017) IEEE Journal of Biomedical and Health Informatics, 21 (1), pp. 22-30. , 2017; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387. , IEEE; Papernot, N., McDaniel, P., Swami, A., Harang, R., Crafting adversarial input sequences for recurrent neural networks (2016) Military Communications Conference, MILCOM 2016-2016 IEEE, pp. 49-54. , IEEE; Pham, T., Tran, T., Phung, D., Venkatesh, S., Deepcare: A deep dynamic memory model for predictive medicine (2016) Pacific-Asia Conference on Knowledge Discovery and Data Mining, pp. 30-41. , Springer; Rozsa, A., Rudd, E.M., Boult, T.E., Adversarial diversity and hard positive generation (2016) Proceedings of The IEEE Conference on Computer Vision and Pattern Recognition Workshops, pp. 25-32; Sabour, S., Cao, Y., Faghri, F., Fleet, D.J., (2015) Adversarial Manipulation of Deep Representations, , arXiv preprint 2015; Shickel, B., Tighe, P.J., Bihorac, A., Rashidi, P., Deep EHR: A Survey of Recent Advances in Deep Learning Techniques for Electronic Health Record (EHR) Analysis (2017) IEEE Journal of Biomedical and Health Informatics, , 2017; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint 2013; Wang, F., Lee, N., Hu, J., Sun, J., Ebadollahi, S., Towards heterogeneous temporal clinical event pattern discovery: A convolutional approach (2012) Proceedings of The 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 453-461. , ACM; Zhao, Z., Dua, D., Singh, S., (2017) Generating Natural Adversarial Examples, , arXiv preprint 2017; Zhou, J., Wang, F., Hu, J., Ye, J., From micro to macro: Data driven phenotyping by densification of longitudinal electronic medical records (2014) Proceedings of The 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 135-144. , ACM",,,"ACM SIGKDD;ACM SIGMOD","Association for Computing Machinery","24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD 2018","19 August 2018 through 23 August 2018",,138322,,9781450355520,,,"English","Proc. ACM SIGKDD Int. Conf. Knowl. Discov. Data Min.",Conference Paper,"Final","All Open Access, Bronze, Green",Scopus,2-s2.0-85051524753
"Liu N., Yang H., Hu X.","57191072267;57054215300;35114937200;","Adversarial detection with model interpretation",2018,"Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",,,,"1803","1811",,24,"10.1145/3219819.3220027","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051514922&doi=10.1145%2f3219819.3220027&partnerID=40&md5=17d2da65db38d060d7ee5e47dd30df0a","Texas A and M University, United States; Alibaba Group, China","Liu, N., Texas A and M University, United States; Yang, H., Alibaba Group, China; Hu, X., Texas A and M University, United States","Machine learning (ML) systems have been increasingly applied in web security applications such as spammer detection, malware detection and fraud detection. These applications have an intrinsic adversarial nature where intelligent attackers can adaptively change their behaviors to avoid being detected by the deployed detectors. Existing efforts against adversaries are usually limited by the type of applied ML models or the specific applications such as image classification. Additionally, the working mechanisms of ML models usually cannot be well understood by users, which in turn impede them from understanding the vulnerabilities of models nor improving their robustness. To bridge the gap, in this paper, we propose to investigate whether model interpretation could potentially help adversarial detection. Specifically, we develop a novel adversary-resistant detection framework by utilizing the interpretation of ML models. The interpretation process explains the mechanism of how the target ML model makes prediction for a given instance, thus providing more insights for crafting adversarial samples. The robustness of detectors is then improved through adversarial training with the adversarial samples. A data-driven method is also developed to empirically estimate costs of adversaries in feature manipulation. Our approach is model-agnostic and can be applied to various types of classification models. Our experimental results on two real-world datasets demonstrate the effectiveness of interpretation-based attacks and how estimated feature manipulation cost would affect the behavior of adversaries. © 2018 Association for Computing Machinery.","Adversarial Detection; Machine Learning Interpretation; Spammer Detection","Artificial intelligence; Cost estimating; Data mining; Learning systems; Malware; Classification models; Data-driven methods; Detection framework; Malware detection; Model interpretations; Real-world datasets; Spammer detections; Working mechanisms; Cost benefit analysis",,,,,"Alfeld, S., Zhu, X., Barford, P., Data poisoning attacks against autoregressive models (2016) AAAI; Alfeld, S., Zhu, X., Barford, P., Explicit defense actions against test-set attacks (2017) AAAI; Baehrens, D., Schroeter, T., Harmeling, S., Kawanabe, M., Hansen, K., MÃžller, K.-R., How to explain individual classification decisions (2010) Journal of Machine Learning Research, , 2010; Benevenuto, F., Magno, G., Rodrigues, T., Almeida, V., Detecting spammers on twitter (2010) CEAS; Beutel, A., Xu, W., Guruswami, V., Palow, C., Faloutsos, C., Copycatch: Stopping group attacks by spotting lockstep behavior in social networks (2013) WWW; Biggio, B., Corona, I., Evasion attacks against machine learning at test time (2013) Joint European Conference on Machine Learning and Knowledge Discovery in Databases, , Others; Biggio, B., Fumera, G., Roli, F., Security evaluation of pattern classifiers under attack (2014) TKDE, , 2014; Biggio, B., Nelson, B., Laskov, P., Support vector machines under adversarial label noise (2011) ACML; Brückner, M., Kanzow, C., Scheffer, T., Static prediction games for adversarial learning problems (2012) JMLR, , 2012; Brückner, M., Scheffer, T., Nash equilibria of static prediction games (2009) NIPS; Brückner, M., Scheffer, T., Stackelberg games for adversarial prediction problems (2011) KDD; Bucilua, C., Caruana, R., Niculescu-Mizil, A., Model compression (2006) KDD; Cao, X., Gong, N.Z., Mitigating evasion attacks to deep neural networks via region-based classification (2017) ACSAC; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium on, , IEEE; Castillo, C., Mendoza, M., Poblete, B., Information credibility on twitter (2011) WWW; Choi, E., Bahadori, M.T., Sun, J., Kulas, J., Schuetz, A., Stewart, W., Retain: An interpretable predictive model for healthcare using reverse time attention mechanism (2016) NIPS; Dalvi, N., Domingos, P., Sanghai, S., Verma, D., Adversarial classification (2004) KDD; Du, M., Liu, N., Song, Q., Hu, X., Towards explanation of dnn-based prediction with guided feature inversion (2018) KDD; Ertoz, L., Eilertson, E., Lazarevic, A., Tan, P.-N., Kumar, V., Srivastava, J., Dokas, P., Minds-Minnesota intrusion detection system (2004) Next Generation Data Mining, , 2004; Gao, J., Liu, N., Lawley, M., Hu, X., An interpretable classification framework for information extraction from online healthcare forums (2017) Journal of Healthcare Engineering, , 2017; Ghosh, S., Viswanath, B., Understanding and combating link farming in the twitter social network (2012) WWW; Goodfellow, I.J., Shlens, J., Szegedy, C., (2015) EXPLAINING AND HARNESSING ADVERSARIAL EXAMPLES. Stat 1050, p. 20. , 2015; Hinton, G., Vinyals, O., Dean, J., Distilling the knowledge in a neural network (2015) Stat 1050, p. 9. , 2015; Huang, S., Papernot, N., Goodfellow, I., Duan, Y., Abbeel, P., (2017) Adversarial Attacks on Neural Network Policies, , arXiv preprint 2017; Jindal, N., Liu, B., Opinion spam and analysis (2008) Proceedings of The 2008 International Conference on Web Search and Data Mining, pp. 219-230. , ACM; Kim, B., Khanna, R., Koyejo, O.O., Examples are not enough, learn to criticize! criticism for interpretability (2016) NIPS; Kim, B., Rudin, C., Shah, J.A., The Bayesian case model: A generative approach for case-based reasoning and prototype classification (2014) NIPS; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in The Physical World, , arXiv preprint 2016; Lake, B.M., Salakhutdinov, R., Tenenbaum, J.B., Human-level concept learning through probabilistic program induction (2015) Science, , 2015; Lakkaraju, H., Bach, S.H., Leskovec, J., Interpretable decision sets: A joint framework for description and prediction (2016) KDD; Lee, K., Eoff, B.D., Caverlee, J., Seven months with the devils: A long-term study of content polluters on twitter (2011) ICWSM; Li, F., Huang, M., Yang, Y., Zhu, X., Learning to identify review spam (2011) IJCAI; Liu, N., Huang, X., Li, J., Hu, X., On interpretation of network embedding via taxonomy induction (2018) KDD; Liu, N., Shin, D., Hu, X., (2017) Contextual Outlier Interpretation, , arXiv preprint 2017; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) ICLR; Mariconti, E., Onwuzurike, L., Andriotis, P., De Cristofaro, E., Ross, G., Stringhini, G., Mamadroid: Detecting android malware by building markov chains of behavioral models (2017) NDSS; Montavon, G., Samek, W., Müller, K.-R., (2017) Methods for Interpreting and Understanding Deep Neural Networks, , arXiv preprint 2017; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) CVPR; Mukherjee, A., Liu, B., Glance, N., Spotting fake reviewer groups in consumer reviews (2012) WWW; Mukherjee, A., Venkataraman, V., Liu, B., Glance, N., Fake review detection: Classification and analysis of real and pseudo reviews (2013) Technical Report UIC-CS-2013-03, , University of Illinois at Chicago, Tech. Rep. 2013; Nie, F., Huang, H., Cai, X., Ding, C.H., Efficient and robust feature selection via joint l2,1-norms minimization (2010) NIPS; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: from Phenomena to Black-Box Attacks Using Adversarial Samples, , arXiv preprint 2016; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., (2016) Practical Black-Box Attacks Against Deep Learning Systems Using Adversarial Examples, , arXiv preprint 2016; Papernot, N., McDaniel, P., Distillation as a defense to adversarial perturbations against deep neural networks (2016) SP, , Others; Papernot, N., McDaniel, P., The limitations of deep learning in adversarial settings (2016) EuroS&P, , Others; Ribeiro, M.T., Singh, S., Guestrin, C., Why should i trust you?: Explaining the predictions of any classifier (2016) KDD; Settles, B., (2010) Active Learning Literature Survey, 52, pp. 55-66. , University of Wisconsin, Madison 2010), 11; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint 2013; Tramèr, F., Zhang, F., Juels, A., Reiter, M.K., Ristenpart, T., Stealing machine learning models via prediction apis (2016) USENIX Security; Wang, G., Wang, T., Zheng, H., Zhao, B.Y., Man vs. machine: Practical adversarial detection of malicious crowdsourcing workers (2014) Usenix Security; Xu, W., Evans, D., Qi, Y., Feature squeezing: Detecting adversarial examples in deep neural networks (2018) NDSS; Xu, W., Qi, Y., Evans, D., Automatically evading classifiers (2016) Proceedings of The 2016 Network and Distributed Systems Symposium; Yang, C., Harkreader, R.C., Gu, G., Die free or live hard? empirical evaluation and new design for fighting evolving twitter spammers (2011) Recent Advances in Intrusion Detection, pp. 318-337. , Springer; Zhou, Y., Kantarcioglu, M., Thuraisingham, B., Xi, B., Adversarial support vector machine learning (2012) KDD",,,"ACM SIGKDD;ACM SIGMOD","Association for Computing Machinery","24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD 2018","19 August 2018 through 23 August 2018",,138322,,9781450355520,,,"English","Proc. ACM SIGKDD Int. Conf. Knowl. Discov. Data Min.",Conference Paper,"Final","",Scopus,2-s2.0-85051514922
"Zügner D., Akbarnejad A., Günnemann S.","57188995298;57203390828;35242528700;","Adversarial attacks on neural networks for graph data",2018,"Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",,,,"2847","2856",,217,"10.1145/3219819.3220078","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051494482&doi=10.1145%2f3219819.3220078&partnerID=40&md5=65208af81d50b37ef27678b865843346","Technical University of Munich, Germany","Zügner, D., Technical University of Munich, Germany; Akbarnejad, A., Technical University of Munich, Germany; Günnemann, S., Technical University of Munich, Germany","Deep learning models for graphs have achieved strong performance for the task of node classification. Despite their proliferation, currently there is no study of their robustness to adversarial attacks. Yet, in domains where they are likely to be used, e.g. the web, adversaries are common. Can deep learning models for graphs be easily fooled? In this work, we introduce the first study of adversarial attacks on attributed graphs, specifically focusing on models exploiting ideas of graph convolutions. In addition to attacks at test time, we tackle the more challenging class of poisoning/causative attacks, which focus on the training phase of a machine learning model. We generate adversarial perturbations targeting the node's features and the graph structure, thus, taking the dependencies between instances in account. Moreover, we ensure that the perturbations remain unnoticeable by preserving important data characteristics. To cope with the underlying discrete domain we propose an efficient algorithm Nettack exploiting incremental computations. Our experimental study shows that accuracy of node classification significantly drops even when performing only few perturbations. Even more, our attacks are transferable: the learned attacks generalize to other state-of-the-art node classification models and unsupervised approaches, and likewise are successful even when only limited knowledge about the graph is given. © 2018 Copyright held by the owner/author(s).","Adversarial machine learning; Graph convolutional networks; Graph mining; Network mining; Semi-supervised learning","Artificial intelligence; Convolution; Data mining; Deep learning; Learning algorithms; Supervised learning; Classification models; Convolutional networks; Data characteristics; Graph mining; Incremental computation; Machine learning models; Semi- supervised learning; Unsupervised approaches; Graph theory",,,,,"Adamic, L.A., Glance, N., The political blogosphere and the 2004 US election: Divided they blog (2005) International Workshop on Link Discovery, pp. 36-43; Bessi, A., (2015) Two Samples Test for Discrete Power-Law Distributions, , arXiv preprint 2015; Biggio, B., Fumera, G., Roli, F., Security evaluation of pattern classifiers under attack (2014) IEEE TKDE, 26 (4), pp. 984-996. , 2014; Bojchevski, A., Günnemann, S., Bayesian robust attributed graph clustering: Joint learning of partial anomalies and group structure (2018) AAAI, pp. 2738-2745; Bojchevski, A., Günnemann, S., Deep Gaussian embedding of graphs: Unsupervised inductive learning via ranking (2018) ICLR; Bojchevski, A., Matkovic, Y., Günnemann, S., Robust spectral clustering for noisy data: Modeling sparse corruptions improves latent embeddings (2017) SIGKDD, pp. 737-746; Cai, H., Zheng, V.W., Chang, K., A comprehensive survey of graph embedding: Problems, techniques and applications (2018) IEEE TKDE, , 2018; Chapelle, O., Schölkopf, B., Zien, A., Semi-supervised learning (2006) Adaptive Computation and Machine Learning Series, , The MIT Press; Chen, Y., Nadji, Y., Kountouras, A., Monrose, F., Perdisci, R., Antonakakis, M., Vasiloglou, N., (2017) Practical Attacks Against Graph-Based Clustering, , arXiv preprint 2017; Clauset, A., Shalizi, C.R., Newman, M.E.J., Power-law distributions in empirical data (2009) SIAM Review, 51 (4), pp. 661-703. , 2009; Defferrard, M., Bresson, X., Vandergheynst, P., Convolu-tional neural networks on graphs with fast localized spectral filtering (2016) NIPS, pp. 3837-3845; Eswaran, D., Günnemann, S., Faloutsos, C., Makhija, D., Kumar, M., ZooBP: Belief propagation for heterogeneous networks (2017) PVLDB, 10 (5), pp. 625-636. , 2017; Gilmer, J., Schoenholz, S.S., Riley, P.F., Vinyals, O., Dahl, G.E., Neural message passing for quantum chemistry (2017) ICML, pp. 1263-1272; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR; Grosse, K., Papernot, N., Manoharan, P., Backes, M., McDaniel, P., Adversarial examples for malware detection (2017) European Symposium on Research in Computer Security, pp. 62-79; Grover, A., Leskovec, J., Node2vec: Scalable feature learning for networks (2016) SIGKDD, pp. 855-864; Hamilton, W.L., Ying, R., Leskovec, J., Inductive representation learning on large graphs (2017) NIPS; Hooi, B., Shah, N., Beutel, A., Günnemann, S., Akoglu, L., Kumar, M., Makhija, D., Faloutsos, C., BIRDNEST: Bayesian inference for ratings-fraud detection (2016) SIAM SDM, pp. 495-503; Kipf, T.N., Welling, M., Semi-supervised classification with graph convolutional networks (2017) ICLR; Li, B., Wang, Y., Singh, A., Vorobeychik, Y., Data poisoning attacks on factorization-based collaborative filtering (2016) NIPS, pp. 1885-1893; London, B., Getoor, L., Collective classification of network data (2014) Data Classification: Algorithms and Applications, p. 399. , 2014; McCallum, A.K., Nigam, K., Rennie, J., Seymore, K., Automating the construction of internet portals with machine learning (2000) Information Retrieval, 3 (2), pp. 127-163. , 2000; Mei, S., Zhu, X., Using machine teaching to identify optimal training-set attacks on machine learners (2015) AAAI, pp. 2871-2877; Mohamed El-Sayed, A.M., Modeling multivariate correlated binary data (2016) American Journal of Theoretical and Applied Statistics, 5 (4), pp. 225-233. , 2016; Monti, F., Boscaini, D., Masci, J., Rodola, E., Svoboda, J., Bronstein, M.M., Geometric deep learning on graphs and manifolds using mixture model CNNs (2017) CVPR, 1 (3); Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) IEEE European Symposium on Security and Privacy, pp. 372-387; Perozzi, B., Al-Rfou, R., Skiena, S., Deepwalk: Online learning of social representations (2014) SIGKDD, pp. 701-710; Pham, T., Tran, T., Phung, D.Q., Venkatesh, S., Column networks for collective classification (2017) AAAI, pp. 2485-2491; Sen, P., Namata, G., Bilgic, M., Getoor, L., Galligher, B., Eliassi-Rad, T., Collective classification in network data (2008) AI Magazine, 29 (3), p. 93. , 2008; Szegedy, C., Zaremba, W., Sutskever, I., Inc, G., Bruna, J., Erhan, D., Inc, G., Fergus, R., Intriguing properties of neural networks (2014) ICLR; Torkamani, M.A., Lowd, D., Convex adversarial collective classification (2013) ICML, pp. 642-650; Tramèr, F., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2017) The Space of Transferable Adversarial Examples, , arXiv preprint 2017; Zhao, M., An, B., Yu, Y., Liu, S., Pan, S.J., Data Poisoning Attacks on Multi-Task Relationship Learning (2018) AAAI, pp. 2628-2635",,,"ACM SIGKDD;ACM SIGMOD","Association for Computing Machinery","24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD 2018","19 August 2018 through 23 August 2018",,138322,,9781450355520,,,"English","Proc. ACM SIGKDD Int. Conf. Knowl. Discov. Data Min.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85051494482
"Lu P.-H., Chen P.-Y., Chen K.-C., Yu C.-M.","57200512365;36930105800;57194338374;14322694600;","On the Limitation of MagNet Defense Against L1-Based Adversarial Examples",2018,"Proceedings - 48th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops, DSN-W 2018",,,"8416250","200","214",,6,"10.1109/DSN-W.2018.00065","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051222058&doi=10.1109%2fDSN-W.2018.00065&partnerID=40&md5=36090b4a198892a4c15cb9ecec423eca","National Chung Hsing University, Taiwan; IBM Research, United States; Yuan Ze University, Taiwan","Lu, P.-H., National Chung Hsing University, Taiwan; Chen, P.-Y., IBM Research, United States; Chen, K.-C., Yuan Ze University, Taiwan; Yu, C.-M., National Chung Hsing University, Taiwan","In recent years, defending adversarial perturbations to natural examples in order to build robust machine learning models trained by deep neural networks (DNNs) has become an emerging research field in the conjunction of deep learning and security. In particular, MagNet consisting of an adversary detector and a data reformer is by far one of the strongest defenses in the black-box oblivious attack setting, where the attacker aims to craft transferable adversarial examples from an undefended DNN model to bypass an unknown defense module deployed on the same DNN model. Under this setting, MagNet can successfully defend a variety of attacks in DNNs, including the high-confidence adversarial examples generated by the Carlini and Wagner's attack based on the L2 distortion metric. However, in this paper, under the same attack setting we show that adversarial examples crafted based on the L1 distortion metric can easily bypass MagNet and mislead the target DNN image classifiers on MNIST and CIFAR-10. We also provide explanations on why the considered approach can yield adversarial examples with superior attack performance and conduct extensive experiments on variants of MagNet to verify its lack of robustness to L1 distortion based attacks. Notably, our results substantially weaken the assumption of effective threat models on MagNet that require knowing the deployed defense technique when attacking DNNs (i.e., the gray-box attack setting). © 2018 IEEE.","adversarial example; neural network","Magnets; Network security; Neural networks; adversarial example; Defense techniques; Distortion metrics; High confidence; Image Classifiers; Machine learning models; Research fields; Threat models; Deep neural networks",,,,,"Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR'15; Evtimov, I., Eykholt, K., Fernandes, E., Kohno, T., Li, B., Prakash, A., Rahmati, A., Song, D., (2017) Robust Physical-world Attacks on Machine Learning Models; Athalye, A., Sutskever, I., (2017) Synthesizing Robust Adversarial Examples; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) ACM Asia Conference on Computer and Communications Security, pp. 506-519; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) ACM Workshop on Artificial Intelligence and Security, pp. 15-26; Liu, Y., Chen, X., Liu, C., Song, D., (2016) Delving into Transferable Adversarial Examples and Black-box Attacks; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy (SP), pp. 39-57; Carlini, N., Wagner, D., (2017) Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods; Sharma, Y., Chen, P.-Y., Attacking the Madry defense model with L1- based adversarial examples (2018) ICLR Workshop; Lu, P.-H., Chen, P.-Y., Yu, C.-M., On the limitation of local intrinsic dimensionality for characterizing the subspaces of adversarial examples (2018) ICLR Workshop; Athalye, A., Carlini, N., Wagner, D., (2018) Obfuscated Gradients Give A False Sense of Security: Circumventing Defenses to Adversarial Examples; Sharma, Y., Chen, P.-Y., (2018) Bypassing Feature Squeezing by Increasing Adversary Strength; Meng, D., Chen, H., Magnet: A two-pronged defense against adversarial examples (2017) ACM CCS; Chen, P.-Y., Sharma, Y., Zhang, H., Yi, J., Hsieh, C.-J., (2018) Ead: Elasticnet Attacks to Deep Neural Networks Via Adversarial Examples, , AAAI; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2016) ICLR'17; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Carlini, N., Wagner, D., (2017) Magnet and ""efficient Defenses Against Adversarial Attacks"" Are Not Robust to Adversarial Examples; Beck, A., Teboulle, M., A fast iterative shrinkage-thresholding algorithm for linear inverse problems (2009) SIAM Journal on Imaging Sciences, 2 (1), pp. 183-202",,,"","Institute of Electrical and Electronics Engineers Inc.","48th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops, DSN-W 2018","25 June 2018 through 28 June 2018",,138147,,9781538655955,,,"English","Proc. - Annu. IEEE/IFIP Int. Conf. Dependable Syst. Networks Workshops, DSN-W",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85051222058
"Wen J., Hui L.C.K., Yiu S.-M., Zhang R.","57203305034;8905728300;7003282240;57193956197;","DCN: Detector-Corrector Network Against Evasion Attacks on Deep Neural Networks",2018,"Proceedings - 48th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops, DSN-W 2018",,,"8416251","215","221",,2,"10.1109/DSN-W.2018.00066","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051164392&doi=10.1109%2fDSN-W.2018.00066&partnerID=40&md5=a77d0cef0e785034ec74fac0df049058","Dept. of Computer Science, University of Hong Kong, Hong Kong; Hong Kong Applied Science and Technology Research Institute (ASTRI), Hong Kong","Wen, J., Dept. of Computer Science, University of Hong Kong, Hong Kong; Hui, L.C.K., Hong Kong Applied Science and Technology Research Institute (ASTRI), Hong Kong; Yiu, S.-M., Dept. of Computer Science, University of Hong Kong, Hong Kong; Zhang, R., Dept. of Computer Science, University of Hong Kong, Hong Kong","Deep neural networks are extensively used in image recognition. However, its integrity is compromised by evasion attacks. Attackers can easily craft adversarial examples that make DNNs unknowingly output the labels they want rather than the right labels. In a recent study, it was shown that existing detection methods are not effective in identifying these adversarial examples, i.e., it is a realistic threat to existing systems. Unlike the previous detection methods, we observe that the classification probability distributions of adversarial examples and those of untampered examples exhibit a big difference, which can be easily identified based on the output of a DNN without getting into the complicated DNN internal structure. Based on this new insight, we propose a new light-weight detection method by transforming the detection of adversarial examples into a binary classification problem. The detector we train achieves almost 100% accuracy on adversarial examples. Moreover, we propose a detector-corrector network that effectively reduces successful rate of existing state-of-the-art evasion attacks under three commonly used distance metrics. In particular, for the common L2 attack, DCN mitigates 99% adversarial examples on MNIST and 95% on CIFAR-10. Our evaluation demonstrates that DCN is significantly more effective and efficient against various evasion attacks than existing methods. © 2018 IEEE.","adversarial learning; Deep learning; evasion attacks","Deep learning; Image recognition; Probability distributions; Adversarial learning; Binary classification problems; Detection methods; Distance metrics; evasion attacks; Existing systems; Internal structure; State of the art; Deep neural networks",,,,,"Hinton, G., Deng, L., Yu, D., Dahl, G.E., Mohamed, A.-R., Jaitly, N., Senior, A., Sainath, T.N., Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups (2012) IEEE Signal Processing Magazine, 29 (6), pp. 82-97; Silver, D., Huang, A., Maddison, C.J., Guez, A., Sifre, L., Van Den-Driessche, G., Schrittwieser, J., Lanctot, M., Mastering the game of go with deep neural networks and tree search (2016) Nature, 529 (7587), pp. 484-489; Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D., Riedmiller, M., (2013) Playing Atari with Deep Reinforcement Learning; Andor, D., Alberti, C., Weiss, D., Severyn, A., Presta, A., Ganchev, K., Petrov, S., Collins, M., (2016) Globally Normalized Transition-based Neural Networks; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Ciregan, D., Meier, U., Schmidhuber, J., Multi-column deep neural networks for image classification (2012) Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, pp. 3642-3649. , IEEE; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks; Stoica, I., Song, D., Popa, R.A., Patterson, D., Mahoney, M.W., Katz, R., Joseph, A.D., Gonzalez, J.E., (2017) A Berkeley View of Systems Challenges for Ai; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Security and Privacy (SP), 2016 IEEE Symposium on, pp. 582-597. , IEEE; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium on, pp. 39-57. , IEEE; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., (2017) On Detecting Adversarial Perturbations; Hendrycks, D., Gimpel, K., (2017) Early Methods for Detecting Adversarial Images; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 3-14. , ACM; Cao, X., Gong, N.Z., Mitigating evasion attacks to deep neural networks via region-based classification (2017) Proceedings of the 33rd Annual Computer Security Applications Conference, pp. 278-287. , ACM; Moosavi Dezfooli, S.M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , EPFL-CONF-218057; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387. , IEEE; Xu, W., Evans, D., Qi, Y., (2017) Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks; Meng, D., Chen, H., Magnet: A two-pronged defense against adversarial examples (2017) Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pp. 135-147. , ACM; Chollet, F., (2015) Keras, , https://keras.io; Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G.S., Zheng, X., (2015) TensorFlow: Large-scale Machine Learning on Heterogeneous Systems, , https://www.tensorflow.org/, software available from tensorflow.org. [Online]; LeCun, Y., (1998) The Mnist Database of Handwritten Digits, , http://yann.lecun.com/exdb/mnist/; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images; Papernot, N., Carlini, N., Goodfellow, I., Feinman, R., Faghri, F., Matyasko, A., Hambardzumyan, K., Sheatsley, R., (2016) Cleverhans v2. 0.0: An Adversarial Machine Learning Library",,,"","Institute of Electrical and Electronics Engineers Inc.","48th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops, DSN-W 2018","25 June 2018 through 28 June 2018",,138147,,9781538655955,,,"English","Proc. - Annu. IEEE/IFIP Int. Conf. Dependable Syst. Networks Workshops, DSN-W",Conference Paper,"Final","",Scopus,2-s2.0-85051164392
"Prakash A., Moran N., Garber S., Dilillo A., Storer J.","57194418224;57191255609;57194420056;57192541823;57000678400;","Protecting JPEG images against adversarial attacks",2018,"Data Compression Conference Proceedings","2018-March",,,"137","146",,12,"10.1109/DCC.2018.00022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050972491&doi=10.1109%2fDCC.2018.00022&partnerID=40&md5=bfb42bfe42b2aad0eaffa8975be58bba","Brandeis University, United States","Prakash, A., Brandeis University, United States; Moran, N., Brandeis University, United States; Garber, S., Brandeis University, United States; Dilillo, A., Brandeis University, United States; Storer, J., Brandeis University, United States","As deep neural networks (DNNs) have been integrated into critical systems, several methods to attack these systems have been developed. These adversarial attacks make imperceptible modifications to an image that fool DNN classifiers. We present an adaptive JPEG encoder which defends against many of these attacks. Experimentally, we show that our method produces images with high visual quality while greatly reducing the potency of state-of-the-art attacks. Our algorithm requires only a modest increase in encoding time, produces a compressed image which can be decompressed by an off-the-shelf JPEG decoder, and classified by an unmodified classifier. © 2018 IEEE.","adversarial attacks; computer vision; deep learning; jpeg; jpeg defense; security","Computer vision; Deep learning; Signal encoding; adversarial attacks; Compressed images; Critical systems; jpeg; jpeg defense; security; State of the art; Visual qualities; Deep neural networks",,,,,"He, K., Deep residual learning for image recognition (2016) CVPR; Bojarski, M., (2016) End to End Learning for Self-Driving Cars, , ArXiv preprint arXiv:1604.07316; Pascanu, R., Malware classification with recurrent networks (2015) Acoustics, Speech and Signal Processing (ICASSP), 2015. IEEE; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2014) CoRR, , abs/1412.6572; Das, N., (2017) Keeping the Bad Guys Out: Protecting and Vaccinating Deep Learning with JPEG Compression, , CoRR abs/1705.02900; Dziugaite, G.K., Ghahramani, Z., Roy, D.M., A study of the efiect of JPG compression on adversarial images (2016) CoRR, , abs/1608.00853; Papernot, N., Distillation as a defense to adversarial perturbations against deep neural networks (2016) SSP; Miyato, T., (2015) Distributional Smoothing with Virtual Adversarial Train; Prakash, A., Semantic perceptual image compression using deep convolution networks (2017) 2017 Data Compression Conference (DCC); Papernot, N., Practical black-box attacks against deep learning systems using adversarial examples (2016) CoRR, , abs/1602.02697; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial Examples in the Physical World"". In: CoRR abs/1607.02533 (2016); Moosavi-Dezfooli, S., Fawzi, A., Frossard, P., Deep-Fool: A simple and accurate method to fool deep neural networks (2016) 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2574-2582; Carlini, N., Wagner, D.A., Towards evaluating the robustness of neural networks (2017) SSP; Szegedy, C., Intriguing properties of neural networks (2013) CoRR, , abs/1312.6199; Tramfier, F., The space of transferable adversarial examples (2017) CoRR, , abs/1704.03453; Liu, Y., Delving into transferable adversarial examples and black-box attacks (2016) CoRR, , abs/1611.02770; Liang, B., (2017) Detecting Adversarial Examples in Deep Networks with Adap-tive Noise Reduction, , ArXiv preprint; Prakash, A., (2018) Deecting Adversarial Attacks with Pixel Deection, , ArXiv preprint; Guo, C., (2017) Countering Adversarial Images Using Input Transforma-tions, , ArXiv preprint; Erhan, D., (2014) Scalable Object Detection Using Deep Neural Networks, , CVPR; Zhao, R., Saliency detection by multi-context deep learning (2015) CVPR, , June; Wang, Z., Image quality assessment: From error visibility to structural similarity (2004) IEEE Transactions on Image Processing, 13 (4), pp. 600-612",,"Bilgin A.Storer J.A.Serra-Sagrista J.Marcellin M.W.","Brandeis University;Microsoft Research;University of Arizona","Institute of Electrical and Electronics Engineers Inc.","2018 Data Compression Conference, DCC 2018","27 March 2018 through 30 March 2018",,138136,10680314,9781538648834,DDCCF,,"English","Data Compression Conf Proc",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85050972491
[No author name available],[No author id available],"Data Compression Conference Proceedings",2018,"Data Compression Conference Proceedings","2018-March",,,"","",450,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050971593&partnerID=40&md5=6586b5ed1a1e1490f6cb9e566b55f72c",,"","The proceedings contain 70 papers. The topics discussed include: film grain synthesis for AV1 video codec; co-located reference frame interpolation using optical flow estimation for video compression; adaptive interpolated motion-compensated prediction with variable block partitioning; a grammar compression algorithm based on induced suffix sorting; engineering compressed static functions; online decomposition of compressive streaming data using n-l1 cluster-weighted minimization; rate allocation for motion compensated JPEG2000; guided cross-component prediction for RGB video coding; entropy coding and entropy coding improvements of JPEG XS; compressed image restoration via external-image assisted band adaptive PCA model learning; convex optimization based bit allocation for light field compression under weighting and consistency constraints; spike coding for dynamic vision sensors; a group variational transformation neural network for fractional interpolation of video coding; protecting JPEG images against adversarial attacks; joint source-channel coding with neural networks for analog data compression and storage; graph-based transforms based on prediction inaccuracy modeling for pathology image coding; lossy compression of quality scores in differential gene expression: a first assessment and impact analysis; the bits between proteins; a new HEVC In-loop Filter Based on Multi-channel Long-Short-Term Dependency Residual Networks; Compact Representations of Event Sequences; and fixed-rate zero-delay source coding for stationary vector-valued Gauss-Markov sources.",,,,,,,,,"Bilgin A.Storer J.A.Serra-Sagrista J.Marcellin M.W.","Brandeis University;Microsoft Research;University of Arizona","Institute of Electrical and Electronics Engineers Inc.","2018 Data Compression Conference, DCC 2018","27 March 2018 through 30 March 2018",,138136,10680314,9781538648834,DDCCF,,"English","Data Compression Conf Proc",Conference Review,"Final","",Scopus,2-s2.0-85050971593
"Bai X., Niu W., Liu J., Gao X., Xiang Y., Liu J.","57195494795;25028470300;7410116593;57203240365;57195495277;57195493415;","Adversarial examples construction towards white-box Q table variation in DQN pathfinding training",2018,"Proceedings - 2018 IEEE 3rd International Conference on Data Science in Cyberspace, DSC 2018",,,"8411947","781","787",,11,"10.1109/DSC.2018.00126","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051011666&doi=10.1109%2fDSC.2018.00126&partnerID=40&md5=06155c086fe9ceead43a44b68e57b0d4","Beijing Key Laboratory of Security and Privacy in Intelligent Transportation, Beijing Jiaotong University, Beijing, China","Bai, X., Beijing Key Laboratory of Security and Privacy in Intelligent Transportation, Beijing Jiaotong University, Beijing, China; Niu, W., Beijing Key Laboratory of Security and Privacy in Intelligent Transportation, Beijing Jiaotong University, Beijing, China; Liu, J., Beijing Key Laboratory of Security and Privacy in Intelligent Transportation, Beijing Jiaotong University, Beijing, China; Gao, X., Beijing Key Laboratory of Security and Privacy in Intelligent Transportation, Beijing Jiaotong University, Beijing, China; Xiang, Y., Beijing Key Laboratory of Security and Privacy in Intelligent Transportation, Beijing Jiaotong University, Beijing, China; Liu, J., Beijing Key Laboratory of Security and Privacy in Intelligent Transportation, Beijing Jiaotong University, Beijing, China","As a new research hotspot in the field of artificial intelligence, deep reinforcement learning (DRL) has achieved certain success in various fields such as robot control, computer vision, natural language processing and so on. At the same time, the possibility of its application being attacked and whether it have a strong resistance to strike has also become a hot topic in recent years. Therefore, we select the representative Deep Q Network (DQN) algorithm in deep reinforcement learning, and use the robotic automatic pathfinding application as a countermeasure application scenario for the first time, and attack DQN algorithm against the vulnerability of the adversarial samples. In this paper, we first use DQN to find the optimal path, and analyze the rules of DQN pathfinding. Then, we propose a method that can effectively find vulnerable points towards White-Box Q table variation in DQN pathfinding training. Finally, we build a simulation environment as a basic experimental platform to test our method, through multiple experiments, we can successfully find the adversarial examples and the experimental results show that the supervised method we proposed is effective. © 2018 IEEE.","Adversarial examples; DQN; Pathfinding; White-Box attack","Computers; Intelligent robots; Natural language processing systems; Network security; Reinforcement learning; Vector quantization; Adversarial examples; Application scenario; Experimental platform; ITS applications; Pathfinding; Simulation environment; Supervised methods; White box; Deep learning",,,,,"Lillicrap, T.P., Hunt, J.J., Pritzel, A., Heess, N., Erez, T., Tassa, Y., Silver, D., Wierstra, D., Continuous control with deep reinforcement learning (2015) Computer Science, 8 (6), p. A187; Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.A., Veness, J., Bellemare, M.G., Graves, A., Ostrovski, G., Human-level control through deep reinforcement learning (2015) Nature, 518 (7540), p. 529; Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D., Riedmiller, M., Playing atari with deep reinforcement learning (2013) Computer Science; Duan, Y., Chen, X., Houthooft, R., Schulman, J., Abbeel, P., (2016) Benchmarking Deep Reinforcement Learning for Continuous Control, pp. 1329-1338; Andrychowicz, M., Denil, M., Gomez, S., Hoffman, M.W., Pfau, D., Schaul, T., Shillingford, B., De Freitas, N., (2016) Learning to Learn by Gradient Descent by Gradient Descent; Caicedo, J.C., Lazebnik, S., Active object localization with deep reinforcement learning (2015) IEEE International Conference on Computer Vision, pp. 2488-2496; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2014) Computer Science; Tamar, A., Wu, Y., Thomas, G., Levine, S., Abbeel, P., (2016) Value Iteration Networks; Sabes, P.N., Jordan, M.I., Advances in neural information processing systems (1995) Advances in Neural Information Processing Systems., , G. Tesauro & D. Touretzky & T. Leed (Eds.), Citeseer; Watkins, C.J., Dayan, P., Q-learning (1992) Machine Learning, 8 (3-4), pp. 279-292; Mnih, V., Badia, A.P., Mirza, M., Graves, A., Lillicrap, T., Harley, T., Silver, D., Kavukcuoglu, K., Asynchronous methods for deep reinforcement learning (2016) International Conference on Machine Learning, pp. 1928-1937; Jaderberg, M., Mnih, V., Czarnecki, W.M., Schaul, T., Leibo, J.Z., Silver, D., Kavukcuoglu, K., (2016) Reinforcement Learning with Unsupervised Auxiliary Tasks; Xin, J., Zhao, H., Liu, D., Li, M., Application of deep reinforcement learning in mobile robot path planning (2017) Chinese Automation Congress, pp. 7112-7116; Mozer, S.C.M., Hasselmo, M., (2005) Reinforcement Learning: An Introduction, pp. 285-286; Lin, L.J., (1993) Reinforcement Learning for Robots Using Neural Networks; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, pp. 2672-2680; Mirza, M., Osindero, S., (2014) Conditional Generative Adversarial Nets, , arXiv preprint arXiv","Niu, W.; Beijing Key Laboratory of Security and Privacy in Intelligent Transportation, China; email: niuwj@bjtu.edu.cn",,"","Institute of Electrical and Electronics Engineers Inc.","3rd IEEE International Conference on Data Science in Cyberspace, DSC 2018","18 June 2018 through 21 June 2018",,138050,,9781538642108,,,"English","Proc. - IEEE Int. Conf. Data Sci. Cyberspace, DSC",Conference Paper,"Final","",Scopus,2-s2.0-85051011666
"Xiang Y., Niu W., Liu J., Chen T., Han Z.","57195495277;25028470300;7410116593;57195492238;7402859064;","A PCA-based model to predict adversarial examples on Q-learning of path finding",2018,"Proceedings - 2018 IEEE 3rd International Conference on Data Science in Cyberspace, DSC 2018",,,"8411946","773","780",,8,"10.1109/DSC.2018.00125","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051009997&doi=10.1109%2fDSC.2018.00125&partnerID=40&md5=3e4f1af88e8559c7194daf9ca82fa632","Beijing Key Laboratory of Security and Privacy in Intelligent Transportation, Beijing Jiaotong University, Beijing, China","Xiang, Y., Beijing Key Laboratory of Security and Privacy in Intelligent Transportation, Beijing Jiaotong University, Beijing, China; Niu, W., Beijing Key Laboratory of Security and Privacy in Intelligent Transportation, Beijing Jiaotong University, Beijing, China; Liu, J., Beijing Key Laboratory of Security and Privacy in Intelligent Transportation, Beijing Jiaotong University, Beijing, China; Chen, T., Beijing Key Laboratory of Security and Privacy in Intelligent Transportation, Beijing Jiaotong University, Beijing, China; Han, Z., Beijing Key Laboratory of Security and Privacy in Intelligent Transportation, Beijing Jiaotong University, Beijing, China","Reinforcement learning is a core learning approach of machine learning in artificial intelligence, which has been widely used to realize the module of automatic path finding for robots. However, recent researches have shown that the designed adversarial examples can make an algorithm-level attack on reinforcement learning in the Atari game. Obviously, such attack may be also brought into the automatic path finding based on reinforcement learning. In this paper, we focus on the adversarial example-based attack on a representative reinforcement learning named Q-learning in automatic path finding. We propose a probabilistic output model based on the influence factors and the corresponding weights to predict the adversarial examples. Through calculation on five factors including the energy point gravitation, the key point gravitation, the path gravitation, the included angle and the placid point, a natural linear model is constructed to fit these factors with the weight parameters computation based on the principal component analysis(PCA). Through massive experiments, we successfully find the adversarial examples for the first time on Q-learning in path finding and our model can make a satisfactory prediction. Under a guaranteed recall, the precision of the proposed model can reach to 70% with the proper parameter setting. © 2018 IEEE.","Adversarial examples; Path finding; PCA-based model; Q-learning","Artificial intelligence; Computers; Forecasting; Gravitation; Intelligent robots; Learning algorithms; Principal component analysis; Adversarial examples; Corresponding weights; Learning approach; Path finding; Probabilistic output; Q-learning; Satisfactory predictions; Weight parameters; Reinforcement learning",,,,,"He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Xiong, W., Droppo, J., Huang, X., Seide, F., Seltzer, M., Stolcke, A., Yu, D., Zweig, G., (2016) Achieving Human Parity in Conversational Speech Recognition, , arXiv preprint arXiv; Ren, T., (2017) Berkeley Released AI System Challenge Report, , http://www.weiyuehao.com/wechatarticle-85405.html, Website; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint arXiv; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint arXiv; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint arXiv; Carlini, N., Mishra, P., Vaidya, T., Zhang, Y., Sherr, M., Shields, C., Wagner, D., Zhou, W., Hidden voice commands (2016) USENIX Security Symposium, pp. 513-530; Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D., Riedmiller, M., (2013) Playing Atari with Deep Reinforcement Learning, , arXiv preprint arXiv; Watkins, C.J., Dayan, P., Q-learning (1992) Machine Learning, 8 (3-4), pp. 279-292; Deng, R.W., Wang, Y.H., Lin, C.J., Li, T.H.S., Implementation of human following mission by using fuzzy head motion control and qlearning wheel motion control for home service robot (2014) International Conference on Fuzzy Theory and ITS Applications, pp. 55-60; Syafiie, S., Tadeo, F., Martinez, E., Model-free learning control of neutralization processes using reinforcement learning (2007) Engineering Applications of Artificial Intelligence, 20 (6), pp. 767-782; Luo, B., Liu, D., Huang, T., (2014) Q-learning for Optimal Control of Continuous-time Systems, , arXiv preprint arXiv; Konar, A., Chakraborty, I.G., Singh, S.J., Jain, L.C., Nagar, A.K., A deterministic improved q-learning for path planning of a mobile robot (2013) IEEE Transactions on Systems, Man, and Cybernetics: Systems, 43 (5), pp. 1141-1153; Das, P.K., Mandhata, S., Behera, H., Patro, S., An improved qlearning algorithm for path-planning of a mobile robot (2012) International Journal of Computer Applications, 51 (9); Watkins, C.J.C.H., (1989) Learning from Delayed Rewards, , Ph.D. dissertation, King's College, Cambridge; Liu, Y., Chen, X., Liu, C., Song, D., (2016) Delving into Transferable Adversarial Examples and Black-box Attacks, , arXiv preprint arXiv; Saaty, T.L., Decision making with the analytic hierarchy process (2008) International Journal of Services Sciences, 1 (1), pp. 83-98; Hsu, C.-C., Sandford, B.A., The delphi technique: Making sense of consensus (2007) Practical Assessment, Research & Evaluation, 12 (10), pp. 1-8; Wold, S., Esbensen, K., Geladi, P., Principal component analysis (1987) Chemometrics and Intelligent Laboratory Systems, 2 (1-3), pp. 37-52; Buchwalder, M., Bühlmann, H., Merz, M., Wüthrich, M.V., The mean square error of prediction in the chain ladder reserving method (mack and murphy revisited) (2006) ASTIN Bulletin: The Journal of the IAA, 36 (2), pp. 521-542; Marler, R.T., Arora, J.S., Survey of multi-objective optimization methods for engineering (2004) Structural and Multidisciplinary Optimization, 26 (6), pp. 369-395","Niu, W.; Beijing Key Laboratory of Security and Privacy in Intelligent Transportation, China; email: niuwj@bjtu.edu.cn",,"","Institute of Electrical and Electronics Engineers Inc.","3rd IEEE International Conference on Data Science in Cyberspace, DSC 2018","18 June 2018 through 21 June 2018",,138050,,9781538642108,,,"English","Proc. - IEEE Int. Conf. Data Sci. Cyberspace, DSC",Conference Paper,"Final","",Scopus,2-s2.0-85051009997
[No author name available],[No author id available],"Proceedings - 2018 International Conference on Biometrics, ICB 2018",2018,"Proceedings - 2018 International Conference on Biometrics, ICB 2018",,,,"","",320,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050985020&partnerID=40&md5=0815129c6e7b5cae24b00c4fa2a4090c",,"","The proceedings contain 42 papers. The topics discussed include: fingerprint distortion rectification using deep convolutional neural networks; robust minutiae extractor: integrating deep networks and fingerprint domain knowledge; comparative study of digital fingerprint quality assessment metrics; filter design based on spectral dictionary for latent fingerprint pre-enhancement; fingerprint synthesis: evaluating fingerprint search at scale; evolutionary methods for generating synthetic masterprint templates: dictionary attack in fingerprint recognition; hierarchical multi-class iris classification for liveness detection; securing minutia cylinder codes for fingerprints through physically unclonable functions: an exploratory study; on effectiveness of anomaly detection approaches against unseen presentation attacks in face anti-spoofing; and semi-adversarial networks: convolutional autoencoders for imparting privacy to face images.",,,,,,,,,,"APRS;IAPR;IEEE Biometrics Council","Institute of Electrical and Electronics Engineers Inc.","11th IAPR International Conference on Biometrics, ICB 2018","20 February 2018 through 23 February 2018",,137923,,9781538642856,,,"English","Proc. - Int. Conf. Biom., ICB",Conference Review,"Final","",Scopus,2-s2.0-85050985020
"Kotinas I., Fakotakis N.","36696339300;7003320511;","Text analysis for decision making under adversarial environments",2018,"ACM International Conference Proceeding Series",,,,"","",,,"10.1145/3200947.3201018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052027242&doi=10.1145%2f3200947.3201018&partnerID=40&md5=a9cad41137f4bbde0d40ed49b80e9184","University of Patras, Greece","Kotinas, I., University of Patras, Greece; Fakotakis, N., University of Patras, Greece","Sentiment analysis and other practices for text analytics on social media rely on publicly available and editable collections of data for training and evaluation. These data collections are subject to poisoning and data contamination attacks by adversaries having an interest in misleading the results of the performed analysis. We present the problem of adversarial text mining with a focus on decision making and we suggest cross-discipline, cross-application and cross-model strategies for more robust analyses. Our approach is practitioner-centric and is based on broadly-used interpretable models with applications in decision making. © 2018 Copyright held by the owner/author(s).","Adversarial learning; Decision support; Sentiment analysis; Social media; Text analytics","Artificial intelligence; Data acquisition; Data mining; Decision support systems; Natural language processing systems; Sentiment analysis; Social networking (online); Adversarial environments; Adversarial learning; Cross-disciplines; Data collection; Decision supports; Robust analysis; Social media; Text analytics; Decision making",,,,,"Aue, A., Gamon, M., Customizing sentiment classifiers to new domains: A case study (2005) Proceedings of Recent Advances in Natural Language Processing (RANLP), 1, pp. 2-11. , Citeseer; Barreno, M., Nelson, B., Sears, R., Joseph, A.D., Doug Tygar, J., Can machine learning be secure? (2006) Proceedings of The 2006 ACM Symposium on Information, Computer and Communications Security, pp. 16-25. , ACM; Biggio, B., Corona, I., Fumera, G., Giacinto, G., Roli, F., Bagging classifiers for fighting poisoning attacks in adversarial classification tasks (2011) International Workshop on Multiple Classifier Systems, pp. 350-359. , Springer; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndić, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 387-402. , Springer; Biggio, B., Fumera, G., Roli, F., Security evaluation of pattern classifiers under attack (2014) IEEE Transactions on Knowledge and Data Engineering, 26 (4), pp. 984-996. , 2014; Biggio, B., Pillai, I., Bulò, S.R., Ariu, D., Pelillo, M., Roli, F., Is data clustering in adversarial settings secure? (2013) Proceedings of The 2013 ACM Workshop on Artificial Intelligence and Security, pp. 87-98. , ACM; Chen, C., Wu, K., Srinivasan, V., Zhang, X., Battling the internet water army: Detection of hidden paid posters (2013) Advances in Social Networks Analysis and Mining (ASONAM), 2013 IEEE/ACM International Conference on, pp. 116-120. , IEEE; Dalvi, N., Domingos, P., Sanghai, S., Verma, D., Adversarial classification (2004) Proceedings of The Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 99-108. , ACM; Glassman, M., Kang, M.J., Intelligence in the internet age: The emergence and evolution of open source intelligence (osint) (2012) Computers in Human Behavior, 28 (2), pp. 673-682. , 2012; Globerson, A., Roweis, S., Nightmare at test time: Robust learning by feature deletion (2006) Proceedings of The 23rd International Conference on Machine Learning, pp. 353-360. , ACM; Hobbs, J.R., Riloff, E., Information extraction (2010) Handbook of Natural Language Processing, 2. , 2010; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I.P., Tygar, J.D., Adversarial machine learning (2011) Proceedings of The 4th ACM Workshop on Security and Artificial Intelligence, pp. 43-58. , ACM; Jansen, B.J., Click fraud (2007) Computer, 40, p. 7. , 2007; Jindal, N., Liu, B., Opinion spam and analysis (2008) Proceedings of The 2008 International Conference on Web Search and Data Mining, pp. 219-230. , ACM; Koumpouri, A., Mporas, I., Megalooikonomou, V., Evaluation of four approaches for ""sentiment analysis on movie reviews"": The kaggle competition (2015) Proceedings of The 16th International Conference on Engineering Applications of Neural Networks (INNS) (EANN’15), p. 5. , https://doi.org/10.1145/2797143.2797182, ACM, New York, NY, USA, Article; Loughran, T., McDonald, B., When is a liability not a liability? textual analysis, dictionaries, and 10-ks (2011) The Journal of Finance, 66 (1), pp. 35-65. , 2011; Maas, A.L., Daly, R.E., Pham, P.T., Huang, D., Ng, A.Y., Potts, C., Learning word vectors for sentiment analysis (2011) Proceedings of The 49th Annual Meeting of The Association for Computational Linguistics: Human Language Technologies, pp. 142-150. , http://www.aclweb.org/anthology/P11-1015, Association for Computational Linguistics, Portland, Oregon, USA; Manning, C., Surdeanu, M., Bauer, J., Finkel, J., Bethard, S., McClosky, D., The stanford corenlp natural language processing toolkit (2014) Proceedings of 52nd Annual Meeting of The Association for Computational Linguistics: System Demonstrations, pp. 55-60; Newell, A., Potharaju, R., Xiang, L., Nita-Rotaru, C., On the practicality of integrity attacks on document-level sentiment analysis (2014) Proceedings of The 2014 Workshop on Artificial Intelligent and Security Workshop (AISec’14), pp. 83-93. , https://doi.org/10.1145/2666652.2666661, ACM, New York, NY, USA; Nielsen, F.Å., (2011) A New ANEW: Evaluation of A Word List for Sentiment Analysis in Microblogs, , arXiv preprint 2011; Pang, B., Lee, L., Opinion mining and sentiment analysis (2008) Foundations and Trends® in Information Retrieval, 2 (1-2), pp. 1-135. , 2008; Petitcolas, F.A.P., Kerckhoffs⇔ principle (2011) Encyclopedia of Cryptography and Security, p. 675. , Springer; Polanyi, L., Zaenen, A., Contextual valence shifters (2006) Computing Attitude and Affect in Text: Theory and Applications, pp. 1-10. , Springer; Sahami, M., Dumais, S., Heckerman, D., Horvitz, E., A Bayesian approach to filtering junk e-mail (1998) Learning for Text Categorization: Papers from The 1998 Workshop, 62, pp. 98-105; Shearer, C., The crisp-dm model: The new blueprint for data mining (2000) Journal of Data Warehousing, 5 (4), pp. 13-22. , 2000; Spatiotis, N., Paraskevas, M., Perikos, I., Mporas, I., Examining the impact of feature selection on sentiment analysis for the Greek language (2017) Speech and Computer, pp. 353-361. , Alexey Karpov, Rodmonga Potapova, and Iosif Mporas (Eds.). Springer International Publishing, Cham; Taboada, M., Brooke, J., Tofiloski, M., Voll, K., Stede, M., Lexicon-based methods for sentiment analysis (2011) Computational Linguistics, 37 (2), pp. 267-307. , 2011; Tetlock, P.C., Does public financial news resolve asymmetric information? (2010) The Review of Financial Studies, 23 (9), pp. 3520-3557. , 2010; Tetlock, P.C., Saar-Tsechansky, M., Macskassy, S., More than words: Quantifying language to measure firms⇔ fundamentals (2008) The Journal of Finance, 63 (3), pp. 1437-1467. , 2008; Turney, P.D., Thumbs up or thumbs down?: Semantic orientation applied to unsupervised classification of reviews (2002) Proceedings of The 40th Annual Meeting on Association for Computational Linguistics, pp. 417-424. , Association for Computational Linguistics; Zhou, Y., Kantarcioglu, M., Thuraisingham, B., Xi, B., Adversarial support vector machine learning (2012) Proceedings of The 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 1059-1067. , ACM; Zielinski, A., Middleton, S.E., Tokarchuk, L.N., Wang, X., Social media text mining and network analysis for decision support in natural crisis management (2013) ISCRAM",,,"Hellenic Artificial Intelligence Society (EETN);University of Patras (UOP);University of Thessaly","Association for Computing Machinery","10th Hellenic Conference on Artificial Intelligence, SETN 2018","9 July 2018 through 12 July 2018",,137907,,9781450364331,,,"English","ACM Int. Conf. Proc. Ser.",Conference Paper,"Final","",Scopus,2-s2.0-85052027242
"Wang Z.","56102987300;","Deep Learning-Based Intrusion Detection with Adversaries",2018,"IEEE Access","6",,"8408779","38367","38384",,89,"10.1109/ACCESS.2018.2854599","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049809355&doi=10.1109%2fACCESS.2018.2854599&partnerID=40&md5=a5ad0010114c177d2f807776e46c06d9","National Institute of Standards and Technology, Gaithersburg, MD  20899, United States","Wang, Z., National Institute of Standards and Technology, Gaithersburg, MD  20899, United States","Deep neural networks have demonstrated their effectiveness in most machine learning tasks, with intrusion detection included. Unfortunately, recent research found that deep neural networks are vulnerable to adversarial examples in the image classification domain, i.e., they leave some opportunities for an attacker to fool the networks into misclassification by introducing imperceptible changes to the original pixels in an image. The vulnerability raises some concerns in applying deep neural networks in security-critical areas, such as intrusion detection. In this paper, we investigate the performances of the state-of-the-art attack algorithms against deep learning-based intrusion detection on the NSL-KDD data set. The vulnerabilities of neural networks employed by the intrusion detection systems are experimentally validated. The roles of individual features in generating adversarial examples are explored. Based on our findings, the feasibility and applicability of the attack methodologies are discussed. © 2013 IEEE.","classification algorithms; data security; Intrusion detection; neural networks","Artificial intelligence; Data mining; Deep neural networks; Feature extraction; Job analysis; Learning algorithms; Learning systems; Measurement; Network security; Neural networks; Perturbation techniques; Security of data; Classification algorithm; Individual features; Misclassifications; Perturbation method; Recent researches; Security-critical; State of the art; Task analysis; Intrusion detection",,,,,"Shone, N., Ngoc, T.N., Phai, V.D., Shi, Q., A deep learning approach to network intrusion detection (2018) IEEE Trans. Emerg. Topics Comput. Intell, 2 (1), pp. 41-50. , Feb; Yin, C., Zhu, Y., Fei, J., He, X., A deep learning approach for intru-sion detection using recurrent neural networks (2017) IEEE Access, 5, pp. 21954-21961; Javaid, A., Niyaz, Q., Sun, W., Alam, M., A deep learning approach for network intrusion detection system (2015) Proc. 9th EAI Int. Conf. Bio-Inspired Inf. Commun. Technol. (BICT), pp. 21-26; Tang, T.A., Mhamdi, L., McLernon, D., Zaidi, S.A.R., Ghogho, M., Deep learning approach for network intrusion detection in software de-ned networking (2016) Proc. Int. Conf. Wireless Netw. Mobile Com-mun. (WINCOM), pp. 258-263. , Oct; LeCun, Y., Backpropagation applied to handwritten zip code recog-nition (1989) Neural Comput, 1 (4), pp. 541-551; Szegedy, C., (2013) Intriguing Properties of Neural Networks, , https://arxiv.org/abs/1312.6199; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , https://arxiv.org/abs/1412.6572; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , https://arxiv.org/abs/1607.02533; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2015) Proc. IEEE Eur. Symp. Secur. Privacy, pp. 372-387. , Nov; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., DeepFool: A simple and accurate method to fool deep neural networks (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 2574-2582. , Jun; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Proc. IEEE Symp. Secur. Privacy, pp. 39-57. , Mar; Tavallaee, M., Bagheri, E., Lu, W., Ghorbani, A., A detailed analysis of the KDD CUP 99 data set (2009) Proc. IEEE Symp. Comput. Intell. Secur. Defense Appl. (CISDA), pp. 1-6. , Jul; http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html, KDD Cup 99 Dataset. Accessed: Apr. 21, 2018; http://www.unb.ca/cic/research/datasets/nsl.html, NSL-KDD Dataset. Accessed: Apr. 21, 2018; https://www.Tensor-ow.org, TensorFlow. Accessed: Apr. 21, 2018","Wang, Z.; National Institute of Standards and TechnologyUnited States; email: zhengwang98@gmail.com",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85049809355
"Hemberg E., Zipkin J.R., Skowyra R.W., Wagner N., O'Reilly U.-M.","19638760600;56199320200;36148435300;57213479876;6602579515;","Adversarial co-evolution of aack and defense in a segmented computer network environment",2018,"GECCO 2018 Companion - Proceedings of the 2018 Genetic and Evolutionary Computation Conference Companion",,,,"1648","1655",,8,"10.1145/3205651.3208287","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051552106&doi=10.1145%2f3205651.3208287&partnerID=40&md5=10f5193ffef7808d3d633efd24063ade","MIT, CSAIL, Cambridge, MA, United States; MIT Lincoln Laboratory, Lexington, MA, United States","Hemberg, E., MIT, CSAIL, Cambridge, MA, United States; Zipkin, J.R., MIT Lincoln Laboratory, Lexington, MA, United States; Skowyra, R.W., MIT Lincoln Laboratory, Lexington, MA, United States; Wagner, N., MIT Lincoln Laboratory, Lexington, MA, United States; O'Reilly, U.-M., MIT Lincoln Laboratory, Lexington, MA, United States","In computer security, guidance is slim on how to prioritize or con-gure the many available defensive measures, when guidance is available at all. We show how a competitive co-evolutionary algorithm framework can identify defensive congurations that are eective against a range of attackers. We consider network segmentation, a widely recommended defensive strategy, deployed against the threat of serial network security attacks that delay the mission of the network's operator. We employ a simulation model to investigate the eectiveness over time of dierent defensive strategies against dierent attack strategies. For a set of four network topologies, we generate strong availability attack patterns that were not identied a priori. Then, by combining the simulation with a coevolutionary algorithm to explore the adversaries' action spaces, we identify eective congurations that minimize mission delay when facing the attacks. The novel application of co-evolutionary computation to enterprise network security represents a step toward course-of-action determination that is robust to responses by intelligent adversaries. © 2018 Copyright held by the owner/author(s). Publication rights licensed to the Association for Computing Machinery.","Co-evolution; Cybersecurity; Evolutionary algorithms; Network","Calculations; Evolutionary algorithms; Networks (circuits); Co-evolution; Co-evolutionary algorithm; Computer network environment; Cyber security; Defensive measures; Defensive strategies; Enterprise networks; Network segmentation; Network security",,,,,"(2017) State of The Internet Quarterly Security Reports, , https://www.akamai.com/us/en/about/our-thinking/state-of-the-internet-report/global-state-of-the-internet-security-ddos-attack-reports.jsp, 2017; Bongard, J.C., Lipson, H., Nonlinear system identication using coevolution of models and tests (2005) IEEE Transactions on Evolutionary Computation, 9 (4), pp. 361-384. , 2005; Bronk, C., Tikk-Ringas, E., The cyber attack on saudi aramco (2013) Survival, 55 (2), pp. 81-96. , 2013; Ficici, S.G., (2004) Solution Concepts in Coevolutionary Algorithms, , Ph.D. Dissertation. Citeseer; Garcia, D., Erb Lugo, A., Hemberg, E., O'Reilly, U., Investigating coevolutionary archive based genetic algorithms on cyber defense networks (2017) Proceedings of The 19th Annual Conference on Genetic and Evolutionary Computation (GECCO'17), p. 8. , https://doi.org/10.475/1234, ACM; Gezelter, R., E-commerce and Web server safeguards (2015) Computer Security Handbook, , 6th ed.), Seymour Bosworth, Michel E. Kalbay, and Eric Whyne (Eds.). Wiley; Harper, R., Evolving robocode tanks for Evo robocode (2014) Genetic Programming and Evolvable Machines, 15 (4), pp. 403-431. , 2014; Lange, M., Kott, A., Ben-Asher, N., Mees, W., Baykal, N., Vidu, C.-M., Merialdo, M., Mada-Har, B., (2017) Recommendations for Model-Driven Paradigms for Integrated Approaches to Cyber Defense, , arXiv preprint 2017; McClure, S., Scambray, J., Kurtz, G., (2009) Hacking Exposed: Network Security Secrets and Solutions, , 2009; Miconi, T., Why coevolution doesnâĂŹt ""work"": Superiority and progress in coevolution (2009) European Conference on Genetic Programming, pp. 49-60. , Springer Berlin Heidelberg; (2013) IAD'S Top 10 Information Assurance Mitigation Strategies, , National Security Agency Information Assurance Directorate. 2013; O'Neill, M., Ryan, C., (2003) Grammatical Evolution: Evolutionary Automatic Programming in An Arbitrary Language, 4. , Springer; Popovici, E., Bucci, A., Paul Wiegand, R., De Jong, E.D., Coevolutionary principles (2012) Handbook of Natural Computing, pp. 987-1033. , Springer; Roque, A., (2018) Validating Computer Security Models, , arXiv preprint 2018; Rush, G., Tauritz, D.R., Kent, A.D., Coevolutionary agent-based network defense lightweight event system (CANDLES) (2015) Proceedings of The Companion Publication of The 2015 on Genetic and Evolutionary Computation Conference, pp. 859-866. , ACM; Saltzer, J.H., Schroeder, M.D., The protection of information in computer systems (1975) Proc. IEEE, 63 (9), pp. 1278-1308. , 1975; Tambe, M., (2012) Security and Game Theory: Algorithms, Deployed Systems, Lessons Learned, , Ed. Cambridge University Press; Thompson, B., Morris-King, J., Cam, H., Controlling risk of data exltration in cyber networks due to stealthy propagating malware (2016) Military Communications Conference, MILCOM 2016-2016 IEEE, pp. 479-484. , IEEE; Wagner, N., Şahin, C.Ş., Pena, J., Riordan, J., Neu-Mayer, S., Capturing the security eects of network segmentation via a continuous-time Markov chain model (2017) Proceedings of The 50th Annual Simulation Symposium, , ACM; Wagner, N., Şahin, C.Ş., Winterrose, M., Riordan, J., Hanson, D., Peña, J., Streilein, W.W., Quantifying the mission impact of network-level cyber defensive mitigations (2016) The Journal of Defense Modeling and Simulation: Applications, Methodology, Technology, , 2016; Whigham, P.A., Dick, G., Maclaurin, J., Owen, C.A., Examining the best of both worlds of grammatical evolution (2015) Proceedings of The 2015 on Genetic and Evolutionary Computation Conference, pp. 1111-1118. , ACM; Winterrose, M.L., Carter, K.M., Strategic evolution of adversaries against temporal platform diversity active cyber defenses (2014) Proceedings of The 2014 Symposium on Agent Directed Simulation, 9. , Society for Computer Simulation International; Yu, S., Gu, G., Barnawi, A., Guo, S., Stojmenovic, I., Malware propagation in large-scale networks (2015) IEEE Transactions on Knowledge and Data Engineering, 27 (1), pp. 170-179. , 2015",,,"et al.;Nature Research;Sentient;SparkCognition;Springer;Uber AI Labs","Association for Computing Machinery, Inc","2018 Genetic and Evolutionary Computation Conference, GECCO 2018","15 July 2018 through 19 July 2018",,137917,,9781450357647,,,"English","GECCO Companion - Proc. Genet. Evol. Comput. Conf. Companion",Conference Paper,"Final","",Scopus,2-s2.0-85051552106
"Quiring E., Arp D., Rieck K.","56875387900;55947768800;14016551700;","Forgotten Siblings: Unifying Attacks on Machine Learning and Digital Watermarking",2018,"Proceedings - 3rd IEEE European Symposium on Security and Privacy, EURO S and P 2018",,,,"488","502",,27,"10.1109/EuroSP.2018.00041","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050729012&doi=10.1109%2fEuroSP.2018.00041&partnerID=40&md5=bb586ec7f67c18f915287616d8558a9d","Technische Universitat Braunschweig, Brunswick, Germany","Quiring, E., Technische Universitat Braunschweig, Brunswick, Germany; Arp, D., Technische Universitat Braunschweig, Brunswick, Germany; Rieck, K., Technische Universitat Braunschweig, Brunswick, Germany","Machine learning is increasingly used in securitycritical applications, such as autonomous driving, face recognition, and malware detection. Most learning methods, however, have not been designed with security in mind and thus are vulnerable to different types of attacks. This problem has motivated the research field of adversarial machine learning that is concerned with attacking and defending learning methods. Concurrently, a separate line of research has tackled a very similar problem: In digital watermarking, a pattern is embedded in a signal in the presence of an adversary. As a consequence, this research field has also extensively studied techniques for attacking and defending watermarking methods. The two research communities have worked in parallel so far, unnoticeably developing similar attack and defense strategies. This paper is a first effort to bring these communities together. To this end, we present a unified notation of blackbox attacks against machine learning and watermarking. To demonstrate its efficacy, we apply concepts from watermarking to machine learning and vice versa. We show that countermeasures from watermarking can mitigate recent model-extraction attacks and, similarly, that techniques for hardening machine learning can fend off oracle attacks against watermarks. We further demonstrate a novel threat for watermarking schemes based on recent deep learning attacks from adversarial learning. Our work provides a conceptual link between two research fields and thereby opens novel directions for improving the security of both, machine learning and digital watermarking. © 2018 IEEE.","Adversarial Learning; adversarial machine learning; Adversarial Signal Processing; Digital Watermarking; Machine Learning","Artificial intelligence; Deep learning; Digital watermarking; Face recognition; Learning systems; Malware; Watermarking; Adversarial learning; Autonomous driving; Hardening machine; Malware detection; Research communities; Security-critical; Watermarking methods; Watermarking schemes; E-learning",,,,,"Barni, M., Comesaña-Alfaro, P., Pérez-González, F., Tondi, B., Are you threatening me?: Towards smart detectors in watermarking (2014) Proceedings of SPIE, 9028; Barni, M., Pérez-González, F., Coping with the enemy: Advances in adversary-aware signal processing (2013) IEEE International Conference on Acoustics, Speech, and Signal Processing, pp. 8682-8686; Barni, M., Pérez-González, F., Comesaña, P., Bartoli, G., Putting reproducible signal processing into practice: A case study in watermarking (2007) International Conference on Acoustics Speech and Signal Processing (ICASSP), pp. 1261-1264; Bas, P., Westfeld, A., Two key estimation techniques for the broken arrows watermarking scheme (2009) Proc. of ACM Workshop on Multimedia and Security, pp. 1-8; Biggio, B., Corona, I., He, Z., Chan, P.P.K., Giacinto, G., Yeung, D.S., Roli, F., One-and-a-half-class multiple classifier systems for secure learning against evasion attacks at test time (2015) Proc. of International Workshop on Multiple Classifier Systems (MCS); Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndić, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Machine Learning and Knowledge Discovery in Databases, pp. 387-402. , Springer; Biggio, B., Fumera, G., Roli, F., Adversarial pattern classification using multiple classifiers and randomisation (2008) Structural Syntactic, and Statistical Pattern Recognition, pp. 500-509. , Springer; Biggio, B., Nelson, B., Laskov, P., Support vector machines under adversarial label noise (2011) Proc. of Asian Conference on Machine Learning (ACML), pp. 97-112; Biggio, B., Nelson, B., Laskov, P., Poisoning attacks against support vector machines (2012) Proc. of International Conference on Machine Learning (ICML); Carlini, N., Wagner, D.A., Towards evaluating the robustness of neural networks (2017) Proc. of IEEE Symposium on Security and Privacy, pp. 39-57; Choubassi, M.E., Moulin, P., On the fundamental tradeoff between watermark detection performance and robustness against sensitivity analysis attacks (2006) Proceedings of SPIE, 6072, pp. 1-12; Choubassi, M.E., Moulin, P., Noniterative algorithms for sensitivity analysis attacks (2007) IEEE Transactions on Information Forensics and Security, 2 (2), pp. 113-126; Choubassi, M.E., Moulin, P., On reliability and security of randomized detectors against sensitivity analysis attacks (2009) IEEE Transactions on Information Forensics and Security, 4 (3), pp. 273-283; Comesaña, P., Pérez-Freire, L., Pérez-González, F., Blind Newton sensitivity attack (2006) IEE Proceedings - Information Security, 153 (3), pp. 115-125; Comesaña, P., Pérez-González, F., Breaking the BOWS watermarking system: Key guessing and sensitivity attacks (2007) EURASIP Journal on Information Security, 2007 (1); Cox, I.J., Linnartz, J.-P.M.G., Public watermarks and resistance to tampering (1997) Proc. of IEEE International Conference on Image Processing (ICIP), pp. 26-29; Cox, I.J., Miller, M., Bloom, J., Fridrich, J., Kalker, T., (2002) Digital Watermarking and Steganography, , Morgan Kaufmann Publishers; Craver, S., Yu, J., Reverse-engineering a detector with false alarms (2007) Proceedings of SPIE, 6505, p. 65050C; Dalvi, N.N., Domingos, P., Sanghai, K.M.S., Verma, D., Adversarial classification (2004) Proc. of International Conference on Knowledge Discovery and Data Mining (KDD), pp. 99-108; Dang, H., Huang, Y., Chang, E.-C., Evading classifiers by morphing in the dark (2017) Proc. of ACM Conference on Computer and Communications Security (CCS), pp. 119-133; Dang-Nguyen, D.-T., Pasquini, C., Conotter, V., Boato, G., RAISE: A raw images dataset for digital image forensics (2015) 6th ACM Multimedia Systems Conference, pp. 219-224; Duda, R., Hart, P.E., Stork, D.G., (2001) Pattern Classification, , 2nd ed. John Wiley & Sons; Fogla, P., Lee, W., Evading network anomaly detection systems: Formal reasoning and practical techniques (2006) Proc. of ACM Conference on Computer and Communications Security (CCS), pp. 59-68; Fogla, P., Sharif, M., Perdisci, R., Kolesnikov, O., Lee, W., Polymorphic blending attacks (2006) Proc. of USENIX Security Symposium, pp. 241-256; Furon, T., Bas, P., Broken arrows (2008) EURASIP Journal on Information Security, 2008, pp. 1-13; Furon, T., Macq, B., Hurley, N., Silvestre, G., JANIS: Just another N-order side-informed watermarking scheme (2002) Proc. of IEEE International Conference on Image Processing (ICIP), 3, pp. 153-156; Furon, T., Venturini, I., Duhamel, P., Unified approach of asymmetric watermarking schemes (2001) Proceedings of SPIE, 4314, pp. 269-279; Gloe, T., Böhme, R., The Dresden Image Database for benchmarking digital image forensics (2010) Journal of Digital Forensic Practice, 3 (2-4), pp. 150-159; Grosse, K., Papernot, N., Manoharan, P., Backes, M., McDaniel, P., Adversarial perturbations against deep neural networks for malware classification (2016) Computing Research Repository (CoRR), Tech. Rep. Abs/1606.04435; Hastie, T., Tibshirani, R., Friedman, J., (2001) The Elements of Statistical Learning: Data Mining, Inference and Prediction, ser, , Springer series in statistics. New York, N.Y.: Springer; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I.P., Tygar, J.D., Adversarial machine learning (2011) Proc. of ACM Workshop on Artificial Intelligence and Security (AISEC), pp. 43-58; Kalker, T., Linnartz, J.-P.M.G., Van Dijk, M., Watermark estimation through detector analysis (1998) Proc. of IEEE International Conference on Image Processing (ICIP), pp. 425-429; Kapravelos, A., Shoshitaishvili, Y., Cova, M., Kruegel, C., Vigna, G., Revolver: An automated approach to the detection of evasive webbased malware (2013) Proc. of USENIX Security Symposium, pp. 637-651. , Aug; Levinson, J., Askeland, J., Becker, J., Dolson, J., Held, D., Kammel, S., Kolter, J.Z., Thrun, S., Towards fully autonomous driving: Systems and algorithms (2011) Proc. of IEEE Intelligent Vehicles Symposium (IV), pp. 163-168; Liao, X., Yuan, K., Wang, X., Li, Z., Xing, L., Beyah, R.A., Acing the ioc game: Toward automatic discovery and analysis of open-source cyber threat intelligence (2016) Proc. of ACM Conference on Computer and Communications Security (CCS), pp. 755-766; Linnartz, J.-P.M.G., Van Dijk, M., Analysis of the sensitivity attack against electronic watermarks in images (1998) Proc. of Information Hiding Conference, 1525, pp. 258-272; Lowd, D., Meek, C., Good word attacks on statistical spam filters (2005) Conference on Email and Anti-Spam; Lowd, D., Meek, C., Adversarial learning (2005) Proc. of ACM SIGKDD Conference on Knowledge Discovery in Data Mining (KDD), pp. 641-647; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., MNIST Adversarial Examples Challenge, , https://github.com/MadryLab/mnistchallenge, last visited February 2018; Mansour, M.F., Tewfik, A.H., Improving the security of watermark public detectors (2002) Proc. of International Conference on Digital Signal Processing (DSP), pp. 59-66; Mansour, M.F., Tewfik, A.H., LMS-based attack on watermark public detectors (2002) Proc. of International Conference on Image Processing (ICIP), pp. 649-652; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples, , Tech. Rep; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) Proc. of ACM Asia Conference on Computer Computer and Communications Security (ASIA CCS), pp. 506-519; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Proc. of IEEE European Symposium on Security and Privacy (EuroS&P); Papernot, N., McDaniel, P., Sinha, A., Wellman, M.P., SoK: Security and privacy in machine learning (2018) Proc. of IEEE European Symposium on Security and Privacy (EuroS&P); Perdisci, R., Gu, G., Lee, W., Using an ensemble of one-class SVM classifiers to harden payload-based anomaly detection systems (2006) Proc. of International Conference on Data Mining (ICDM), pp. 488-498; Piva, A., Barni, M., Design and analysis of the first BOWS contest (2007) EURASIP Journal on Information Security, 2007, pp. 31-37; Russu, P., Demontis, A., Biggio, B., Fumera, G., Roli, F., Secure kernel machines against evasion attacks (2016) Proc. of ACM Workshop on Artificial Intelligence and Security (AISEC), pp. 59-69; Schölkopf, B., Smola, A.J., (2002) Learning with Kernels, , Cambridge MA: MIT Press; Schroff, F., Kalenichenko, D., Philbin, J., Facenet: A unified embedding for face recognition and clustering (2015) Proc. of IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 815-823; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proc. of ACM Conference on Computer and Communications Security (CCS), pp. 1528-1540; Shokri, R., Stronati, M., Song, C., Shmatikov, V., Membership inference attacks against machine learning models (2017) Proc. of IEEE Symposium on Security and Privacy (S&P); Song, Y., Locasto, M.E., Stavrou, A., Stolfo, S.J., On the infeasibility of modeling polymorphic shellcode (2007) Proc. of ACM Conference on Computer and Communications Security (CCS), pp. 541-551; Srndic, N., Laskov, P., Practical evasion of a learning-based classifier: A case study (2014) Proc. of IEEE Symposium on Security and Privacy, pp. 197-211; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R., Intriguing properties of neural networks (2013) Computing Research Repository (CoRR), Tech. Rep. Abs/1312.6199; Taigman, Y., Yang, M., Ranzato, M.A., Wolf, L., Deepface: Closing the gap to human-level performance in face verification (2014) Proc. of IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Tondi, B., Comesaña-Alfaro, P., Pérez-González, F., Barni, M., On the effectiveness of meta-detection for countering oracle attacks in watermarking (2015) Workshop on Information Forensics and Security (WIFS), pp. 1-6; Tondi, B., Comesaña-Alfaro, P., Pérez-González, F., Barni, M., Smart detection of line-search oracle attacks (2017) IEEE Transactions on Information Forensics and Security, 12 (3), pp. 588-603; Tramér, F., Zhang, F., Juels, A., Reiter, M.K., Ristenpart, T., Stealing machine learning models via prediction apis (2016) Proc. of USENIX Security Symposium, pp. 601-618; Venkatesan, R., Jakubowski, M.H., Randomized detection for spread-spectrum watermarking: Defending against sensitivity and other attacks (2005) Proc. of IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), 2, pp. 9-12; Venturini, I., Oracle attacks and covert channels (2005) Proc. of International Workshop on Digital Watermarking, 3710, pp. 171-185; Šrndić, N., Laskov, P., Practical evasion of a learning-based classifier: A case study (2014) Proc. of IEEE Symposium on Security and Privacy; Wang, K., Parekh, J.J., Stolfo, S.J., Anagram: A content anomaly detector resistant to mimicry attack (2006) Proc. of International Symposium on Recent Advances in Intrusion Detection (RAID), pp. 226-248; Adversarial Attacks and Defences, , https://www.kaggle.com/nips-2017-adversarial-learning-competition, last visited January 2018; (2008) BOWS-2 Web Page, , http://bows2.ec-lille.fr/, last visited August 2017; (2012) Pornographic Films on BitTorrent: Flava Works Gets Huge Damages, , http://www.bbc.co.uk/news/technology-20178171, last visited August 2017; Westfeld, A., A workbench for the BOWS contest (2008) EURASIP Journal on Information Security, 2007 (1), p. 064521; Westfeld, A., Fast determination of sensitivity in the presence of countermeasures in BOWS-2 (2009) International Workshop on Information Hiding, pp. 89-101. , Springer; Xu, W., Qi, Y., Evans, D., Automatically evading classifiers: A case study on pdf malware classifiers (2016) Proc. of Network and Distributed System Security Symposium (NDSS); Zhu, Z., Liang, D., Zhang, S., Huang, X., Li, B., Hu, S., Traffic-sign detection and classification in the wild (2016) Proc. of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",,,"Facebook;Google;Hyperledger;The Turing Institute","Institute of Electrical and Electronics Engineers Inc.","3rd IEEE European Symposium on Security and Privacy, EURO S and P 2018","24 April 2018 through 26 April 2018",,137873,,9781538642276,,,"English","Proc. - IEEE Eur. Symp. Secur. Priv., Euro S P",Conference Paper,"Final","",Scopus,2-s2.0-85050729012
"Papernot N., McDaniel P., Sinha A., Wellman M.P.","56732917800;7006537016;52063804200;7005153459;","SoK: Security and Privacy in Machine Learning",2018,"Proceedings - 3rd IEEE European Symposium on Security and Privacy, EURO S and P 2018",,,,"399","414",,133,"10.1109/EuroSP.2018.00035","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050721582&doi=10.1109%2fEuroSP.2018.00035&partnerID=40&md5=f8bea7af4041c5e45849fb22041ac9ba","Pennsylvania State University, United States; University of Michigan, United States","Papernot, N., Pennsylvania State University, United States; McDaniel, P., Pennsylvania State University, United States; Sinha, A., University of Michigan, United States; Wellman, M.P., University of Michigan, United States","Advances in machine learning (ML) in recent years have enabled a dizzying array of applications such as data analytics, autonomous systems, and security diagnostics. ML is now pervasive - new systems and models are being deployed in every domain imaginable, leading to widespread deployment of software based inference and decision making. There is growing recognition that ML exposes new vulnerabilities in software systems, yet the technical community's understanding of the nature and extent of these vulnerabilities remains limited. We systematize findings on ML security and privacy, focusing on attacks identified on these systems and defenses crafted to date.We articulate a comprehensive threat model for ML, and categorize attacks and defenses within an adversarial framework. Key insights resulting from works both in the ML and security communities are identified and the effectiveness of approaches are related to structural elements of ML algorithms and the data used to train them. In particular, it is apparent that constructing a theoretical understanding of the sensitivity of modern ML algorithms to the data they analyze, à la PAC theory, will foster a science of security and privacy in ML. © 2018 IEEE.","machine learning; privacy; security","Artificial intelligence; Data privacy; Decision making; Autonomous systems; security; Security and privacy; Security community; Software systems; Structural elements; Technical community; Threat modeling; Learning systems",,,,,"House, W., Preparing for the future of artificial intelligence (2016) Executive Office of the President, National Science and Technology Council, Committee on Technology; Pfleeger, C.P., Pfleeger, S.L., (2012) Analyzing Computer Security: A Threat/Vulnerability/Countermeasure Approach, , Prentice Hall; Amodei, D., Olah, C., Steinhardt, J., Christiano, P., Schulman, J., Mané, D., (2016) Concrete Problems in AI Safety; Ohrimenko, O., Schuster, F., Fournet, C., Mehta, A., Nowozin, S., Vaswani, K., Costa, M., Oblivious multi-party machine learning on trusted processors (2016) 25th USENIX Security Symposium; Murphy, K.P., (2012) Machine Learning: A Probabilistic Perspective, , MIT Press; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Sutskever, I., Vinyals, O., Le, Q.V., Sequence to sequence learning with neural networks (2014) Advances in Neural Information Processing Systems, pp. 3104-3112; Drucker, H., Wu, D., Vapnik, V.N., Support vector machines for spam categorization (1999) IEEE Transactions on Neural Networks, 10 (5), pp. 1048-1054; Jain, A.K., Murty, M.N., Flynn, P.J., Data clustering: A review (1999) ACM Computing Surveys, 31 (3), pp. 264-323; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images; Erhan, D., Bengio, Y., Courville, A., Manzagol, P.-A., Vincent, P., Bengio, S., Why does unsupervised pre-training help deep learning? (2010) Journal of Machine Learning Research, 11, pp. 625-660; Chandola, V., Banerjee, A., Kumar, V., Anomaly detection: A survey (2009) ACM Computing Surveys, 41 (3), pp. 151-1558; Hu, J., Wellman, M.P., Nash Q-learning for general-sum stochastic games (2003) Journal of Machine Learning Research, 4, pp. 1039-1069; Sutton, R.S., Barto, A.G., (1998) Reinforcement Learning: An Introduction, , MIT Press; Silver, D., Huang, A., Maddison, C.J., Guez, A., Sifre, L., Mastering the game of Go with deep neural networks and tree search (2016) Nature, 529 (7587), pp. 484-489; Bishop, C.M., Pattern recognition (2006) Machine Learning; Goodfellow, I., Bengio, Y., Courville, A., (2016) Deep Learning, , www.deeplearningbook.org), Book in preparation for MIT Press; Altman, N.S., An introduction to kernel and nearest-neighbor nonparametric regression (1992) The American Statistician, 46 (3), pp. 175-185; Barreno, M., Nelson, B., Sears, R., Joseph, A.D., Tygar, J.D., Can machine learning be secure? (2006) ACM Symposium on Information, Computer and Communications Security, pp. 16-25; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I., Tygar, J., Adversarial machine learning (2011) 4th ACM Workshop on Security and Artificial Intelligence, pp. 43-58; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) 1st IEEE European Symposium on Security and Privacy; Kloft, M., Laskov, P., Online anomaly detection under adversarial impact (2010) 13th International Conference on Artificial Intelligence and Statistics, pp. 405-412; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) 23rd ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., (2016) Practical Black-box Attacks Against Deep Learning Systems Using Adversarial Examples; Šrndić, N., Laskov, P., Practical evasion of a learning-based classifier: A case study (2014) IEEE Symposium on Security and Privacy, pp. 197-211; Bolton, R.J., Hand, D.J., Statistical fraud detection: A review (2002) Statistical Science, 17, pp. 235-249; Rindfleisch, T.C., Privacy, information technology, and health care (1997) Communications of the ACM, 40 (8), pp. 92-100; Fredrikson, M., Jha, S., Ristenpart, T., Model inversion attacks that exploit confidence information and basic countermeasures (2015) 22nd ACM SIGSAC Conference on Computer and Communications Security, pp. 1322-1333; Shokri, R., Stronati, M., Shmatikov, V., (2016) Membership Inference Attacks Against Machine Learning Models; Powers, D.M., Evaluation: From precision, recall and F-measure to ROC, informedness, markedness and correlation (2011) Journal of Machine Learning Technologies, 2, pp. 37-63; Kearns, M., Li, M., Learning in the presence of malicious errors (1993) SIAM Journal on Computing, 22 (4), pp. 807-837; Globerson, A., Roweis, S., Nightmare at test time: Robust learning by feature deletion (2006) 23rd International Conference on Machine Learning, pp. 353-360; Manwani, N., Sastry, P.S., Noise tolerance under risk minimization (2013) IEEE Transactions on Cybernetics, 43 (3), pp. 1146-1151; Nelson, B., Joseph, A.D., Bounding an attack's complexity for a simple learning model (2006) First Workshop on Tackling Computer Systems Problems with Machine Learning Techniques; Hulten, G., Spencer, L., Domingos, P., Mining time-changing data streams (2001) 7th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 97-106; Biggio, B., Nelson, B., Laskov, P., Support vector machines under adversarial label noise (2011) Asian Conference on Machine Learning, pp. 97-112; Mozaffari-Kermani, M., Sur-Kolay, S., Raghunathan, A., Jha, N.K., Systematic poisoning attacks on and defenses for machine learning in healthcare (2015) IEEE Journal of Biomedical and Health Informatics, 19 (6), pp. 1893-1905; Xiao, H., Xiao, H., Eckert, C., Adversarial label flips attack on support vector machines (2012) 20th European Conference on Artificial Intelligence, pp. 870-875; Vapnik, V.N., (1998) Statistical Learning Theory, , Wiley; Biggio, B., Rieck, K., Ariu, D., Wressnegger, C., Corona, I., Giacinto, G., Roli, F., Poisoning behavioral malware clustering (2014) Workshop on Artificial Intelligence and Security, pp. 27-36; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndić, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Machine Learning and Knowledge Discovery in Databases, pp. 387-402. , Springer; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) 3d International Conference on Learning Representations; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Alfeld, S., Zhu, X., Barford, P., Data poisoning attacks against autoregressive models (2016) 30th AAAI Conference on Artificial Intelligence, pp. 1452-1458; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy, pp. 39-57; Hayes, J., Melis, L., Danezis, G., De Cristofaro, E., (2017) Logan: Evaluating Privacy Leakage of Generative Models Using Generative Adversarial Networks; Ateniese, G., Mancini, L.V., Spognardi, A., Villani, A., Vitali, D., Felici, G., Hacking smart machines with smarter ones: How to extract meaningful data from machine learning classifiers (2015) International Journal of Security and Networks, 10 (3), pp. 137-150; Grosse, K., Papernot, N., Manoharan, P., Backes, M., McDaniel, P., Adversarial perturbations against deep neural networks for malware classification (2017) 22nd European Symposium on Research in Computer Security; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World; Xu, W., Qi, Y., Evans, D., Automatically evading classifiers: A case study on PDF malware classifiers (2016) Network and Distributed Systems Symposium; Fredrikson, M., Lantz, E., Jha, S., Lin, S., Page, D., Ristenpart, T., Privacy in pharmacogenetics: An end-to-end case study of personalized warfarin dosing (2014) 23rd USENIX Security Symposium, pp. 17-32; Tramér, F., Zhang, F., Juels, A., Reiter, M.K., Ristenpart, T., Stealing machine learning models via prediction APIs (2016) 25th USENIX Security Symposium, pp. 601-618; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples; Liu, Y., Chen, X., Liu, C., Song, D., (2016) Delving into Transferable Adversarial Examples and Black-box Attacks; Biggio, B., Nelson, B., Pavel, L., Poisoning attacks against support vector machines (2012) 29th International Conference on Machine Learning; Mei, S., Zhu, X., Using machine teaching to identify optimal training-set attacks on machine learners (2015) AAAI, pp. 2871-2877; Xiao, H., Biggio, B., Brown, G., Fumera, G., Eckert, C., Roli, F., Is feature selection secure against training data poisoning? (2015) Proceedings of the 32nd International Conference on Machine Learning (ICML-15), pp. 1689-1698; Behzadan, V., Munir, A., (2017) Vulnerability of Deep Reinforcement Learning to Policy Induction Attacks; Newsome, J., Karp, B., Song, D., Polygraph: Automatically generating signatures for polymorphic worms (2005) Security and Privacy, 2005 IEEE Symposium on, pp. 226-241. , IEEE; Perdisci, R., Dagon, D., Lee, W., Fogla, P., Sharif, M., Misleading worm signature generators using deliberate noise injection (2006) Security and Privacy, 2006 IEEE Symposium on, p. 15. , IEEE; Hinton, G., Vinyals, O., Dean, J., Distilling the knowledge in a neural network (2014) NIPS-14 Workshop on Deep Learning and Representation Learning; Liu, D.C., Nocedal, J., On the limited memory bfgs method for large scale optimization (1989) Mathematical Programming, 45 (1-3), pp. 503-528; LeCun, Y., Cortes, C., (1998) The Mnist Database of Handwritten Digits; Huang, R., Xu, B., Schuurmans, D., Szepesvari, C., (2015) Learning with A Strong Adversary; Warde-Farley, D., Goodfellow, I., Adversarial perturbations of deep neural networks (2016) Advanced Structured Prediction, , T. Hazan, G. Papandreou, and D. Tarlow, Eds; Tramér, F., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2017) The Space of Transferable Adversarial Examples; Huang, S., Papernot, N., Goodfellow, I., Duan, Y., Abbeel, P., (2017) Adversarial Attacks on Neural Network Policies; Wittel, G.L., Wu, S.F., On attacking statistical spam filters (2004) CEAS; Lowd, D., Meek, C., Good word attacks on statistical spam filters (2005) CEAS; Vorobeychik, Y., Li, B., Optimal randomized classification in adversarial settings (2014) 13th International Conference on Autonomous Agents and Multi-Agent Systems, pp. 485-492; Lowd, D., Meek, C., Adversarial learning (2005) Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining. ACM, pp. 641-647; Nelson, B., Rubinstein, B.I., Huang, L., Joseph, A.D., Lee, S.J., Rao, S., Tygar, J., Query strategies for evading convex-inducing classifiers (2012) Journal of Machine Learning Research, 13, pp. 1293-1332; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, pp. 2672-2680; McSherry, F., (2016) Statistical Inference Considered Harmful, , https://github.com/frankmcsherry/blog/blob/master/posts/2016-06-14.md; Zeiler, M.D., Fergus, R., Visualizing and understanding convolutional networks (2014) Computer Vision-ECCV 2014, pp. 818-833. , Springer; Rubinstein, B.I.P., Nelson, B., Huang, L., Joseph, A.D., Lau, S.-H., Rao, S., Taft, N., Tygar, J.D., Antidote: Understanding and defending against poisoning of anomaly detectors (2009) 9th ACM SIGCOMM Conference on Internet Measurement, pp. 1-14; Stempfel, G., Ralaivola, L., Learning SVMs from sloppily labeled data (2009) International Conference on Artificial Neural Networks, pp. 884-893. , Springer; Xu, L., Crammer, K., Schuurmans, D., Robust support vector machine training via convex outlier ablation (2006) Twenty-First AAAI National Conference on Artificial Intelligence, 6, pp. 536-542; Kerckhoffs, A., La cryptographie militaire (1883) Journal des Sciences Militaires, pp. 5-83; Steinhardt, J., Koh, P.W., Liang, P., (2017) Certified Defenses for Data Poisoning Attacks; Gu, S., Rigazio, L., Towards deep neural network architectures robust to adversarial examples (2015) Proceedings of the 2015 International Conference on Learning Representations. Computational and Biological Learning Society; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Proceedings of the 37th IEEE Symposium on Security and Privacy, , IEEE; Papernot, N., McDaniel, P., (2016) On the Effectiveness of Defensive Distillation; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., (2015) Rethinking the Inception Architecture for Computer Vision; Warde-Farley, D., Goodfellow, I., Adversarial perturbations of deep neural networks (2016) Advanced Structured Prediction, , T. Hazan, G. Papandreou, and D. Tarlow, Eds; Li, Y., Gal, Y., (2017) Dropout Inference in Bayesian Neural Networks with Alpha-divergences; Dwork, C., Roth, A., The algorithmic foundations of differential privacy (2014) Foundations and Trends in Theoretical Computer Science, 9 (3-4), pp. 211-407; Kasiviswanathan, S.P., Lee, H.K., Nissim, K., Raskhodnikova, S., Smith, A., What can we learn privately? (2011) SIAM Journal on Computing, 40 (3), pp. 793-826; Erlingsson, U., Pihur, V., Korolova, A., Rappor: Randomized aggregatable privacy-preserving ordinal response (2014) 21st ACM SIGSAC Conference on Computer and Communications Security, pp. 1054-1067; Chaudhuri, K., Monteleoni, C., Sarwate, A.D., Differentially private empirical risk minimization (2011) Journal of Machine Learning Research, 12, pp. 1069-1109. , no. Mar; Bassily, R., Smith, A., Thakurta, A., (2014) Differentially Private Empirical Risk Minimization: Efficient Algorithms and Tight Error Bounds; Shokri, R., Shmatikov, V., Privacy-preserving deep learning (2015) 22nd ACM SIGSAC Conference on Computer and Communications Security, pp. 1310-1321; Abadi, M., Chu, A., Goodfellow, I., McMahan, H.B., Mironov, I., Talwar, K., Zhang, L., Deep learning with differential privacy (2016) 23rd ACM SIGSAC Conference on Computer and Communications Security, pp. 308-318; Hamm, J., Cao, P., Belkin, M., (2016) Learning Privately from Multiparty Data; Papernot, N., Abadi, M., Erlingsson, U., Goodfellow, I., Talwar, K., (2016) Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data; Rivest, R.L., Adleman, L., Dertouzos, M.L., On data banks and privacy homomorphisms (1978) Foundations of Secure Computation, 4 (11), pp. 169-180; Gilad-Bachrach, R., Dowlin, N., Laine, K., Lauter, K., Naehrig, M., Wernsing, J., Cryptonets: Applying neural networks to encrypted data with high throughput and accuracy (2016) Proceedings of the 33rd International Conference on Machine Learning, pp. 201-210; Consortium, I.W.P., Estimation of the warfarin dose with clinical and pharmacogenetic data (2009) N Engl J Med, 2009 (360), pp. 753-764; Goodman, B., Flaxman, S., (2016) European Union Regulations on Algorithmic Decision-making and A"" Right to Explanation; Kleinberg, J., Mullainathan, S., Raghavan, M., (2016) Inherent Tradeoffs in the Fair Determination of Risk Scores; Kusner, M.J., Loftus, J.R., Russell, C., Silva, R., (2017) Counterfactual Fairness; Barocas, S., Selbst, A.D., Big data's disparate impact (2016) California Law Review, 104; Zafar, M.B., Valera, I., Gomez Rodriguez, M., Gummadi, K.P., (2017) Fairness Constraints: Mechanisms for Fair Classification; Kearns, M., Fair algorithms for machine learning (2017) Proceedings of the 2017 ACM Conference on Economics and Computation, p. 1. , ACM; Corbett-Davies, S., Pierson, E., Feller, A., Goel, S., Huq, A., Algorithmic decision making and the cost of fairness (2017) Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 797-806. , ACM; Dwork, C., Hardt, M., Pitassi, T., Reingold, O., Zemel, R., Fairness through awareness (2012) Proceedings of the 3rd Innovations in Theoretical Computer Science Conference, pp. 214-226. , ACM; Edwards, H., Storkey, A., (2015) Censoring Representations with An Adversary; Stock, P., Cisse, M., (2017) Convnets and Imagenet beyond Accuracy: Explanations, Bias Detection, Adversarial Examples and Model Criticism; Letham, B., Rudin, C., McCormick, T.H., Madigan, D., Interpretable classifiers using rules and Bayesian analysis: Building a better stroke prediction model (2015) The Annals of Applied Statistics, 9 (3), pp. 1350-1371; Ribeiro, M.T., Singh, S., Guestrin, C., Why should i trust you?: Explaining the predictions of any classifier (2016) Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 1135-1144. , ACM; Datta, A., Sen, S., Zick, Y., Algorithmic transparency via quantitative input influence (2016) Proceedings of 37th IEEE Symposium on Security and Privacy; Koh, P.W., Liang, P., (2017) Understanding Black-box Predictions Via Influence Functions; Erhan, D., Bengio, Y., Courville, A., Vincent, P., Visualizing higher-layer features of a deep network (2009) University of Montreal, 1341; Mahendran, A., Vedaldi, A., Visualizing deep convolutional neural networks using natural pre-images (2016) International Journal of Computer Vision, pp. 1-23",,,"Facebook;Google;Hyperledger;The Turing Institute","Institute of Electrical and Electronics Engineers Inc.","3rd IEEE European Symposium on Security and Privacy, EURO S and P 2018","24 April 2018 through 26 April 2018",,137873,,9781538642276,,,"English","Proc. - IEEE Eur. Symp. Secur. Priv., Euro S P",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85050721582
"Beigi G., Shu K., Zhang Y., Liu H.","56465110300;57192389892;36109723600;7409751811;","Securing social media user data - An adversarial approach",2018,"HT 2018 - Proceedings of the 29th ACM Conference on Hypertext and Social Media",,,,"165","173",,15,"10.1145/3209542.3209552","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051560711&doi=10.1145%2f3209542.3209552&partnerID=40&md5=b2fe6c46beb6ea2a36bf07ce548e1e8a","Arizona State University, United States","Beigi, G., Arizona State University, United States; Shu, K., Arizona State University, United States; Zhang, Y., Arizona State University, United States; Liu, H., Arizona State University, United States","Social media users generate tremendous amounts of data. To better serve users, it is required to share the user-related data among researchers, advertisers and application developers. Publishing such data would raise more concerns on user privacy. To encourage data sharing and mitigate user privacy concerns, a number of anonymization and de-anonymization algorithms have been developed to help protect privacy of social media users. In this work, we propose a new adversarial attack specialized for social media data.We further provide a principled way to assess effectiveness of anonymizing different aspects of social media data. Our work sheds light on new privacy risks in social media data due to innate heterogeneity of user-generated data which require striking balance between sharing user data and protecting user privacy. © 2018 Association for Computing Machinery.",,"Hypertext systems; Social networking (online); Anonymization; Application developers; Data Sharing; Privacy risks; Social media; Social media datum; Social media users; User-generated; Data privacy",,,,,"Abawajy, J.H., Hafez Ninggal, M.I., Herawan, T., Privacy preserving social network data publication (1974) IEEE Communications Surveys & Tutorials, 18 (3); Backstrom, L., Dwork, C., Kleinberg, J., Wherefore art thou r3579x?: Anonymized social networks, hidden patterns, and structural steganography (2007) Proceedings of International Conference on World Wide Web., , ACM; Beigi, G., Jalili, M., Alvari, H., Sukthankar, G., Leveraging community detection for accurate trust prediction (2014) ASE International Conference on Social Computing, , Palo Alto, CA, May 2014; Beigi, G., Liu, H., Similar but different: Exploiting users' congruity for recommendation systems (2018) International Conference on Social Computing, Behavioral-Cultural Modeling, and Prediction., , Springer; Beigi, G., Tang, J., Liu, H., Signed link analysis in social media networks (2016) 10th International Conference onWeb and Social Media, ICWSM, , 2016. AAAI Press; Beigi, G., Tang, J., Wang, S., Liu, H., Exploiting emotional information for trust/distrust prediction (2016) Proceedings of the 2016 SIAM International Conference on Data Mining. SIAM, pp. 81-89; Beretta, V., Maccagnola, D., Cribbin, T., Messina, E., An interactive method for inferring demographic attributes in Twitter (2015) Proceedings of the 26th ACM Conference on Hypertext & Social Media, , ACM; Buades, A., Coll, B., Morel, J.-M., A non-local algorithm for image denoising (2005) Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on, 2, pp. 60-65. , IEEE; Crandall, D., Cosley, D., Huttenlocher, D., Kleinberg, J., Suri, S., Feedback effects between similarity and social influence in online communities (2008) Proceedings of ACM SIGKDD, pp. 160-168; Dwork, C., Differential privacy: A survey of results (2008) International Conference on Theory and Applications of Models of Computation., pp. 1-19. , Springer; Fu, H., Zhang, A., Xie, X., Effective social graph deanonymization based on graph structure and descriptive information (2015) ACM Transactions on Intelligent Systems and Technology (TIST), 6 (4), p. 49. , 2015); Hajibagheri, A., (2017) Learning Dynamic Network Models for Complex Social Systems., , 2017; Hajibagheri, A., Sukthankar, G., Lakkaraju, K., Extracting information from negative interactions in multiplex networks using mutual information (2017) International Conference on Social Computing, Behavioral-Cultural Modeling and Prediction and Behavior Representation in Modeling and Simulation., pp. 322-328. , Springer; Hajibagheri, A., Sukthankar, G., Lakkaraju, K., Alvari, H., Rolf T Wigand, Agarwal, N., Using massively multiplayer online game data to analyze the dynamics of social interactions (2018) Social Interactions in Virtual Worlds An Interdisciplinary Perspective, , Cambridge University Press; Hay, M., Miklau, G., Jensen, D., Weis, P., Srivastava, S., Anonymizing social networks (2007) Computer Science Department Faculty Publication Series, 180. , 2007); Ji, S., Li, W., Mittal, P., SecGraph: A uniform and opensource evaluation system for graph data anonymization and de-anonymization (2015) 24th USENIX Security Symposium (USENIX Security, 15; Ji, S., Li, W., Srivatsa, M., Beyah, R., Structural data de-anonymization: Quantification practice and implications Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security; Ji, S., Li, W., Srivatsa, M., He, J.S., Beyah, R., General graph data de-anonymization: From mobility traces to social networks (2016) ACM Transactions on Information and System Security (TISSEC) (2016; Ji, S., Mittal, P., Beyah, R., Graph data anonymization de-anonymization attacks and de-anonymizability quantification: A survey (2016) IEEE Communications Surveys & Tutorials, , 2016; Liu, K., Terzi, E., Towards identity anonymization on graphs (2008) Proceedings of international conference on Management of data., , ACM; McPherson, M., Lynn Smith-Lovin, Cook, J.M., Birds of a feather: Homophily in social networks (2001) Annual Review of Sociology, 27 (1), pp. 415-444. , 2001); Narayanan, A., Shi, E., Rubinstein, B.I.P., Link prediction by de-anonymization: Howwewon the kaggle social network challenge (2011) Neural Networks (IJCNN), The 2011 International Joint Conference on. IEEE, pp. 1825-1834; Narayanan, A., Shmatikov, V., Robust de-anonymization of large sparse datasets (2008) IEEE Symposium on Security and Privacy. IEEE; Narayanan, A., Shmatikov, V., De-anonymizing social networks (2009) Security and Privacy, 2009 30th IEEE Symposium on. IEEE, pp. 173-187; Nilizadeh, S., Kapadia, A., Ahn, Y.-Y., Community-enhanced de-anonymization of online social networks (2014) Proceedings of the 2014 ACM sigsac conference on Computer and Communications Security, pp. 537-548. , ACM; Pedarsani, P., Figueiredo, D.R., Grossglauser, M., A Bayesian method for matching two similar graphs without seeds (2013) Communication, Control, and Computing (Allerton, , IEEE; Puttaswamy, K.P.N., Wang, S., Steinbauer, T., Agrawal, D., El Abbadi, A., Kruegel, C., Zhao, B.Y., Preserving location privacy in geosocial applications (2014) IEEE Transactions on Mobile Computing; Qian, J., Li, X.-Y., Zhang, C., Chen, L., Deanonymizing social networks and inferring private attributes using knowledge graphs (2016) INFOCOM International Conference on Computer Communications; Sala, A., Zhao, X., Wilson, C., Zheng, H., Zhao, B.Y., Sharing graphs using differentially private graph models (2011) Proceedings of the 2011 ACM SIGCOMM Conference on Internet Measurement Conference; Sharad, K., True friends let you down: Benchmarking social graph anonymization schemes (2016) Proceedings of Workshop on Artificial Intelligence and Security., , ACM; Shu, K., Wang, S., Tang, J., Zafarani, R., Liu, H., User identity linkage across online social networks: A review (2017) ACM SIGKDD Explorations Newsletter, 18 (2), pp. 5-17. , 2017); Sweeney, L., K-anonymity: A model for protecting privacy (2002) International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems; Tassa, T., Cohen, D.J., Anonymization of centralized and distributed social networks by sequential clustering (2013) IEEE Transactions on Knowledge and Data Engineering, 25 (2), pp. 311-324. , 2013); Wu, X., Ying, X., Liu, K., Chen, L., A survey of privacypreservation of graphs and social networks (2010) Managing and Mining Graph Data, pp. 421-453. , 2010); Yartseva, L., Grossglauser, M., On the performance of percolation graph matching (2013) Proceedings of the First ACM Conference on Online Social Networks, pp. 119-130. , ACM; Ying, X., Wu, X., Graph generation with prescribed feature constraints (2009) Proceedings of SDM., , SIAM; Zhou, B., Pei, J., Preserving privacy in social networks against neighborhood attacks (2008) Proceedings of International Conference on Data Engineering",,,"ACM SIGWEB","Association for Computing Machinery, Inc","29th ACM International Conference on Hypertext and Social Media, HT 2018","9 July 2018 through 12 July 2018",,137934,,9781450354271,,,"English","HT - Proc. ACM Conf. Hypertext Soc. Media",Conference Paper,"Final","",Scopus,2-s2.0-85051560711
"Zhang X., Shan S., Tang S., Zheng H., Zhao B.Y.","57192189429;57202050635;57192202734;7403440632;7403058954;","Penny auctions are predictable: Predicting and profiling user behavior on dealdash",2018,"HT 2018 - Proceedings of the 29th ACM Conference on Hypertext and Social Media",,,,"123","127",,1,"10.1145/3209542.3209576","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051470228&doi=10.1145%2f3209542.3209576&partnerID=40&md5=d3e5ee1fac99c8f0cf3a9b2675e8aec8","UC Santa Barbara, United States; University of Chicago, United States","Zhang, X., UC Santa Barbara, United States; Shan, S., University of Chicago, United States; Tang, S., UC Santa Barbara, United States; Zheng, H., University of Chicago, United States; Zhao, B.Y., University of Chicago, United States","We study user behavior and the predictability of penny auctions, auction sites often criticized for misrepresenting themselves as lowprice auction marketplaces. Using a 166-day trace of 134,568 auctions involving 174 million bids on DealDash, the largest penny auction site in service, we show that a) both the timing and source of bids are highly predictable, and b) users are easily classified into clear behavioral groups by their bidding behavior, and such behaviors correlate highly with the eventual profitability of their bidding strategies. This suggests that penny auction sites are vulnerable to modeling and adversarial attacks. © 2018 Association for Computing Machinery.","Clustering; Online auctions; Sequence prediction; User behavior","Commerce; Hypertext systems; Social networking (online); Auction sites; Bidding behavior; Bidding strategy; Clustering; Online auctions; Sequence prediction; User behaviors; Behavioral research",,,,,"(2017) DealDash, , https://dealdash.com/, (October 2017; Angst, C.M., Agarwal, R., Kuruzovich, J., Bid or buy? Individual shopping traits as predictors of strategic exit in on-line auctions (2008) International Journal of Electronic Commerce, 13 (1), pp. 59-84. , 2008); Augenblick, N., The sunk-cost fallacy in penny auctions (2015) The Review of Economic Studies, 83 (1), pp. 58-86. , 2015); Backus, M., Blake, T., Masterov, D.V., Tadelis, S., Is sniping a problem for online auction markets? (2015) Proc. of WWW; Bapna, R., Goes, P., Gupta, A., Jin, Y., User heterogeneity and its impact on electronic auction market design: An empirical exploration (2004) Mis Quarterly, pp. 21-43. , 2004); Bradlow, E.T., Park, Y.-H., Bayesian estimation of bid sequences in internet auctions using a generalized record-breaking model (2007) Marketing Science, 26 (2), pp. 218-229. , 2007); Brown, P.F., Desouza, P.V., Mercer, R.L., Pietra, V.J.D., Lai, J.C., Class-based n-gram models of natural language (1992) Computa- tional linguistics, 18 (4), pp. 467-479. , 1992); Byers, J.W., Mitzenmacher, M., Zervas, G., Information asymmetries in pay-per-bid auctions (2010) Proc. of ACM EC; Collinson, P., Six auction sites' ads banned over misleading savings claims (2017) The Guardian, , https://www.theguardian.com/money/2017/feb/22/auction-sites-ads-banned-claims-madbid-asa, (February 2017; Easley, R.F., Tenorio, R., Jump bidding strategies in internet auctions (2004) Management Science, 50 (10), pp. 1407-1419. , 2004); Ghani, R., Price prediction and insurance for online auctions (2005) Proc. of KDD; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural computation, 9 (8), pp. 1735-1780. , 1997); Jank, W., Shmueli, G., Wang, S., Dynamic, real-time forecasting of online auctions via functional models (2006) Proc. of KDD; Kaufman, L., Rousseeuw, P.J., (2009) Finding Groups in Data: An Introduction to Cluster Analysis., 344. , John Wiley & Sons; Konkel, D.R., Costing a pretty penny: Online penny auctions revive the pestilence of unregulated lotteries (2012) Seattle University Law Review, 36, p. 1967. , 2012); Newman, M.E.J., Modularity and community structure in networks (2006) PNAS, 103 (23), pp. 8577-8582. , 2006); Park, Y.-H., Bradlow, E.T., An integrated model for bidding behavior in Internet auctions: Whether, who, when, and how much (2005) Journal of Marketing Research, 42 (4), pp. 470-482. , 2005); Platt, B.C., Price, J., Tappen, H., The role of risk preferences in pay-to-bid auctions (2013) Management Science, 59 (9), pp. 2117-2134. , 2013); Roth, A.E., Ockenfels, A., Last-minute bidding and the rules for ending second-price auctions: Evidence from eBay and Amazon auctions on the Internet (2002) American Economic Review, 92 (4), pp. 1093-1103. , 2002); Trevathan, J., Read, W., Detecting shill bidding in online English auctions (2009) Handbook of research on social and organizational liabilities in information security, 46, pp. 446-470. , 2009); Van Heijst, D., Potharst, R., Van Wezel, M., A support system for predicting eBay end prices (2008) Decision Support Systems, 44 (4), pp. 970-982. , 2008); Wang, S., Jank, W., Shmueli, G., Explaining and forecasting online auction prices and their dynamics using functional data analysis (2008) Journal of Business & Economic Statistics, 26 (2), pp. 144-160. , 2008); Wang, Z., Minbo, Xu., Selling a dollar for more than a dollar? Evidence from online penny auctions (2016) Information Economics and Policy, 36, pp. 53-68. , 2016)",,,"ACM SIGWEB","Association for Computing Machinery, Inc","29th ACM International Conference on Hypertext and Social Media, HT 2018","9 July 2018 through 12 July 2018",,137934,,9781450354271,,,"English","HT - Proc. ACM Conf. Hypertext Soc. Media",Conference Paper,"Final","All Open Access, Bronze",Scopus,2-s2.0-85051470228
"Shi Y., Sagduyu Y.E., Erpek T., Davaslioglu K., Lu Z., Li J.H.","36141159700;6507416617;36100030900;36343287800;54983839500;37100868400;","Adversarial deep learning for cognitive radio security: Jamming attack and defense strategies",2018,"2018 IEEE International Conference on Communications Workshops, ICC Workshops 2018 - Proceedings",,,,"1","6",,44,"10.1109/ICCW.2018.8403655","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050306231&doi=10.1109%2fICCW.2018.8403655&partnerID=40&md5=81f038c81b5715f5250019adeef3b013","Intelligent Automation, Inc., Rockville, MD  20855, United States; University of South Florida, Tampa, FL  33620, United States","Shi, Y., Intelligent Automation, Inc., Rockville, MD  20855, United States; Sagduyu, Y.E., Intelligent Automation, Inc., Rockville, MD  20855, United States; Erpek, T., Intelligent Automation, Inc., Rockville, MD  20855, United States; Davaslioglu, K., Intelligent Automation, Inc., Rockville, MD  20855, United States; Lu, Z., University of South Florida, Tampa, FL  33620, United States; Li, J.H., Intelligent Automation, Inc., Rockville, MD  20855, United States","This paper presents an adversarial machine learning approach to launch jamming attacks on wireless communications and introduces a defense strategy. In a cognitive radio network, a transmitter senses channels, identifies spectrum opportunities, and transmits data to its receiver in idle channels. On the other hand, an attacker may also sense channels, identify busy channels and aim to jam transmissions of legitimate users. In a dynamic system with complex channel, traffic and interference characteristics, the transmitter applies some pre-trained machine learning algorithm to classify a channel as idle or busy. This classifier is unknown to the attacker that senses a channel, captures the transmitter's decisions by tracking the acknowledgments and applies deep learning (in form of an exploratory attack, i.e., inference attack) to build a classifier that is functionally equivalent to the one at the transmitter. This approach is shown to support the attacker to reliably predict successful transmissions based on the sensing results and effectively jam these transmissions. Then, a defense scheme is developed against adversarial deep learning by exploiting the sensitivity of deep learning to training errors. The transmitter deliberately takes a small number of wrong actions (in form of a causative attack, i.e., poisoning attack, launched against the attacker) when it accesses the spectrum. The objective is to prevent the attacker from building a reliable classifier. For that purpose, the attacker systematically selects when to take wrong actions to balance the conflicting effects of deceiving the attacker and making correct transmission decisions. This defense scheme successfully fools the attacker into making prediction errors and allows the transmitter to sustain its performance against intelligent jamming attacks. © 2018 IEEE.","Adversarial machine learning; Cognitive radio; Deep learning; Defense; Exploratory attack; Jamming attack","Artificial intelligence; Cognitive radio; Jamming; Learning algorithms; Network security; Radio transmission; Secure communication; Transmitters; Wireless telecommunication systems; Cognitive radio network; Cognitive radio securities; Defense; Exploratory attack; Interference characteristics; Jamming attacks; Machine learning approaches; Wireless communications; Deep learning",,,,,"Clancy, C., Stuntebeck, H.J., O'Shea, T., Applications of machine learning to cognitive radio networks (2007) IEEE Wireless Communications, 14 (4), pp. 47-52; Thilina, K., Choi, K.W., Saquib, N., Hossain, E., Machine learning techniques for cooperative spectrum sensing in cognitive radio networks (2013) IEEE Journal on Selected Areas in Communications, 31 (11), pp. 2209-2221; Chen, M., Challita, U., Saad, W., Yin, C., Debbah, M., (2017) Machine Learning for Wireless Networks with Artificial Intelligence: A Tutorial on Neural Networks; Alsheikh, M., Lin, S., Niyato, D., Tan, H., Machine learning in wireless sensor networks: Algorithms, strategies, and applications (2014) IEEE Communications Surveys &Tutorials, 16 (4), pp. 1996-2018. , Apr; O'Shea, T., Corgan, J., Clancy, C., Convolutional radio modulation recognition networks (2016) International Conference on Engineering Applications of Neural Networks; Lee, W., Kim, M., Cho, D., Schober, R., (2017) Deep Sensing: Cooperative Spectrum Sensing Based on Convolutional Neural Networks; Davaslioglu, K., Sagduyu, Y.E., Generative adversarial learning for spectrum sensing (2018) IEEE International Conference on Communications (ICC); Ateniese, G., Mancini, L., Spognardi, A., Villani, A., Vitali, D., Felici, G., Hacking smart machines with smarter ones: How to extract meaningful data from machine learning classifiers (2015) International Journal of Security and Networks, 10 (3), pp. 137-150; Tramer, F., Zhang, F., Juels, A., Reiter, M., Ristenpart, T., Stealing machine learning models via prediction apis (2016) USENIX Security; Fredrikson, M., Jha, S., Ristenpart, T., Model inversion attacks that exploit confidence information and basic countermeasures (2015) ACM SIGSAC Conference on Computer and Communications Security; Shi, Y., Sagduyu, Y.E., Grushin, A., How to steal a machine learning classifier with deep learning (2017) IEEE Symposium on Technologies for Homeland Security, , May; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Srndic, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) ECML PKDD; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2016) IEEE European Symposium on Security and Privacy; Pi, L., Lu, Z., Sagduyu, Y., Chen, S., Defending active learning against adversarial inputs in automated document classification (2016) IEEE Global Conference on Signal and Information Processing (GlobalSIP); Shi, Y., Sagduyu, Y.E., Evasion and causative attacks with adversarial deep learning (2017) IEEE Military Communications Conference; Sagduyu, Y.E., Berry, R., Ephremides, A., Jamming games in wireless networks with incomplete information (2011) IEEE Communications Magazine, 49 (8). , Aug; https:.docs.microsoft.com/enus/cognitive-toolkit, Microsoft Cognitive Toolkit (CNTK)",,,"Cisco;et al.;Huawei;National Instruments;Qualcomm;Sprint","Institute of Electrical and Electronics Engineers Inc.","2018 IEEE International Conference on Communications Workshops, ICC Workshops 2018","20 May 2018 through 24 May 2018",,137742,,9781538643280,,,"English","IEEE Int. Conf. Commun. Workshops, ICC Workshops - Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85050306231
"Yi Z., Li S., Yu J., Tan Y., Wu Q.","57193609760;36634432600;57209187003;7402139872;8454790400;","A Novel Misclassification Attack Against Black Box Neural Network Classifiers",2018,"Proceedings - 2018 14th International Conference on Semantics, Knowledge and Grids, SKG 2018",,,"8703949","38","45",,1,"10.1109/SKG.2018.00013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065759537&doi=10.1109%2fSKG.2018.00013&partnerID=40&md5=5e516c8f3e0df1f7b9a85b0235fb2de9","National University of Defense Technology, College of Computer, Changsha, Hunan Province, China","Yi, Z., National University of Defense Technology, College of Computer, Changsha, Hunan Province, China; Li, S., National University of Defense Technology, College of Computer, Changsha, Hunan Province, China; Yu, J., National University of Defense Technology, College of Computer, Changsha, Hunan Province, China; Tan, Y., National University of Defense Technology, College of Computer, Changsha, Hunan Province, China; Wu, Q., National University of Defense Technology, College of Computer, Changsha, Hunan Province, China","It is generally believed that neural network classifiers are vulnerable to misclassification attacks. An adversary generates adversarial samples by adding small perturbations to the original samples. These adversarial samples will mislead classifiers, although they are almost the same as the original samples from the perspective of human observation. However, the existing misclassification attacks need either the details of classifier or a fake classifier to craft the adversarial samples. One may think a black box classifier is robust enough against misclassification attacks. We demonstrate that black box classifier is still vulnerable to our proposed misclassification attack. We conceal the details of classifier. The only thing an adversary can do is to query samples' classification results. We proposed a particle swarm optimization based misclassification attack. Using this attack an adversary can make black box classifiers yield erroneous results. The experiments show that LeNet and GoogLeNet are vulnerable to our proposed attack. The misclassification rate on MNIST and ImageNet ILSVRC 2012 dataset are 99.1% and 98.4%. Finally, we give some defense strategies against misclassification attacks. © 2018 IEEE.","adversarial samples; black box attack; misclassification attack; neural network classifier; particle swarm optimization","Semantics; Black boxes; Classification results; Defense strategy; Human observations; Misclassification rates; Misclassifications; Neural network classifier; Small perturbations; Particle swarm optimization (PSO)",,,,,"Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) Cvpr; Luong, M.-T., Pham, H., Manning, C.D., (2015) Effective Approaches to Attention-based Neural Machine Translation, , arXiv preprint arXiv: 1508. 04025; Collobert, R., Weston, J., A unified architecture for natural language processing: Deep neural networks with multitask learning (2008) Proceedings of the 25th International Conference on Machine Learning. ACM, pp. 160-167; Mikolov, T., Corrado, G., Chen, K., Dean, J., Mikolov, T., Corrado, G., Chen, K., Dean, J., Efficient estimation of word representations in vector space (2013) International Conference on Learning Representations, pp. 1-12; Liu, S., Tang, B., Chen, Q., Wang, X., Drug-drug interaction extraction via convolutional neural networks (2016) Computational and Mathematical Methods in Medicine, 2016; Yi, Z., Li, S., Yu, J., Tan, Y., Wu, Q., Yuan, H., Wang, T., Drug-drug interaction extraction via recurrent neural network with multiple attention layers (2017) International Conference on Advanced Data Mining and Applications, pp. 554-566. , Springer; Dahl, G.E., Stokes, J.W., Deng, L., Yu, D., Largescale malware classification using random projections and neural networks (2013) Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference On. IEEE, pp. 3422-3426; Yuan, Z., Lu, Y., Wang, Z., Xue, Y., Droid-sec: Deep learning in android malware detection (2014) ACM SIGCOMM Computer Communication Review, 44 (4), pp. 371-372. , ACM; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Srndíc, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 387-402. , Springer; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint arXiv: 1412. 6572; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 427-436; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium On. IEEE, pp. 372-387; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security. ACM, pp. 506-519; Moosavi Dezfooli, S.M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , EPFLCONF-218057; Narodytska, N., Kasiviswanathan, S., Simple black-box adversarial attacks on deep neural networks (2017) Computer Vision and Pattern Recognition Workshops, pp. 1310-1318; Dang, H., Huang, Y., Chang, E.C., Evading classifiers by morphing in the dark (2017) ACM Sigsac Conference, pp. 119-133; Su, J., Vargas, D.V., Kouichi, S., (2017) One Pixel Attack for Fooling Deep Neural Networks, , arXiv preprint arXiv: 1710. 08864; Kim, Y.-H., Lee, K.H., Yoon, Y., Visualizing the search process of particle swarm optimization (2009) Proceedings of the 11th Annual Conference on Genetic and Evolutionary Computation. ACM, pp. 49-56; Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G.S., Devin, M., (2016) Tensorflow: Large-scale Machine Learning on Heterogeneous Distributed Systems, , arXiv preprint arXiv: 1603. 04467; LeCun, Y., Haffner, P., Bottou, L., Bengio, Y., Object recognition with gradient-based learning (1999) Shape, Contour and Grouping in Computer Vision, pp. 319-345. , Springer; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., Imagenet: A large-scale hierarchical image database (2009) Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference On. IEEE, pp. 248-255",,,"Chinese Academy of Sciences;Guangzhou University;Institute of Computing Technology (ICT), Chinese Academy of Sciences;National Basic Research Program of China","Institute of Electrical and Electronics Engineers Inc.","14th International Conference on Semantics, Knowledge and Grids, SKG 2018","12 September 2018 through 14 September 2018",,147692,,9781728104416,,,"English","Proc. - Int. Conf. Semant., Knowl. Grids, SKG",Conference Paper,"Final","",Scopus,2-s2.0-85065759537
"Agarwal A., Singh R., Vatsa M., Ratha N.","57188752637;15061841400;55908650100;6603955463;","Are image-agnostic universal adversarial perturbations for face recognition difficult to detect?",2018,"2018 IEEE 9th International Conference on Biometrics Theory, Applications and Systems, BTAS 2018",,,"8698548","","",,19,"10.1109/BTAS.2018.8698548","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065444304&doi=10.1109%2fBTAS.2018.8698548&partnerID=40&md5=42b28f1a168e1d4a11d9f56454454cb7","IIIT-Delhi, India; IBM, Watson, TJ, United States","Agarwal, A., IIIT-Delhi, India, IBM, Watson, TJ, United States; Singh, R., IIIT-Delhi, India, IBM, Watson, TJ, United States; Vatsa, M., IIIT-Delhi, India, IBM, Watson, TJ, United States; Ratha, N., IIIT-Delhi, India, IBM, Watson, TJ, United States","High performance of deep neural network based systems have attracted many applications in object recognition and face recognition. However, researchers have also demonstrated them to be highly sensitive to adversarial perturbation and hence, tend to be unreliable and lack robustness. While most of the research on adversarial perturbation focuses on image specific attacks, recently, image-agnostic Universal perturbations are proposed which learn the adversarial pattern over training distribution and have broader impact on real-world security applications. Such adversarial attacks can have compounding effect on face recognition where these visually imperceptible attacks can cause mismatches. To defend against adversarial attacks, sophisticated detection approaches are prevalent but most of the existing approaches do not focus on image-agnostic attacks. In this paper, we present a simple but efficient approach based on pixel values and Principal Component Analysis as features coupled with a Support Vector Machine as the classifier, to detect image-agnostic universal perturbations. We also present evaluation metrics, namely adversarial perturbation class classification error rate, original class classification error rate, and average classification error rate, to estimate the performance of adversarial perturbation detection algorithms. The experimental results on multiple databases and different DNN architectures show that it is indeed not required to build complex detection algorithms; rather simpler approaches can yield higher detection rates and lower error rates for image agnostic adversarial perturbation. © 2018 IEEE.",,"Biometrics; Complexation; Deep neural networks; Error detection; Object recognition; Principal component analysis; Signal detection; Classification error rate; Detection algorithm; Detection approach; Detection rates; Evaluation metrics; Network based systems; Perturbation detection; Security application; Face recognition",,,,,"Akhtar, N., Liu, J., Mian, A., Defense against universal adversarial perturbations (2018) IEEE CVPR; Beveridge, J., Phillips, P., Bolme, D., Draper, B., Given, G., Lui, Y.M., Teli, M., Cheng, S., The challenge of face recognition from digital point-and-shoot cameras (2013) IEEE BTAS, pp. 1-8; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) ACM WAIC; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE S&P, pp. 39-57; Chen, P.-Y., Sharma, Y., Zhang, H., Yi, J., Hsieh, C.-J., (2017) Ead: Elastic-net Attacks to Deep Neural Networks Via Adversarial Examples; Cortes, C., Vapnik, V., Support vector machine (1995) Machine Learning, 20 (3), pp. 273-297; Cox, I., Miller, M., Bloom, J., Fridrich, J., Kalker, T., (2008) Digital Watermarking and Steganography, , Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 2 edition; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts; Founds, A.P., Orlans, N., Genevieve, W., Watson, C.I., (2011) Nist Special Databse 32-multiple Encounter Dataset II (Medsii), , NIST Interagency/Internal Report (NISTIR)-7807; Goel, A., Singh, A., Agarwal, A., Vatsa, M., Singh, R., Smartbox: Benchmarking adversarial detection and mitigation algorithms for face recognition (2018) IEEE BTAS; Gong, Z., Wang, W., Ku, W.-S., (2017) Adversarial and Clean Data Are Not Twins; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Goswami, G., Ratha, N., Agarwal, A., Singh, R., Vatsa, M., Unravelling robustness of deep learning based face recognition against adversarial attacks (2018) AAAI; Gross, R., Matthews, I., Cohn, J., Kanade, T., Baker, S., Multi-pie (2010) Image and Vision Computing, 28 (5), pp. 807-813; Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., (2017) On the (Statistical) Detection of Adversarial Examples; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) IEEE CVPR, pp. 770-778; Hendrycks, D., Gimpel, K., (2016) Early Methods for Detecting Adversarial Images; Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadarrama, S., Darrell, T., Caffe: Convolutional architecture for fast feature embedding (2014) ACM International Conference on Multimedia, pp. 675-678; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Machine Learning at Scale; Li, X., Li, F., Adversarial examples detection in deep networks with convolutional filter statistics (2017) ICCV; Liang, B., Li, H., Su, M., Li, X., Shi, W., Wang, X., (2017) Detecting Adversarial Examples in Deep Networks with Adaptive Noise Reduction; Lu, J., Issaranon, T., Forsyth, D., Safetynet: Detecting and rejecting adversarial examples robustly (2017) IEEE CVPR, pp. 446-454; Luo, Y., Boix, X., Roig, G., Poggio, T., Zhao, Q., (2015) Foveationbased Mechanisms Alleviate Adversarial Examples; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., (2017) On Detecting Adversarial Perturbations; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) IEEE CVPR; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) IEEE CVPR, pp. 2574-2582; Mopuri, K.R., Garg, U., Babu, R.V., Fast feature fool: A data independent approach to universal adversarial perturbations (2017) BMVC; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) IEEE ESSP, pp. 372-387; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) IEEE S&P, pp. 582-597. , IEEE; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) IEEE CVPR, pp. 1-9; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks; Tanay, T., Griffin, L., (2016) A Boundary Tilting Persepective on the Phenomenon of Adversarial Examples; Turk, M., Pentland, A., Eigenfaces for recognition (1991) Journal of Cognitive Neuroscience, 3 (1), pp. 71-86",,,,"Institute of Electrical and Electronics Engineers Inc.","9th IEEE International Conference on Biometrics Theory, Applications and Systems, BTAS 2018","22 October 2018 through 25 October 2018",,147636,,9781538671795,,,"English","IEEE Int. Conf. Biom. Theory, Appl. Syst., BTAS",Conference Paper,"Final","",Scopus,2-s2.0-85065444304
"Piplani T., Merill N., Chuang J.","57208642349;57208656633;7201692538;","Faking it, making it: Fooling and improving brain-based authentication with generative adversarial networks",2018,"2018 IEEE 9th International Conference on Biometrics Theory, Applications and Systems, BTAS 2018",,,"8698606","","",,8,"10.1109/BTAS.2018.8698606","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065420109&doi=10.1109%2fBTAS.2018.8698606&partnerID=40&md5=425628ee7c391c5f7a4e38105623e435","School of Information, UC Berkeley, China","Piplani, T., School of Information, UC Berkeley, China; Merill, N., School of Information, UC Berkeley, China; Chuang, J., School of Information, UC Berkeley, China","In this paper, we empirically demonstrate the vulnerability of a passthought authentication system to fake signals generated by Generative Adversarial Networks (GANs), and use these same signals to make authenticators more robust. We first train a classifier that is able to authenticate a subject based on their EEG signals. The classifier performs a binary classification task: either the user is who they claim to be, or not. To test the robustness of the authenticator against attacks we train a GAN to generate signals that mimic the EEG signals of the 'positive' subject. We find that a well-trained GAN is able to generate signals that the classifier consistently accepts. To alleviate this vulnerability, we re-train the classifier with this GAN-generated data. We find that the classifier re-trained against synthetic data is both more robust against this attack, and more accurate in accepting real data than the initial classifier. We conclude with recommendations for the design of passthought authentication systems. © 2018 IEEE.",,"Authentication; Biometrics; Classification (of information); Adversarial networks; Authentication systems; Binary classification; EEG signals; Synthetic data; Biomedical signal processing",,,,,"Bergstra, J., Bengio, Y., Random search for hyperparameter optimization (2012) J. Mach. Learn. Res., 13 (1), pp. 281-305. , Feb; Chen, T., Guestrin, C., (2016) Xgboost: A Scalable Tree Boosting System, , CoRR, abs/1603.02754; Chuang, J., Nguyen, H., Wang, C., Johnson, B., I think, therefore i am: Usability and security of authentication using brainwaves (2013) Financial Cryptography and Data Security, pp. 1-16. , In A. A. Adams, M. Brenner, and M. Smith, editors, Berlin, Heidelberg. Springer Berlin Heidelberg; Cortes, C., Vapnik, V., Support-vector networks (1995) Mach. Learn., 20 (3), pp. 273-297. , Sept; Gentleman, W.M., Sande, G., Fast fourier transforms: For fun and profit (1966) Proceedings of the November 7-10, 1966, Fall Joint Computer Conference, AFIPS '66 (Fall), pp. 563-578. , New York, NY, USA. ACM; Goodfellow, I.J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., (2014) Generative Adversarial Networks, , ArXiv e-prints, June; Hochreiter, S., The vanishing gradient problem during learning recurrent neural nets and problem solutions (1998) Int. J. Uncertain. Fuzziness Knowl.-Based Syst., 6 (2), pp. 107-116. , Apr; Chuang, J., Merrill, N., Maillart, S.T., (2015) Synchronized Brainwave Recordings from A Group Presented with A Common Audio-Visual Stimulus, , Of the UC Berkeley Spring 2015 MIDS Immersion Class; Johnson, B., Maillart, T., Chuang, J., My thoughts are not your thoughts (2014) Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct Publication, UbiComp '14 Adjunct, pp. 1329-1338. , New York, NY, USA. ACM; Li, Z., Luo, Y., (2017) Generate Identity-preserving Faces by Generative Adversarial Networks, , CoRR, abs/1706.03227; Matovu, R., Serwadda, A., Your substance abuse disorder is an open secret! gleaning sensitive personal information from templates in an EEG-based authentication system (2016) 2016 IEEE 8th International Conference on Biometrics Theory, Applications and Systems (BTAS), pp. 1-7; Merrill, N., Curran, M.T., Chuang, J., Is the future of authenticity all in our heads?: Moving passthoughts from the lab to the world (2017) Proceedings of the 2017 New Security Paradigms Workshop, NSPW 2017, pp. 70-79. , New York, NY, USA. ACM; Neurosky. Mindwave Mobile brainwave sensing headset; Palazzo, S., Spampinato, C., Kavasidis, I., Giordano, D., Shah, M., Generative adversarial networks conditioned by brain signals (2017) 2017 IEEE International Conference on Computer Vision (ICCV), pp. 3430-3438; Rumelhart, D.E., Widrow, B., Lehr, M.A., The basic ideas in neural networks (1994) Commun. ACM, 37 (3), pp. 87-92. , Mar; Schwartz, A.B., Cui, X.T., Weber, D., Moran, D.W., Brain-controlled interfaces: Movement restoration with neural prosthetics (2006) Neuron, 52 (1), pp. 205-220; Curran, M.T., Yang, J.-K., Merrill, N., Chuang, J., Passthoughts authentication with low cost eareeg (2016) Conference Proceedings: . Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Conference, 2016, pp. 1979-1982. , 08; Thorpe, J., Van Oorschot, P.C., Somayaji, A., Passthoughts: Authenticating with our minds (2005) Proceedings of the 2005 Workshop on New Security Paradigms, NSPW '05, pp. 45-56. , New York, NY, USA. ACM; Xu, B., Wang, N., Chen, T., Li, M., (2015) Empirical Evaluation of Rectified Activations in Convolutional Network, , CoRR, abs/1505.00853; Zhang, H., Patel, V.M., Riggan, B.S., Hu, S., (2017) Generative Adversarial Network-based Synthesis of Visible Faces from Polarimetric Thermal Faces, , CoRR, abs/1708.02681",,,,"Institute of Electrical and Electronics Engineers Inc.","9th IEEE International Conference on Biometrics Theory, Applications and Systems, BTAS 2018","22 October 2018 through 25 October 2018",,147636,,9781538671795,,,"English","IEEE Int. Conf. Biom. Theory, Appl. Syst., BTAS",Conference Paper,"Final","",Scopus,2-s2.0-85065420109
"Goel A., Singh A., Agarwal A., Vatsa M., Singh R.","57208645062;57208642791;57188752637;55908650100;15061841400;","SmartBox: Benchmarking adversarial detection and mitigation algorithms for face recognition",2018,"2018 IEEE 9th International Conference on Biometrics Theory, Applications and Systems, BTAS 2018",,,"8698567","","",,12,"10.1109/BTAS.2018.8698567","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065398047&doi=10.1109%2fBTAS.2018.8698567&partnerID=40&md5=75bf5b609764804aadc11c32ba9d6ef0","IIIT-Delhi, India","Goel, A., IIIT-Delhi, India; Singh, A., IIIT-Delhi, India; Agarwal, A., IIIT-Delhi, India; Vatsa, M., IIIT-Delhi, India; Singh, R., IIIT-Delhi, India","Deep learning models are widely used for various purposes such as face recognition and speech recognition. However, researchers have shown that these models are vulnerable to adversarial attacks. These attacks compute perturbations to generate images that decrease the performance of deep learning models. In this research, we have developed a toolbox, termed as SmartBox, for benchmarking the performance of adversarial attack detection and mitigation algorithms against face recognition. SmartBox is a python based toolbox which provides an open source implementation of adversarial detection and mitigation algorithms. In this research, Extended Yale Face Database B has been used for generating adversarial examples using various attack algorithms such as DeepFool, Gradient methods, Elastic-Net, and L2 attack. SmartBox provides a platform to evaluate newer attacks, detection models, and mitigation approaches on a common face recognition benchmark. To assist the research community, the code of SmartBox is made available11http://iab-rubric.org/resources/SmartBox.html. © 2018 IEEE.",,"Benchmarking; Biometrics; Deep learning; Gradient methods; Speech recognition; Attack detection; Detection models; Face recognition benchmarks; Learning models; Open source implementation; Research communities; Various attacks; Yale face database; Face recognition",,,,,"Agarwal, A., Singh, R., Vatsa, M., Ratha, N., Are imageagnostic universal adversarial perturbations for face recognition difficult to detect? (2018) IEEE BTAS; Akhtar, N., Mian, A., Threat of adversarial attacks on deep learning in computer vision: A survey (2018) IEEE Access, 6, pp. 14410-14430; Bhagoji, A.N., Cullina, D., Sitawarin, C., Mittal, P., Enhancing robustness of machine learning systems via data transformations (2018) CISS, pp. 1-5; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) ACM AISec; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE S&P, pp. 39-57; Chen, P.-Y., Sharma, Y., Zhang, H., Yi, J., Hsieh, C.-J., EAD: Elastic-net attacks to deep neural networks via adversarial examples (2018) AAAI; Cisse, M., Bojanowski, P., Grave, E., Dauphin, Y., Usunier, N., Parseval networks: Improving robustness to adversarial examples (2017) ICML, pp. 854-863; Creswell, A., Bharath, A.A., (2017) Denoising Adversarial Autoencoders, , CoRR, abs/1703.01220; Das, N., Shanbhogue, M., Chen, S.-T., Hohman, F., Chen, L., Kounavis, M.E., Chau, D.H., (2017) Keeping the Bad Guys Out: Protecting and Vaccinating Deep Learning with Jpeg Compression; Dong, Y., Liao, F., Pang, T., Su, H., Hu, X., Li, J., Zhu, J., Boosting adversarial attacks with momentum (2018) CVPR; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts; Gao, J., Wang, B., Lin, Z., Xu, W., Qi, Y., Deepcloak: Masking deep neural network models for robustness against adversarial samples (2017) ICLR; Georghiades, A., Belhumeur, P., Kriegman, D., From few to many: Illumination cone models for face recognition under variable lighting and pose (2001) TPAMI, 23 (6), pp. 643-660; Gong, Z., Wang, W., Ku, W.-S., (2017) Adversarial and Clean Data Are Not Twins; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Goswami, G., Ratha, N., Agarwal, A., Singh, R., Vatsa, M., Unravelling robustness of deep learning based face recognition against adversarial attacks (2018) AAAI; Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., (2017) On the (Statistical) Detection of Adversarial Examples; He, K., Zhang, X., Ren, S., Sun, J., Delving deep into rectifiers: Surpassing human-level performance on imagenet classification (2015) ICCV, pp. 1026-1034; Hendrik Metzen, J., Genewein, T., Fischer, V., Bischoff, B., On detecting adversarial perturbations (2017) ICLR; Hendrycks, D., Gimpel, K., (2016) Visible Progress on Adversarial Images and A New Saliency Map, , CoRR, abs/1608.00530; Lee, K., Ho, J., Kriegman, D., Acquiring linear subspaces for face recognition under variable lighting (2005) TPAMI, 27 (5), pp. 684-698; Li, X., Li, F., Adversarial examples detection in deep networks with convolutional filter statistics (2017) ICCV, 7; Liang, B., Li, H., Su, M., Li, X., Shi, W., Wang, X., (2017) Detecting Adversarial Examples in Deep Networks with Adaptive Noise Reduction; Lu, C., Tang, X., Surpassing human-level face verification performance on lfw with gaussianface (2015) AAAI, pp. 3811-3819; Lu, J., Issaranon, T., Forsyth, D., Safetynet: Detecting and rejecting adversarial examples robustly (2017) ICCV; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) CVPR, pp. 1765-1773; Dezfooli, S.M.M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) CVPR, pp. 2574-2582; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) IEEE S&P, pp. 582-597; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-ofthe-art face recognition (2016) CCS, pp. 1528-1540. , ACM; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., (2017) Adversarial Generative Nets: Neural Network Attacks on State-ofthe-art Face Recognition; Su, J., Vargas, D.V., Sakurai, K., (2017) One Pixel Attack for Fooling Deep Neural Networks, , CoRR, abs/1710.08864; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) ICLR; Wang, Q., Guo, W., Zhang, K., Ororbia, I., Alexander, G., Xing, X., Liu, X., Giles, C.L., (2016) Learning Adversary-resistant Deep Neural Networks; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., Mitigating adversarial effects through randomization (2018) ICLR",,,,"Institute of Electrical and Electronics Engineers Inc.","9th IEEE International Conference on Biometrics Theory, Applications and Systems, BTAS 2018","22 October 2018 through 25 October 2018",,147636,,9781538671795,,,"English","IEEE Int. Conf. Biom. Theory, Appl. Syst., BTAS",Conference Paper,"Final","",Scopus,2-s2.0-85065398047
"Bontrager P., Roy A., Togelius J., Memon N., Ross A.","57201402290;24336345100;55918891800;7005458042;57210541733;","DeepMasterPrints: Generating masterprints for dictionary attacks via latent variable evolution",2018,"2018 IEEE 9th International Conference on Biometrics Theory, Applications and Systems, BTAS 2018",,,"8698539","","",,57,"10.1109/BTAS.2018.8698539","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065397323&doi=10.1109%2fBTAS.2018.8698539&partnerID=40&md5=1136c62cba94e7f218f1e040729c135e","New York University Tandon, United States; Michigan State University, United States","Bontrager, P., New York University Tandon, United States; Roy, A., New York University Tandon, United States; Togelius, J., New York University Tandon, United States; Memon, N., New York University Tandon, United States; Ross, A., Michigan State University, United States","Recent research has demonstrated the vulnerability of fingerprint recognition systems to dictionary attacks based on MasterPrints. MasterPrints are real or synthetic fingerprints that can fortuitously match with a large number of fingerprints thereby undermining the security afforded by fingerprint systems. Previous work by Roy et al. generated synthetic MasterPrints at the feature-level. In this work we generate complete image-level MasterPrints known as DeepMasterPrints, whose attack accuracy is found to be much superior than that of previous methods. The proposed method, referred to as Latent Variable Evolution, is based on training a Generative Adversarial Network on a set of real fingerprint images. Stochastic search in the form of the Covariance Matrix Adaptation Evolution Strategy is then used to search for latent input variables to the generator network that can maximize the number of impostor matches as assessed by a fingerprint recognizer. Experiments convey the efficacy of the proposed method in generating DeepMasterPrints. The underlying method is likely to have broad applications in fingerprint security as well as fingerprint synthesis. © 2018 IEEE.",,"Biometrics; Computer crime; Covariance matrix; Optimization; Stochastic systems; Adversarial networks; Covariance matrix adaptation evolution strategies; Fingerprint images; Fingerprint recognition systems; Fingerprint systems; Recent researches; Stochastic search; Synthetic fingerprints; Palmprint recognition",,,,,"Apple. iOS Security-White Paper, 2017. 2; Arjovsky, M., Chintala, S., Bottou, L., (2017) Wasserstein GAN, 3, p. 4; Arora, S., Zhang, Y., (2017) Do GANs Actually Learn the Distribution? An Empirical Study, 4; Bontrager, P., Lin, W., Togelius, J., Risi, S., Deep interactive evolution (2018) International Conference on Evolutionary and Biologically Inspired Music and Art, 3, p. 8. , Springer; Cao, K., Jain, A.K., Fingerprint synthesis: Evaluating fingerprint search at scale (2018) Proceedings of International Conference on Biometrics, pp. 1-8. , 1; Galbally, J., Cappelli, R., Lumini, A., De Rivera, G.G., Maltoni, D., Fierrez, J., Ortega-Garcia, J., Maio, D., An evaluation of direct attacks using fake fingers generated from ISO templates (2010) Pattern Recognition Letters, 31 (8), pp. 725-732; Goodfellow, I., (2016) NIPS 2016 Tutorial: Generative Adversarial Networks, , 1, 2; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., (2014) Generative Adversarial Nets. in Advances in Neural Information Processing Systems, pp. 2672-2680. , 1; Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., Courville, A.C., (2017) Improved Training of Wasserstein GANs. in Advances in Neural Information Processing Systems, pp. 5769-5779. , 3; Han, B.B., Marciniak, C.A., Westerman, W.C., (2014) Fingerprint Sensing and Enrollment, , US Patent App. 14/244,143. 1; Hansen, N., (2006) The CMA Evolution Strategy: A Comparing Review, 4, pp. 75-102. , Springer, Berlin, Heidelberg; Hansen, N., Ostermeier, A., Completely derandomized selfadaptation in evolution strategies (2001) Evolutionary Computation, 9 (2), pp. 159-195. , 3, 4; Jia, X., Yang, X., Zang, Y., Zhang, N., Tian, J., A crossdevice matching fingerprint database from multi-type sensors (2012) 21st International Conference on Pattern Recognition (ICPR), pp. 3001-3004. , . 6; Karras, T., Aila, T., Laine, S., Lehtinen, J., (2017) Progressive Growing of GANs for Improved Quality, Stability, and Variation, , 3; Lehman, J., Chen, J., Clune, J., Stanley, K.O., (2017) Safe Mutations for Deep and Recurrent Neural Networks Through Output Gradients, , 3; Lui, M., Kurach, K., Michalski, M., Gelly, S., Bousquet, O., (2017) Are GANs Created Equal? A Large-scale Study, , 3; Marasco, E., Ross, A., A survey on anti-spoofing schemes for fingerprint recognition systems (2015) ACM Computing Surveys, 47 (2), pp. 1-36. , 2; Radford, A., Metz, L., Chintala, S., (2015) Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks, , 4; Ratha, N., Connell, J., Bolle, R., Enhancing security and privacy in biometrics-based authentication systems (2001) IBM Systems Journal, 40 (3), pp. 614-634. , 2; Ross, A., Jain, A., Reisman, J., A hybrid fingerprint matcher (2003) Pattern Recognition, 36 (7), pp. 1661-1673. , 1; Ross, A., Reisman, J., Jain, A.K., Fingerprint matching using feature space correlation (2004) Proc. of International ECCV Workshop on Biometric Authentication, pp. 48-57. , 1; Ross, A., Shah, J., Jain, A.K., From template to image: Reconstructing fingerprints from minutiae points (2007) IEEE Transactions on Pattern Analysis and Machine Intelligence, 29 (4), pp. 544-560. , , April 2; Roy, A., (2017) Personal Communication, , 8; Roy, A., Memon, N., Togelius, J., Ross, A., Evolutionary methods for generating synthetic masterprint templates: Dictionary attack in fingerprint recognition (2018) International Conference on Biometrics, pp. 1-8. , 1; Roy, A., Memon, N., Ross, A., Masterprint: Exploring the vulnerability of partial fingerprint-based authentication systems (2017) IEEE Transactions on Information Forensics and Security, , 1, 2, 5, 6, 8; Such, F.P., Madhavan, V., Conti, E., Lehman, J., Stanley, K.O., Clune, J., (2017) Deep Neuroevolution: Genetic Algorithms Are A Competitive Alternative for Training Deep Neural Networks for Reinforcement Learning, , 3; Une, M., Otsuka, A., Imai, H., Wolf attack probability: A new security measure in biometric authentication systems (2007) International Conference on Biometrics, pp. 396-406. , Springer. 2; Watson, C.I., (1993) NIST Special Database 9, Mated Fingerprint Card Pairs, , National Institute of Standards and Technology, February. 6; Yao, X., Evolving artificial neural networks (1999) Proceedings of the IEEE, 87 (9), pp. 1423-1447. , 3",,,,"Institute of Electrical and Electronics Engineers Inc.","9th IEEE International Conference on Biometrics Theory, Applications and Systems, BTAS 2018","22 October 2018 through 25 October 2018",,147636,,9781538671795,,,"English","IEEE Int. Conf. Biom. Theory, Appl. Syst., BTAS",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85065397323
"Tabassi E., Chugh T., Deb D., Jain A.K.","14833589900;56031923100;55537246000;36071504600;","Altered fingerprints: Detection and localization",2018,"2018 IEEE 9th International Conference on Biometrics Theory, Applications and Systems, BTAS 2018",,,"8698549","","",,3,"10.1109/BTAS.2018.8698549","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065391204&doi=10.1109%2fBTAS.2018.8698549&partnerID=40&md5=1b57969e9ea0f15ba22160f41a307df6","Department of Computer Science and Engineering, Michigan State University, East Lansing, MI  48824, United States","Tabassi, E., Department of Computer Science and Engineering, Michigan State University, East Lansing, MI  48824, United States; Chugh, T., Department of Computer Science and Engineering, Michigan State University, East Lansing, MI  48824, United States; Deb, D., Department of Computer Science and Engineering, Michigan State University, East Lansing, MI  48824, United States; Jain, A.K., Department of Computer Science and Engineering, Michigan State University, East Lansing, MI  48824, United States","Fingerprint alteration, also referred to as obfuscation presentation attack, is to intentionally tamper or damage the real friction ridge patterns to avoid identification by an AFIS. This paper proposes a method for detection and localization of fingerprint alterations. Our main contributions are: (i) design and train CNN models on fingerprint images and minutiae-centered local patches in the image to detect and localize regions of fingerprint alterations, and (ii) train a Generative Adversarial Network (GAN) to synthesize altered fingerprints whose characteristics are similar to true altered fingerprints. A successfully trained GAN can alleviate the limited availability of altered fingerprint images for research. A database of 4,815 altered fingerprints from 270 subjects, and an equal number of rolled fingerprint images are used to train and test our models. The proposed approach achieves a True Detection Rate (TDR) of 99.24% at a False Detection Rate (FDR) of 2%, outperforming published results. The altered fingerprint detection and localization model and code, and the synthetically generated altered fingerprint dataset will be open-sourced. © 2018 IEEE.",,"Biometrics; Damage detection; Adversarial networks; Detection and localization; Detection rates; False detections; Fingerprint dataset; Fingerprint detections; Fingerprint images; Ridge patterns; Palmprint recognition",,,,,"Jain, A.K., Nandakumar, K., Ross, A., 50 Years of biometric research: Accomplishments, challenges, and opportunities (2016) Pattern Recognition Letters, 79, pp. 80-105. , 1; Watson, C., Fiumara, G., Tabassi, E., Chang, S.L., Flanagan, P., Salamon, W., (2015) Fingerprint Vendor Technology Evaluation, , NIST Interagency Report 8034. 1; (2015), www.crime-sceneinvestigator.net/altered-fingerprints.html.1, Altered Fingerprints: A Challenge to Law Enforcement Identification Efforts; Yoon, S., Feng, J., Jain, A.K., Altered fingerprints: Analysis and detection (2012) IEEE Transactions on Pattern Analysis and Machine Intelligence, 34 (3), pp. 451-464. , 1, 2, 3, 4, 6, 7; Feng, J., Jain, A.K., Ross, A., Detecting altered fingerprints (2010) 20th International Conference on Pattern Recognition, pp. 1622-1625. , Aug. 2; Tiribuzi, M., Pastorelli, M., Valigi, P., Ricci, E., A multiple kernel learning framework for detecting altered fingerprints (2012) 21st International Conference on Pattern Recognition (ICPR), pp. 3402-3405. , 2; Yoon, S., Jain, A.K., Is there a fingerprint pattern in the image? (2013) International Conference on Biometrics (ICB), pp. 1-8. , 2; Ellingsgaard, J., Busch, C., Altered Fingerprint Detection (2017) Handbook of Biometrics for Forensic Science, pp. 85-123. , 2, 3; Ellingsgaard, J., Sousedik, C., Busch, C., Detecting fingerprint alterations by orientation field and minutiae orientation analysis (2014) 2nd International Workshop on Biometrics and Forensics, pp. 1-6. , March. 2; Cummins, H., Attempts to alter and obliterate finger-prints (1935) Journal of Criminal Law and Criminology, 25 (12). , 1, 2; (2018), http://www.businessinsider.com/fbi-10-most-wanted-criminals-list-2017-11.2, These are the fugitives on the fbi's 10 most wanted list; abcnews.go.com/Technology/GadgetGuide/surgicallyaltered-fingerprints-woman-evadeimmigration/story?id=9302505.2, Surgically Altered Fingerprints Help Woman Evade Immigration 2009; (2015), www.forensicmag.com/article/2015/05/fbi-warns-about-altered-fingerprints.2, Fbi warns about altered fingerprints; Yoon, S., Zhao, Q., Jain, A.K., On matching altered fingerprints (2012) International Conference on Biometrics (ICB), pp. 222-229. , 05. 2; Chugh, T., Cao, K., Jain, A.K., Fingerprint spoof buster: Use of minutiae-centered patches (2018) IEEE Transactions on Information Forensics and Security, , 4; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826. , 4, 5; Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H., (2017) MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications; Tabassi, E., (2016) NIST Fingerprint Image Quality, NFIQ 2.0, , https://www.nist.gov/servicesresources/software/development-nfiq-20.4; (2017), https://www.iso.org/standard/62791.html.4, Information Technology-Biometric Sample Quality-Part 4: Finger Image Data; https://github.com/tensorflow/models/tree/master/research/slim.5, Tensorflow Slim (TF-Slim) Library; Radford, A., Metz, L., Chintala, S., (2015) Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks, , CoRR abs/1511.06434. 5",,,,"Institute of Electrical and Electronics Engineers Inc.","9th IEEE International Conference on Biometrics Theory, Applications and Systems, BTAS 2018","22 October 2018 through 25 October 2018",,147636,,9781538671795,,,"English","IEEE Int. Conf. Biom. Theory, Appl. Syst., BTAS",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85065391204
"Satav P.R., Jawandhiya P.M., Thakare V.M.","57194685575;36600676700;8264851500;","Secure Route Selection Mechanism in the Presence of Black Hole Attack with AOMDV Routing Algorithm",2018,"Proceedings - 2018 4th International Conference on Computing, Communication Control and Automation, ICCUBEA 2018",,,"8697660","","",,6,"10.1109/ICCUBEA.2018.8697660","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065197663&doi=10.1109%2fICCUBEA.2018.8697660&partnerID=40&md5=b4b1e3f5d34d8784574c7b219dd8dc48","S. G. B. A. U., Amravati, India; Computer Engineering, Government Polytechnic Arvi, India; Pankaj Ladhhad College of Engineering, Buldhana, India; Department of Computer Science, S.G.B.A.U, Amravati, India","Satav, P.R., S. G. B. A. U., Amravati, India, Computer Engineering, Government Polytechnic Arvi, India; Jawandhiya, P.M., Pankaj Ladhhad College of Engineering, Buldhana, India; Thakare, V.M., Department of Computer Science, S.G.B.A.U, Amravati, India","The research in MANET has been carried out for the development of various techniques which will increase the competency of the network only. A plenty number of proposed routing protocols are magnificent in terms of efficiency. However, proposed protocols were generally fulfilling the set of trusted network and not considered for adversarial network setting, hence there is no security mechanism has been considered. MANET is widely used in sensitive fields like battlefield, police rescue operation and many more in such type of sensitive field an attacker may try to gather information about the conversation starting from the origin node to the terminal node. Secure route selection approach for route selection in adverse environment is discussed in this article. The results shows that proposed algorithm, will resolve the single collaborative attack by increasing the computational storage overhead and by improving the significant PDR, achieves a noticeable enhancement in the end to end delay. © 2018 IEEE.","AOMDV; blackhole attack; MANET; routing","Mobile ad hoc networks; Mobile security; Network protocols; Routing algorithms; Adversarial networks; Adverse environment; AOMDV; Blackhole attacks; MANET; Rescue operations; routing; Security mechanism; Network security",,,,,"Saleem Khan, M., Midi, D., Khan, M.I., Bertino, E., Fine-grained analysis of packet loss in MANETs (2017) IEEE Access, 5, pp. 7798-7807. , 24 April; Tseng, F., Choul, L., Chao, H., A survey of black hole attacks in wireless mobile ad hoc networks (2011) Human-centric Computing and Information Sciences; Geetha, D., Revathi, B., AOMDV routing based enhanced security for black hole attack in MANETs International Conference on Research Trends in Computer Technologies (ICRTCT-2013) Proceedings Published in International Journal of Computer Applications (IJCA) (0975-8887), pp. 20-24; Hoan Vu, C., Soneye, A., An analysis of collaborative attacks on mobile ad hoc networks (2009) Master Thesis at School of Computing, Blekinge Institute of Technology; Marina, M.K., Das, S.R., Ad hoc on-demand multipath distance vector routing (2006) Wirel. Commun. Mob. Comput., 6, pp. 969-988. , Published online in Wiley InterScience; Suresh Babua, E., Nagarajub, C., Krishna Prasad, M., Analysis of secure routing protocol for wireless adhoc networks using efficient DNA based cryptographic mechanism (2015) 4th International Conference on Ecofriendly Computing and Communication Systems, ICECCS 2015, Procedia Computer Science, 70, pp. 341-347; Tan, S., Sok, P., Kim, K., Using cryptographic technique for securing route discovery and data transmission from blackhole attack on AODV-based MANET (2014) International Journal of Networked and Distributed Computing, 2 (2), pp. 100-107; Chandera, D., Kumar, R., QoS enabled cross-layer multicast routing over mobile ad hoc networks (2018) International Conference on Smart Computing & Communication (ICSCC) 2017, Procedia Computer Science, 125, pp. 215-227; Rajaram, A., Indrapriyadarsini, H., A cross layer based secure multipath neighbour routing protocol in MANET (2014) International Journal of Advanced Information Science and Technology (IJAIST), 3 (3). , March; Patil, S., Borade, D., Dynamic cluster based intrusion detection architecture to detect routing protocol attacks in MANET T. Sensor Netw Data Commun, 3, p. 116; Nayak, P., Bhavani Lavanya B, V., Impact of black hole and sink hole attacks on routing protocols for WSN (2015) International Journal of Computer Applications (0975-8887), 116 (4), pp. 42-46. , April; Solanki, P., Shuhkla, D., Detection and prevention of black hole attack to improve network performance by using fidelity and ECARP algorithms (2014) International Journal of Engineering and Computer Science, 3 (2), pp. 3884-3890. , February; Banerjee, S., Detection/removal of cooperative black and gray hole attack in mobile ad-hoc networks (2008) Proceedings of the World Congress on Engineering and Computer Science; Shrivastava, S., Agrawal, C., Jain, A., An IDS scheme against black hole attack to secure AOMDV routing in MANET (2015) Int. J. on AdHoc Networking Systems (IJANS), 5 (1); Sharma, R., Singla, B., Comparison of AOMDV with and without black hole attack (2015) On International Journal of Engineering Science (IJECS), 4 (8), pp. 13892-13899. , Aug; Bhardwaj, N., Singh, R., Detection and avoidance of blackhole attack in AOMDV protocol in MANETs (2014) International Journal of Application or Innovation in Engineering & Management (IJAIEM), 3 (5). , May; Rani, J., Kumar, N., Improving AOMDV protocol for black hole detection in mobile ad hoc network (2013) IEEE International Conference on Control, Computing, Communication and Materials (ICCCCM); Satav, P.R., Jawandhiya, P.M., Review on single-path multipath routing protocol in MANET: A study (2016) IEEE International Conference on Recent Advances and Innovations in Engineering (ICRAIE-2016), , Jaipur, India, December 23-25; Dhakaa, A., Nandal, A., Dhaka, R.S., Gray and black hole attack identification using control packets in MANETs (2015) Eleventh International Multi-Conference on Information Processing-2015 (IMCIP-2015) Procedia Computer Science, 54, pp. 83-91; Satav, P.R., Jawandhiya, P.M., A novel protocol switching approach to increase network performance (2017) 2017 International Conference on Intelligent Computing and Control (I2C2) IEEE at Department of Electronics and Communication Engineering Karpagam College of Engineering Coimbatore on Dated 23-24 June; Arathy, K.S., Sminesh, C.N., A novel approach for detection of single and collaborative black hole attacks in MANET (2016) Procedia Technology, 25, pp. 264-271; Joy Jeba Merline, S., Geetha Priya, S., Shinu, P.S., Roshini, R., Santhiya, G., (2017) A Study on Blackhole Attacks in Adhoc Networks, 3 (2), pp. 5396-5400. , IJARIIE-(O)-2395-4396; Wahane, G., Kanthe, A.M., Simunic, D., Detection of cooperative black hole attack using crosschecking with truelink in MANET (2014) IEEE, International Confrence on Computational Intelligence and Computing Research, on, , 18-20 Dec; Balakrishna, R., Rajeswar Rao, U., Geethanjali, N., Performance issues on AODV and AOMDV for MANETS (2010) International Journal of Computer Science and Information Technologies (IJCSIT), 1 (2), pp. 38-43",,,,"Institute of Electrical and Electronics Engineers Inc.","4th International Conference on Computing, Communication Control and Automation, ICCUBEA 2018","16 August 2018 through 18 August 2018",,147581,,9781538652572,,,"English","Proc. - Int. Conf. Comput., Commun. Control Autom., ICCUBEA",Conference Paper,"Final","",Scopus,2-s2.0-85065197663
"Damer N., Saladie A.M., Braun A., Kuijper A.","50861109400;57208645670;55822966075;56131137100;","MorGAN: Recognition vulnerability and attack detectability of face morphing attacks created by generative adversarial network",2018,"2018 IEEE 9th International Conference on Biometrics Theory, Applications and Systems, BTAS 2018",,,"8698563","","",,41,"10.1109/BTAS.2018.8698563","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063430281&doi=10.1109%2fBTAS.2018.8698563&partnerID=40&md5=3b358ee9d436c2181988fc5ff4901a91","Fraunhofer Institute for Computer Graphics Research IGD, Darmstadt, Germany; Mathematical and Applied Visual Computing, TU Darmstadt, Darmstadt, Germany","Damer, N., Fraunhofer Institute for Computer Graphics Research IGD, Darmstadt, Germany, Mathematical and Applied Visual Computing, TU Darmstadt, Darmstadt, Germany; Saladie, A.M., Fraunhofer Institute for Computer Graphics Research IGD, Darmstadt, Germany; Braun, A., Fraunhofer Institute for Computer Graphics Research IGD, Darmstadt, Germany, Mathematical and Applied Visual Computing, TU Darmstadt, Darmstadt, Germany; Kuijper, A., Fraunhofer Institute for Computer Graphics Research IGD, Darmstadt, Germany, Mathematical and Applied Visual Computing, TU Darmstadt, Darmstadt, Germany","Face morphing attacks aim at creating face images that are verifiable to be the face of multiple identities, which can lead to building faulty identity links in operations like border crossing. Research has been focused on creating more accurate attack detection approaches by considering different image properties. However, all the attacks considered so far are based on manipulating facial landmarks localized in the morphed face images. In contrast, this work presents novel face morphing attacks based on image generated by generative adversarial networks. We present the MorGAN structure that considers the representation loss to successfully create realistic morphing attacks. Based on that, we present a novel face morphing attacks database (MorGAN database) that contains 1000 morph images for both, the proposed MorGAN and landmark-based attacks. We present vulnerability analysis of two face recognition approaches facing the proposed attacks. Moreover, the detectability of the proposed MorGAN attacks is studied, in the scenarios where this type of attacks is know and un- known. We concluded with pointing out the challenge of detecting such unknown novel attacks and an analysis of detection performances of different features in detecting such attacks. © 2018 IEEE.",,"Biometrics; Network security; Adversarial networks; Attack detection; Border crossings; Detection performance; Facial landmark; Image properties; Multiple identities; Vulnerability analysis; Face recognition",,,,,"Ahonen, T., Hadid, A., Pietikäinen, M., Face recognition with local binary patterns (2004) Computer Vision-ECCV 2004, 8th European Conference on Computer Vision, Prague, Czech Republic, May 11-14, 2004. Proceedings, Part I, Volume 3021 of Lecture Notes in Computer Science, pp. 469-481. , In T. Pajdla and J. Matas, editors, Springer; Amos, B., Ludwiczuk, B., Satyanarayanan, M., (2016) Openface: A General-purpose Face Recognition Library with Mobile Applications, , Technical report, CMU-CS-16-118, CMU School of Computer Science; Antipov, G., Baccouche, M., Dugelay, J., Face aging with conditional generative adversarial networks (2017) 2017 IEEE International Conference on Image Processing, ICIP 2017, pp. 2089-2093. , , Beijing, China, September 17-20, 2017IEEE; Bengio, Y., Laufer, E., Alain, G., Yosinski, J., Deep generative stochastic networks trainable by backprop (2014) International Conference on Machine Learning, pp. 226-234; Bolle, R., Pankanti, S., (1998) Biometrics, Personal Identification in Networked Society: Personal Identification in Networked Society, , Kluwer Academic Publishers, Norwell, MA, USA; Chu, C., Zhmoginov, A., Sandler, M., (2017) Cyclegan: A Master of Steganography; Damer, N., Boller, V., Wainakh, Y., Boutros, F., Terhörst, P., Braun, A., Kuijper, A., Detecting face morphing attacks by analyzing the directed distances of facial landmarks shifts (2018) Pattern Recognition-40th German Conference, GCPR 2018, , Stuttgart, Germany, October 10-12, 2018, Proceedings, Lecture Notes in Computer Science. Springer; Damer, N., Boller, V., Wainakh, Y., Berken Den S.Von, Terhörst, P., Braun, A., Kuijper, A., CrazyFaces: Unassisted circumvention of watchlist face identification (2018) 9th IEEE International Conference on Biometrics Theory, Applications and Systems, BTAS 2018, , Los Angeles, California, USA, October 22-25, 2018. IEEE; Damer, N., Dimitrov, K., Practical view on face presentation attack detection (2016) Proceedings of the British Machine Vision Conference 2016, BMVC 2016, , In R. C. Wilson, E. R. Hancock, and W. A. P. Smith, editors, York, UK, September 19-22, 2016. BMVA Press; Dhamecha, T.I., Nigam, A., Singh, R., Vatsa, M., Disguise detection and face recognition in visible and thermal spectrums (2013) International Conference on Biometrics, ICB 2013, 4-7 June, 2013, Madrid, Spain, pp. 1-8. , In J. Fierrez, A. Kumar, M. Vatsa, R. N. J. Veldhuis, and J. Ortega-Garcia, editors, IEEE; Donahue, J., Krähenbühl, P., Darrell, T., (2016) Adversarial Feature Learning; Dumoulin, V., Belghazi, I., Poole, B., Mastropietro, O., Lamb, A., Arjovsky, M., Courville, A., (2016) Adversarially Learned Inference; Ferrara, M., Cappelli, R., Maltoni, D., On the feasibility of creating double-identity fingerprints (2017) IEEE Trans. Information Forensics and Security, 12 (4), pp. 892-900; Ferrara, M., Franco, A., Maltoni, D., The magic passport (2014) IEEE International Joint Conference on Biometrics, Clearwater, IJCB 2014, pp. 1-7. , , FL, USA, September 29-October 2, 2014IEEE; Ferrara, M., Franco, A., Maltoni, D., On the effects of image alterations on face recognition accuracy (2016) Face Recognition Across the Imaging Spectrum, pp. 195-222. , In T. Bourlai, editor, Springer; Ferrara, M., Franco, A., Maltoni, D., Face demorphing (2018) IEEE Trans. Information Forensics and Security, 13 (4), pp. 1008-1017; Frossard, D., VGG in TensorFlow, , http://www.cs.toronto.edu/frossard/post/vgg16, (visited on 08/10/2018); Gan, Z., Chen, L., Wang, W., Pu, Y., Zhang, Y., Liu, H., Li, C., Carin, L., Triangle generative adversarial networks (2017) Advances in Neural Information Processing Systems, pp. 5247-5256; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, pp. 2672-2680; Huang, R., Zhang, S., Li, T., He, R., (2017) Beyond Face Rotation: Global and Local Perception Gan for Photorealistic and Identity Preserving Frontal View Synthesis; International Civil Aviation Organisation (ICAO). ICAO Draft Technical Report: Portrait quality (reference facial images for MRTD). technical report, Version 0.9, 2017; International Organization for Standardization. ISO/IEC DIS 30107-3:2016: Information Technology Biometric presentation attack detection Part 3: Testing and reporting. Standard, 2017; Kähm, O., Damer, N., 2d face liveness detection: An overview (2012) 2012 BIOSIG-Proceedings of the International Conference of Biometrics Special Interest Group, Darmstadt, Germany, September 6-7, 2012, Volume 197 of LNI, pp. 1-12. , In A. Brömme and C. Busch, editors, IEEE/GI; Karras, T., Aila, T., Laine, S., Lehtinen, J., (2017) Progressive Growing of Gans for Improved Quality, Stability, and Variation, , CoRR, abs/1710.10196; Kazemi, V., Sullivan, J., One millisecond face alignment with an ensemble of regression trees (2014) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1867-1874; Kim, T., Cha, M., Kim, H., Lee, J.K., Kim, J., (2017) Learning to Discover Cross-domain Relations with Generative Adversarial Networks; Kingma, D.P., Ba, J., (2014) Adam: A Method for Stochastic Optimization; Kingma, D.P., Welling, M., (2013) Auto-encoding Variational Bayes, , CoRR, abs/1312.6114; Lee, D.-T., Schachter, B.J., Two algorithms for constructing a delaunay triangulation (1980) International Journal of Computer &Information Sciences, 9 (3), pp. 219-242; Lin, J., Divergence measures based on the shannon entropy (1991) IEEE Transactions on Information Theory, 37 (1), pp. 145-151; Liu, X., Kumar, B.V., Ge, Y., Yang, C., You, J., Jia, P., Normalized face image generation with perceptron generative adversarial networks (2018) Identity, Security, and Behavior Analysis (ISBA), 2018 IEEE 4th International Conference on, pp. 1-8. , IEEE; Liu, Z., Luo, P., Wang, X., Tang, X., Deep learning face attributes in the wild (2015) Proceedings of International Conference on Computer Vision (ICCV); Mallick, S., (2016) Face Morph Using Opencv C++ / Python, , https://www.learnopencv.com/face-morph-usingopencv-cpp-python/; Markets and Markets. Facial Recognition Market by Component (Software Tools and Services), Technology, Use Case (Emotion Recognition, Attendance Tracking and Monitoring, Access Control, Law Enforcement), End-User, and Region-Global Forecast to 2022. Report, November 2017; Neubert, T., Face morphing detection: An approach based on image degradation analysis (2017) Digital Forensics and Watermarking-16th International Workshop, IWDW 2017, Magdeburg, Germany, August 23-25, 2017, Proceedings, Volume 10431 of Lecture Notes in Computer Science, pp. 93-106. , In C. Kraetzer, Y. Shi, J. Dittmann, and H. J. Kim, editors, Springer; Parkhi, O.M., Vedaldi, A., Zisserman, A., Deep face recognition (2015) Proceedings of the British Machine Vision Conference 2015, BMVC 2015, pp. 411-4112. , In X. Xie, M. W. Jones, and G. K. L. Tam, editors, Swansea, UK, September 7-10. BMVA Press, 2015; Radford, A., Metz, L., Chintala, S., (2015) Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks, , CoRR, abs/1511.06434; Ramachandra, R., Raja, K.B., Busch, C., Detecting morphed face images (2016) 8th IEEE International Conference on Biometrics Theory, Applications and Systems, BTAS 2016, pp. 1-7. , , Niagara Falls, NY, USA, September 6-9, 2016IEEE; Ramachandra, R., Raja, K.B., Venkatesh, S., Busch, C., Face morphing versus face averaging: Vulnerability and detection (2017) 2017 IEEE International Joint Conference on Biometrics, IJCB 2017, pp. 555-563. , , Denver, CO, USA, October 1-4, 2017IEEE; Ramachandra, R., Raja, K.B., Venkatesh, S., Busch, C., Transferable deep-cnn features for detecting digital and print-scanned morphed face images (2017) 2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops, CVPR Workshops, pp. 1822-1830. , , Honolulu, HI, USA, July 21-26, 2017IEEE Computer Society; Rathgeb, C., Busch, C., On the feasibility of creating morphed iris-codes (2017) 2017 IEEE International Joint Conference on Biometrics, IJCB 2017, pp. 152-157. , , Denver, CO, USA, October 1-4, 2017IEEE; Rezende, D.J., Mohamed, S., Wierstra, D., (2014) Stochastic Backpropagation and Approximate Inference in Deep Generative Models; Robertson, D.J., Kramer, R.S.S., Burton, A.M., Fraudulent id using face morphs: Experiments on human and automatic recognition (2017) PLOS ONE, 12 (3), pp. 1-12. , 03; Scherhag, U., Nautsch, A., Rathgeb, C., Gomez-Barrero, M., Veldhuis, R.N.J., Spreeuwers, L.J., Schils, M., Busch, C., Biometric systems under morphing attacks: Assessment of morphing techniques and vulnerability reporting (2017) International Conference of the Biometrics Special Interest Group, BIOSIG 2017, Darmstadt, Germany, September 20-22, 2017, Volume P-270 of LNI, pp. 149-159. , In A. Brömme, C. Busch, A. Dantcheva, C. Rathgeb, and A. Uhl, editors, GI / IEEE; Scherhag, U., Ramachandra, R., Raja, K.B., Gomez-Barrero, M., Rathgeb, C., Busch, C., On the vulnerability of face recognition systems towards morphed face attacks (2017) 5th International Workshop on Biometrics and Forensics, IWBF 2017, pp. 1-6. , , Coventry, United Kingdom, April 4-5, 2017IEEE; Schroff, F., Kalenichenko, D., Philbin, J., Facenet: A unified embedding for face recognition and clustering (2015) IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2015, pp. 815-823. , , Boston, MA, USA, June 7-12, 2015IEEE Computer Society; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., (2018) Adversarial Generative Nets: Neural Network Attacks on State-ofthe-art Face Recognition, , CoRR, abs/1801.00349; Al-Rfou, R., Alain, G., Almahairi, A., Angermueller, C., Bahdanau, D., Ballas, N., Bastien, F., Belikov, A., (2016) Theano: A Python Framework for Fast Computation of Mathematical Expressions, , Team T.T.D; Theis, L., Oord Den A.Van, Bethge, M., (2015) A Note on the Evaluation of Generative Models, , CoRR, abs/1511.01844; Yi, Z., Zhang, H., Tan, P., Gong, M., (2017) Dualgan: Unsupervised Dual Learning for Image-to-image Translation, , arXiv preprint",,,,"Institute of Electrical and Electronics Engineers Inc.","9th IEEE International Conference on Biometrics Theory, Applications and Systems, BTAS 2018","22 October 2018 through 25 October 2018",,147636,,9781538671795,,,"English","IEEE Int. Conf. Biom. Theory, Appl. Syst., BTAS",Conference Paper,"Final","",Scopus,2-s2.0-85063430281
"Aiken W., Kim H.","57103289200;35310921400;","Ignore the noise: Using autoencoders against adversarial attacks in reinforcement learning (lightning talk)",2018,"Proceedings - 2018 4th International Conference on Software Security and Assurance, ICSSA 2018",,,"9092100","81","",,,"10.1109/ICSSA45270.2018.00028","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085602652&doi=10.1109%2fICSSA45270.2018.00028&partnerID=40&md5=c447ddf8b8162cca09121ada6dae543f","Department of Electrical and Computer Engineering, Sungkyunkwan University, Suwon, South Korea","Aiken, W., Department of Electrical and Computer Engineering, Sungkyunkwan University, Suwon, South Korea; Kim, H., Department of Electrical and Computer Engineering, Sungkyunkwan University, Suwon, South Korea","Reinforcement learning (RL) algorithms learn and explore nearly any state any number of times in their environment, but minute adversarial attacks cripple these agents. In this work, we define our threat model against RL agents as such: Adversarial agents introduce small permutations to the input data via black-box models with the goal of reducing the optimality of the agent. We focus on pre-processing adversarial images before they enter the network to reconstruct the ground-truth images. © 2018 IEEE.","Adversarial examples; Autoencoders; Reinforcement learning","Adversarial agent; Autoencoders; Black-box model; Ground truth; Input datas; Optimality; Pre-processing; Threat modeling; Reinforcement learning",,,,,"Huang, S., Papernot, N., Goodfellow, I., Duan, Y., Abbeel, P., (2017) Adversarial Attacks on Neural Network Policies; Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2018) International Conference on Learning Representations; Raghunathan, A., Steinhardt, J., Liang, P., (2018) Certified Defenses Against Adversarial Examples; Chen, J., Wu, X., Liang, Y., Jha, S., (2018) Improving Adversarial Robustness by Data-specific Discretization; Lin, Y.-C., Liu, M.-Y., Sun, M., Huang, J.-B., (2017) Detecting Adversarial Attacks on Neural Network Policies with Visual Foresight; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium On. IEEE, pp. 39-57; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks",,,"/fh/// St. Polten;PennState Altoona;Seoul Womens University;Sungkyunkwan University","Institute of Electrical and Electronics Engineers Inc.","4th International Conference on Software Security and Assurance, ICSSA 2018","26 July 2018 through 27 July 2018",,159801,,9781538692103,,,"English","Proc. - Int. Conf. Softw. Secur. Assur., ICSSA",Conference Paper,"Final","",Scopus,2-s2.0-85085602652
"Guri M.","55844361900;","Beatcoin: Leaking private keys from air-gapped cryptocurrency wallets",2018,"Proceedings - IEEE 2018 International Congress on Cybermatics: 2018 IEEE Conferences on Internet of Things, Green Computing and Communications, Cyber, Physical and Social Computing, Smart Data, Blockchain, Computer and Information Technology, iThings/GreenCom/CPSCom/SmartData/Blockchain/CIT 2018",,,"8726762","1308","1316",,7,"10.1109/Cybermatics_2018.2018.00227","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067836252&doi=10.1109%2fCybermatics_2018.2018.00227&partnerID=40&md5=bf8f8152276a5b1bf1726ab8564bb38b","Cyber-Security Research Center, Ben-Gurion University of the Negev, Israel","Guri, M., Cyber-Security Research Center, Ben-Gurion University of the Negev, Israel","Cryptocurrency wallets store the wallet's private key(s), and hence, are a lucrative target for attackers. With possession of the private key, an attacker virtually owns all of the currency in the compromised wallet. Managing cryptocurrency wallets offline, in isolated ('air-gapped') computers, has been suggested in order to secure the private keys from theft. Such air-gapped wallets are often referred to as 'cold wallets.' In this paper we show how private keys can be exfiltrated from air-gapped wallets. In the adversarial attack model, the attacker infiltrates the offline wallet, infecting it with malicious code. The malware can be preinstalled or pushed in during the initial installation of the wallet, or it can infect the system when removable media (e.g., USB flash drive) is inserted into the wallet's computer in order to sign a transaction. These attack vectors have repeatedly been proven feasible in the last decade (e.g., [1], [2], [3], [4], [5], [6], [7], [8], [9], [10]). Having obtained a foothold in the wallet, an attacker can utilize various air-gap covert channel techniques (bridgeware [11]) to jump the airgap and exfiltrate the wallet's private keys. We evaluate various exfiltration techniques, including physical, electromagnetic, electric, magnetic, acoustic, optical, and thermal techniques. This research shows that although cold wallets provide a high degree of isolation, it's not beyond the capability of motivated attackers to compromise such wallets and steal private keys from them. We demonstrate how a 256-bit private key (e.g., Bitcoin's private keys) can be exfiltrated from an offline, air-gapped wallet of a fictional character named Satoshi within a matter of seconds. © 2018 IEEE.",,"Blockchain; Digital storage; Electronic money; Internet of things; Malware; Attack model; Attack vector; Covert channels; Exfiltration; Malicious codes; Private key; Thermal techniques; USB flash drives; Green computing",,,,,"25% of New Worms in 2010 Are Designed Specifically to Spread Through Usb Devices-panda Security Mediacenter, , https://www.pandasecurity.com/mediacenter/press-releases/25-of-new-wormsin-2010-Are-designed-specifically-To-spread-Through-usb-devices/, (Accessed on 04/05/2018; New Cryptolocker Spreads Via Removable Drives-Trendlabs Security Intelligence Blog, , https://blog.trendmicro.com/trendlabssecurity-intelligence/new-cryptolocker-spreads-via-removable-drives/, (Accessed on 04/05/2018; W32.daprosy-symantec, , https://www.symantec.com/securityresponse/writeup.jsp?docid=2009-071521-4358-99, (Accessed on 04/05/2018; Spora-The Shortcut Worm That Is Also A Ransomware, , https://www.gdatasoftware.com/blog/2017/01/29442-spora-wormand-ransomware, (Accessed on 04/05/2018; Ciscos Talos Intelligence Group Blog: The Medoc Connection, , http://blog.talosintelligence.com/2017/07/the-medoc-connection.html, (Accessed on 04/08/2018; Shadowpad: How Attackers Hide Backdoor in Software Used by Hundreds of Large Companies Around the World-kaspersky Lab, , https://www.kaspersky.com/about/press-releases/2017shadowpadhow-Attackers-hide-backdoor-in-software-used-by-hundreds-of-largecompanies-Around-The-world, (Accessed on 04/08/2018; Beware of Hacked Isos if You Downloaded Linux Mint on February 20th! the Linux Mint Blog, , https://blog.linuxmint.com/?p=2994, (Accessed on 04/08/2018; Kaspersky Lab Whitepaper Regin Platform Eng.pdf, , https://securelist.com/files/2014/11/KasperskyLabwhitepaperReginplatformeng.pdf, (Accessed on 04/05/2018; A Fanny Equation: I Am Your Father, Stuxnet""-securelist, , https://securelist.com/a-fanny-equation-i-Am-your-father-stuxnet/68787/, (Accessed on 04/05/2018; Langner, R., Stuxnet: Dissecting a cyberwarfare weapon (2011) IEEE Security & Privacy, 9 (3), pp. 49-51; Guri, M., Elovici, Y., Bridgeware: The air-gap malware Commun ACM, 61 (4), pp. 74-82. , http://doi.acm.org/10.1145/3177230, Mar. 2018; Bitcoin-open Source p2p Money, , https://bitcoin.org/en/, (Accessed on 04/10/2018; Ethereum Project, , https://www.ethereum.org/, (Accessed on 04/10/2018; Kosba, A., Miller, A., Shi, E., Wen, Z., Papamanthou, C., Hawk: The blockchain model of cryptography and privacy-preserving smart contracts (2016) Security and Privacy (SP) 2016 IEEE Symposium On. IEEE, pp. 839-858; Azaria, A., Ekblaw, A., Vieira, T., Lippman, A., Medrec: Using blockchain for medical data access and permission management (2016) Open and Big Data (OBD), International Conference on IEEE, pp. 25-30; Pilkington, M., 11 blockchain technology: Principles and applications (2016) Research Handbook on Digital Transformations, p. 225; Nakamoto, S., (2008) Bitcoin: A Peer-To-peer Electronic Cash System; Trezor Bitcoin Wallet (Official)-The Most Secure Hardware Wallet, , https://trezor.io/, (Accessed on 04/10/2018; Ledger Wallet-ledger Nano S-cryptocurrency Hardware Wallet, , https://www.ledgerwallet.com/products/ledger-nano-s, (Accessed on 04/10/2018; Provos, N., McNamee, D., Mavrommatis, P., Wang, K., Modadugu, N., The ghost in the browser: Analysis of web-based malware (2007) HotBots, 7, p. 4; Cova, M., Kruegel, C., Vigna, G., Detection and analysis of driveby-download attacks and malicious Javascript code (2010) Proceedings of the 19th International Conference on World Wide Web ACM, pp. 281-290; Sood, A.K., Enbody, R.J., Malvertising-exploiting web advertising (2011) Computer Fraud & Security, 2011 (4), pp. 11-16; Peltier, T.R., Social engineering: Concepts and solutions (2006) Information Systems Security, 15 (5), pp. 13-21; Smutz, C., Stavrou, A., Malicious pdf detection using metadata and structural features (2012) Proceedings of the 28th Annual Computer Security Applications Conference ACM, pp. 239-248; Sure, Ill Take That! New Combojack Malware Alters Clipboards to Steal Cryptocurrency, , https://researchcenter.paloaltonetworks.com/2018/03/unit42-sure-ill-Take-new-combojack-malware-Alters-clipboards-stealcryptocurrency/, (Accessed on 04/11/2018; Cryptoshuffler Trojan Has Quietly Stolen 140, 000 Worth of Bitcoin Kaspersky Lab Official Blog, , https://www.kaspersky.com/blog/cryptoshuffler-bitcoin-stealer/19976/, (Accessed on 04/11/2018; Trickbots Cryptocurrency Hunger: Targeting Exchange Users to Steal Coins, , https://securityintelligence.com/trickbots-cryptocurrencyhunger-Tricking-The-bitcoin-out-of-wallets/, (Accessed on 04/11/2018; Kocher, P., Genkin, D., Gruss, D., Haas, W., Hamburg, M., Lipp, M., Mangard, S., Yarom, Y., (2018) Spectre Attacks: Exploiting Speculative Execution; Lipp, M., Schwarz, M., Gruss, D., Prescher, T., Haas, W., Mangard, S., Kocher, P., Hamburg, M., (2018) Meltdown; Us-15-shen-Attack-your-Trusted-core, , https://www.blackhat.com/docs/us-15/materials/us-15-Shen-Attacking-Your-Trusted-Core-Exploiting-Trustzone-On-Android.pdf, (Accessed on 04/11/2018; Project Zero: Trust Issues: Exploiting Trustzone Tees, , https://googleprojectzero.blogspot.co.il/2017/07/trust-issues-exploitingtrustzone-Tees.html, (Accessed on 04/11/2018; Cold Storage Electrum 3.1 Documentation, , http://docs.electrum.org/en/latest/coldstorage.html, (Accessed on 04/04/2018; Bitkey-secure Bitcoin Swiss Army Knife, , https://bitkey.io/, (Accessed on 04/05/2018; Bitdefender Stops Zcrypt Worm-like Ransomware Bitdefender Labs, , https://labs.bitdefender.com/2016/06/bitdefender-stops-zcrypt-wormlike-ransomware/, (Accessed on 04/05/2018; The-projectsauron-Apt Research Kl.pdf, , https://securelist.com/files/2016/07/The-ProjectSauron-APTresearchKL.pdf, (Accessed on 04/05/2018; Grant, R., The cyber menace (2009) Air Force Magazine, 92 (3); Hammerdrill v2.0, , https://wikileaks.org/ciav7p1/cms/page17072172.html, (Accessed on 04/05/2018; Wikileaks-vault 7: Projects, , https://wikileaks.org/vault7/?#Brutal%20Kangaroo, (Accessed on 04/05/2018; https://www.kde.org/info/security/advisory-20180208-2.txt, https://www.kde.org/info/security/advisory-20180208-2.txt, (Accessed on 04/05/2018; Ccleaner.com-security Notification for Ccleaner v5.33.6162 and Ccleaner Cloud v1.07.3191 for 32-bit Windows Users, , https://www.ccleaner.com/news/release-Announcements/2017/9/18/security-notification-for-ccleaner-v5336162-And-ccleaner-cloudv1073191-for-32-bit-windows-users, (Accessed on 04/08/2018; McFadden, F.E., Arnold, R.D., Supply chain risk mitigation for it electronics (2010) Technologies for Homeland Security (HST) 2010 IEEE International Conference On. IEEE, pp. 49-55; Github-bitpay/bitcore-wallet: A Command Line Interface Multisig HD Wallet, Based on Bitcore-wallet-service, , https://github.com/bitpay/bitcore-wallet, (Accessed on 04/04/2018; Wikileaks: Cia Uses Brutal Kangaroo Toolkit to Hack Air-gapped Networks, , https://www.theinquirer.net/inquirer/news/3012499/-wikileakscia-uses-brutal-kangaroo-Toolkit-To-hack-Air-gapped-networks2017, (Accessed on 12/03/2017; Equation Group Questions and Answers.pdf, , https://securelist.com/files/2015/02/Equationgroupquestionsandanswers.pdf, (Accessed on 04/04/2018; A Fanny Equation: I Am Your Father, Stuxnet""-securelist, , https://securelist.com/a-fanny-equation-i-Am-your-father-stuxnet/68787/, (Accessed on 12/03/2017; Kuhn, M.G., Anderson, R.J., Soft tempest: Hidden data transmission using electromagnetic emanations."" in (1998) Information Hiding, 1525, pp. 124-142. , Springer; Tempest for Eliza, , http://www.erikyyy.de/tempest/, (Accessed on 12/03/2017; Guri, M., Kedma, G., Kachlon, A., Elovici, Y., Airhopper: Bridging the air-gap between isolated networks and mobile phones using radio frequencies (2014) Malicious and Unwanted Software: The Americas (MALWARE), 2014 9th International Conference on IEEE, pp. 58-67; Guri, M., Monitz, M., Elovici, Y., Bridging the air gap between isolated networks and mobile phones in a practical cyber-Attack (2017) ACM Transactions on Intelligent Systems and Technology (TIST, 8 (4), p. 50; Guri, M., Kachlon, A., Hasson, O., Kedma, G., Mirsky, Y., Elovici, Y., Gsmem: Data exfiltration from air-gapped computers over gsm frequencies (2015) USENIX Security Symposium, pp. 849-864; Guri, M., (2018) Radiot: Exfiltration of Data from Air-gapped Internet-of-Things (Iot) and Embedded Devices Via Radio Signals; Secure Your Bitcoins! How to Build A Hackproof Bitcoin Wallet Cryptohq, , https://cryptohq.org/secure-your-bitcoins-how-To-builda-hackproof-bitcoin-wallet/, (Accessed on 04/14/2018; Offline Bitcoin Wallet Creation on Raspberry Pi Steemit, , https://steemit.com/bitcoin/@deaddy/offline-bitcoin-wallet-creation-onraspberry-pi, (Accessed on 04/14/2018; Guri, M., Zadov, B., Bykhovsky, D., Elovici, Y., (2018) PowerHammer: Exfiltrating Data from Air-Gapped Computers Through Power Lines, , ArXiv e-prints Apr; Guri, M., Zadov, B., Daidakulov, A., Elovici, Y., (2018) Odini: Escaping Sensitive Data from Faraday-caged, Air-gapped Computers Via Magnetic Fields; Guri, M., Daidakulov, A., Elovici, Y., (2018) Magneto: Covert Channel between Air-gapped Systems and Nearby Smartphones Via Cpu-generated Magnetic Fields; Matyunin, N., Szefer, J., Biedermann, S., Katzenbeisser, S., Covert channels using mobile devices magnetic field sensors (2016) Design Automation Conference (ASP-DAC), 2016 21st Asia and South Pacific IEEE, pp. 525-532; Loughry, J., Umphress, D.A., Information leakage from optical emanations (2002) ACM Transactions on Information and System Security (TISSEC, 5 (3), pp. 262-289; Guri, M., Zadov, B., Elovici, Y., Led-it-go: Leaking (a lot of) data from air-gapped computers via the (small) hard drive led (2017) International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment, pp. 161-184. , Springer; Guri, M., Zadov, B., Daidakulov, A., Elovici, Y., (2017) Xled: Covert Data Exfiltration from Air-gapped Networks Via Router Leds; Guri, M., Hasson, O., Kedma, G., Elovici, Y., An optical covertchannel to leak data through an air-gap (2016) Privacy, Security and Trust (PST), 2016 14th Annual Conference on IEEE, pp. 642-649; Cucurull, J., Guasch, S., Escala, A., Navarro-Arribas, G., Acin, V., Qr steganography: A threat to new generation electronic voting systems (2014) Security and Cryptography (SECRYPT), 2014 11th International Conference on IEEE, pp. 1-8; Hanspach, M., Goetz, M., (2014) On Covert Acoustical Mesh Networks in Air; Deshotels, L., Inaudible sound as a covert channel in mobile devices (2014) WOOT; Guri, M., Solwicz, Y., Daidakulov, A., Elovici, Y., Mosquito: Covert Ultrasonic Transmissions between Two Air-gapped Computers Using Speaker-To-speaker Communication, p. 2018; Guri, M., Solewicz, Y., Daidakulov, A., Elovici, Y., (2016) Fansmitter: Acoustic Data Exfiltration from (Speakerless) Air-gapped Computers; Guri, M., Solewicz, Y., Daidakulov, A., Elovici, Y., Acoustic data exfiltration from speakerless air-gapped computers via covert hard-drive noise (diskfiltration) (2017) European Symposium on Research in Computer Security, pp. 98-115. , Springer; Guri, M., Monitz, M., Mirski, Y., Elovici, Y., Bitwhisper: Covert signaling channel between air-gapped computers using thermal manipulations (2015) Computer Security Foundations Symposium (CSF 2015 IEEE 28th. IEEE, pp. 276-289; Guri, M., Monitz, M., Elovici, Y., Usbee: Air-gap covert-channel via electromagnetic emission from usb (2016) Privacy, Security and Trust (PST), 2016 14th Annual Conference on IEEE, pp. 264-268; Funtenna Github, , https://github.com/funtenna2015, (Accessed on 12/03/2017; Lopes, A.C., Aranha, D.F., Platform-Agnostic low-intrusion optical data exfiltration."" in ICISSP, 2017, pp. 474-480; Guri, M., Bykhovsky, D., Elovici, Y., Air-jumper: Covert Air-gap Exfiltration/infiltration Via Security Cameras & Infrared (Ir), p. 2017; Puñal, O., Aguiar, A., Gross, J., In vanets we trust?: Characterizing rf jamming in vehicular networks (2012) Proceedings of the Ninth ACM International Workshop on Vehicular Inter-networking, Systems, and Applications. ACM, pp. 83-92; Beatcoin: Leaking Bitcoins Private Keys from Air-gapped Wallets (Youtube), , https://www.youtube.com/watch?v=ddmHOvT866o2018, (Accessed on 06/17/2018; Beatcoin 2: Leaking Bitcoin Private Key from Air-gapped Wallet (Youtube), , https://www.youtube.com/watch?v=2WtiHZNeveY2018, (Accessed on 06/17/2018","Guri, M.; Cyber-Security Research Center, Israel; email: gurim@post.bgu.ac.il",,"IEEE Computer Society","Institute of Electrical and Electronics Engineers Inc.","11th IEEE International Congress on Conferences on Internet of Things, 14th IEEE International Conference on Green Computing and Communications, 11th IEEE International Conference on Cyber, Physical and Social Computing, 4th IEEE International Conference on Smart Data, 1st IEEE International Conference on Blockchain and 18th IEEE International Conference on Computer and Information Technology, iThings/GreenCom/CPSCom/SmartData/Blockchain/CIT 2018","30 July 2018 through 3 August 2018",,148584,,9781538679753,,,"English","Proc. - IEEE Int. Congr. Cybermatics: IEEE Conf. Internet Things, Green Comput. Commun., Cyber, Phys. Soc. Comput., Smart Data, Blockchain, Comput. Inf. Technol., iThings/GreenCom/CPSCom/SmartData/Blockchain/CIT",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85067836252
"Tug S., Meng W., Wang Y.","57207199247;56062319900;57217363842;","CBSigIDS: Towards Collaborative Blockchained Signature-Based Intrusion Detection",2018,"Proceedings - IEEE 2018 International Congress on Cybermatics: 2018 IEEE Conferences on Internet of Things, Green Computing and Communications, Cyber, Physical and Social Computing, Smart Data, Blockchain, Computer and Information Technology, iThings/GreenCom/CPSCom/SmartData/Blockchain/CIT 2018",,,"8726642","1228","1235",,18,"10.1109/Cybermatics_2018.2018.00217","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062294162&doi=10.1109%2fCybermatics_2018.2018.00217&partnerID=40&md5=b5d231c4d0a2e863e39d9cb50458c2bf","Department of Applied Mathematics and Computer Science, Technical University of Denmark, Denmark; School of Computer Science, Guangzhou University, China","Tug, S., Department of Applied Mathematics and Computer Science, Technical University of Denmark, Denmark; Meng, W., Department of Applied Mathematics and Computer Science, Technical University of Denmark, Denmark; Wang, Y., School of Computer Science, Guangzhou University, China","Intrusion detection systems (IDSs) are one of the most important security mechanisms that help identify various attacks. To enhance the detection performance of a single IDS, collaborative intrusion detection systems or networks (CIDSs or CIDNs) are often implemented in practical organizations, which encourage a set of IDS nodes to exchange information like alarms and signatures with each other. However, due to the distributed nature, malicious nodes within such collaborative network are able to generate untruthful signatures and share to others. This may significantly degrade the effectiveness and efficiency of detection. Recently, blockchain technology has received much attention from both academia and industry, which can provide a verifiable manner for distributed architectures without the need of a trusted intermediary. In this work, our motivation is thus to develop CBSigIDS, a generic framework of collaborative blockchained signature-based IDSs, which utilizes blockchains to help incrementally update a trusted signature database for different IDS nodes in a collaborative network. In the evaluation, our results show that blockchain technology can indeed help enhance the robustness and effectiveness of signature-based IDSs under adversarial scenarios via building a trusted signature database. © 2018 IEEE.","Blockchain Technology; Collaborative and Distributed Network; Generic Framework; Insider Attacks; Intrusion Detection Systems; Signature-based Approach","Blockchain; Computer crime; Green computing; Internet of things; Network security; Distributed networks; Generic frameworks; Insider attack; Intrusion Detection Systems; Signature-based approach; Intrusion detection",,,,,"Alexopoulos, N., Vasilomanolakis, E., Ivanko, N.R., Muhlhauser, M., Towards blockchain-based collaborative intrusion detection systems Proc. Int. Conf. Critical Inf. Infrastruct. Secur, 2017, pp. 1-12; Douceur, J., (2002) The Sybil Attack, , Druschel, P., Kaashoek, M.F., Rowstron, A. (eds) IPTPS 2002 LNCS 2429 Springer, Heidelberg; Duma, C., Karresand, M., Shahmehri, N., Caronni, G., A trust-Aware, p2p-based overlay for intrusion detection (2006) DEXA Workshop, pp. 692-697; Fadlullah, Z.M., Taleb, T., Vasilakos, A.V., Guizani, M., Kato, N., DTRAB: Combating against attacks on encrypted protocols through traffic-feature analysis (2010) IEEE/ACM Trans. Netw, 18 (4), pp. 1234-1247; Friedberg, I., Skopik, F., Settanni, G., Fiedler, R., Combating advanced persistent threats: From network event correlation to incident detection (2015) Computers & Security, 48, pp. 35-37; Fung, C.J., Baysal, O., Zhang, J., Aib, I., Boutaba, R., (2008) Trust Management for Host-based Collaborative Intrusion Detection, 2008, pp. 109-122. , De Turck, F., Kellerer, W. Kormentzas, G. (eds) DSOM LNCS 5273; Gong, F., (2003) Next Generation Intrusion Detection Systems (IDS), , McAfee Network Security Technologies Group; Golomb, T., Mirsky, Y., Elovici, Y., Ciota: Collaborative iot anomaly detection via blockchain Workshop on Decentralized IoT Security and Standards (DISS), 2018; Ghosh, A.K., Wanken, J., Charron, F., Detecting anomalous and unknown intrusions against programs (1998) Proc. Annual Computer Security Applications Conference (ACSAC), pp. 259-267; Huebsch, R., Chun, B.N., Hellerstein, J.M., Loo, B.T., Maniatis, P., Roscoe, T., Shenker, S., Yumerefendi, A.R., The architecture of pier: An internet-scale query processor (2005) Proceedings of the 2005 Conference on Innovative Data Systems Research (CIDR), pp. 28-43; Li, Z., Chen, Y., Beach, A., Towards scalable and robust distributed intrusion alert fusion with good load balancing Proceedings of the 2006 SIGCOMM Workshop on Largescale Attack Defense (LISA), 2006, pp. 115-122; Li, W., Meng, Y., Kwok, L.F., Enhancing trust evaluation using intrusion sensitivity in collaborative intrusion detection networks: Feasibility and challenges (2013) Proceedings of the 9th International Conference on Computational Intelligence and Security (CIS), pp. 518-522; Li, W., Meng, Y., Kwok, L.F., Design of intrusion sensitivity-based trust management model for collaborative intrusion detection networks (2014) Proceedings of the 8th IFIP WG 11.11 International Conference on Trust Management (IFIPTM), pp. 61-76; Li, W., Meng, W., Luo, X., Kwok, L.F., Mvpsys: Towards practical multi-view based false alarm reduction system in network intrusion detection Computers & Security, 60 (2016), pp. 177-192; Li, W., Meng, Y., Enhancing collaborative intrusion detection networks using intrusion sensitivity in detecting pollution attacks (2016) Information and Computer Security, 24 (3); Li, W., Meng, W., Kwok, L.F., Ip, H.H.S., Pmfa: Toward passive message fingerprint attacks on challenge-based collaborative intrusion detection networks (2016) Proceedings of the 10th International Conference on Network and System Security (NSS), pp. 433-449; Li, W., Meng, W., Kwok, L.F., Ip, H.H.S., Developing advanced fingerprint attacks on challenge-based collaborative intrusion detection networks (2017) Cluster Computing, , Springer; Li, W., Meng, W., Kwok, L.F., Investigating the influence of special on-off attacks on challenge-based collaborative intrusion detection networks (2018) Future Internet, 10 (1), pp. 1-16; Li, W., Meng, W., Su, C., Kwok, L.F., False alarm reduction using fuzzy if-Then rules for medical cyber physical systems IEEE Access, 6 (1), pp. 6530-6539. , IEEE, 2018; Meng, Y., Kwok, L.F., Enhancing false alarm reduction using voted ensemble selection in intrusion detection (2013) International Journal of Computational Intelligence Systems, 6 (4), pp. 626-638; Meng, Y., Kwok, L.F., Adaptive non-critical alarm reduction using hash-based contextual signatures in intrusion detection (2014) Computer Communications, 38, pp. 50-59; Meng, Y., Li, W., Kwok, L.F., Towards adaptive character frequency-based exclusive signature matching scheme and its applications in distributed intrusion detection (2013) Computer Networks, 57 (17), pp. 3630-3640; Li, W., Meng, W., Kwok, L.F., An evaluation of single character frequency-based exclusive signature matching in distinct ids environments (2014) Proceedings of the 17th International Conference on Information Security (ISC), pp. 465-476; Meng, W., Li, W., Kwok, L.F., Efm: Enhancing the performance of signature-based network intrusion detection systems using enhanced filter mechanism (2014) Computers & Security, 43, pp. 189-204; Meng, W., Li, W., Kwok, L.F., Design of intelligent knnbased alarm filter using knowledge-based alert verification in intrusion detection (2015) Security and Communication Networks, 8 (18), pp. 3883-3895; Meng, W., Li, W., Xiang, Y., Choo, K.K.R., Bayesian inference-based detection mechanism to defend medical smartphone networks against insider attacks Journal of Network and Computer Applications, 78 (2017), pp. 162-169; Meng, W., Li, W., Kwok, L.F., Towards effective trustbased packet filtering in collaborative network environments (2017) IEEE Transactions on Network and Service Management, 14 (1), pp. 233-245; Meng, W., Tischhauser, E.W., Wang, Q., Wang, Y., Han, J., When intrusion detection meets blockchain technology: A review IEEE Access, 6 (1), pp. 10179-10188. , IEEE, 2018; Meng, W., Choo, K.-K.R., Furnell, S., Vasilakos, A.V., Probst, C.W., Towards Bayesian-based trust management for insider attacks in healthcare software-defined networks (2018) IEEE Transactions on Network and Service Management; Mishra, A., Gupta, B.B., Joshi, R.C., A comparative study of distributed denial of service attacks, intrusion tolerance and mitigation techniques (2011) Proceedings of the 2011 European Intelligence and Security Informatics Conference, pp. 286-289; Nakamoto, S., (2008) Bitcoin: A Peer-To-peer Electronic Cash System, , http://bitcoin.org/bitcoin.pdf; Paxson, V., Bro: A system for detecting network intruders in real-Time (1999) Computer Networks, 31 (23-24), pp. 2435-2463; Papadopoulos, C., Lindell, R., Mehringer, J., Hussain, A., Govindan, R., Cossack: Coordinated suppression of simultaneous attacks (2003) Proceedings of the 2003 DARPA Information Survivability Conference and Exposition (DISCEX, pp. 94-96; Porras, P.A., Neumann, P.G., Emerald: Event monitoring enabling responses to anomalous live disturbances (1997) Proceedings of the 20th National Information Systems Security Conference, pp. 353-365; Roesch, M., Snort: Lightweight intrusion detection for networks (1999) Proceedings of Usenix Lisa Conference, pp. 229-238; Scarfone, K., Mell, P., Guide to Intrusion Detection and Prevention Systems (IDPS) (2007) NIST Special Publication 800, 94. , Feb; Scarfone, K., Mell, P., Guide to intrusion detection and prevention systems (idps) (2007) NIST Special Publication 800-94; Sharma, P.K., Singh, S., Jeong, Y.-S., Park, J.H., Distblocknet: A distributed blockchains-based secure SDN architecture for iot networks (2017) IEEE Communications Magazine, 55 (9), pp. 78-85; Snapp, S.R., Dids (distributed intrusion detection system)-motivation, architecture, and an early prototype (1991) Proceedings of the 14th National Computer Security Conference, pp. 167-176; Snort: An An Open Source Network Intrusion Prevention and Detection System (IDS/IPS) Homepage, , http://www.snort.org/; Sommer, R., Paxson, V., Outside the closed world: On using machine learning for network intrusion detection (2010) IEEE Symposium on Security and Privacy, pp. 305-316; Steichen, M., Hommes, S., State, R., Chainguard-A firewall for blockchain applications using SDN with open-flow (2017) Proceedings of International Conference on Principles, Systems and Applications of IP Telecommunications (IPTComm), pp. 1-8; Tuan, T.A., A game-Theoretic analysis of trust management in p2p systems (2006) Proceedings of ICCE, pp. 130-134; Valdes, A., Anderson, D., (1995) Statistical Methods for Computer Usage Anomaly Detection Using NIDES, , Technical Report SRI International, January; Vigna, G., Kemmerer, R.A., Netstat: A network-based intrusion detection approach (1998) Proc. Annual Computer Security Applications Conf. (ACSAC), pp. 25-34; Wang, L., Liu, Y., Exploring miner evolution in bitcoin network (2015) Passive and Active Measurement 8995 of Lecture Notes in Computer Science, pp. 290-302. , Mirkovic J, Liu Y, editors Springer; Wood, G., (2016) Ethereum: A Secure Decentralised Generalised Transaction Ledger, , EIP-150 Revision; Wu, Y.-S., Foo, B., Mei, Y., Bagchi, S., Collaborative intrusion detection system (CIDS): A framework for accurate and efficient IDS Proceedings of the 2003 Annual Computer Security Applications Conference (ACSAC), 2003, pp. 234-244; Wüst, K., Gervais, A., Do you need a blockchain? IACR Cryptology EPrint Archive, 2017 (2017), p. 375. , http://eprint.iacr.org/2017/375; Xu, X., The blockchain as a software connector Proceedings of the 13th Working IEEE/IFIP Conference on Software Architecture, 2016, pp. 1-10; Yegneswaran, V., Barford, P., Jha, S., Global intrusion detection in the domino overlay system (2004) Proceedings of the 2004 Network and Distributed System Security Symposium (NDSS, pp. 1-17","Meng, W.; Department of Applied Mathematics and Computer Science, Denmark; email: weme@dtu.dk",,"IEEE Computer Society","Institute of Electrical and Electronics Engineers Inc.","11th IEEE International Congress on Conferences on Internet of Things, 14th IEEE International Conference on Green Computing and Communications, 11th IEEE International Conference on Cyber, Physical and Social Computing, 4th IEEE International Conference on Smart Data, 1st IEEE International Conference on Blockchain and 18th IEEE International Conference on Computer and Information Technology, iThings/GreenCom/CPSCom/SmartData/Blockchain/CIT 2018","30 July 2018 through 3 August 2018",,148584,,9781538679753,,,"English","Proc. - IEEE Int. Congr. Cybermatics: IEEE Conf. Internet Things, Green Comput. Commun., Cyber, Phys. Soc. Comput., Smart Data, Blockchain, Comput. Inf. Technol., iThings/GreenCom/CPSCom/SmartData/Blockchain/CIT",Conference Paper,"Final","",Scopus,2-s2.0-85062294162
"Li B., Vorobeychik Y.","57188689924;8913948800;","Evasion-robust classification on binary domains",2018,"ACM Transactions on Knowledge Discovery from Data","12","4","a50","","",,12,"10.1145/3186282","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051469625&doi=10.1145%2f3186282&partnerID=40&md5=fe79c68d786c45a07e3ea577ef4ef1b9","University of California, Berkeley, 5221 Panama Ave, Berkeley, Richmond, CA  94804, United States; Vanderbilt University, 401 Bowling Ave #7, Nashville, TN  37212, United States","Li, B., University of California, Berkeley, 5221 Panama Ave, Berkeley, Richmond, CA  94804, United States; Vorobeychik, Y., Vanderbilt University, 401 Bowling Ave #7, Nashville, TN  37212, United States","The success of classification learning has led to numerous attempts to apply it in adversarial settings such as spam and malware detection. The core challenge in this class of applications is that adversaries are not static, but make a deliberate effort to evade the classifiers. We investigate both the problem of modeling the objectives of such adversaries, as well as the algorithmic problem of accounting for rational, objective-driven adversaries. We first present a general approach based on mixed-integer linear programming (MILP) with constraint generation. This approach is the first to compute an optimal solution to adversarial loss minimization for two general classes of adversarial evasion models in the context of binary feature spaces. To further improve scalability and significantly generalize the scope of the MILP-based method, we propose a principled iterative retraining framework, which can be used with arbitrary classifiers and essentially arbitrary attack models. We show that the retraining approach, when it converges, minimizes an upper bound on adversarial loss. Extensive experiments demonstrate that the mixed-integer programming approach significantly outperforms several state-of-the-art adversarial learning alternatives. Moreover, the retraining framework performs nearly as well, but scales significantly better. Finally, we show that our approach is robust to misspecifications of the adversarial model. © 2018 ACM.","Adversarial classification; Adversarial examples; Classifier evasion; Mixed-integer linear programming; Robust learning","Iterative methods; Malware; Adversarial classifications; Adversarial examples; Classification learning; Constraint generation; Mixed integer linear programming; Mixed integer linear programming (MILP); Mixed integer programming; Robust learning; Integer programming",,,,,"Deshpande, V.P., Erbacher, R.F., Harris, C., An evaluation of Naïve Bayesian anti-spam filtering techniques (2007) Information Assurance and Security Workshop (IAW'07), , IEEE SMC, IEEE; Androutsopoulos, I., Magirou, E.F., Vassilakis, D.K., A game theoretic model of spam e-mailing (2005) Proceedings of The 2nd Conference on Email and Anti-Spam (CEAS'05); Barreno, M., Bartlett, P.L., Chi, F.J., Joseph, A.D., Nelson, B., Rubinstein, B.I.P., Saini, U., Doug Tygar, J., Open problems in the security of learning (2008) Proceedings of The 1st ACM Workshop on Workshop on AISec, pp. 19-26. , ACM; Barreno, M., Nelson, B., Joseph, A.D., Tygar, J.D., The security of machine learning (2010) Machine Learning, 81 (2), pp. 121-148. , 2010; Biggio, B., Fumera, G., Roli, F., Security evaluation of pattern classifiers under attack (2014) IEEE Transactions on Knowledge and Data Engineering, 26 (4), pp. 984-996. , 2014; Boyd, S., Vandenberghe, L., (2004) Convex Optimization, , Cambridge University Press; Brückner, M., Scheffer, T., Nash equilibria of static prediction games (2009) Proceedings of The Advances in Neural Information Processing Systems, pp. 171-179; Brückner, M., Scheffer, T., Stackelberg games for adversarial prediction problems (2011) Proceedings of The 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 547-555. , ACM; Carreras, X., Marquez, L., (2001) Boosting Trees for Anti-Spam Email Filtering, , cs/0109015; Cohen, W.W., (2009) Enron Email Dataset, , 2009; Dalvi, N., Domingos, P., Sanghai, S., Verma, D., Adversarial classification (2004) Proceedings of The 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 99-108. , ACM; Ghaoui, L.E., Lanckriet, G.R.G., Natsoulis, G., (2003) Robust Classification with Interval Data, , others. Computer Science Division, University of California; Fawcett, T., In vivo spam filtering: A challenge problem for KDD (2003) ACM SIGKDD Explorations Newsletter, 5 (2), pp. 140-148. , 2003; Fawcett, T., Provost, F., Adaptive fraud detection (1997) Data Mining and Knowledge Discovery, 1 (3), pp. 291-316. , 1997, Amir Globerson and Sam Roweis. 2006. Nightmare at test time: Robust learning by feature deletion. In Proceedings of the 23rd International Conference on Machine Learning. ACM, 353-360; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Goodman, J., Cormack, G.V., Heckerman, D., Spam and the ongoing battle for the inbox (2007) Communications of The ACM, 50 (2), pp. 25-33. , 2007; Gyongi, Z., Garcia-Molina, H., Spam: It's not just for inboxes anymore (2005) Computer, 38 (10), pp. 28-34. , 2005; Hinde, S., Spam: The evolution of a nuisance (2003) Computers & Security, 22 (6), pp. 474-478. , 2003; Huber, P.J., (2011) Robust Statistics, , Springer; Kantchelian, A., Tygar, J.D., Joseph, A.D., (2015) Evasion and Hardening of Tree Ensemble Classifiers, , arXiv; Karlberger, C., Bayler, G., Kruegel, C., Kirda, E., Exploiting redundancy in natural language to penetrate Bayesian spam filters (2007) Proceedings of The Workshop on Offensive Technologies (WOOT'07), 7, pp. 1-7. , 2007; Ke, L., Li, B., Vorobeychik, Y., Behavioral experiments in email filter evasion (2016) Proceedings of The AAAI Conference on Artificial Intelligence; Kearns, M., Li, M., Learning in the presence of malicious errors (1993) SIAM Journal on Computing, 22 (4), pp. 807-837. , 1993; Klimt, B., Yang, Y., The enron corpus: A new dataset for email classification research (2004) Proceedings of The European Conference on Machine Learning (ECML'04), pp. 217-226. , Springer; Kloft, M., Laskov, P., Security analysis of online centroid anomaly detection (2012) The Journal of Machine Learning Research, 13 (1), pp. 3681-3724. , 2012; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial machine learning at scale (2017) Proceedings of The International Conference on Learning Representations; Lakhina, A., Crovella, M., Diot, C., Diagnosing network-wide traffic anomalies (2004) Proceedings of The ACM SIGCOMM Conference on Applications, Technologies, Architectures, and Protocols for Computer Communications (SIGCOMM'04), 34, pp. 219-230. , ACM; Laskov, P., Lippmann, R., Machine learning in adversarial environments (2010) Machine Learning, 81 (2), pp. 115-119. , 2010; LeCun, Y., Cortes, C., (2010) MNIST Handwritten Digit Database, , http://yann.lecun.com/exdb/mnist, Retrieved from; Li, B., Vorobeychik, Y., Feature cross-substitution in adversarial classification (2014) Proceedings of The Advances in Neural Information Processing Systems, pp. 2087-2095; Li, B., Vorobeychik, Y., Scalable optimization of randomized operational decisions in adversarial classification settings (2015) Proceedings of The 18th International Conference on Artificial Intelligence and Statistics, pp. 599-607; Lichman, M., (2013) UCI Machine Learning Repository, , http://archive.ics.uci.edu/ml, 2013); Liu, W., Chawla, S., A game theoretical model for adversarial learning (2009) Proceedings of The IEEE International Conference on Data Mining Workshops (ICDMW'09), pp. 25-30. , IEEE; Liu, W., Chawla, S., Mining adversarial patterns via regularized loss minimization (2010) Machine Learning, 81 (1), pp. 69-83. , 2010; Lowd, D., Meek, C., Adversarial learning (2005) Proceedings of The 11th ACM SIGKDD International Conference on Knowledge Discovery in Data Mining, pp. 641-647. , ACM; Mahoney, M.V., Chan, P.K., Learning nonstationary models of normal network traffic for detecting novel attacks (2002) Proceedings of The 8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 376-385. , ACM; McCormick, G.P., Computability of global solutions to factorable nonconvex programs: Part I. Convex underestimating problems (1976) Mathematical Programming, 10 (1), pp. 147-175. , 1976; Metsis, V., Androutsopoulos, I., Paliouras, G., Spam filtering with naive Bayes-which naive bayes? (2006) Proceedings of The 3rd Conference on Email and Anti-Spam (CEAS'06), pp. 27-28; Nelson, B., Rubinstein, B., Huang, L., Joseph, A., Lee, S., Rao, S., Tygar, J.D., Query strategies for evading convex-inducing classifiers (2012) Journal of Machine Learning Research, 13, pp. 1293-1332. , 2012; Nelson, B., Rubinstein, B.I.P., Huang, L., Joseph, A.D., Lee, S.J., Rao, S., Tygar, J.D., Query strategies for evading convex-inducing classifiers (2012) The Journal of Machine Learning Research, 13 (1), pp. 1293-1332. , 2012; Nelson, B., Rubinstein, B.I.P., Huang, L., Joseph, A.D., Tygar, J.D., Classifier evasion: Models and open problems (2011) Proceedings of The International Workshop on Privacy and Security Issues in Data Mining and Machine Learning, pp. 92-98. , Springer; Newsome, J., Karp, B., Song, D., Paragraph: Thwarting signature learning by training maliciously (2006) Proceedings of The International Workshop on Recent Advances in Intrusion Detection, pp. 81-105. , Springer; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Proceedings of The IEEE Conference on Computer Vision and Pattern Recognition (CVPR'15), pp. 427-436. , IEEE; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-Box Attacks Using Adversarial Samples; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., (2016) Practical Black-Box Attacks Against Deep Learning Systems Using Adversarial Examples; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2016) Prceedings of The IEEE European Symposium on Security and Privacy (EuroS&P'16), pp. 372-387. , IEEE; Parameswaran, M., Rui, H., Sayin, S., A game theoretic model and empirical analysis of spammer strategies (2010) Proceedings of The 7th Annual Collaboration, Electronic Messaging, AntiAbuse and Spam Conference, 7; Peterson, L.E., K-nearest neighbor (2009) Scholarpedia, 4 (2), p. 1883. , 2009; Pita, J., Tambe, M., Kiekintveld, C., Cullen, S., Steigerwald, E., GUARDS: Game theoretic security allocation on a national scale (2011) Proceedings of The 10th International Conference on Autonomous Agents and Multiagent Systems-Volume 1, pp. 37-44. , ternational Foundation for Autonomous Agents and Multiagent Systems; Ramachandran, A., Feamster, N., Understanding the network-level behavior of spammers (2006) Proceedings of The ACM SIGCOMM Conference on Applications, Technologies, Architectures, and Protocols for Computer Communications, 36 (4), pp. 291-302. , 2006; Ramachandran, A., Feamster, N., Vempala, S., Filtering spam with behavioral blacklisting (2007) Proceedings of The ACM Conference on Computer and Communications Security, pp. 342-351; Rao, J.M., Reiley, D.H., The economics of spam (2012) Journal of Economic Perspectives, 26 (3), pp. 87-110. , 2012; Reshef, E., Solan, E., The effects of anti-spam methods on spam mail (2006) Proceedings of The Conference on Email and Anti-Spam; Rubinstein, B.I.P., Nelson, B., Huang, L., Joseph, A.D., Lau, S.-H., Rao, S., Taft, N., Tygar, J.D., Antidote: Understanding and defending against poisoning of anomaly detectors (2009) Proceedings of The 9th ACM SIGCOMM Conference on Internet Measurement Conference, pp. 1-14. , ACM; Sabour, S., Cao, Y., Faghri, F., Fleet, D.J., (2015) Adversarial Manipulation of Deep Representations; Sahami, M., Dumais, S., Heckerman, D., Horvitz, E., A Bayesian approach to filtering junk e-mail (1998) Proceedings of The Papers from The Workshop on Learning for Text Categorization, 62, pp. 98-105; Smutz, C., Stavrou, A., Malicious PDF detection using metadata and structural features (2012) Proceedings of The Annual Computer Security Applications Conference, pp. 239-248; Srndic, N., Laskov, P., Detection of malicious PDF files based on hierarchical document structure (2013) Proceedings of The Annual Network & Distributed System Security Symposium; Tabacof, P., Valle, E., (2015) Exploring The Space of Adversarial Images; Teo, C.H., Globerson, A., Roweis, S.T., Smola, A.J., Convex learning with invariances (2007) Proceedings of The 21st Annual Conference on Neural Information Processing Systems (NIPS'07), 20, pp. 1489-1496; Torkamani, M., Lowd, D., Convex adversarial collective classification (2013) Proceedings of The 30th International Conference on Machine Learning, pp. 642-650; Tyler, D.E., Robust statistics: Theory and methods (2008) Journal of The American Statistical Association, 103 (482), pp. 888-889. , 2008; Vassilakis, D.K., Androutsopoulos, I., Magirou, E.F., A game-theoretic investigation of the effect of human interactive proofs on spam e-mail (2007) Proceedings of The Conference on Email and Anti-Spam; Venkataraman, S., Blum, A., Song, D., (2008) Limits of Learning-Based Signature Generation with Adversaries, , 2008; Vorobeychik, Y., Li, B., Optimal randomized classification in adversarial settings (2014) Proceedings of The International Conference on Autonomous Agents and Multiagent Systems; Wagner, D., Resilient aggregation in sensor networks (2004) Proceedings of The 2nd ACM Workshop on Security of Ad Hoc and Sensor Networks, pp. 78-87. , ACM; Xu, H., Caramanis, C., Mannor, S., Robustness and regularization of support vector machines (2009) Journal of Machine Learning Research, 10, pp. 1485-1510. , Jul. 2009; Ying, K., Jie, Z., Learning to filter unsolicited commercial e-mail (2012) International Proceedings of Computer Science & Information Technology, 49. , 2012; Zhang, F., Chan, P.P.K., Biggio, B., Yeung, D.S., Roli, F., (2015) Adversarial Feature Selection Against Evasion Attacks, , 2015; Zhou, Y., Kantarcioglu, M., Adversarial learning with Bayesian hierarchical mixtures of experts (2014) Proceedings of The SIAM International Conference on Data Mining, pp. 929-937; Zhou, Y., Kantarcioglu, M., Thuraisingham, B., Xi, B., Adversarial support vector machine learning (2012) Proceedings of The SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 1059-1067",,,,"Association for Computing Machinery",,,,,15564681,,,,"English","ACM Trans. Knowl. Discov. Data",Article,"Final","All Open Access, Bronze",Scopus,2-s2.0-85051469625
"Duddu V.","57202859043;","A survey of adversarial machine learning in cyber warfare",2018,"Defence Science Journal","68","4",,"356","366",,17,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049580491&partnerID=40&md5=e3880809e92c62f0c680e4a76d8d2aae","Indraprastha Institute of Information Technology, Delhi, 110 020, India","Duddu, V., Indraprastha Institute of Information Technology, Delhi, 110 020, India","The changing nature of warfare has seen a paradigm shift from the conventional to asymmetric, contactless warfare such as information and cyber warfare. Excessive dependence on information and communication technologies, cloud infrastructures, big data analytics, data-mining and automation in decision making poses grave threats to business and economy in adversarial environments. Adversarial machine learning is a fast growing area of research which studies the design of Machine Learning algorithms that are robust in adversarial environments. This paper presents a comprehensive survey of this emerging area and the various techniques of adversary modelling. We explore the threat models for Machine Learning systems and describe the various techniques to attack and defend them. We present privacy issues in these models and describe a cyber-warfare test-bed to test the effectiveness of the various attack-defence strategies and conclude with some open problems in this area of research. © 2018 DESIDOC.","Adversarial machine learning; Adversary modelling; Cyber attacks; Privacy; Security","Computer crime; Data Analytics; Data mining; Data privacy; Decision making; Learning algorithms; Network security; Surveys; Adversarial environments; Cloud infrastructures; Cyber-attacks; Information and Communication Technologies; Paradigm shifts; Privacy issue; Security; Various attacks; Machine learning",,,,,"Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I.P., Tygar, J.D., (2011) Adversarial Machine Learning, pp. 43-58. , Chicago, Illinois, uSA. AISec' 11, October 21; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) The International Conference on Learning Representations (ICLR), San Diego, CA, USA; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial examples in the physical world (2017) The International Conference on Learning Representations (ICLR), Toulon, France; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial machine learning at scale (2017) The International Conference on Learning Representations (ICLR), Toulon, France; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., Adversarial Examples for Semantic Segmentation and Object Detection, , [cs.CV]; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) IEEE European Symposium on Security and Privacy (EuroS&P), pp. 372-387; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy, San Jose, CA, USA, pp. 39-57; Biggio, B., Nelson, B., Laskov, P., Support vector machines under adversarial label noise (2011) JMLR: Workshop and Conference Proceeding, Taoyuan, Taiwan, pp. 97-112; Srndic, N., Laskov, P., Practical evasion of a learning-based classifer: A case study (2014) IEEE Symposium on Security and Privacy, San Jose, CA, USA, pp. 197-211; Xu, W., Qi, Y., Evans, D., Automatically evading classifers: A case study on PDF malware classifers Network and Distributed System Security Symposium 2016 (NDSS), San Diego, February 2016; Khorshidpour, Z., Hashemi, S., Hamzeh, A., Learning a secure classifer against evasion attack (2016) IEEE 16th International Conference on Data Mining Workshop, Barcelona, Spain, pp. 295-302; Liang, B., Li, H., Su, H., Bian, M., Li, M., Shi, X., Deep Text Classifcation Can Be Fooled, , [cs. CR]; Kloft, M., Laskov, P., Online anomaly detection under adversarial impact (2010) International Conference on Artifcial Intelligence and Statistics (AISTATS), Sardinia, Italy; Biggio, B., Didaci, L., Fumera, G., Roli, F., Poisoning attacks to compromise face templates (2013) International Conference on Biometrics (ICb), Madrid, Spain, pp. 1-7; Mozafari-Kermani, M., Sur-Kolay, S., Raghunathan, A., Jha, N.K., Systematic poisoning attacks on and defenses for machine learning in healthcare (2015) J. Biom. Health Infor., 19 (6), pp. 1893-1905; Tramer, F., Zhang, F., Juels, A., Reiter, M.K., Ristenpart, T., Stealing machine learning models via prediction APIs (2016) Proceedings of 25th Usenix Security Symposium, Austin, Texas; Frekrikson, M., Jha, S., Ristenpart, T., Model inversion attacks that exploit confdence information and Basic Countermeasures (2015) Proceedings of the 22nd ACM SIgSAC Conference on Computer and Communications Security (CCS'15), Colorado, USA, pp. 1322-1333; Tramèr, F., Papernot, N., Goodfellow, I.J., Boneh, D., McDaniel, P., The Space of Transferable Adversarial Examples, , [stat.ML]; Papernot, N., McDaniel, P., Goodfellow, I.J., Transferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples, , [cs.CR]; Papernot, N., McDaniel, P., Goodfellow, I.J., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security (ASIA CCS'17), Abu Dhabi, pp. 506-519; Liu, Y., Chen, X., Liu, C., Song, D., Delving into Transferable Adversarial Examples and Black-box Attacks, , [cs.Lg]; Hayes, J., Danezis, G., Machine Learning As An Adversarial Service: Learning Black-box Adversarial Examples, , [cs.CR]; Shokri, R., Stronati, M., Song, C., Shmatikov, V., Membership inference attacks against machine learning models (2017) IEEE Symposium on Security and Privacy (S&P)-Oakland, pp. 3-18; Biggio, B., Fumera, G., Roli, F., Adversarial pattern classifcation using multiple classifers and randomisation (2008) Proceedings of the 2008 Joint IAPR International Workshop on Structural, Syntactic, and Statistical Pattern Recognition (SSPR'08), Florida, USA, pp. 500-509; Biggio, B., Fumera, G., Roli, F., Multiple classifer systems under attack (2010) Proceedings of the 9th International Conference on Multiple Classifer Systems, Cairo, Egypt, pp. 74-83; Biggio, B., Fumera, G., Roli, F., Security evaluation of pattern classifers under attack (2014) IEEE Transactions on Knowledge and Data Engineering, 26 (4), pp. 984-996; Lowd, D., Meek, C., (2005) Adversarial Learning, pp. 641-647. , KDD, Illinois, uSA; Grobhans, M., Sawade, C., Bruckner, M., Schefer, T., Bayesian games for adversarial regression problems (2013) Proceedings of the 30th International Conference on International Conference on Machine Learning, Atlanta, GA, USA, pp. 55-63; Biggio, B., Nelson, B., Laskov, P., Poisoning attacks against support vector machine (2012) ICML, Edinburg, Scotland, pp. 1467-1474; Xiao, H., Xiao, H., Eckert, C., Adversarial label fips attack on support vector machines (2012) ECAI'12 Proceedings of the 20th European Conference on Artifcial Intelligence, Montpellier, France, pp. 870-875; Xiao, H., Biggio, B., Nelson, B., Xiao, H., Eckert, C., Roli, F., Support vector machines under adversarial label contamination (2014) Neurocomputing, 160 (C), pp. 53-62; Burkard, C., Lagesse, B., Analysis of causative attacks against SVMs learning from data streams (2017) IWSPA, Scottsdale, Arizona, pp. 31-36; Szegedy, C., Erhan, D., Ilya Sutskever, W.Z., Goodfellow, I.J., Bruna, J., Fergus, R., Intriguing Properties of Neural Networks, , [cs.CV]; Gu, T., Dolan-Gavitt, B., Garg, S., BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain, , [cs.CR]; Dezfooli, S.M., Fawzi, A., Frossard, P., DeepFool: A simple and accurate method to fool deep neural networks (2016) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2574-2582; Munoz-Gonzalez, L., Biggio, B., Demontis, A., Paudice, A., Wongrassamee, V., Lupu, E.C., Roli, F., Towards poisoning of deep learning algorithms with back-gradient optimization (2017) Proceedings of the 10th ACM Workshop on Artifcial Intelligence and Security, pp. 27-38; Narodytska, N., Kasiviswanathan, S., Simple black-box adversarial attacks on deep neural networks (2017) IEEE Conference on Computer Vision and Pattern Recognition Workshop, Hawaii, USA, pp. 1310-1318; Papernot, N., McDaniel, P., Swami, A., Harang, R., Crafting adversarial input sequences for recurrent neural networks (2016) Military Communications Conference, MILCOM, LA, USA; Goodfellow, I.J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) NIPS'14 Proceedings of the 27th International Conference on Neural Information Processing Systems, Montreal, Canada, pp. 2672-2680; Hu, W., Tan, Y., Generating Adversarial Malware Examples for Black-box Attacks Based on GAN, , [cs.Lg]; Shen, S., Jin, G., Gao, K., APEgAN: Adversarial Perturbation Elimination with GAN, , [cs.CV]; Kos, J., Fischer, I., Song, D., Adversarial Examples for Generative Models, , [stat.ML]; Tabacof, P., Tavares, J., Valle, E., Adversarial Images for Variational Autoencoders, , [cs.NE]; Makhzani, A., Shlens, J., Jaitly, N., Goodfellow, I.J., Frey, B., Adversarial Autoencoders, , [cs.Lg]; Biggio, B., Pillai, I., Rota Bulo, S., Ariu, D., Pelillo, M., Roli, F., Is data clustering in adversarial settings secure? (2013) AISec, Berlin, Germany, pp. 87-98; Dutrisac, J.D., Skillicorn, D.B., Hiding clusters in adversarial settings (2008) IEEE International Conference on Intelligence and Security Informatics(ISI), pp. 185-197; Biggio, B., Poisoning complete-linkage hierarchical clustering (2014) Joint IAPR Int'l Workshop on Structural, Syntactic, and Statistical Pattern Recognition (LNCS), Joensuu, Finland, 8621, pp. 42-52; Biggio, B., Poisoning behavioral malware clustering Proceedings of the 2014 ACM Workshop on Artifcial Intelligence and Security, Colocated with CCS '14, Scottsdale, Arizona, USA, 2014, pp. 27-36; Uther, W., Veloso, M., (1997) Adversarial Reinforcement Learning.; Behzadan, V., Munir, A., Vulnerability of deep reinforcement learning to policy induction attacks (2017) International Conference on Machine Learning and Data Mining in Pattern Recognition; Huang, S., Papernot, N., Goodfellow, I.J., Duan, Y., Abbeel, P., Adversarial Attacks on Neural Network Policies, , [cs.Lg]; Kos, J., Song, D., Delving into adversarial attacks on deep policies (2017) Workshop Track-ICLR; Chen Lin, Y., Wei Hong, Z., Hong Liao, Y., Shih, M., Liu, M., Sun, M., Tactics of adversarial attack on deep reinforcement learning agents (2017) Proceedings of the 26th International Joint Conference on Artifcial Intelligence, IJCAI'17, Melbourne, Australia; Xie, P., CryptoNets: Neural Networks over Encrypted Data, , [cs.Lg]; Dowlin, N., CryptoNets: Applying neural networks to encrypted data with high thorughput and accuracy (2016) Proceedings of the 33rd International Conference on Machine Learning, New York, Ny, USA, pp. 201-210; Rouhani, B.D., Sadegh Riazi, M., Koushanfar, F., DeepSecure: Scalable Provably-secure Deep Learning; Ohrimenko, O., Schuster, F., Fournet, C., Mehta, A., Nowozin, S., Vaswani, K., Costa, M., Oblivious multi-party machine learning on trusted processors (2016) 25th USENIX Security Symposium, Austin, TX, USA, pp. 619-636; Mohassel, P., Zhang, Y., SecureML: A system for scalable privacy-preserving machine learning (2015) IEEE Security and Privacy Symposium, San Jose, CA, USA, pp. 19-38; Papernot, N., Abadi, M., Erlingsson, U., Goodfellow, I.J., Talwar, K., Semi-supervised knowledge transfer for deep learning from private training data (2017) International Conference on Learning Representations (ICLR), Toulon, France; Shokri, R., Shmatikov, V., Privacy-preserving deep learning (2015) CCS'15, Colarado, USA, pp. 1310-1321; Abadi, M., McMahan, H.B., Chu, A., Mironov, I., Zhang, L., Goodfellow, I.J., Talwar, K., Deep learning with diferential privacy (2016) CCS'16, Vienna, Austria, pp. 308-318; Papernot, N., McDaniel, P., Sinha, A., Wellman, M., Towards the Science of Security and Privacy in Machine Learning; Hinton, G., Vinyals, O., Dean, J., Distilling the Knowledge in a Neural Network, , [stat.ML]; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) The 37th IEEE Symposium on Security & Privacy, San Jose, CA, USA, pp. 582-597; Carlini, N., Wagner, D., (2016) Defensive Distillation Is Not Robust to Adversarial Examples, , arXiv; Papernot, N., McDaniel, P., Extending Defensive Distillation, , [cs:Lg]; Tramer, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., Ensemble Adversarial Training, , [stat.ML]; Miyato, T., Dai, A.M., Goodfellow, I.J., Adversarial training methods for semi-supervised text classifcation (2017) International Conference on Learning Representations (ICLR), Toulon, France; Xu, W., Evans, D., Qi, Y., Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks, , [cs.CV]; Lu, J., Issaranon, T., SafetyNet, F.D., Detecting and Rejecting Adversarial Examples Robustly, , [cs.CV]; Metzen, J.K., Genewein, T., Fischer, V., Bischof, B., On Detecting adversarial perturbations (2017) ICLR, Toulon, France; Barreno, M., Nelson, B., Joseph, A.D., Tygar, J.D., The security of machine learning (2010) Machine Learning J., 81 (2), pp. 121-148; Bhagoji, A.N., Cullina, D., Sitawarin, B., Mittal, P., Enhancing Robustness of Machine Learning Systems Via Data Transformations, , [cs:CR]; Athalye, A., Sutskever, I., Synthesizing Robust Adversarial Examples, , [cs.CV]; Demontis, A., Melis, M., Biggio, B., Maiorca, D., Arp, D., Rieck, K., Corona, I., Roli, F., Yes. Machine learning can be more secure! A case study on android malware detection IEEE Transactions on Dependable and Secure Computing, 2017, p. 1. , Early Access; Xiao, H., Biggio, B., Brown, G., Fumera, G., Eckert, C., Roli, F., Is Feature selection secure against training data poisoning? (2015) The Proceedings of the 32nd International Conference on Machine Learning, Lille, France, 37, pp. 1689-1698; Zhang, F., Chan, P., Biggio, B., Yeung, D.S., Roli, F., Adversarial feature selection against evasion attacks (2016) IEEE Trans. Cybernetics, 46 (3), pp. 766-777; Ravishankar, M., Vijay Rao, D., Kumar, C.R., S. Game theory based defence mechanisms of cyber warfare (2017) 1st Conference on Latest Advances in Machine Learning and Data Science LAMDA, NIT Goa; Ravishankar, M., Vijay Rao, D., Kumar, C.R.S., A game theoretic approach to modeling jamming attacks, delay tolerant networks (2017) Def. Sci. J., 67 (3), pp. 282-290; Ravishankar, M., Vijay Rao, D., Kumar, C.R.S., A game theoretic software test-bed for cyber security of critical infrastructure (2018) Def Sci. J., 68 (1), pp. 54-63; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndic, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Lecture Notes in Computer Science, 8190, pp. 387-402","Duddu, V.; Indraprastha Institute of Information TechnologyIndia; email: vduddu@tutamail.com",,,"Defense Scientific Information and Documentation Centre",,,,,0011748X,,DSJOA,,"English","Def. Sci. J.",Article,"Final","",Scopus,2-s2.0-85049580491
"Marra F., Gragnaniello D., Verdoliva L.","57209195452;55547170900;6506573720;","On the vulnerability of deep learning to adversarial attacks for camera model identification",2018,"Signal Processing: Image Communication","65",,,"240","248",,27,"10.1016/j.image.2018.04.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046151211&doi=10.1016%2fj.image.2018.04.007&partnerID=40&md5=52fa6c48605d6aacc36fccf93d4bb7d1","University Federico II of Naples, Italy","Marra, F., University Federico II of Naples, Italy; Gragnaniello, D., University Federico II of Naples, Italy; Verdoliva, L., University Federico II of Naples, Italy","Camera model identification is a fundamental task for many investigative activities, and is drawing great attention in the research community. In this context, convolutional neural networks (CNN) are expected to provide a significant performance gain over the current state of the art, as already happened for a wide range of image processing applications. However, recent studies enlightened the vulnerability of CNNs to adversarial attacks, casting shadows on their reliability for critical applications. In this paper, we investigate the robustness to adversarial attacks of CNN-based methods for camera model identification. Several networks and attack methods are considered, both when the attacker has complete knowledge of the network and when only the training set is available. In addition, the analysis concerns both original and JPEG compressed images, to simulate a social network environment. The experiments, carried out on a publicly available dataset with images coming from 29 different camera models, shed some light on the suitability of CNN-based approaches for this task. © 2018 Elsevier B.V.","Adversarial attacks; Camera model identification; Convolutional neural networks","Cameras; Convolution; Image processing; Neural networks; Adversarial attacks; Camera model identifications; Convolutional neural network; Convolutional Neural Networks (CNN); Critical applications; Image processing applications; JPEG compressed images; Research communities; Deep learning",,,,,"Stamm, M., Wu, M., Liu, K., Information forensics: An overview of the first decade (2013) IEEE Access, 1, pp. 167-200; Kirchner, M., Gloe, T., Forensic camera model identification (2015) Handbook of Digital Forensics of Multimedia Data and Devices, , Ho T. Li S. Wiley-IEEE Press; Satta, R., Ciardulli, A., Sensor pattern noise and image similarity for picture-to-identity linking (2015) IET Comput. Vis., pp. 1-12; Caldelli, R., Becarelli, R., Amerini, I., Image origin classification based on social network provenance (2017) IEEE Trans. Inf. Forensics Secur., 12 (6), pp. 1299-1308; Verdoliva, L., Cozzolino, D., Poggi, G., A feature-based approach for image tampering detection and localization (2014), pp. 149-154. , IEEE Workshop on Information Forensics and Security; Bondi, L., Lameri, S., Güera, D., Bestagini, P., Delp, E., Tubaro, S., Tampering detection and localization through clustering of camera-based CNN features (2017), IEEE Computer Vision and Pattern Recognition Workshops; Galdi, C., Nappi, M., Dugelay, J.-L., Multimodal authentication on smartphones: Combining iris and sensor recognition for a double check of user identity (2016) Pattern Recognit. Lett., 82, pp. 144-153; Bayram, S., Sencar, H., Memon, N., Avcibas, I., Source camera identification based on CFA interpolation (2005), pp. 69-72. , IEEE Int. Conference on Image Processing; Cao, H., Kot, A., Accurate detection of demosaicing regularity for digital image forensics (2009) IEEE Trans. Inf. Forensics Secur., 4 (4), pp. 899-910; Fan, N., Jin, C., Huang, Y., Source camera identification by JPEG compression statistics for image forensics (2006), pp. 1-4. , TENCON; Van, L.T., Emmanuel, S., Kankanhalli, M., Identifying source cell phone using chromatic aberration (2007), pp. 883-886. , IEEE International Conference on Multimedia and Expo; Thai, T., Cogranne, R., Retraint, F., Camera model identification based on the heteroscedastic noise model (2014) IEEE Trans. Image Process., 23 (1), pp. 250-263; Qiao, T., Retraint, F., Cogranne, R., Thai, T., Individual camera device identification from jpeg images (2017) Signal Process., Image Commun., 52, pp. 74-86; Lukàš, J., Fridrich, J., Goljan, M., Digital camera identification from sensor pattern noise (2006) IEEE Trans. Inf. Forensics Secur., 1 (2), pp. 205-214; Amerini, I., Becarelli, R., Caldelli, R., Melani, A., Niccolai, M., Smartphone fingerprinting combining features of on-board sensors (2017) IEEE Trans. Inf. Forensics Secur., 12 (10), pp. 2457-2466; Gloe, T., Feature-based forensic camera model identification (2012) LNCS Transactions on Data Hiding and Multimedia Security VIII, Vol. 7228, pp. 42-62; Xu, G., Shi, Y., Camera model identification using local binary patterns (2012), pp. 392-397. , IEEE International Conference on Multimedia and Expo; Razzazi, F., Seyedabadi, A., A robust feature for single image camera identification using local binary patterns (2014), pp. 462-467. , IEEE International Symposium on Signal Processing and Information Technology; Tuama, A., Comby, F., Chaumont, M., Camera model identification based machine learning approach with high order statistics features (2016), pp. 1-5. , European Signal Processing Conference, EUSIPCO; Chen, C., Stamm, M., Camera model identification framework using an ensemble of demosaicing features (2015), pp. 1-6. , IEEE Workshop on Information Forensics and Security; Marra, F., Poggi, G., Sansone, C., Verdoliva, L., A study of co-occurrence based local features for camera model identification (2017) Multimedia Tools Appl., 76 (4), pp. 4765-4781; Tuama, A., Comby, F., Chaumont, M., Camera model identification with the use of deep convolutional neural networks (2016), pp. 1-6. , IEEE Workshop on Information Forensics and Security; Bondi, L., Baroffio, L., Güera, D., Bestagini, P., Delp, E.J., Tubaro, S., First steps toward camera model identification with convolutional neural networks (2017) IEEE Signal Process. Lett., 24 (3), pp. 259-263; Freire-Obregòn, D., Narducci, F., Barra, S., Castrillòn-Santana, M., Deep learning for source camera identification on mobile devices (2018) Pattern Recognit. Lett., , in press; He, K., Zhang, X., Ren, S., Sun, J., Delving deep into rectifiers: Surpassing human-level performance on imagenet classification (2015), pp. 1026-1034. , IEEE International Conference on Computer Vision; Marra, F., Poggi, G., Sansone, C., Verdoliva, L., Deep learning for iris sensor model identification (2017) Pattern Recognit. Lett., , in press; Böhme, R., Kirchner, M., Counter-forensics: attacking image forensics (2012) Digital Image Forensics, , Sencar Husrev Taha Memon Nasir Springer New York (Chapter 10); Gloe, A.W.T., Kirchner, M., Böhme, R., Can we trust digital image forensics? (2007), pp. 78-86. , ACM 15th Int. Conf. Multimedia; Dirik, A., Sencar, H., Memon, N., Analysis of seam-carving based anonymization of images against PRNU noise pattern-based source attribution (2014) IEEE Trans. Inf. Forensics Secur., 9 (12), pp. 2277-2290; Entrieri, J., Kirchner, M., Patch-based desynchronization of digital camera sensor fingerprints (2016) Electronic Imaging, pp. 1-9; Barni, M., Fontani, M., Tondi, B., A universal technique to hide traces of histogram-based image manipulations (2012), pp. 97-104. , ACM Multimedia and Security Workshop; Iuliani, M., Rossetto, S., Bianchi, T., Rosa, A.D., Piva, A., Barni, M., Image counter-forensics based on feature injection (2014) Media Watermarking, Security, and Forensics, Proc. SPIE, 9028, pp. 1-15; Marra, F., Poggi, G., Roli, F., Sansone, C., Verdoliva, L., Counter-forensics in machine learning based forgery detection (2015), 9409. , Proc. of SPIE; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014), International Conference on Learning Representations; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015), pp. 427-436. , IEEE Conference on Computer Vision and Pattern Recognition; Güera, D., Wang, Y., Bondi, L., Bestagini, P., Tubaro, S., Delp, E., A counter-forensic method for CNN-based camera model identification (2017), IEEE Computer Vision and Pattern Recognition Workshops; Huang, G., Liu, Z., van der Maaten, L., Weinberger, K., (2017), pp. 4700-1708. , Densely connected convolutional networks, in: IEEE Conference on Computer Vision and Pattern Recognition; Shullani, D., Fontani, M., Iuliani, M., Shaya, O.A., Piva, A., VISION: a video and image dataset for source identification (2017) EURASIP J. Inf. Secur., pp. 1-16; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016), pp. 770-778. , IEEE Conference on Computer Vision and Pattern Recognition; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015), pp. 1-9. , IEEE Conference on Computer Vision and Pattern Recognition; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016), pp. 2818-2826. , IEEE Conference on Computer Vision and Pattern Recognition; Chollet, F., Xception: Deep learning with depthwise separable convolutions (2017), pp. 1800-1807. , IEEE Conference on Computer Vision and Pattern Recognition; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) Int. Conf. Learn. Represent.; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: a simple and accurate method to fool deep neural networks (2016), pp. 2574-2582. , IEEE Conference on Computer Vision and Pattern Recognition; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016), pp. 372-387. , IEEE European Symposium on Security and Privacy; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017), arXiv:1706.06083 Towards deep learning models resistant to adversarial attacks; Papernot, N., Carlini, N., Goodfellow, I., Feinman, F.F.R., Matyasko, A., Hambardzumyan, K., Juang, Y.-L., Lin, Y.-C., (2017), arXiv:1610.00768 Cleverhans v2.0.0: an adversarial machine learning library, arXiv preprint; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017), pp. 39-57. , IEEE Symposium on Security and Privacy; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., (2016), arXiv:1602.02697 Practical black-box attacks against deep learning systems using adversarial examples, arXiv preprint","Verdoliva, L.; University Federico II of NaplesItaly; email: verdoliv@unina.it",,,"Elsevier B.V.",,,,,09235965,,SPICE,,"English","Signal Process Image Commun",Article,"Final","All Open Access, Bronze",Scopus,2-s2.0-85046151211
"Abbasinezhad-Mood D., Nikooghadam M.","57195403240;24438284400;","Design and hardware implementation of a security-enhanced elliptic curve cryptography based lightweight authentication scheme for smart grid communications",2018,"Future Generation Computer Systems","84",,,"47","57",,49,"10.1016/j.future.2018.02.034","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042874260&doi=10.1016%2fj.future.2018.02.034&partnerID=40&md5=586aec96f8c9ae47cfcf03634c520e58","Department of Computer Engineering and Information Technology, Imam Reza International University, Mashhad, Iran","Abbasinezhad-Mood, D., Department of Computer Engineering and Information Technology, Imam Reza International University, Mashhad, Iran; Nikooghadam, M., Department of Computer Engineering and Information Technology, Imam Reza International University, Mashhad, Iran","Security and privacy are among the main concerns in the smart grid adoption. The different parties of smart grid can communicate securely by means of symmetric key algorithms. However, in order to utilize the symmetric key encryption methods, the parties need to establish a common key beforehand. To do so, several key management schemes have been presented during the last decade to be employed in the context of smart grid. Quite recently, Mahmood et al. have proposed an interesting elliptic curve cryptography-based authentication and key agreement scheme for smart grid communications. They have said that their presented scheme can withstand several known attacks and can provide the perfect forward secrecy. After careful deliberation, we found that their scheme cannot provide the perfect forward secrecy. Furthermore, their scheme is vulnerable under the commonly accepted Canetti–Krawczyk adversarial model. That is to say, the private key of users and shared session keys can be easily compromised in case of ephemeral secrets leakage. As a result, to remedy the existing challenges, in this paper, an authentication scheme is proposed that can both provide the desired security features and offer better efficiency in communication and computational costs than several recently-published schemes. Finally yet importantly, the security of our proposed scheme has been validated using the widely-accepted ProVerif tool and the cryptographic elements have been implemented on a suitable hardware for smart meters. The results are indicative of the betterment of the proposed scheme for real-world applications. We hope that the obtained results be useful for other researches in this field. © 2018 Elsevier B.V.","Authentication; Elliptic curve cryptography; Ephemeral secret leakage; ProVerif; Smart grid security","Authentication; Computational efficiency; Electric power transmission networks; Geometry; Hardware; Hardware security; Network security; Public key cryptography; Smart power grids; Authentication and key agreements; Elliptic curve cryptography; Hardware implementations; Proverif; Smart Grid Communications; Smart grid securities; Symmetric key algorithms; Symmetric key encryption; Cryptography",,,,,"Kabalci, Y., A survey on smart metering and smart grid communication (2016) Renewable Sustainable Energy Rev., 57, pp. 302-318; Badra, M., Zeadally, S., Design and performance analysis of a virtual ring architecture for smart grid privacy (2014) IEEE Trans. Inf. Forensics Secur., 9 (2), pp. 321-329; Fadlullah, Z., Kato, N., Lu, R., Shen, X., Nozaki, Y., Toward secure targeted broadcast in smart grid (2012) IEEE Commun. Mag., 50 (5), pp. 150-156; Wang, H., Qin, B., Wu, Q., Xu, L., Domingo-Ferrer, J., TPP: Traceable privacy-preserving communication and precise reward for vehicle-to-grid networks in smart grids (2015) IEEE Trans. Inf. Forensics Secur., 10 (11), pp. 2340-2351; Mets, K., Ojea, J.A., Develder, C., Combining power and communication network simulation for cost-effective smart grid analysis (2014) IEEE Commun. Surv. Tutor., 16 (3), pp. 1771-1796; Tonyali, S., Akkaya, K., Saputro, N., Selcuk Uluagac, A., Nojoumian, M., Privacy-preserving protocols for secure and reliable data aggregation in IoT-enabled smart metering systems (2017) Future Gener. Comput. Syst.; Liu, H., Ning, H., Zhang, Y., Xiong, Q., Yang, L.T., Role-dependent privacy preservation for secure V2G networks in the smart grid (2014) IEEE Trans. Inf. Forensics Secur., 9 (2), pp. 208-220; Lo, C.H., Ansari, N., The progressive smart grid system from both power and communications aspects (2011) IEEE Commun. Surv. Tutor.; Ma, R., Chen, H.H., Huang, Y.R., Meng, W., Smart grid communication: its challenges and opportunities (2013) IEEE Trans. Smart Grid, 4 (1), pp. 36-46; Abbasinezhad-Mood, D., Nikooghadam, M., An ultra-lightweight and secure scheme for communications of smart meters and neighborhood gateways by utilization of an ARM Cortex-M microcontroller (2017) IEEE Trans. Smart Grid; Fouda, M.M., Fadlullah, Z.M., Kato, N., Lu, R., Shen, X., A lightweight message authentication scheme for smart grid communications (2011) IEEE Trans. Smart Grid, 2 (4), pp. 675-685; Wu, D., Zhou, C., Fault-tolerant and scalable key management for smart grid (2011) IEEE Trans. Smart Grid, 2 (2), pp. 375-381; Sule, R., Katti, R.S., Kavasseri, R.G., A variable length fast message authentication code for secure communication in smart grids (2012), http://dx.doi.org/10.1109/Pesgm.2012.6345622, IEEE Power and Energy Society General Meeting., 2012; Xia, J., Wang, Y., secure key distribution for the smart grid (2012) IEEE Trans. Smart Grid, 3 (3), pp. 1437-1443; Park, J.H., Kim, M., Kwon, D., Security weakness in the smart grid key distribution scheme proposed by Xia and Wang (2013) IEEE Trans. Smart Grid, 4 (3), pp. 1613-1614; Mahmood, K., Ashraf Chaudhry, S., Naqvi, H., Shon, T., Farooq Ahmad, H., A lightweight message authentication scheme for smart grid communications in power sector (2016) Comput. Electr. Eng., pp. 114-124; Mahmood, K., Chaudhry, S.A., Naqvi, H., Kumari, S., Li, X., Sangaiah, A.K., An elliptic curve cryptography based lightweight authentication scheme for smart grid communication (2017) Future Gener. Comput. Syst.; Canetti, R., Krawczyk, H., Analysis of key-exchange protocols and their use for building secure channels (2001) Advances in Cryptology, pp. 453-474. , Springer; Hankerson, D., Menzes, A.J., Vanstone, S., Guide To Elliptic Curve Cryptography (2004), springer; Hafiz Islam, S.K., Biswas, G.P., Design of two-party authenticated key agreement protocol based on ECC and self-certified public keys (2015) Wirel. Pers. Commun., 82 (4), pp. 2727-2750; Schnorr, C.-P., Efficient signature generation by smart cards (1991) J. Cryptol., 4 (3), pp. 161-174; Cheng, Z., (2005), On the indistinguishability-based security model of key agreement protocols-simple cases., IACR Cryptology ePrint Archive; http://prosecco.gforge.inria.fr/personal/bblanche/proverif, ProVerif; Kilinc, H.H., Yanik, T., A survey of SIP authentication and key agreement schemes (2014) IEEE Commun. Surv. Tutor., 16 (2), pp. 1005-1023; Badra, M., Zeadally, S., Lightweight and efficient privacy-preserving data aggregation approach for the smart grid (2017) Ad Hoc Networks; Abbasinezhad-Mood, D., Nikooghadam, M., Efficient anonymous password-authenticated key exchange protocol to read isolated smart meters by utilization of extended Chebyshev chaotic maps (2018) IEEE Trans. Industrial Inform.; Cataliotti, A., (2015), http://dx.doi.org/10.1109/amps.2015.7312745, Experimental evaluation of an hybrid communication system architecture for smart grid applications, in: 2015 IEEE International Workshop on Applied Measurements for Power Systems (AMPS) September; http://www.nxp.com/docs/en/data-sheet/LPC1769_68_67_66_65_64_63.pdf; http://rweather.github.io/arduinolibs/crypto.html, ArduinoLibs: Cryptographic library","Nikooghadam, M.; Department of Computer Engineering and Information Technology, Iran; email: m.nikooghadam@imamreza.ac.ir",,,"Elsevier B.V.",,,,,0167739X,,FGCSE,,"English","Future Gener Comput Syst",Article,"Final","",Scopus,2-s2.0-85042874260
"Dong B., Wang H.W.","55813342900;34880986300;","Secure partial encryption with adversarial functional dependency constraints in the database-as-a-service model",2018,"Data and Knowledge Engineering","116",,,"1","20",,,"10.1016/j.datak.2018.01.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041594107&doi=10.1016%2fj.datak.2018.01.001&partnerID=40&md5=d8089f7dc641b68a5ce2a9ee22d28035","Department of Computer Science, Montclair State University, Montclair, NJ  07043, United States; Department of Computer Science, Stevens Institute of Technology, Hoboken, NJ  07030, United States","Dong, B., Department of Computer Science, Montclair State University, Montclair, NJ  07043, United States; Wang, H.W., Department of Computer Science, Stevens Institute of Technology, Hoboken, NJ  07030, United States","Cloud computing enables end-users to outsource their dataset and data management needs to a third-party service provider. One of the major security concerns of the outsourcing paradigm is how to protect sensitive information in the outsourced dataset. In some applications, only partial values are considered sensitive. In general, the sensitive information can be protected by encryption. However, data dependency constraints (together with the unencrypted data) in the outsourced data may serve as adversary knowledge and bring security vulnerabilities to the encrypted data. In this paper, we focus on functional dependency (FD), an important type of data dependency constraints, and study the security threats by the adversarial FDs. We design a practical scheme that can defend against the FD attack by encrypting a small amount of non-sensitive data (encryption overhead). We prove that finding the scheme that leads to the optimal encryption overhead is NP-complete, and design efficient heuristic algorithms, under the presence of one or multiple FDs. We design a secure query rewriting scheme that enables the service provider to answer various types of queries on the encrypted data with provable security guarantee. We extend our study to enforce security when there are conditional functional dependencies (CFDs) and data updates. We conduct an extensive set of experiments on two real-world datasets. The experiment results show that our heuristic approach brings small amounts of encryption overhead (at most 1% more than the optimal overhead), and enjoys a 10-time speedup compared with the optimal solution. Besides, our approach can reduce up to 90% of the encryption overhead of state-of-the-art solution. © 2018 Elsevier B.V.","Data outsourcing; Database management; Database-as-a-service; Management of integrity constraints; Security, integrity, and protection","Database systems; Finite difference method; Heuristic algorithms; Heuristic methods; Human computer interaction; Information management; Optimization; Outsourcing; Query processing; Data outsourcing; Database as a service; Database management; Integrity constraints; Security, integrity, and protection; Cryptography",,,,,"Agrawal, R., Kiernan, J., (2004), pp. 563-574. , Ramakrishnan Srikant, Yirong Xu, Order-preserving encryption for numeric data, in: Proceedings of the ACM International Conference on Management of Data; Arasu, A., Blanas, S., (2013), Ken Eguro, Raghav Kaushik, Donald Kossmann, Ravishankar Ramamurthy, and Ramarathnam Venkatesan. Orthogonal security with cipherbase, in: Proceedings of the Conference on Innovative Data Systems Research; (1974), pp. 580-583. , Dependency structures of data base relationships, in: IFIP Congress, Geneva, Switzerland, 74; Batini, C., Lenzerini, M., Navathe, S.B., A comparative analysis of methodologies for database schema integration (1986) ACM Comput. Surv. (CSUR), pp. 323-364; Roberto, J.B., Agrawal, R., Data privacy through optimal k-anonymization (2005) in: Proceedings of the IEEE International Conference on Data Engineering, pp. 217-228; Bohannon, P., Fan, W., (2007), pp. 746-755. , Floris Geerts, Xibei Jia, and Anastasios Kementsietsidis. Conditional functional dependencies for data cleaning, in: Proceedings of the IEEE International Conference on Data Engineering; Boldyreva, A., Chenette, N., Lee, Y., Oneill, A., Order-preserving symmetric encryption (2009) Adv. Cryptol.-EUROCRYPT, pp. 224-241; Boneh, D., Di Crescenzo, G., Ostrovsky, R., Persiano, G., Public key encryption with keyword search (2004) Adv. Cryptol.-EUROCRYPT, pp. 506-522; Alexander, B., Farkas, C., Jajodia, S., Secure databases: constraints, inference channels, and monitoring disclosures (2000) IEEE Trans. Knowl. Data Eng., 12 (6), pp. 900-919; Chen, R., (2014), pp. 653-676. , Benjamin CM Fung, Philip S Yu, Bipin C Desai, Correlated network data publication via differential privacy, in: Proceedings of the International Conference on Very Large Data Bases, 23, 4; Chen, Y., Wesley, W.C., Database security protection via inference detection (2006) Intell. Secur. Inform., pp. 452-458; Chiticariu, L., (2007), pp. 1326-1329. , Mauricio A Hernández, Phokion G Kolaitis, Lucian Popa, Semi-automatic schema integration in clio, in: Proceedings of the International Conference on Very Large Data Bases; Ciriani, V., Capitani Di Vimercati, S.D., Foresti, S., Jajodia, S., Paraboschi, S., Samarati, P., Sara Foresti, Sushil Jajodia, Stefano Paraboschi, Pierangela Samarati. Combining fragmentation and encryption to protect privacy in data storage (2010) ACM Trans. Inform. Syst. Secur., 13 (3), p. 22; Clifton, C., Tassa, T., (2013), pp. 88-93. , On syntactic anonymity and differential privacy, in: Proceedings of the IEEE International Conference on Data Engineering Workshops (ICDEW); Coppersmith, D., The data encryption standard (des) and its strength against attacks (1994) IBM J. Res. Dev., 38 (3), pp. 243-250; Curino, C., Jones, E., Zhang, Y., Wu, E., Madden, S., Relational cloud: the case for a database service (2010) N. Engl. Database Summit, pp. 1-6; Cynthia, D., Differential privacy (2006) Automata Lang. Programm., pp. 1-12; Daemen, J., Rijmen, V., (1999), Aes proposal: Rijndael; Damiani, E., (2003), pp. 93-102. , S. De Capitanidi Vimercati, Sushil Jajodia, Stefano Paraboschi, Pierangela Samarati. Balancing confidentiality and efficiency in untrusted relational dbmss, in: Proceedings of the ACM Conference on Computer and Communications Security; Anand, D., New paradigms for constructing symmetric encryption schemes secure against chosen-ciphertext attack (2000) Adv. Cryptol.-CRYPT, pp. 394-412; Dong, B., Wang, W., (2016), pp. 73-78. , Jie Yang, Secure data outsourcing with adversarial data dependency constraints, in: Proceedings of the IEEE International Conference on Big Data Security on Cloud; (2016), pp. 1155-1166. , F Betül Durak, Thomas M DuBuisson, David Cash, What else is revealed by order-revealing encryption? in: Proceedings of the ACM Conference on Computer and Communications Security; Fan, L., Xiong, L., An adaptive approach to real-time aggregate monitoring with differential privacy (2014) IEEE Trans. Knowl. Data Eng., pp. 2094-2106; Fan, W., Geerts, F., Li, J., Xiong, M., Discovering conditional functional dependencies (2011) IEEE Transactions on Knowledge and Data Engineering, 23 (5), pp. 683-698; Joseph, A., Goguen, Jos Meseguer, Unwinding and inference control (1984), pp. 75-87. , Proceedings of the IEEE Symposium on Security and Privacy; (2002), pp. 29-38. , Hakan Hacigümüs, Balakrishna R. Iyer, Sharad Mehrotra, Providing database as a service, in: Proceedings of the IEEE International Conference on Data Engineering; (2014), pp. 16-27. , Hakan Hacigümüs, Balakrishna R. Iyer, Sharad Mehrotra. Secure computation on outsourced data: A 10-year retrospective, in: Proceedings of the International Conference on Database Systems for Advanced Applications; Hang, I., Kerschbaum, F., (2015), pp. 183-196. , Ernesto Damiani, Enki: access control for encrypted query processing, in: Proceedings of the ACM International Conference on Management of Data; Hawkes, P., Rose, G.G., A mode of operation with partial encryption and message integrity (pemi) (2003) IACR Cryptol. ePrint Arch., pp. 1-8; Hay, M., Rastogi, V., (2010), pp. 1021-1032. , Gerome Miklau, Dan Suciu, Boosting the accuracy of differentially private histograms through consistency, in: Proceedings of the International Conference on Very Large Data Bases; Huhtala, Y., Kärkkäinen, J., Porkka, P., Toivonen, H., Tane: an efficient algorithm for discovering functional and approximate dependencies (1999) Comput. J., 42 (2), pp. 100-111; (2012), pp. 12-23. , Mohammad Saiful Islam, Mehmet Kuzu, Murat Kantarcioglu, Access pattern disclosure on searchable encryption: Ramification, attack and mitigation, in: Proceedings of the Network and Distributed System Security Symposium, 20; (2014), pp. 235-246. , Mohammad Saiful Islam, Mehmet Kuzu, Murat Kantarcioglu. Inference attack against encrypted range queries on outsourced databases, in: Proceedings of the ACM Conference on Data and Application Security and Privacy; Kerschbaum, F., (2015), pp. 656-667. , Frequency-hiding order-preserving encryption, in: Proceedings of the ACM Conference on Computer and Communications Security; Kifer, D., Machanavajjhala, A., (2011), pp. 193-204. , No free lunch in data privacy, in: Proceedings of the ACM International Conference on Management of Data; Li, C., Shirani-Mehr, H., Yang, X., Protecting individual information against inference attacks in data publishing (2007) Adv. Databases: Concepts Syst. Appl., 7, pp. 422-433; Li, H., Xiong, L., (2014), pp. 1677-1680. , Lifan Zhang, Xiaoqian Jiang, Dpsynthesizer: differentially private data synthesizer for privacy preserving data sharing, in: Proceedings of the International Conference on Very Large Data Bases; Li, N., Qardaji, W., (2012), pp. 32-33. , Dong Su, On sampling, anonymization, and differential privacy or, k-anonymization meets differential privacy, in: Proceedings of the ACM Symposium on Information, Computer and Communications Security; Li, R., (1953), 14, pp. 2014-1964. , Alex X Liu, Ann L Wang, Bezawada Bruhadeshwar, Fast range query processing with strong privacy protection for cloud computing, in: Proceedings of the International Conference on Very Large Data Bases, 7; Liu, J., Li, J., Liu, C., Chen, Y., Discover dependencies from data: a review (2010) IEEE Trans. Knowl. Data Eng.; Machanavajjhala, A., Gehrke, J., (2006), p. 24. , Daniel Kifer, Muthuramakrishnan Venkitasubramaniam, l-diversity: Privacy beyond k-anonymity, in: Proceedings of the International Conference on Data Engineering; Meyerson, A., Williams, R., (2004), pp. 223-228. , On the complexity of optimal k-anonymity, in: Proceedings of the ACM Symposium on Principles of Database Systems; Miklau, G., Suciu, D., (2003), pp. 898-909. , Controlling access to published data using cryptography, in: Proceedings of the International Conference on Very Large Data Bases; (1993), pp. 120-133. , Renée J Miller, Yannis E Ioannidis, Raghu Ramakrishnan, The use of information capacity in schema integration and translation, in: Proceedings of the International Conference on Very Large Data Bases; Mohammed, N., Chen, R., (2011), pp. 493-501. , Benjamin Fung, Philip S Yu, Differentially private data release for data mining, in: Proceedings of the International Conference on Knowledge Discovery and Data Mining; Morgenstern, M., (1988), pp. 245-255. , Controlling logical inference in multilevel database systems, in: Proceedings of the IEEE Symposium on Security and Privacy; Naehrig, M., Lauter, K., (2011), pp. 113-124. , Vinod Vaikuntanathan, Can homomorphic encryption be practical? in: Proceedings of the ACM Workshop on Cloud Computing Security Workshop; Naveed, M., Kamara, S., (2015), pp. 644-655. , Charles V Wright, Inference attacks on property-preserving encrypted databases, in: Proceedings of the Conference on Computer and Communications Security; Papenbrock, T., Ehrlich, J., (2015), pp. 1082-1093. , Jannik Marten, Tommy Neubert, Jan-Peer Rudolph, Martin Schönberg, Jakob Zwiener, Felix Naumann, Functional dependency discovery: An experimental evaluation of seven algorithms, in: Proceedings of the International Conference on Very Large Data Bases, 8, 10; Popa, R.A., Redfield, C., Zeldovich, N., Balakrishnan, H., Cryptdb: processing queries on an encrypted database (2012) Commun. ACM, 55 (9), pp. 103-111; Rastogi, V., Nath, S., (2010), pp. 735-746. , Differentially private aggregation of distributed time-series with transformation and encryption, in: Proceedings of the International Conference on Management of Data; Smart, N.P., Vercauteren, F., Fully homomorphic encryption with relatively small key and ciphertext sizes (2010) Public Key Cryptogr. (PKC), pp. 420-443; (2000), pp. 44-55. , Dawn Xiaoding Song, David Wagner, Adrian Perrig, Practical techniques for searches on encrypted data, in: Proceedings of IEEE Symposium on Security and Privacy; Stachour, P.D., Thuraisingham, B.M., Design of ldv: a multilevel secure relational database management system (1990) IEEE Trans. Knowl. Data Eng., pp. 190-209; Su, T.-A., Ozsoyoglu, G., Controlling fd and mvd inferences in multilevel relational database systems (1991) IEEE Trans. Knowl. Data Eng., 3 (4), pp. 474-485; Sweeney, L., Achieving k-anonymity privacy protection using generalization and suppression (2002) Int. J. Uncertain. Fuzziness Knowl.-Based Syst., 10 (5), pp. 571-588; (2010), pp. 176-183. , Hui Wendy Wang, Ruilin Liu, Privacy-preserving publishing data with full functional dependencies, in: Proceedings of the International Conference on Database Systems for Advanced Applications; Wang, K., Fung, B.C., Yu, P.S., Handicapping attacker's confidence: an alternative to k-anonymization (2007) Knowl. Inform. Syst., pp. 345-368; Xiao, Y., Xiong, L., Yuan, C., Differentially private data release through multidimensional partitioning (2010) Secure Data Manag., 6358, pp. 150-168; Xu, X., Xiong, L., (2015), pp. 263-270. , Jinfei Liu, Database fragmentation with confidentiality constraints: A graph search approach, in: Proceedings of the ACM Conference on Data and Application Security and Privacy; Yao, H., (2002), pp. 729-732. , Howard J Hamilton, Cory J Butz, Fd_mine: discovering functional dependencies in a database using equivalences, in: Proceedings of the IEEE International Conference on Data Mining","Dong, B.; Department of Computer Science, United States; email: dongb@montclair.edu",,,"Elsevier B.V.",,,,,0169023X,,DKENE,,"English","Data Knowl Eng",Article,"Final","",Scopus,2-s2.0-85041594107
"Barni M., Nowroozi E., Tondi B.","7005442155;57200532119;55389019900;","Detection of adaptive histogram equalization robust against JPEG compression",2018,"IWBF 2018 - Proceedings: 2018 6th International Workshop on Biometrics and Forensics",,,,"1","8",,9,"10.1109/IWBF.2018.8401564","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050537582&doi=10.1109%2fIWBF.2018.8401564&partnerID=40&md5=3d90e0bbf4a81c6f055244af15b2f5a8","Department of Information Engineering and Mathematics, University of Siena, Via Roma 56, Siena, 53100, Italy","Barni, M., Department of Information Engineering and Mathematics, University of Siena, Via Roma 56, Siena, 53100, Italy; Nowroozi, E., Department of Information Engineering and Mathematics, University of Siena, Via Roma 56, Siena, 53100, Italy; Tondi, B., Department of Information Engineering and Mathematics, University of Siena, Via Roma 56, Siena, 53100, Italy","Contrast Enhancement (CE) detection in the presence of laundering attacks, i.e. common processing operators applied with the goal to erase the traces the CE detector looks for, is a challenging task. JPEG compression is one of the most harmful laundering attacks, which has been proven to deceive most CE detectors proposed so far. In this paper, we present a system that is able to detect contrast enhancement by means of adaptive histogram equalization in the presence of JPEG compression, by training a JPEG-aware SVM detector based on color SPAM features, i.e., an SVM detector trained on contrastenhanced- then-JPEG-compressed images. Experimental results show that the detector works well only if the Quality Factor (QF) used during training matches the QF used to compress the images under test. To cope with this problem in cases where the QF cannot be extracted from the image header, we use a QF estimation step based on the idempotency properties of JPEG compression. Experimental results show good performance under a wide range of QFs. © 2018 IEEE-CONFERENCE. All rights reserved.","Adversarial multimedia forensics; Histogram equalization detection; JPEG quality factor estimation; Multimedia forensics","Biometrics; Equalizers; Graphic methods; Image enhancement; Laundering; Adaptive histogram equalization; Contrast Enhancement; Contrast-enhanced; Histogram equalizations; JPEG compressed images; JPEG compression; Multimedia forensics; Quality factor estimation; Image compression",,,,,"Böhme, R., Kirchner, M., Counter-forensics: Attacking image forensics (2012) Digital Image Forensics, , H. T. Sencar and N. Memon, Eds. Springer Berlin/Heidelberg; Barni, M., Pérez-González, F., Coping with the enemy: Advances in adversary-aware signal processing (2013) ICASSP 2013, IEEE International Conference on Acoustics, Speech and Signal Processing, pp. 8682-8686. , Vancouver, Canada, 26-31 May; Stamm, M.C., Liu, K.R., Forensic detection of image manipulation using statistical intrinsic fingerprints (2010) IEEE Transactions on Information Forensics and Security, 5 (3), pp. 492-506; Cao, G., Zhao, Y., Ni, R., Forensic estimation of gamma correction in digital images (2010) Image Processing (ICIP), 2010 17th IEEE International Conference on. IEEE, pp. 2097-2100; Cao, G., Zhao, Y., Ni, R., Li, X., Contrast enhancement-based forensics in digital images (2014) IEEE Transactions on Information Forensics and Security, 9 (3), pp. 515-525; Cao, G., Zhao, Y., Ni, R., Tian, H., Anti-forensics of contrast enhancement in digital images (2010) Proceedings of the 12th ACM Workshop on Multimedia and Security, pp. 25-34. , ACM; Barni, M., Fontani, M., Tondi, B., A universal technique to hide traces of histogram-based image manipulations (2012) Proceedings of the on Multimedia and security., pp. 97-104. , ACM; Chen, C., Shi, Y.Q., Su, W., A machine learning based scheme for double JPEG compression detection (2008) 19th International Conference on Pattern Recognition, 2008. ICPR 2008., pp. 1-4. , IEEE; De Rosa, A., Fontani, M., Massai, M., Piva, A., Barni, M., Secondorder statistics analysis to cope with contrast enhancement counterforensics (2015) IEEE Signal Processing Letters, 22 (8), pp. 1132-1136; Pan, X., Zhang, X., Lyu, S., Exposing image forgery with blind noise estimation (2011) Proceedings of the Thirteenth ACM Multimedia Workshop on Multimedia and Security. ACM, pp. 15-20; Li, H., Luo, W., Qiu, X., Huang, J., Identification of various image operations using residual-based features (2016) IEEE Transactions on Circuits and Systems for Video Technology; Singh, N., Gupta, A., Analysis of contrast enhancement forensics in compressed and uncompressed images (2016) Signal Processing and Communication (ICSC), 2016 International Conference on., pp. 303-307. , IEEE; Barni, M., Nowroozi, E., Tondi, B., Higher-order, adversary-aware, double jpeg-detection via selected training on attacked samples (2017) 2017 25th European Signal Processing Conference (EUSIPCO), pp. 281-285. , Aug; Bestagini, P., Allam, A., Milani, S., Tagliasacchi, M., Tubaro, S., Video codec identification (2012) Acoustics, Speech and Signal Processing (ICASSP), 2012 IEEE International Conference on. IEEE, pp. 2257-2260; Fridrich, J., Kodovsky, J., Rich models for steganalysis of digital images (2012) IEEE Transactions on Information Forensics and Security, 7 (3), pp. 868-882; Verdoliva, L., Cozzolino, D., Poggi, G., A feature-based approach for image tampering detection and localization (2014) Information Forensics and Security (WIFS), 2014 IEEE International Workshop on. IEEE, pp. 149-154; Goljan, M., Fridrich, J., Cogranne, R., Rich model for steganalysis of color images (2014) Information Forensics and Security (WIFS), 2014 IEEE International Workshop on. IEEE, pp. 185-190; Pizer, S.M., Amburn, E.P., Austin, J.D., Cromartie, R., Geselowitz, A., Greer, T., Zuiderveld, K., Adaptive histogram equalization and its variations (1987) Computer vision, graphics, and image processing, 39 (3), pp. 355-368; Kodovsky, J., Fridrich, J., Holub, V., Ensemble classifiers for steganalysis of digital media (2012) IEEE Transactions on Information Forensics and Security, 7 (2), pp. 432-444; Pevny, T., Bas, P., Fridrich, J., Steganalysis by subtractive pixel adjacency matrix (2010) IEEE Transactions on Information Forensics and Security, 5 (2), pp. 215-224. , June; Zuiderveld, K., (1994) Graphics Gems IV, pp. 474-485. , http://dl.acm.org/citation.cfm?id=180895.180940, P. S. Heckbert, Ed. San Diego, CA, USA: Academic Press Professional, Inc.,ch. Contrast Limited Adaptive Histogram Equalization,. [Online]; Chang, C.-C., Lin, C.-J., LIBSVM: A library for support vector machines (2011) ACM Transactions on Intelligent Systems and Technology, 2, pp. 271-2727. , http://www.csie.ntu.edu.tw/~cjlin/libsvm, software; Dang-Nguyen, D.-T., Pasquini, C., Conotter, V., Boato, G., Raise: A raw images dataset for digital image forensics (2015) Proceedings of the 6th ACM Multimedia Systems Conference, ser. MMSys, 15, pp. 219-224. , http://doi.acm.org/10.1145/2713168.2713194, New York, NY, USA: ACM,. [Online]; Cozzolino, D., Gragnaniello, D., Verdoliva, L., Image forgery detection through residual-based local descriptors and block-matching (2014) Image Processing (ICIP), 2014 IEEE International Conference on. IEEE, pp. 5297-5301","Nowroozi, E.; Department of Information Engineering and Mathematics, Via Roma 56, Italy; email: ehsan.nowroozi@student.unisi.it",,"","Institute of Electrical and Electronics Engineers Inc.","6th International Workshop on Biometrics and Forensics, IWBF 2018","7 June 2018 through 8 June 2018",,137652,,9781538613665,,,"English","IWBF - Proc.: Int. Workshop Biom. Forensics",Conference Paper,"Final","",Scopus,2-s2.0-85050537582
"Eisen J., Watson S., Willink T.","57203021519;7401463720;6701545091;","Location constrained jamming: Surgical link removal using local graph partitioning",2018,"2018 International Conference on Military Communications and Information Systems, ICMCIS 2018",,,,"1","7",,2,"10.1109/ICMCIS.2018.8398713","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050258242&doi=10.1109%2fICMCIS.2018.8398713&partnerID=40&md5=1390ba9424cd67646727162b888b6091","Defence RandD Canada, Ottawa Research Centre, 3701 Carling Avenue, Ottawa, ON  K1A0Z4, Canada","Eisen, J., Defence RandD Canada, Ottawa Research Centre, 3701 Carling Avenue, Ottawa, ON  K1A0Z4, Canada; Watson, S., Defence RandD Canada, Ottawa Research Centre, 3701 Carling Avenue, Ottawa, ON  K1A0Z4, Canada; Willink, T., Defence RandD Canada, Ottawa Research Centre, 3701 Carling Avenue, Ottawa, ON  K1A0Z4, Canada","Knowing the topology of an adversarial network, heuristics exist based on spectral graph theory for calculating which edges, when removed, will partition the network. Knowing these weak links in the network under attack, a surgical jammer may be used to conduct man-in-the-middle attacks or to maximally affect the adversary network's connectivity. However, it is not always possible to control where the jammer is located with respect to the network. This paper describes a method to find a graph partition when, due to limited jammer range, we cannot affect all the links in the network, but the links are all known. © 2018 IEEE.",,"Graph theory; Information systems; Information use; Jamming; Military communications; Surgery; Adversarial networks; Graph partition; Graph Partitioning; Man in the middle attacks; Spectral graph theory; Weak links; Data communication systems",,,,,"Agarwal, M., Biswas, S., Nandi, S., Advanced stealth man-in-the-middle attack in WPA2 encrypted Wi-Fi networks (2015) IEEE Communications Letters, 19 (4), pp. 581-584. , April; Cassola, A., Robertson, W., Kirda, E., Noubir, G., A practical, targeted, and stealthy attack against wpa enterprise authentication (2012) NDSS, , February; Noubir, G., Rajaraman, R., Sheng, B., Thapa, B., On the robustness of IEEE 802.11 rate adaptation algorithms against smart jamming (2011) Proceedings of the Fourth ACM Conference on Wireless Network Security, Ser. WiSec '11, pp. 97-108. , New York, NY, USA: ACM; Vanhoef, M., Piessens, F., Advanced wi-fi attacks using commodity hardware (2014) Proceedings of the 30th Annual Computer Security Applications Conference, Ser. ACSAC '14, pp. 256-265. , New York, NY, USA: ACM; Spielman, D.A., Spectral graph theory and its applications (2007) Foundations of Computer Science 2007. FOCS '07. 48th Annual IEEE Symposium on, pp. 29-38. , Oct; Sawilla, R., A survey of data mining of graphs using spectral graph theory (2008) Defence R&D Canada, Technical Memorandum DRDC Ottawa TM 2008-317, , http://cradpdf.drdc.gc.ca/PDFS/unc87/p531357.pdf, December; Chen, P.Y., Choudhury, S., Hero, A.O., Multi-centrality graph spectral decompositions and their application to cyber intrusion detection (2016) 2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 4553-4557. , March; Alenazi, M.J.F., Sterbenz, J.P.G., Evaluation and improvement of network resilience against attacks using graph spectral metrics (2015) 2015 Resilience Week (RWS), pp. 1-6. , Aug; Hui, K.-P., Cooperative Cross-Entropy method for generating entangled networks (2011) Annals of Operations Research, 189 (1), pp. 205-214. , Sep; Chevalier, C., Safro, I., (2009) Comparison of Coarsening Schemes for Multilevel Graph Partitioning, pp. 191-205. , Berlin, Heidelberg: Springer, Berlin Heidelberg; Feng, J., Pasiliao, E.L., Dixon, W.E., Shea, J.M., An optimal jamming strategy to partition a wireless network (2015) MILCOM 2015-2015 IEEE Military Communications Conference, pp. 978-984. , Oct; Faramondi, L., Oliva, G., Pascucci, F., Panzieri, S., Setola, R., Critical node detection based on attacker preferences (2016) 2016 24th Mediterranean Conference on Control and Automation (MED), pp. 773-778. , June; Bollobás, B., (1998) Modern Graph Theory, , New York NY: Springer; Chung, F., Four proofs for the Cheeger inequality and graph partition algorithms (2007) Proceedings of ICCM; Penrose, M., (2003) Random Geometric Graphs, , Oxford University Press",,,"","Institute of Electrical and Electronics Engineers Inc.","2018 International Conference on Military Communications and Information Systems, ICMCIS 2018","22 May 2018 through 23 May 2018",,137544,,9781538645598,,,"English","Int. Conf. Mil. Commun. Inf. Syst., ICMCIS",Conference Paper,"Final","",Scopus,2-s2.0-85050258242
"Marra F., Gragnaniello D., Cozzolino D., Verdoliva L.","57209195452;55547170900;55440439700;6506573720;","Detection of GAN-Generated Fake Images over Social Networks",2018,"Proceedings - IEEE 1st Conference on Multimedia Information Processing and Retrieval, MIPR 2018",,,,"384","389",,104,"10.1109/MIPR.2018.00084","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050127334&doi=10.1109%2fMIPR.2018.00084&partnerID=40&md5=3ef2be23f2f02172ebc7ed9cc9258f9c","Dep. of Electrical Engineering and Information Technology, University Federico II of Naples, Naples, Italy","Marra, F., Dep. of Electrical Engineering and Information Technology, University Federico II of Naples, Naples, Italy; Gragnaniello, D., Dep. of Electrical Engineering and Information Technology, University Federico II of Naples, Naples, Italy; Cozzolino, D., Dep. of Electrical Engineering and Information Technology, University Federico II of Naples, Naples, Italy; Verdoliva, L., Dep. of Electrical Engineering and Information Technology, University Federico II of Naples, Naples, Italy","The diffusion of fake images and videos on social networks is a fast growing problem. Commercial media editing tools allow anyone to remove, add, or clone people and objects, to generate fake images. Many techniques have been proposed to detect such conventional fakes, but new attacks emerge by the day. Image-to-image translation, based on generative adversarial networks (GANs), appears as one of the most dangerous, as it allows one to modify context and semantics of images in a very realistic way. In this paper, we study the performance of several image forgery detectors against image-to-image translation, both in ideal conditions, and in the presence of compression, routinely performed upon uploading on social networks. The study, carried out on a dataset of 36302 images, shows that detection accuracies up to 95% can be achieved by both conventional and deep learning detectors, but only the latter keep providing a high accuracy, up to 89%, on compressed data. © 2018 IEEE.","convolutional neural networks; GAN; image forensics","Deep learning; Neural networks; Semantics; Social networking (online); Adversarial networks; Compressed datum; Convolutional neural network; Detection accuracy; Image forensics; Image forgery; Image translation; Media editing; Digital forensics",,,,,"Nightingale, S., Wade, K., Watson, D., Can people identify original and manipulated photos of real-world scenes? (2017) Cognitive Research: Principles and Implications, pp. 2-30; Schetinger, V., Oliveira, M., Da Silva, R., Carvalho, T., Humans are easily fooled by digital images (2017) Computers & Graphics, 68, pp. 142-151; Cozzolino, D., Gragnaniello, D., Verdoliva, L., Image forgery detection through residual-based local descriptors and block-matching (2014) IEEE Conference on Image Processing (ICIP), pp. 5297-5301. , October; Fan, S., Ng, T.-T., Koenig, B., Herberg, J., Jiang, M., Shen, Z., Zhao, Q., Image visual realism: From human perception to machine computation (2017) IEEE Transactions on Pattern Analysis and Machine Intelligence, , in press; Lyu, S., Farid, H., How realistic is photorealistic? (2005) IEEE Transactions on Signal Processing, 53 (2), pp. 845-850; Wu, R., Li, X., Yang, B., Identifying computer generated graphics via histogram features (2011) IEEE ICIP, pp. 1933-1936; Dehnie, S., Sencar, H., Memon, N., Digital image forensics for identifying computer generated and digital camera images (2006) IEEE ICIP, pp. 2313-2316; Dirik, A., Bayram, S., Sencar, H., Memon, N., New features to identify computer generated images (2006) IEEE ICIP, pp. 433-436. , Oct; Gallagher, A., Chen, T., Image authentication by detecting traces of demosaicing (2008) IEEE CVPR Workshops, pp. 1-8. , June; Lalonde, J.-F., Efros, A., Using color compatibility for assessing image realism (2007) IEEE ICCV, pp. 1-8. , Oct; Zhang, R., Wang, R.-D., Ng, T.-T., Distinguishing photographic images and photorealistic computer graphics using visual vocabulary on local image edges (2011) International Workshop on Digital Forensics and Watermarking, pp. 292-305. , Oct; Dang-Nguyen, D.-T., Boato, G., Natale, F.D., Discrimination between computer generated and natural human faces based on asymmetry information (2012) Eusipco, pp. 1234-1238; Rahmouni, N., Nozick, V., Yamagishi, J., Echizeny, I., Distinguishing computer graphics from natural images using convolution neural networks (2017) IEEE WIFS, pp. 1-6; De Rezende, E., Ruppert, G., Carvalho, T., Detecting computer generated images with deep convolutional neural networks (2017) SIBGRAPI Conference on Graphics, Patterns and Images, pp. 71-78; Holmes, O., Banks, M., Farid, H., Assessing and improving the identification of computer generated portraits (2016) ACM Transactions on Applied Perception, 13, pp. 1-12; Thies, J., Zollhöfer, M., Stamminger, M., Theobalt, C., Nießner, M., Face2Face: Real-time face capture and reenactment of RGB videos (2016) IEEE CVPR, pp. 2387-2395; Isola, P., Zhu, J.-Y., Zhou, T., Efros, A.A., Image-toimage translation with conditional adversarial networks (2017) IEEE CVPR; Zhu, J.Y., Park, T., Isola, P., Efros, A.A., Unpaired image-to-image translation using cycle-consistent adversarial networks (2017) IEEE ICCV; Shrivastava, A., Pfister, T., Tuzel, O., Susskind, J., Wang, W., Webb, R., Learning from simulated and unsupervised images through adversarial training (2017) IEEE CVPR; Liu, M.-Y., Breuel, T., Kautz, J., Unsupervised image-toimage translation networks (2017) NIPS; Haouchine, N., Roy, F., Courtecuisse, H., Nießner, M., Cotin, S., (2017) Calipso: Physics-based Image and Video Editing Through Cad Model Proxies, , arXiv preprint arXiv; Zampoglou, M., Papadopoulos, S., Kompatsiaris, Y., Large-scale evaluation of splicing localization algorithms for web images (2017) Multimedia Tools and Applications, 76 (4), pp. 4801-4834. , february; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, pp. 2672-2680; Cozzolino, D., Poggi, G., Verdoliva, L., Recasting residual-based local descriptors as convolutional neural networks: An application to image forgery detection (2017) ACM Workshop on Information Hiding and Multimedia Security, pp. 1-6; Bayar, B., Stamm, M., A deep learning approach to universal image manipulation detection using a new convolutional layer (2016) ACM Workshop on Information Hiding and Multimedia Security, pp. 5-10; Huang, G., Liu, Z., Van Der-Maaten, L., Weinberger, K., Densely connected convolutional networks (2017) IEEE CVPR, pp. 1708-4700; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) IEEE CVPR, pp. 2818-2826; Chollet, F., Xception: Deep learning with depthwise separable convolutions (2017) IEEE CVPR, pp. 1800-1807; Fridrich, J., Kodovský, J., Rich models for steganalysis of digital images (2012) IEEE Transactions on Information Forensics and Security, 7 (3), pp. 868-882. , Jun; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) IEEE CVPR, pp. 770-778; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) IEEE CVPR",,,"","Institute of Electrical and Electronics Engineers Inc.","1st IEEE Conference on Multimedia Information Processing and Retrieval, MIPR 2018","10 April 2018 through 12 April 2018",,137505,,9781538618578,,,"English","Proc. - IEEE Conf. Multimed. Inf. Process. Retr., MIPR",Conference Paper,"Final","",Scopus,2-s2.0-85050127334
"Yin C., Zhu Y., Liu S., Fei J., Zhang H.","37666468500;7406074177;36010722100;55576523700;57203002483;","An enhancing framework for botnet detection using generative adversarial networks",2018,"2018 International Conference on Artificial Intelligence and Big Data, ICAIBD 2018",,,,"228","234",,36,"10.1109/ICAIBD.2018.8396200","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050189066&doi=10.1109%2fICAIBD.2018.8396200&partnerID=40&md5=e8988e30145456c52f53d52df6ffb981","State Key Laboratory of Mathematical Engineering and Advanced Computing, Zhengzhou, China","Yin, C., State Key Laboratory of Mathematical Engineering and Advanced Computing, Zhengzhou, China; Zhu, Y., State Key Laboratory of Mathematical Engineering and Advanced Computing, Zhengzhou, China; Liu, S., State Key Laboratory of Mathematical Engineering and Advanced Computing, Zhengzhou, China; Fei, J., State Key Laboratory of Mathematical Engineering and Advanced Computing, Zhengzhou, China; Zhang, H., State Key Laboratory of Mathematical Engineering and Advanced Computing, Zhengzhou, China","The botnet, as one of the most formidable threats to cyber security, is often used to launch large-scale attack sabotage. How to accurately identify the botnet, especially to improve the performance of the detection model, is a key technical issue. In this paper, we propose a framework based on generative adversarial networks to augment botnet detection models (Bot-GAN). Moreover, we explore the performance of the proposed framework based on flows. The experimental results show that Bot-GAN is suitable for augmenting the original detection model. Compared with the original detection model, the proposed approach improves the detection performance, and decreases the false positive rate, which provides an effective method for improving the detection performance. In addition, it also retains the primary characteristics of the original detection model, which does not care about the network payload information, and has the ability to detect novel botnets and others using encryption or proprietary protocols. © 2018 IEEE.","Anomaly detection; Botnet; Botnet detection; Deep learning; Generative adversarial networks","Artificial intelligence; Big data; Cryptography; Deep learning; Adversarial networks; Anomaly detection; Botnet detections; Detection performance; False positive rates; Large-scale attacks; Payload information; Proprietary protocols; Botnet",,,,,"Feily, M., Shahrestani, A., Ramadass, S., A survey of botnet and botnet detection (2009) Emerging Security Information, Systems and Technologies, 2009. SECURWARE'09. Third International Conference on, , IEEE; Zhu, Z., Botnet research survey (2008) Computer Software and Applications, 2008. COMPSAC'08. 32nd Annual IEEE International, , IEEE; Bailey, M., A survey of botnet technology and defenses (2009) Conference for Homeland Security, 2009. CATCH'09. Cybersecurity Applications &Technology, , IEEE; John, J.P., Studying spamming botnets using botlab (2009) NSDI, 9; Hoque, N., Bhattacharyya, D.K., Kalita, J.K., Botnet in ddos attacks: Trends and challenges (2015) IEEE Communications Surveys &Tutorials, 17 (4), pp. 2242-2270; Feily, M., Shahrestani, A., Ramadass, S., A survey of botnet and botnet detection (2009) Emerging Security Information, Systems and Technologies, 2009. SECURWARE'09. Third International Conference on, , IEEE; Qiu, Z., Miller, D.J., Kesidis, G., Flow based botnet detection through semi-supervised active learning (2017) Acoustics, Speech and Signal Processing (ICASSP), 2017 IEEE International Conference on, , IEEE; Lashkari, A.H., A survey leading to a new evaluation framework for network-based botnet detection (2017) Proceedings of the 2017 the 7th International Conference on Communication and Network Security, , ACM; Goodfellow, I., Generative adversarial nets (2014) Advances in Neural Information Processing Systems; Garg, S., Sarje, A.K., Peddoju, S.K., Improved detection of P2P botnets through network behavior analysis (2014) International Conference on Security in Computer Networks and Distributed Systems, , Springer, Berlin, Heidelberg; Wang, J., Chen, Y., Botnet detection method based on permutation entropy and clustering variance (2017) DEStech Transactions on Engineering and Technology Research Ismii; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), p. 436; Schmidhuber, J., Deep learning in neural networks: An overview (2015) Neural Networks, 61, pp. 85-117; Goodfellow, I., (2016) Deep Learning., 1. , Cambridge: MIT press; Gao, N., An intrusion detection model based on deep belief networks (2014) Advanced Cloud and Big Data (CBD), 2014 Second International Conference on, , IEEE; Niyaz, Q., Sun, W., Javaid, A.Y., (2016) A Deep Learning Based DDoS Detection System in Software-defined Networking (SDN); Kudugunta, S., Ferrara, E., (2018) Deep Neural Networks for Bot Detection; Tran, D., A lstm based framework for handling multiclass imbalance in DGA botnet detection (2018) Neurocomputing, 275, pp. 2401-2413; Torres, P., An analysis of recurrent neural networks for botnet detection behavior (2016) Biennial Congress of Argentina (ARGENCON), 2016 IEEE, , IEEE; Anderson, H.S., Woodbridge, J., Filar, B., Deepdga: Adversarially-tuned domain generation and detection (2016) Proceedings of the 2016 ACM Workshop on Artificial Intelligence and Security, , ACM; Ledig, C., (2016) Photo-realistic Single Image Super-resolution Using A Generative Adversarial Network, , arXiv preprint; Scott, R., (2016) Generative Adversarial Text to Image Synthesis; Isola, P., (2017) Image-to-image Translation with Conditional Adversarial Networks, , arXiv preprint; Pascual, S., Bonafonte, A., Serra, J., (2017) SEGAN: Speech Enhancement Generative Adversarial Network; Beigi, E.B., Towards effective feature selection in machine learning-based botnet detection approaches (2014) Communications and Network Security (CNS), 2014 IEEE Conference on, , IEEE; Zhao, D., Botnet detection based on traffic behavior analysis and flow intervals (2013) Computers &Security, 39, pp. 2-16; Shiravi, A., Toward developing a systematic approach to generate benchmark datasets for intrusion detection (2012) Computers &Security, 31 (3), pp. 357-374; García, S., (2013) Malware Capture Facility Project, , cvut; Saad, S., Detecting P2P botnets through network behavior analysis and machine learning (2011) Privacy, Security and Trust (PST), 2011 Ninth Annual International Conference on, , IEEE; Yu, X., Data-adaptive clustering analysis for online botnet detection (2010) Computational Science and Optimization (CSO), 2010 Third International Joint Conference On., 1. , IEEE; Liao, W.-H., Chang, C.-C., Peer to peer botnet detection using data mining scheme (2010) Internet Technology and Applications, 2010 International Conference on, , IEEE; Livadas, C., Usilng machine learning technliques to identify botnet traffic (2006) Local Computer Networks, Proceedings 2006 31st IEEE Conference on, , IEEE; Strayer, W.T., Botnet detection based on network behavior (2008) Botnet Detection, pp. 1-24. , Springer, Boston, MA; Zhao, D., Peer to peer botnet detection based on flow intervals (2012) IFIP International Information Security Conference, , Springer, Berlin, Heidelberg","Yin, C.; State Key Laboratory of Mathematical Engineering and Advanced ComputingChina; email: dragonyincl@163.com",,"Chengdu University of Information Technology (CUIT);College of Computer Science at Sichuan University;Sichuan Province Computer Federation","Institute of Electrical and Electronics Engineers Inc.","2018 International Conference on Artificial Intelligence and Big Data, ICAIBD 2018","26 May 2018 through 28 May 2018",,137534,,9781538669877,,,"English","Int. Conf. Artif. Intell. Big Data, ICAIBD",Conference Paper,"Final","",Scopus,2-s2.0-85050189066
"Kailkhura B., Vempaty A., Varshney P.K.","55694465200;40662045900;35571661500;","Collaborative Spectrum Sensing in the Presence of Byzantine Attacks",2018,"Cooperative and Graph Signal Processing: Principles and Applications",,,,"505","522",,3,"10.1016/B978-0-12-813677-5.00020-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082075204&doi=10.1016%2fB978-0-12-813677-5.00020-1&partnerID=40&md5=4564f2834eccda0a737a369bf9227e16","Center for Applied Scientific Computing, Lawrence Livermore National Laboratory, Livermore, CA, United States; IBM Thomas J. Watson Research Center, Yorktown Heights, NY, United States; Department of EECS, Syracuse University, Syracuse, NY, United States","Kailkhura, B., Center for Applied Scientific Computing, Lawrence Livermore National Laboratory, Livermore, CA, United States; Vempaty, A., IBM Thomas J. Watson Research Center, Yorktown Heights, NY, United States; Varshney, P.K., Department of EECS, Syracuse University, Syracuse, NY, United States","Cognitive radio (CR) has emerged as an enabling technology for supporting dynamic spectrum access (DSA). DSA enables the solution of the spectrum scarcity problem by exploiting transmission opportunities in the underutilized spectrum bands of primary users. In collaborative (or distributed) spectrum sensing, multiple CRs collaborate with each other by sharing their inference to make a global inference regarding the availability of the spectrum, i.e., licensed primary channels. This approach has been shown to have various advantages in terms of spectrum utilization and robustness. A key component of collaborative spectrum sensing is the distributed data fusion scheme. However, the distributed nature of these schemes makes them quite vulnerable to adversarial attacks. A potential attack on this scheme is the Byzantine (or data falsification) attack where some of the CRs are reprogrammed by an adversary, and these malicious CRs (also referred to as Byzantines) introduce false sensing information in the fusion process to degrade the spectrum-sensing process. In this chapter, we analyze the performance limits of collaborative spectrum sensing under Byzantine attacks for different practical network architectures. Specifically, we begin the study from an attacker's perspective and discuss the optimal attacking strategies for given attacking resources. Next, we discuss possible countermeasures from a network designer's perspective and present robust spectrum-sensing algorithms. Finally, we discuss some of the main challenges and research opportunities that exist in emerging CR-based sensing networks. This chapter provides comprehensive insights into the use of signal processing methods for robust spectrum sensing in cognitive radio networks. © 2018 Elsevier Inc. All rights reserved.","Byzantine attacks; Cognitive radio networks; Data falsification; Spectrum sensing",,,,,,"Kolodzy, P., Avoidance, I., Spectrum policy task force (2002) Federal Commun Comm, Washington, DC, Report ET Docket, 2 (135); Biglieri, E., (2013) Principles of cognitive radio, , Cambridge University Press; Lamport, L., Shostak, R., Pease, M., The Byzantine generals problem (1982) ACM Trans Program Lang Syst, 4 (3), pp. 382-401; Rappaport, T., (1996) Wireless communications: principles and practice, , Prentice Hall; Rawat, A.S., Anand, P., Chen, H., Varshney, P.K., Collaborative spectrum sensing in the presence of Byzantine attacks in cognitive radio networks (2011) IEEE Trans Signal Process, 59 (2), pp. 774-786; Vempaty, A., Agrawal, K., Varshney, P., Chen, H., Adaptive learning of Byzantines' behavior in cooperative spectrum sensing (2011) 2011 IEEE wireless communications and networking conference, pp. 1310-1315; Chair, Z., Varshney, P., Optimal data fusion in multiple sensor detection systems (1986) IEEE Trans Aerosp Electron Syst, (1), pp. 98-2101; Digham, F.F., Alouini, M.S., Simon, M.K., On the energy detection of unknown signals over fading channels (2007) IEEE Trans Commun, 55 (1), pp. 21-24; Olfati-Saber, R., Fax, J.A., Murray, R.M., Consensus and cooperation in networked multi-agent systems (2007) Proc IEEE, 95 (1), pp. 215-233; Zhang, W., Wang, Z., Guo, Y., Liu, H., Chen, Y., Mitola, I.I.I.J., Distributed cooperative spectrum sensing based on weighted average consensus (2011) 2011 IEEE global telecommunications conference (GLOBECOM 2011), pp. 1-6. , IEEE; Kay, S.M., (1993) Fundamentals of statistical signal processing, , Prentice Hall PTR; Kailkhura, B., Brahma, S., Varshney, P.K., Data falsification attacks on consensus-based detection systems (2017) IEEE Trans Signal Inf Process Netw, 3 (1), pp. 145-158","Kailkhura, B.; Center for Applied Scientific Computing, United States",,,"Elsevier",,,,,,9780128136782; 9780128136775,,,"English","Coop. and Graph Signal Process.: Princ. and Appl.",Book Chapter,"Final","",Scopus,2-s2.0-85082075204
"Goyal V., Kumar A.","23396292000;57202315425;","Non-malleable secret sharing",2018,"Proceedings of the Annual ACM Symposium on Theory of Computing",,,,"632","645",,26,"10.1145/3188745.3188872","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049923129&doi=10.1145%2f3188745.3188872&partnerID=40&md5=f9f9ce4c861819aa4286af1e2a0033c4","CMU, Pittsburgh, United States; UCLA, Los Angeles, United States","Goyal, V., CMU, Pittsburgh, United States; Kumar, A., UCLA, Los Angeles, United States","A number of works have focused on the setting where an adversary tampers with the shares of a secret sharing scheme. This includes literature on verifiable secret sharing, algebraic manipulation detection(AMD) codes, and, error correcting or detecting codes in general. In this work, we initiate a systematic study of what we call non-malleable secret sharing. Very roughly, the guarantee we seek is the following: the adversary May potentially tamper with all of the shares, and still, either the reconstruction procedure outputs the original secret, or, the original secret is “destroyed"" and the reconstruction outputs a string which is completely “unrelated"" to the original secret. Recent exciting work on non-malleable codes in the split-state model led to constructions which can be seen as 2-out-of-2 non-malleable secret sharing schemes. These constructions have already found a number of applications in cryptography. We investigate the natural question of constructing t-out-of-n non-malleable secret sharing schemes. Such a secret sharing scheme ensures that only a set consisting of t or more shares can reconstruct the secret, and, additionally guarantees non-malleability under an attack where potentially every share Maybe tampered with. Techniques used for obtaining split-state non-malleable codes (or 2-out-of-2 non-malleable secret sharing) are (in some form) based on two-source extractors and seem not to generalize to our setting. Our first result is the construction of a t-out-of-n non-malleable secret sharing scheme against an adversary who arbitrarily tampers each of the shares independently. Our construction is unconditional and features statistical non-malleability. As our main technical result, we present t-out-of-n non-malleable secret sharing scheme in a stronger adversarial model where an adversary May jointly tamper multiple shares. Our construction is unconditional and the adversary is allowed to jointly-tamper subsets of up to (t-1) shares.We believe that the techniques introduced in our construction May be of independent interest. Inspired by the well studied problem of perfectly secure message transmission introduced in the seminal work of Dolev et. al (J. of ACM 93), we also initiate the study of non-malleable message transmission. Non-malleable message transmission can be seen as a natural generalization in which the goal is to ensure that the receiver either receives the original message, or, the original message is essentially destroyed and the receiver receives an unrelated message, when the network is under the influence of an adversary who can byzantinely corrupt all the nodes in the network. As natural applications of our non-malleable secret sharing schemes, we propose constructions for non-malleable message transmission. © 2018 Association for Computing Machinery.","Non-malleable codes; Non-malleable message transmission; Non-malleable secret sharing; Secret sharing; Threshold cryptography","Codes (symbols); Computation theory; Algebraic manipulations; Message transmissions; Non-malleable codes; Perfectly secure message transmissions; Reconstruction procedure; Secret sharing; Threshold cryptography; Verifiable secret sharing; Cryptography",,,,,"Aggarwal, D., Dodis, Y., Lovett, S., Non-malleable codes from additive combinatorics (2014) Proceedings of The 46th Annual ACM Symposium on Theory of Computing, pp. 774-783. , ACM; Aggarwal, D., Dziembowski, S., Kazana, T., Obremski, M., Leakage-resilient non-malleable codes (2015) Twelfth IACR Theory of Cryptography Conference (TCC 2015); Beimel, A., Secure Schemes for Secret Sharing and Key Distribution, , PhD Thesis; Beimel, A., Secret-sharing schemes: A survey (2011) International Conference on Coding and Cryptology, pp. 11-46. , Springer Berlin Heidelberg; Ben-Or, M., Goldwasser, S., Wigderson, A., Completeness theorems for non-cryptographic fault-tolerant distributed computation (1988) Proceedings of The Twentieth Annual ACM Symposium on Theory of Computing, pp. 1-10. , ACM; Blakley, G.R., Safeguarding cryptographic keys (1979) AFIPS National Computer Conference (NCC’79), pp. 313-317. , https://doi.org/doi.ieeecomputersociety.org/10.1109/AFIPS.1979.98, IEEE Computer Society, Los Alamitos, CA, USA; Chattopadhyay, E., Goyal, V., Li, X., Non-malleable extractors and codes, with their many tampered extensions (2016) Proceedings of The 48th Annual ACM SIGACT Symposium on Theory of Computing, STOC 2016, pp. 285-298. , https://doi.org/10.1145/2897518.2897547, Cambridge, MA, USA, June 18-21, 2016; Cohen, G., Non-malleable extractors–New tools and improved constructions (2016) 31st Conference on Computational Complexity; Coretti, S., Dodis, Y., Tackmann, B., Venturi, D., Non-malleable encryption: Simpler, shorter, stronger (2016) Theory of Cryptography Conference, pp. 306-335. , Springer; Cramer, R., Dodis, Y., Fehr, S., Padró, C., Wichs, D., Detection of algebraic manipulation with applications to robust secret sharing and fuzzy extractors (2008) Eurocrypt, pp. 471-488. , Springer; Dodis, Y., Ostrovsky, R., Reyzin, L., Smith, A., (2008) Fuzzy Extractors: How to Generate Strong Keys from Biometrics and Other Noisy Data, 38, pp. 97-139. , 2008; Dolev, D., Dwork, C., Naor, M., Non-malleable cryptography (Extended abstract) (1991) Proceedings of The 23rd Annual ACM Symposium on Theory of Computing, pp. 542-552. , May 5-8, 1991, New Orleans, Louisiana, USA; Dolev, D., Dwork, C., Waarts, O., Yung, M., Perfectly secure message transmission (1993) J. ACM, 40 (1), pp. 17-47. , https://doi.org/10.1145/138027.138036, Jan. 1993; Dziembowski, S., Kazana, T., Obremski, M., Non-malleable codes from two-source extractors (2013) CRYPTO 2013, pp. 239-257. , Springer; Dziembowski, S., Pietrzak, K., Intrusion-resilient secret sharing (2007) Foundations of Computer Science, 2007. FOCS’07. 48th Annual IEEE Symposium on. IEEE, pp. 227-237; Dziembowski, S., Pietrzak, K., Leakage-resilient cryptography (2008) Foundations of Computer Science, 2008. FOCS’08. IEEE 49th Annual IEEE Symposium on. IEEE, pp. 293-302; Dziembowski, S., Pietrzak, K., Wichs, D., Non-malleable codes (2010) Innovations in Computer Science - ICS 2010, pp. 434-452. , Tsinghua University, Beijing, China, January 5-7, 2010. Proceedings; Goyal, V., Jain, A., Khurana, D., Non-malleable multi-prover interactive proofs and witness signatures (2015) Cryptology ePrint Archive, Report 2015/1095, , http://eprint.iacr.org/2015/1095, 2015; Goyal, V., Kumar, A., Park, S., Richelson, S., Srinivasan, A., Non-malleable commitments from non-malleable extractors (2018) Manuscript, , 2018; Goyal, V., Pandey, O., Richelson, S., Textbook non-malleable commitments (2016) Proceedings of The 48th Annual ACM SIGACT Symposium on Theory of Computing, STOC 2016, pp. 1128-1141. , https://doi.org/10.1145/2897518.2897657, Cambridge, MA, USA, June 18-21, 2016; Kishore, R., Kumar, A., Vanarasa, C., Srinathan, K., On the price of proactivizing round-optimal perfectly secret message transmission (2018) IEEE Transactions on Information Theory, 64 (2), pp. 1404-1422. , https://doi.org/10.1109/TIT.2017.2776099, Feb 2018; Kurosawa, K., Suzuki, K., Truly efficient-round perfectly secure message transmission scheme (2009) IEEE Transactions on Information Theory, 55 (11), pp. 5223-5232. , 2009; Lee, C.-J., Lu, C.-J., Tsai, S.-C., Tzeng, W.-G., Extracting randomness from multiple independent sources (2005) IEEE Transactions on Information Theory, 51 (6), pp. 2224-2227. , 2005; Li, X., Improved non-malleable extractors, non-malleable codes and independent source extractors (2017) Proceedings of The 49th Annual ACM SIGACT Symposium on Theory of Computing, pp. 1144-1156. , ACM; Liu, F.-H., Lysyanskaya, A., Tamper and leakage resilience in the split-state model (2012) CRYPTO 2012 -, 7417, pp. 517-532. , Springer-Verlag New York, Inc., New York, NY, USA; McEliece, R.J., Sarwate, D.V., On sharing secrets and reed-solomon codes (1981) Commun. ACM, 24 (9), pp. 583-584. , 1981; Rabin, T., Ben-Or, M., Verifiable secret sharing and multiparty protocols with honest majority (1989) STOC, pp. 73-85. , https://doi.org/10.1145/73007.73014, ACM, New York, NY, USA; Raz, R., Extractors with weak random seeds (2005) Proceedings of The Thirty-Seventh Annual ACM Symposium on Theory of Computing, pp. 11-20. , ACM; Shamir, A., How to share a secret (1979) Commun. ACM, 22 (11), pp. 612-613. , 1979; Srinathan, K., Narayanan, A., Pandu Rangan, C., Optimal perfectly secure message transmission (2004) Proc. of Advances in Cryptology: CRYPTO 2004, LNCS, 3152, pp. 545-561. , Springer-Verlag New York, Inc; Wang, Y., Desmedt, Y., Perfectly secure message transmission revisited (2008) IEEE Transactions on Information Theory, 54 (6), pp. 2582-2595. , 2008",,"Henzinger M.Kempe D.Diakonikolas I.","ACM Special Interest Group on Algorithms and Computation Theory (SIGACT)","Association for Computing Machinery","50th Annual ACM Symposium on Theory of Computing, STOC 2018","25 June 2018 through 29 June 2018",,137531,07378017,9781450355599,,,"English","Proc. Annu. ACM Symp. Theory Comput.",Conference Paper,"Final","All Open Access, Bronze",Scopus,2-s2.0-85049923129
"Samanta P., Kelly E., Bashir A., Debroy S.","57200313105;57202978838;57200315101;26642460800;","Collaborative Adversarial Modeling for Spectrum Aware IoT Communications",2018,"2018 International Conference on Computing, Networking and Communications, ICNC 2018",,,,"447","451",,1,"10.1109/ICCNC.2018.8390289","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050082989&doi=10.1109%2fICCNC.2018.8390289&partnerID=40&md5=71133cf625296db3dd4ab64559c629a4","City University of New York, United States","Samanta, P., City University of New York, United States; Kelly, E., City University of New York, United States; Bashir, A., City University of New York, United States; Debroy, S., City University of New York, United States","In order to cater the growing spectrum demands of large scale future 5G Internet of Things (IoT) applications, Dynamic Spectrum Access (DSA) based networks are being proposed as a high-throughput and cost-effective solution. However the lack of understanding of DSA paradigm's inherent security vulnerabilities on IoT networks might become a roadblock towards realizing such spectrum aware 5G vision. In this paper, we make an attempt to understand how such inherent DSA vulnerabilities in particular Spectrum Sensing Data Falsification (SSDF) attacks can be exploited by collaborative group of selfish adversaries and how that can impact the performance of spectrum aware IoT applications. We design a utility based selfish adversarial model mimicking collaborative SSDF attack in a cooperative spectrum sensing scenario where IoT networks use dedicated environmental sensing capability (ESC) for spectrum availability estimation. We model the interactions between the IoT system and collaborative selfish adversaries using a leaderfollower game and investigate the existence of equilibrium. Using simulation results, we show the nature of adversarial and system utility components against system variables. We also explore Pareto-optimal adversarial strategy design that maximizes the attacker utility for varied system strategy spaces. © 2018 IEEE.","collaborative attacks; Dynamic spectrum access; Internet of things; leader-follower game; selfish adversary","5G mobile communication systems; Cost effectiveness; Pareto principle; Spectroscopy; Co-operative spectrum sensing; collaborative attacks; Dynamic spectrum access; Dynamic spectrum accesses (DSA); Internet of Things (IOT); Leader-follower games; Security vulnerabilities; selfish adversary; Internet of things",,,,,"Akyildiz, I.F., Lo, B.F., Balakrishnan, R., Cooperative spectrum sensing in cognitive radio networks: A survey (2011) Physical Communication, 4 (1), pp. 40-62; Commission, F.C., Report and order and second further notice of proposed rulemaking (2015) Amendment of the Commissions Rules with Regard to Commercial Operations in the, pp. 3550-3650; Yang, G., Wang, J., Luo, J., Wen, O.Y., Li, H., Li, Q., Li, S., Cooperative spectrum sensing in heterogeneous cognitive radio networks based on normalized energy detection (2016) IEEE Transactions on Vehicular Technology, 65 (3), pp. 1452-1463; Andrea, I., Chrysostomou, C., Hadjichristofi, G., Internet of things: Security vulnerabilities and challenges (2015) Computers and Communication (ISCC), 2015 IEEE Symposium On. IEEE, pp. 180-187; Medaglia, C.M., Serbanati, A., An overview of privacy and security issues in the internet of things (2010) The Internet of Things. Springer, pp. 389-395; Li, L., Study on security architecture in the internet of things (2012) Measurement, Information and Control (MIC), 2012 International Conference on, 1, pp. 374-377. , IEEE; Suo, H., Wan, J., Zou, C., Liu, J., Security in the internet of things: A review (2012) Computer Science and Electronics Engineering (ICCSEE), 2012 International Conference on, 3, pp. 648-651. , IEEE; Newman, T.R., Clancy, T.C., McHenry, M., Reed, J.H., Case study: Security analysis of a dynamic spectrum access radio system (2010) Global Telecommunications Conference (GLOBECOM 2010), 2010 IEEE. IEEE, pp. 1-6; Bhattacharjee, S., Debroy, S., Chatterjee, M., Quantifying trust for robust fusion while spectrum sharing in distributed dsa networks (2017) IEEE Transactions on Cognitive Communications and Networking, 3 (2), pp. 138-154; Bhattacharjee, S., Debroy, S., Chatterjee, M., Kwiat, K., Utilizing misleading information for cooperative spectrum sensing in cognitive radio networks (2013) Communications (ICC), 2013 IEEE International Conference On. IEEE, pp. 2612-2616; Jakimoski, G., Subbalakshmi, K., Denial-of-service attacks on dynamic spectrum access networks (2008) Communications Workshops, 2008. ICC Workshops' 08. IEEE International Conference On. IEEE, pp. 524-528; Jin, F., Varadharajan, V., Tupakula, U., Improved detection of primary user emulation attacks in cognitive radio networks (2015) Telecommunication Networks and Applications Conference (ITNAC), 2015 International. IEEE, pp. 274-279; Jia, M., Wang, X., Guo, Q., Gu, X., Yu, Z., A multi-bit decision cooperative spectrum sensing algorithm in mobile scenarios based on trust valuations in cognitive radio context (2014) Wireless Personal Multimedia Communications (WPMC), 2014 International Symposium On. IEEE, pp. 335-339",,,"","Institute of Electrical and Electronics Engineers Inc.","2018 International Conference on Computing, Networking and Communications, ICNC 2018","5 March 2018 through 8 March 2018",,137313,,9781538636527,,,"English","Int. Conf. Comput., Netw. Commun., ICNC",Conference Paper,"Final","",Scopus,2-s2.0-85050082989
"Shrestha P., Saxena N.","57031498700;57206303753;","Listening watch: Wearable two-factor authentication using speech signals resilient to near-far attacks",2018,"WiSec 2018 - Proceedings of the 11th ACM Conference on Security and Privacy in Wireless and Mobile Networks",,,,"99","110",,8,"10.1145/3212480.3212501","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050926699&doi=10.1145%2f3212480.3212501&partnerID=40&md5=5d9890a2ed68bfb3a4f9aa1bbc19dec1","University of Alabama, Birmingham, United States","Shrestha, P., University of Alabama, Birmingham, United States; Saxena, N., University of Alabama, Birmingham, United States","Reducing the level of user effort involved in traditional two-factor authentication (TFA) constitutes an important research topic. A recent effort in this direction leverages ambient sounds to detect the proximity between the second factor device (phone) and the login terminal (browser), and eliminates the need for the user to transfer PIN codes. This approach is highly usable, but is completely vulnerable against far-near attackers, i.e., ones who are remotely located and can guess the victim's audio environment or make the phone create predictable sounds (e.g., ringers), and those who are in physical proximity of the user. In this paper, we propose Listening-Watch, a new TFA mechanism based on a wearable device (watch/bracelet) and active browser-generated random speech sounds. As the user attempts to login, the browser populates a short random code encoded into speech, and the login succeeds if the watch's audio recording contains this code (decoded using speech recognition), and is similar enough to the browser's audio recording. The remote attacker, who has guessed the user's environment or created predictable phone/watch sounds, will be defeated since authentication success relies upon the presence of the random code in watch's recordings. The proximity attacker will also be defeated unless it is extremely close to the watch, since the wearable microphones are usually designed to be only capable of picking up nearby sounds (e.g., voice commands). Furthermore, due to the use of a wearable second factor device, Listening-Watch naturally enables two-factor security even when logging in from a mobile phone. Our contributions are three-fold. First, we introduce the idea of strong and low-effort TFA based on wearable devices, active speech sounds and speech recognition, giving rise to the Listening-Watch system that is secure against both remote and proximity attackers. Second, we design and implement Listening-Watch for an Android smartwatch (and companion smartphone) and the Chrome browser, without the need for any browser plugins. Third, we evaluate Listening-Watch for authentication errors in both benign and adversarial settings. Our results show that Listening-Watch can result in minimal errors in both settings based on appropriate thresholdization and speaker volume levels. © 2018 Association for Computing Machinery.",,"Audio acoustics; Audio equipment; Audio recordings; Authentication; Codes (symbols); Mobile security; Mobile telecommunication systems; Network security; Speech; Telephone sets; Watches; Wearable technology; Wireless networks; Ambient sounds; Design and implements; Mechanism-based; Minimal errors; Physical proximity; Research topics; Two factor authentication; Wearable devices; Speech recognition",,,,,"Yubico, A.B., (2017) Yubico | Trust The Net with YubiKey Strong Two-Factor Authentication, , https://www.yubico.com/, Retrieved May 13, 2017 from; (2017) Two-Factor Authentication - Authy, , https://www.authy.com/, Retrieved May 13, 2017 from; Bonneau, J., Herley, C., Van Oorschot, P.C., Stajano, F., The quest to replace passwords: A framework for comparative evaluation of web authentication schemes (2012) Security and Privacy (SP), 2012 IEEE Symposium on, pp. 553-567; (2017) How to Play Music Through The Internal Pc Speaker, , https://cd3dtech.com/tutorials/general/how-to-play-music-through-the-internal-pc-speaker, Retrieved December 31, 2017 from; (2017) Celestix HOTPin Two Factor Authentication, , http://www.celestixworks.com/HOTPin.asp, Retrieved May 13, 2017 from; (2017) Bluetooth - Google Chrome, , https://developer.chrome.com/apps/app_bluetooth, Retrieved May 13, 2017 from; Czeskis, A., Dietz, M., Kohno, T., Wallach, D., Balfanz, D., Strengthening user authentication through opportunistic cryptographic identity assertions (2012) Proceedings of The 2012 ACM Conference on Computer and Communications Security, pp. 404-414; Du, J., Huo, Q., A feature compensation approach using high-order vector Taylor series approximation of an explicit distortion model for noisy speech recognition (2011) IEEE Transactions on Audio, Speech, and Language Processing, 19 (8), pp. 2285-2293. , 2011; (2010) Integration of Short-Time Fourier Domain Speech Enhancement and Observation Uncertainty Techniques for Robust Automatic Speech Recognition, , Ram n Fern ndez Astudillo. 2010; (2017) Web Bluetooth API (Firefox OS, , https://developer.mozilla.org/en-US/docs/Archive/B2G_OS/Bluetooth_API, Retrieved May 13, 2017 from; Gibson, J., (2017) Introduction to MIDI and Computer Music: The MIDI Standard, , http://www.indiana.edu/~emusic/361/midi.htm, Retrieved December 31, 2017 from; Goodrich, M.T., Sirivianos, M., Solis, J., Tsudik, G., Uzun, E., Loud and clear: Human-verifiable authentication based on audio (2006) Distributed Computing Systems, 2006. ICDCS 2006. 26th IEEE International Conference on., p. 10; Halevi, T., Ma, D., Saxena, N., Xiang, T., Secure proximity detection for NFC devices based on ambient sensor data (2012) Computer Security-ESORICS 2012, pp. 379-396. , Springer; (2017) Basic Trackers Take A Back Seat as Smartwatches Accelerate in The Second Quarter, , https://goo.gl/2wDj4x, According to IDC. Retrieved December 28, 2017 from; (2017) Understanding Microphone Sensitivity, , https://goo.gl/WJhdCi, Retrieved October 27, 2017 from; (2017) Easy Authentication: Duo Security, , https://duo.com/solutions/features/user-experience/easy-authentication, Retrieved May 13, 2017 from; (2017) Gartner Says Worldwide Wearable Device Sales to Grow 17 Percent in 2017, , https://goo.gl/z7DTz1, Retrieved December 28, 2017 from; (2017) Google 2-Step Verification, , https://www.google.com/landing/2step/, Retrieved May 13, 2017 from; (2017) Speech API - Speech Recognition | Google Cloud Platform, , https://cloud.google.com/speech/, Retrieved May 13, 2017 from; Karapanos, N., Marforio, C., Soriente, C., Capkun, S., Sound-proof: Usable two-factor authentication based on ambient sound (2015) USENIX Security Symposium; Koldovsky, Z., Mullek, J., Nouza, J., Miroslav Bal, K., CHIME data separation based on target signal cancellation and noise masking (2011) Machine Listening in Multisource Environments; Kumpardk, G., (2014) Google Acquires SlickLogin, The Sound-Based Password Alternative | TechCrunch, , http://techcrunch.com/2014/02/16/google-acquires-slicklogin-the-sound-based-password-alternative/, Retrieved May 13, 2017 from; Mare, S., Markham, A.M., Cornelius, C., Peterson, R., Kotz, D., Zebra: Zero-effort bilateral recurring authentication (2014) Security and Privacy (SP), 2014 IEEE Symposium on, pp. 705-720; (2017) Butterworth Filter Design, , http://www.mathworks.com/help/signal/ref/butter.html, Retrieved May 13, 2017 from; (2017) Large Vs Small Diagpragms in Microphones, , https://goo.gl/TGjcke, Retrieved October 27, 2017 from; (2017) Nymi | Always On Authentication, , https://nymi.com/, Retrieved October 27, 2017 from; (2017) Omate TrueSmart, , https://www.omate.com/, Retrieved May 13, 2017 from; (2017) Make Listening Safe, , https://goo.gl/4hfd98, Retrieved October 28, 2017 from; (2017) SecurID | RSA Security Token Based Authentication, , https://www.yubico.com/, Retrieved May 13, 2017 from; (2017) Samsung Gear S Smartwatch | Samsung, , http://www.samsung.com/us/explore/gear-s-features-and-specs/, Retrieved May 13, 2017 from; Shirvanian, M., Jarecki, S., Saxena, N., Nathan, N., Two-factor authentication resilient to server compromise using mix-bandwidth devices (2014) Network and Distributed System Security Symposium; Shrestha, B., Shirvanian, M., Shrestha, P., Saxena, N., The sounds of the phones: Dangers of zero-effort second factor login based on ambient audio Conference on Computer and Communications Security, , n. d; Soriente, C., Tsudik, G., Uzun, E., HAPADEP: Human-assisted pure audio device pairing (2008) Information Security, pp. 385-400. , 2008; (2017) Personal Distance - Zones, , http://www.study-body-language.com/Personal-distance.html, Retrieved October 27, 2017 from; (2017) Solfa Cipher, , http://www.wmich.edu/mus-theo/solfa-cipher/, Retrieved December 31, 2017 from; Vinyals, O., Ravuri, S.V., Comparing multilayer perceptron to deep belief network tandem features for robust ASR (2011) Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE International Conference on, pp. 4596-4599; (2017) WebRTC Home | WebRTC, , https://webrtc.org/, Retrieved May 13, 2017 from; Weninger, F., Wollmer, M., Geiger, J., Schuller, B., Gemmeke, J.F., Hurmalainen, A., Virtanen, T., Rigoll, G., Non-negative matrix factorization for highly noise-robust asr: To enhance or to recognize? (2012) Acoustics, Speech and Signal Processing (ICASSP), 2012 IEEE International Conference on, pp. 4681-4684; Williams, B., (2017) Smartwatches Surge to Take The Wearable Crown, , https://goo.gl/tJPtfY, Retrieved December 28, 2017 from; Wilson, K.W., Raj, B., Smaragdis, P., Divakaran, A., Speech denoising using nonnegative matrix factorization with priors (2008) Acoustics, Speech and Signal Processing, 2008. ICASSP 2008. IEEE International Conference on., pp. 4029-4032; Zandbergen, P.A., Barbeau, S.J., Positional accuracy of assisted GPS data from high-sensitivity GPS-enabled mobile phones (2011) Journal of Navigation, 64, pp. 381-399. , 03 2011",,,"ACM SIGSAC","Association for Computing Machinery, Inc","11th ACM Conference on Security and Privacy in Wireless and Mobile Networks, WiSec 2018","18 June 2018 through 20 June 2018",,137827,,9781450357319,,,"English","WiSec - Proc. ACM Conf. Security Priv. Wirel. Mob. Networks",Conference Paper,"Final","All Open Access, Bronze",Scopus,2-s2.0-85050926699
"Kovalchuk L., Kaidalov D., Nastenko A., Shevtsov O., Rodinko M., Oliynykov R.","36646180900;54420289900;57200181514;57194046677;57194032767;36104503000;","Number of confirmation blocks for Bitcoin and GHOST consensus protocols on networks with delayed message delivery",2018,"CRYBLOCK 2018 - Proceedings of the 1st Workshop on Cryptocurrencies and Blockchains for Distributed Systems, Part of MobiSys 2018",,,,"42","47",,3,"10.1145/3211933.3211941","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051681763&doi=10.1145%2f3211933.3211941&partnerID=40&md5=8fb29e9b40f65c5ccf13aecf5abb8570","Department of Mathematical Methods of Information Security, National Technical University of Ukraine Igor Sikorsky Kyiv Polytechnic Institute, Ukraine; Input Output HK, Kyiv, Ukraine; Input Output HK, Kharkiv, Ukraine; V.N. Karazin Kharkiv National University, Kharkiv, Ukraine","Kovalchuk, L., Department of Mathematical Methods of Information Security, National Technical University of Ukraine Igor Sikorsky Kyiv Polytechnic Institute, Ukraine, Input Output HK, Kyiv, Ukraine; Kaidalov, D., Input Output HK, Kharkiv, Ukraine; Nastenko, A., Input Output HK, Kharkiv, Ukraine; Shevtsov, O., Input Output HK, Kharkiv, Ukraine; Rodinko, M., Input Output HK, Kharkiv, Ukraine; Oliynykov, R., Input Output HK, Kharkiv, Ukraine, V.N. Karazin Kharkiv National University, Kharkiv, Ukraine","A specific number of transaction confirmation blocks determines average time of receiving and accepting payments at cryptocurrencies, and the shortest confirmation time for the same level of blockchain security provides the best user properties. Existing papers on transaction confirmation blocks for Bitcoin use implicit assumption of prompt spreading of Bitcoin blocks over the network (that is not always the case for the real world conditions). The newer publications with rigorous analysis and proofs of Bitcoin blockchain properties that take into account network delays provide asymptotic estimates, with no specific numbers for transaction confirmation blocks. We propose three methods for determination of required number of confirmation blocks for Bitcoin and GHOST on networks with delayed message delivery with different models that take into account the possibility of faster adversarial node syncronization. For the GHOST we propose the first (to our knowledge) strict theoretical method that allows to get required number of confirmation blocks for a given attacker's hashrate and attack success probability. © 2018 Copyright held by the owner/author(s).","Bitcoin; Blockchain; GHOST; Proof-of-stake; Proof-of-work","Blockchain; Network security; Asymptotic estimates; Bitcoin; Consensus protocols; GHOST; Proof of work; Proof-of-stake; Success probabilities; Theoretical methods; Electronic money",,,,,"Double-spending, , https://en.bitcoin.it/wiki/Double-spending; Garay, J., Kiayias, A., Leonardos, N., (2015) The Bitcoin Backbone Protocol: Analysis and Applications 2015, pp. 281-310; Garay, J.A., Kiayias, A., Leonardos, N., The bitcoin backbone protocol with chains of variable difficulty (2016) IACR Cryptology EPrint Archive 2016, p. 1048. , http://dblp.uni-trier.de/db/journals/iacr/iacr2016.html#GarayKL16, 2016; Grunspan, C., Pérez-Marco, R., Double spend races (2017) CoRR abs/1702.02867, , http://arxiv.org/abs/1702.02867, 2017; Kiayias, A., Panagiotakos, G., Speed-security tradeoffs in blockchain protocols (2015) Cryptology EPrint Archive, Report 2015/1019, , https://doi.org/2015/1019, 2015; Nakomoto, S., (2008) A Peer-to-peer Electronic Cash System, , https://doi.org/bitcoin.pdf, 2008; Pass, R., Seeman, L., Shelat, A., Analysis of the blockchain protocol in asynchronous networks (2017) Annual International Conference on the Theory and Applications of Cryptographic Techniques; Pinzon, C., Rocha, C., Double-spend attack models with time advantange for bitcoin (2016) Electronic Notes in Theoretical Computer Science, 329, pp. 79-103. , 2016; Rosenfeld, M., (2014) Analysis of Hashrate-based Double-spending, , https://doi.org/abs/1402.2009, arXiv preprint 2014; Sompolinsky, Y., Zohar, A., Accelerating bitcoin's transaction processing (2013) Fast Money Grows on Trees, Not Chains. IACR Cryptology EPrint Archive 2013, p. 881. , http://eprint.iacr.org/2013/881, 2013; Sompolinsky, Y., Zohar, A., Secure high-rate transaction processing in Bitcoin (2015) Financial Cryptography, , 2015",,,"ACM Special Interest Group on Mobility of Systems, Users, Data and Computing (SIGMOBILE);ACM Special Interest Group on Operating Systems (SIGOPS)","Association for Computing Machinery, Inc","1st Workshop on Cryptocurrencies and Blockchains for Distributed Systems, CRYBLOCK 2018 - Part of MobiSys 2018","15 June 2018",,138271,,9781450358385,,,"English","CRYBLOCK - Proc. Workshop Cryptocurrencies Blockchains Distrib. Syst., Part MobiSys",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85051681763
"Liang Q., Modiano E.","55505746800;7006138684;","Minimizing Queue Length Regret under Adversarial Network Models",2018,"Performance Evaluation Review","46","1",,"31","32",,,"10.1145/3219617.3219630","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084191932&doi=10.1145%2f3219617.3219630&partnerID=40&md5=5112e0305131edcf3b6f41f3957e6e53","LIDS, Massachusetts Institute of Technology, United States","Liang, Q., LIDS, Massachusetts Institute of Technology, United States; Modiano, E., LIDS, Massachusetts Institute of Technology, United States","Stochastic models have been dominant in network optimization theory for over two decades, due to their analytical tractability. However, these models fail to capture non-stationary or even adversarial network dynamics which are of increasing importance for modeling the behavior of networks under malicious attacks or characterizing short-term transient behavior. In this paper, we focus on minimizing queue length regret under adversarial network models, which measures the finite-time queue length difference between a causal policy and an ""oracle"" that knows the future. Two adversarial network models are developed to characterize the adversary's behavior. We provide lower bounds on queue length regret under these adversary models and analyze the performance of two control policies (i.e., the MaxWeight policy and the Tracking Algorithm). We further characterize the stability region under adversarial network models, and show that both the MaxWeight policy and the Tracking Algorithm are throughput-optimal even in adversarial settings. © 2018 ACM.","adversarial; maxweight; network optimization; scheduling; stability","Queueing theory; Site selection; Stochastic control systems; Stochastic systems; Tracking (position); Adversarial networks; Adversary models; Analytical tractability; MaxWeight policies; Stability regions; Throughput-optimal; Tracking algorithm; Transient behavior; Stochastic models",,,,,"Andrews, M., Jung, K., Stolyar, A., Stability of the max-weight routing and scheduling protocol in dynamic networks and at critical loads (2007) Proceedings of the Thirty-ninth Annual ACM Symposium on Theory of Computing (STOC '07), pp. 145-154. , ACM; Andrews, M., Zhang, L., Scheduling over a time-varying user-dependent channel with applications to high speed wireless data (2002) The 43rd Annual IEEE Symposium on Foundations of Computer Science, 2002. Proceedings, pp. 293-302. , https://doi.org/10.1109/SFCS.2002.1181952; Andrews, M., Zhang, L., Scheduling over nonstationary wireless channels with finite rate sets (2006) IEEE/ACM Transactions on Networking, 14 (5), pp. 1067-1077. , https://doi.org/10.1109/TNET.2006.882835, Oct 2006; Liang, Q., Modiano, E., Minimizing queue length regret under adversarial network models (2018) Proceedings of the ACM on Measurement and Analysis of Computing Systems, 2 (1), p. 11. , 2018; Lim, S., Jung, K., Andrews, M., Stability of the maxweight protocol in adversarial wireless networks (2014) IEEE/ACM Trans. Netw., 22 (6), pp. 1859-1872. , Dec. 2014; Neely, M.J., Universal scheduling for networks with arbitrary traffic, channels, and mobility (2010) Decision and Control (CDC), 2010 49th IEEE Conference On. IEEE, pp. 1822-1829; Tassiulas, L., Ephremides, A., Stability properties of constrained queueing systems and scheduling policies for maximum throughput in multihop radio networks (1992) IEEE Transactions on Automatic Control, 37 (12), pp. 1936-1948. , 1992; Zou, Y., Zhu, J., Wang, X., Hanzo, L., A survey on wireless security: Technical challenges, recent advances, and future trends (2016) Proc. IEEE, 104 (9), pp. 1727-1765. , 2016",,,,"Association for Computing Machinery",,,,,01635999,,PERED,,"English","Perform Eval Rev",Article,"Final","All Open Access, Bronze, Green",Scopus,2-s2.0-85084191932
"Liang Q., Modiano E.","55505746800;7006138684;","Minimizing queue length regret under adversarial network models",2018,"SIGMETRICS 2018 - Abstracts of the 2018 ACM International Conference on Measurement and Modeling of Computer Systems",,,,"31","32",,2,"10.1145/3219617.3219630","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050406281&doi=10.1145%2f3219617.3219630&partnerID=40&md5=0243b6a00d5b8ad38c36cd97cefeb1c3","LIDS, Massachusetts Institute of Technology, United States","Liang, Q., LIDS, Massachusetts Institute of Technology, United States; Modiano, E., LIDS, Massachusetts Institute of Technology, United States","Stochastic models have been dominant in network optimization theory for over two decades, due to their analytical tractability. However, these models fail to capture non-stationary or even adversarial network dynamics which are of increasing importance for modeling the behavior of networks under malicious attacks or characterizing short-term transient behavior. In this paper, we focus on minimizing queue length regret under adversarial network models, which measures the finite-time queue length difference between a causal policy and an “oracle"" that knows the future. Two adversarial network models are developed to characterize the adversary’s behavior. We provide lower bounds on queue length regret under these adversary models and analyze the performance of two control policies (i.e., the MaxWeight policy and the Tracking Algorithm). We further characterize the stability region under adversarial network models, and show that both the MaxWeight policy and the Tracking Algorithm are throughput-optimal even in adversarial settings. © 2018 Copyright held by the owner/author(s).",,"Network security; Queueing theory; Site selection; Stochastic control systems; Stochastic systems; Tracking (position); Adversarial networks; Adversary models; Analytical tractability; MaxWeight policies; Stability regions; Throughput-optimal; Tracking algorithm; Transient behavior; Stochastic models",,,,,"Andrews, M., Jung, K., Stolyar, A., Stability of the Max-weight Routing and Scheduling Protocol in Dynamic Networks and at Critical Loads (2007) Proceedings of The Thirty-Ninth Annual ACM Symposium on Theory of Computing (STOC’07), pp. 145-154; Andrews, M., Zhang, L., Scheduling over a time-varying user-dependent channel with applications to high speed wireless data (2002) The 43rd Annual IEEE Symposium on Foundations of Computer Science, 2002. Proceedings, pp. 293-302. , https://doi.org/10.1109/SFCS.2002.1181952; Andrews, M., Zhang, L., Scheduling over nonstationary wireless channels with finite rate sets (2006) IEEE/ACM Transactions on Networking, 14 (5), pp. 1067-1077. , https://doi.org/10.1109/TNET.2006.882835, Oct 2006; Liang, Q., Modiano, E., Minimizing queue length regret under adversarial network models (2018) Proceedings of The ACM on Measurement and Analysis of Computing Systems, 2 (1), p. 11. , 2018; Lim, S., Jung, K., Andrews, M., Stability of the max-weight protocol in adversarial wireless networks (2014) IEEE/ACM Trans. Netw., 22 (6), pp. 1859-1872. , Dec. 2014; Neely, M.J., Universal scheduling for networks with arbitrary traffic, channels, and mobility (2010) Decision and Control (CDC), 2010 49th IEEE Conference on, pp. 1822-1829; Tassiulas, L., Ephremides, A., Stability properties of constrained queueing systems and scheduling policies for maximum throughput in multihop radio networks (1992) IEEE Transactions on Automatic Control, 37 (12), pp. 1936-1948. , 1992; Zou, Y., Zhu, J., Wang, X., Hanzo, L., A survey on wireless security: Technical challenges, recent advances, and future trends (2016) Proc. IEEE, 104 (9), pp. 1727-1765. , 2016",,,"ACM SIGMETRICS;Cisco;et al.;Facebook;Microsoft Research;National Science Foundation","Association for Computing Machinery, Inc","2018 ACM International Conference on Measurement and Modeling of Computer Systems, SIGMETRICS 2018","18 June 2018 through 22 June 2018",,137354,,9781450358460,,,"English","SIGMETRICS - Abstr. ACM Int. Conf. Meas. Model. Comput. Syst.",Conference Paper,"Final","All Open Access, Bronze, Green",Scopus,2-s2.0-85050406281
[No author name available],[No author id available],"SIGMETRICS 2018 - Abstracts of the 2018 ACM International Conference on Measurement and Modeling of Computer Systems",2018,"SIGMETRICS 2018 - Abstracts of the 2018 ACM International Conference on Measurement and Modeling of Computer Systems",,,,"149p","",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050394988&partnerID=40&md5=80e0753718024dcb357e09d56c674c61",,"","The proceedings contain 45 papers. The topics discussed include: state dependent control of closed queueing networks; Dandelion++: lightweight cryptocurrency networking with formal anonymity guarantees: extended abstract; bootstrapped graph diffusions: exposing the power of nonlinearity; the cost of uncertainty in curing epidemics; the price of fragmentation in mobility-on-demand services; new metrics and models for a post-ISA era: managing complexity; delay scaling in many-sources wireless networks without queue state information; practical bounds on optimal caching with variable object sizes; on resource pooling and separation for LRU caching; an optimal randomized online algorithm for QoS buffer management; minimizing queue length regret under adversarial network models; dynamic proportional sharing: a game-theoretic approach; SOAP: one clean analysis of all age-based scheduling policies; a Whittle's index based approach for QoE optimization in wireless networks; an optimal algorithm for online non-convex learning; asymptotic optimal control of Markov-modulated restless bandits; online learning of optimally diverse rankings; learning proportionally fair allocations with low regret; multi-armed bandit with additional observations; online learning in weakly coupled Markov decision processes: a convergence time study; working set size estimation techniques in virtualized environments: one size does not fit all; PreFix: switch failure prediction in datacenter networks; on non-preemptive VM scheduling in the cloud; and why some like it loud: timing power attacks in multi-tenant data centers using an acoustic side channel.",,,,,,,,,,"ACM SIGMETRICS;Cisco;et al.;Facebook;Microsoft Research;National Science Foundation","Association for Computing Machinery, Inc","2018 ACM International Conference on Measurement and Modeling of Computer Systems, SIGMETRICS 2018","18 June 2018 through 22 June 2018",,137354,,9781450358460,,,"English","SIGMETRICS - Abstr. ACM Int. Conf. Meas. Model. Comput. Syst.",Conference Review,"Final","",Scopus,2-s2.0-85050394988
"Liu T., Wen W., Jin Y.","57201036884;55301112800;24471712200;","SIN2: Stealth infection on neural network - A low-cost agile neural Trojan attack methodology",2018,"Proceedings of the 2018 IEEE International Symposium on Hardware Oriented Security and Trust, HOST 2018",,,,"227","230",,19,"10.1109/HST.2018.8383920","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049998978&doi=10.1109%2fHST.2018.8383920&partnerID=40&md5=ea7ef9b7557187e47199444f9eba28bd","Florida International University, United States; University of Florida, United States","Liu, T., Florida International University, United States; Wen, W., Florida International University, United States; Jin, Y., University of Florida, United States","Deep Neural Network (DNN) has recently become the 'de facto' technique to drive the artificial intelligence (AI) industry. However, there also emerges many security issues as the DNN based intelligent systems are being increasingly prevalent. Existing DNN security studies, such as adversarial attacks and poisoning attacks, are usually narrowly conducted at the software algorithm level, with the misclassification as their primary goal. The more realistic system-level attacks introduced by the emerging intelligent service supply chain, e.g. the third-party cloud based machine learning as a service (MLaaS) along with the portable DNN computing engine, have never been discussed. In this work, we propose a low-cost modular methodology-Stealth Infection on Neural Network, namely ""SIN2"", to demonstrate the novel and practical intelligent supply chain triggered neural Trojan attacks. Our ""SIN2"" well leverages the attacking opportunities built upon the static neural network model and the underlying dynamic runtime system of neural computing framework through a bunch of neural Trojaning techniques. We implement a variety of neural Trojan attacks in Linux sandbox by following proposed ""SIN2"". Experimental results show that our modular design can rapidly produce and trigger various Trojan attacks that can easily evade the existing defenses. © 2018 IEEE.",,"Computer operating systems; Deep neural networks; Distributed computer systems; Hardware; Intelligent systems; Supply chains; Computing engines; Intelligent Services; Misclassifications; Poisoning attacks; Realistic systems; Software algorithms; Static neural networks; Underlying dynamics; Malware",,,,,"Szegedy, C., An overview of deep learning (2016) AITP 2016; He, K., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Amazon Machine Learning, , https://aws.amazon.com/machine-learning/, Amazon; Movidius Neural Compute Stick, , https://newsroom.intel.com/news/intel-democratizes-deep-learning-application-developmentlaunch-movidius-neural-compute-stick/, Intel; Goodfellow, I.J., (2014) Explaining and Harnessing Adversarial Examples; Uchida, Y., Embedding watermarks into deep neural networks (2017) Proceedings of the 2017 ACM on International Conference on Multimedia Retrieval, pp. 269-277. , ACM; Hinton, G.E., Reducing the dimensionality of data with neural networks (2006) Science, 313 (5786), pp. 504-507; Jouppi, N.P., (2017) In-datacenter Performance Analysis of A Tensor Processing Unit; Abadi, M., (2016) Tensorflow: Large-scale Machine Learning on Heterogeneous Distributed Systems; Barry, B., Always-on vision processing unit for mobile applications (2015) IEEE Micro, 35 (2), pp. 56-66; Katzenbeisser, S., (2000) Information Hiding Techniques for Steganography and Digital Watermarking, , Artech house; Krizhevsky, A., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Szegedy, C., Going deeper with convolutions (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9; Simonyan, K., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition; Multiple Security Engines, , http://www.metadefender.com/#!/scan-file/, Metadefender; Zeusvm and Steganography, , http://www.xylibox.com/2014/04/zeusvm-and-steganography.html/, XyliBox; Idika, N., (2007) A Survey of Malware Detection Techniques, 48. , Purdue University; Collobert, R., Torch7: A matlab-like environment for machine learning (2011) BigLearn, NIPS Workshop, , no. EPFL-CONF-192376; Fork Bomb, , http://malware.wikia.com/wiki/Fork_Bomb/, MalwareWiki",,,"AMD;et al.;Qualcomm;Raith Nanofabrication;Rambus;Riscure","Institute of Electrical and Electronics Engineers Inc.","2018 IEEE International Symposium on Hardware Oriented Security and Trust, HOST 2018","30 April 2018 through 4 May 2018",,137176,,9781538647318,,,"English","Proc. IEEE Int. Symp. Hardw. Oriented Secur. Trust, HOST",Conference Paper,"Final","",Scopus,2-s2.0-85049998978
"Harshan J., Hu Y.-C.","23566360400;57201948004;","Cognitive radio from hell: Flipping attack on direct-sequence spread spectrum",2018,"IEEE Wireless Communications and Networking Conference, WCNC","2018-April",,,"1","6",,2,"10.1109/WCNC.2018.8376978","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049187212&doi=10.1109%2fWCNC.2018.8376978&partnerID=40&md5=07d6b90e8ed35274ff713c7bee8bf729","Indian Institute of Technology Delhi, India; University of Illinois Urbana-Champaign, United States","Harshan, J., Indian Institute of Technology Delhi, India; Hu, Y.-C., University of Illinois Urbana-Champaign, United States","In this paper, we introduce a strong adversarial attack, referred to as the flipping attack, on Direct-Sequence Spread Spectrum (DSSS) systems. In this attack, the attacker, which is appropriately positioned between the transmitter and the receiver, instantaneously flips the transmitted symbols in the air at 50% rate, thereby driving the channel capacity to zero. Unlike the traditional jamming attack, this attack, when perfectly executed, cannot be detected at the receiver using signal-to-noise-ratio measurements. However, this attack necessitates the attacker to perfectly know the realizations of all the channels in the model. We first introduce the consequences of the flipping attack on narrowband frequency-flat channels, and subsequently discuss its feasibility in wideband frequency-selective channels. From the legitimate users' perspective, we present a method to detect this attack and also propose heuristics to improve the error-performance under the attack. We emphasize that future cyber-physical systems that employ DSSS should design transceivers to detect the proposed flipping attack, and then apply appropriate countermeasures. © 2018 IEEE.",,"Channel capacity; Cognitive radio; Embedded systems; Heuristic methods; Radio transceivers; Signal to noise ratio; Spectroscopy; Wireless telecommunication systems; Direct sequence spread spectrum; Direct sequence spread spectrum system; Error performance; Flat channels; Jamming attacks; Legitimate users; Narrow bands; Wide band frequencies; Direct sequence systems",,,,,"Morris, T.H., Engineering future cyber-physical energy systems: Challenges, research needs, and roadmap (2009) 41st North American Power Symposium, pp. 1-6. , Starkville, MS, USA; Duarte, M., Sabharwal, A., Full-duplex wireless communications using off-the-shelf radios: Feasibility and first results (2010) Forty Fourth Asilomar Conference on Signals, Systems and Computers, pp. 1558-1562. , Pacific Grove, CA; Ho, Z.K.M., Jorswieck, E.A., Instantaneous relaying: Optimal strategies and interference neutralization (2012) IEEE Transactions on Signal Processing, 60 (12), pp. 6655-6668. , Dec; Wang, Q., Dong, Y., Zhao, J., Li, N., Qian, J., Liu, B., Instantaneous relaying: Feasibility conditions for interference neutralization (2015) IEEE Communications Letters, 19 (8), pp. 1370-1373. , Aug; El Gamal, A., Hassanpour, N., Relay-without-delay (2005) The Proc. of IEEE ISIT 2005, pp. 1078-1080. , Adelaide, SA; Shafiee, S., Ulukus, S., Capacity of multiple access channels with correlated jamming (2005) IEEE MILCOM 2005, , Atlantic City, NJ; Kashyap, A., Basar, T., Srikant, R., Correlated jamming on MIMO Gaussian fading channels (2004) IEEE Trans. on IT, 50 (9), pp. 2119-2123. , Sept; Cover, T.M., Thomas, J.A., (2006) Elements of Information Theory, , Wiley-Interscience; Studer, C., Benkeser, C., Belfanti, S., Huang, Q., Design and implementation of a parallel turbo-decoder ASIC for 3GPP-LTE (2011) IEEE Journal of Solid-State Circuits, 46 (1), pp. 8-17",,,"","Institute of Electrical and Electronics Engineers Inc.","2018 IEEE Wireless Communications and Networking Conference, WCNC 2018","15 April 2018 through 18 April 2018",,137074,15253511,9781538617342,,,"English","IEEE Wireless Commun. Networking Conf. WCNC",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85049187212
"Alshinina R.A., Elleithy K.M.","56026317800;35576221100;","A Highly Accurate Deep Learning Based Approach for Developing Wireless Sensor Network Middleware",2018,"IEEE Access","6",,,"29885","29898",,20,"10.1109/ACCESS.2018.2844255","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048185131&doi=10.1109%2fACCESS.2018.2844255&partnerID=40&md5=005996d3304970b56c4658c07a11f947","Department of Computer Science and Engineering, University of Bridgeport, Bridgeport, CT  06604, United States","Alshinina, R.A., Department of Computer Science and Engineering, University of Bridgeport, Bridgeport, CT  06604, United States; Elleithy, K.M., Department of Computer Science and Engineering, University of Bridgeport, Bridgeport, CT  06604, United States","Despite the popularity of wireless sensor networks (WSNs) in a wide range of applications, security problems associated with them have not been completely resolved. Middleware is generally introduced as an intermediate layer between WSNs and the end user to resolve some limitations, but most of the existing middleware is unable to protect data from malicious and unknown attacks during transmission. This paper introduces a secure wireless sensor network middleware (SWSNM) based on an unsupervised learning technique called generative adversarial network algorithm. SWSNM consists of two networks: a generator (G) network and a discriminator (D) network. The G creates fake data that are similar to the real sample and combines it with real data from the sensors to confuse the attacker. The D contains multi-layers that have the ability to differentiate between real and fake data. The output intended for this algorithm shows an actual interpretation of the data that is securely communicated through the WSN. The framework is implemented in Python with experiments performed using Keras. Results illustrate that SWSNM algorithm improves the accuracy of the data and enhances its security by protecting data from adversaries. In addition, the SWSNM algorithm consumes significantly less energy, has higher throughput, and lower end-to-end delay when compared with a similar conventional approach. © 2013 IEEE.","confusion matrix; delay; discriminator; energy consumption; GANs; generator; Middleware; security; unsupervised learning; visualization; WSNs","Deep learning; Discriminators; Energy utilization; Flow visualization; Middleware; Network security; Unsupervised learning; Confusion matrices; delay; GANs; generator; security; WSNs; Wireless sensor networks",,,,,"Bispo, K.A., Rosa, N.S., Cunha, P.R.F., SITRUS: Semantic infrastructure for wireless sensor networks (2015) Sensors, 15 (11), pp. 27436-27469; Xu, G., Shen, W., Wang, X., Applications of wireless sensor networks in marine environment monitoring: A survey (2014) Sensors, 14 (9), pp. 16932-16954; Hadim, S., Mohamed, N., Middleware for wireless sensor networks: A survey (2006) Proc. 1st Int. Conf. Commun. Syst. Softw. Middleware, pp. 1-7. , New Delhi, India, Jan; Alshinina, R., Elleithy, K., Performance and challenges of serviceoriented architecture for wireless sensor networks (2017) Sensors, 17 (3), p. 536; Al-Jaroodi, J., Al-Dhaheri, A., Security issues of service-oriented middleware (2011) Int. J. Comput. Sci. Netw. Secur., 11 (1), pp. 153-160; Shchzad, A., Ngo, H.Q., Lee, S.Y., Lee, Y.-K., A comprehensive middleware architecture for context-aware ubiquitous computing systems (2005) Proc. 4th Annu. ACIS Int. Conf. Comput. Inf. Sci. (ICIS), pp. 251-256. , Jeju, South Korea, Jul; Wang, Y., Attebury, G., Ramamurthy, B., A survey of security issues in wireless sensor networks (2006) IEEE Commun. Surveys Tuts., 8 (2), pp. 2-23. , 2nd Quart; Law, Y.W., Doumen, J., Hartel, P., Benchmarking block ciphers for wireless sensor networks (2004) Proc.IEEE Int. Conf. Mobile Ad-Hoc Sensor Syst., pp. 447-456. , Fort Lauderdale, FL, USA, Oct; Newsome, J., Shi, E., Song, D., Perrig, A., The sybil attack in sensor networks: Analysis & defenses (2004) 3rd Int. Symp. Inf. Process. Sensor Netw., , Berkeley, CA, USA; Pirzada, A.A., McDonald, C., Secure routing with the AODV protocol (2005) Proc. Asia-Pacific Conf. Commun., pp. 57-61. , Perth, WA, Australia, Oct; Bhargava, S., Agrawal, D.P., Security enhancements in AODV protocol for wireless ad hoc networks (2001) Proc.IEEE VTS 54th Veh. Technol. Conf. (VTC Fall), 4, pp. 2143-2147. , Atlantic City, NJ, USA, Oct; Capkun, S., Hubaux, J.-P., Secure positioning of wireless devices with application to sensor networks (2005) Proc. 24th Annu. Joint Conf. IEEE Comput. Commun. Soc. (INFOCOM), 3, pp. 1917-1928. , Miami, FL, USA, Mar; Aggarwal, P., Sharma, S.K., Analysis of KDD dataset attributes-Class wise for intrusion detection (2015) Procedia Comput. Sci., 57, pp. 842-851. , Mar; Jeyanna, J.A., Indumathi, E., Punithavathani, D.S., A network intrusion detection system using clustering and outlier detection (2015) Int. J. Innov. Res. Comput. Commun. Eng. (IJIRCCE, 3 (2), pp. 975-982; Shi, E., Perrig, A., Designing secure sensor networks (2004) IEEE Wireless Commun., 11 (6), pp. 38-43. , Dec; Chen, X., Makki, K., Yen, K., Pissinou, N., Sensor network security: A survey (2009) IEEE Commun. Surveys Tuts., 11 (2), pp. 52-73. , 2nd Quart; Roy, S., Maitra, N., Nath, J., Agarwal, S., Nath, A., Ultra encryption standard modified (UES) version-I: Symmetric key cryptosystem with multiple encryption and randomized vernam key using generalized modi- fied vernam cipher method, permutation method, and columnar transposition method (2012) Proc.IEEE Sponsored Nat. Conf. Recent Adv. Commun., Control Comput. Technol. (RACCCT, pp. 29-30; Swaminathan, A., Krishnan, B.S., Ramaswamy, M., A novel security enhancement strategy for improving the concert of CDMA based mobile ad-hoc network (2017) Proc. Int. J. Mod. Electron. Commun. Eng. (IJMECE, pp. 1-8. , Jan; Kaur, A., Kang, S.S., Attacks in wireless sensor network-A review (2016) Int. J. Comput. Sci. Eng., 4 (5), pp. 157-162. , May; Shinganjude, R.D., Theng, D.P., Inspecting the ways of source anonymity in wireless sensor network (2014) Proc. 4th Int. Conf. Commun. Syst. Netw. Technol. (CSNT, pp. 705-707; Lingaraj, K., Biradar, R.V., Patil, V.C., Eagilla: An enhanced mobile agent middleware for wireless sensor networks Alexandria Eng. J., , to be published; Capra, L., MaLM: Machine learning middleware to tackle ontology heterogeneity (2007) Proc. 5th Annu. IEEE Int. Conf. Pervasive Comput. Com- Mun.Workshops (PerComWorkshops), pp. 449-454. , White Plains, NY, USA, Mar; Avram, T., Oh, S., Hariri, S., Analyzing attacks in wireless ad hoc network with self-organizing maps (2007) Proc. 5th Annu. Conf. Commun. Netw. Services Res. (CNSR), pp. 166-175. , Frederlcton, NB, Canada, May; Alsheikh, M.A., Lin, S., Niyato, D., Tan, H.P., Machine learning in wireless sensor networks: Algorithms, strategies, and applications (2014) IEEE Commun. Surveys Tuts., 16 (4), pp. 1996-2018. , 4th Quart; Ribeiro, M., Grolinger, K., Capretz, M.A.M., MLaaS: Machine learning as a service (2015) Proc.IEEE 14th Int. Conf. Mach. Learn. Appl. (ICMLA), pp. 896-902. , Miami, FL, USA, Dec; Husain, R., Vohra, D.R., A survey on machine learning in wireless sensor networks (2017) Int. Edu. and Res. J., 3 (1), pp. 17-18; Ahad, N., Qadir, J., Ahsan, N., Neural networks in wireless networks: Techniques, applications and guidelines (2016) J. Netw. Comput. Appl., 68, pp. 1-27. , Jun; Zhang, Y., Meratnia, N., Havinga, P., Outlier detection techniques for wireless sensor networks: A survey (2010) IEEE Commun. Surveys Tuts., 12 (2), pp. 159-170. , 2nd Quart; Mehboob, U., Qadir, J., Ali, S., Vasilakos, A., Genetic algorithms in wireless networking: Techniques, applications, and issues (2016) Soft Comput., 20 (6), pp. 2467-2501; Vasseur, J.-P., Mermoud, G., Dasgupta, S., Predictive learning machine-based approach to detect traffic outside of service level agreements (2016), May 10; Janakiram, D., Reddy, V.A., Kumar, A.V.U.P., Outlier detection in wireless sensor networks using Bayesian belief networks (2006) Proc. 1st Int. Conf. Commun. Syst. Softw. Middleware, pp. 1-6. , New Delhi, India, Jan; Branch, J.W., Szymanski, B., Giannella, C., Ran, W., Kargupta, H., Innetwork outlier detection in wireless sensor networks (2006) Proc. 26th IEEE Int. Conf. Distrib. Comput. Syst. (ICDCS), p. 51. , Lisboa, Portugal; Kaplantzis, S., Shilton, A., Mani, N., Sekercioglu, Y.A., Detecting selective forwarding attacks in wireless sensor networks using support vector machines (2007) Proc. 3rd Int. Conf. Intell. Sensors, Sensor Netw. Inf., pp. 335-340. , Melbourne, QLD, Australia, Dec; Rajasegarar, S., Leckie, C., Palaniswami, M., Bezdek, J.C., Quarter sphere based distributed anomaly detection in wireless sensor networks (2007) Proc.IEEE Int. Conf. Commun., pp. 3864-3869. , Glasgow, U.K., Jun; Beyer, K., Goldstein, J., Ramakrishnan, R., Shaft, U., When is 'nearest neighbor' meaningful? (1999) Proc. 7th Int. Conf. Database Theory (ICDT), pp. 217-235. , Jerusalem, Israel, C. Beeri and P. Buneman, Eds. Berlin, Germany: Springer; Goodfellow, I., Generative adversarial nets (2014) Proc. Adv. Neural Inf. Process. Syst., pp. 2672-2680; Salimans, T., Improved techniques for training GANs (2016) Proc. Adv. Neural Inf. Process. Syst., pp. 2234-2242; Springenberg, J.T., (2015) Unsupervised and Semi-supervised Learning with Categorical Generative Adversarial Networks, , https://arxiv.org/abs/1511.06390, [Online]; NSL-KDD, , http://nsl.cs.unb.ca/nsl-kdd/, University of New Brunswick, [Online]; Tavallaee, M., Bagheri, E., Lu, W., Ghorbani, A.A., A detailed analysis of the KDD CUP 99 data set (2009) Proc.IEEE Symp. Comput. Intell. Secur. Defense Appl., pp. 1-6. , Ottawa, ON, Canada, Jul; Hettich, S., Bay, S., (1999) The UCI KDD Archive, p. 152. , http://kdd.ics.uci.edu, Dept. Inf. Comput. Sci., Univ. California, Irvine, Irvine, CA, USA, Tech. Rep., [Online]; (1999) KDD Cup 1999, , http://Kdd.Ics.Uci.Edu/Databases/Kddcup99.html, University of California, Irvine, [Online]; Ray, L., Determining the number of hidden neurons in a multi layer feed forward neural network (2013) J. Inf. Secur. Res., 4 (2), pp. 63-70; Chollet, F., (2015) Keras, , https://github.com/fchollet/keras, [Online]; Ioffe, S., Szegedy, C., Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015) Proc. Int. Conf. Mach. Learn., pp. 448-456; Glorot, X., Bengio, Y., Understanding the difficulty of training deep feedforward neural networks (2010) Proc. 13th Int. Conf. Artif. Intell. Statist., pp. 249-256; He, K., Sun, J., Convolutional neural networks at constrained time cost (2015) Proc.IEEE Conf. Comput. Vis. Pattern Recognit., pp. 5353-5360. , Jun; Srivastava, R.K., Greff, K., Schmidhuber, J., Training very deep networks (2015) Proc. Adv. Neural Inf. Process. Syst., pp. 2377-2385; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc.IEEE Conf. Comput. Vis. Pattern Recognit., pp. 770-778. , Las Vegas, NV, USA, Jun; Albelwi, S., Mahmood, A., Aframework for designing the architectures of deep convolutional neural networks (2017) Entropy, 19 (6), p. 242; Ingre, B., Yadav, A., Performance analysis of NSL-KDD dataset using ANN (2015) Proc. Int. Conf. Signal Process. Commun. Eng. Syst., pp. 92-96. , Guntur, India, Jun; Panda, M., Abraham, A., Patra, M.R., Discriminative multinomial Naïve Bayes for network intrusion detection (2010) Proc. 6th Int. Conf. Inf. Assurance Secur., pp. 5-10. , Atlanta, GA, USA, Aug; Ibrahim, L.M., Basheer, D.T., Mahmod, M.S., A comparison study for intrusion database (KDD99, NSL-KDD) based on self organization map (SOM) artificial neural network (2013) J. Eng. Sci. Technol., 8 (1), pp. 107-119; Van Der Maaten, L., Hinton, G., Visualizing data using t-SNE (2008) J. Mach. Learn. Res., 9, pp. 2579-2605. , Nov; Singh, S.S., Jinila, Y.B., Sensor node failure detection using check point recovery algorithm (2016) Proc. Int. Conf. Recent Trends Inf. Technol. (ICRTIT), pp. 1-4. , Chennai, India, Apr; Sumalatha, G., Zareena, N., Raju, C.G., (2014) A Review on Failure Node Recovery Algorithms in Wireless Sensor Actor Networks, , https://arxiv.org/abs/1407.0009, [Online]; Jiang, P., A new method for node fault detection in wireless sensor networks (2009) Sensors, 9 (2), pp. 1282-1294; LeCun, Y., (1998) The MNIST Database of Handwritten Digits, , http://yann.lecun.com/exdb/mnist/, [Online]","Alshinina, R.A.; Department of Computer Science and Engineering, United States; email: ralshini@my.bridgeport.edu",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85048185131
"Sun D., Yang K., Shi Z., Chen C.","56419137200;56438337000;57214682025;57257625700;","A new mimicking attack by LSGAN",2018,"Proceedings - International Conference on Tools with Artificial Intelligence, ICTAI","2017-November",,,"441","447",,3,"10.1109/ICTAI.2017.00074","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048512064&doi=10.1109%2fICTAI.2017.00074&partnerID=40&md5=050f3e01289a5632d8592d4e89a46203","School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China","Sun, D., School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China, Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China, School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; Yang, K., Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China, School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; Shi, Z., Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Chen, C., Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China","Discriminating Distributed Denial of Service Attacks (DDoS) from Flash Crowds (FC) is a tough and challenging problem. If attackers could generate mimicking traffic which have little difference from the traffic produced by legitimate users in FC, are existing methods and defense systems still able to distinguish DDoS from FC? To verify the possibility of the existence of this mimicking attack and prove the existing methods cannot discriminate this attack from FC, this paper proposes an idea employed Least Squares Generative Adversarial Networks (LSGAN) to generate mimicking traffic based on a statistical features achieved from an extensive analysis of user traffic behavior of DDoS and FC. Then to establish an efficient defense system employed Random Forest to prove it can achieve better performance on real network traffic traces, but cannot discriminate this mimicking attack traffic from FC. The experiments results show the proposed idea can generate this mimicking attack traffic and the defense system cannot discriminate it from FC. In addition, a comparison with GAN has been made to show that LSGAN is better than GAN in performance. © 2017 IEEE.","DDoS; Flash Crowds; GAN; LSGAN; Mimicking Attacks","Artificial intelligence; Behavioral research; Decision trees; Least squares approximations; Network security; Adversarial networks; DDoS; Distributed denial of service attack; Flash crowd; Legitimate users; LSGAN; Mimicking Attacks; Statistical features; Denial-of-service attack",,,,,"Jung, J., Krishnamurthy, B., Rabinovich, M., Flash crowds and denial of service attacks: Characterization and implications for cdns and web sites (2002) Proceedings of the 11th International Conference on World Wide Web, pp. 293-304. , ACM; (2016) Worldwide Infrastructure Security Report, , Arbor Networks; Munivara Prasad, K., Rama Mohan Reddy, A., Venugopal Rao, K., Discriminating ddos attack traffic from flash crowds on internet threat monitors (itm) using entropy variations (2013) African Journal of Computing & ICT, 6 (3); The Arbor Networks Wisrreport, , http://www.arbornetworks.com/images/documents/WISR2016ENWeb.pdf, WISR; Behal, S., Kumar, K., Detection of ddos attacks and flash events using novel information theory metrics (2017) Computer Networks, 116, pp. 96-110; Yan, Q., Richard Yu, F., Gong, Q., Li, J., Software-defined networking (SDN) and distributed denial of service (ddos) attacks in cloud computing environments: A survey, some research issues, and challenges (2016) IEEE Communications Surveys & Tutorials, 18 (1), pp. 602-622; Somani, G., Singh Gaur, M., Sanghi, D., Conti, M., Buyya, R., Ddos attacks in cloud computing: Issues, taxonomy, and future directions (2017) Computer Communications, 107 (10), pp. 30-48; Srihari Rao, N., Chandra Sekharaiah, K., Ananda Rao, A., (2016) A Survey of Discriminating Distributed DoS Attacks from Flash Crowds, , Springer Singapore; Mao, X., Li, Q., Xie, H., Lau, K.R.Y., Wang, Z., Paul Smolley, S., (2017) Least Squares Generative Adversarial Networks; Behal, S., Kumar, K., Sachdeva, M., Discriminating flash events from ddos attacks: A comprehensive review (2017) International Journal of Network Security, 19 (5), pp. 734-741; Li, K., Zhou, W., Li, P., Hai, J., Liu, J., Distinguishing ddos attacks from flash crowds using probability metrics (2009) NSS, pp. 9-17. , IEEE Computer Society; Bhatia, S., Mohay, G., Tickle, A., Ahmed, E., Parametric differences between a real-world distributed denial-of-service attack and a flash event (2011) Availability, Reliability and Security (ARES), 2011 Sixth International Conference on, pp. 210-217. , IEEE; Sharma, P., Sharma, N., Singh, R., A secure intrusion detection system against ddos attack in wireless mobile ad-hoc network (2012) International Journal of Computer Applications, 41 (21); Yu, S., Guo, S., Stojmenovic, I., Fool me if you can: Mimicking attacks and anti-Attacks in cyberspace (2015) IEEE Transactions on Computers, 64 (1), pp. 139-151; Gupta, P., Bansal, P., A survey of attacks and countermeasures for denial of services (dos) in wireless ad hoc networks (2016) Proceedings of the Second International Conference on Information and Communication Technology for Competitive Strategies, p. 25. , ACM; Marcus, G., Rossi, F., Veloso, M., Beyond the turing test (2016) Ai Magazine; Schmidhuber, J., (2015) Deep Learning in Neural Networks, , Elsevier Science Ltd and rgen; Lecun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), pp. 436-444; Breiman, L., Random forests (2001) Machine Learning, 45 (1), pp. 5-32; Goodfellow, I.J., Pougetabadie, J., Mirza, M., Xu, B., Wardefarley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial networks (2014) Advances in Neural Information Processing Systems, 3, pp. 2672-2680; Goodfellow, I., (2016) Nips 2016 Tutorial: Generative Adversarial Networks; (2007) DDoS, , http://www.caida.org/data/passive/ddos-20070804.dataset.xml, Caida ddos attack 2007 dataset; (1998) FlashCrowds, , http://ita.ee.lbl.gov/html/contrib/WorldCup.html, World cup 1998 dataset",,,"IEEE Computer Society","IEEE Computer Society","29th IEEE International Conference on Tools with Artificial Intelligence, ICTAI 2017","6 November 2017 through 8 November 2017",,136944,10823409,9781538638767,PCTIF,,"English","Proc. Int. Conf. Tools Artif. Intell. ICTAI",Conference Paper,"Final","",Scopus,2-s2.0-85048512064
"Bhunia S., Regis P.A., Sengupta S.","36452102600;57188568176;57200399811;","Distributed adaptive beam nulling to survive against jamming in 3D UAV mesh networks",2018,"Computer Networks","137",,,"83","97",,4,"10.1016/j.comnet.2018.03.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044519358&doi=10.1016%2fj.comnet.2018.03.011&partnerID=40&md5=158682a31df7a3a9d8525aec7ba89dbf","Department of Computer Science, University of California, Davis, 95616, United States; Department of Computer Science and Engineering, University of Nevada, Reno, 89557, United States","Bhunia, S., Department of Computer Science, University of California, Davis, 95616, United States; Regis, P.A., Department of Computer Science and Engineering, University of Nevada, Reno, 89557, United States; Sengupta, S., Department of Computer Science and Engineering, University of Nevada, Reno, 89557, United States","In the future generation mission-centric tactical network, 3D UAV mesh network will play a crucial role for its several advantages. However, any adversarial node with the 3D movement capability poses a significant threat to these networks as the adversary can position itself to attack the crucial links. An adaptive beamnulling antenna is used to spatially filter out signal coming from a certain direction that can maintain the links active without requiring additional spectrum. However, determining the beamnull region is very challenging for jammer with mobility. This paper presents a distributed mechanism where nodes measure the jammer's direction in a discrete interval and determine the optimal beamnull for the next interval. Kalman filter based tracking mechanism is used to estimate the most likely trajectory of the jammer from noisy observation of the jammer's position. A beam null border is determined by calculating confidence region of jammer's current and next position estimates. An optimization goal is presented to determine the optimal beam null that minimizes the number of deactivated links while maximizing the higher value of confidence for keeping the jammer inside the null. The framework works in the physical layer and can work with any upper layer protocol. The survivability of a 3D mesh network with a mobile jammer is studied through simulation that validates an 96.65% reduction in the number of jammed nodes. © 2018 Elsevier B.V.","3D Mesh; Beam nulling; Directional antenna; Jamming; Kalman filter; MANET; Tracking; VANET","Directive antennas; Jamming; Kalman filters; Mesh generation; Network layers; Surface discharges; Unmanned aerial vehicles (UAV); Vehicular ad hoc networks; 3D meshes; Directional Antenna; MANET; Nulling; VANET; MESH networking",,,,,"Bhunia, S., Sengupta, S., Distributed adaptive beam nulling to mitigate jamming in 3D UAV mesh networks (2017) Proceedings of the International Conference on Computing, Networking and Communications (ICNC), , IEEE; Bekmezci, I., Sahingoz, O.K., Temel, A., Flying ad-hoc networks (fanets): a survey (2013) Ad. Hoc. Netw., 11 (3), pp. 1254-1270; Yu, C., Shin, K.G., Song, L., Maximizing communication concurrency via link-layer packet salvaging in mobile ad hoc networks (2007) IEEE Trans. Mob. Comput., 6 (4); Gupta, L., Jain, R., Vaszkun, G., Survey of important issues in uav communication networks (2016) IEEE Commun. Surv. Tutor., 18 (2), pp. 1123-1152; Motlagh, N.H., Bagaa, M., Taleb, T., UAV-based IOT platform: a crowd surveillance use case (2017) IEEE Commun. Mag., 55 (2), pp. 128-134; http://www.firstresponder.gov/SitePages/HomePage/FirstResponder.aspx; http://www.faa.gov/news/updates/?newsId=68004, FAA makes progress with UAS integration; http://www.kolotv.com/home/headlines/Washoe-County-Will-Test-Drones-for-Emergency-Use-305475261.html, Washoe county test drones for emergency use; De Filippis, L., Guglieri, G., Quagliotti, F., Path planning strategies for UAVs in 3d environments (2012) J. Intell. Robot. Syst., 65 (1-4), pp. 247-264; Jhaveri, R.H., Patel, S.J., Jinwala, D.C., Dos attacks in mobile ad hoc networks: a survey (2012) Proceedings of the 2012 Second International Conference on Advanced Computing & Communication Technologies (ACCT), pp. 535-541. , IEEE; von Mulert, J., Welch, I., Seah, W.K., Security threats and solutions in manets: a case study using {AODV} and {SAODV} (2012) J. Netw. Comput. Appl., 35 (4), pp. 1249-1259; Li, M., Koutsopoulos, I., Poovendran, R., Optimal jamming attack strategies and network defense policies in wireless sensor networks (2010) IEEE Trans. Mob. Comput., 9 (8), pp. 1119-1133; Saranyadevi, R., Shobana, M., Prabakar, D., Article: a survey on preventing jamming attacks in wireless communication (2012) Int. J. Comput. Appl., 57 (23), pp. 1-3. , Full text available; Van Veen, B.D., Buckley, K.M., Beamforming: a versatile approach to spatial filtering (1988) IEEE ASSP Mag., 5 (2), pp. 4-24; Seifi, N., Zhang, J., Heath, R.W., Svensson, T., Coldrey, M., Coordinated 3d beamforming for interference management in cellular networks (2014) IEEE Trans. Wirel. Commun., 13 (10), pp. 5396-5410; Cummings, W.C., Anadaptive nulling antenna for military (1992) Linc. Lab. J., 5 (2); Mingjie, D., Xinjian, P., Fang, Y., Jianghong, L., Research on the technology of adaptive nulling antenna used in anti-jam GPS (2001) Proceedings of the 2001 CIE International Conference on Radar Proceedings, pp. 1178-1181. , IEEE; Rao, G.K., Rao, R.S.H., Status study on sustainability of satellite communication systems under hostile jamming environment (2011) Proceedings of the 2011 Annual IEEE India Conference (INDICON), pp. 1-7. , IEEE; Willerton, M., Yates, D., http://sine.ni.com/cs/app/doc/p/id/cs-15016#, Imperial college London enhances direction finding and beamforming using LabVIEW and NI USRP; http://forums.ni.com/t5/Software-Defined-Radio/Angle-of-Arrival-Detection-with-NI-USRP-and-LabVIEW/ta-p/3534214, Angle of arrival detection with NI USRP RIO; Bhunia, S., Behzadan, V., Regis, P.A., Sengupta, S., Adaptive beam nulling in multihop ad hoc networks against a jammer in motion (2016) Comput. Netw., 109, pp. 50-66; Brown, R.G., Hwang, P.Y., Introduction to Random Signals and Applied Kalman Filtering with Matlab Exercises, 4th Edition (2012), Wiley; Chiang, J.T., Hu, Y.-C., Cross-layer jamming detection and mitigation in wireless broadcast networks (2011) IEEE/ACM Trans. Netw. (TON), 19 (1), pp. 286-298; Sorrells, C., Qian, L., Li, H., Quickest detection of denial-of-service attacks in cognitive wireless networks (2012) Proceedings of the 2012 IEEE Conference on Technologies for Homeland Security (HST), pp. 580-584. , IEEE; Spuhler, M., Giustiniano, D., Lenders, V., Wilhelm, M., Schmitt, J.B., Detection of reactive jamming in DSSS-based wireless communications (2014) IEEE Trans. Wirel. Commun., 13 (3), pp. 1593-1603; Lu, Z., Wang, W., Wang, C., Modeling, evaluation and detection of jamming attacks in time-critical wireless applications (2014) IEEE Trans. Mob. Comput., 13 (8), pp. 1746-1759; He, X., Dai, H., Ning, P., Dynamic adaptive anti-jamming via controlled mobility (2014) IEEE Trans. Wirel. Commun., 13 (8), pp. 4374-4388; Hanawal, M.K., Abdel-Rahman, M.J., Krunz, M., Joint adaptation of frequency hopping and transmission rate for anti-jamming wireless systems (2016) IEEE Trans. Mob. Comput., 15 (9), pp. 2247-2259; Huang, J.-F., Chang, G.-Y., Huang, J.-X., Anti-jamming rendezvous scheme for cognitive radio networks (2017) IEEE Trans. Mob. Comput., 16 (3), pp. 648-661; Sorrells, C., Potier, P., Qian, L., Li, X., Anomalous spectrum usage attack detection in cognitive radio wireless networks (2011) Proceedings of the IEEE International Conference on Technologies for Homeland Security (HST), 2011, pp. 384-389. , IEEE; Mneimneh, S., Bhunia, S., Vázquez-Abad, F., Sengupta, S., A game-theoretic and stochastic survivability mechanism against induced attacks in cognitive radio networks (2017) Pervasive Mob. Comput., 40, pp. 577-592; Bhunia, S., Su, X., Sengupta, S., Vázquez-Abad, F., Stochastic model for cognitive radio networks under jamming attacks and honeypot-based prevention (2014) Proceedings of the International Conference on Distributed Computing and Networks (ICDCN), pp. 438-452. , Springer Berlin Heidelberg; Bhunia, S., Sengupta, S., Vazquez-Abad, F., Cr-Honeynet: a learning & decoy based sustenance mechanism against jamming attack in CRN (2014) Proceedings of the 2014 IEEE Military Communications Conference, pp. 1173-1180. , IEEE; Bhunia, S., Sengupta, S., VÃ!‘zquez-Abad, F., Performance analysis of cr-Honeynet to prevent jamming attack through stochastic modeling (2015) Pervasive Mob. Comput., 21, pp. 133-149; Volakis, J., Antenna Engineering Handbook, Fourth Edition (2007), McGraw-Hill Companies,Incorporated; Becker, J.M., (2014) Dynamic beamforming optimization for anti-jamming and hardware fault recovery, , Carnegie Mellon University Ph.D. thesis; Lei, L., Rongqing, X., Gaopeng, L., Robust adaptive beamforming based on generalized sidelobe cancellation (2006) Proceedings of the International Conference on Radar, 2006. CIE'06., pp. 1-4. , IEEE; Xu, Y., Liu, Z., Noncircularity-rate maximization: a new approach to adaptive blind beamforming (2009) Proceedings of the WiCom, pp. 1-4. , IEEE; Chen, S., Hanzo, L., Ahmad, N.N., Wolfgang, A., Adaptive minimum bit error rate beamforming assisted receiver for QPSK wireless communication (2005) Digit. Signal Process., 15 (6), pp. 545-567; Haupt, R., Southall, H., Experimental adaptive nulling with a genetic algorithm (1999) MICROWAVE JOURNAL-EUROGLOBAL EDITION-, 42, pp. 78-89; Massa, A., Donelli, M., De Natale, F.G., Caorsi, S., Lommi, A., Planar antenna array control with genetic algorithms and adaptive array theory (2004) IEEE Trans. Antennas Propag., 52 (11), pp. 2919-2924; Lee, Y.-J., Seo, J.-W., Ha, J.-K., Park, D.-C., Null steering of linear phased array antenna using genetic algorithm (2009) Proceedings of the Microwave Conference, 2009. APMC 2009. Asia Pacific, pp. 2726-2729. , IEEE; Sadler, D.J., Planar array design for low ambiguity (2009) Proceedings of the Antennas & Propagation Conference, 2009. LAPC 2009. Loughborough, pp. 713-716. , IEEE; Evans, H., Gale, P., Aljibouri, B., Lim, E., Korolkwiwicz, E., Sambell, A., Application of simulated annealing to design of serial feed sequentially rotated 2 ×  2 antenna array (2000) Electron. Lett., 36 (24), pp. 1987-1988; Ram, S., (2007) A study of adaptive beamforming techniques using smart antenna For mobile communication, , National Institute of Technology Rourkela Ph.D. thesis; Van Trees, H.L., Detection, Estimation, and Modulation Theory (2004), John Wiley & Sons; Jin, M., Liao, G., Li, J., Joint dod and doa estimation for bistatic mimo radar (2009) Signal Processing, 89 (2), pp. 244-251; Zhang, X., Xu, L., Xu, L., Xu, D., Direction of departure (dod) and direction of arrival (doa) estimation in mimo radar with reduced-dimension music (2010) IEEE Commun. Lett., 14 (12), pp. 1161-1163; Vaidyanathan, C., Buckley, K.M., Performance analysis of the mvdr spatial spectrum estimator (1995) IEEE Trans. Signal Process., 43 (6), pp. 1427-1437; Krishnaveni, V., Kesavamurthy, T., Beamforming for direction-of-arrival (doa) estimation: a survey (2013) Int. J. Comput. Appl., 61 (11), pp. 4-11; Szalay, Z., Nagy, L., Target modeling, antenna array design and conventional beamforming algorithms for radar target DOA estimation (2015) Proceedings of the 2015 17th International Conference on Transparent Optical Networks (ICTON), pp. 1-4; Tayem, N., 2D DOA estimation of multiple coherent sources using a new antenna array configuration (2012) Proceedings of the 2012 Conference Record of the Forty Sixth Asilomar Conference on Signals, Systems and Computers (ASILOMAR), pp. 212-216; Akbari, F., Moghaddam, S., Vakili, V., MUSIC and MVDR DOA estimation algorithms with higher resolution and accuracy (2010) Proceedings of the 2010 5th International Symposium on Telecommunications (IST), pp. 76-81; Bazan, O., Jaseemuddin, M., A survey on MAC protocols for wireless adhoc networks with beamforming antennas (2012) Commun. Surv. Tutor. IEEE, 14 (2), pp. 216-239; Ansari, A.A., Hasan, Z., Alam, M.J., Mohammad, K., Siddique, A., Performance comparison for omnidirectional and directional MAC protocols for ad hoc network (2013) Int. J. Comput. Appl, 70 (21), pp. 26-31; Niu, J., Zhang, R., Cai, L., Yuan, J., A fully-distributed directional-to-directional MAC protocol for mobile ad hoc networks (2015) Proceedings of the IEEE ICNC, pp. 766-770; Ullah, M.S., Nur, F.N., Moon, N.N., Optimization of wireless ad-hoc networks using an adjacent collaborative directional MAC (ACDM) protocol (2015) Int. J. Comput. Appl., 114 (3); Nasipuri, A., Ye, S., You, J., Hiromoto, R.E., A MAC protocol for mobile ad hoc networks using directional antennas (2000) Proceedings of the 2000 IEEE Wireless Communications and Networking Conference. Conference Record, 3, pp. 1214-1219. , IEEE; Wirth, W.-D., Radar techniques using array antennas (2001), 10. , IET; Chandran, S., Adaptive Antenna Arrays: Trends and Applications (2013), Springer Science & Business Media; Regis, P.A., Bhunia, S., Sengupta, S., Implementation of 3d obstacle compliant mobility models for uav networks in ns-3 (2016) Proceedings of the Workshop on Ns-3, WNS3 ’16, pp. 124-131. , ACM New York, NY, USA; Bhunia, S., Behzadan, V., Regis, P.A., Sengupta, S., Performance of adaptive beam nulling in multihop ad-hoc networks under jamming (2015) Proceedings of the IEEE CSS, pp. 1236-1241. , IEEE; https://www.nsnam.org/, ns-3 Consortium, Network simulator, ns-3; Perkins, C., Belding-Royer, E., Das, S., Ad hoc on-demand distance vector (AODV) routing (2003) Technical Report; Perkins, C.E., Bhagwat, P., Highly dynamic destination-sequenced distance-vector routing (DSDV) for mobile computers (1994) Proceedings of the SIGCOMM, pp. 234-244. , ACM New York, NY, USA; https://codereview.appspot.com/6620057/#ps1, Directional antenna patch for ns-3","Bhunia, S.; Department of Computer Science, United States; email: sbhunia@ucdavis.edu",,,"Elsevier B.V.",,,,,13891286,,CNETD,,"English","Comput. Networks",Article,"Final","",Scopus,2-s2.0-85044519358
"Mao D., Li Z., Cai Q., Xue Z.","55647384200;57202463740;55722661500;56985142800;","Tickling Deep Differential Privacy Protection Method Based on DCGAN [基于DCGAN反馈的深度差分隐私保护方法]",2018,"Beijing Gongye Daxue Xuebao/Journal of Beijing University of Technology","44","6",,"870","877",,2,"10.11936/bjutxb2017070017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056296318&doi=10.11936%2fbjutxb2017070017&partnerID=40&md5=a00a456adeec9bf5dc81d11bd010a2fa","Beijing Key Laboratory of Big Data Technology for Food Safety, School of Computer and Information Engineering, Beijing Technology and Business University, Beijing, 100048, China; National Engineering Laboratory for Quality and Safety Traceability Technology and Application of Agricultural Products, Beijing Technology and Business University, Beijing, 100048, China","Mao, D., Beijing Key Laboratory of Big Data Technology for Food Safety, School of Computer and Information Engineering, Beijing Technology and Business University, Beijing, 100048, China, National Engineering Laboratory for Quality and Safety Traceability Technology and Application of Agricultural Products, Beijing Technology and Business University, Beijing, 100048, China; Li, Z., Beijing Key Laboratory of Big Data Technology for Food Safety, School of Computer and Information Engineering, Beijing Technology and Business University, Beijing, 100048, China, National Engineering Laboratory for Quality and Safety Traceability Technology and Application of Agricultural Products, Beijing Technology and Business University, Beijing, 100048, China; Cai, Q., Beijing Key Laboratory of Big Data Technology for Food Safety, School of Computer and Information Engineering, Beijing Technology and Business University, Beijing, 100048, China, National Engineering Laboratory for Quality and Safety Traceability Technology and Application of Agricultural Products, Beijing Technology and Business University, Beijing, 100048, China; Xue, Z., Beijing Key Laboratory of Big Data Technology for Food Safety, School of Computer and Information Engineering, Beijing Technology and Business University, Beijing, 100048, China, National Engineering Laboratory for Quality and Safety Traceability Technology and Application of Agricultural Products, Beijing Technology and Business University, Beijing, 100048, China","To prevent attackers from using generative adversarial networks (GAN) and other technologies in the application of deep learning model to restore the data in the training dataset, and to protect the sensitive information of users in the training dataset, a ticking deep differential privacy protection method was proposed based on DCGAN. The noise data was added the differential privacy theory when optimizing the in-depth network parameters in this method. Then the privacy budget of each layer of the deep network was calculated in a stochastic gradient descent (SGD), which based on the combination of differential privacy and Gaussian distribution, Gaussian noise was added to minimize the total privacy budget in the stochastic gradient descent calculation. And then the optimal result that the attacker may obtain was generated by using DCGAN. Finally, in order to achieve balance between data availability and privacy protection, the difference among the attack result and the original data was used to adjust the deep differential privacy model. The results show that this method has high privacy protection ability for sensitive information in training dataset. © 2018, Editorial Department of Journal of Beijing University of Technology. All right reserved.","Deep convolutional generative adversarial networks (DCGAN); Deep learning; Differential privacy; Image generation; Training dataset protection",,,,,,"Zhou, F.Y., Jin, L.P., Dong, J., Review of convolutional neural network Chinese (2017) Journal of Computers, 40 (7), pp. 1-23. , 周飞燕, 金林鹏, 董军. 卷积神经网络研究综述[J]. 计算机学报, 2017, 40(7): 1-23. (in Chinese); Jin, L.W., Zhong, Z.Y., Yang, Z., Applications of deep learning for handwritten Chinese character recognition: a review (2016) Acta Automatica Sinica, 42 (8), pp. 1125-1141. , 金连文, 钟卓耀, 杨钊, 等. 深度学习在手写汉字识别中的应用综述[J]. 自动化学报, 2016, 42(8): 1125-1141. (in Chinese); Pierangela, S., Protecting respondents' identities in microdata release (2001) IEEE Transactions on Knowledge and Data Engineering, 13 (6), pp. 1010-1027; Ashwin, W., Daniel, K., Johannes, G., L-diversity: privacy beyond k-anonymity (2007) IEEE Transactions on Knowledge Discovery and Data Mining, 1 (1), pp. 1-5; Justin, B., Vitaly, S., The cost of privacy: destruction of data-mining utility in anonymized data publishing (2008) ACM SIGKDD International Conference on Knowledge Discovery and Data Mining., pp. 70-78. , New York: ACM; Reza, S., Vitaly, S., Privacy-preserving deep learning (2015) ACM SIGSAC Conference on Computer and Communications Security., pp. 1310-1321. , New York: ACM; Matt, F., Somesh, J., Thomas, R., Model inversion attacks that exploit confidence information and basic countermeasures (2015) ACM SIGSAC Conference on Computer and Communications Security., pp. 1322-1333. , New York: ACM; Ian, J.G., Jean, P., Mehdi, M., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, (3), pp. 2672-2680; Nhat, H.P., Wang, Y., Wu, X.T., Differential privacy preservation for deep auto-encoders: an application of human behavior prediction (2016) Thirtieth AAAI Conference on Artificial Intelligence., pp. 1309-1316. , Palo Alto: AAAI Press; Nicolas, P., Martín, A., Úifar, E., Semi-supervised knowledge transfer for deep learning from private training data (2016), arXiv Preprint arXiv: 1610.05755; Zhang, X.J., Meng, X.F., Differential privacy in data publication and analysis (2014) Journal of Computers, 37 (4), pp. 927-949. , 张啸剑, 孟小峰. 面向数据发布和分析的差分隐私保护[J]. 计算机学报, 2014, 37(4): 927-949. (in Chinese); Xiong, P., Zhu, T.Q., Wang, X.F., A survey on differential privacy and applications (2014) Journal of Computers, 37 (1), pp. 101-122. , 熊平, 朱天清, 王晓峰. 差分隐私保护及其应用[J]. 计算机学报, 2014, 37(1): 101-122. (in Chinese); Ilya, M., Renyi differential privacy (2017), arXiv Preprint arXiv: 1702.07476; Cynthia, D., Aaron, R., The algorithmic foundations of differential privacy (2014) Foundations and Trends in Theoretical Computer Science, 9 (3-4), pp. 211-407; Jürgen, S., Deep learning in neural networks: an overview (2015) Neural Networks, (61), pp. 85-117; Zhang, X.J., Meng, X.F., Streaming histogram publication method with differential privacy (2016) Journal of Software, 27 (2), pp. 381-393. , 张啸剑, 孟小峰. 基于差分隐私的流式直方图发布方法[J]. 软件学报, 2016, 27(2): 381-393. (in Chinese); Martín, A., Andy, C., Ian, J.G., Deep learning with differential privacy (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security., pp. 308-318. , New York: ACM; Zhou, S.G., Li, F., Tao, Y.F., Privacy preservation in database applications: a survey (2009) Journal of Computers, 32 (5), pp. 847-861. , 周水庚, 李丰, 陶宇飞, 等. 面向数据库应用的隐私保护研究综述[J]. 计算机学报, 2009, 32(5): 847-861. (in Cninese); Alec, R., Luke, M., Soummith, C., Unsupervised representation learning with deep convolutional generative adversarial networks (2015) Computer Science, (4), pp. 1-16; Yann, L.C., Courant Institute NYU, MNIST datasets[DB/OL] http://yann.lecun.com/exdb/mnist/, [1998-11-01]; Papernot, N., Mcdaniel, P., Sinha, A., Towards the science of security and privacy in machine learning (2016), arXiv Preprint arXiv: 1611.03814",,,,"Beijing University of Technology",,,,,02540037,,BGDXD,,"Chinese","Beijing Gongye Daxue Xuebao J. Beijing Univ. Technol.",Article,"Final","",Scopus,2-s2.0-85056296318
"Zhang Y., Dong Y., Liu C., Lei K., Sun H.","56027290000;56388997800;57195492134;57191882718;57203889719;","Situation, Trends and Prospects of Deep Learning Applied to Cyberspace Security [深度学习应用于网络空间安全的现状,趋势与展望]",2018,"Jisuanji Yanjiu yu Fazhan/Computer Research and Development","55","6",,"1117","1142",,19,"10.7544/issn1000-1239.2018.20170649","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053400566&doi=10.7544%2fissn1000-1239.2018.20170649&partnerID=40&md5=bc42676824d63f756fa315c8827cee04","National Computer Network Intrusion Protection Center, University of Chinese Academy of Sciences, Beijing, 101408, China; School of Cyber Engineering, Xidian University, Xi'an, 710071, China","Zhang, Y., National Computer Network Intrusion Protection Center, University of Chinese Academy of Sciences, Beijing, 101408, China, School of Cyber Engineering, Xidian University, Xi'an, 710071, China; Dong, Y., National Computer Network Intrusion Protection Center, University of Chinese Academy of Sciences, Beijing, 101408, China; Liu, C., National Computer Network Intrusion Protection Center, University of Chinese Academy of Sciences, Beijing, 101408, China; Lei, K., National Computer Network Intrusion Protection Center, University of Chinese Academy of Sciences, Beijing, 101408, China, School of Cyber Engineering, Xidian University, Xi'an, 710071, China; Sun, H., National Computer Network Intrusion Protection Center, University of Chinese Academy of Sciences, Beijing, 101408, China, School of Cyber Engineering, Xidian University, Xi'an, 710071, China","Recently, research on deep learning applied to cyberspace security has caused increasing academic concern, and this survey analyzes the current research situation and trends of deep learning applied to cyberspace security in terms of classification algorithms, feature extraction and learning performance. Currently deep learning is mainly applied to malware detection and intrusion detection, and this survey reveals the existing problems of these applications: feature selection, which could be achieved by extracting features from raw data; self-adaptability, achieved by early-exit strategy to update the model in real time; interpretability, achieved by influence functions to obtain the correspondence between features and classification labels. Then, top 10 obstacles and opportunities in deep learning research are summarized. Based on this, top 10 obstacles and opportunities of deep learning applied to cyberspace security are at first proposed, which falls into three categories. The first category is intrinsic vulnerabilities of deep learning to adversarial attacks and privacy-theft attacks. The second category is sequence-model related problems, including program syntax analysis, program code generation and long-term dependences in sequence modeling. The third category is learning performance problems, including poor interpretability and traceability, poor self-adaptability and self-learning ability, false positives and data unbalance. Main obstacles and their opportunities among the top 10 are analyzed, and we also point out that applications using classification models are vulnerable to adversarial attacks and the most effective solution is adversarial training; collaborative deep learning applications are vulnerable to privacy-theft attacks, and prospective defense is teacher-student model. Finally, future research trends of deep learning applied to cyberspace security are introduced. © 2018, Science Press. All right reserved.","Application security; Attacks and defenses; Cyberspace security; Deep learning; Network security","Classification (of information); Computers; Crime; Data mining; Feature extraction; Intrusion detection; Malware; Network security; Personnel training; Surveys; Syntactics; Teaching; Application security; Attacks and defenses; Classification algorithm; Classification labels; Current research situation; Cyberspaces; Program-code generation; Self-learning ability; Deep learning",,,,,"Lecun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), pp. 436-444; Goodfellow, I., Bengio, Y., Courville, A., (2016) Deep Learning, pp. 528-566. , Cambridge, MA: MIT Press; Deng, L., Yu, D., Deep learning: Methods and applications (2014) Foundations and Trends in Signal Processing, 7 (3-4), pp. 197-387; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Communications of the ACM, 60 (2), pp. 2012-2025; Taigman, Y., Yang, M., Ranzato, M.A., Deepface: Closing the gap to human-level performance in face verification (2014) Proc of the 29th IEEE Conf on Computer Vision and Pattern Recognition, pp. 1701-1708. , Piscataway, NJ: IEEE; Dahl, G.E., Deng, L., Yu, D., Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition (2012) IEEE Trans on Audio, Speech, and Language Processing, 20 (1), pp. 30-42; Sainath, T.N., Vinyals, O., Senior, A., Convolutional, long short-term memory, fully connected deep neural networks (2015) Proc of the 39th IEEE Int Conf on Acoustics, Speech and Signal, pp. 4580-4584. , Piscataway, NJ: IEEE; Sak, H., Senior, A., Beaufays, F., Long short-term memory based recurrent neural network architectures for large vocabulary speech recognition (2014) Computer Science, 9 (3), pp. 338-342; Collobert, R., Weston, J., A unified architecture for natural language processing: Deep neural networks with multitask learning (2008) Proc of the 25th Int Conf on Machine Learning, pp. 160-167. , New York: ACM; Cruz-Roa, A., Ovalle, J.E.A., Madabhushi, A., A deep learning architecture for image representation, visual interpretability and automated basal-cell carcinoma cancer detection (2013) Proc of the 9th Int Conf on Medical Image Computing and Computer-Assisted Intervention, pp. 403-410. , Berlin: Springer; Huang, W., Stokes, J.W., MtNet: A multi-task neural network for dynamic malware classification (2016) Proc of the 5th Int Conf on Detection of Intrusions and Malware, and Vulnerability Assessment, pp. 399-418. , Berlin: Springer; Lecun, Y., Jackel, L.D., Boser, B., Handwritten digit recognition: Applications of neural network chips and automatic learning (1989) IEEE Communications Magazine, 27 (11), pp. 41-46; Rumelhart, D.E., Hinton, G.E., Williams, R.J., Learning representations by back-propagating errors (1988) Cognitive Modeling, 5 (3), pp. 533-536; Hinton, G.E., Osindero, S., Teh, Y.W., A fast learning algorithm for deep belief nets (2006) Neural Computation, 18 (7), pp. 1527-1554; Hinton, G.E., Mcclelland, J.L., Learning representations by recirculation (1987) Proc of the 1st Int Conf on Neural Information Systems, pp. 358-366. , Cambridge, MA: MIT Press; Papernot, N., Mcdaniel, P., Sinha, A., Towards the science of security and privacy in machine learning (2016), https://arxiv.org/pdf/1611.03814.pdf, [2017-07-12]; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Proc of the 30th IEEE Conf on Computer Vision and Pattern Recognition, pp. 427-436. , Piscataway, NJ: IEEE; Bolukbasi, T., Wang, J., Dekel, O., Adaptive neural networks for efficient inference (2017) Proc of the 34th Int Conf on Machine Learning, pp. 527-536. , New York: ACM; Koh, P.W., Liang, P., Understanding black-box predictions via influence functions (2017), https://arxiv.org/pdf/1703.04730.pdf, [2017-08-11]; Srivastava, N., Hinton, G.E., Krizhevsky, A., Dropout: A simple way to prevent neural networks from overfitting (2014) Journal of Machine Learning Research, 15 (1), pp. 1929-1958; Deep learning and convolutional neural networks: RSIP vision blogs (2016), http://www.rsipvision.com/exploring-deep-learning/, [2017-08-18]RSIP; Deng, L., Three classes of deep learning architectures and their applications: A tutorial survey (2012) APSIPA Trans on Signal and Information Processing, 11 (2), pp. 1132-1160; Lecun, Y., Bottou, L., Bengio, Y., Gradient-based learning applied to document recognition (1998) Proceedings of the IEEE, 86 (11), pp. 2278-2324; Szegedy, C., Liu, W., Jia, Y., Going deeper with convolutions (2015) Proc of the 30th IEEE Conf on Computer Vision and Pattern Recognition, pp. 37-46. , Piscataway, NJ: IEEE; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2014), https://arxiv.org/pdf/1409.1556.pdf, [2017-08-02]; He, K., Zhang, X., Ren, S., Deep residual learning for image recognition (2016) Proc of the 31st IEEE Conf on Computer Vision and Pattern Recognition, pp. 770-778. , Piscataway, NJ: IEEE; Eigen, D., Rolfe, J., Fergus, R., Understanding deep architectures using a recursive convolutional network (2014) Computer Science, 10 (2), pp. 38-55; Masci, J., Meier, U., Cireşan, D., Stacked convolutional autoencoders for hierarchical feature extraction (2011) Proc of the 20th Int Conf on Artificial Neural Networks, pp. 52-59. , Berlin: Springer; Krizhevsky, A., Hinton, G., Convolutional deep belief networks on cifar-10 (2010) Unpublished Manuscript, 7 (6), pp. 1007-1020; Cho, K., Van Merriёnboer, B., Gulcehre, C., Learning phrase representations using RNN encoder-decoder for statistical machine translation (2014) Computer Science, 10 (2), pp. 187-205; Sutskever, I., Vinyals, O., Le, Q.V., Sequence to sequence learning with neural networks (2014) IEEE Trans on Signal Processing, 4 (2), pp. 3104-3112; Bahdanau, D., Cho, K., Bengio, Y., Neural machine translation by jointly learning to align and translate (2014) Computer Science, 7 (2), pp. 109-136; Schuster, M., Paliwal, K.K., Bidirectional recurrent neural networks (1997) IEEE Trans on Signal Processing, 45 (11), pp. 2673-2681; Graves, A., (2012) Supervised Sequence Labelling with Recurrent Neural Networks, pp. 4-38. , Berlin: Springer; Graves, A., Liwicki, M., Bunke, H., Unconstrained on-line handwriting recognition with recurrent neural networks (2007) Proc of the 29th Conf on Neural Information Processing Systems, pp. 458-464. , Piscataway, NJ: IEEE; Graves, A., Schmidhuber, J., Offline handwriting recognition with multidimensional recurrent neural networks (2008) Proc of the 30th Int Conf on Neural Information Processing Systems, pp. 545-552. , Piscataway, NJ: IEEE; Graves, A., Schmidhuber, J., Framewise phoneme classification with bidirectional LSTM and other neural network architectures (2005) Neural Networks, 18 (5), pp. 602-610; Graves, A., Generating sequences with recurrent neural networks (2013) Computer Science, 10 (3), pp. 30-45; Baldi, P., Brunak, S., Frasconi, P., Exploiting the past and the future in protein secondary structure prediction (1999) Bioinformatics, 15 (11), pp. 937-946; Gers, F.A., Schmidhuber, J., Cummins, F., Learning to forget: Continual prediction with LSTM (2000) Neural Computation, 12 (10). , 2451-247; Cho, K., Van Merriёnboer, B., Bahdanau, D., On the properties of neural machine translation: Encoder-decoder approaches (2014) Computer Science, 7 (2), pp. 103-111; Chung, J., Gulcehre, C., Cho, K.H., Empirical evaluation of gated recurrent neural networks on sequence modeling (2014), https://arxiv.org/pdf/1412.3555, [2017-08-11]; Chung, J., Gulcehre, C., Cho, K., Gated feedback recurrent neural networks (2015) Proc of the 32nd Int Conf on Machine Learning, pp. 2067-2075. , New York: ACM; Jozefowicz, R., Zaremba, W., Sutskever, I., An empirical exploration of recurrent network architectures (2015) Proc of the 32nd Int Conf on Machine Learning, pp. 2342-2350. , New York: ACM; Chrupa Ła, G., Kádár, A., Alishahi, A., Learning language through pictures (2015) Computer Science, 8 (2), pp. 76-90; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9 (8), pp. 1735-1780; Graves, A., Jaitly, N., Towards end-to-end speech recognition with recurrent neural networks (2014) Proc of the 31st Int Conf on Machine Learning, pp. 1764-1772. , New York: ACM; Kiros, R., Salakhutdinov, R., Zemel, R.S., Unifying visual-semantic embeddings with multimodal neural language models (2014) Computer Science, 10 (3), pp. 137-152; Vinyals, O., Toshev, A., Bengio, S., Show and tell: A neural image caption generator (2015) Proc of the 30th IEEE Conf on Computer Vision and Pattern Recognition, pp. 3156-3164. , Piscataway, NJ: IEEE; Xu, K., Ba, J., Kiros, R., Show, attend and tell: Neural image caption generation with visual attention (2015) Prof of the 32nd Int Conf on Machine Learning, pp. 2048-2057. , New York: ACM; Vinyals, O., Kaiser, Ł., Koo, T., Grammar as a foreign language (2015) Proc of the 28th Conf on Advances in Neural Information Processing Systems, pp. 2773-2781. , Cambridge, MA: MIT Press; Pascanu, R., Gulcehre, C., Cho, K., How to construct deep recurrent neural networks (2013) Computer Science, 6 (5), pp. 90-109; Salakhutdinov, R., Mnih, A., Hinton, G., Restricted Boltzmann machines for collaborative filtering (2007) Proc of the 24th Int Conf on Machine Learning, pp. 791-798. , New York: ACM; Salakhutdinov, R., Hinton, G., Deep Boltzmann machines (2009) Journal of Machine Learning Research, 5 (2), pp. 196-2006; Rozanov, Y.A., (1982) Markov Random Fields, pp. 55-102. , Berlin: Springer; Elfwing, S., Uchibe, E., Doya, K., Expected energy-based restricted Boltzmann machine for classification (2015) Neural Networks, 64 (2), pp. 29-38; Mnih, V., Larochelle, H., Hinton, G.E., Conditional restricted Boltzmann machines for structured output prediction (2011) Proc of the 27th Conf on Uncertainty in Artificial Intelligence, pp. 514-522. , Berlin: Springer; Taylor, G.W., Hinton, G.E., Roweis, S.T., Two distributed-state models for generating high-dimensional time series (2011) Journal of Machine Learning Research, 12 (3), pp. 1025-1068; Hinton, G., A practical guide to training restricted Boltzmann machines (2010) Momentum, 9 (1), pp. 926-937; Tang, Y., Salakhutdinov, R., Hinton, G., Robust Boltzmann machines for recognition and denoising (2012) Proc of the 27th Computer Vision and Pattern Recognition, pp. 2264-2271. , Piscataway, NJ: IEEE; Li, G., Deng, L., Xu, Y., Temperature based restricted Bzoltzmann machines (2016) Scientific Reports, 6 (2), pp. 191-210; Nair, V., Hinton, G.E., 3D object recognition with deep belief nets (2009) Proc of the 22nd Conf on Advances in Neural Information Processing Systems, pp. 1339-1347. , Cambridge, MA: MIT Press; Indiveri, G., Liu, S., Memory and information processing in neuromorphic systems (2015) Proceedings of the IEEE, 103 (8), pp. 1379-1397; Liao, B., Xu, J., Lü, J., An image retrieval method for binary images based on DBN and softmax classifier (2015) IETE Technical Review, 32 (4), pp. 294-303; Abdel-Zaher, A.M., Eldeib, A.M., Breast cancer classification using deep belief networks (2016) Expert Systems with Applications, 46 (2), pp. 139-144; Deng, L., Yu, D., Deep convex net: A scalable architecture for speech pattern classification (2011) Proc of the 12th Conf of the Int Speech Communication Association, pp. 2285-2288. , Florence, Italy: ISCA; Hinton, G.E., Salakhutdinov, R.R., Using deep belief nets to learn covariance kernels for Gaussian processes (2008) Proc of the 1st Conf on Advances in Neural Information Processing Systems, pp. 1249-1256. , Cambridge, MA: MIT Press; Arel, I., Rose, D.C., Karnowski, T.P., Deep machine learning-a new frontier in artificial intelligence research (2010) IEEE Computational Intelligence Magazine, 5 (4), pp. 13-18; Bengio, Y., Learning deep architectures for AI (2009) Foundations and Trends in Machine Learning, 2 (1), pp. 1-127; Alain, G., Bengio, Y., What regularized autoencoders learn from the data-generating distribution (2014) The Journal of Machine Learning Research, 15 (1), pp. 3563-3593; Hinton, G.E., Salakhutdinov, R.R., Reducing the dimensionality of data with neural networks (2006) Science, 313 (5786), pp. 504-507; Schmidhuber, J., Deep learning in neural networks: An overview (2015) Neural Networks, 61 (9), pp. 85-117; Makhzani, A., Frey, B., K-sparse autoencoders (2013), https://arxiv.org/pdf/1312.5663, [2017-06-14]; Vincent, P., A connection between score matching and denoising autoencoders (2011) Neural Computation, 23 (7), pp. 1661-1674; Vincent, P., Larochelle, H., Bengio, Y., Extracting and composing robust features with denoising autoencoders (2008) Proc of the 25th Int Conf on Machine Learning, pp. 1096-1103. , New York: ACM; Ling, Z., Kang, S., Zen, H., Deep learning for acoustic modeling in parametric speech generation: A systematic review of existing techniques and future trends (2015) IEEE Signal Processing Magazine, 32 (3), pp. 35-52; Kamyshanska, H., Memisevic, R., The potential energy of an autoencoder (2015) IEEE Trans on Pattern Analysis and Machine Intelligence, 37 (6), pp. 1261-1273; Bengio, Y., Courville, A., Vincent, P., Representation learning: A review and new perspectives (2013) IEEE Trans on Pattern Analysis and Machine Intelligence, 35 (8), pp. 1798-1828; Vincent, P., Larochelle, H., Lajoie, I., Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion (2010) Journal of Machine Learning Research, 11 (12), pp. 3371-3408; Rifai, S., Vincent, P., Muller, X., Contractive autoencoders: Explicit invariance during feature extraction (2011) Proc of the 28th Int Conf on Machine Learning, pp. 833-840. , New York: ACM; Rifai, S., Mesnil, G., Vincent, P., Higher order contractive autoencoder (2011) Proc of the 24th European Conf on Machine Learning and Knowledge Discovery in Databases, pp. 645-660. , Berlin: Springer; Sun, M., Zhang, X., Zheng, T.F., Unseen noise estimation using separable deep auto encoder for speech enhancement (2016) IEEE/ACM Trans on Audio, Speech, and Language Processing, 24 (1), pp. 93-104; Staudemeyer, R.C., Applying long short-term memory recurrent neural networks to intrusion detection (2015) South African Computer Journal, 56 (1), pp. 136-154; Dahl, G.E., Stokes, J.W., Deng, L., Large-scale malware classification using random projections and neural networks (2013) Proc of the 38th Int Conf on Acoustics, Speech and Signal Processing, pp. 3422-3426. , Piscataway, NJ: IEEE; Kolosnjaji, B., Zarras, A., Webster, G., Deep learning for classification of malware system call sequences (2016) Proc of the 30th Australasian Joint Conf on Artificial Intelligence, pp. 137-149. , Berlin: Springer; Tobiyama, S., Yamaguchi, Y., Shimada, H., Malware detection with deep neural network using process behavior (2016) Proc of the 8th Int Conf on Computer Software and Applications, pp. 577-582. , Piscataway, NJ: IEEE; Pascanu, R., Stokes, J.W., Sanossian, H., Malware classification with recurrent networks (2015) Proc of the 40th Int Conf on Acoustics, Speech and Signal Processing, pp. 1916-1920. , Piscataway, NJ: IEEE; Athiwaratkun, B., Stokes, J.W., Malware classification with LSTM and GRU language models and a character-level CNN (2017) Proc of the 42nd Int Conf on Acoustics, Speech and Signal Processing, pp. 2482-2486. , Piscataway, NJ: IEEE; Wang, X., Yiu, S.M., A multi-task learning model for malware classification with useful file access pattern from API call sequence (2016), https://arxiv.org/pdf/1610.05945, [2017-08-17]; Hardy, W., Chen, L., Hou, S., DL4MD: A deep learning framework for intelligent malware detection (2016) Proc of the 16th Int Conf on Data Mining, pp. 61-68. , Piscataway, NJ: IEEE; Rhode, M., Burnap, P., Jones, K., Early stage malware prediction using recurrent neural networks (2017), https://arxiv.org/pdf/1708.03513, [2017-06-14]; Nix, R., Zhang, J., Classification of Android apps and malware using deep neural networks (2017) Proc of the 17th Int Joint Conf on Neural Networks, pp. 1871-1878. , Piscataway, NJ: IEEE; Saxe, J., Berlin, K., Deep neural network-based malware detection using two-dimensional binary program features (2015) Proc of the 10th Int Conf on Malicious and Unwanted Software, pp. 11-20. , Piscataway, NJ: IEEE; Shin, E.C.R., Song, D., Moazzezi, R., Recognizing functions in binaries with neural networks (2015) Proc of the 24th USENIX Security Symp, pp. 611-626. , Berkely, CA: USENIX Association; Yuan, Z., Lu, Y., Wang, Z., Droid-Sec: Deep learning in Android malware detection (2014) ACM SIGCOMM Computer Communication Review, 44 (4), pp. 371-372; Yuan, Z., Lu, Y., Xue, Y., DroidDetector: Android malware characterization and detection using deep learning (2016) Tsinghua Science and Technology, 21 (1), pp. 114-123; Xu, L., Zhang, D., Jayasena, N., HADM: Hybrid analysis for detection of malware (2016) Proc of the 3rd SAI Intelligent Systems Conf, pp. 702-724. , Berlin: Springer; Jung, W., Kim, S., Choi, S., Poster: Deep learning for zero-day flash malware detection (2015) Proc of the 36th IEEE Symp on Security and Privacy, pp. 32-34. , Piscataway, NJ: IEEE; Li, P., Hastie, T.J., Church, K.W., Very sparse random projections (2006) Proc of the 12th ACM SIGKDD Int Conf on Knowledge Discovery and Data Mining, pp. 287-296. , New York: ACM; David, O.E., Netanyahu, N.S., Deepsign: Deep learning for automatic malware signature generation and classification (2015) Proc of the 12th Int Joint Conf on Neural Networks, pp. 76-84. , Piscataway, NJ: IEEE; Debar, H., Becker, M., Siboni, D., A neural network component for an intrusion detection system (1992) Proc of the 23rd Computer Society Symp on Research in Security and Privacy, pp. 240-250. , Piscataway, NJ: IEEE; Creech, G., Hu, J., A semantic approach to host-based intrusion detection systems using contiguous and discontiguous system call patterns (2014) IEEE Trans on Computers, 63 (4), pp. 807-819; Fiore, U., Palmieri, F., Castiglione, A., Network anomaly detection with the restricted Boltzmann machine (2013) Neurocomputing, 122 (3), pp. 13-23; KDD Cup 99 (1999), http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html, University of California [2017-08-18]; Tavallaee, M., Bagheri, E., Lu, W., A detailed analysis of the KDD CUP 99 data set (2009) Proc of the 2nd IEEE Symp on Computational Intelligence for Security and Defense Applications, pp. 1-6. , Piscataway, NJ: IEEE; NSL-KDD dataset (2017), http://www.unb.ca/cic/research/datasets/nsl.html, Canadian Institute for Cybersecurity.[2017-08-18]; Kim, J., Kim, J., Thu, H.L.T., Long short-term memory recurrent neural network classifier for intrusion detection (2016) Proc of the 22nd Int Conf on Platform Technology and Service, pp. 49-54. , Piscataway, NJ: IEEE; Putchala, M.K., Deep learning approach for intrusion detection system (IDS) in the Internet of things (IoT) network using gated recurrent neural networks (GRU) (2017), Dayton, Ohio, USA: Wright State University; Gao, N., Gao, L., Gao, Q., An intrusion detection model based on deep belief networks (2014) Proc of the 12th Int Conf on Advanced Cloud and Big Data, pp. 247-252. , Piscataway, NJ: IEEE; Li, Y., Ma, R., Jiao, R., A hybrid malicious code detection method based on deep learning (2015) International Journal of Software Engineering & Its Applications, 9 (5), pp. 205-216; Salama, M.A., Eid, H.F., Ramadan, R.A., Hybrid intelligent intrusion detection scheme (2011) Soft Computing in Industrial Applications, pp. 293-303. , Berlin: Springer; Niyaz, Q., Javaid, A., Sun, W., A deep learning approach for network intrusion detection system (2016) Proc of the 9th EAI Int Conf on Bio-inspired Information and Communications Technologies, pp. 21-26. , New York: ACM; Abolhasanzadeh, B., Nonlinear dimensionality reduction for intrusion detection using autoencoder bottleneck features (2015) Proc of the 7th Conf on Information and Knowledge Technology, pp. 26-31. , Piscataway, NJ: IEEE; Alom, M.Z., Bontupalli, V.R., Taha, T.M., Intrusion detection using deep belief networks (2015) Proc of the 9th Conf on Aerospace and Electronics, pp. 339-344. , Piscataway, NJ: IEEE; Aygun, R.C., Yavuz, A.G., Network anomaly detection with stochastically improved autoencoder based models (2017) Proc of the 4th Int Conf on Cyber Security and Cloud Computing, pp. 193-198. , Piscataway, NJ: IEEE; Wang, Z., The applications of deep learning on traffic identification (2015), https://www.blackhat.com/docs/us-15/materials/us-15-Wang-The-Applications-Of-Deep-Learning-On-Traffic-Identification-wp.pdf, [2017-07-15]; Yu, Y., Long, J., Cai, Z., Network intrusion detection through stacking dilated convolutional autoencoders (2017) Security and Communication Networks, 2 (3), pp. 212-225; Wang, W., Zhu, M., Zeng, X., Malware traffic classification using convolutional neural network for representation learning (2017) Proc of the 1st Int Conf on Information Networking, pp. 712-717. , Piscataway, NJ: IEEE; Kim, G., Yi, H., Lee, J., LSTM-based system-call language modeling and robust ensemble method for designing host-based intrusion detection systems (2016), https://arxiv.org/pdf/1611.01726, [2017-08-02]; Yu, Y., Long, J., Cai, Z., Session-based network intrusion detection using a deep learning architecture (2017) Proc of the 14th Conf on Modeling Decisions for Artificial Intelligence, pp. 144-155. , Berlin: Springer; Zaheer, M., Tristan, J.B., Wick, M.L., Learning a static analyzer: A case study on a toy language (2016), https://openreview.net/references/pdf?id=ry54RWtxx, [2017-08-17]; Godefroid, P., Peleg, H., Singh, R., Learn& fuzz: Machine learning for input fuzzing (2017), https://arxiv.org/pdf/1701.07232, [2017-08-17]; Melicher, W., Ur, B., Segreti, S.M., Fast, lean, and accurate: Modeling password guessability using neural networks (2016) Proc of the 25th USENIX Security Symp, pp. 175-191. , Berkely, CA: USENIX Association; Hu, W., Tan, Y., Generating adversarial malware examples for black-box attacks based on GAN (2017), https://arxiv.org/pdf/1702.05983, [2017-06-14]; Hu, W., Tan, Y., Black-box attacks against RNN based malware detection algorithms (2017), https://arxiv.org/pdf/1705.08131, [2017-08-02]; Rosenberg, I., Shabtai, A., Rokach, L., Generic black-box end-to-end attack against RNNs and other API calls based malware classifiers (2017), https://arxiv.org/pdf/1707.05970, [2017-06-14]; Grosse, K., Papernot, N., Manoharan, P., Adversarial perturbations against deep neural networks for malware classification (2016), https://arxiv.org/pdf/1606.04435, [2017-08-19]; Wang, Q., Guo, W., Zhang, K., Adversary resistant deep neural networks with an application to malware detection (2017) Proc of the 23rd ACM SIGKDD Int Conf on Knowledge Discovery and Data Mining, pp. 1145-1153. , New York: ACM; Explainable artificial intelligence (XAI) (2016), https://www.darpa.mil/program/explainable-artificial-intelligence, DARPA. [2017-08-18]; Ribeiro, M.T., Singh, S., Guestrin, C., Why should I trust you? Explaining the predictions of any classifier (2016) Proc of the 22nd ACM SIGKDD Int Conf on Knowledge Discovery and Data Mining, pp. 1135-1144. , New York: ACM; Goodfellow, I.J., Vinyals, O., Saxe, A.M., Qualitatively characterizing neural network optimization problems (2014), https://arxiv.org/pdf/1412.6544, [2017-08-19]; Weston, J., Chopra, S., Bordes, A., Memory networks (2014), https://arxiv.org/pdf/1410.3916, [2017-07-15]; Kumar, A., Irsoy, O., Ondruska, P., Ask me anything: Dynamic memory networks for natural language processing (2016) Proc of the 33rd Int Conf on Machine Learning, pp. 1378-1387. , New York: ACM; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Generative adversarial nets (2014) Proc of the 27th Conf on Advances in Neural Information Processing Systems, pp. 2672-2680. , Cambridge, MA: MIT Press; Wang, K., Gou, C., Duan, Y., Generative adversarial networks: The state of the art and beyond (2017) Acta Automatica Sinca, 43 (3), pp. 321-332. , (in Chinese) (王坤峰, 苟超, 段艳杰, 等. 生成式对抗网络 GAN 的研究进展与展望[J]. 自动化学报, 2017, 43(3): 321-332); Mirza, M., Osindero, S., Conditional generative adversarial nets (2014), https://arxiv.org/pdf/1411.1784, [2017-08-02]; Odena, A., Semi-supervised learning with generative adversarial networks (2016), https://arxiv.org/pdf/1606.01583, [2017-07-15]; Donahue, J., Krähenbühl, P., Darrell, T., Adversarial feature learning (2016), https://arxiv.org/pdf/1605.09782, [2017-08-19]; Chen, X., Duan, Y., Houthooft, R., InfoGAN: Interpretable representation learning by information maximizing generative adversarial nets (2016) Proc of the 29th Conf on Advances in Neural Information Processing Systems, pp. 2172-2180. , Cambridge, MA: MIT Press; Odena, A., Olah, C., Shlens, J., Conditional image synthesis with auxiliary classifier GANs (2016), https://arxiv.org/pdf/1610.09585, [2017-08-13]; Yu, L., Zhang, W., Wang, J., SeqGAN: Sequence generative adversarial nets with policy gradient (2017) Proc of the 31st Conf on Artificial Intelligence, pp. 2852-2858. , Menlo Park, CA: AAAI; Radford, A., Metz, L., Chintala, S., Unsupervised representation learning with deep convolutional generative adversarial networks (2015), https://arxiv.org/pdf/1511.06434, [2017-07-16]; Denton, E.L., Chintala, S., Fergus, R., Deep generative image models using a Laplacian pyramid of adversarial networks (2015) Proc of the 28th Conf on Advances in Neural Information Processing Systems, , Cambridge, MA: MIT Press; Larsen, A.B.L., S∅nderby, S.K., Larochelle, H., Autoencoding beyond pixels using a learned similarity metric (2015), https://arxiv.org/pdf/1512.09300, [2017-07-16]; Im, D.J., Kim, C.D., Jiang, H., Generating images with recurrent adversarial networks (2016), https://arxiv.org/pdf/1602.05110, [2017-08-13]; Arjovsky, M., Chintala, S., Bottou, L., Wasserstein GAN (2017), https://arxiv.org/pdf/1701.07875, [2017-07-25]; Salimans, T., Goodfellow, I., Zaremba, W., Improved techniques for training GANs (2016) Proc of the 29th Conf on Advances in Neural Information Processing Systems, pp. 2234-2242. , Cambridge, MA: MIT Press; Goodfellow, I., NIPS 2016 tutorial: Generative adversarial networks (2016), https://arxiv.org/pdf/1701.00160, [2017-07-24]; Non-targeted adversarial attack (2017), https://www.kaggle.com/nips-2017-adversarial-learning-competition, [2017-07-24].NIPS; Pascanu, R., Mikolov, T., Bengio, Y., On the difficulty of training recurrent neural networks (2013) Proc of the 30th Int Conf on Machine Learning, pp. 1310-1318. , New York: ACM; Andreas, J., Rohrbach, M., Darrell, T., Neural module networks (2016) Proc of the 31st IEEE Conf on Computer Vision and Pattern Recognition, pp. 39-48. , Piscataway, NJ: IEEE; Mcdaniel, P., Papernot, N., Celik, Z.B., Machine learning in adversarial settings (2016) IEEE Security & Privacy, 14 (3), pp. 68-72; Huang, L., Joseph, A.D., Nelson, B., Adversarial machine learning (2011) Proc of the 4th ACM Workshop on Security and Artificial Intelligence, pp. 43-58. , New York: ACM; Biggio, B., Corona, I., Maiorca, D., Evasion attacks against machine learning at test time (2013) Proc of the 23rd Joint European Conf on Machine Learning and Knowledge Discovery in Databases, pp. 387-402. , Berlin: Springer; Biggio, B., Fumera, G., Roli, F., Pattern recognition systems under attack: Design issues and research challenges (2014) International Journal of Pattern Recognition and Artificial Intelligence, 28 (7), pp. 146-158; Szegedy, C., Zaremba, W., Sutskever, I., Intriguing properties of neural networks (2013), https://arxiv.org/pdf/1312.6199, [2017-08-02]; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2014), https://arxiv.org/pdf/1412.6572, [2017-07-27]; Warde-Farley, D., Goodfellow, I., Hazan, T., (2016) Perturbations, Optimization, and Statistics, pp. 1-32. , Cambridge, MA: MIT Press; Cireşan, D., Meier, U., Masci, J., Multi-column deep neural network for traffic sign classification (2012) Neural Networks, 32, pp. 333-338; Papernot, N., Mcdaniel, P., Jha, S., The limitations of deep learning in adversarial settings (2016) Proc of the 1st European Symp on Security and Privacy, pp. 372-387. , Piscataway, NJ: IEEE; Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proc of the 31st IEEE Conf on Computer Vision and Pattern Recognition, pp. 2574-2582. , Piscataway, NJ: IEEE; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2016), https://arxiv.org/pdf/1607.02533, [2017-07-27]; Papernot, N., Mcdaniel, P., Goodfellow, I., Practical black-box attacks against machine learning (2017) Proc of the 12th ACM Asia Conf on Computer and Communications Security, pp. 506-519. , New York: ACM; Papernot, N., Mcdaniel, P., Goodfellow, I., Transferability in machine learning: From phenomena to black-box attacks using adversarial samples (2016), https://arxiv.org/pdf/1605.07277, [2017-07-19]; Tramèr, F., Papernot, N., Goodfellow, I., The space of transferable adversarial examples (2017), https://arxiv.org/pdf/1704.03453, [2017-07-19]; Moosavi-Dezfooli, S.M., Fawzi, A., Fawzi, O., Universal adversarial perturbations (2017) Proc of the 32nd IEEE Conf on Computer Vision and Pattern Recognition, pp. 893-901. , Piscataway, NJ: IEEE; Russakovsky, O., Deng, J., Su, H., ImageNet large scale visual recognition challenge (2015) International Journal of Computer Vision, 115 (3), pp. 211-252; Liu, Y., Chen, X., Liu, C., Delving into transferable adversarial examples and black-box attacks (2016), https://arxiv.org/pdf/1611.02770, [2017-08-02]; Papernot, N., Mcdaniel, P., Swami, A., Crafting adversarial input sequences for recurrent neural networks (2016) Proc of the 35th Military Communications Conf, pp. 49-54. , Piscataway, NJ: IEEE; Papernot, N., Mcdaniel, P., Wu, X., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Proc of the 37th IEEE Symp on Security and Privacy, pp. 582-597. , Piscataway, NJ: IEEE; Hinton, G., Vinyals, O., Dean, J., Distilling the knowledge in a neural network (2015), https://arxiv.org/pdf/1503.02531, [2017-08-14]; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Proc of the 38th IEEE Symp on Security and Privacy, pp. 39-57. , Piscataway, NJ: IEEE; Carlini, N., Wagner, D., Defensive distillation is not robust to adversarial examples (2016), https://arxiv.org/pdf/1607.04311, [2017-08-09]; Hosseini, H., Chen, Y., Kannan, S., Blocking transferability of adversarial examples in black-box learning systems (2017), https://arxiv.org/pdf/1703.04318, [2017-08-09]; Papernot, N., Mcdaniel, P., Extending defensive distillation (2017), https://arxiv.org/pdf/1705.05264, [2017-08-09]; Brendel, W., Bethge, M., Comment on ""biologically inspired protection of deep networks from adversarial attacks"" (2017), https://arxiv.org/pdf/1704.01547, [2017-08-09]; Wang, Q., Guo, W., Zhang, K., Learning adversary-resistant deep neural networks (2016), https://arxiv.org/pdf/1612.01401, [2017-08-16]; Wang, Q., Guo, W., Ororbia, I.I., Using non-invertible data transformations to build adversary-resistant deep neural networks (2016), https://arxiv.org/pdf/1610.01934, [2017-08-16]; Gu, S., Rigazio, L., Towards deep neural network architectures robust to adversarial examples (2014), https://arxiv.org/pdf/1412.5068, [2017-08-16]; Ororbia, I.I., Alexander, G., Giles, C.L., Unifying adversarial training algorithms with flexible deep data gradient regularization (2016), https://arxiv.org/pdf/1601.07213, [2017-06-06]; Lyu, C., Huang, K., Liang, H., A unified gradient regularization family for adversarial examples (2015) Proc of the 15th Int Conf on Data Mining, pp. 301-309. , Piscataway, NJ: IEEE; Zhao, Q., Griffin, L.D., Suppressing the unusual: Towards robust cnns using symmetric activation functions (2016), https://arxiv.org/pdf/1603.05145, [2017-08-14]; Rozsa, A., Gunther, M., Boult, T.E., Towards robust deep neural networks with BANG (2016), https://arxiv.org/pdf/1612.00138, [2017-06-06]; Miyato, T., Maeda, S., Koyama, M., Distributional smoothing with virtual adversarial training (2015), https://arxiv.org/pdf/1507.00677, [2017-06-06]; Tramèr, F., Kurakin, A., Papernot, N., Ensemble adversarial training: Attacks and defenses (2017), https://arxiv.org/pdf/1705.07204, [2017-06-04]; Na, T., Ko, J.H., Mukhopadhyay, S., Cascade adversarial machine learning regularized with a unified embedding (2017), https://arxiv.org/pdf/1708.02582, [2017-06-04]; Shaham, U., Yamada, Y., Negahban, S., Understanding adversarial training: Increasing local stability of neural nets through robust optimization (2015), https://arxiv.org/pdf/1511.05432, [2017-09-14]; Huang, R., Xu, B., Schuurmans, D., Learning with a strong adversary (2015), https://arxiv.org/pdf/1511.03034, [2017-09-17]; N∅kland, A., Improving back-propagation by adding an adversarial gradient (2015), https://arxiv.org/pdf/1510.04189, [2017-09-12]; Demyanov, S., Bailey, J., Kotagiri, R., Invariant backpropagation: How to train a transformation-invariant neural network (2015), https://arxiv.org/pdf/1502.04434, [2017-08-02]; Grosse, K., Manoharan, P., Papernot, N., On the (statistical) detection of adversarial examples (2017), https://arxiv.org/pdf/1702.06280, [2017-09-12]; Metzen, J.H., Genewein, T., Fischer, V., On detecting adversarial perturbations (2017), https://arxiv.org/pdf/1702.04267, [2017-09-12]; Lu, J., Issaranon, T., Forsyth, D., SafetyNet: Detecting and rejecting adversarial examples robustly (2017), https://arxiv.org/pdf/1704.00103, [2017-08-02]; The wireX botnet: How industry collaboration disrupted a DDoS attack (2017), https://blog.cloudflare.com/the-wirex-botnet/, [2017-09-02]Cloudflare; Fredrikson, M., Jha, S., Ristenpart, T., Model inversion attacks that exploit confidence information and basic countermeasures (2015) Proc of the 22nd ACM SIGSAC Conf on Computer and Communications Security, pp. 1322-1333. , New York: ACM; Shen, S., Tople, S., Saxena, P., Auror: Defending against poisoning attacks in collaborative deep learning systems (2016) Proc of the 32nd Annual Conf on Computer Security Applications, pp. 508-519. , New York: ACM; Hitaj, B., Ateniese, G., Perez-Cruz, F., Deep models under the GAN: Information leakage from collaborative deep learning (2017), https://arxiv.org/pdf/1702.07464, [2017-09-01]; Dwork, C., Roth, A., The algorithmic foundations of differential privacy (2014) Foundations and Trends in Theoretical Computer Science, 9 (3-4), pp. 211-407; Dwork, C., Differential privacy: A survey of results (2008) Proc of the 5th Int Conf on Theory and Applications of Models of Computation, pp. 42-61. , Berlin: Springer; Dwork, C., Mcsherry, F., Nissim, K., Calibrating noise to sensitivity in private data analysis (2016) Journal of Privacy and Confidentiality, 7 (3), pp. 265-284; Zhu, T., Li, G., Zhou, W., Differentially private data publishing and analysis: A survey (2017) IEEE Trans on Knowledge and Data Engineering, 29 (8), pp. 1619-1638; Xie, P., Bilenko, M., Finley, T., Crypto-nets: Neural networks over encrypted data (2014), https://arxiv.org/pdf/1412.6181, 2017-09-01]; Rivest, R.L., Adleman, L., Dertouzos, M.L., On data banks and privacy homomorphisms (1978) Foundations of Secure Computation, 4 (11), pp. 169-180; Ohrimenko, O., Schuster, F., Fournet, C., Oblivious multi-party machine learning on trusted processors (2016) Proc of the 25th USENIX Security Symp, pp. 619-636. , Berkely, CA: USENIX Association; Shokri, R., Shmatikov, V., Privacy-preserving deep learning (2015) Proc of the 22nd ACM SIGSAC Conf on Computer and Communications Security, pp. 1310-1321. , New York: ACM; Abadi, M., Chu, A., Goodfellow, I., Deep learning with differential privacy (2016) Proc of the 23rd ACM SIGSAC Conf on Computer and Communications Security, pp. 308-318. , New York: ACM; Papernot, N., Abadi, M., Erlingsson, Ú., Semi-supervised knowledge transfer for deep learning from private training data (2016), https://arxiv.org/pdf/1610.05755, [2017-08-02]; Hamm, J., Cao, P., Belkin, M., Learning privately from multi-party data (2016) Proc of the 33rd Int Conf on Machine Learning, pp. 555-563. , New York: ACM",,,,"Science Press",,,,,10001239,,JYYFE,,"Chinese","Jisuanji Yanjiu yu Fazhan",Article,"Final","",Scopus,2-s2.0-85053400566
"Yanagita Y., Yamamura M.","57202608258;55812193300;","Gradient masking is a type of overfitting",2018,"International Journal of Machine Learning and Computing","8","3",,"203","207",,1,"10.18178/ijmlc.2018.8.3.688","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048899587&doi=10.18178%2fijmlc.2018.8.3.688&partnerID=40&md5=705843d595ac0ec48426f573f3c3e6a0","Department of Computer Science, School of Computer, Tokyo Institute of Technology, Yokohama, 226-8503, Japan","Yanagita, Y., Department of Computer Science, School of Computer, Tokyo Institute of Technology, Yokohama, 226-8503, Japan; Yamamura, M., Department of Computer Science, School of Computer, Tokyo Institute of Technology, Yokohama, 226-8503, Japan","Neural networks have recently been attracting attention again as classifiers with high accuracy, so called ""deep learning,"" which is applied in a wide variety of fields. However, this advanced machine learning algorithms are vulnerable to adversarial perturbations. Although they cannot be recognized by humans, these perturbations deliver a fatal blow to the estimation ability of classifiers. Thus, while humans perceive perturbed examples as being the same as the original natural examples, sophisticated classifiers identify them as completely different examples. Although several defensive measures against such adversarial examples have been suggested, they are known to fail in undesirable phenomena, gradient masking. Gradient masking can neutralize the useful gradient for adversaries, but adversarial perturbations tend to transfer across most models, and these models can be deceived by adversarial examples crafted based on other models, which is called a black-box attack. Therefore, it is necessary to develop training methods to withstand black-box attacks and conduct studies to investigate the weak points of current NN training. This paper argues that no special defensive measures are necessary for NN to fall into gradient masking, and it is sufficient to slightly change the initial learning rate of Adam from the recommended value. Moreover, our experiment implies that gradient masking is a type of overfitting. © 2018, International Association of Computer Science and Information Technology.","Adam; Adversarial examples; Gradient masking; Machine learning; Neural network",,,,,,"Hinton, G.E., Osindero, S., Teh, Y.-W., 'A fast learning algorithm for deep belief nets,' (2006) Neural Comput, 18 (7), pp. 1527-1554; Yann, L., Yoshua, B., Geoffrey, H., 'Deep learning,' (2015) Nature, 521 (7553), pp. 436-444; Szegedy, C., 'Intriguing properties of neural networks, ' Proc. ICLR; Ian, G., Jonathon, J.S., Christian, S., 'Exampling and harnessing adversarial examples, ' (2015) Proc. ICLR; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossar, P., 'DeepFool: A simple and accurate method to fool deep neural networks, ' (2016) in IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Papernot, N., Mcdaniel, P., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., 'The limitations of deep learning in adversarial settings, ' (2016) Proc. the 1st IEEE European Symposium on Security and Privacy; Carlini, N., Wagner, D., 'Towards Evaluating the Robustness of Neural Networks, ' (2017) Proc. IEEE Symposium on Security and Privacy; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., 'Universal adversarial perturbations, ' (2017) Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Papernot, N., Mcdaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., 'Practical black-box attacks against machine learning, ' (2017) Proc. ACM Asia Conference on Computer and Communications Security; Papernot, N., Mcdaniel, P., Goodfellow, I., 'Transferability in machine learning: From phenomena to black-box attacks using adversarial samples, ' (2016), arXiv preprint; Tramèr, F., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., 'The space of transferable adversarial examples, "" arXiv preprint arXiv: 1704.03453, 2017. N. Papernot, P. McDaniel, X. Wu, S. Jha, and A. Swami, ""Distillation as a defense to adversarial perturbations against deep neural networks, ' (2016) Proc. 2016 IEEE Symposium on Security and Privacy, pp. 582-597; Papernot, N., McDaniel, P., 'Extending defensive distillation, ' (2017), arXiv preprint; Jimmy Ba, L., Caruana, R., 'Do deep nets really need to be deep?' (2014) Adv. Neural Inf. Process. Syst; Sengupta, S., Chakraborti, T., Kambhampati, S., (2017) 'Securing deep neural nets against adversarial attacks with moving target defense, ', , arXiv preprint; Kingma, D.P., Ba, J.L., 'Adam: A method for stocastic optimization, ' (2015) Proc. ICLR; Polyak, B.T., 'Some methods of speeding up the convergence of iteration methods,' (1964) Comput. Math. Math. Phys, 4 (5), pp. 1-17; Duchi, J., Edu, J.B., Hazan, E., Singer, Y., 'Adaptive subgradient methods for online learning and stochastic optimization*, ' (2011) J. Mach. Learn. Res, 12, pp. 2121-2159; Tieleman, T., Hinton, G., 'Lecture 6.5-RMSProp, COURSERA: Neural networks for machine learning, ' (2012) Tech. Rep",,,,"International Association of Computer Science and Information Technology",,,,,20103700,,,,"English","Int. J. Mach. Learn. Comput.",Article,"Final","All Open Access, Bronze, Green",Scopus,2-s2.0-85048899587
"Chan P.P.K., He Z.-M., Li H., Hsu C.-C.","7403497727;57194773200;56981822400;7404947474;","Data sanitization against adversarial label contamination based on data complexity",2018,"International Journal of Machine Learning and Cybernetics","9","6",,"1039","1052",,11,"10.1007/s13042-016-0629-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047265787&doi=10.1007%2fs13042-016-0629-5&partnerID=40&md5=6d7f3af9deb7ed4d4c7ddd1a00ca4c31","School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; School of Electronic and Information Engineering, Foshan University, Foshan, 528000, China; Computer Science and Information Engineering, Fu Jen Catholic University, New Taipei City, Taiwan","Chan, P.P.K., School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; He, Z.-M., School of Electronic and Information Engineering, Foshan University, Foshan, 528000, China; Li, H., School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; Hsu, C.-C., Computer Science and Information Engineering, Fu Jen Catholic University, New Taipei City, Taiwan","Machine learning techniques may suffer from adversarial attack in which an attacker misleads a learning process by manipulating training samples. Data sanitization is one of countermeasures against poisoning attack. It is a data pre-processing method which filters suspect samples before learning. Recently, a number of data sanitization methods are devised for label flip attack, but their flexibility is limited due to specific assumptions. It is observed that abrupt label flip caused by attack changes complexity of classification. A data sanitization method based on data complexity, which is a measure of the difficulty of classification on a dataset, is proposed in this paper. Our method measures the data complexity of a training set after removing a sample and its nearest samples. Contaminated samples are then distinguished from untainted samples according to their data complexity values. Experimental results support the idea that data complexity can be used to identify attack samples. The proposed method achieves a better result than the current sanitization method in terms of detection accuracy for well known security application problems. © 2017, Springer-Verlag Berlin Heidelberg.","Adversarial learning; Data complexity; Data sanitization; Poisoning attack","Classification (of information); Learning systems; Adversarial learning; Data complexity; Data preprocessing; Detection accuracy; Machine learning techniques; Poisoning attacks; Sanitization; Security application; Data handling",,,,,"Alfeld, S., Zhu, X., Barford, P., Data poisoning attacks against autoregressive models (2016) Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, AAAI’16, pp. 1452-1458; Amos, B., Turner, H., White, J., Applying machine learning classifiers to dynamic android malware detection at scale (2013) Wireless Communications and Mobile Computing Conference (IWCMC), IEEE, pp. 1666-1671; Barreno, M., Nelson, B., Sears, R., Joseph, A.D., Tygar, J.D., Can machine learning be secure? (2006) Proceedings of the 2006 ACM Symposium on Information, Computer and Communications Security, pp. 16-25. , ACM; Barreno, M., Nelson, B., Joseph, A.D., Tygar, J., The security of machine learning (2010) Mach Learn, 81 (2), pp. 121-148; Bernadó-Mansilla, E., Ho, T.K., Domain of competence of xcs classifier system in complexity measurement space (2005) IEEE Trans Evol Comput, 9 (1), pp. 82-104; Biggio, B., Fumera, G., Roli, F., Multiple classifier systems for robust classifier design in adversarial environments (2010) Int J Mach Learn Cybernet, 1 (1-4), pp. 27-41; Biggio, B., Corona, I., Fumera, G., Giacinto, G., Roli, F., Bagging classifiers for fighting poisoning attacks in adversarial classification tasks (2011) Multiple Classifier Systems, pp. 350-359. , Springer, Berlin; Biggio, B., Fumera, G., Roli, F., Design of robust classifiers for adversarial environments (2011) IEEE International Conference on Systems, Man, and Cybernetics (SMC), IEEE, pp. 977-982; Biggio, B., Nelson, B., Laskov, P., (2011) Support Vector Machines under Adversarial Label Noise, pp. 97-112. , ACML; Biggio, B., Nelson, B., Laskov, P., Poisoning attacks against support vector machines (2012) 29Th Intl Conf. on Machine Learning (ICML), pp. 1807-1814; Biggio, B., Fumera, G., Roli, F., Security evaluation of pattern classifiers under attack (2014) IEEE Trans Knowl Data Eng, 26 (4), pp. 984-996; Brückner, M., Kanzow, C., Scheffer, T., Static prediction games for adversarial learning problems (2012) J Mach Learn Res, 13 (1), pp. 2617-2654; Chan, P.P.K., Yang, C., Yeung, D.S., Ng, W.W.Y., Spam filtering for short messages in adversarial environment (2015) Neurocomputing, 155 (C), pp. 167-176; Corona, I., Giacinto, G., Roli, F., Adversarial attacks against intrusion detection systems: taxonomy, solutions and open issues (2013) Inf Sci, 239, pp. 201-225; Cretu, G.F., Stavrou, A., Locasto, M.E., Stolfo, S.J., Keromytis, A.D., Casting out demons: Sanitizing training data for anomaly sensors (2008) IEEE Symposium on Security and Privacy, IEEE, pp. 81-95; Dalvi, N., Domingos, P., Sanghai, S., Verma, D., Adversarial classification (2004) Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ACM, pp. 99-108; Fefilatyev, S., Shreve, M., Kramer, K., Hall, L., Goldgof, D., Kasturi, R., Daly, K., Bunke, H., Label-noise reduction with support vector machines (2012) 21St International Conference on Pattern Recognition (ICPR), pp. 3504-3508. , IEEE; Georgala, K., Kosmopoulos, A., Paliouras, G., Spam filtering: An active learning approach using incremental clustering (2014) Proceedings of the 4Th International Conference on Web Intelligence, Mining and Semantics (WIMS14), pp. 1-12. , ACM; Globerson, A., Roweis, S., Nightmare at test time: Robust learning by feature deletion (2006) Proceedings of the 23Rd International Conference on Machine Learning, pp. 353-360. , ACM; He, Z.M., Chan, P.P.K., Yeung, D.S., Pedrycz, W., Ng, W.W.Y., Quantification of side-channel information leaks based on data complexity measures for web browsing (2015) Int J Mach Learn Cybernet, 6 (4), pp. 607-619; Ho, T.K., Basu, M., Complexity measures of supervised classification problems (2002) IEEE Trans Pattern Anal Mach Intell, 24 (3), pp. 289-300; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I., Tygar, J., Adversarial machine learning (2011) Proceedings of the 4Th ACM Workshop on Security and Artificial Intelligence, pp. 43-58. , ACM; Jorgensen, Z., Zhou, Y., Inge, M., A multiple instance learning strategy for combating good word attacks on spam filters (2008) J Mach Learn Res, 9, pp. 1115-1146; Kong, J.S., Rezaei, B., Sarshar, N., Roychowdhury, V.P., Collaborative spam filtering using e-mail networks (2006) Computer, 39 (8), pp. 67-73; Lee, H., Ng, A.Y., Spam deobfuscation using a hidden markov model (2005) In: CEAS; Li, B., Wang, Y., Singh, A., Vorobeychik, Y., Data poisoning attacks on factorization-based collaborative filtering (2016) Advances in Neural Information Processing Systems, pp. 1885-1893; Lichman, M., (2013) UCI Machine Learning Repository, , http://archive.ics.uci.edu/ml; Lowd, D., Meek, C., Adversarial learning (2005) Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining, ACM, pp. 641-647; Luengo, J., Herrera, F., Shared domains of competence of approximate learning models using measures of separability of classes (2012) Inf Sci, 185 (1), pp. 43-65; Michie, D., Spiegelhalter, D.J., Taylor, C.C., Campbell, J., (1994) Machine Learning, Neural and Statistical Classification, , Ellis Horwood, Upper Saddle River; Nelson, B., Barreno, M., Chi, F.J., Joseph, A.D., Rubinstein, B.I., Saini, U., Sutton, C.A., Xia, K., Exploiting machine learning to subvert your spam filter (2008) LEET, 8, pp. 1-9; Nelson, B., Barreno, M., Chi, F.J., Joseph, A.D., Rubinstein, B.I., Saini, U., Sutton, C., Xia, K., Misleading learners: Co-opting your spam filter (2009) Machine Learning in Cyber Trust, pp. 17-51. , Springer, Berlin; Rubinstein, B.I., Nelson, B., Huang, L., Joseph, A.D., Sh, L., Rao, S., Taft, N., Tygar, J., Antidote: Understanding and defending against poisoning of anomaly detectors (2009) Proceedings of the 9Th ACM SIGCOMM Conference on Internet Measurement Conference, ACM, pp. 1-14; SáEz, J.A., Luengo, J., Herrera, F., Predicting noise filtering efficacy with data complexity measures for nearest neighbor classification (2013) Pattern Recognit, 46 (1), pp. 355-364; Sahs, J., Khan, L., A machine learning approach to android malware detection (2012) Intelligence and Security Informatics Conference (EISIC), IEEE, pp. 141-147; Saini, U., (2008) Machine learning in the presence of an adversary: Attacking and defending the spambayes spam filter, , Tech. rep, DTIC Document; Satpute, K., Agrawal, S., Agrawal, J., Sharma, S., A survey on anomaly detection in network intrusion detection system using particle swarm optimization based machine learning techniques (2013) Proceedings of the International Conference on Frontiers of Intelligent Computing: Theory and Applications (FICTA), pp. 441-452; Servedio, R.A., Smooth boosting and learning with malicious noise (2003) J Mach Learn Res, 4, pp. 633-648; Singh, S., Multiresolution estimates of classification complexity (2003) IEEE Trans Pattern Anal Mach Intell, 12, pp. 1534-1539; Smith, F.W., Pattern classifier design by linear programming (1968) IEEE Trans Comput, 100 (4), pp. 367-372; Suthaharan, S., Big data classification: problems and challenges in network intrusion prediction with machine learning (2014) ACM SIGMETRICS Perform Eval Rev, 41 (4), pp. 70-73; Wittel, G.L., Wu, S.F., On attacking statistical spam filters (2004) Conference on Email and Anti-Spam; Xiao, H., Xiao, H., Eckert, C., Adversarial label flips attack on support vector machines (2012) ECAI, pp. 870-875; Xiao, H., Biggio, B., Brown, G., Fumera, G., Eckert, C., Roli, F., Is feature selection secure against training data poisoning? (2015) Proceedings of the 32Nd International Conference on Machine Learning (ICML’15), pp. 1689-1698; Xiao, H., Biggio, B., Nelson, B., Xiao, H., Eckert, C., Roli, F., Support vector machines under adversarial label contamination (2015) Neurocomputing, 160, pp. 53-62; Zhang, F., Chan, P., Biggio, B., Yeung, D., Roli, F., Adversarial feature selection against evasion attacks (2016) IEEE Trans Cybernet, 46, pp. 766-777; Zhou, B., Yao, Y., Luo, J., Cost-sensitive three-way email spam filtering (2014) J Intell Inf Syst, 42 (1), pp. 19-45","He, Z.-M.; School of Electronic and Information Engineering, China; email: zhmihe@gmail.com",,,"Springer Verlag",,,,,18688071,,,,"English","Intl. J. Mach. Learn. Cybern.",Article,"Final","",Scopus,2-s2.0-85047265787
"Kusyk J., Uyar M.U., Sahin C.S.","12767640900;7006444505;24282108800;","Survey on evolutionary computation methods for cybersecurity of mobile ad hoc networks",2018,"Evolutionary Intelligence","10","3-4",,"95","117",,15,"10.1007/s12065-018-0154-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047151349&doi=10.1007%2fs12065-018-0154-4&partnerID=40&md5=d084a22a2164a773fa3b2b6f322faef5","NYC College of Technology, City University of New York, Brooklyn, NY  11201, United States; City College of New York, City University of New York, New York, NY  10031, United States; MIT Lincoln Laboratory, Lexington, MA  02420, United States","Kusyk, J., NYC College of Technology, City University of New York, Brooklyn, NY  11201, United States; Uyar, M.U., City College of New York, City University of New York, New York, NY  10031, United States; Sahin, C.S., MIT Lincoln Laboratory, Lexington, MA  02420, United States","In this paper, a comprehensive survey of evolutionary computation (EC) methods for cybersecurity of mobile ad hoc networks (MANETs) is presented. Typically, EC methods are named based on the natural processes inspiring them, such as swarm intelligence (e.g., ant colony optimization, artificial bee colony, and particle swarm optimization), evolutionary algorithms (e.g., genetic algorithms, genetic programming, grammatical evolution, and differential evolution), artificial immune systems, and evolutionary games analyzing strategic interactions among different population types. We introduce these methods with their typical applications, and commonly used algorithms to improve cybersecurity within the scope of MANETs. Ongoing and speedy topology changes, multi-hop communication, non-hierarchical organization, and power and computational limitations are among the intrinsic characteristics of MANETs causing cybersecurity vulnerabilities. We describe basic defense mechanisms in MANETs for vulnerability detection, attack deterrence, prevention and recovery, and risk mitigation. We classify principal applications of EC as intrusion detection, trust management, and cryptography in cybersecurity systems to counter measure adversarial activities. © 2018, Springer-Verlag GmbH Germany, part of Springer Nature.","Ant colony optimization; Artificial bee colony; Artificial immune systems; Artificial intelligence; Cybersecurity; Differential evolution; Evolutionary games; Genetic algorithms; Genetic programming; Grammatical evolution; MANETs; Particle swarm optimization; Swarm intelligence","Ant colony optimization; Artificial intelligence; Computational grammars; Genetic algorithms; Genetic programming; Immune system; Intrusion detection; Particle swarm optimization (PSO); Surveys; Swarm intelligence; Artificial bee colonies; Artificial Immune System; Cyber security; Differential Evolution; Evolutionary games; Grammatical evolution; MANETs; Mobile ad hoc networks",,,,,"(2016), https://cdn2.hubspot.net/hubfs/533449/SecurityScorecard_2016_Govt_Cybersecurity_Report.pdf, Accessed 14 Mar 2018; (1999), https://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html, Accessed 14 Mar 2018; (2013), https://cs.gmu.edu/~eclab/projects/ecj/, Accessed 14 Mar 2018; (2015), https://www.defense.gov/Portals/1/features/2015/0415_cyber-strategy/Final_2015_DoD_CYBER_STRATEGY_for_web.pdf, Accessed 14 Mar 2018; Abass, A., Hajimirsadeghi, M., Mandayam, N., Gajic, Z., Evolutionary game theoretic analysis of distributed denial of service attacks in a wireless network (2016) Annual Conf. on Information Science and Systems (CISS), pp. 36-41; Aljarah, I., Ludwig, A., Mapreduce intrusion detection system based on a particle swarm optimization clustering algorithm (2013) IEEE Congr. on Evolutionary Computation (CEC), 2013 IEEE Congress On. IEEE, pp. 955-962; Arenella, G., de Santis, F., Malandrino, D., BeeAdHocServiceDiscovery: A MANET service discovery algorithm based on bee colonies (2014) In: 11Th Int’l. Conf. on Informatics in Control, Automation and Robotics (ICINCO), pp. 1-6; Arora, S., Singhb, P., Gupta, A., Adaptive selection of cryptographic protocols in wireless sensor networks using evolutionary game theory (2015) In: Int’l. Conf. on Information Security and Privacy (ICISP’15), 78, pp. 358-366. , Procedia Computer Science; Bäck, T., Selective pressure in evolutionary algorithms: A characterization of selection mechanisms (1994) IEEE World Congr. on Computational Intelligence, Proc. of the 1St IEEE Conf. on Evolutionary Computation, pp. 9-16; Bagga, E., Adhikary, E., A review on various protocols and security issues in MANET (2014) Int J Adv Res Comput Commun Eng, 3, pp. 7478-7482; Baker, J., Reducing bias and inefficiency in the selection algorithm (1987) Proc. of the 2Nd Int’l. Conf. on Genetic Algorithms on Genetic Algorithms and Their Application, , J.J. Grefenstette, Lawrence Erlbaum Associates, Publishers; Ball, M., Qela, B., Wesolkowski, S., A review of the use of computational intelligence in the design of military surveillance networks (2015) Recent Advances in Computational Intelligence in Defense and Security, pp. 663-693. , Springer; Barani, K., A hybrid approach for dynamic intrusion detection in ad hoc networks using genetic algorithm and artificial immune system (2014) Iranian Conf. on Intelligent Systems (ICIS). IEEE, pp. 1-6; Barani, K., Abadi, M., BeeID: intrusion detection in AODV-based MANETs using artificial bee colony and negative selection algorithms (2012) Int J Inf Secur ISC, 4 (1), pp. 25-39; Barolli, L., Koyama, A., Shiratori, N., A QoS routing method for ad-hoc networks based on genetic algorithm Proc. of the 14Th Int. Work. on Database and Expert Systems Applications (DEXA), pp. 175-179; Beni, G., Wang, J., Swarm intelligence (1989) In: Proc. of Seventh Annual Meeting of the Robotics Society of Japan, pp. 425-428. , RSJ Press; Bouhaddi, M., Adi, K., Radjef, M., Evolutionary game-based defense mechanism in the MANETs (2016) In: Proc. of the 9Th Int’l. Conf. on Security of Information and Networks (SIN’16), pp. 88-95; Brameier, M., Banzhaf, W., A comparison of linear genetic programming and neural networks in medical data mining (2001) IEEE Trans Evolut Comput, 5 (1), pp. 17-26; Brameier, M., Banzhaf, W., Linear genetic programming (2007) Springer Science & Business Media; Bretscher, P., Cohn, M., A theory of self-nonself discrimination (1970) Science, 169, pp. 1042-1049; Camazine, S., Deneubourg, S., Franks, J., Sneyd, J., Theraulaz, G., Bonabeau, E., (2001) Selforganization in biological systems, , Princeton University Press, Princeton; de Campos, L., de Oliveiraa, R., Roisenbergb, M., Optimization of neural networks through grammatical evolution and a genetic algorithm (2016) Exp Syst Appl, 46, pp. 368-384; Caro, G.D., Dorigo, M., AntNet: distributed stigmergetic control for communication networks (1998) J Artif Intell Res, 9, pp. 317-365; Caro, G.D., Ducatelle, F., Gambardella, L., AntHocNet: an adaptive nature-inspired algorithm for routing in mobile ad hoc networks (2005) Emerg Telecomun Technol, 16, pp. 443-455; Castro, L.D., Timmis, J., Artificial immune systems: a novel paradigm to pattern recognition (2002) Artif Neural Netw Pattern Recognit, 1, pp. 67-84; Cho, J., Swami, A., Shen, I., A survey on trust management for mobile ad-hoc networks (2011) IEEE Commun Surveys Tutorials, 14, pp. 562-583; Crosbie, M., Spafford, E., Applying genetic programming to intrusion detection (1995) Working Notes for the AAAI Symposium on Genetic Programming, pp. 1-8. , MIT Press, MA; Şen, S., A survey of intrusion detection systems using evolutionary computation (2015) Bio-Inspired Computation in Telecommunications, pp. 73-94; Şen, S., Clark, J., A grammatical evolution approach to intrusion detection on mobile ad hoc networks (2009) Proc. of the 2Nd ACM Conf. on Wireless Network Security, pp. 95-102. , AMC; Şen, S., Clark, J., Tapiador, J., Power-aware intrusion detection in mobile ad hoc networks (2010) Ad Hoc Netw, 28, pp. 224-239; Cui, W., Brabazon, A., O’Neill, M., Evolving dynamic trade execution strategies using grammatical evolution (2011) Int J Financial Markets Deriv, 2 (1-2), pp. 4-31; Dal, D., Abraham, S., Abraham, A., Sanyal, S., Sanglikar, M., Evolution induced secondary immunity: An artificial immune system based intrusion detection system (2008) Computer Information Systems and Industrial Management Applications (CISIM'08), pp. 65-70; Dorigo, M., (1992) Optimization, learning and natural algorithms, , Ph.D. thesis, Politecnico di Milano, Italy; Dorigo, M., Socha, K., An introduction to ant colony optimization (2007) Handbook of Approximation Algorithms and Metaheuristics, pp. 26-31. , CRC Press, Boca Raton; Dorronsoro, B., Ruiz, P., Danoy, G., Pigne, Y., Bouvry, P., (2014) Evolutionary algorithms for mobile ad hoc networks, , John Wiley & Sons; Eidenbenz, S., Kumar, V., Zust, S., Equilibria in topology control games for ad hoc networks (2006) Mobile Netw Appl, 11 (2), pp. 143-159; Elsayed, S., Sarker, R., Slay, J., Evaluating the performance of a differential evolution algorithm in anomaly detection (2015) 2015 IEEE Congr. on Evolutionary Computation (CEC), pp. 2490-2497; Farmer, J., Packard, N., Perelson, A., The immune system, adaptation, and machine learning (1986) Physica, 22, pp. 187-204; Fidalcastro, A., Baburaj, E., An advanced grammatical evolution approach for intrusion detection on multicast routing in MANET (2014) In: 2014 Int’l. Conf. on Information Communication and Embedded Systems (ICICES); Fischer, S., Vöcking, B., Evolutionary game theory with applications to adaptive routing (2005) Euro. Conf. on Complex Systems (ECCS), pp. 1-6; Fudenberg, D., Tirole, J., (1991) Game theory, , The MIT Press, Cambridge. MA; Gairing, M., Monien, B., Tiemann, T., Selfish routing with incomplete information (2005) ACM Symp. on Parallel Algorithms and Architectures, pp. 203-212; Garnier, S., Gautrais, J., Theraulaz, G., The biological principles of swarm intelligence (2007) Swarm Intell, 1 (1), pp. 3-31; Greensmith, J., Aickelin, U., Cayzer, S., Introducing dendritic cells as a novel immune-inspired algorithm for anomaly detection (2005) Int’l. Conf. on Artificial Immune Systems (ICARIS), pp. 153-167; Gundry, S., Zou, J., Kusyk, J., Sahin, C., Uyar, M., Differential evolution based fault tolerant topology control in MANETs (2013) In: IEEE Military Communications Conf. (MILCOM); Güneş, M., Sorges, U., Bouazizi, I., ARA the ant-colony based routing algorithm for MANETs (2002) Int’l. Work. on Ad Hoc Networks (IWAHN), pp. 79-85; Harmer, P., Temple, M., An improved LFS engine for physical layer security augmentation in cognitive networks (2013) Int. Conf. on Computing, Networking and Communication, Cognitive Computing and Networking, pp. 719-723; Harmer, P., Williams, M., Temple, M., Using DE-optimized LFS processing to enhance 4G communication security (2011) Proc. of Int’l. Conf. on 20Th Computer Communicqtion and Networks (ICCCN); Harsanyi, J., Games with incomplete information played by ’Bayesian’ players, parts I, II and III (1967) Manag Sci, 14 (3), pp. 159-182; van Hoesel, S., An overview of Stackelberg pricing in networks (2008) Euro J Oper Res, 189 (3), pp. 1393-1402; Hofmeyr, S., Forrest, S., Architecture for an artificial immune system (2000) Evolut Comput, 8 (4), pp. 443-473; Holland, J., (1992) Adaptation in natural and artificial systems: an introductory analysis with applications to biology, control and artificial intelligence, , The MIT Press, Cambridge MA; Huang, J., Berry, R., Honig, M., Auction-based spectrum sharing (2006) Mob Netw Appl, 11 (3), pp. 405-418; Ibrahim, M., Alexander, B., Evolving decision-making functions in an autonomous robotic exploration strategy using grammatical evolution (2013) Int’l. Conf. on Intelligent Robots and Systems (IROS). IEEE, pp. 4340-4346; Indirani, G., Selvakumar, K., Handling cross-layer attacks using neighbors monitoring scheme and swarm intelligence in MANET (2013) Int J Comp Appl Technol Res, 2 (1), pp. 41-48; Ji, Z., Liu, K., Multi-stage pricing game for collusion-resistant dynamic spectrum allocation (2008) IEEE J Sel Areas Commun, 26 (1), pp. 182-191; Jiang, G., Shen, S., Hu, K., Huang, L., Li, H., Han, R., Evolutionary game-based secrecy rate adaptation in wireless sensor networks (2015) Int J Distrib Sens Netw, 11, p. 975454; Jiang, T., Baras, J., Ant-based adaptive trust evidence distribution in MANET (2004) 24Th Int’l. Conf. on Distributed Computing Systems Workshops; Jim, L., Gregory, M., A review of artificial immune system based security frameworks for MANET (2016) Int J Commun Netw Syst Sci, 9 (1), pp. 1-18; Johnson, D., Teredesai, A., Saltarelli, R., Genetic programming in wireless sensor networks (2005) European Conf. on Genetic Programming, 3447, pp. 96-107. , Springer; Kadri, B., Moussaoui, D., Feham, M., Agreensmith (2013) Int Netw Secur, 15 (1), pp. 2231-5268; Kamal, A., Warip, M., Elshaikh, M., Badlishah, R., Differential evolution (DE) algorithm to optimize Berkeley-MAC protocol for wireless sensor network (2016) J Theor Appl Inf Technol, 89 (2), pp. 314-319; Karaboga, D., (2005) An idea based on honey bee swarm for numerical optimization, , Technical report TR06, Erciyes University, Computer Engineering Department; Karaboga, D., Basturk, B., Artificial bee colony (ABC) optimization algorithm for solving constrained optimization problems (2007) Int. Fuzzy Systems Association World Congress. Springer, pp. 789-798; Karaboga, D., Okdem, S., Ozturk, C., Cluster based wireless sensor network routing using artificial bee colony algorithm (2015) Wirel Netw, 18 (7), pp. 847-860; Kavitha, K., Kumari, S., Phil, M., Particle swarm optimization for adaptive anomaly-based intrusion detection system using fuzzy controller (2013) Int J Comput Trends Technol (IJCTT), 4 (10), pp. 3536-3541; Kennedy, J., Eberhart, R., A new optimizer using particle swarm theory (1995) In: Proc. of the 6Th Int’l. Symp. on Micro Machine and Human Science, pp. 39-43; Kephart, J., A biologically inspired immune system for computers (1994) In: Artificial Life IV: Proc. of the 4Th Int. Work. on the Synthesis and Simulation of Living Systems, pp. 130-139; Khannous, A., Rghioui, A., Elouaai, F., Bouhorma, M., Securing manet using the integration of concepts from diverse immune theories (2016) J Theor Appl Inf Technol, 88 (1), pp. 35-50; Kim, I., de Weck, O., Variable chromosome length genetic algorithm for progressive refinement in topology optimization (2005) Struct Multidiscip Optim, 29, pp. 445-456; Kim, Y., Lee, M., Scheduling multi-channel and multi-timeslot in time constrained wireless sensor networks via simulated annealing and particle swarm optimization (2014) IEEE Commun Mag, 52, pp. 122-129; Komali, R., MacKenzie, A., Gilles, R., Effect of selfish node behavior on efficient topology design (2008) IEEE Trans Mob Comput, 7 (9), pp. 1057-1070; Komathy, K., Narayanasamy, P., Secure data forwarding against denial of service attack using trust based evolutionary game (2008) Vehicular Technology Conference (VTC), pp. 31-35; Koza, J., (1992) Genetic programming: on the programming of computers by means of natural selection, , The MIT Press, Cambridge, MA; Koza, J., Genetic programming as a means for programming computers by natural selection (1994) Stat Comput, 4, pp. 87-112; Kuila, P., Jana, P., A novel differential evolution based clustering algorithm for wireless sensor networks (2014) Appl Soft Comput, 25, pp. 414-425; Kumar, B., Sekhar, P., Papanna, N., Bhushan, B., A survey on MANET security challenges and routing (2013) Int J Comput Technol Appl, 4 (2), pp. 248-256; Kusyk, J., (2011) Game-theoretic and bio-inspired techniques for self-positioning autonomous mobile nodes, , Ph.D. thesis, CUNY, New York, NY; Kusyk, J., Sahin, C., Uyar, M., Urrea, E., Gundry, S., Self organization of nodes in mobile ad hoc networks using evolutionary games and genetic algorithms (2011) J Adv Res, 2, pp. 253-264; Kusyk, J., Urrea, E., Sahin, C., Uyar, M., Game theory and genetic algorithm based approach for self positioning of autonomous nodes (2012) Int J Ad Hoc Sens Wirel Netw, 16, pp. 93-118; Laskari, E., Meletiou, G., Vrahatis, M., Problems of cryptography as discrete optimization tasks (2004) Nonlinear Anal, 63, pp. 831-837; Lewontin, R.C., Evolution and the theory of games (1961) J Theor Biol, 1, pp. 382-403; Li, C., Antonsson, A., Variable length genomes for evolutionary algorithms (2000) Genetic Programming 1996: Proc. of the First Annual Conf, pp. 512-520. , MIT Press; Li, Y., Xu, H., Cao, Q., Li, Z., Shen, S., Evolutionary game-based trust strategy adjustment among nodes in wireless sensor networks (2015) Int J Distrib Sens Netw, 11 (2), pp. 1-12; Lim, Y., Cheng, P., Clark, J., Rohatgi, P., Policy evolution with grammatical evolution (2008) Lecture Notes Comput Sci Simul Evolut Learning, 5361, pp. 71-80; MacKenzie, A., DaSilva, L., Game theory for wireless engineers (2010) Synth Lect Commun, 1, pp. 1-86; Montana, D., Automatic tuning of communication protocols for vehicular ad hoc networks using metaheuristics (2010) Eng Appl Artif Intell, 23, pp. 795-805; Movahedi, Z., Hosseini, Z., Bayan, F., Pujolle, G., Trust-distortion resistant trust management frameworks on mobile ad hoc networks: a survey (2016) IEEE Commun Surveys Tutorials, 18, pp. 1287-1309; Mukkamala, S., Sung, A., Abraham, A., Modeling intrusion detection systems using linear genetic programming approach (2004) Int’l. Conf. on Industrial, Engineering and Other Applications of Applied Intelligent Systems. Springer, pp. 633-642; Nadeem, A., Howarth, M., A survey of MANET intrusion detection and prevention approaches for network layer attacks (2013) IEEE Commun Surveys Tutorials, 15, pp. 2027-2045; Nash, J., The bargaining problem (1950) Econometrica, 18, pp. 155-162; Nash, J., Equilibrium points in n-person games (1950) Proc Natl Acad Sci USA, 36, pp. 48-49; Nash, J., Non-cooperative games (1951) Ann Math, 54, pp. 286-295; von Neumann, J., Morgenstern, O., (1944) Theory of games and economic behavior, , Princeton University Press, Princeton NJ; O’Neill, M., Ryan, C., Grammatical evolution (2001) IEEE Trans Evolut Comput, 5, pp. 349-358; Pan, M., Liang, S., Xiong, H., Chen, J., Li, G., A novel bargaining based dynamic spectrum management scheme in reconfigurable systems (2006) In: Int. Conf. on Systems and Networks Communications (ICSNC'06), p. 54; Parham, P., (2009) The Immune System, , 3rd edn. Garland Science; Pathan, A., (2010) Security of self-organizing networks: MANET, WSN, WMN, VANET, , Auerbach Publications, Taylor & Francis Group; Qiu, Y., Chen, Z., Xu, L., Active defense model of wireless sensor networks based on evolutionary game theory (2010) 6Th Int’l. Conf. on Wireless Communications Networking and Mobile Computing (Wicom), pp. 1-4; Reina, D., Ruiz, P., Ciobanu, R., Toral, S., Dorronsoro, B., Dobre, C., A survey on the application of evolutionary algorithms for mobile multihop ad hoc network optimization problems (2016) Int J Distrib Sens Netw, 12, p. 2082496; Robinson, Y., Rajaram, M., Energy-aware multipath routing scheme based on particle swarm optimization in mobile ad hoc networks (2015) Sci World J, pp. 1-9; Ruan, N., Gao, L., Zhu, H., Jia, W., Li, X., Hu, Q., Toward optimal dos-resistant authentication in crowdsensing networks via evolutionary game (2016) IEEE 36Th Int. Conf. on Distributed Computing Systems (ICDCS), pp. 364-373; Ryan, C., O’Neill, M., (1998) Grammatical Evolution: A Steady State Approach, pp. 180-185. , Late Breaking Papers, Genetic Programming; Sahin, C., Urrea, E., Uyar, M., Conner, M., Bertoli, G., Pizzo, C., Design of genetic algorithms for topology control of unmanned vehicles (2010) Spec Issue Int J Appl Decis Sci (IJADS) Decis Support Syst Unmanned Vehicles, 3 (3), pp. 221-238; Sahin, C., Urrea, E., Uyar, M., Conner, M., Hokelek, I., Bertoli, G., Pizzo, C., Genetic algorithms for self-spreading nodes in MANETs (2008) Proc. of the 10Th Annual Conf. on Genetic and Evolutionary Computation (GECCO), pp. 1141-1142; Sahoo, D., Rai, S.C., Pradhan, S., Threshold cryptography & genetic algorithm based secure key exchange for mobile hosts (2009) IEEE Int’l. Advance Computing Conf. (IACC). IEEE, pp. 1297-1302; Sahoo, R., Singh, M., Sahoo, B., Majumder, K., Ray, S., Sarkar, S., A light weight trust based secure and energy efficient clustering in wireless sensor network: Honey bee mating intelligence approach (2013) First Int’l. Conf. on Computational Intelligence: Modeling Techniques and Applications (CIMTA), 10, pp. 515-523; Sarafijanovic, S., Boudec, J.L., An artificial immune system for misbehavior detection in mobile ad-hoc networks with virtual thymus, clustering, danger signal, and memory detectors (2004) Int’l. Conf. on Artificial Immune Systems (ICARIS), pp. 342-356; Sasikala, E., Nandhakumar, N., An intelligent technique to detect jamming attack in wireless sensor networks (WSNs) (2015) Int J Fuzzy Syst, 17, pp. 76-83; Seredynski, M., Bouvry, P., Evolutionary game theoretical analysis of reputation-based packet forwarding in civilian mobile ad hoc networks (2009) Parallel & Distributed Processing (IPDPS), IEEE Int, Symp, pp. 1-8; Shamshirband, S., Anuar, N., Kiah, L., Rohani, V., Patković, D., Misra, S., Kahan, A., Co-FAIS: Cooperative fuzzy artificial immune system for detecting intrusion in wireless sensor networks (2014) J Netw Comput Appl, 42, pp. 102-117; Shen, S., Jiang, C., Jiang, H., Guo, L., Cao, Q., Evolutionary game based dynamics of trust decision in WSNs (2013) Int’l. Conf. on Sensor Network Security Technology and Privacy Communication System, pp. 1-4; Sindhuja, K., Devi, S.P., A symmetric key encryption technique using genetic algorithm (2014) Int J Comput Sci Inf Technol (IJCSIT), 5, pp. 414-416; Smith, J., Price, G., The logic of animal conflict (1973) Nature, 246, pp. 15-18; Song, D., Heywood, M., Zincir-Heywood, A., A linear genetic programming approach to intrusion detection (2003) Genetic and Evolutionary Computation Conference (GECCO’03), pp. 2325-2336; Storn, R., (1996) On the usage of differential evolution for function optimization. In: Fuzzy information processing society, 1996, pp. 519-523. , NAFIPS., 1996 Biennial Conf. of the North American; Storn, R., Price, K., Differential evolution: a simple and efficient adaptive scheme for global optimization over continuous spaces (1995) J Global Optim, 23, pp. 341-359; Stützle, T., Hoos, H., MAX-MIN ant system (2000) Future Gener Comput Syst, 16, pp. 889-914; Tahta, U., Şen, S., Can, A., Gentrust: A genetic trust management model for peer-to-peer systems (2015) Appl Soft Comput, 34, pp. 693-704; Taylor, P., Jonker, L., Evolutionary stable strategies and game dynamics (1978) Math Biosci, 16, pp. 76-83; Troiano, L., Birtolo, C., Armenise, R., Searching optimal menu layouts by linear genetic programming (2016) J Ambient Intell Hum Comput, 7 (2), pp. 239-256; Urrea, E., Sahin, C., Hokelek, I., Uyar, M., Conner, M., Bertoli, G., Pizzo, C., Bio-inspired topology control for knowledge sharing mobile agents (2009) Ad Hoc Netw, 7 (4), pp. 677-689; Varshney, P., Bibhu, V., Sahoo, B., Gupta, A., Quantitative review of malicious node detection of mobile ad-hoc network (2014) Int J Comput Math Sci (IJCMS), 3, pp. 102-110; Victoire, T., Sakthivel, M., A refined differential evolution algorithm based fuzzy classifier for intrusion detection (2011) Euro J Sci Res, 65 (2), pp. 246-259; Visu, P., Janet, J., Kannan, E., Koteeswaran, S., Optimal energy management in wireless adhoc network using artificial bee colony based routing protocol (2012) Euro J Sci Res, 74 (2), pp. 301-307; Walters, R., Cyber attacks on US companies in 2016 (2016) The Heritage Foundation, 4289, pp. 1-5; Wang, B., Liu, K., Clancy, T., Evolutionary game framework for behavior dynamics in cooperative spectrum sensing (2008) IEEE Global Telecommunications Conference (GLOBECOM), pp. 1-5; Wang, X., Ding, L., Bi, D., Reputation-enabled self-modification for target sensing in wireless sensor networks (2010) IEEE Trans Instrum Meas, 59, pp. 171-179; Wang, X., Osagie, E., Thulasiraman, P., Thulasiram, R., HOPNET: A hybrid ant colony optimization routing algorithm for mobile ad hoc network (2009) Ad Hoc Netw, 7, p. 690705; Wang, X., Wu, Y., Ren, Y., Feng, R., Yu, N., Wan, J., An evolutionary game-based trust cooperative stimulation model for large scale MANETs (2013) Int J Distrib Sens Netw, 13, p. 245017; Watkins, A., Timmis, J., Boggess, L., Artificial immune recognition system (AIRS): an immune-inspired supervised learning algorithm (2004) Genet Program Evolv Mach, 5 (3), pp. 291-317; Wedde, H., Farooq, M., Pannenbaecker, T., Vogel, B., Mueller, C., Meth, J., Jeruschkat, R., Beeadhoc: An energy efficient routing algorithm for mobile ad hoc networks inspired by bee behavior (1995) 7Th Annual Conf. on Genetic and Evolutionary Computation (GECCO’05), pp. 153-160; Weibull, J., (1997) Evolutionary game theory, , The MIT Press, Cambridge MA; Weise, T., Genetic programming for sensor networks (2006) Technical Report, , University of Kassel, Germany; Wu, Y., Zhao, Y., Riguidel, M., Wang, G., Yi, P., Security and trust management in opportunistic networks: a survey (2015) Secur Commun Netw, 8 (9), pp. 1812-1827; Wulandari, G., Rismawan, W., Saadah, S., Differential evolution for the cryptanalysis of transposition cipher (2015) 3Rd Int’l. Conf. on Information and Comm. Tech. (Icoict), pp. 45-48; Wyner, A., The wire-tap channel (1975) Bell Syst Tech J, 54, pp. 1355-1387; Zou, J., Gundry, S., Uyar, M., Kusyk, J., Sahin, C., Bio-inspired topology control mechanism for unmanned underwater vehicles (2016) Recent Advances in Computational Intelligence in Defense and Security. Springer, pp. 727-752","Uyar, M.U.; City College of New York, United States; email: uyar@ccny.cuny.edu",,,"Springer Verlag",,,,,18645909,,,,"English","Evol. Intelligence",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85047151349
"Gulcu T.C., Chatziafratis V., Zhang Y., Yagan O.","56534151400;57193734809;57189904355;24922359600;","Attack Vulnerability of Power Systems under an Equal Load Redistribution Model",2018,"IEEE/ACM Transactions on Networking","26","3",,"1306","1319",,8,"10.1109/TNET.2018.2823325","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045741354&doi=10.1109%2fTNET.2018.2823325&partnerID=40&md5=984f81a97ae1e8250a200f49fb1779df","TUBITAK Software Technologies Research Institute, Ankara, 06100, Turkey; Computer Science Department, Stanford University, Palo Alto, CA  94305, United States; Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA  15213, United States","Gulcu, T.C., TUBITAK Software Technologies Research Institute, Ankara, 06100, Turkey; Chatziafratis, V., Computer Science Department, Stanford University, Palo Alto, CA  94305, United States; Zhang, Y., Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA  15213, United States; Yagan, O., Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA  15213, United States","This paper studies the vulnerability of flow networks against adversarial attacks. In particular, consider a power system (or, any system carrying a physical flow) consisting of N transmission lines with initial loads L-{1}, \ldots , L-{N} and capacities C-{1}, \ldots , C-{N} , respectively; the capacity C-{i} defines the maximum flow allowed on line i. Under an equal load redistribution model, where load of failed lines is redistributed equally among all remaining lines, we study the optimization problem of finding the best k lines to attack so as to minimize the number of alive lines at the steady-state (i.e., when cascades stop). This is done to reveal the worst-case attack vulnerability of the system as well as to reveal its most vulnerable lines. We derive optimal attack strategies in several special cases of load-capacity distributions that are practically relevant. We then consider a modified optimization problem where the adversary is also constrained by the total load (in addition to the number) of the initial attack set, and prove that this problem is NP-hard. Finally, we develop heuristic algorithms for selecting the attack set for both the original and modified problems. Through extensive simulations, we show that these heuristics outperform benchmark algorithms under a wide range of settings. © 1993-2012 IEEE.","cascading failures vulnerability; Flow networks; optimal attack strategies","Constrained optimization; Electric load management; Electric power transmission; Heuristic algorithms; Optimization; Robustness (control systems); Benchmark testing; Cascading failures; Flow network; Load modeling; Optimal attack strategies; Power system dynamics; Load testing",,,,,"Andersen, J.V., Sornette, D., Leung, K.-T., Tricritical behavior in rupture induced by disorder (1997) Phys. Rev. Lett., 78 (11), pp. 2140-2143. , Mar; Andersson, G., Causes of the 2003 major grid blackouts in North America and Europe, and recommended means to improve system dynamic performance (2005) IEEE Trans. Power Syst., 20 (4), pp. 1922-1928. , Nov; Buldyrev, S.V., Parshani, R., Paul, G., Stanley, H.E., Havlin, S., Catastrophic cascade of failures in interdependent networks (2010) Nature, 464, pp. 1025-1028. , Apr; Chatziafratis, E., Zhang, Y., Yagan, O., On the robustness of power systems: Optimal load-capacity distributions and hardness of attacking (2016) Proc. Inf. Theory Appl. Workshop (ITA), pp. 1-10. , Jan./Feb; Crucitti, P., Latora, V., Marchiori, M., Model for cascading failures in complex networks (2004) Phys. Rev. E, Stat. Phys. Plasmas Fluids Relat. Interdiscip. Top., 69, p. 045104. , Apr; Daniels, H.E., The statistical theory of the strength of bundles of threads. i (1945) Proc. Roy. Soc. London A, Math. Phys. Sci., 183 (995), pp. 405-435; Daqing, L., Yinan, J., Rui, K., Havlin, S., Spatial correlation analysis of cascading failures: Congestions and blackouts (2014) Sci. Rep., 4. , Jun; Dobson, I., Carreras, B.A., Lynch, V.E., Newman, D.E., Complex systems analysis of series of blackouts: Cascading failure, critical points, and self-organization (2007) Chaos, 17 (2), p. 026103. , Jun; Dobson, I., Chen, J., Thorp, J.S., Carreras, B.A., Newman, D.E., Examining criticality of blackouts in power system models with cascading events (2002) Proc. 35th Annu. Hawaii Int. Conf. Syst. Sci., p. 10. , Jan; Kempe, D., Kleinberg, J., Tardos, É., Maximizing the spread of influence through a social network (2003) Proc. ACM SIGKDD Conf., pp. 137-146; Kinney, R., Crucitti, P., Albert, R., Latora, V., Modeling cascading failures in the North American power grid (2005) Eur. Phys. J. B-Condensed Matter Complex Syst., 46 (1), pp. 101-107; Loulou, R., Michaelides, E., New greedy-like heuristics for the multidimensional 0-1 knapsack problem (1979) Oper. Res., 27 (6), pp. 1101-1114; Mirzasoleiman, B., Babaei, M., Jalili, M., Safari, M., Cascaded failures in weighted networks (2011) Phys. Rev. E, Stat. Phys. Plasmas Fluids Relat. Interdiscip. Top., 84 (4), p. 046114; Motter, A.E., Lai, Y.-C., Cascade-based attacks on complex networks (2002) Phys. Rev. E, Stat. Phys. Plasmas Fluids Relat. Interdiscip. Top., 66, p. 065102. , Dec; (2016), http://www2.nationalgrid.com/uk/industry-information/future-of-energy/electricity-ten-yearstatement, NationalGrid; O'Rourke, T.D., Critical infrastructure, interdependencies, and resilience (2007) BRIDGE-Washington-Nat. Acad. Eng., 37 (1), p. 22; Overbye, T.J., Cheng, X., Sun, Y., A comparison of the AC and DC power flow models for LMP calculations (2004) Proc. 37th Hawaii Int. Conf. Syst. Sci., pp. 1-9; Ozel, O., Sinopoli, B., Yagan, O., (2018) Robustness of Flow Networks Against Cascading Failures under Partial Load Redistribution., , https://arxiv.org/abs/1802.07664; Pahwa, S., Scoglio, C., Scala, A., Abruptness of cascade failures in power grids (2014) Sci. Rep., 4. , Jan; Pradhan, S., Chakrabarti, B.K., Failure properties of fiber bundle models (2003) Int. J. Mod. Phys. B, 17 (29), pp. 5565-5581; Rosas-Casals, M., Solé, R., Analysis of major failures in Europe's power grid (2011) Int. J. Electr. Power Energy Syst., 33 (3), pp. 805-808; Roy, C., Kundu, S., Manna, S.S., Fiber bundle model with highly disordered breaking thresholds (2015) Phys. Rev. E, Stat. Phys. Plasmas Fluids Relat. Interdiscip. Top., 91 (3), p. 032103; Senju, S., Toyoda, Y., An approach to linear programming with 0-1 variables (1968) Manage. Sci., 15 (4), pp. B196-B207; Stott, B., Jardim, J., Alsac, O., DC power flow revisited (2009) IEEE Trans. Power Syst., 24 (3), pp. 1290-1300. , Aug; Toyoda, Y., A simplified algorithm for obtaining approximate solutions to zero-one programming problems (1975) Manage. Sci., 21 (12), pp. 1417-1427; Wang, W.-X., Chen, G., Universal robustness characteristic of weighted networks against cascading failure (2008) Phys. Rev. E, Stat. Phys. Plasmas Fluids Relat. Interdiscip. Top., 77, p. 026101. , Feb; Watts, D.J., A simple model of global cascades on random networks (2002) Proc. Nat. Acad. Sci. USA, 99 (9), pp. 5766-5771; Yang, Y., Nishikawa, T., Motter, A.E., Small vulnerable sets determine large network cascades in power grids (2017) Science, 358 (6365), p. eaan3184; Yagan, O., Robustness of power systems under a democratic-fiberbundle-like model (2015) Phys. Rev. E, Stat. Phys. Plasmas Fluids Relat. Interdiscip. Top., 91, p. 062811. , Jun; Yagan, O., Gligor, V., Analysis of complex contagions in random multiplex networks (2012) Phys. Rev. E, Stat. Phys. Plasmas Fluids Relat. Interdiscip. Top., 86 (3), p. 036103; Yagan, O., Qian, D., Zhang, J., Cochran, D., Information diffusion in overlaying social-physical networks (2012) Proc. CISS, pp. 1-6. , Mar; Yagan, O., Qian, D., Zhang, J., Cochran, D., Optimal allocation of interconnecting links in cyber-physical systems: Interdependence, cascading failures, and robustness (2012) IEEE Trans. Parallel Distrib. Syst., 23 (9), pp. 1708-1720. , Sep; Yagan, O., Qian, D., Zhang, J., Cochran, D., Conjoining speeds up information diffusion in overlaying social-physical networks (2013) IEEE J. Sel. Areas Commun., 31 (6), pp. 1038-1048. , Jun; Zhang, G., Li, Z., Zhang, B., Halang, W.A., Understanding the cascading failures in indian power grids with complex networks theory (2013) Phys. A, Stat. Mech. Appl., 392 (15), pp. 3273-3280; Zhang, Y., Arenas, A., Yagan, O., Cascading failures in interdependent systems under a flow redistribution model (2018) Phys. Rev. E, Stat. Phys. Plasmas Fluids Relat. Interdiscip. Top., 97, p. 022307. , Feb; Zhang, Y., Yagan, O., Optimizing the robustness of electrical power systems against cascading failures (2016) Sci. Rep., 6. , Jun","Yagan, O.; Department of Electrical and Computer Engineering, United States; email: oyagan@andrew.cmu.edu",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,10636692,,IEANE,,"English","IEEE ACM Trans Networking",Article,"Final","All Open Access, Bronze, Green",Scopus,2-s2.0-85045741354
"Pu C., Lim S., Jung B., Chae J.","56430573100;8437951300;57193224251;15123874100;","EYES: Mitigating forwarding misbehavior in energy harvesting motivated networks",2018,"Computer Communications","124",,,"17","30",,13,"10.1016/j.comcom.2018.04.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045713367&doi=10.1016%2fj.comcom.2018.04.007&partnerID=40&md5=c4fcb5b33a571f2dc1c356c0ad6bc55e","Weisberg Division of Computer Science, Marshall University, Huntington, WV  25755, United States; T2WISTOR: TTU Wireless Mobile Networking Laboratory, Department of Computer Science, Texas Tech University, Lubbock, TX  79409, United States; Department of Computer Science and Engineering, Incheon National University, Incheon, 22012, South Korea","Pu, C., Weisberg Division of Computer Science, Marshall University, Huntington, WV  25755, United States; Lim, S., T2WISTOR: TTU Wireless Mobile Networking Laboratory, Department of Computer Science, Texas Tech University, Lubbock, TX  79409, United States; Jung, B., T2WISTOR: TTU Wireless Mobile Networking Laboratory, Department of Computer Science, Texas Tech University, Lubbock, TX  79409, United States; Chae, J., Department of Computer Science and Engineering, Incheon National University, Incheon, 22012, South Korea","Energy harvesting motivated networks (EHNets) has been becoming increasingly popular in the presence of Internet-of-Things (IoT). Each self-sustainable node periodically harvests energy from an immediate environment but it is admittedly vulnerable to a Denial-of-Service (DoS) attack in the EHNets. In this paper, we propose a novel countermeasure, called EYES, to the forwarding misbehavior of multiple colluding malicious nodes in the realm of EHNets. Under the charge-and-spend harvesting policy, we first establish a set of adversarial scenarios, analyze its forwarding operations, and identify vulnerable cases. The EYES consists of two schemes, SlyDog and LazyDog, and cooperatively detects the forwarding misbehavior. In the SlyDog, each node actively disguises itself as an energy harvesting node and stealthily monitors the forwarding operations of adjacent nodes. In the LazyDog, however, each node periodically requests the number of overheard packets from its adjacent nodes and validates any prior uncertain forwarding operation. The combination of two schemes can efficiently detect the forwarding misbehaviors of colluding malicious nodes and quickly isolate them from the network. We also present a simple analytical model and its numerical result in terms of detection rate. We evaluate the proposed countermeasure through extensive simulation experiments using the OMNeT++ and compare its performance with two existing schemes, the hop-by-hop cooperative detection (HCD) and Watchdog. Simulation results show that the EYES provides 70–92% detection rate and achieves 23–60% lower detection latency compared to the HCD and Watchdog. The EYES also shows a competitive performance in packet delivery ratio. © 2018 Elsevier B.V.","Denial-of-Service; Energy harvesting motivated networks; Forwarding misbehavior","Denial-of-service attack; Internet of things; Colluding malicious nodes; Competitive performance; Denial of Service; Extensive simulations; Forwarding misbehavior; Immediate environment; Internet of Things (IOT); Packet delivery ratio; Energy harvesting",,,,,"Gubbi, J., Buyya, R., Marusic, S., Palaniswami, M., Internet of things (IoT): a vision, architectural elements, and future directions (2013) Futur. Gener. Comput. Syst., 29, pp. 1645-1660; Kravets, R., Krishnan, P., Power management techniques for mobile communication (1998) Proceedings of ACM MOBICOM, pp. 157-168; Pantazis, N.A., Nikolidakis, S.A., Vergados, D.D., Energy-efficient routing protocols in wireless sensor networks: A Survey (2013) IEEE Commun. Surv. Tutor., 15 (2), pp. 551-591; Gorlatova, M., Sarik, J., Grebla, G., Cong, M., Kymissis, I., Zussman, G., Movers and shakers: kinetic energy harvesting for the internet of things (2015) IEEE J. Sel. Areas Commun., 33 (8), pp. 1624-1639; Kamalinejad, P., Mahapatra, C., Sheng, Z., Mirabbasi, S., Leung, V., Guan, Y.L., Wireless energy harvesting for the internet of things (2015) IEEE Commun. Mag., 53 (6), pp. 102-108; Wang, Y., Liu, Y., Wang, C., Li, Z., Sheng, X., Lee, H., Chang, N., Yang, H., Storage-less and converter-less photovoltaic energy harvesting with maximum power point tracking for internet of things (2015) IEEE Trans. Comput. Aided Des. Integr. Circuits Syst., 35 (2), pp. 173-186; Wood, A.D., Stankovic, J.A., Denial of service in sensor networks (2002) IEEE Comput., 35 (10), pp. 54-62; Marti, S., Giuli, T.J., Lai, K., Baker, M., Mitigating routing misbehavior in mobile ad hoc networks (2000) Proceedings of ACM MOBICOM, pp. 255-265; Raymond, D.R., Midkiff, S.F., Denial-of-service in wireless sensor networks: attacks and defense (2008) IEEE Pervasive Comput., 7 (1), pp. 74-81; Hai, T.H., Huh, E., Detecting selective forwarding attacks in wireless sensor networks using two-hops neighbor knowledge (2008) Proceedings of IEEE NCA, pp. 325-331; Yu, B., Xiao, B., Detecting selective forwarding attacks in wireless sensor networks (2006) IEEE IPDPS, pp. 1-8; Xiao, B., Yu, B., Gao, C., CHEMAS: identify suspect nodes in selective forwarding attacks (2007) J. Parallel Distrib. Comput., 67 (11), pp. 1218-1230; Liu, K., Deng, J., Varshney, P.K., Balakrishnan, K., An acknowledgment-based approach for the detection of routing misbehavior in MANETs (2007) IEEE Trans. Mob. Comput., 6 (5), pp. 536-550; Shila, D.M., Yu, C., Anjali, T., Mitigating selective forwarding attacks with a channel-Aware approach in WMNs (2010) IEEE Trans. Wirel. Commun., 9 (5), pp. 1661-1675; Li, X., Lu, R., Liang, X., Shen, X., Side channel monitoring: packet drop attack detection in wireless ad hoc networks (2011) Proceedings of IEEE ICC, pp. 1-5; Shakshuki, E.M., Kang, N., Sheltami, T.R., EAACK: a secure intrusion-detection system for MANETs (2013) IEEE Trans. Ind. Electron., 60 (3), pp. 1089-1098; Liu, Q., Yin, J., Leung, V., Cai, Z., FADE: forwarding assessment based detection of collaborative grey hole attacks in WMNs (2013) IEEE Trans. Wirel. Commun., 12 (10), pp. 5124-5137; Ren, J., Zhang, Y., Zhang, K., Shen, X.S., Exploiting channel-aware reputation system against selective forwarding attacks in WSNs (2014) Proceedings of IEEE GLOBECOM, pp. 330-335; Chang, J.-M., Tsou, P.-C., Woungang, I., Chao, H.-C., Lai, C.-F., Defending against collaborative attacks by malicious nodes in MANETs: a cooperative bait detection approach (2015) IEEE Syst. J., 9 (1), pp. 65-75; Jhaveri, R.H., Patel, N.M., A sequence number based bait detection scheme to Thwart grayhole attack in mobile ad hoc networks (2015) Wirel. Netw., 21 (8), pp. 2781-2798; Pu, C., Lim, S., A light-weight countermeasure to forwarding misbehavior in wireless sensor networks: design, analysis, and evaluation (2016) IEEE Syst. J.; Lim, S., Lauren, H., Hop-by-hop cooperative detection of selective forwarding attacks in energy harvesting wireless sensor networks (2015) Proceedings of ICNC, pp. 315-319; Varga, A., (2014), http://www.omnetpp.org/, OMNeT++; Chae, Y., DiPippo, L.C., Sun, Y.L., Trust management for defending on-off attacks (2015) IEEE Trans. Parallel Distrib. Syst., 26 (4), pp. 1178-1191; Ren, J., Zhang, Y., Zhang, K., Shen, X., Adaptive and channel-aware detection of selective forwarding attacks in wireless sensor networks (2016) IEEE Trans. Wirel. Commun., 15 (5), pp. 3718-3731; Pu, C., Hajjar, S., Mitigating forwarding misbehaviors in RPL-basedlow power and lossy networks (2018) Proceedingsof IEEE CCNC; Pu, C., Lim, S., Spy vs. spy: camouflage-based active detection in energy harvesting motivated networks (2015) Proceedings of MILCOM, pp. 903-908; Midi, D., Bertino, E., Node or link? Fine-grained analysis of packet-loss attacks in wireless sensor networks (2016) ACM Trans. Sensor Netw., 12 (2); Zhang, Y., Lazos, L., Kozma, W., AMD: audit-based misbehavior detection in wireless ad hoc networks (2016) IEEE Trans. Mob. Compu., 15 (8), pp. 1893-1907; Stehlik, M., Matyas, V., Stetsko, A., Towards better selective forwarding and delay attacks detection in wireless sensor networks (2016) Proceedings of IEEE ICNSC, pp. 1-6; Lim, S., Kimn, J., Kim, H., Analysis of energy harvesting for vibration-motivated wireless sensor networks (2010) Proceedings of ICWN, pp. 391-397; http://www.ti.com/lit/ds/symlink/cc2420.pdf, 2.4 GHz IEEE 802.15.4/ZigBee-ready RF transceiver, (Last accessed at Feb 2018); https://www.cisco.com/c/en/us/products/collateral/wireless/aironet-802-11a-b-g-cardbus-wireless-lan-client-adapter-cb21ag/product_data_sheet09186a00801ebc29.html, Cisco Aironet 802.11a/b/g wireless CardBus adapter, (Last accessed at Feb 2018); Starner, T., Human-powered wearable computing (1996) IBM Syst. J., 35 (3 & 4), pp. 618-629; Starner, T., Paradiso, J.A., Human Generated Power for Mobile Electronics (2004), pp. 1-35. , in: CRC Press; Wang, Z.L., Nanogenerators for Self-powered Devices and Systems (2011), Georgia Institute of Technology, Atlanta, USA; Xue, X., Wang, S., Guo, W., Zhang, Y., Wang, Z.L., Hybridizing energy conversion and storage in a mechanical-to-electrochemical process for self-charging power cell (2012) Nano Lett., 12 (9), pp. 5048-5054; Eu, Z.A., Tan, H., Seah, W.K.G., Design and performance analysis of MAC schemes for wireless sensor networks powered by ambient energy harvesting (2011) Ad Hoc Netw., 9 (3), pp. 300-323; Fujii, C., Seah, W.K.G., Multi-tier probabilistic polling for wireless sensor networks powered by energy harvesting (2011) Proceedings of IEEE ISSNIP, pp. 383-388; Pu, C., Gade, T., Lim, S., Min, M., Wang, W., Light-weight forwarding protocols in energy harvesting wireless sensor networks (2014) Proceedings of MILCOM, pp. 1053-1059; Stallings, W., Cryptography and Network Security - Principles and Practices (2013), 6th Edition Prentice Hall; Boulis, A., (2014), http://castalia.forge.nicta.com.au, Castalia; Tang, X., Xu, J., Extending network lifetime for precision-constrained data aggregation in wireless sensor networks (2006) INFOCOM, pp. 1-12; Jiang, S., (2006) Efficient Network Camouflaging in Wireless Networks, , Ph.D. thesis. Texas A&M University; Deng, J., Han, R., Mishra, S., INSENS: intrusion-tolerant routing for wireless sensor networks (2006) Comput. Commun., 29 (2), pp. 216-230; Fang, Q., Gao, J., Guibas, L.J., Locating and bypassing holes in sensor networks (2006) Mob. Netw. Appl., 11 (2), pp. 187-200","Pu, C.; Weisberg Division of Computer Science, United States; email: puc@marshall.edu",,,"Elsevier B.V.",,,,,01403664,,COCOD,,"English","Comput Commun",Article,"Final","",Scopus,2-s2.0-85045713367
"Yin Z., Wang F., Liu W., Chawla S.","57200422351;55971216500;56718721100;7103098407;","Sparse Feature Attacks in Adversarial Learning",2018,"IEEE Transactions on Knowledge and Data Engineering","30","6",,"1164","1177",,12,"10.1109/TKDE.2018.2790928","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041207690&doi=10.1109%2fTKDE.2018.2790928&partnerID=40&md5=20a79a0613664e9de6f682cbae381d73","School of Information Technologies, University of Sydney, Camperdown, NSW  2006, Australia; Advanced Analytics Institute, University of Technology, Sydney, Ultimo, NSW  2007, Australia; Qatar Computing Research Institute (QCRI), HBKU, Doha, 34110, Qatar","Yin, Z., School of Information Technologies, University of Sydney, Camperdown, NSW  2006, Australia; Wang, F., School of Information Technologies, University of Sydney, Camperdown, NSW  2006, Australia; Liu, W., Advanced Analytics Institute, University of Technology, Sydney, Ultimo, NSW  2007, Australia; Chawla, S., Qatar Computing Research Institute (QCRI), HBKU, Doha, 34110, Qatar","Adversarial learning is the study of machine learning techniques deployed in non-benign environments. Example applications include classification for detecting spam, network intrusion detection, and credit card scoring. In fact, as the use of machine learning grows in diverse application domains, the possibility for adversarial behavior is likely to increase. When adversarial learning is modelled in a game-theoretic setup, the standard assumption about the adversary (player) behavior is the ability to change all features of the classifiers (the opponent player) at will. The adversary pays a cost proportional to the size of the 'attack'. We refer to this form of adversarial behavior as a dense feature attack. However, the aim of an adversary is not just to subvert a classifier but carry out data transformation in a way such that spam continues to remain effective. We demonstrate that an adversary could potentially achieve this objective by carrying out a sparse feature attack. We design an algorithm to show how a classifier should be designed to be robust against sparse adversarial attacks. Our main insight is that sparse feature attacks are best defended by designing classifiers which use ℓ1 regularizers. © 2018 IEEE.","Adversarial learning; nash equilibrium; sparse modeling; stackelberg game; ℓ1 regularizer","Artificial intelligence; Data structures; Electronic mail; Gallium compounds; Gallium nitride; Intrusion detection; Learning systems; Mathematical transformations; Robustness (control systems); Adversarial learning; Games; Nash equilibria; Regularizer; Stackelberg Games; Game theory",,,,,"Wang, F., Liu, W., Chawla, S., On sparse feature attacks in adversarial learning (2014) Proc. IEEE Int. Conf. Data Mining, pp. 1013-1018; Dalvi, N., Domingos, P., Mausam, Sanghai, S., Verma, D., Adversarial classification (2004) Proc. 10th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, pp. 99-108; Lowd, D., Meek, C., Adversarial learning (2005) Proc. 11th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, pp. 641-647; Globerson, A., Roweis, S., Nightmare at test time: Robust learning by feature deletion (2006) Proc. 23rd Int. Conf. Mach. Learn., pp. 353-360; Kocz, A., Teo, C.H., Feature weighting for improved classifier robustness (2009) Proc. 6th Conf. Email Anti-Spam; Kantarcoǧlu, M., Xi, B., Clifton, C., Classifier evaluation and attribute selection against active adversaries (2011) Data Mining Knowl. Discovery, 22 (1-2), pp. 291-335; Li, X., Cui, G., Dong, Y., Graph regularized non-negative lowrank matrix factorization for image clustering (2017) IEEE Trans. Cybern., 47 (11), pp. 3840-3853. , Nov; Dong, Y., Tao, D., Li, X., Nonnegative multiresolution representation-based texture image classification (2015) ACM Trans. Intell. Syst. Technol., 7 (1), pp. 1-21; Liu, W., Chawla, S., Mining adversarial patterns via regularized lossminimization (2010) Mach. Learn., 81 (1), pp. 69-83; Brückner, M., Scheffer, T., Stackelberg games for adversarial prediction problems (2011) Proc. 17th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, pp. 547-555; Zhou, Y., Kantarcioglu, M., Thuraisingham, B., Xi, B., Adversarial support vector machine learning (2012) Proc. 18th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, pp. 1059-1067; Zhou, Y., Kantarcioglu, M., Adversarial learning with Bayesian hierarchical mixtures of experts (2014) Proc. SIAM Int. Conf. Data Mining, pp. 929-937; Xu, H., Caramanis, C., Mannor, S., Robust regression and lasso (2010) IEEE Trans. Inf. Theory, 56 (7), pp. 3561-3574. , Jul; Goodfellow, I., Generative adversarial nets (2014) Proc. Int. Conf. Neural Inf. Process. Syst., pp. 2672-2680; Mirza, M., Osindero, S., Conditional generative adversarial nets (2014) CoRR, , http://arxiv.org/abs/1411.1784, [Online]; Denton, E.L., Chintala, S., Szlam, A., Fergus, R., Deep generative image models using a laplacian pyramid of adversarial networks (2015) Proc. Int. Conf. Neural Inf. Process. Syst., pp. 1486-1494; Fudenberg, D., Tirole, J., (1991) Game Theory, , 1st ed. Cambridge, MA, USA: MIT Press; Leyton-Brown, K., Shoham, Y., (2008) Essentials of Game Theory: A Concise, Multidisciplinary Introduction, , 1st ed. San Rafael, CA, USA: Morgan and Claypool Publishers; Osborne, M.J., Rubinstein, A., (1994) A Course in Game Theory, , Cambridge, MA, USA: MIT Press; Vicente, L.N., Calamai, P.H., Bilevel and multilevel programming: A bibliography review (1994) J. Global Optimization, 5 (3), pp. 291-306; Wang, F., Chawla, S., Liu, W., Tikhonov or lasso regularization: Which is better and when (2013) Proc. IEEE 25th Int. Conf. Tools Artif. Intell., pp. 795-802; Teo, C., Vishwanthan, S., Smola, A., Le, Q., Bundle methods for regularized risk minimization (2010) J. Mach. Learn. Res., 11, pp. 311-365; Grant, M., Boyd, S., Ye, Y., (2008) CVX: Matlab Software for Disciplined Convex Programming, , http://cvxr.com/cvx/, Online; Hastie, T., Tibshirani, R., Friedman, J., Hastie, T., Friedman, J., Tibshirani, R., (2009) The Elements of Statistical Learning, , Berlin, Germany: Springer; Lecun, Y., (1998) The MNIST Database of Handwritten Digits, , http://yann.lecun.com/exdb/mnist/, [Online]; Smola, A.J., (1998) Learning with Kernels, , Ph.D. dissertation, GMD, Birlinghoven, Germany; Brückner, M., Kanzow, C., Scheffer, T., Static prediction games for adversarial learning problems (2012) J. Mach. Learn. Res., 13, pp. 2617-2654; Frank, A., Asuncion, A., (2010) UCI Machine Learning Repository, , http://archive.ics.uci.edu/ml, [Online]; Shalev-Shwartz, S., Srebro, N., Zhang, T., Trading accuracy for sparsity in optimization problems with sparsity constraints (2010) SIAM J. Optimization, 20 (6), pp. 2807-2832; Aliprantis, C., Chakrabarti, S., (2000) Games and Decision Making, , Oxford, U.K.: Oxford Univ. Press; Pekhimenko, G., Penalizied Logistic Regression for Classification, , Dept. Comput. Sci.., Univ. Toronto, Toronto, ON M5S3L1; Liu, W., Chawla, S., A game theoretical model for adversarial learning (2009) Proc. IEEE Int. Conf. Data Mining Workshops, pp. 25-30; Radford, A., Metz, L., Chintala, S., (2015) Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks","Liu, W.; Advanced Analytics Institute, Australia; email: wei.liu@uts.edu.au",,,"IEEE Computer Society",,,,,10414347,,ITKEE,,"English","IEEE Trans Knowl Data Eng",Article,"Final","",Scopus,2-s2.0-85041207690
"Liu S., Zhou W., Zhang J., Xiang Y., Wangt Y., De Vel O.","56195519800;7404511655;57198771239;57114147900;57202752178;56429241700;","A data-driven attack against support vectors of SVM",2018,"ASIACCS 2018 - Proceedings of the 2018 ACM Asia Conference on Computer and Communications Security",,,,"723","734",,2,"10.1145/3196494.3196539","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049181321&doi=10.1145%2f3196494.3196539&partnerID=40&md5=299118164af4d985f96f06266d290273","Swinburne University of Technology, Hawthorn, VIC  3122, Australia; Deakin University, Burwood, VIC  3125, Australia; Guangzhou University, Guangzhou, 510006, China; Defence Science and Technology Group, Edinburgh, SA  5111, Australia","Liu, S., Swinburne University of Technology, Hawthorn, VIC  3122, Australia; Zhou, W., Deakin University, Burwood, VIC  3125, Australia; Zhang, J., Swinburne University of Technology, Hawthorn, VIC  3122, Australia; Xiang, Y., Swinburne University of Technology, Hawthorn, VIC  3122, Australia; Wangt, Y., Guangzhou University, Guangzhou, 510006, China; De Vel, O., Defence Science and Technology Group, Edinburgh, SA  5111, Australia","Machine learning (ML) is commonly used in multiple disciplines and real-world applications, such as information retrieval, financial systems, health, biometrics and online social networks. However, their security profiles against deliberate attacks have not often been considered. Sophisticated adversaries can exploit specific vulnerabilities exposed by classical ML algorithms to deceive intelligent systems. It is emerging to perform a thorough security evaluation as well as potential attacks against the machine learning techniques before developing novel methods to guarantee that machine learning can be securely applied in adversarial setting. In this paper, an effective attack strategy for crafting foreign support vectors in order to attack a classic ML algorithm, the Support Vector Machine (SVM) has been proposed with mathematical proof. The new attack can minimize the margin around the decision boundary and maximize the hinge loss simultaneously. We evaluate the new attack in different real-world applications including social spam detection, Internet traffic classification and image recognition. Experimental results highlight that the security of classifiers can be worsened by poisoning a small group of support vectors. © 2018 Association for Computing Machinery.","Adversarial learning; Evasion attacks; Support vector machines","Image recognition; Intelligent systems; Online systems; Petroleum reservoir evaluation; Search engines; Social networking (online); Telecommunication traffic; Vectors; Adversarial learning; Evasion attacks; Internet traffic classifications; Machine learning techniques; Mathematical proof; Multiple disciplines; On-line social networks; Security evaluation; Support vector machines",,,,,"Anzai, Y., (2012) Pattern Recognition & Machine Learning, , Elsevier; Azmandian, F., Kaeli, D.R., Dy, J.G., Aslam, J.A., Securing virtual execution environments through machine learning-based intrusion detection (2015) Machine Learning for Signal Processing (MLSP), 2015 IEEE 25th International Workshop on, pp. 1-6. , IEEE; Baesens, B., Van Vlasselaer, V., Verbeke, W., (2015) Fraud Analytics Using Descriptive, Predictive, and Social Network Techniques: A Guide to Data Sciencefur Fraud Detection, , John Wiley & Sons; Barni, M., Chen, Z., Tondi, B., Adversary-aware, data-driven detection of double JPEG compression: How to make counter-forensics harder (2016) 2016 IEEE International Workshop onInformation Forensics and Security (WIFS), pp. 1-6. , IEEE; Barreno, M., Nelson, B., Joseph, A.D., Tygar, J.D., The security of machine learning (2010) Machine Learning, 81 (2), pp. 121-148. , 2010; Barreno, M., Nelson, B., Sears, R., Joseph, A.D., Doug Tygar, J., Can machine learning be secure? (2006) Proceedings of The 2006 ACM Symposium on Information, Computer and Communications Security, pp. 16-25. , ACM; Biggio, B., Bulo, S.R., Pillai, I., Mura, M., Mequanint, E.Z., Pelillo, M., Roli, F., Poisoning complete-linkage hierarchical clustering (2014) Structural, Syntactic, and Statistical Pattern Recognition, pp. 42-52. , Springer; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Srndic, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Machine Learning and Knowledge Discovery in Databases, pp. 387-402. , Springer; Biggio, B., Fumera, G., Marcialis, G.L., Roli, F., Statistical meta-analysis of presentation attacks for secure multibiometric systems IEEE Transactions onPatternAnalysis and Machine Intelligence, , press. press). tion:DOI10; Biggio, B., Fumera, G., Roli, F., Security evaluation of pattern classifiers under attack (2014) Knowledge and Data Engineering, IEEE Transactions on, 26 (4), pp. 984-996. , 2014; Biggio, B., Nelson, B., Laskov, P., Support vector machines under adversarial label noise (2011) ACML, 20, pp. 97-112. , 2011; Biggio, B., Nelson, B., Laskov, P., Poisoning attacks against support vector machines (2012) Proc. 29th Int'L Conf. Machine Learning, , http://icml.cc/discuss/2012/880.html; Christmann, A., Steinwart, I., On robustness properties of convex risk minimization methods for pattern recognition (2004) The Journal of Machine Learning Research5, pp. 1007-1034. , 2004; Chung, S.P., Mok, A.K., Allergy attack against automatic signature generation (2006) RecentAdvances inIntrusionDetection, pp. 61-80. , Springer; Crawford, M., Khoshgoftaar, T.M., Prusa, J.D., Richter, A.N., Najada, H.A., Survey of review spam detection using machine learning techniques (2015) Journal Of Big Data, 2 (1), pp. 1-24. , 2015; Cristianini, N., Shawe-Taylor, J., (2000) An Introduction to Support Vector Machines and Other Kernel-Based Learning Methods, , le: Cambridge university press; Dalvi, N., Domingos, P., Sanghai, S., Verma, D., Adversarial classification (2004) Proceedings of The Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 99-108. , i?: ACM; Darcy, A.M., Louie, A.K., Roberts, L.W., Machine learning [is: And the profession of medicine (2016) JAMA, 315 (6), pp. 551-552. , 2016; Demontis, A., Melis, M., Biggio, B., Maiorca, D., Arp, D., Rieck, K., Corona, I., Roli, F., Yes, machine learning can be more secure! A case study on android malware detection (2017) IEEE Transactions on Dependable and Secure Computing, , 2017; Frank, A., Asuncion, A., (2010) UCI Machine Learning Repository, , http://archive.ics.uci.edu/ml, Irvine, CA: University of California. School of Information and Computer Science 213 2010; Ghahramani, Z., Probabilistic machine learning and artificial intelligence (2015) Nature, 521 (7553), pp. 452-459. , 2015; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I.P., Tygar, J.D., Adversarial machine learning (2011) Proceedings of The 4th ACM Workshop on Security and Artificial Intelligence, pp. 43-58. , ACM; Ibrahim, H.A.H., Al Zuobi, O.R.A., Al-Namari, M.A., Mohamed Aii, G., Abdalla, A.A.A., Internet traffic classification using machine learning approach: Datasets validation issues (2016) 2016 Conference ofBasic Sciences and Engineering Studies (SGCAC), pp. 158-166. , IEEE; Joachims, T., Training linear SVMs in linear time (2006) Proceedings of The 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 217-226. , ACM; Kantchelian, A., Tygar, J.D., Joseph, A.D., (2015) Evasion and Hardening of Tree Ensemble Classifiers, , arXiv preprint 2015; Kumar, A., Mehta, S., Vijaykeerthy, D., An introduction to adversarial machine learning (2017) International Conference onBig Data Analytics, pp. 293-299. , Springer; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Rnachine Learning at Scale, , arXiv preprint 2016; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), pp. 436-444. , 2015; Liang, B., Su, M., You, W., Shi, W., Yang, G., Cracking classifiers for evasion: A case study on the google's phishing pages filter (2016) Proceedings of The 25th International Conference on World Wide Web. International World Wide Web, pp. 345-356. , Conferences Steering Committee; Liu, S., Wang, Y., Zhang, J., Chen, C., Xiang, Y., Addressing the class imbalance problem in twitter spam detection using ensemble learning (2017) Computers & Security, 69, pp. 35-49. , 2017; Liu, S., Zhang, J., Xiang, Y., Statistical detection of online drifting twitter spam: Invited paper (2016) Proceedings of The 11th ACM on Asia Conference on Computer and Communications Security, pp. 1-10. , ACM; Lutkepohl, H., Handbook of matrices (1997) Computational Statistics and Data Analysis, 2, p. 25. , 1997; Mei, S., Zhu, X., Using machine teaching to identify optimal training-set attacks on machine learners (2015) AAAI, pp. 2871-2877; Miller, B., Kantchelian, A., Afroz, S., Bachwani, R., Dauber, E., Huang, L., Tschantz, M.C., Doug Tygar, J., Adversarial active learning (2014) Proceedings of The 2014 Workshop on Artificial Intelligent and Security Workshop, pp. 3-14. , ACM; Narudin, F.A., Feizollah, A., Anuar, N.B., Gani, A., Evaluation of machine learning classifiers for mobile malware detection (2016) Soft Computing, 20 (1), pp. 343-357. , 2016; Nelson, B., Barreno, M., Chi, F.J., Joseph, A.D., Rubinstein, B.D., Saini, U., Sutton, C.A., Xia, K., Exploiting machine learning to subvert your spam filter (2008) LEET, 8, pp. 1-9. , 2008; Newsome, J., Karp, B., Song, D., Paragraph: Thwarting signature learning by training maliciously (2006) Recent Advances in Intrusion Detection, pp. 81-105. , Springer; Papemot, N., McDaniel, P.D., Wu, X.I., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) IEEE Symposium on Security and Privacy, SP 2016, pp. 582-597. , https://doi.org/10.1109/SP.2016.41, San Jose, CA, USA, May 22-26, 2016; Poggio, T., Cauwenberghs, G., Incremental and décrémentai support vector machine learning (2001) Advances in Neural Information Processing Systems, 13, p. 409. , 2001; Ricci, F., Rokach, L., Shapira, B., (2011) Introduction to Recommender Systems Handbook, , Springer; Rndic, N., Laskov, P., Practical evasion of a learning-based classifier: A case study (2014) Security and Privacy (SP), 2014IEEE Symposium on, pp. 197-211. , IEEE; Salem, M.B., Hershkop, S., Stolfo, S.J., A survey of insider attack detection research (2008) InsiderAttack and Cyber Security, pp. 69-90. , Springer; Schnabel, T., Bennett, P.N., Dumais, S.T., Joachims, T., Using shortlists to support decision making and improve recommender system performance (2016) Proceedings of The 25th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee, pp. 987-997; Shipp, M.A., Ross, K.N., Tamayo, P., Weng, A.P., Kutok, J.L., Aguiar, R.C.T., Gaasenbeek, M., Pinkus, G.-D.S., Diffuse large B-cell lymphoma outcome prediction by gene-expression profiling and supervised machine learning (2002) Nature Medicine, 8 (1), pp. 68-74. , 2002; Steinwart, I., Christrnann, A., (2008) Support Vector Machines, , Springer Science & Business Media; Tjandrasa, H., Putra, R.E., Wijaya, A.Y., Arieshanti, I., Classification of non-proliferative diabetic retinopathy based on hard exudates using soft margin SVM (2013) Control System, Computing and Engineering (ICCSCE), 2013 IEEE International Conference on, pp. 376-380. , IEEE; Venkataraman, S., Blum, A., Song, D., (2008) Limits of Learning-Based Signature Generation with Adversaries, , 2008; Wang, Y., Xiang, Y., Zhang, J., Zhou, W., Wei, G., Yang, L.T., Internet traffic classification using constrained clustering (2014) IEEE Transactions on Parallel and Distributed Systems, 25 (11), pp. 2932-2943. , 2014; Xiao, H., Biggio, B., Nelson, B., Xiao, H., Eckert, C., Roli, F., Support vector machines under adversarial label contamination (2015) Neurocomputing, 160, pp. 53-62. , 2015; Xu, L., Zhan, Z., Xu, S., Ye, K., An evasion and counter-evasion study in malicious websites detection (2014) Communications andNetwork Security (CNS), 2014 IEEE Conference on, pp. 265-273. , IEEE; Zhang, F., Chan, P.P.K., Biggio, B., Yeung, D.S., Roli, F., Adversarial feature selection against evasion attacks (2016) WEE Trans. Cybernetics, 46 (3), pp. 766-777. , https://doi.org/10.1109/TCYB.2015.2415032, 2016",,,"ACM SIGSAC","Association for Computing Machinery, Inc","13th ACM Symposium on Information, Computer and Communications Security, ASIACCS 2018","4 June 2018 through 8 June 2018",,136866,,9781450355766,,,"English","ASIACCS - Proc. ACM Asia Conf. Comput. Commun. Secur.",Conference Paper,"Final","",Scopus,2-s2.0-85049181321
"Aiken W., Kim H.","57103289200;35310921400;","POSTER: DeepCRACk: Using deep learning to automatically CRack audio CAPTCHAs",2018,"ASIACCS 2018 - Proceedings of the 2018 ACM Asia Conference on Computer and Communications Security",,,,"797","799",,3,"10.1145/3196494.3201581","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049172613&doi=10.1145%2f3196494.3201581&partnerID=40&md5=91c2da890b84d5cd1584d03d70ca8d5b","Sungkyunkwan University, Suwon, South Korea","Aiken, W., Sungkyunkwan University, Suwon, South Korea; Kim, H., Sungkyunkwan University, Suwon, South Korea","A Completely Automated Public Turing test to tell Computers and Humans Apart (CAPTCHA) is a defensive mechanism designed to differentiate humans and computers to prevent unauthorized use of online services by automated attacks. They often consist of a visual or audio test that humans can perform easily but that bots cannot solve. However, with current machine learning techniques and open-source neural network architectures, it is now possible to create a self-contained system that is able to solve specific CAPTCHA types and outperform some human users. In this paper, we present a neural network that leverages Mozilla's open source implementation of Baidu's Deep Speech architecture; our model is currently able to solve the audio version of an open-source CATPCHA system (named SimpleCaptcha) with 98.8% accuracy. Our network was trained on 100,000 audio samples generated from SimpleCaptcha and can solve new SimpleCaptcha audio tests in 1.25 seconds on average (with a standard deviation of 0.065 seconds). Our implementation seems additionally promising because it does not require a powerful server to function and is robust to adversarial examples that target Deep Speech's pre-trained models. © 2018 Association for Computing Machinery.","Adversarial machine learning; CAPTCHA; Neural networks","Computer architecture; Electronic mail filters; Network architecture; Network security; Neural networks; Online systems; Open systems; Automated attacks; CAPTCHAs; Defensive mechanism; Machine learning techniques; On-line service; Open source implementation; Self-contained systems; Standard deviation; Deep learning",,,,,"Bock, K., Patel, D., Hughey, G., Levin, D., UnCaptcha: A low-resource defeat of reCaptcha's audio challenge (2017) Proceedings of The 11th USENIX Workshop on Offensive Technologies; Carlini, N., Wagner, D., (2018) Audio Adversarial Examples: Targeted Attacks on Speech-to-Text, , arXiv preprint January 2018; (2018) Google reCAPTCHA: Tough on Bots, Easy on Humans, , https://www.google.com/recaptcha/intro/android.html, accessed March 1, 2018; Hannun, A., Case, C., Casper, J., Catanzaro, B., Diamos, G., Elsen, E., Prenger, R., Ng, A.Y., (2014) Deep Speech: Scaling up End-to-End Speech Recognition, , arXiv preprint December 2014; Kopp, M., Nikl, M., Holeň, M., Breaking CAPTCHAs with convolutional neural networks (2017) Proceedings of The 17th Conference on Information Technologies - Applications and Theory; Powell, B.M., Kalsy, E., Goswami, G., Vatsa, M., Singh, R., Noore, A., Attack-Resistant aiCAPTCHA using a negative selection artificial immune system (2017) IEEE Security and Privacy Workshops; Powell, B.M., Kumar, A., Thapar, J., Goswami, G., Vatsa, M., Singh, R., Noore, A., A multibiometrics-based CAPTCHA for improved online security (2016) IEEE 8th International Conference on Biometrics Theory, Applications and Systems; Sivakorn, S., Polakis, I., Keromytis, A.D., I am robot: (deep) learning to break semantic image CAPTCHAs (2016) IEEE European Symposium on Security and Privacy (EuroS&P); Sket, C., (2017) 508 Compliance: Who Needs to Be Compliant?, , https://brailleworks.com/508-compliance-needs-compliant/, accessed March 8, 2018",,,"ACM SIGSAC","Association for Computing Machinery, Inc","13th ACM Symposium on Information, Computer and Communications Security, ASIACCS 2018","4 June 2018 through 8 June 2018",,136866,,9781450355766,,,"English","ASIACCS - Proc. ACM Asia Conf. Comput. Commun. Secur.",Conference Paper,"Final","",Scopus,2-s2.0-85049172613
"Kwon H., Yoon H., Choi D.","57197769092;15061371300;8660876600;","POSTER: Zero-day evasion attack analysis on race between attack and defense",2018,"ASIACCS 2018 - Proceedings of the 2018 ACM Asia Conference on Computer and Communications Security",,,,"805","807",,1,"10.1145/3196494.3201583","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049170600&doi=10.1145%2f3196494.3201583&partnerID=40&md5=9ef61a4d2b219bad1505edf58b8625d8","Korea Advanced Institute of Science and Technology, School of Computing, Daejeon, South Korea; Kongju National University, Department of Medical Information, Gongju-si, South Korea","Kwon, H., Korea Advanced Institute of Science and Technology, School of Computing, Daejeon, South Korea; Yoon, H., Korea Advanced Institute of Science and Technology, School of Computing, Daejeon, South Korea; Choi, D., Kongju National University, Department of Medical Information, Gongju-si, South Korea","Deep neural networks (DNNs) exhibit excellent performance in machine learning tasks such as image recognition, pattern recognition, speech recognition, and intrusion detection. However, the usage of adversarial examples, which are intentionally corrupted by noise, can lead to misclassification. As adversarial examples are serious threats to DNNs, both adversarial attacks and methods of defending against adversarial examples have been continuously studied. Zero-day adversarial examples are created with new test data and are unknown to the classifier; hence, they represent a more significant threat to DNNs. To the best of our knowledge, there are no analytical studies in the literature of zero-day adversarial examples with a focus on attack and defense methods through experiments using several scenarios. Therefore, in this study, zero-day adversarial examples are practically analyzed with an emphasis on attack and defense methods through experiments using various scenarios composed of a fixed target model and an adaptive target model. The Carlini method was used for a state-of-the-art attack, while an adversarial training method was used as a typical defense method. We used the MNIST dataset and analyzed success rates of zero-day adversarial examples, average distortions, and recognition of original samples through several scenarios of fixed and adaptive target models. Experimental results demonstrate that changing the parameters of the target model in real time leads to resistance to adversarial examples in both the fixed and adaptive target models. © 2018 Association for Computing Machinery.","Adversarial example; Adversarial training; Deep neural network (DNN); Zero-day adversarial examples","Image recognition; Intrusion detection; Network security; Speech recognition; Adversarial example; Analytical studies; Attack analysis; Misclassifications; Original sample; State of the art; Training methods; Zero days; Deep neural networks",,,,,"Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) ICLR; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium on, pp. 39-57. , IEEE; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387. , IEEE; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR; Shen, S., Jin, G., Gao, K., Zhang, Y., (2017) Ae-Gan: Adversarial Eliminating with Gan, , arXiv preprint arXiv:1707.05474; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Security and Privacy (SP), 2016 IEEE Symposium on, pp. 582-597. , IEEE",,,"ACM SIGSAC","Association for Computing Machinery, Inc","13th ACM Symposium on Information, Computer and Communications Security, ASIACCS 2018","4 June 2018 through 8 June 2018",,136866,,9781450355766,,,"English","ASIACCS - Proc. ACM Asia Conf. Comput. Commun. Secur.",Conference Paper,"Final","",Scopus,2-s2.0-85049170600
"Hu H., Liu Y., Zhang H., Pan R.","56784727600;36071900900;37007258200;57205716051;","Optimal Network Defense Strategy Selection Based on Incomplete Information Evolutionary Game",2018,"IEEE Access","6",,,"29806","29821",,28,"10.1109/ACCESS.2018.2841885","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047792020&doi=10.1109%2fACCESS.2018.2841885&partnerID=40&md5=8798c6fbfc3523c4de6a93484efb1f16","China National Digital Switching System Engineering and Technological Research Center, Zhengzhou, 450001, China; Trusted Computing and Information Assurance Laboratory, Institute of Software, Chinese Academy of Sciences, Beijing, 450001, China","Hu, H., China National Digital Switching System Engineering and Technological Research Center, Zhengzhou, 450001, China, Trusted Computing and Information Assurance Laboratory, Institute of Software, Chinese Academy of Sciences, Beijing, 450001, China; Liu, Y., China National Digital Switching System Engineering and Technological Research Center, Zhengzhou, 450001, China; Zhang, H., China National Digital Switching System Engineering and Technological Research Center, Zhengzhou, 450001, China, Trusted Computing and Information Assurance Laboratory, Institute of Software, Chinese Academy of Sciences, Beijing, 450001, China; Pan, R., China National Digital Switching System Engineering and Technological Research Center, Zhengzhou, 450001, China, Trusted Computing and Information Assurance Laboratory, Institute of Software, Chinese Academy of Sciences, Beijing, 450001, China","The issue of selecting the optimal defense strategy in the dynamic adversarial network is difficult. To solve this problem, we start from the realistic bounded rationality of both the attacker and the defender. First, we build the Bayesian attack-defense evolutionary game model combining with incomplete information game scenario. Specifically, we convert the uncertainty of the strategy payoffs of attackers and defenders to the uncertainty of their related types. Meanwhile, both the set of player types and the set of game strategies can be expanded to $n$ in our model. Furthermore, we improve the replicator dynamics equation by adding the selecting intensity factor to depict the noise effect. This reflects the randomness of decision making for players due to their bounded learning capacities. In this way, the static analysis in the traditional game is extended as a dynamic process. On this basis, we summarize the evolutions of different player types with different strategies. Finally, by calculating the evolutionary stable equilibrium, we give the algorithm of selecting optimal defense strategy and depict the evolutionary track of this strategy selected by the defender with time going by. Our method provides decision support for the network proactive defense toward moderate security. Moreover, the dynamic analysis efficiency of defense decision making is improved, and the predicting ability of the defense situation is enhanced. Experimental results verify the scientificity and availability of the proposed model and method. © 2013 IEEE.","bounded rationality; evolutionary game; incomplete information; Network attack-defense; optimal defense strategy","Behavioral research; Decision making; Decision support systems; Game theory; Mathematical models; Static analysis; Telecommunication networks; Bounded rationality; Defense strategy; Evolutionary games; Games; Incomplete information; Network attack; Security; Uncertainty; Network security",,,,,"Do, C.T., Game theory for cyber security and privacy (2017) ACM Comput. Surv., 50 (2); Jiang, W., Fang, B., Tian, Z., Zhang, H., Research on defense strategies selection based on attack-defense stochastic game model (2010) Chin. J. Com-put. Res. Develop., 47 (10), pp. 1714-1723; Jiang, W., Fang, B.-X., Tian, Z.-H., Zhang, H.-L., Evaluating network security and optimal active defense based on attack-defense game model (2009) Chin. J. Comput., 32 (4), pp. 817-827; Li, Y., Quevedo, D.E., Dey, S., Shi, L., A game-theoretic approach to fake-acknowledgment attack on cyber-physical systems (2017) IEEE Trans. Signal Inf. Process. Netw., 3 (1), pp. 1-11. , Mar; Agah, A., Das, S.K., Preventing DoS attacks in wireless sensor networks: A repeated game theory approach (2007) Int. J. Netw. Secur., 5 (2), pp. 145-153; Esmalifalak, M., Shi, G., Han, Z., Song, L., Bad data injection attack and defense in electricity market using game theory study (2013) IEEE Trans. Smart Grid, 4 (1), pp. 160-169. , Mar; Wu, J., Ota, K., Dong, M., Li, J., Wang, H., Big data analysis based security situational awareness for smart grid IEEE Trans. Big Data, , https://ieeexplore.ieee.org/document/7587350/, to be published; Serra, E., Jajodia, S., Pugliese, A., Rullo, A., Subrahmanian, V.S., Pareto-optimal adversarial defense of enterprise systems (2015) ACM Trans. Inf. Syst. Secur., 17 (3); Wang, Y.-Z., Lin, C., Cheng, X.-Q., Fang, B.-X., Analysis for network attack-defense based on stochastic game model (2010) Chin. J. Comput., 33 (9), pp. 1748-1762; Liu, Y., Feng, D., Wu, L., Performance evaluation of worm attack and defense strategies based on static Bayesian game (2012) Chin. J. Softw., 23 (3), pp. 712-723; Zhang, H., Yu, D., Hang, J., Defense policies selection method based on attack-defense signaling game model (2016) J. Commun., 37 (5), pp. 39-49; Liu, J., Zhang, H., Liu, Y., Research on optimal selection of moving tar-get defense policy based on dynamic game with incomplete Information (2018) Acta Electron. Sinica, 46 (1), pp. 82-89; Patcha, A., Park, J.M., A game theoretic formulation for intrusion detection in mobile ad hoc networks (2006) Int. J. Netw. Secur., 2 (2), pp. 131-137; Rass, S., Alshawish, A., Abid, M.A., Schauer, S., Zhu, Q., De Meer, H., Physical intrusion games Optimizing surveillance by simulation and game theory (2017) IEEE Access, 5, pp. 8394-8407; Liu, J.H., Yu, J., Shen, S., Energy-efficient two-layer cooperative defense scheme to secure sensor-clouds (2018) IEEE Trans. Inf. Forensics Secu-rity, 13 (2), pp. 408-420. , Feb; Zhu, J., Song, B., Huang, Q., Evolution game model of offense-defense for network security based on system dynamics (2014) J. Commun., 25 (1), pp. 54-61; Huang, J., Zhang, H., Wang, J., Markov evolutionary games for net-work defense strategy selection (2017) IEEE Access, 5, pp. 19505-19516; Huang, J., Zhang, H., Wang, J., Defense strategies selection based on attack-defense evolutionary game model (2017) J. Commun., 38 (1), pp. 168-176; Hayel, Y., Zhu, Q., Epidemic protection over heterogeneous networks using evolutionary Poisson games (2017) IEEE Trans. Inf. Forensics Security, 12 (8), pp. 1786-1800. , Aug; Chen, B.-S., Yeh, C.-H., Stochastic noncooperative and coopera-tive evolutionary game strategies of a population of biological networks under natural selection (2017) Biosystems, 162, pp. 90-118. , Dec; Liu, P.H., Liu, J., Robustness of coevolution in resolving prisoner's dilemma games on interdependent networks subject to attack (2017) Phys. A, Stat. Mech. Appl., 479, pp. 362-370. , Aug; Du, J., Jiang, C., Chen, K.-C., Ren, Y., Poor, H.V., Community-structured evolutionary game for privacy protection in social networks (2018) IEEE Trans. Inf. Forensics Security, 13 (3), pp. 574-589. , Mar; Jiang, C., Chen, Y., Liu, K.J.R., Evolutionary dynamics of information diffusion over social networks (2014) IEEE Trans. Signal Process., 62 (17), pp. 4573-4586. , Sep; Jiang, C., Chen, Y., Liu, K.R., Graphical evolutionary game for information diffusion over social networks (2014) IEEE J. Sel. Topics Signal Process., 8 (4), pp. 524-536. , Aug; Wang, Y., Yu, J., Qiu, W., Evolutionary game model and analysis methods for network population behavior (2015) Chin. J. Comput., 38 (2), pp. 282-300; Harsanyi, J.C., Games with incomplete information played by Bayesian' players (1982) Papers in Game Theory (Theory and Decision Library), 28. , https://doi.org/10.1007/978-94-017-2527-9-7, Dordrecht, The Netherlands: Springer; Sigmund, K., Nowak, M.A., Evolutionary game theory (1997) Cur-rent Biology CB, 38, pp. 847-858. , Cambridge, MA, USA: MIT Press; Tanimoto, J., (2015) Fundamentals of Evolutionary Game Theory and Its Applications (Evolutionary Economics and Social Complexity Science), , http://ktlabo.cm.kyushu-u.ac.jp/j_old/event/productFlyer_978-4-431-54961-1.pdf, Tokyo, Japan: Springer; Liu, Y., Comaniciu, C., Man, H., A Bayesian game approach for intrusion detection in wireless ad hoc networks (2006) Proc. ACM Workshop Game Theory Commun. Netw., , https://doi.org/10.1145/1190195.1190198; Wang, X.-J., Quan, J., Liu, W.-B., Study on evolutionary games and cooperation mechanism within the framework of bounded rationality (2011) Syst. Eng. Theory Pract., 31, pp. 82-93; Gordon, L.A., Loeb, M.P., Lucyshyn, W., Richardson, R., CSI/FBI computer crime and security survey (2006) Inf. Manage. Comput. Secur., 15 (3), pp. 78-101","Liu, Y.; China National Digital Switching System Engineering and Technological Research CenterChina; email: ylliu@tca.iscas.ac.cn",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85047792020
"Kumar S., Viinikainen A., Hamalainen T.","57202479570;35613325100;56899176100;","A network-based framework for mobile threat detection",2018,"Proceedings - 2018 1st International Conference on Data Intelligence and Security, ICDIS 2018",,,,"227","233",,5,"10.1109/ICDIS.2018.00044","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048548559&doi=10.1109%2fICDIS.2018.00044&partnerID=40&md5=19aeed5ba17b644b74cf961cb8eb670f","Faculty of Information Technology, University of Jyvaskyla, Jyvaskyla, Finland","Kumar, S., Faculty of Information Technology, University of Jyvaskyla, Jyvaskyla, Finland; Viinikainen, A., Faculty of Information Technology, University of Jyvaskyla, Jyvaskyla, Finland; Hamalainen, T., Faculty of Information Technology, University of Jyvaskyla, Jyvaskyla, Finland","Mobile malware attacks increased three folds in the past few years and continued to expand with the growing number of mobile users. Adversary uses a variety of evasion techniques to avoid detection by traditional systems, which increase the diversity of malicious applications. Thus, there is a need for an intelligent system that copes with this issue. This paper proposes a machine learning (ML) based framework to counter rapid evolution of mobile threats. This model is based on flow-based features, that will work on the network side. This model is designed with adversarial input in mind. The model uses 40 time-based network flow features, extracted from the real-Time traffic of malicious and benign applications. The proposed model not only to detects the known and unknown mobile threats but also deals with the changing behavior of the attackers by triggering the retraining phase. The proposed framework can be used by the mobile operators to protect their subscribers. We used several supervised ML algorithms to build the model and got an average accuracy of up to 99.8. © 2018 IEEE.","Anomaly detection; Concept-drift; Intrusion Detection; Machine Learning; Mobile Threats","Intelligent systems; Intrusion detection; Learning systems; Anomaly detection; Concept drifts; Mobile operators; Mobile Threats; Network-based framework; Real time traffics; Threat detection; Traditional systems; Malware",,,,,"(2017) Mobile Phone Users Worldwide 2013-2019, , https://www.statista.com/statistics/274774/forecast-of-mobile-phone-users-worldwide, Statista Tech. Rep., Access Date 30 Nov; (2017) Smartphone Os Market Share, 2017 q1, , https://www.idc.com/promo/smartphone-market-share/os, IDC, Tech. Rep., Access Date 30 Nov; (2017) Trojans, Ghosts, and More Mean Bumps Ahead for Mobile and Connected Things (What Lies Ahead for 2017), , https://www.mcafee.com/us/resources/reports/rp-mobile-Threat-report-2017.pdf, McAfee Tech. Rep, Access Date 30 Nov, 2017; Timm, K., (2017) Strategies to Reduce False Positives and False Negatives in Nids, , http://www.symantec.com/connect/articles/strategies-reduce-false-positives-And-false-negatives-nids, Tech. Rep 2001, Access Date 10 Sep; Julisch, K., Dacier, M., Mining intrusion detection alarms for actionable knowledge (2002) Proceedings of the Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining-KDD, 2. , Association for Computing Machinery ACM; Koch, R., Towards next-generation intrusion detection (2011) Cyber Conflict (ICCC) 2011 3rd International Conference on, pp. 1-18. , IEEE; Copeland, J.A., III, (2007) Flow-based Detection of Network Intrusions, , Feb. 27 uS Patent 7 185 368; (2017) Malware Detection and Subscriber Protection Infographic, , https://networks.nokia.com/solutions/security-guardian-infographic, Nokia, Tech. Rep., Access Date 30 Nov; Narudin, F.A., Feizollah, A., Anuar, N.B., Gani, A., Evaluation of machine learning classifiers for mobile malware detection (2014) Soft Comput, , nov; Arp, D., Spreitzenbarth, M., Hübner, M., Gascon, H., Rieck, K., Siemens, C., Drebin: Effective and explainable detection of android malware in your pocket (2014) Proceedings of the Annual Symposium on Network and Distributed System Security (NDSS; Feizollah, A., Anuar, N.B., Salleh, R., Amalina, F., Maarof, R.R., Shamshirband, S., A study of machine learning classifiers for anomaly-based mobile botnet detection (2014) Malaysian Journal of Computer Science, 26 (4); Su, X., Chuah, M.C., Tan, G., Smartphone dual defense protection framework: Detecting malicious applications in android markets (2012) Mobile Ad-hoc and Sensor Networks (MSN) 2012 Eighth International Conference on, pp. 153-160. , IEEE; Kumar, S., Viinikainen, A., Hamalainen, T., Machine learning classification model for network based intrusion detection system (2016) Proc. 11th Int. Conf. for Internet Technology and Secured Transactions (ICITST, pp. 242-249. , Dec; Wang, S., Chen, Z., Zhang, L., Yan, Q., Yang, B., Peng, L., Jia, Z., Trafficav: An effective and explainable detection of mobile malware behavior using network traffic (2016) Quality of Service (IWQoS) 2016 IEEE/ACM 24th International Symposium On. IEEE, pp. 1-6; Zhou, Y., Jiang, X., Dissecting android malware: Characterization and evolution (2012) Security and Privacy (SP) 2012 IEEE Symposium on, pp. 95-109. , IEEE; Zhao, D., Traore, I., Sayed, B., Lu, W., Saad, S., Ghorbani, A., Garant, D., Botnet detection based on traffic behavior analysis and flow intervals (2013) Computers & Security, 39, pp. 2-16; Stevanovic, M., Pedersen, J.M., An efficient flowbased botnet detection using supervised machine learning (2014) Computing, Networking and Communications (ICNC )2014 International Conference on, pp. 797-801. , IEEE; Livadas, C., Walsh, R., Lapsley, D., Strayer, W.T., Usilng machine learning technliques to identify botnet traffic (2006) Local Computer Networks, Proceedings 2006 31st IEEE Conference On. IEEE, pp. 967-974; Kowsalya, S.S., Website Fingerprinting Using Traffic Analysis Attacks; Hintz, A., Fingerprinting websites using traffic analysis (2002) International Workshop on Privacy Enhancing Technologies, pp. 171-178. , Springer; Virustotal.com, , https://www.virustotal.com/; Lindorfer, M., Neugschwandtner, M., Weichselbaum, L., Fratantonio, Y., Veen, V.V.D., Platzer, C., Andrubis-1, 000, 000 Apps later: A view on current android malware behaviors (2014) Proc. Third Int. Workshop Building Analysis Datasets and Gathering Experience Returns for Security (BADGERS, pp. 3-17. , Sep; Digit Oktavianto, I.M., (2013) Cuckoo Malware Analysis. Packt Publishing; Trammell, B.H., Boschi, E., (2015) Bidirectional Flow Export Using IP Flow Information Export (IPfix) : Rfc-5103, , https://tools.ietf.org/html/rfc5103.html, IETF, Tech. Rep., Access Date 01 Jan; Boschi, E., Trammell, B., (2006) Bidirectional Flow Measurement, Ipfix, and Security Analysis; Kumar, S., Viinikainen, A., Hamalainen, T., Evaluation of ensemble machine learning methods in mobile threat detection (2017) Proc. 12th Int. Conf. for Internet Technology and Secured Transactions (ICITST), , in press. Dec; Barreno, M., Nelson, B., Sears, R., Joseph, A.D., Tygar, J.D., Can machine learning be secure? (2006) Proceedings of the 2006 ACM Symposium on Information, Computer and Communications Security, pp. 16-25. , ACM; Kloft, M., Laskov, P., Security analysis of online centroid anomaly detection (2012) Journal of Machine Learning Research, 13, pp. 3681-3724. , Dec; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I., Tygar, J., Adversarial machine learning (2011) Proceedings of the 4th ACM Workshop on Security and Artificial Intelligence. ACM, pp. 43-58; Newsome, J., Karp, B., Song, D., Paragraph: Thwarting signature learning by training maliciously (2006) International Workshop on Recent Advances in Intrusion Detection, pp. 81-105. , Springer; Provost, F.J., Fawcett, T., Kohavi, R., The case against accuracy estimation for comparing induction algorithms (1998) ICML, 98, pp. 445-453; Quinlan, R., (1993) 4.5: Programs for Machine Learning Morgan Kaufmann Publishers Inc, , an Francisco, USA; (2017) Cross-validation: Evaluating Estimator Performance, , http://scikit-learn.org/stable/modules/crossvalidation.html, Access Date 30 Nov",,,"Computer Science Department, The University of Texas Rio Grande Valley","Institute of Electrical and Electronics Engineers Inc.","1st International Conference on Data Intelligence and Security, ICDIS 2018","8 April 2018 through 10 April 2018",,136735,,9781538657621,,,"English","Proc. - Int. Conf. Data Intell. Secur., ICDIS",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85048548559
"Brown A.J., Andel T.R., Yampolskiy M., McDonald J.T.","57189321546;14047854100;22036716900;36027126600;","CAn authorization using message priority bit-level access control",2018,"Proceedings - 2018 1st International Conference on Data Intelligence and Security, ICDIS 2018",,,,"1","8",,4,"10.1109/ICDIS.2018.00008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048547848&doi=10.1109%2fICDIS.2018.00008&partnerID=40&md5=2e84dc87a038facd7423abc68bbdf715","School of Computing, University of South Alabama, Mobile, Alabama  36688, United States","Brown, A.J., School of Computing, University of South Alabama, Mobile, Alabama  36688, United States; Andel, T.R., School of Computing, University of South Alabama, Mobile, Alabama  36688, United States; Yampolskiy, M., School of Computing, University of South Alabama, Mobile, Alabama  36688, United States; McDonald, J.T., School of Computing, University of South Alabama, Mobile, Alabama  36688, United States","The controller area network (CAN) is widely used to interconnect electronic components of cyber-physical systems, such as automobiles. It was designed to suffice near-real-Time requirements, which makes it an attractive choice for the transportation industry. However, CAN lacks means to authenticate transmitted messages and as such is vulnerable to a variety of attacks. In this paper, we consider a scenario in which one node is compromised and is sending illicit messages across the bus. We propose a solution that leverages the existing CAN specifications by employing the standards error handling and fault confinement properties to enforce authorization. The proposed solution limits the efficacy of an adversarial node on the network, without negatively affecting bit time during normal operations or compliance with the base standard. Our analysis shows that a malicious node can be identified and denied access to the bus after 37 consecutive messages. For even the slowest bus speeds of 10kbps, our solution reduces the downtime experienced from a denial of service attack to be less than one second. © 2018 IEEE.","Access control; Authorization; Automobile; CAN; Controller area network; Resilience; Robustness; Security","Access control; Automobiles; Buses; Control system synthesis; Controllers; Denial-of-service attack; Embedded systems; Process control; Regulatory compliance; Robustness (control systems); Authorization; Controller area network; Electronic component; Fault confinement; Normal operations; Resilience; Security; Transportation industry; Network security",,,,,"Corrigan, S., Introduction to the controller area network (can) (2008) Texas Instruments, Tech. Rep. Application Report SLOA101A; Hoppe, T., Kiltz, S., Dittmann, J., Security threats to automotive can networks-practical examples and selected short-Term countermeasures (2008) Proc. of the 27th International Conference on Computer Safety, Reliability, and Security (SAFECOMP?08, pp. 235-248. , https://dx.doi.org/10.1007/978-3-540-87698-4\21; Kleberger, P., Olovsson, T., Jonsson, E., Security aspects of the in-vehicle network in the connected car (2011) IEEE Symposium on Intelligent Vehicles (IV ?11, pp. 528-533. , https://dx.doi.org/10.1109/IVS.2011.5940525; Lin, C.-W., Sangiovanni-Vincentelli, A., Cyber-security for the controller area network (can) communication protocol (2012) Proc. of the 2012 International Conference on Cyber Security (CYBERSECURITY ?12, pp. 1-7. , https://dx.doi.org/10.1109/CyberSecurity.2012.7; Ueda, H., Kurachi, R., Takada, H., Mizutani, T., Inoue, M., Horihata, S., Security authentication system for in-vehicle network (2015) SEI Technical Review, 81, pp. 5-9; Groza, B., Murvay, S., Efficient protocols for secure broadcast in controller area networks (2013) IEEE Transactions on Industrial Informatics, 9 (4), pp. 2034-2042. , https://dx.doi.org/10.1109/TII.2013.2239301; Checkoway, S., McCoy, D., Kantor, B., Anderson, D., Shacham, H., Savage, S., Koscher, K., Kohno, T., Comprehensive experimental analyses of automotive attack surfaces (2011) Proc. of the 20th USENIX Conference on Security (SEC?11; Koscher, K., Czeskis, A., Roesner, F., Patel, S., Kohno, T., Checkoway, S., McCoy, D., Savage, S., Experimental security analysis of a modern automobile (2010) Proc. of the 2010 IEEE Symposium on Security and Privacy (SP ?10, pp. 447-462. , https://dx.doi.org/10.1109/SP.2010.34; Larson, U.E., Nilsson, D.K., Jonsson, E., An approach to specification-based attack detection for in-vehicle networks (2008) Proc. of the 2008 IEEE Symposium on Intelligent Vehicles (IV ?08, pp. 220-225. , https://dx.doi.org/10.1109/IVS.2008, 4621263; Foster, I., Koscher, K., Exploring Controller Area Networks, , login; Carsten, P., Andel, T.R., Yampolskiy, M., McDonald, J.T., (2015) Vehicle Networks: Attacks, Vulnerabilities, and Proposed Solutions, , https://doi.org/10.1145/2746266.2746267; Carsten, P., Andel, T.R., Yampolskiy, M., McDonald, J.T., Russ, S., A system to recognize intruders in controller area network (can) (2015) Proc. of the 3rd International Symposium for ICS & SCADA Cyber Security Research (ICS-CSR ?15, pp. 111-114. , https://doi.org/10.14236/ewic/ICS2015.15; Lin, C.-W., Zhu, Q., Phung, C., Sangiovanni-Vincentelli, A., Securityaware mapping for can-based real-Time distributed automotive systems (2013) Proc. of the International Conference on Computer-Aided Design (ICCAD ?13; Patsakis, C., Dellios, K., Bouroche, M., Towards a distributed secure in-vehicle communication architecture for modern vehicles (2014) Computer Security, 40, pp. 60-74. , https://doi.org/10.1016/j.cose.2013.11.003, feb",,,"Computer Science Department, The University of Texas Rio Grande Valley","Institute of Electrical and Electronics Engineers Inc.","1st International Conference on Data Intelligence and Security, ICDIS 2018","8 April 2018 through 10 April 2018",,136735,,9781538657621,,,"English","Proc. - Int. Conf. Data Intell. Secur., ICDIS",Conference Paper,"Final","",Scopus,2-s2.0-85048547848
"Servia-Rodriguez S., Wang L., Zhao J.R., Mortier R., Haddadi H.","55135807400;55695097200;57192980932;6701782778;24766186400;","Privacy-preserving personal model training",2018,"Proceedings - ACM/IEEE International Conference on Internet of Things Design and Implementation, IoTDI 2018",,,,"153","164",,11,"10.1109/IoTDI.2018.00024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048481749&doi=10.1109%2fIoTDI.2018.00024&partnerID=40&md5=7e535f5b402f9bdee809f4f75bf4174c","Department of Computer Science and Technology, Univery of Cambrdge, United Kingdom; Dyson School of Desgn Engineering, Imperial College London, United Kingdom","Servia-Rodriguez, S., Department of Computer Science and Technology, Univery of Cambrdge, United Kingdom; Wang, L., Department of Computer Science and Technology, Univery of Cambrdge, United Kingdom; Zhao, J.R., Department of Computer Science and Technology, Univery of Cambrdge, United Kingdom; Mortier, R., Department of Computer Science and Technology, Univery of Cambrdge, United Kingdom; Haddadi, H., Dyson School of Desgn Engineering, Imperial College London, United Kingdom","Many current Internet services rely on inferences from models trained on user data. Commonly, both the training and inference tasks are carried out using cloud resources fed by personal data collected at scale from users. Holding and using such large collections of personal data in the cloud creates privacy risks to the data subjects, but is currently required for users to benefit from such services. We explore how to provide for model training and inference in a system where computation is pushed to the data in preference to moving data to the cloud, obviating many current privacy risks. Specifically, we take an initial model learnt from a small set of users and retrain it locally using data from a single user. We evaluate on two tasks: one supervised learning task, using a neural network to recognise users' current activity from accelerometer traces; and one unsupervised learning task, identifying topics in a large set of documents. In both cases the accuracy is improved. We also analyse the robustness of our approach against adversarial attacks, as well as its feasibility by presenting a performance evaluation on a representative resource-constrained device (a Raspberry Pi). © 2018 IEEE.","Algorithms; Machine learning; Privacy","Algorithms; Distributed computer systems; Internet of things; Learning systems; Petroleum reservoir evaluation; Data subjects; Internet services; Model training; Performance evaluations; Personal models; Privacy preserving; Privacy risks; Resourceconstrained devices; Data privacy",,,,,"Falahrastegar, M., Haddadi, H., Uhlig, S., Mortier, R., Tracking personal identifiers across the web (2016) Passive and Active Measurement Conference (PAM 2016; (2017), https://www.arnazon.com/Amazon-Echo-Bluetooth-Speaker-with-WiFi-Alexa/dp/B0OX4WHP5E/,Nodate, accessed May 25; (2017), https://madeby.google.com/home/,Nodate, accessed May 25; (2017), https://www.apple.com/ios/home/,Nodate, accessed May 25; Chaudhry, A., Crowcroft, J., Howard, H., Madhavapeddy, A., Mortier, R., Haddadi, H., McAuley, D., Personal data:Thinking inside the box (2015) Proceedings of the Fifth Decennial Aarhus Conference on Critical Alternatives, Ser. AA '15. Aarhus University Press, pp. 29-32. , http://dx.doi.org/10.7146/aahcc.vlil.21312; Mortier, R., Zhao, J., Crowcroft, J., Wang, L., Li, Q., Haddadi, H., Amar, Y., Greenhalgh, C., Personal data management wiht the Databox:What's inside the box (2016) Proc. Cloud Assisted Networking Workshop at ACM CoNEXT, Dec. 12; (2017), https://www.raspberrypi.org/products/raspberry-pi-3-model-b/,Nodate, accessed February 15; Kwapisz, J.R., Weiss, G.M., Moore, S.A., Activity recognition using cell phone accelerometers (2011) ACM SigKDD Explorations Newsletter, 12 (2), pp. 74-82; Blei, D.M., Ng, A.Y., Jordan, M.I., Latent dirichl et allocation (2003) J. Mach. Learn. Res, 3, pp. 993-1022. , http://dl.acm.org/citation.cfmid=944919.944937, Mar; (2017), https://archive.ics.uci.edu/ml/machine-learning-databases/bag-of-words/, Nips-bag of words data set, No date, accessed January 20; (2017), https://dumps.wikimedia.org/enwiki/latest/, No date, accessed January 20; Weiss, G.M., Lockhart, J.W., The impact of personalization on smartphone-based activity recognition (2012) AAAI Workshop on Activity Context Representation:Techniques and Languages; Shokri, R., Shmatikov, V., Privacy-preserving deep learning (2015) Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security. ACM, pp. 1310-1321; McMahan, H.B., Moore, E., Ramage, D., Hampson, S., (2016) Communication-efficient Learning of Deep Networks from Decentralized Data, , arXiv preprint arXiv:1602.05629; Hamm, J., Cao, P., Belkin, M., Learning privately from multiparty data (2016) Proceedings of the 33rd International Conference on Machine Learning, pp. 555-563; Papernot, N., Abadi, M., Erlingsson, U., Goodfellow, I., Talwar, K., Semi-supervised knowledge transfer for deep learning from private training data (2017) Proceedings of the 5th International Conference on Learning Representations; Meng, X., Bradley, J., Yavuz, B., Sparks, E., Venkataraman, S., Liu, D., Freeman, J., Owen, S., Mllib:Machine learning in apache spark (2016) Journal of Machine Learning Research, 17 (34), pp. 1-7; Low, Y., Bickson, D., Gonzalez, J., Guestrin, C., Kyrola, A., Hellerstein, J.M., Distributed graphlab:A framework for machine learning and data mining in the cloud (2012) Proc. VLDB Endow, 5 (8), pp. 716-727. , https://doi.org/10.14778/2212351.2212354, Apr; (2017) Zeromq-distributed Messaging, , http://zeromq.org,Nodate, accessed January 20; Theano Deep Learning, , http://deeplearning.net/software/theano,Nodate, accessed January 20 2017; (2017), http://scikit-learn.org/, No date, accessed January 20; Wang, L., (2017) Owl:A General-purpose Numerical Library in Ocaml, , http://arxiv.org/abs/1707.09616; Wang, L., Catterall, B., Mortier, R., (2017) Probabilistic Synchronous Parallel, , ArXiv e-prints; He, K., Zhang, X., Ren, S., Sun, J., Delving deep into rectifiers:Surpassing human-level performance on imagenet classification (2015) Proceedings of the IEEE International Conference on Computer Vision, pp. 1026-1034; Nair, V., Hinton, G.E., Rectified linear units improve restricted boltz-mann machines (2010) Proceedings of the 27th International Conference on Machine Learning (ICML-10, pp. 807-814; Hinton, G., A practical guide to training restricted boltzmann machines (2010) Momentum, 9 (1), p. 926; Hofmann, T., Probabilistic latent semantic indexing (1999) Proceedings of the 22Nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, Ser. SIGIR '99, pp. 50-57. , http://doi.acm.org/10.1145/312624.312649, New York, NY, USA:ACM; Wang, L., Tasoulis, S., Roos, T., Kangasharju, J., Kvasir:Scalable provision of semantically relevant web content on big data framework (2016) IEEE Transactions on Big Data, 2 (3), pp. 219-233. , Sept; Hajebi, K., Abbasi-Yadkori, Y., Shahbazi, H., Zhang, H., Fast approximate nearest-neighbor search with k-nearest neighbor graph (2011) Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence-Volume Two, Ser. Ijcai'Ll, pp. 1312-1317. , http://dx.doi.org/10.5591/978-l-57735-516-8/UCAUl-222, AAAI Press; He, J., Liu, W., Chang, S.-F., Scalable similarity search with optimized kernel hashing (2010) Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Ser. KDD '10, pp. 1129-1138. , http://doi.acm.org/10.1145/18358O4.1835946, New York, NY, USA:ACM; Hyvonen, V., Ktkanen, T., Tasoulis, S., Jaasaari, E., Tuomainen, R., Wang, L., Corander, J., Roos, T., Fast nearest neighbor search through sparse random projections and voting (2016) 2016 IEEE International Conference on Big Data (Big Data), pp. 881-888. , Dec; Barreno, M., Nelson, B., Joseph, A.D., Tygar, J., The security of machine learning (2010) Machine Learning, 81 (2), pp. 121-148; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I., Tygar, J., Adversarial machine learning (2011) Proceedings of the 4th ACM Workshop on Security and Artificial Intelligence. ACM, pp. 43-58; Fredrikson, M., Lantz, E., Jha, S., Lin, S., Page, D., Ristenpart, T., Privacy in pharmacogenetics:An end-to-end case study of personalized warfarin dosing (2014) USENIX Security, pp. 17-32; Shokri, R., Stronati, M., Shmatikov, V., Membership inference attacks against machine learning models (2017) Proceedings of the 38th IEEE Symposium on Security and Privacy; Bonomi, F., Milito, R., Zhu, J., Addepalli, S., Fog computing and its role in the internet of things (2012) Proceedings of the First Edition of the MCC Workshop on Mobile Cloud Computing, Ser. MCC '12, pp. 13-16. , http://doi.acm.org/10.1145/2342509.2342513, New York, NY, USA:ACM; Chen, C.P., Zhang, C.-Y., Data-intensive applications, challenges, techniques and technologies:A survey on big data (2014) Information Sciences, 275, pp. 314-347. , http://www.sciencedirect.com/science/article/pii/S0020025514000346; Wu, X., Zhu, X., Wu, G.Q., Ding, W., Data mining with big data (2014) IEEE Transactions on Knowledge and Data Engineering, 26 (1), pp. 97-107. , Jan; Brandimarte, L., Acquisti, A., Loewenstein, G., Misplaced confidences (2013) Social Psychological and Personality Science, 4 (3), pp. 340-347; Agrawal, R., Srikant, R., Privacy-preserving data mining (2000) Proceedings of the 2000 ACM SIGMOD International Conference on Management of Data, Set. SIGMOD '00, pp. 439-450. , http://doi.acm.org/10.1145/342009.335438, New York, NY, USA:ACM; Aggarwal, C.C., Philip, S.Y., A general survey of privacy-preserving data mining models and algorithms (2008) Privacy-preserving Data Mining. Springer, pp. 11-52; Erkin, Z., Troncoso-Pastoriza, J.R., Lagendijk, R.L., Perez-Gonzalez, F., Privacy-preserving data aggregation in smart metering systems:an overview (2013) IEEE Signal Processing Magazine, 30 (2), pp. 75-86. , March; Bellala, G., Huberman, B., Securing private data sharing in multiparty analytics (2016) First Monday, 21 (9). , http://www.firetmonday.dk/ojs/index.php/fm/article/view/6842; Sarwate, A.D., Chaudhuri, K., Signal processing and machine learning with differential privacy:Algorithms and challenges for continuous data (2013) IEEE Signal Processing Magazine, 30 (5), pp. 86-94; Song, S., Chaudhuri, K., Sarwate, A.D., Stochastic gradient descent with differentially private updates (2013) Global Conference on Signal and Information Processing (GlobalSIP), 2013 IEEE. IEEE, p. 245248; Chaudhuri, K., Monteleoni, C., Sarwate, A.D., Differentially private empirical risk minimization (2011) Journal of Machine Learning Research, 12, pp. 1069-1109. , Mar; Abadi, M., Chu, A., Goodfellow, I., McMahan, H.B., Mironov, I., Talwar, K., Zhang, L., Deep learning with differential privacy (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security. ACM, pp. 308-318; Dwork, C., Differential privacy:A survey of results (2008) International Conference on Theory and Applications of Models of Computation. Springer, pp. 1-19; Li, M., Andersen, D.G., Smola, A.J., Yu, K., Communication efficient distributed machine learning with the parameter server (2014) Advances in Neural Information Processing Systems, pp. 19-27; Cormen, T.H., Goodrich, M.T., (1996) A bridging model for parallel computation, communication, and i/o, 28 (4), p. 208. , ACM Computing Surveys (CSUR); Agarwal, A., Duchi, J.C., Distributed delayed stochastic optimization (2011) Advances in Neural Information Processing Systems, pp. 873-881; Ho, Q., Cipar, J., Cui, H., Lee, S., Kim, J.K., Gibbons, P.B., Gibson, G.A., Xing, E.P., More effective distributed ml via a stale synchronous parallel parameter server (2013) Advances in Neural Information Processing Systems, pp. 1223-1231; Low, Y., Bickson, D., Gonzalez, J., Guestrin, C., Kyrola, A., Hellerstein, J.M., Distributed graphlab:a framework for machine learning and data mining in the cloud (2012) Proceedings of the VLDB Endowment, 5 (8), pp. 716-727; Hitaj, B., Ateniese, G., Perez-Cruz, F., Deep Models under the GAN:information Leakage from Collaborative Deep Learning, , http://arxiv.org/abs/1702.07464, CoRR vl. abs/1702.07464, 2017; Jain, S., Tiwari, V., Balasubramanian, A., Balasubramanian, N., Chakraborty, S., Pria:A private intelligent assistant (2017) Proceedings of the 18th International Workshop on Mobile Computing Systems and Applications, Ser. HotMobile '17, pp. 91-96. , http://doi.acm.org/10.1145/3032970.3032988, New York, NY, USA:ACM; Pan, S.J., Yang, Q., A survey on transfer learning (2010) IEEE Transactions on Knowledge and Data Engineering, 22 (10), p. 13451359; Shi, W., Cao, J., Zhang, Q., Li, Y., Xu, L., Edge computing:Vision and challenges (2016) IEEE Internet of Things Journal, 3 (5), pp. 637-646; Georgiev, P., Lane, N.D., Rachuri, K.K., Mascolo, C., Dsp. Ear:Leveraging co-processor support for continuous audio sensing on smartphones (2014) Proceedings of the 12th ACM Conference on Embedded Network Sensor Systems. ACM, pp. 295-309; Leo:Scheduling sensor inference algorithms across heterogeneous mobile processors and network resources (2016) Proceedings of the Annual International Conference on Mobile Computing and Networking, MOBICOMno. CONFCODE. ACM, pp. 320-333. , http://dx.doi.org/10.1177/1948550612455931",,,"ACM;IEEE;IEEE Computer Society;SIGBED","Institute of Electrical and Electronics Engineers Inc.","3rd ACM/IEEE International Conference on Internet of Things Design and Implementation, IoTDI 2018","17 April 2018 through 20 April 2018",,136740,,9781538663127,,,"English","Proc. - ACM/IEEE Int. Conf. Internet Things Des. Implement., IoTDI",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85048481749
"Alshinina R., Elleithy K.","56026317800;35576221100;","A highly accurate machine learning approach for developing wireless sensor network middleware",2018,"Wireless Telecommunications Symposium","2018-April",,,"1","7",,7,"10.1109/WTS.2018.8363955","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048171795&doi=10.1109%2fWTS.2018.8363955&partnerID=40&md5=659ffea86aa3b332b5dec6879083a487","Department of Computer Science and Engineering, University of Bridgeport, Bridgeport, CT, United States","Alshinina, R., Department of Computer Science and Engineering, University of Bridgeport, Bridgeport, CT, United States; Elleithy, K., Department of Computer Science and Engineering, University of Bridgeport, Bridgeport, CT, United States","Despite the popularity of wireless sensor networks (WSNs) in a wide range of applications, security problems associated with them have not been completely resolved. Middleware is generally introduced as an intermediate layer between WSNs and the end user to resolve some limitations, but most of the existing middleware is unable to protect data from malicious and unknown attacks during transmission. This paper introduces an intelligent middleware based on an unsupervised learning technique called Generative Adversarial Networks (GANs) algorithm. GANs contain two networks: a generator (G) network and a detector (D) network. The G creates fake data similar to the real samples and combines it with real data from the sensors to confuse the attacker. The D contains multi-layers that have the ability to differentiate between real and fake data. The output intended for this algorithm shows an actual interpretation of the data that is securely communicated through the WSN. The framework is implemented in Python with experiments performed using Keras. Results illustrate that the suggested algorithm not only improves the accuracy of the data but also enhances its security by protecting data from adversaries. Data transmission from the WSN to the end user then becomes much more secure and accurate compared to conventional techniques. © 2018 IEEE.","confusion matrix; detector; GANs; generator; Middleware; security; unsupervised learning; visualization; WSNs","Detectors; Flow visualization; Middleware; Network security; Unsupervised learning; Confusion matrices; GANs; generator; security; WSNs; Wireless sensor networks",,,,,"Bispo, K., Rosa, N., Cunha, P., SITRUS: Semantic infrastructure for wireless sensor networks (2015) Sensors, 15 (11), p. 27436; Xu, G., Shen, W., Wang, X., Applications of wireless sensor networks in marine environment monitoring: A survey (2014) Sensors, 14 (9), p. 16932; Hadim, S., Mohamed, N., Middleware for wireless sensor networks: A survey (2006) 1st International Conference on Communication Systems Software & Middleware, pp. 1-7. , New Delhi, India, 8-12 Jan; Alshinina, R., Elleithy, K., Performance and challenges of service-oriented architecture for wireless sensor networks (2017) Sensors, 17 (3), p. 536; Al-Jaroodi, J., Al-Dhaheri, A., Security issues of service-oriented middleware (2011) International Journal of Computer Science and Network Security, 11 (1), pp. 153-160; Shchzad, A., Hung Quoc, N., Lee, S.Y., Young-Koo, L., A comprehensive middleware architecture for context-aware ubiquitous computing systems (2005) Fourth Annual ACIS International Conference on Computer and Information Science (ICIS'05), pp. 251-256. , Jeju Island, South Korea, 14-16 July; Wang, Y., Attebury, G., Ramamurthy, B., A survey of security issues in wireless sensor networks (2006) IEEE Communications Surveys & Tutorials, pp. 2-23. , Second Quarter 2006; Law, Y.W., Doumen, J., Hartel, P., Benchmarking block ciphers for wireless sensor networks (2004) Mobile Ad-hoc and Sensor Systems, 2004 IEEE International Conference on, pp. 447-456. , Fort Lauderdale, FL, USA, IEEE; Newsome, J., Shi, E., Song, D., Perrig, A., The sybil attack in sensor networks: Analysis & defenses (2004) Proceedings of the 3rd International Symposium on Information Processing in Sensor Networks, , presented at the Berkeley, California, USA; Pirzada, A.A., McDonald, C., Secure routing with the AODV protocol (2005) Communications, 2005 Asia-Pacific Conference on, pp. 57-61. , Perth, WA, Australia, IEEE; Bhargava, S., Agrawal, D.P., Security enhancements in AODV protocol for wireless ad hoc networks (2001) Vehicular Technology Conference, 2001. VTC 2001 Fall. IEEE VTS 54th, 4, pp. 2143-2147. , Atlantic City, NJ, USA IEEE; Capkun, S., Hubaux, J.-P., Secure positioning of wireless devices with application to sensor networks (2005) INFOCOM 2005. 24th Annual Joint Conference of the IEEE Computer and Communications Societies. Proceedings IEEE, 3, pp. 1917-1928. , Miami, FL, USA IEEE; Shi, E., Perrig, A., Designing secure sensor networks (2004) IEEE Wireless Communications, 11 (6), pp. 38-43. , 20 December 2004; Chen, X., Makki, K., Yen, K., Pissinou, N., Sensor network security: A survey (2009) IEEE Communications Surveys & Tutorials, 11 (2). , 02 June 2009; Standard, U.E., Version-i: Symmetric key cryptosystem using generalized modified vernam cipher method, permutation method and columnar transposition method, satyaki roy, navajit maitra, joyshree nath, shalabh agarwal and asoke nath (2012) Proceedings of IEEE Sponsored National Conference on Recent Advances in Communication, Control and Computing Technology-RACCCT, pp. 29-30; Krishnan, B.S., II, Ramaswamy, M., III, A Novel Security Enhancement Strategy for Improving the Concert of CDMA Based Mobile Ad-Hoc Network; Kaur, A., Kang, S.S., Attacks in wireless sensor network - A review (2016) International Journal of Computer Sciences and Engineering, , May-31; Shinganjude, R.D., Theng, D.P., Inspecting the ways of source anonymity in wireless sensor network (2014) Communication Systems and Network Technologies (CSNT), 2014 Fourth International Conference on, pp. 705-707. , IEEE; Capra, L., MaLM: Machine learning middleware to tackle ontology heterogeneity (2007) Pervasive Computing and Communications Workshops, 2007. PerCom Workshops '07. Fifth Annual IEEE International Conference on, pp. 449-454. , White Plains, NY,USA, IEEE; Avram, T., Oh, S., Hariri, S., Analyzing attacks in wireless ad hoc network with self-organizing maps (2007) Fifth Annual Conference on Communication Networks and Services Research (CNSR '07), pp. 166-175. , Frederlcton, NB, Canada, IEEE; Alsheikh, M.A., Lin, S., Niyato, D., Tan, H.P., Machine learning in wireless sensor networks: Algorithms, strategies, and applications (2014) IEEE Communications Surveys & Tutorials, 16 (4), pp. 1996-2018; Ribeiro, M., Grolinger, K., Capretz, M.A.M., MLaaS: Machine learning as a service (2015) IEEE 14th International Conference on Machine Learning and Applications (ICMLA), pp. 896-902. , Miami, FL, USA; Husain, R., Vohra, D.R., A survey on machine learning in wireless sensor networks International Education and Research Journal, Wireless Sensor Networks(WSNs), Machine Learning Techniques,WSN Applications., 3 (1). , 2017-01-16 2017; Janakiram, D., Reddy, V.A., Kumar, A.V.U.P., Outlier detection in wireless sensor networks using Bayesian belief networks (2006) 1st International Conference on Communication Systems Software & Middleware, pp. 1-6. , New Delhi, India, IEEE; Branch, J., Szymanski, B., Giannella, C., Ran, W., Kargupta, H., In-network outlier detection in wireless sensor networks (2006) 26th IEEE International Conference on Distributed Computing Systems (ICDCS'06), p. 51. , Lisboa, Portugal, Portugal; Kaplantzis, S., Shilton, A., Mani, N., Sekercioglu, Y.A., Detecting selective forwarding attacks in wireless sensor networks using support vector machines (2007) 3rd International Conference on Intelligent Sensors, Sensor Networks and Information, pp. 335-340. , Melbourne, Qld., Australia IEEE; Rajasegarar, S., Leckie, C., Palaniswami, M., Bezdek, J.C., Quarter sphere based distributed anomaly detection in wireless sensor networks (2007) IEEE International Conference on Communications, pp. 3864-3869. , Glasgow, UK; Beyer, K., Goldstein, J., Ramakrishnan, R., Shaft, U., When is ""nearest neighbor"" meaningful? (1999) Database Theory - ICDT'99: 7th International Conference Jerusalem, Israel, January 10-12, 1999 Proceedings, pp. 217-235. , C. Beeri and P. Buneman, Eds. Berlin, Heidelberg: Springer Berlin Heidelberg; Goodfellow, I., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, pp. 2672-2680; Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., Chen, X., Improved techniques for training gans (2016) Advances in Neural Information Processing Systems, pp. 2234-2242; Springenberg, J.T., (2015) Unsupervised and Semi-supervised Learning with Categorical Generative Adversarial Networks, , arXiv preprint; http://nsl.cs.unb.ca/nsl-kdd/, N.-K. d. o. a. ed. University of New Brunswick; Hettich, S., Bay, S., (1999) The UCI KDD Archive [Http://kdd. Ics. Uci. Edu]. Irvine, CA: University of California, 152. , Department of Information and Computer Science; Aggarwal, P., Sharma, S.K., Analysis of KDD dataset attributes-class wise for intrusion detection Procedia Computer Science, 57, pp. 842-851. , 2015/01/01/2015; Ray, L., Determining the number of hidden neurons in a multi layer feed forward neural network (2013) Journal of Information Security Research, 4 (2), pp. 63-70; Chollet, F.O.A.H.K.I., (2015) Keras; Ioffe, S., Szegedy, C., Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015) International Conference on Machine Learning, pp. 448-456; Glorot, X., Bengio, Y., Understanding the difficulty of training deep feedforward neural networks (2010) Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics, pp. 249-256; Ingre, B., Yadav, A., Performance analysis of NSL-KDD dataset using ANN (2015) International Conference on Signal Processing and Communication Engineering Systems, pp. 92-96. , Guntur, India, IEEE; Tavallaee, M., Bagheri, E., Lu, W., Ghorbani, A., A detailed analysis of the KDD CUP 99 data set (2009) IEEE Symposium on Computational Intelligence for Security and Defense Applications, pp. 1-6. , Ottawa, ON, Canada; Panda, M., Abraham, A., Patra, M.R., Discriminative multinomial Naïve Bayes for network intrusion detection (2010) Sixth International Conference on Information Assurance and Security, pp. 5-10. , Atlanta, GA, USA, IEEE; Ibrahim, L.M., Basheer, D.T., Mahmod, M.S., A comparison study for intrusion database (Kdd99, Nsl-Kdd) based on self organization map (SOM) artificial neural network (2013) Journal of Engineering Science and Technology, 8 (1), pp. 107-119; Maaten, L.V.D., Hinton, G., Visualizing data using t-SNE (2008) Journal of Machine Learning Research, 9 (NOV), pp. 2579-2605",,,"","IEEE Computer Society","17th Annual Wireless Telecommunications Symposium, WTS 2018","18 April 2018 through 20 April 2018",,136701,19345070,9781538633953,,,"English","Wirel. Telecommun. Symp.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85048171795
"Sethi T.S., Kantardzic M.","37102752400;8670147400;","Data driven exploratory attacks on black box classifiers in adversarial domains",2018,"Neurocomputing","289",,,"129","143",,19,"10.1016/j.neucom.2018.02.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042194251&doi=10.1016%2fj.neucom.2018.02.007&partnerID=40&md5=acfecad2b705b357a8b652fd23a5a3cf","Data Mining Lab, University of Louisville, Louisville, United States","Sethi, T.S., Data Mining Lab, University of Louisville, Louisville, United States; Kantardzic, M., Data Mining Lab, University of Louisville, Louisville, United States","While modern day web applications aim to create impact at the civilization level, they have become vulnerable to adversarial activity, where the next cyber-attack can take any shape and can originate from anywhere. The increasing scale and sophistication of attacks, has prompted the need for a data driven solution, with machine learning forming the core of many cybersecurity systems. Machine learning was not designed with security in mind and the essential assumption of stationarity, requiring that the training and testing data follow similar distributions, is violated in an adversarial domain. In this paper, an adversary's view point of a classification based system, is presented. Based on a formal adversarial model, the Seed-Explore-Exploit framework is presented, for simulating the generation of data driven and reverse engineering attacks on classifiers. Experimental evaluation, on 10 real world datasets and using the Google Cloud Prediction Platform, demonstrates the innate vulnerability of classifiers and the ease with which evasion can be carried out, without any explicit information about the classifier type, the training data or the application domain. The proposed framework, algorithms and empirical evaluation, serve as a white hat analysis of the vulnerabilities, and aim to foster the development of secure machine learning frameworks. © 2018 Elsevier B.V.","Adversarial machine learning; Black box attacks; Classification; Cybersecurity; Data diversity; Reverse engineering","Artificial intelligence; Learning systems; Reverse engineering; Black boxes; Cyber security; Data diversity; Empirical evaluations; Experimental evaluation; Explicit information; Real-world datasets; Training and testing; Classification (of information); Article; black box; classification; classifier; computer security; computer simulation; controlled study; cyber attack; data base; data driven; data processing; Internet; priority journal; reverse engineering",,,,,"Abramson, M., Toward adversarial online learning and the science of deceptive machines (2015) Proceedings of 2015 AAAI Fall Symposium Series; Akhtar, Z., Biggio, B., Fumera, G., Marcialis, G.L., Robustness of multi-modal biometric systems under realistic spoof attacks against all traits (2011) Proceedings of BIOMS 2011, pp. 1-6. , IEEE; Alabdulmohsin, I.M., Gao, X., Zhang, X., Adding robustness to support vector machines against adversarial reverse engineering (2014) Proceedings of the 23rd ACM CIKM, pp. 231-240. , ACM; Barreno, M., Nelson, B., Sears, R., Joseph, A.D., Tygar, J.D., Can machine learning be secure? (2006) Proceedings of the 2006 ACM Symposium on Information, Computer and Communications Security, pp. 16-25. , ACM; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndić, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Machine Learning and Knowledge Discovery in Databases, pp. 387-402. , Springer; Biggio, B., Fumera, G., Roli, F., Pattern recognition systems under attack: Design issues and research challenges (2014) Int. J. Pattern Recogn. Artif. Intell., 28 (7), p. 1460002; Biggio, B., Fumera, G., Roli, F., Security evaluation of pattern classifiers under attack (2014) IEEE Trans. Knowl. Data Eng., 26 (4), pp. 984-996; Bilge, L., Dumitras, T., Before we knew it: an empirical study of zero-day attacks in the real world (2012) Proceedings of the 2012 ACM conference on Computer and communications security, pp. 833-844. , ACM; Breiman, L., Random forests (2001) Mach. Learn., 45 (1), pp. 5-32; Chan, P.P., Yang, C., Yeung, D.S., Ng, W.W., Spam filtering for short messages in adversarial environment (2015) Neurocomputing, 155, pp. 167-176; Chawla, N.V., Bowyer, K.W., Hall, L.O., Kegelmeyer, W.P., Smote: synthetic minority over-sampling technique (2002) J. Artif. Intell. Res., 16, pp. 321-357; Chen, J., Xin, B., Peng, Z., Dou, L., Zhang, J., Optimal contraction theorem for exploration–exploitation tradeoff in search and optimization (2009) IEEE Trans. Syst. Man Cybern.-Part A: Syst. Hum., 39 (3), pp. 680-691; Cover, T.M., Hart, P.E., Nearest neighbor pattern classification (1967) IEEE Trans. Inf. Theory, 13 (1), pp. 21-27; D'Souza, D.F., (2014), Avatar captcha: telling computers and humans apart via face classificationand mouse dynamics, Electronic Theses and Dissertations-1715, University of Louisville; Group, B.D.W., Big data analytics for security intelligence (2013) Cloud Security Alliance; Guerra, P.H.C., Exploring the spam arms race to characterize spam evolution (2010) Proceedings of the 7th Collaboration, Electronic messaging, Anti-Abuse and Spam Conference (CEAS); Haussler, D., (1990) Probably Approximately Correct Learning, , University of California,Computer Research Laboratory Santa Cruz; He, J., Carbonell, J.G., Nearest-neighbor-based active learning for rare category detection (2007) Proceedings of Advances in Neural Information Processing systems, pp. 633-640; Hong, J.B., Kim, D.S., Assessing the effectiveness of moving target defenses using security models (2016) IEEE Trans. Depend. Sec. Comput., 13 (2), pp. 163-177; Huh, J.H., Kim, H., Phishing detection with popular search engines: simple and effective (2011) Foundations and Practice of Security, pp. 194-207. , Springer; Kantchelian, A., Afroz, S., Huang, L., Islam, A.C., Miller, B., Tschantz, M.C., Greenstadt, R., Tygar, J., Approaches to adversarial drift (2013) Proceedings of the 2013 ACM workshop on Artificial intelligence and Security, pp. 99-110. , ACM; Lacevic, B., Amaldi, E., Ectropy of diversity measures for populations in euclidean space (2011) Inf. Sci., 181 (11), pp. 2316-2339; Li, H., Chan, P.P., An improved reject on negative impact defense (2014) Proceedings of International Conference on Machine Learning and Cybernetics, pp. 452-459. , Springer; Li, Y., Yeung, D.S., A causative attack against semi-supervised learning (2014) Machine Learning and Cybernetics, pp. 196-203. , Springer; Lichman, M., (2013), UCI machine learning repository; Lowd, D., Meek, C., Adversarial learning (2005) Proceedings of the 11th ACM SIGKDD, pp. 641-647. , ACM; Lowd, D., Meek, C., Good word attacks on statistical spam filters. (2005) Proceedings of CEAS; Nelson, B., Query strategies for evading convex-inducing classifiers (2012) J. Mach. Learn. Res., 13 (1), pp. 1293-1332; Nelson, B., (2010), 1003.2751 Near-optimal evasion of convex-inducing classifiers, arXiv preprint arXiv; Papernot, N., McDaniel, P., Goodfellow, I., (2016), 1605.07277 Transferability in machine learning: from phenomena to black-box attacks using adversarial samples, arXiv preprint arXiv; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Proceedings of IEEE European Symposium on Security and Privacy (EuroS&P), pp. 372-387. , IEEE; Pastrana Portillo, S., Attacks against intrusion detection networks: evasion, reverse engineering and optimal countermeasures, (Doctoral Thesis), Universidad Carlos III de Madrid(2014); Pedregosa, F., Scikit-learn: Machine learning in Python (2011), 12, pp. 2825-2830; Prakash, P., Kumar, M., Kompella, R.R., Gupta, M., Phishnet: predictive blacklisting to detect phishing attacks (2010) Proceedings IEEE INFOCOM, 2010, pp. 1-5. , IEEE; Quinlan, J.R., C4. 5: Programming for machine learning (1993) Morgan Kauffmann; Rndic, N., Laskov, P., Practical evasion of a learning-based classifier: a case study (2014) Proceedings of IEEE Symposium on Security and Privacy (SP), 2014, pp. 197-211. , IEEE; Saha, A., Sanyal, S., (2014), 1411.3089 Application layer intrusion detection with combination of explicit-rule-based and machine learning algorithms and deployment in cyber-defence program, arXiv preprint arXiv; Sethi, T.S., Kantardzic, M., Arabmakki, E., Monitoring classification blindspots to detect drifts from unlabeled data (2016) Proceedings of 17th IEEE International Conference on Information Reuse and Integration (IRI), , IEEE; Sethi, T.S., Kantardzic, M., Hu, H., A grid density based framework for classifying streaming data in the presence of concept drift (2016) J. Intell. Inf. Syst., 46 (1), pp. 179-211; Sethi, T.S., Kantardzic, M., Ryu, J.W., Security theater: on the vulnerability of classifiers to exploratory attacks (2017) Proceedings of 12th Pacific Asia Workshop on Intelligence and Security Informatics, (Under Consideration), , Springer; Smutz, C., Stavrou, A., When a tree falls: using diversity in ensemble classifiers to identify evasion in malware detectors (2016) Proceedings of NDSS Symposium; Tramèr, F., Zhang, F., Juels, A., Reiter, M.K., Ristenpart, T., (2016), 1609.02943 Stealing machine learning models via prediction APIS, arXiv preprint arXiv; Tzu, S., (1963), The art of war edited by Samuel B. Griffith; Wagner, D., Soto, P., Mimicry attacks on host-based intrusion detection systems (2002) Proceedings of the 9th ACM Conference on Computer and Communications Security, pp. 255-264. , ACM; Walgampaya, C., Kantardzic, M., Cracking the smart clickbot (2011) Proceedings of 13th IEEE International Symposium on Web Systems Evolution (WSE), pp. 125-134. , IEEE; Wang, L., Hu, X., Yuan, B., Lu, J.G., Active learning via query synthesis and nearest neighbour search (2015) Neurocomputing, 147, pp. 426-434; Xiao, H., Biggio, B., Nelson, B., Xiao, H., Eckert, C., Roli, F., Support vector machines under adversarial label contamination (2015) Neurocomputing, 160, pp. 53-62; Xiaoyan, W.P.Z., Model selection of SVM with RBF kernel and its application (2003) Comput. Eng. Appl., 24, p. 021; Xu, L., Zhan, Z., Xu, S., Ye, K., An evasion and counter-evasion study in malicious websites detection (2014) Proceedings of IEEE Conference on Communications and Network Security (CNS), 2014, pp. 265-273. , IEEE; Xu, W., Qi, Y., Evans, D., Automatically evading classifiers (2016) Proceedings of the Network and Distributed Systems Symposium; Zamani, M., Movahedi, M., (2013), 1312.2177 Machine learning techniques for intrusion detection, arXiv preprint arXiv; Zhou, Y., Kantarcioglu, M., Thuraisingham, B., Xi, B., Adversarial support vector machine learning (2012) Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 1059-1067. , ACM; Žliobaitė, I., (2010), 1010.4784 Learning under concept drift: an overview, arXiv preprint arXiv","Sethi, T.S.; Data Mining Lab, United States; email: t0seth01@louisville.edu",,,"Elsevier B.V.",,,,,09252312,,NRCGE,,"English","Neurocomputing",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85042194251
"Dong Y., Zhou P., Li X., Peng C.","57195671322;56523808800;55718125700;56891800400;","Adversarial intrusion detection against denial of service attack for networked system [网络化系统拒绝服务攻击对抗式检测方法研究]",2018,"Yi Qi Yi Biao Xue Bao/Chinese Journal of Scientific Instrument","39","5",,"205","213",,,"10.19650/j.cnki.cjsi.J1702639","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054373017&doi=10.19650%2fj.cnki.cjsi.J1702639&partnerID=40&md5=36e79cc3b5d21e415a030bb1ef72351d","School of Mechatronic Engineering and Automation, Shanghai University, Shanghai, 200072, China","Dong, Y., School of Mechatronic Engineering and Automation, Shanghai University, Shanghai, 200072, China; Zhou, P., School of Mechatronic Engineering and Automation, Shanghai University, Shanghai, 200072, China; Li, X., School of Mechatronic Engineering and Automation, Shanghai University, Shanghai, 200072, China; Peng, C., School of Mechatronic Engineering and Automation, Shanghai University, Shanghai, 200072, China","Abstract:Denial of service (DoS) attack is one of the most typical attack targeting network control systems (NCS). By initiating lots of additional network traffic, DoS can block the network channel to disable remote control operation. The existed DoS detection methods usually build a detection model on network traffic features. Then this model is utilized to detect new DoS. However, this approach does not consider the factor of the attacker intelligence. If the traffic features for identifying the attack are revealed, attackers are likely to avoid the detection by adjusting their attacking strategy. In this paper, one new type of DoS detection method using adversarial machine learning is proposed. DoS attackers' capacities to avoid detection are considered. Thereby, the Stackelberg leader (the attacker)-followers (the classifier) model to analysis the corresponding cost and benefit is formulated. Finally, the theoretical Stackelberg equilibrium is achieved. As a case study, a new adversarial bagging classifier based on traditional decision tree ensemble classifier is designed. The effectiveness of the proposed method using practical DoS attacking data set is verified. © 2018, Science Press. All right reserved.","Adversarial machine learning; Denial of service attack; Intrusion detection; Stackelberg game theory","Artificial intelligence; Cost benefit analysis; Decision trees; Feature extraction; Game theory; Intrusion detection; Learning systems; Remote control; Attacking strategy; Cost and benefits; Denial of Service; Network control systems; Networked systems; Remote control operations; Stackelberg equilibrium; Stackelberg Games; Denial-of-service attack",,,,,"Zhang, X., Han, Q.L., Yu, X., Survey on recent advances in networked control systems (2016) IEEE Transactions on Industrial Informatics, 12 (5), pp. 1740-1752; Zhang, H., Peng, C., Sun, H.T., Stabilization analysis of wireless networked control system with multi-path channels (2016) Journal of Electronic Measurement and Instrumentation, 30 (11), pp. 1627-1634. , 张浩, 彭晨, 孙洪涛. 多路径的无线网络控制系统镇定性研究[J]. 电子测量与仪器学报, 2016, 30(11): 1627-1634; Wang, Y.W., Liu, Y.J., Design and implement of embedded network controller system (2014) Foreign Electronic Measurement Technology, 33 (9), pp. 50-53. , 王永伟, 刘岩俊. 嵌入式网络控制系统设计与实现[J]. 国外电子测量技术, 2014, 33(9): 50-53; Pasqualetti, F., Dorfler, F., Bullo, F., Control-theoretic methods for cyberphysical security: Geometric principles for optimal cross-layer resilient control systems (2015) IEEE Control Systems, 35 (1), pp. 110-127; Peng, Y., Jiang, C.Q., Xie, F., Industrial control system cybersecurity research (2013) Journal of Tsinghua University(Science and Technology), 52 (10), pp. 1396-1408. , 彭勇, 江常青, 谢丰, 等. 工业控制系统信息安全研究进展[J]. 清华大学学报(自然科学版), 2013, 52(10): 1396-1408; Gao, Y., Feng, Y., Kawamoto, J., A machine learning based approach for detecting DRDoS attacks and its performance evaluation (2016) 11th Asia Joint Conference on Information Security, IEEE, pp. 80-86; Vrat, B., Aggarwal, N., Venkatesan, S., Anomaly detection in IPv4 and IPv6 networks using machine learning (2015) IEEE India Conference, pp. 1-6; Tsiatsikas, Z., Fakis, A., Papamartzivanos, D., Battling against DDoS in SIP: Is machine learning-based detection an effective weapon? (2016) International Joint Conference on E-Business and Telecommunications; Agarwal, M., Biswas, S., Nandi, S., Detection of de-authentication dos attacks in Wi-Fi networks: A machine learning approach (2016) IEEE International Conference on Systems, Man, and Cybernetics, pp. 246-251; Ranekar, A.P., Patil, A.R.B., Survey of DOS defense mechanisms (2015) IEEE International Conference on Innovations in Information, Embedded and Communication Systems (ICIIECS), pp. 1-5; Raj, A.B., Ramesh, M.V., Kulkarni, R.V., Security enhancement in wireless sensor networks using machine learning (2012) IEEE International Conference on High Performance Computing and Communication & International Conference on Embedded Software and Systems, pp. 1264-1269; Zhou, P., Chang, R., Gu, X., Magic train: Design of measurement methods against bandwidth inflation attacks (2018) IEEE Transactions on Dependable and Secure Computing, 15 (1), pp. 98-111; Sedjelmaci, H., Senouci, S.M., Ansari, N., Intrusion detection and ejection framework against lethal attacks in UAV-aided networks: A bayesian game-theoretic methodology (2017) IEEE Transactions on Intelligent Transportation Systems, 18 (5), pp. 1143-1153; Kayn, A.O., Yüksek, A.G., Görmez, Y., Intrusion detection with autoencoder based deep learning machine (2017) IEEE Signal Processing and Communications Applications Conference (SIU), pp. 1-4; Zhou, P., Jiang, S., Irissappane, A., Toward energy-efficient trust system through watchdog optimization for WSNs (2015) IEEE Transactions on Information Forensics and Security, 10 (3), pp. 613-625; Wei, M., Wang, P., Kim, K., Hierarchical intrusion detection method for WIA-PA industrial wireless networks (2012) Chinese Journal of Scientific Instrument, 33 (7), pp. 1453-1459. , 魏旻, 王平, 金基天. 一种适用于WIA-PA网络的分层入侵检测方法[J]. 仪器仪表学报, 2012, 33(7): 1453-1459; Li, Y.Z., Zhang, J., New intrusion detection algorithm based on cluster and cloud model (2014) Journal of Electronic Measurement and Instrumentation, 28 (12), pp. 1376-1381. , 李永忠, 张杰. 一种基于云模型和半监督聚类的入侵检测算法[J]. 电子测量与仪器学报, 2014, 28(12): 1376-1381; Modelohoward, G., Bagchi, S., Lebanon, G., Approximation algorithms for determining placement of intrusion detectors (2011) Journal of Instrumentation, 6 (12), pp. 570-582; Liu, H.R., Zhao, C.X., Li, X., Study on a neural network optimization algorithm based on improved genetic algorithm (2016) Chinese Journal of Scientific Instrument, 37 (7), pp. 1573-1580. , 刘浩然, 赵翠香, 李轩, 等. 一种基于改进遗传算法的神经网络优化算法研究[J]. 仪器仪表学报, 2016, 37(7): 1573-1580; Chen, C., Shen, F., Yan, R.Q., Enhanced least squares support vector machine-based transfer learning strategy for bearing fault diagnosis (2017) Chinese Journal of Scientific Instrument, 38 (1), pp. 33-40. , 陈超, 沈飞, 严如强. 改进LSSVM迁移学习方法的轴承故障诊断[J]. 仪器仪表学报, 2017, 38(1): 33-40; Mei, H.G., Yin, L.S., Liu, D.M., Analogue circuit fault diagnosis based on SVM optimized by IPSO (2017) Journal of Electronic Measurement and Instrumentation, 31 (8), pp. 1239-1246. , 梅恒荣, 殷礼胜, 刘冬梅, 等. 改进粒子群算法优化的SVM模拟电路故障诊断[J]. 电子测量与仪器学报, 2017, 31(8): 1239-1246; Sun, Z., Research of network flow feature selection based on machine learning (2017) Electronic Measurement Technology, 40 (7), pp. 131-136. , 孙振. 基于机器学习的网络流量特征选择[J]. 电子测量技术, 2017, 40(7): 131-136; Qu, J.Y., Sun, X., Gao, X., Remote sensing image target recognition based on CNN (2016) Foreign Electronic Measurement Technology, 35 (8), pp. 45-50. , 曲景影, 孙显, 高鑫. 基于CNN模型的高分辨率遥感图像目标识别[J]. 国外电子测量技术, 2016, 35(8): 45-50; Alves, A., Stacking machine learning classifiers to identify higgs bosons at the LHC (2016) Journal of Instrumentation, 12; Zhang, H.M., Real-time intrusion detection system base on random subspace PCA-SVM ensemble (2009) Chinese Journal of Scientific Instrument, 30 (12), pp. 2680-2684. , 张红梅. 基于随机子空间PCA-SVM集成的实时入侵检测系统[J]. 仪器仪表学报, 2009, 30(12): 2680-2684; Lu, H.B., Tan, L., Wang, Y., Application of the network intrusion detection based on support vector machine (2008) Electronic Measurement Technology, 31 (2), pp. 57-59. , 卢辉斌, 谭龙, 王昱. 支持向量机在入侵检测中的应用[J]. 电子测量技术, 2008, 31(2): 57-59; Zhou, P., Gu, X., Zhang, J., A priori trust inference with context-aware stereotypical deep learning (2015) Knowledge-Based Systems, 88, pp. 97-106; Lowd, D., Meek, C., Adversarial learning (2005) Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining, pp. 641-647; Rota, B.S., Biggio, B., Pillai, I., Randomized prediction games for adversarial machine learning (2017) IEEE Transaction on Neural Networks and Learning Systems, 28 (11), pp. 2466-2478; Wang, F., Liu, W., Chawla, S., On sparse feature attacks in adversarial learning (2015) IEEE International Conference on Data Mining, pp. 1013-1018; Demontis, A., Melis, M., Biggio, B., Yes, machine learning can be more secure! A case study on android malware detection (2017) IEEE Transactions on Dependable & Secure Computing; Chivukula, A.S., Liu, W., Adversarial learning games with deep learning models (2017) IEEE International Joint Conference on Neural Networks, pp. 2758-2767; Zeager, M.F., Sridhar, A., Fogal, N., Adversarial learning in credit card fraud detection (2017) IEEE Systems and Information Engineering Design Symposium (SIEDS), pp. 112-116; Yuan, Y., Sun, F., Liu, H., Resilient control of cyber-physical systems against intelligent attacker: a hierarchal stackelberg game approach (2016) International Journal of Systems Science, 47 (9), pp. 2067-2077; Jain, P., Varma, S., Ankit, A supervised approach towards network control system modelling (2017) IEEE International Conference on Communication Systems and Networks, pp. 346-353; Cloosterman, M.B.G., Van, D., Wouw, N., Heemels, W., Stability of networked control systems with uncertain time-varying delays (2009) IEEE Transactions on Automatic Control, 54 (7), pp. 1575-1580; Lin, H., Antsaklis, P.J., Stability and persistent disturbance attenuation properties for a class of networked control systems: Switched system approach (2005) International Journal of Control, 78 (18), pp. 1447-1458; Zhang, X.M., Han, Q.L., Yu, X., Survey on recent advances in networked control systems (2016) IEEE Transactions on Industrial Informatics, 12 (5), pp. 1740-1752; Kevric, J., Jukic, S., Subasi, A., An effective combining classifier approach using tree algorithms for network intrusion detection (2017) Neural Computing and Applications, 28 (1), pp. 1051-1058",,,,"Science Press",,,,,02543087,,YYXUD,,"Chinese","Yi Qi Yi Biao Xue Bao",Article,"Final","",Scopus,2-s2.0-85054373017
"Coutinho M., Albuquerque R.O., Borges F., Villalba L.J.G., Kim T.-H.","57201779077;16745042500;38961099800;57192440178;56981749100;","Learning perfectly secure cryptography to protect communications with adversarial neural cryptography",2018,"Sensors (Switzerland)","18","5","1306","","",,21,"10.3390/s18051306","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046073653&doi=10.3390%2fs18051306&partnerID=40&md5=1f3a06aab284d8e85a7f2dcb83f0c483","Cybersecurity INCT Unit 6, Decision Technologies Laboratory—LATITUDE, Electrical Engineering Department (ENE), Technology College, University of Brasília (UnB), DF, Brasília, 70.910-900, Brazil; National Laboratory for Scientific Computing, Petrópolis, RJ  25.651-075, Brazil; Group of Analysis, Security and Systems (GASS), Department of Software Engineering and Artificial Intelligence (DISIA), Faculty of Computer Science and Engineering, Office 431, Universidad Complutense de Madrid (UCM), Calle Profesor José García Santesmases, 9, Ciudad Universitaria, Madrid, 28040, Spain; Department of Convergence Securit, Sungshin Women’s University, 249-1 Dongseon-Dong 3-ga, Seoul, 136-742, South Korea","Coutinho, M., Cybersecurity INCT Unit 6, Decision Technologies Laboratory—LATITUDE, Electrical Engineering Department (ENE), Technology College, University of Brasília (UnB), DF, Brasília, 70.910-900, Brazil; Albuquerque, R.O., Cybersecurity INCT Unit 6, Decision Technologies Laboratory—LATITUDE, Electrical Engineering Department (ENE), Technology College, University of Brasília (UnB), DF, Brasília, 70.910-900, Brazil; Borges, F., National Laboratory for Scientific Computing, Petrópolis, RJ  25.651-075, Brazil; Villalba, L.J.G., Group of Analysis, Security and Systems (GASS), Department of Software Engineering and Artificial Intelligence (DISIA), Faculty of Computer Science and Engineering, Office 431, Universidad Complutense de Madrid (UCM), Calle Profesor José García Santesmases, 9, Ciudad Universitaria, Madrid, 28040, Spain; Kim, T.-H., Department of Convergence Securit, Sungshin Women’s University, 249-1 Dongseon-Dong 3-ga, Seoul, 136-742, South Korea","Researches in Artificial Intelligence (AI) have achieved many important breakthroughs, especially in recent years. In some cases, AI learns alone from scratch and performs human tasks faster and better than humans. With the recent advances in AI, it is natural to wonder whether Artificial Neural Networks will be used to successfully create or break cryptographic algorithms. Bibliographic review shows the main approach to this problem have been addressed throughout complex Neural Networks, but without understanding or proving the security of the generated model. This paper presents an analysis of the security of cryptographic algorithms generated by a new technique called Adversarial Neural Cryptography (ANC). Using the proposed network, we show limitations and directions to improve the current approach of ANC. Training the proposed Artificial Neural Network with the improved model of ANC, we show that artificially intelligent agents can learn the unbreakable One-Time Pad (OTP) algorithm, without human knowledge, to communicate securely through an insecure communication channel. This paper shows in which conditions an AI agent can learn a secure encryption scheme. However, it also shows that, without a stronger adversary, it is more likely to obtain an insecure one. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Adversarial Neural Cryptography; Artificial intelligence; Chosen-Plaintext Attack; Cryptography; Neural network; One-Time Pad","Artificial intelligence; Cryptography; Intelligent agents; Neural networks; Bibliographic reviews; Chosen-plaintext attack; Complex neural networks; Cryptographic algorithms; Encryption schemes; Insecure communication channel; Neural Cryptography; One time pads; Network security; algorithm; artificial intelligence; interpersonal communication; Algorithms; Artificial Intelligence; Communication",,,,,"Simonyan, K., Zisserman, A., Very Deep Convolutional Networks for Large-Scale Image Recognition, , arXiv 2014, [CrossRef]; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Proceedings of the 25Th International Conference on Neural Information Processing Systems, pp. 1097-1105. , Lake Tahoe, NV, USA, 3-6 December; Graves, A., Mohamed, A.R., Hinton, G., Speech recognition with deep recurrent neural networks (2013) Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 6645-6649. , Vancouver, BC, Canada, 26-31 May; Bojarski, M., Del Testa, D., Dworakowski, D., Firner, B., Flepp, B., Goyal, P., Jackel, L.D., Zhang, J., End to End Learning for Self-Driving Cars, , arXiv 2016, [CrossRef]; Silver, D., Schrittwieser, J., Simonyan, K., Antonoglou, I., Huang, A., Guez, A., Hubert, T., Bolton, A., Mastering the game of Go without human knowledge (2017) Nature, 550, p. 354. , [CrossRef]; Kanter, I., Kinzel, W., Kanter, E., Secure Exchange of Information by Synchronization of Neural Networks, , arXiv 2002, arXiv:cond-mat/0202112[CrossRef]; Lian, S., Chen, G., Cheung, A., Wang, Z., A chaotic-neural-network-based encryption algorithm for JPEG2000 encoded images (2004) Lect. Notes Comput. Sci, 3174, pp. 627-632; Yu, W., Cao, J., Cryptography based on delayed chaotic neural networks (2006) Phys. Lett. A, 356, pp. 333-338. , [CrossRef]; Wang, X.Y., Yang, L., Liu, R., Kadir, A., A chaotic image encryption algorithm based on perceptron model (2010) Nonlinear Dyn, 62, pp. 615-621. , [CrossRef]; Klimov, A., Mityagin, A., Shamir, A., Analysis of neural cryptography (2002) Advances in Cryptology— ASIACRYPT 2002, Proceedings of the International Conference on the Theory and Application of Cryptology and Information Security, pp. 288-298. , Queenstown, New Zealand, 1-5 December 2002; Springer: Berlin/Heidelberg, Germany; Li, C., (2005) Cryptanalyses of Somemultimedia Encryption Schemes, , Master’s Thesis, Zhejiang University, Hangzhou, China,May; Qin, K., Oommen, B.J., On the cryptanalysis of two cryptographic algorithms that utilize chaotic neural networks (2015) Math. Probl. Eng, 2015, p. 9. , [CrossRef]; Zhang, Y., Li, C., Li, Q., Zhang, D., Shu, S., Breaking a chaotic image encryption algorithm based on perceptron model (2012) Nonlinear Dyn, 69, pp. 1091-1096. , [CrossRef]; Abadi, M., Andersen, D.G., Learning to Protect Communications with Adversarial Neural Cryptography, , arXiv 2016, [CrossRef]; Shannon, C.E., Communication theory of secrecy systems (1949) Bell Labs Techn. J, 28, pp. 656-715. , [CrossRef]; Katz, J., Lindell, Y., (2007) Introduction to Modern Cryptography, , Chapman & Hall: London, UK; Desai, V., Deshmukh, V., Rao, D., Pseudo random number generator using Elman neural network (2011) Proceedings of the IEEE Recent Advances in Intelligent Computational Systems (RAICS), pp. 251-254. , Trivandrum, India, 22-24 September; Desai, V., Patil, R., Rao, D., Using layer recurrent neural network to generate pseudo random number sequences (2012) Int. J. Comput. Sci. Issues, 9, pp. 324-334; Yayık, A., Kutlu, Y., Improving Pseudo random number generator using artificial neural networks (2013) Proceedings of the IEEE 21St Signal Processing and Communications Applications Conference (SIU), pp. 1-4. , Haspolat, Turkey, 24-26 April; Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Isard, M., TensorFlow: A system for large-scale machine learning (2016) Proceedings of the 12Th USENIX Symposium on Operating Systems Design and Implementation (OSDI), pp. 265-283. , Savannah, GA, USA, 2-4 November; Kingma, D., Ba, J., (2014) Adam: A Method for Stochastic Optimization, , arXiv preprint, [CrossRef]; Goodfellow, I., Bengio, Y., Courville, A., (2016) Deep Learning, , http://www.deeplearningbook.org, MIT Press: Cambridge,MA, USA; Borges De Oliveira, F., Analytical comparison (2017) On Privacy-Preserving Protocols for Smart Metering Systems: Security and Privacy in Smart Grids, pp. 101-110. , Springer International Publishing: Cham, Switzerland; Oliveira, L.B., Pereira, F.M.Q., Misoczki, R., Aranha, D.F., Borges, F., Liu, J., The computer for the 21st century: Security privacy challenges after 25 years (2017) Proceedings of the 26Th International Conference on Computer Communication and Networks (ICCCN), pp. 1-10. , Vancouver, BC, Canada, 31 July-3 August","Villalba, L.J.G.; Group of Analysis, Calle Profesor José García Santesmases, 9, Ciudad Universitaria, Spain; email: javiergv@fdi.ucm.es",,,"MDPI AG",,,,,14248220,,,"29695066","English","Sensors",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85046073653
"Chen Y., Kar S., Moura J.M.F.","56940487400;18042324900;7102993409;","Resilient Distributed Estimation Through Adversary Detection",2018,"IEEE Transactions on Signal Processing","66","9",,"2455","2469",,40,"10.1109/TSP.2018.2813330","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043395601&doi=10.1109%2fTSP.2018.2813330&partnerID=40&md5=74d8623191ddc6b3448eb4075ff2359c","Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA  15217, United States","Chen, Y., Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA  15217, United States; Kar, S., Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA  15217, United States; Moura, J.M.F., Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA  15217, United States","This paper studies resilient multiagent distributed estimation of an unknown vector parameter when a subset of the agents is adversarial. We present and analyze a flag raising distributed estimator ( FRDE) that allows the agents under attack to perform accurate parameter estimation and detect the adversarial agents. The FRDE algorithm is a consensus+innovations estimator in which agents combine estimates of neighboring agents (consensus) with local sensing information (innovations). We establish that, under FRDE, either the uncompromised agents' estimates are almost surely consistent, or the uncompromised agents detect compromised agents (with arbitrarily small false alarm probability) if and only if the network of uncompromised agents is connected and globally observable. Numerical examples illustrate the performance of FRDE. © 1991-2012 IEEE.","Consensus + Innovations; Cyber-physical security; Multi-agent networks; Resilient parameter estimation","Multi agent systems; Adversarial agent; Consensus + innovations; Cyber-Physical securities; Distributed estimation; Local sensing; Multi agent; Multiagent networks; Vector parameter; Parameter estimation",,,,,"Tsitsiklis, J.N., Bertsekas, D.P., Athans, M., Distributed asynchronous deterministic and stochastic gradient optimization algorithms (1986) IEEE Trans. Autom. Control, 31 (9), pp. 803-812. , Sep; Xiao, L., Boyd, S., Fast linear iterations for distributed averaging (2004) Syst. Control Lett, 53 (1), pp. 65-78. , Sep; Kar, S., Moura, J.M.F., Convergence rate analysis of distributed gossip (linear parameter) estimation: Fundamental limits and tradeoffs (2011) IEEE J. Sel. Topics Signal Process, 5 (4), pp. 674-690. , Aug; Kar, S., Moura, J.M.F., Consensus+innovations distributed inference over networks (2013) IEEE Signal Process. Mag, 30 (3), pp. 99-109. , May; Kar, S., Moura, J.M.F., Ramanan, K., Distributed parameter estimation in sensor networks: Nonlinear observation models and imperfect communication (2012) IEEE Trans. Inf. Theory, 58 (6), pp. 3575-3605. , Jun; Sundaram, S., Hadjicostis, C.N., Distributed function calculation and consensus using linear iterative strategies (2008) IEEE J. Sel. Topics Signal Process, 26 (4), pp. 650-660. , May; Das, A.K., Mesbahi, M., Distributed linear parameter estimation over wireless sensor networks (2009) IEEE Trans. Aerosp. Electron. Syst, 45 (4), pp. 1293-1306. , Oct; Cattivelli, F., Sayed, A.H., Diffusion lms strategies for distributed estimation (2010) IEEE Trans. Signal Process, 58 (3), pp. 1035-1047. , Mar; Xie, L., Choi, D.H., Kar, S., Poor, H.V., Fully distributed state estimation for wide-Area monitoring systems (2012) IEEE Trans. Smart Grid, 3 (3), pp. 1154-1169. , Sep; Olfati-Saber, R., Fax, J.A., Murray, R.M., Consensus and cooperation in networked multi-Agent systems (2007) Proc. IEEE, 95 (1), pp. 215-233. , Jan; Antonelli, G., Interconnected dynamic systems: An overview on distributed control (2013) IEEE Control Syst. Mag, 33 (1), pp. 76-88. , Feb; Zhao, X., Sayed, A.H., Clustering via diffusion adaptation over networks (2012) Proc. 3rd Int. Workshop Cogn. Inf. Process, pp. 1-6. , Baiona, Spain, May; Sayed, A.H., Tu, S., Chen, J., Zhao, X., Towfi, Z.J., Diffusion strategies for adaptation and learning over networks (2013) IEEE Signal Process. Mag, 30 (1), pp. 155-171. , May; Lamport, L., Shostak, R., Pease, M., The byzantine generals problem (1982) ACM Trans. Program. Lang. Syst, 4 (3), pp. 382-401. , Jul; Vempaty, A., Tong, L., Varshney, P.K., Distributed inference with byzantine data (2013) IEEE Signal Process. Mag, 30 (5), pp. 65-75. , Sep; Kailkhura, B., Han, Y.S., Brahma, S., Varshney, P.K., Distributed Bayesian detection in the presence of byzantine data (2015) IEEE Trans. Signal Process, 63 (19), pp. 5250-5263. , Oct; Zhang, J., Blum, R., Lu, X., Conus, D., Asymptotically optimum distributed estimation in the presence of attacks (2015) IEEE Trans. Signal Process, 63 (5), pp. 1086-1101. , Mar; Marano, S., Matta, V., Tong, L., Distributed detection in the presence of byzantine attacks (2009) IEEE Trans. Signal Process, 57 (1), pp. 16-29. , Jan; Chen, Y., Kar, S., Moura, J.M.F., Dynamic attack detection in cyberphysical systems with side initial state information (2017) IEEE Trans. Autom. Control, 62 (9), pp. 4618-4624. , Sep; Chen, Y., Kar, S., Moura, J.M.F., Cyber physical attacks with control objectives (2017) IEEE Trans. Autom. Control, 99, pp. 1-8. , Aug; Chen, Y., Kar, S., Moura, J.M.F., Optimal attack strategies subject to detection constraints against cyber-physical systems (2017) IEEE Trans. Control. Netw. Syst, (99), pp. 1-12. , Mar; Mo, Y., Kim, T.H., Brancik, K., Dickinson, D., Lee, H., Perrig, A., Sinopoli, B., Cyber-physical security of a smart grid infrastructure (2012) Proc. IEEE, 100 (1), pp. 195-209. , Jan; Dolev, D., Lynch, N.A., Pinter, S.S., Stark, E.W., Weihl, W.E., Reaching approximate agreement in the presence of faults (1986) J. ACM, 33 (3), pp. 499-516. , Jul; LeBlanc, H.J., Zhang, H., Koustsoukos, X., Sundaram, S., Resilient asymptotic consensus in robust networks (2015) IEEE J. Sel. Areas Commun, 31 (4), pp. 766-781. , Apr; Pasqualetti, F., Bicchi, A., Bullo, F., Consensus computation in unreliable networks:asystem theoretic approach (2012) IEEE Trans. Autom.Control, 57 (1), pp. 90-104. , Jan; Shames, I., Teixeira, A.M.H., Sandberg, H., Johansson, K.H., Distributed fault detection for interconnected second-order systems (2011) Automatica, 47 (12), pp. 2757-2764. , Dec; Sundaram, S., Hadjicostis, C.N., Distributed function calculation via linear iterative strategies in the presence ofmalicious agents (2011) IEEE Trans. Autom. Control, 56 (7), pp. 1495-1508. , Jul; LeBlanc, H.J., Hassan, F., Resilient distributed parameter estimation in heterogeneous time-varying networks (2014) Proc. 3rd Int. Conf. High Confidence Netw. Syst, pp. 19-28. , Berlin, Germany, Apr; Chung, F.R.K., (1997) Spectral Graph Theory, , Providence RI USA: Wiley; Bollobás, B., (1998) Modern Graph Theory, , New York, NY USA: Springer-Verlag; Mieghem, P.V., (2011) Graph Spectra for Complex Networks, , New York, NY, USA: Cambridge Univ. Press ch. 4; Bernstein, D.S., (2009) Matrix Mathematics, , Princeton NJ USA: PrincetonUniv. Press; Kushner, H., (1971) Introduction to Stochastic Control, , New York NY USA: Holt, Rinehart and Winston; Serre, D., (2010) Matrices: Theory and Applications, , New York NY USA: Springer ch. 6","Chen, Y.; Department of Electrical and Computer Engineering, United States; email: yuanche1@andrew.cmu.edu",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,1053587X,,ITPRE,,"English","IEEE Trans Signal Process",Article,"Final","All Open Access, Bronze, Green",Scopus,2-s2.0-85043395601
"Sethi T.S., Kantardzic M., Lyu L., Chen J.","37102752400;8670147400;56516527300;55234032400;","A dynamic-adversarial mining approach to the security of machine learning",2018,"Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery","8","3","e1245","","",,4,"10.1002/widm.1245","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041892437&doi=10.1002%2fwidm.1245&partnerID=40&md5=595fd58702c8fdd963b0e4ae056cd3ba","Data Mining Laboratory, University of Louisville, Louisville, KY, United States; College of Computer Science and Technology, Huai Hai Institute of Technology, Lianyungang, China","Sethi, T.S., Data Mining Laboratory, University of Louisville, Louisville, KY, United States; Kantardzic, M., Data Mining Laboratory, University of Louisville, Louisville, KY, United States; Lyu, L., Data Mining Laboratory, University of Louisville, Louisville, KY, United States; Chen, J., College of Computer Science and Technology, Huai Hai Institute of Technology, Lianyungang, China","Operating in a dynamic real-world environment requires a forward thinking and adversarial aware design for classifiers beyond fitting the model to the training data. In such scenarios, it is necessary to make classifiers such that they are: (a) harder to evade, (b) easier to detect changes in the data distribution over time, and (c) be able to retrain and recover from model degradation. While most works in the security of machine learning have concentrated on the evasion resistance problem (a), there is little work in the areas of reacting to attacks (b) and (c). Additionally, while streaming data research concentrates on the ability to react to changes to the data distribution, they often take an adversarial agnostic view of the security problem. This makes them vulnerable to adversarial activity, which is aimed toward evading the concept drift detection mechanism itself. In this paper, we analyze the security of machine learning from a dynamic and adversarial aware perspective. The existing techniques of restrictive one-class classifier models, complex learning-based ensemble models, and randomization-based ensemble models are shown to be myopic as they approach security as a static task. These methodologies are ill suited for a dynamic environment, as they leak excessive information to an adversary who can subsequently launch attacks which are indistinguishable from the benign data. Based on empirical vulnerability analysis against a sophisticated adversary, a novel feature importance hiding approach for classifier design is proposed. The proposed design ensures that future attacks on classifiers can be detected and recovered from. The proposed work provides motivation, by serving as a blueprint, for future work in the area of dynamic-adversarial mining, which combines lessons learned from streaming data mining, adversarial learning, and cybersecurity. This article is categorized under: Technologies > Machine Learning Technologies > Classification Fundamental Concepts of Data and Knowledge > Motivation and Emergence of Data Mining. © 2018 Wiley Periodicals, Inc.","adaptive models; adversarial machine learning; attacks; classifier; ensemble methods; streaming data","Artificial intelligence; Classifiers; Data mining; Engineering education; Learning systems; Motivation; Adaptive models; Adversarial learning; Attacks; Ensemble methods; Machine learning technology; Real world environments; Streaming data; Vulnerability analysis; Classification (of information)",,,,,"D'souza, D.F., (2014) Avatar CAPTCHA: Telling computers and humans apart via face classification and mouse dynamics, , Phd thesis, University of Louisville, USA; Sethi, T.S., Kantardzic, M., Handling adversarial concept drift in streaming data (2018) Expert Systems with Applications, 97, pp. 18-40; Zhang, F., Chan, P.P., Biggio, B., Yeung, D.S., Roli, F., Adversarial feature selection against evasion attacks (2016) IEEE Transactions on Cybernetics, 46 (3), pp. 766-777; Abramson, M., Toward adversarial online learning and the science of deceptive machines (2015) In, 2015 AAAI Fall Symposium Series; Alabdulmohsin, I.M., Gao, X., Zhang, X., x0026;,). Adding robustness to support vector machines against adversarial reverse engineering (2014) In, Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management, ACM, pp. 231-240; Barreno, M., Nelson, B., Sears, R., Joseph, A.D., Tygar, J.D., x0026;,) (2006) Can machine learning be secure? In, Proceedings of the, 2006, ACM Symposium on Information, Computer and Communications Security, ACM, pp. 16-25; Barreno, M., Nelson, B., Joseph, A.D., Tygar, J.D., The security of machine learning (2010) Machine Learning, 81 (2), pp. 121-148; Barth, A., Rubinstein, B.I.P., Sundararajan, M., Mitchell, J.C., Song, D., Bartlett, P.L., A learning-based approach to reactive security (2012) IEEE Transactions on Dependable and Secure Computing, 9 (4), pp. 482-493; Biggio, B., Corona, I., He, Z.-M., Chan, P.P.K., Giacinto, G., Yeung, D.S., Roli, F., x0026;,). One-and-a-half-class multiple classifier systems for secure learning against evasion attacks at test time (2015) In, Multiple Classifier Systems, Springer, pp. 168-180; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndić, N., Laskov, P., Roli, F., Evasio (2013) attacks against machine learning at test time, pp. 387-402. , In, Machine Learning and Knowledge Discovery in Databases, Springer; Biggio, B., Fumera, G., Roli, F., x0026;,). Adversarial pattern classification using multiple classifiers and randomisation (2008) In, Structural, SyntacticStatistical Pattern Recognition, Springer, pp. 500-509; Biggio, B., Fumera, G., Roli, F., x0026;,). Multiple classifier systems under attack (2010) In, Multiple Classifier Systems, Springer, pp. 74-83; Biggio, B., Fumera, G., Roli, F., Multiple classifier systems for robust classifier design in adversarial environments (2010) International Journal of Machine Learning and Cybernetics, 1 (1-4), pp. 27-41; Biggio, B., Fumera, G., Roli, F., Pattern recognition systems under attack: Design issues and research challenges (2014) International Journal of Pattern Recognition and Artificial Intelligence, 28 (7); Biggio, B., Fumera, G., Roli, F., Security evaluation of pattern classifiers under attack (2014) IEEE Transactions on Knowledge and Data Engineering, 26 (4), pp. 984-996; Bryll, R., Gutierrez-Osuna, R., Quek, F., Attribute bagging: Improving accuracy of classifier ensembles by using random feature subsets (2003) Pattern Recognition, 36 (6), pp. 1291-1302; Brzezinski, D., Stefanowski, J., Reacting to different types of concept drift: The accuracy updated ensemble algorithm (2014) IEEE Transactions on Neural Networks and Learning Systems, 25 (1), pp. 81-94; Carlini, N., Mishra, P., Vaidya, T., Zhang, Y., Sherr, M., Shields, C., Zhou, W., Hidde (2016) voice commands, pp. 513-530. , In, USENIX Security Symposium; Chang, C.-C., Lin, C.-J., Libsvm: A library for support vector machines (2011) ACM Transactions on Intelligent Systems and Technology (TIST), 2 (3), p. 27; Chinavle, D., Kolari, P., Oates, T., Finin, T., x0026;,). Ensembles in adversarial classification for spam (2009) In, Proceedings of the 18th ACM Conference on Information and Knowledge Management, ACM, pp. 2015-2018; Colbaugh, R., Glass, K., x0026;,). Predictive defense against evolving adversaries (2012) In, IEEE International Conference on Intelligence and Security Informatics (ISI), IEEE, pp. 18-23; Colbaugh, R., Glass, K., (2012), pp. 2721-2727. , &,). Predictability-oriented defense against adaptive adversaries. In, IEEE International Conference on Systems, ManCybernetics (SMC), IEEE; Dalvi, N., Domingos, P., Sanghai, S., Verma, D., Adversarial classification (2004) In, Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ACM, pp. 99-108; Ditzler, G., Roveri, M., Alippi, C., Polikar, R., Learning in nonstationary environments: A survey (2015) Computational Intelligence Magazine, 10 (4), pp. 12-25; Gama, J., Žliobaitė, I., Bifet, A., Pechenizkiy, M., Bouchachia, A., A survey on concept drift adaptation (2014) ACM Computing Surveys (CSUR), 46 (4), p. 44; Globerson, A., Roweis, S., x0026;,). Nightmare at test time Robust learning by feature deletion (2006) In, Proceedings of the 23rd International Conference on Machine Learning, ACM, pp. 353-360; Hardt, M., Megiddo, N., Papadimitriou, C., Wootters, M., x0026;,). Strategic classification (2016) In, Proceedings of the, 2016, ACM Conference on Innovations in Theoretical Computer Science, ACM, pp. 111-122; Henke, M., Souto, E., dos Santos, E.M., x0026;,). Analysis of the evolution of features in classification problems with concept drift Application to spam detection (2015) In, IFIP/IEEE International Symposium on Integrated Network Management (IM), IEEE, pp. 874-877; Ho, T.K., The random subspace method for constructing decision forests (1998) IEEE Transactions on Pattern Analysis and Machine Intelligence, 20 (8), pp. 832-844; Hosseini, H., Kannan, S., Zhang, B., Poovendran, R., x0026;,). Deceiving google's perspective API built for detecting toxic comments (2017) , arXiv preprint; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I.P., Tygar, J.D., x0026;,). Adversarial machine learning (2011) In, Proceedings of the 4th ACM Workshop on Security and Artificial Intelligence, ACM, pp. 43-58; Kantchelian, A., Afroz, S., Huang, L., Islam, A.C., Miller, B., Tschantz, M.C., Tygar, J.D., Approaches to adversarial drift (2013) In, Proceedings of the 2013 ACM Workshop on Artificial Intelligence and Security, ACM, pp. 99-110; Kerckhoffs, A., La cryptographie militaire (military cryptography) (1883) Journal of Sciences Militaires (Journal of Military Science, in French), pp. 5-38; Kołcz, A., Teo, C.H., x0026;,). Feature weighting for improved classifier robustness (2009) In, CEAS'09 Sixth Conference on Email and Anti-Spam; Kuncheva, L.I., Classifier ensembles for detecting concept change i (2008) streaming data Overview and perspectives, pp. 5-10. , In, 2nd Workshop SUEMA, 2008; Lee, K., Caverlee, J., Webb, S., x0026;,). Uncovering social spammers social honeypots+ machine learning (2010) In, Proceedings of the 33rd International ACM SIGIR Conference on Research and Development in Information Retrieval, ACM, pp. 435-442; Lichman, M., (2013), http://archive.ics.uci.edu/ml, UCI machine learning repository, Retreived from; Liu, W., Chawla, S., Bailey, J., Leckie, C., Ramamohanarao, K., x0026;,). An efficient adversarial learning strategy for constructing robust classification boundaries (2012) In, AI 2012 Advances in Artificial Intelligence, Springer, pp. 649-660; Lowd, D., Meek, C., x0026;,). Adversarial learning (2005) In, Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining, ACM, pp. 641-647; Miller, B., Kantchelian, A., Afroz, S., Bachwani, R., Dauber, E., Huang, L., Tygar, J.D., Adversarial active learning (2014) In, Proceedings of the 2014 Workshop on Artificial Intelligent and Security Workshop, ACM, pp. 3-14; Minku, L.L., Yao, X., Ddd: A new ensemble approach for dealing with concept drift (2012) IEEE Transactions on Knowledge and Data Engineering, 24 (4), pp. 619-633; Mrdovic, S., Perunicic, B., x0026;,). Kerckhoffs' principle for intrusion detection (2008) In, The 13th International Telecommunications Network Strategy and Planning Symposium, 2008, IEEE, pp. 1-8; Mthembu, L., Marwala, T., x0026;,). A note on the separability index (2008) , arXiv preprint; Onoda, T., Kiuchi, M., x0026;,). Analysis of intrusion detection in control system communication based on outlier detection with one-class classifiers (2012) In, Neural Information Processing, Springer, pp. 275-282; Papernot, N., McDaniel, P., Goodfellow, I., x0026;,). Transferability in machine learning from phenomena to black-box attacks using adversarial samples (2016) , arXiv preprint; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., x0026;,). Practical black-box attacks against machine learning (2017) In, Proceedings of the, 2017, ACM on Asia Conference on Computer and Communications Security, ACM, pp. 506-519; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., x0026;,). The limitations of deep learning in adversarial settings. In, 2016 I.E (2016) European Symposium on Security and Privacy (EuroS&P), IEEE, pp. 372-387; Papernot, N., McDaniel, P., Sinha, A., Wellman, M., x0026;,). Towards the science of security and privacy in machine learning (2016) , arXiv preprint; Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Duchesnay, E., Scikit-learn: Machine learning in python (2011) Journal of Machine Learning Research, 12, pp. 2825-2830; Rndic, N., Laskov, P., (2014), pp. 197-211. , &,). Practical evasion of a learning-based classifier A case study. In, IEEE Symposium on Security and Privacy (SP), IEEE; Ross Quinlan, J., C4 (1993) 5 Programming for machine learning, , , Morgan Kauffmann; Rowe, N.C., John Custy, E., Duong, B.T., Defending cyberspace with fake honeypots (2007) Journal of Computers, 2 (2), pp. 25-36; Salem, M.B., Hershkop, S., Stolfo, S.J., x0026;,). A survey of insider attack detection research (2008) , Insider Attack and Cyber Security, pp. 69-90; Sculley, D., Otey, M.E., Pohl, M., Spitznagel, B., Hainsworth, J., Zhou, Y., x0026;,). Detecting adversarial advertisements in the wild. In, Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD'11, San Diego, CA, 21–24 August (2011) ACM, pp. 274-282; Sethi, T.S., Kantardzic, M., x0026;,). Data driven exploratory attacks on black box classifiers in adversarial domains (2017) , arXiv preprint; Sethi, T.S., Kantardzic, M., Ryu, J.W., x0026;,). Security theater On the vulnerability of classifiers to exploratory attacks (2017) In, 12th Pacific Asia Workshop on Intelligence and Security Informatics, Springer; Sethi, T.S., Kantardzic, M., Don't pay for validation: Detecting drifts from unlabeled data using margin density (2015) Procedia Computer Science, 53, pp. 103-112; Sethi, T.S., Kantardzic, M., On the reliable detection of concept drift from streaming unlabeled data (2017) Expert Systems with Applications, 82, pp. 77-99; Sethi, T.S., Kantardzic, M., Hanquing, H., A grid density based framework for classifying streaming data in the presence of concept drift (2016) Journal of Intelligent Information Systems, 46 (1), pp. 179-211; Singh, A., Walenstein, A., Lakhotia, A., x0026;,). Tracking concept drift in malware families (2012) In, Proceedings of the 5th ACM workshop on Security and Artificial Intelligence, ACM, pp. 81-92; Smutz, C., Stavrou, A., (2016), &,). When a tree falls Using diversity in ensemble classifiers to identify evasion in malware detectors; Stein, T., Chen, E., Mangla, K., x0026;,). Facebook immune system. In, Proceedings of the 4th Workshop on Social Network Systems, ACM, p (2011) 8; Stevens, D., Lowd, D., x0026;,). On the hardness of evading combinations of linear classifiers (2013) In, Proceedings of the 2013 ACM workshop on Artificial Intelligence and Security, ACM, pp. 77-86; Tramèr, F., Zhang, F., Juels, A., Reiter, M.K., Ristenpart, T., x0026;,). Stealing machine learning models via prediction APIs (2016) In, USENIX Security; Vorobeychik, Y., Li, B., x0026;,). Optimal randomized classification in adversarial settings (2014) In, Proceedings of the 2014 International Conference on Autonomous Agents and Multi-Agent Systems, International Foundation for Autonomous Agents and Multiagent Systems, pp. 485-492; Wang, F., (2015) Robust and adversarial data mining, , Doctoral Thesis, School of Information Technologies, The University of Sydney; Woźniak, M., Graña, M., Corchado, E., A survey of multiple classifier systems as hybrid systems (2014) Information Fusion, 16, pp. 3-17; Xu, J., Guo, P., Zhao, M., Erbacher, R.F., Zhu, M., Liu, P., x0026;,). Comparing different moving target defense techniques (2014) In, Proceedings of the First ACM Workshop on Moving Target Defense, ACM, pp. 97-107; Žliobaitė, I., Learning under concept drift a (2010) overview, , , arXiv preprint","Sethi, T.S.; Data Mining Laboratory, United States; email: tegjyotsingh.sethi@louisville.edu",,,"Wiley-Blackwell",,,,,19424787,,,,"English","Wiley Interdiscip. Rev. Data Min. Knowl. Discov.",Review,"Final","All Open Access, Green",Scopus,2-s2.0-85041892437
"Mosca A., Magoulas G.D.","57191280297;26642991300;","Hardening against adversarial examples with the smooth gradient method",2018,"Soft Computing","22","10",,"3203","3213",,2,"10.1007/s00500-017-2998-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040666650&doi=10.1007%2fs00500-017-2998-4&partnerID=40&md5=e128d00e18c34fff4dae08bcc0e4a198","Department of Computer Science and Information Systems, Birkbeck, University of London, Malet Street, London, WC1E 7HX, United Kingdom","Mosca, A., Department of Computer Science and Information Systems, Birkbeck, University of London, Malet Street, London, WC1E 7HX, United Kingdom; Magoulas, G.D., Department of Computer Science and Information Systems, Birkbeck, University of London, Malet Street, London, WC1E 7HX, United Kingdom","Commonly used methods in deep learning do not utilise transformations of the residual gradient available at the inputs to update the representation in the dataset. It has been shown that this residual gradient, which can be interpreted as the first-order gradient of the input sensitivity at a particular point, may be used to improve generalisation in feed-forward neural networks, including fully connected and convolutional layers. We explore how these input gradients are related to input perturbations used to generate adversarial examples and how the networks that are trained with this technique are more robust to attacks generated with the fast gradient sign method. © 2018, Springer-Verlag GmbH Germany, part of Springer Nature.",,"Soft computing; Software engineering; First order; Generalisation; Input perturbation; Input sensitivity; Residual gradient; Gradient methods",,,,,"Anastasiadis, A.D., Magoulas, G.D., Vrahatis, M.N., An efficient improvement of the rprop algorithm (2003) Proceedings of the First International Workshop on Artificial Neural Networks in Pattern Recognition (IAPR 2003), p. 197. , University of Florence, Italy; Ciresan, D.C., Meier, U., Gambardella, L.M., Schmidhuber, J., Deep, big, simple neural nets for handwritten digit recognition (2010) Neural Comput, 22 (12), pp. 3207-3220; Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette, F., Marchand, M., Lempitsky, V., Domain-adversarial training of neural networks (2016) J Mach Learn Res, 17 (59), pp. 1-35; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Hahnloser, R.H., Sarpeshkar, R., Mahowald, M.A., Douglas, R.J., Seung, H.S., Digital selection and analogue amplification coexist in a cortex-inspired silicon circuit (2000) Nature, 405 (6789), p. 947; Hecht-Nielsen, R., Theory of the backpropagation neural network (1989) International Joint Conference on Neural Networks, 1989, pp. 593-605. , IJCNN, IEEE; Hinton, G., Vinyals, O., Dean, J., (2015) Distilling the Knowledge in a Neural Network; Igel, C., Hüsken, M., Improving the Rprop learning algorithm (2000) Proceedings of the Second International ICSC Symposium on Neural Computation (NC 2000), pp. 115-121. , Citeseer; Ioffe, S., Szegedy, C., (2015) Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift; Kingma, D., Ba, J., (2014) Adam: A Method for Stochastic Optimization; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images, , Thesis; LeCun, Y., Bengio, Y., Convolutional networks for images, speech, and time series (1995) Handb Brain Theory Neural Netw, 3361, p. 310; Lecun, Y., Cortes, C., (1998) The MNIST Database of Handwritten Digits, , http://yann.lecun.com/exdb/mnist/, Accessed 3 Sep 2016; Miikkulainen, R., Dyer, M.G., Natural language processing with modular PDP networks and distributed lexicon (1991) Cognit Sci, 15 (3), pp. 343-399; Mosca, A., Magoulas, G.D., (2015); Mosca, A., Magoulas, G., Deep incremental boosting (2016) GCAI 2016. 2Nd Global Conference on Artificial Intelligence, Epic Series in Computing, 41, pp. 293-302. , Benzmuller C, Sutcliffe G, Rojas R, EasyChair; Mosca, A., Magoulas, G.D., Learning input features representations in deep learning (2017) Advances in Computational Intelligence Systems, pp. 433-445. , Springer International Publishing; Mosca, A., Training convolutional networks with weight-wise adaptive learning rates (2017) ESANN 2017 Proceedings, European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning. Bruges (Belgium), 26–28, , http://i6doc.com, April 2017; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., (2016) Practical Black-Box Attacks against Deep Learning Systems Using Adversarial Examples, , (a); Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Security and Privacy (SP), 2016 IEEE Symposium On, IEEE, pp. 582-597; Riedmiller, M., Braun, H., A direct adaptive method for faster backpropagation learning: The rprop algorithm (1993) Proceeding of the IEEE International Conference on Neural Networks, IEEE, pp. 586-591; Rumelhart, D.E., Hinton, G.E., Williams, R.J., Learning representations by back-propagating errors (1988) Cognit Modeling, 5 (3), p. 1; Simard, P.Y., Steinkraus, D., Platt, J.C., (2003) Best practices for convolutional neural networks applied to visual document analysis, , http://research.microsoft.com/apps/pubs/default.aspx?id=68920; Springenberg, J.T., Dosovitskiy, A., Brox, T., Riedmiller, M., (2014) Striving for Simplicity: The All Convolutional Net; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks","Mosca, A.; Department of Computer Science and Information Systems, Malet Street, United Kingdom; email: a.mosca@dcs.bbk.ac.uk",,,"Springer Verlag",,,,,14327643,,,,"English","Soft Comput.",Article,"Final","",Scopus,2-s2.0-85040666650
"Freed D., Palmer J., Minchala D., Levy K., Ristenpart T., Dell N.","57210687213;57202050595;57202048164;57202613926;23393983800;45560910100;","""A stalker's paradise"": How intimate partner abusers exploit technology",2018,"Conference on Human Factors in Computing Systems - Proceedings","2018-April",,,"","",,93,"10.1145/3173574.3174241","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046954121&doi=10.1145%2f3173574.3174241&partnerID=40&md5=26fc880ea288e55991d3316e5ccd770e","Cornell Tech, United States; Hunter College, United States; City College of New York, United States; Cornell University, United States","Freed, D., Cornell Tech, United States; Palmer, J., Hunter College, United States; Minchala, D., City College of New York, United States; Levy, K., Cornell University, United States; Ristenpart, T., Cornell Tech, United States; Dell, N., Cornell Tech, United States","This paper describes a qualitative study with 89 participants that details how abusers in intimate partner violence (IPV) contexts exploit technologies to intimidate, threaten, monitor, impersonate, harass, or otherwise harm their victims. We show that, at their core, many of the attacks in IPV contexts are technologically unsophisticated from the perspective of a security practitioner or researcher. For example, they are often carried out by a UI-bound adversary-an adversarial but authenticated user that interacts with a victim's device or account via standard user interfaces- or by downloading and installing a ready-made application that enables spying on a victim. Nevertheless, we show how the sociotechnical and relational factors that characterize IPV make such attacks both extremely damaging to victims and challenging to counteract, in part because they undermine the predominant threat models under which systems have been designed. We discuss the nature of these new IPV threat models and outline opportunities for HCI research and design to mitigate these attacks. © 2018 ACM.","Domestic abuse; Domestic violence; Intimate partner violence; IPV; Privacy; Safety; Security; Violence against women","Accident prevention; Authentication; Data privacy; Human engineering; Domestic abuse; Domestic violence; Intimate partner violence; Security; Violence against women; User interfaces",,,,,"(2014) TrueCrypt, , http://truecrypt.sourceforge.net/, 2014; Ashktorab, Z., Vitak, J., Designing cyberbullying mitigation and prevention solutions through participatory design with teenagers (2016) ACM Conference on Human Factors in Computing Systems, pp. 3895-3905. , ACM; Assange, J., Dreyfus, S., Weinmann, R., (1997) Rubberhose, , https://web.archive.org/web/20100915130330/http://iq.org/~proff/rubberhose.org/, 1997; Bardram, J.E., The trouble with login: On usability and computer security in ubiquitous computing (2005) Personal and Ubiquitous Computing, 9 (6), pp. 357-367. , 2005; Boyd, D., Truth, lies, and 'doxxing': The real moral of the Gawker/Reddit story (2012) Wired, , 2012; Bernheim Brush, A.J., Inkpen, K., Yours, mine and ours? Sharing and use of technology in domestic environments (2007) UbiComp, 7, pp. 109-126. , Springer; Campbell, J.C., Webster, D., Koziol-McLain, J., Block, C., Campbell, D., Curry, M.A., Gary, F., Sachs, C., Risk factors for femicide in abusive relationships: Results from a multisite case control study (2003) American Journal of Public Health, 93 (7), pp. 1089-1097. , 2003; Chang, J.C., Dado, D., Hawker, L., Cluss, P.A., Buranosky, R., Slagel, L., McNeil, M., Scholle, S.H., Understanding turning points in intimate partner violence: Factors and circumstances leading women victims toward change (2010) Journal of Women's Health, 19 (2), pp. 251-259. , 2010; Clarke, V., Braun, V., Thematic analysis (2014) Encyclopedia of Critical Psychology, pp. 1947-1952. , Springer; Cooley, M.R., Turner, S.M., Beidel, D.C., Composite Abuse Scale (CAS) (2014) Measures of Violence, p. 175. , 2014; Devries, K.M., Mak, J.Y.T., Garcia-Moreno, C., Petzold, M., Child, J.C., Falder, G., Lim, S., Rosenfeld, L., The global prevalence of intimate partner violence against women (2013) Science, 340 (6140), pp. 1527-1528. , 2013; Dillon, G., Hussain, R., Loxton, D., Rahman, S., Mental and physical health and intimate partner violence against women: A review of the literature (2013) International Journal of Family Medicine 2013, , 2013; Dimond, J.P., Fiesler, C., Bruckman, A.S., Domestic violence and information communication technologies (2011) Interacting with Computers, 23 (5), pp. 413-421. , 2011; Dinakar, K., Jones, B., Havasi, C., Lieberman, H., Picard, R., Common sense reasoning for detection, prevention, and mitigation of cyberbullying (2012) ACM Transactions on Interactive Intelligent Systems (TiiS), 2 (3), p. 18. , 2012; Douglas, D.M., Doxing: A conceptual analysis (2016) Ethics and Information Technology, 18 (3), pp. 199-210. , 2016; Egelman, S., Brush, A.J., Inkpen, K.M., Family accounts: A new paradigm for user accounts within the home environment (2008) Proceedings of the 2008 ACM Conference on Computer Supported Cooperative Work, pp. 669-678. , ACM; Ellison, L., Akdeniz, Y., Cyber-stalking: The regulation of harassment on the internet (1998) Criminal Law Review, 29, pp. 29-48. , 1998; Eterovic-Soric, B., Choo, K.-K.R., Ashman, H., Mubarak, S., Stalking the stalkers-detecting and deterring stalking behaviours using technology: A review (2017) Computers & Security, 70, pp. 278-289. , 2017; Ford-Gilboe, M., Nadine Wathen, C., Varcoe, C., MacMillan, H.L., Scott-Storey, K., Mantler, T., Hegarty, K., Perrin, N., Development of a brief measure of intimate partner violence experiences: The Composite Abuse Scale (Revised) Short Form (CAS R-SF) (2016) BMJ Open, 6 (12). , 2016; Fraser, C., Olsen, E., Lee, K., Southworth, C., Tucker, S., The new age of stalking: Technological implications for stalking (2010) Juvenile and Family Court Journal, 61 (4), pp. 39-55. , 2010; Freed, D., Palmer, J., Minchala, D., Levy, K., Ristenpart, T., Dell, N., Digital technologies and intimate partner violence: A qualitative analysis with multiple stakeholders (2017) PACM: Human-Computer Interaction: Computer-Supported Cooperative Work and Social Computing (CSCW), 1 (2). , 2017; Guberman, J., Schmitz, C., Hemphill, L., Quantifying toxicity and verbal violence on Twitter (2016) Proceedings of the 19th ACM Conference on Computer Supported Cooperative Work and Social Computing Companion, pp. 277-280. , ACM; Hayashi, E., Riva, O., Strauss, K., Brush, A.J., Schechter, S., Goldilocks and the two mobile devices: Going beyond all-or-nothing access to a device's applications (2012) Proceedings of the Eighth Symposium on Usable Privacy and Security, p. 2. , ACM; Karlson, A., Brush, A.J., Schechter, S., Can I borrow your phone?: Understanding concerns when sharing mobile phones (2009) Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 1647-1650. , ACM; Liu, Y., Rahmati, A., Huang, Y., Jang, H., Zhong, L., Zhang, Y., Zhang, S., XShare: Supporting impromptu sharing of mobile phones (2009) Proceedings of the 7th International Conference on Mobile Systems, Applications, and Services, pp. 15-28. , ACM; Macdonald, D.W., Jacobsen, K.S., Burnham, D., Johnson, P.J., Loveridge, A.J., Cecil: A moment or a movement? Analysis of media coverage of the death of a lion, Panthera leo (2016) Animals, 6 (5), p. 26. , 2016; Matthews, T., Liao, K., Turner, A., Berkovich, M., Reeder, R., Consolvo, S., She'll just grab any device that's closer: A Study of Everyday Device & Account Sharing in Households (2016) Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems, pp. 5921-5932. , ACM; Matthews, T., O'Leary, K., Turner, A., Sleeper, M., Woelfer, J.P., Shelton, M., Manthorne, C., Consolvo, S., Stories from survivors: Privacy & security practices when coping with intimate partner abuse (2017) Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems, pp. 2189-2201. , ACM; Mazurek, M., Arsenault, J.P., Bresee, J., Gupta, N., Ion, I., Johns, C., Lee, D., Reiter, M., Access control for home data sharing: Attitudes, needs and practices (2010) Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI'10), pp. 645-654. , ACM, New York, NY, USA; McDonald, A.D., Kuhn, M.G., StegFS: A steganographic file system for Linux (1999) International Workshop on Information Hiding, pp. 463-477. , Springer; Nielsen, J., Finding usability problems through heuristic evaluation (1992) Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 373-380. , ACM; Patton, S., (2003) Pathways: How Women Leave Violent Men, , 2003; Pence, E., Paymar, M., Power and control: Tactics of men who batter: An educational curriculum (1990) Minnesota Program Development Incorporated; Rabin, R.F., Jennings, J.M., Campbell, J.C., Bair-Merritt, M.H., Intimate partner violence screening tools: A systematic review (2009) American Journal of Preventive Medicine, 36 (5), pp. 439-445. , 2009; Ruoti, S., Andersen, J., Zappala, D., Seamons, K., (2015) Why Johnny Still, Still Can't Encrypt: Evaluating the Usability of a Modern PGP Client, , 2015; Seifert, J., De Luca, A., Conradi, B., Hussmann, H., Treasurephone: Context-sensitive user data protection on mobile phones (2010) Pervasive Computing (2010), pp. 130-137; Sheng, S., Broderick, L., Koranda, C.A., Hyland, J.J., Why Johnny still can't encrypt: Evaluating the usability of email encryption software (2006) Symposium on Usable Privacy and Security, pp. 3-4; Shimizu, A., Domestic violence in the digital age: Towards the creation of a comprehensive cyberstalking statute (2013) Berkeley J. Gender L. & Just, 28, p. 116. , 2013; Skillen, A., Mannan, M., Mobiflage: Deniable storage encryption for mobile devices (2014) IEEE Transactions on Dependable and Secure Computing, 11 (3), pp. 224-237. , 2014; Smith, S.G., Basile, K.C., Gilbert, L.K., Merrick, M.T., Patel, N., Walling, M., Jain, A., (2017) National Intimate Partner and Sexual Violence Survey (NISVS): 2010-2012 State Report, , 2017; Southworth, C., Dawson, S., Fraser, C., Tucker, S., A high-tech twist on abuse: Technology, intimate partner stalking, and advocacy (2005) Violence Against Women (2005); Southworth, C., Finn, J., Dawson, S., Fraser, C., Tucker, S., Intimate partner violence, technology, and stalking (2007) Violence Against Women, 13 (8), pp. 842-856. , 2007; Southworth, C., Tucker, S., Technology, stalking and domestic violence victims (2006) Miss. LJ, 76, p. 667. , 2006; Stöckl, H., Devries, K., Rotstein, A., Abrahams, N., Campbell, J., Watts, C., Moreno, C.G., The global prevalence of intimate partner homicide: A systematic review (2013) The Lancet, 382 (9895), pp. 859-865. , 2013; Stroud, S.R., The dark side of the online self: A pragmatist critique of the growing plague of revenge porn (2014) Journal of Mass Media Ethics, 29 (3), pp. 168-183. , 2014; (2014) Privacy & Safety on Facebook: A Guide for Survivors of Abuse, , http://nnedv.org/downloads/SafetyNet/NNEDV_FB_Privacy_and_Safety_Guide_2014.pdf, National Network to End Domestic Violence and Facebook, 2014; Vitak, J., Chadha, K., Steiner, L., Ashktorab, Z., Identifying women's experiences with and strategies for mitigating negative effects of online harassment (2017) ACM Conference on Computer Supported Cooperative Work and Social Computing, pp. 1231-1245. , ACM; Walker, L.E., Battered women and learned helplessness (1977) Victimology (1977); Wharton, C., Rieman, J., Lewis, C., Polson, P., The cognitive walkthrough method: A practitioner's guide (1994) Usability Inspection Methods, pp. 105-140. , John Wiley & Sons, Inc; Whitten, A., Tygar, J., Why Johnny can't Encrypt: A usability evaluation of PGP 5.0 (1999) USENIX Security Symposium, 348; Wisniewski, P., Xu, H., Rosson, M.B., Perkins, D.F., Carroll, J.M., Dear diary: Teens reflect on their weekly online risk experiences (2016) Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems, pp. 3919-3930. , ACM; Woodlock, D., (2016) The Abuse of Technology in Domestic Violence and Stalking. Violence Against Women, , 2016, 1077801216646277; Yllo, K.A., (2005) Through a Feminist Lens. Current Controversies in Family Violence, , 2005",,,"ACM SIGCHI","Association for Computing Machinery","2018 CHI Conference on Human Factors in Computing Systems, CHI 2018","21 April 2018 through 26 April 2018",,135975,,9781450356206; 9781450356213,,,"English","Conf Hum Fact Comput Syst Proc",Conference Paper,"Final","",Scopus,2-s2.0-85046954121
"Lawson V., Elwood S.","7005293677;7004191943;","Relational poverty politics: Forms, struggles, and possibilities",2018,"Relational Poverty Politics: Forms, Struggles, and Possibilities",,,,"1","250",,9,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058481824&partnerID=40&md5=f1ca8b9fd0a3c78ffb672aa978866c16","University of Washington, United States","Lawson, V., University of Washington, United States; Elwood, S., University of Washington, United States","This collection examines the power and transformative potential of movements that fight against poverty and inequality. Broadly, poverty politics are struggles to define who is poor, what it means to be poor, what actions might be taken, and who should act. These movements shape the sociocultural and political economic structures that constitute poverty and privilege as material and social relations. Editors Victoria Lawson and Sarah Elwood focus on the politics of insurgent movements against poverty and inequality in seven countries (Argentina, India, Brazil, South Africa, Thailand, Singapore, and the United States). The contributors explore theory and practice in alliance politics, resistance movements, the militarized repression of justice movements, global counterpublics, and political theater. These movements reflect the diversity of poverty politics and the relations between bureaucracies and antipoverty movements. They discuss work done by mass and other types of mobilizations across multiple scales; forms of creative and political alliance across axes of difference; expressions and exercises of agency by people named as poor; and the kinds of rights and other claims that are made in different spaces and places. Relational Poverty Politics advocates for poverty knowledge grounded in relational perspectives that highlight the adversarial relationship of poverty to privilege, as well as the possibility for alliances across different groups. It incorporates current research in the field and demonstrates how relational poverty knowledge is best seen as a model for understanding how theory is derivative of action as much as the other way around. The book lays a foundation for realistic change that can directly attack poverty at its roots. © 2018 by the University of Georgia Press. All Rights Reserved.",,,,,,,,"Lawson, V.; University of WashingtonUnited States",,,"University of Georgia Press",,,,,,9780820353128; 9780820353135,,,"English","Relational Poverty Polit.: Forms, Struggl., and Possibilities",Book,"Final","",Scopus,2-s2.0-85058481824
"Masood R., Vatsalan D., Ikram M., Kaafar M.A.","54999892400;36024754600;57206150249;24338380900;","Incognito: A method for obfuscating web data",2018,"The Web Conference 2018 - Proceedings of the World Wide Web Conference, WWW 2018",,,,"267","276",,11,"10.1145/3178876.3186093","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075033657&doi=10.1145%2f3178876.3186093&partnerID=40&md5=c03301ad490925b1eab10a2dcf51d69d","Data61-CSIRO and UNSW, Sydney, Australia; Data61-CSIRO, Sydney, Australia; Data61-CSIRO and Macquarie University and Optus Macquarie University Cyber Security Hub, Sydney, Australia","Masood, R., Data61-CSIRO and UNSW, Sydney, Australia; Vatsalan, D., Data61-CSIRO, Sydney, Australia; Ikram, M., Data61-CSIRO and UNSW, Sydney, Australia; Kaafar, M.A., Data61-CSIRO and Macquarie University and Optus Macquarie University Cyber Security Hub, Sydney, Australia","Users leave a trail of their personal data, interests, and intents while surfing or sharing information on the Web. Web data could therefore reveal some private/sensitive information about users based on inference analysis. The possible identification of information corresponding to a single individual by an inference attack holds true even if the user identifiers are encoded or removed in the Web data. Several works have been done on improving privacy of Web data through obfuscation methods∼\citeHow09,Dom09,Sha05,Che14. However, these methods are neither comprehensive, generic to be applicable to any Web data, nor effective against adversarial attacks. To this end, we propose a privacy-aware obfuscation method for Web data addressing these identified drawbacks of existing methods. We use probabilistic methods to predict privacy risk of Web data that incorporates all key privacy aspects, which are uniqueness, uniformity, and linkability of Web data. The Web data with high predicted risk are then obfuscated by our method to minimize the privacy risk using semantically similar data. Our method is resistant against adversary who has knowledge about the datasets and model learned risk probabilities using differential privacy-based noise addition. Experimental study conducted on two real Web datasets validates the significance and efficacy of our method. Our results indicate that the average privacy risk reaches to 100% with a minimum of 10 sensitive Web entries, while at most 0% privacy risk could be attained with our obfuscation method at the cost of average utility loss of 64.3%. © 2018 IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC BY 4.0 License.","Adversarial machine learning; Data obfuscation; Privacy risk evaluation; Probabilistic model; Semantic similarity; Web data privacy","Data Sharing; Risks; World Wide Web; Average utilities; Differential privacies; Inference attacks; Noise addition; Privacy aware; Probabilistic methods; Risk probabilities; Sharing information; Data privacy",,,,,"(2018) 2018. Gensim: Topic Modelling for Humans, , https://radimrehurek.com/gensim/, Accessed on: 12-01-2018; (2018) 2018. Natural Language Toolkit, , http://www.nltk.org, Accessed on: 12-01-2018; Balsa, E., Troncoso, C., Diaz, C., OB-pws: Obfuscation-based private web search (2012) IEEE Symposium on Security and Privacy, SP 2012, pp. 491-505. , 21-23 May 2012, San Francisco, California, USA; Biega, J., Mele, I., Weikum, G., Probabilistic prediction of privacy risks in user search histories (2014) Proceedings of the First International Workshop on Privacy and Secuirty of Big Data, PSBD@CIKM 2014, pp. 29-36. , Shanghai, China, November 7, 2014; Biega, J.A., Gummadi, K.P., Mele, I., Milchevski, D., Tryfonopoulos, C., Weikum, G., R-susceptibility: An ir-centric approach to assessing privacy risks for users in online communities (2016) Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '16), pp. 365-374. , ACM, New York, NY, USA; Chairunnanda, P., Pham, N., Hengartner, U., Privacy: Gone with the typing! identifying web users by their typing patterns (2011) PASSAT/ SocialCom 2011, Privacy, Security, Risk and Trust (PASSAT), 2011 IEEE Third International Conference on and 2011 IEEE Third International Conference on Social Computing (SocialCom), pp. 974-980. , Boston, MA, USA, 9-11 Oct., 2011; Chen, T., Boreli, R., Kaafar, M.A., Friedman, A., On the efectiveness of obfuscation techniques in online social networks (2014) Privacy Enhancing Technologies-14th International Symposium, PETS 2014, Amsterdam, the Netherlands, pp. 42-62. , July 16-18, 2014. Proceedings; Chow, R., Golle, P., (2009) Faking Contextual Data for Fun, Proit, and Privacy (2009), pp. 105-108; Das, A., Borisov, N., Caesar, M., Do you hear what i hear?: Fingerprinting smart devices through embedded acoustic components (2014) Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security (CCS), pp. 441-452. , Scottsdale, AZ, USA, November 3-7, 2014; Das, A., Borisov, N., Caesar, M., Tracking mobile web users through motion sensors: Attacks and defenses (2016) 23rd Annual Network and Distributed System Security Symposium (NDSS), , San Diego, California, USA, February 21-24, 2016. The Internet Society; Dey, S., Roy, N., Xu, W., Choudhury, R.R., Nelakuditi, S., AccelPrint: Imperfections of accelerometers make smartphones trackable (2014) 21st Annual Network and Distributed System Security Symposium (NDSS), , San Diego, California, USA, February 23-26, 2014. The Internet Society; Josep, D.-F., Solanas, A., Jordi, C.-R., H (k)-Private information retrieval from privacy-uncooperative queryable databases (2009) Online Information Review, 33 (4), pp. 720-744. , (2009); Eckersley, P., How unique is your web browser (2010) Privacy Enhancing Technologies, 10th International Symposium, PETS 2010, pp. 1-18. , Berlin, Germany, July 21-23, 2010. Proceedings; Gervais, A., Shokri, R., Singla, A., Capkun, S., Lenders, V., Quantifying web-search privacy (2014) Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security (CCS '14), pp. 966-977. , ACM, New York, NY, USA; Han, J., Kamber, M., Pei, J., (2011) Data Mining: Concepts and Techniques, , 3rd edition. Morgan Kaufmann; Hansell, S., (2006) AOL Removes Search Data on Vast Group of Web Users, , http://query.nytimes.com/gst/fullpage.html?res=9504e5d81e3f93ba3575bc0a9609c8b63, New York Times (2006); Horst, B., Michael, C.T., (2001) Hidden Markov Models: Applications in Computer Vision, 45. , World Scientiic; Howe, D.C., Nissenbaum, H., TrackMeNot: Resisting surveillance in web search (2009) Lessons from the Identity Trail: Anonymity, Privacy, and Identity in A Networked Society, 23, pp. 417-436. , (2009); Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I.P., Tygar, J.D., Adversarial machine learning (2011) Proceedings of the 4th ACM Workshop on Security and Artiicial Intelligence, pp. 43-58. , AISec 2011, Chicago, IL, USA, October 21, 2011; Ikram, M., Kaafar, M.A., A irst look at mobile Ad-Blocking apps (2017) 16th IEEE International Symposium on Network Computing and Applications, pp. 343-350. , NCA 2017, Cambridge, MA, USA, October 30-November 1, 2017; Kurtz, A., Gascon, H., Becker, T., Rieck, K., Freiling, F.C., Fingerprinting mobile devices using personalized conigurations (2016) PoPETs 2016, 1 (2016), pp. 4-19; Laperdrix, P., Rudametkin, W., Baudry, B., Beauty and the beast: Diverting modern web browsers to build unique browser fingerprints (2016) Proceedings-IEEE Symposium on Security and Privacy, SP 2016 (2016), pp. 878-894; Li, C., Houtan, S.-M., Yang, X., Protecting individual information against inference attacks in data publishing (2007) Proceedings of the 12th International Conference on Database Systems for Advanced Applications (DASFAA'07), pp. 422-433. , Springer-Verlag, Berlin, Heidelberg; Li, Y., McLean, D., Bandar, Z.A., O'Shea, J.D., Crockett, K., Sentence similarity based on semantic nets and corpus statistics (2006) IEEE Transactions on Knowledge and Data Engineering, 18 (8), pp. 1138-1150. , (2006); Li, Y., McLean, D., Bandar, Z.A., O'Shea, J.D., Crockett, K., Sentence similarity based on semantic nets and corpus statistics (2006) IEEE Trans. on Knowl. and Data Eng, 18 (8), pp. 1138-1150. , (Aug. 2006); Liu, K., Terzi, E., A framework for computing the privacy scores of users in online social networks (2010) ACM Trans. Knowl. Discov. Data 5, 1, 30p. , Article 6 (Dec. 2010); Masood, R., Zhao, B.Z.H., Asghar, H.J., Kaafar, M.A., POSTER: Touchtrack: How unique are your touch gestures (2017) Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, CCS 2017, pp. 2555-2557. , Dallas, TX, USA, October 30-November 03, 2017; Narayanan, A., Shmatikov, V., Robust de-anonymization of large sparse datasets (2008) Proceedings of the 2008 IEEE Symposium on Security and Privacy (SP '08). IEEE Computer Society, pp. 111-125. , Washington, DC, USA; Lstrok, O.U., Castelluccia, C., Janc, A., Why johnny can't browse in peace: On the uniqueness of web browsing history patterns (2012) 5th Workshop on Hot Topics in Privacy Enhancing Technologies (HotPETs 2012), pp. 1-16; Peddinti, S.T., Saxena, N., On the privacy of web search based on query obfuscation: A case study of trackmenot (2010) Proceedings of the 10th International Conference on Privacy Enhancing Technologies (PETS'10), pp. 19-37. , Springer-Verlag, Berlin, Heidelberg; Salamatian, S., Zhang, A., Calmon, F.P., Bhamidipati, S., Fawaz, N., Kveton, B., Oliveira, P., Taft, N., How to hide the elephant-or the donkey-in the room: Practical privacy against statistical inference for large data (2013) IEEE Global Conference on Signal and Information Processing, GlobalSIP 2013, pp. 269-272. , Austin, TX, USA, December 3-5, 2013; Shapira, B., Elovici, Y., Meshiach, A., Kulik, T., PRAW-A privacy model for the web (2005) Journal of the American Society for Information Science and Technology (JASIST), 56 (2), pp. 159-172. , (2005); Su, J., Shukla, A., Goel, S., Narayanan, A., Deanonymizing web browsing data with social networks (2017) Proceedings of the 26th International Conference on World Wide Web, (WWW) 2017, pp. 1261-1269. , Perth, Australia, April 3-7, 2017; Sweeney, L., Weaving technology and policy together to maintain conidentiality (1997) The Journal of Law, Medicine &Ethics, 25 (2-3), pp. 98-110. , (1997); Sweeney, L., (2000) Simple Demographics Often Identify People Uniquely, pp. 1-34. , http://dataprivacylab.org/projects/identiiability/paper1.pdf, Carnegie Mellon University, Data Privacy Working Paper 3. Pittsburgh 2000 (2000); Tibshirani, R., Walther, G., Hastie, T., Estimating the number of clusters in a data set via the gap statistic (2001) Journal of the Royal Statistical Society: Series B (Statistical Methodology), 63 (2), pp. 411-423. , (2001); Weinsberg, U., Bhagat, S., Ioannidis, S., Taft, N., BlurMe: Inferring and obfuscating user gender based on ratings (2012) Proceedings of the Sixth ACM Conference on Recommender Systems (RecSys '12), pp. 195-202. , ACM, New York, NY, USA; Yen, T.-F., Xie, Y., Yu, F., Yu, R.P., Abadi, M., Host fingerprinting and tracking on the web: Privacy and security implications (2012) 19th Annual Network and Distributed System Security Symposium (NDSS), , San Diego, California, USA, February 5-8, 2012. The Internet Society; Zhou, Z., Diao, W., Liu, X., Zhang, K., Acoustic fingerprinting revisited: Generate stable device id stealthily with inaudible sound (2014) Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security (CCS '14), pp. 429-440. , ACM, New York, NY, USA",,,"Amazon;Baidu;et al.;Google;IDEX Lyon;Inria","Association for Computing Machinery, Inc","27th International World Wide Web, WWW 2018","23 April 2018 through 27 April 2018",,159681,,9781450356398,,,"English","Web Conf. - Proc. World Wide Web Conf., WWW",Conference Paper,"Final","",Scopus,2-s2.0-85075033657
[No author name available],[No author id available],"ACM International Conference Proceeding Series",2018,"ACM International Conference Proceeding Series",,,,"","",124,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047204671&partnerID=40&md5=b24ec879802d0fb7a9578c70d0681adc",,"","The proceedings contain 26 papers. The topics discussed include: robustness of deep autoencoder in intrusion detection under adversarial contamination; understanding the challenges to adoption of the microsoft elevation of privilege game; reinventing the privilege drop: how principled preservation of programmer intent would prevent security bugs; integrated instruction set randomization and control reconfiguration for securing cyber-physical systems; formal verification of the W3C web authentication protocol; application of capability-based cyber risk assessment methodology to a space system; challenges and approaches of performing canonical action research in software security; quantifying the security e?ectiveness of firewalls and dmzs; combinatorial security testing course; HACSAW: a trusted framework for cyber situational awareness; a comparative analysis of manual methods for analyzing security requirements in regulatory documents; an expert-based bibliometric for a science of security; detecting monitor compromise using evidential reasoning; exploring the raspberry pi for data summarization in wireless sensor networks; hourglass-shaped architecture for model-based development of safe and secure cyber-physical systems; indirect cyber attacks by perturbation of environment control: a data-driven attack model; and investigating tensorflow for airport facial identification.",,,,,,,,,,"National Security Agency","Association for Computing Machinery","5th Annual Symposium and Bootcamp on Hot Topics in the Science of Security, HoTSoS 2018","10 April 2018 through 11 April 2018",,136022,,9781450364553,,,"English","ACM Int. Conf. Proc. Ser.",Conference Review,"Final","",Scopus,2-s2.0-85047204671
"Xie C.-H., Yang G.-H.","56784918600;7405751358;","Secure estimation for cyber-physical systems with adversarial attacks and unknown inputs: An L2-gain method",2018,"International Journal of Robust and Nonlinear Control","28","6",,"2131","2143",,18,"10.1002/rnc.4007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043368635&doi=10.1002%2frnc.4007&partnerID=40&md5=1247271eccc4e23c15af54e786ecd676","College of Information Science and Engineering, Northeastern University, Shenyang, China; State Key Laboratory of Synthetical Automation for Process Industries, Northeastern University, Shenyang, China","Xie, C.-H., College of Information Science and Engineering, Northeastern University, Shenyang, China; Yang, G.-H., College of Information Science and Engineering, Northeastern University, Shenyang, China, State Key Laboratory of Synthetical Automation for Process Industries, Northeastern University, Shenyang, China","This paper investigates the attack-resilient state estimation problem for linear systems with adversarial attacks and unknown inputs, where the upper bound of the unknown inputs is unknown. It is assumed that the attacker has limited resources and can only manipulate a certain number of sensors. In most of the existing observer design approaches for the systems with unknown inputs even in the absence of attacks, the observer matching condition should be satisfied. To overcome this restriction, a novel switched observer is proposed, where the matched unknown inputs will be completely compensated by means of the outputs and the mismatched part will be suppressed in terms of L2-gain rejection property. Meanwhile, the observer can provide an attack-resilient state estimation. Compared with the existing results, the proposed observer can guarantee that the resulting observer error system is stable with unknown input attenuation level γ that can be optimized. Finally, a simulation example of an unmanned ground vehicle is provided to show the effectiveness of the proposed approach. Copyright © 2017 John Wiley & Sons, Ltd.","attack resilient; estimation; L2-gain rejection property; robustness","Cyber Physical System; Estimation; Linear systems; Robustness (control systems); State estimation; attack resilient; Attenuation levels; Estimation problem; L2 gain; Observer design; Observer matching conditions; Simulation example; Unmanned ground vehicles; Embedded systems",,,,,"Cárdenas, A., Amin, S., Sastry, S., Research challenges for the security of control systems (2008) Proceedings of the 3rd Conference on Hot topics in Security, , San Jose, CA; Chen, T.M., Stuxnet, the real start of cyber warfare? [Editor's Note] (2010) IEEE Netw, 24 (6), pp. 2-3; Fidler, D.P., Was stuxnet an act of war? decoding a cyberattack (2011) IEEE Secur Priv, 9 (4), pp. 56-59; Zhang, H., Cheng, P., Shi, L., Chen, J., Optimal denial-of-service attack scheduling with energy constraint (2015) IEEE Trans Autom Control, 60 (11), pp. 3023-3028; Zhang, H., Cheng, P., Shi, L., Chen, J., Optimal DoS attack scheduling in wireless networked control system (2016) IEEE Trans Control Syst Technol, 24 (3), pp. 843-852; Li, Y., Shi, L., Chen, T., Detection against linear deception attacks on multi-sensor remote state estimation (2017) IEEE Trans Control Netw Syst, , https://doi.org/10.1109/TCNS.2017.2648508; Ding, D., Wang, Z., Ho, D.W.C., Wei, G., Distributed recursive filtering for stochastic systems under uniform quantizations and deception attacks through sensor networks (2017) Automatica, 78, pp. 231-240; Hao, J., Piechocki, R.J., Kaleshi, D., Chin, W.H., Fan, Z., Sparse malicious false data injection attacks and defense mechanisms in smart grids (2015) IEEE Trans Ind Inform, 11 (5), pp. 1198-1209; Zhu, M., Martínez, S., On the performance analysis of resilient networked control systems under replay attacks (2014) IEEE Trans Autom Control, 59 (3), pp. 804-808; Teixeira, A., Shames, I., Sandberg, H., Johansson, K.H., A secure control framework for resource-limited adversaries (2015) Automatica, 51, pp. 135-148; Han, D., Mo, Y., Xie, L., Towards a unified resilience analysis: state estimation against integrity attacks. (2016) Proceedings of the 35th Chinese Control Conference, , Chengdu, China; Fawzi, H., Tabuada, P., Diggavi, S., Secure state-estimation for dynamical systems under active adversaries (2011) Proceedings of the Annual Allerton Conference on Communication, ControlComputing, , Monticello, IL; Fawzi, H., Tabuada, P., Diggavi, S., Secure estimation and control for cyber-physical systems under adversarial attacks (2014) IEEE Trans Autom Control, 59 (6), pp. 1454-1467; Mo, Y., Sinopoli, B., Secure estimation in the presence of integrity attacks (2015) IEEE Trans Autom Control, 60 (4), pp. 1145-1151; An, L., Yang, G., Secure state estimation against sparse sensor attacks with adaptive switching mechanism (2017) IEEE Trans Autom Control, , Submitted for publication; Shoukry, Y., Tabuada, P., Event-triggered state observers for sparse sensor noise/attacks (2016) IEEE Trans Autom Control, 61 (8), pp. 2079-2091; Corless, M., Tu, J., State and input estimation for a class of uncertain systems (1998) Automatica, 34 (6), pp. 757-764; Kalsi, K., Lian, J., Hui, S., Żak, S.H., Sliding-mode observers for systems with unknown inputs: a high-gain approach (2010) Automatica, 46 (2), pp. 347-353; Pajic, M., Tabuada, P., Lee, I., Pappas, G., Attack-resilient state estimation in the presence of noise (2015) Proceedings of the 54th Annual Conference on Decision and Control, , Osaka, Japan; Pajic, M., Tabuada, P., Lee, I., Pappas, G.J., Attack-resilient state estimation for noisy dynamical systems (2017) IEEE Trans Control Netw Syst, 4 (1), pp. 82-92; Han, D., Mo, Y., Xie, L., (2015) Convex optimization based state estimation against sparse integrity attacks; Mo, Y., Garone, E., Secure dynamic state estimation via local estimators (2016) Proceedings of the 55th IEEE Conference on Decision and Control, , Las Vegas, NV; Lu, A., Yang, G., Secure state estimation for cyber-physical systems under sparse sensor attacks via a switched Luenberger observer (2017) Inform sci, 417, pp. 454-464; Lu, A., Yang, G., Secure Luenberger-like observers for cyber-physical systems under sparse actuator and sensor attacks (2017) Automatica, , Submitted for publication; Chong, M.S., Wakaiki, M., Hespanha, J.P., Observability of linear systems under adversarial attacks (2015) Proceedings of the American Control Conference, , Chicago, IL; Shoukry, Y., Nuzzo, P., Puggelli, A., Sangiovanni-Vincentelli, A.L., Seshia, S.A., Tabuada, P., Secure state estimation for cyber physical systems under sensor attacks: a satisfiability modulo theory approach (2017) IEEE Trans Autom Control, 62 (10), pp. 4917-4932; Yang, G.H., Ye, D., Reliable H∞ control of linear systems with adaptive mechanism (2010) IEEE Trans Autom Control, 55 (1), pp. 242-247; Liu, M., Ho, D.W., Shi, P., Adaptive fault-tolerant compensation control for Markovian jump systems with mismatched external disturbance (2015) Automatica, 58, pp. 5-14; Filippov, A.F., (1988) Differential Equations with Discontinuous Righthand Sides, , Dordrecht, Netherlands, Kluwer Academic Publishers; Wang, J.L., Yang, G.H., Liu, J., An LMI approach to H− index and mixed H−/H∞ fault detection observer design (2007) Automatica, 43 (9), pp. 1656-1665","Yang, G.-H.; College of Information Science and Engineering, China; email: yangguanghong@ise.neu.edu.cn",,,"John Wiley and Sons Ltd",,,,,10498923,,IJRCE,,"English","Int J Robust Nonlinear Control",Article,"Final","",Scopus,2-s2.0-85043368635
"Calleja A., Martín A., Menéndez H.D., Tapiador J., Clark D.","56912011200;57143182900;42661760100;57219182184;57213931369;","Picking on the family: Disrupting android malware triage by forcing misclassification",2018,"Expert Systems with Applications","95",,,"113","126",,25,"10.1016/j.eswa.2017.11.032","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035063925&doi=10.1016%2fj.eswa.2017.11.032&partnerID=40&md5=2f3a9bd5a36007876eb18fe0c73976f8","Department of Computer Science, Universidad Carlos III de Madrid, Madrid, Spain; Departamento de Informática, Universidad Autónoma de Madrid, Madrid, Spain; University College London (UCL), Gower Street, London, WC1E 6BT, United Kingdom","Calleja, A., Department of Computer Science, Universidad Carlos III de Madrid, Madrid, Spain; Martín, A., Departamento de Informática, Universidad Autónoma de Madrid, Madrid, Spain; Menéndez, H.D., University College London (UCL), Gower Street, London, WC1E 6BT, United Kingdom; Tapiador, J., Department of Computer Science, Universidad Carlos III de Madrid, Madrid, Spain; Clark, D., University College London (UCL), Gower Street, London, WC1E 6BT, United Kingdom","Machine learning classification algorithms are widely applied to different malware analysis problems because of their proven abilities to learn from examples and perform relatively well with little human input. Use cases include the labelling of malicious samples according to families during triage of suspected malware. However, automated algorithms are vulnerable to attacks. An attacker could carefully manipulate the sample to force the algorithm to produce a particular output. In this paper we discuss one such attack on Android malware classifiers. We design and implement a prototype tool, called IagoDroid, that takes as input a malware sample and a target family, and modifies the sample to cause it to be classified as belonging to this family while preserving its original semantics. Our technique relies on a search process that generates variants of the original sample without modifying their semantics. We tested IagoDroid against RevealDroid, a recent, open source, Android malware classifier based on a variety of static features. IagoDroid successfully forces misclassification for 28 of the 29 representative malware families present in the DREBIN dataset. Remarkably, it does so by modifying just a single feature of the original malware. On average, it finds the first evasive sample in the first search iteration, and converges to a 100% evasive population within 4 iterations. Finally, we introduce RevealDroid*, a more robust classifier that implements several techniques proposed in other adversarial learning domains. Our experiments suggest that RevealDroid* can correctly detect up to 99% of the variants generated by IagoDroid. © 2017 The Authors","Adversarial learning; Genetic algorithms; Iagodroid; Malware classification","Android (operating system); Computer crime; Genetic algorithms; Iterative methods; Learning algorithms; Learning systems; Semantics; Adversarial learning; Automated algorithms; Design and implements; Iagodroid; Machine learning classification; Malware analysis; Malware classifications; Misclassifications; Malware",,,,,"Aafer, Y., Du, W., Yin, H., Droidapiminer: Mining api-level features for robust malware detection in android (2013) International conference on security and privacy in communication systems, pp. 86-103. , Springer; Arp, D., Spreitzenbarth, M., Hubner, M., Gascon, H., Rieck, K., Drebin: Effective and explainable detection of android malware in your pocket. (2014) Ndss; Arzt, S., Rasthofer, S., Fritz, C., Bodden, E., Bartel, A., Klein, J., Flowdroid: Precise context, flow, field, object-sensitive and lifecycle-aware taint analysis for android apps (2014) ACM SIGPLAN Notices, 49 (6), pp. 259-269; Aydogan, E., Sen, S., Automatic generation of mobile malwares using genetic programming (2015) European conference on the applications of evolutionary computation, pp. 745-756. , Springer; Barreno, M., Nelson, B., Joseph, A.D., Tygar, J.D., The security of machine learning (2010) Machine Learning, 81 (2), pp. 121-148; Barreno, M., Nelson, B., Sears, R., Joseph, A.D., Tygar, J.D., Can machine learning be secure? (2006) Proceedings of the 2006 ACM symposium on information, computer and communications security, pp. 16-25. , ACM; Biggio, B., Corona, I., Fumera, G., Giacinto, G., Roli, F., Bagging classifiers for fighting poisoning attacks in adversarial classification tasks (2011) International workshop on multiple classifier systems, pp. 350-359. , Springer; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndić, N., Laskov, P., Evasion attacks against machine learning at test time (2013) Joint European conference on machine learning and knowledge discovery in databases, pp. 387-402. , Springer; Biggio, B., Fumera, G., Roli, F., Security evaluation of pattern classifiers under attack (2014) IEEE Transactions on Knowledge and Data Engineering, 26 (4), pp. 984-996; Biggio, B., Nelson, B., Laskov, P., Poisoning attacks against support vector machines (2012) Proceedings of the 29th international conference on machine learning, ICML 2012, Edinburgh, Scotland, Uk, June 26 - July 1, 2012; Biggio, B., Rieck, K., Ariu, D., Wressnegger, C., Corona, I., Giacinto, G., Poisoning behavioral malware clustering (2014) Proceedings of the 2014 workshop on artificial intelligent and security workshop, pp. 27-36. , ACM; Budhraja, K.K., Oates, T., Adversarial feature selection (2015) 2015 IEEE international conference on data mining workshop (ICDMW), pp. 288-294. , IEEE; Chakradeo, S., Reaves, B., Traynor, P., Enck, W., Mast: triage for market-scale mobile malware analysis (2013) Proceedings of the sixth ACM conference on security and privacy in wireless and mobile networks, pp. 13-24. , ACM; Chin, E., Felt, A.P., Greenwood, K., Wagner, D., Analyzing inter-application communication in android (2011) Proceedings of the 9th international conference on mobile systems, applications, and services, pp. 239-252. , ACM; Chinavle, D., Kolari, P., Oates, T., Finin, T., Ensembles in adversarial classification for spam (2009) Proceedings of the 18th ACM conference on information and knowledge management, pp. 2015-2018. , ACM; Dalvi, N., Domingos, P., Sanghai, S., Verma, D., Adversarial classification (2004) Proceedings of the tenth ACM SIGKDD international conference on knowledge discovery and data mining, pp. 99-108. , ACM; Dash, S.K., Suarez-Tangil, G., Khan, S., Tam, K., Ahmadi, M., Kinder, J., Droidscribe: Classifying android malware based on runtime behavior (2016) Mobile security technologies (MoST 2016), pp. 1-12. , 7kearns1993learning148; Deshotels, L., Notani, V., Lakhotia, A., Droidlegacy: Automated familial classification of android malware (2014) Proceedings of ACM SIGPLAN on program protection and reverse engineering workshop 2014, p. 3. , ACM; Enck, W., Ongtang, M., McDaniel, P., On lightweight mobile phone application certification (2009) Proceedings of the 16th ACM conference on computer and communications security, pp. 235-245. , ACM; Feng, Y., Anand, S., Dillig, I., Aiken, A., Apposcopy: Semantics-based detection of android malware through static analysis (2014) Proceedings of the 22nd ACM SIGSOFT international symposium on foundations of software engineering, pp. 576-587. , ACM; Fratantonio, Y., Bianchi, A., Robertson, W., Kirda, E., Kruegel, C., Vigna, G., Triggerscope: Towards detecting logic bombs in android applications (2016) 2016 IEEE symposium on security and privacy (SP), pp. 377-396; Gandotra, E., Bansal, D., Sofat, S., Malware analysis and classification: A survey (2014) Journal of Information Security, 5 (2), p. 56; Garcia, J., Hammad, M., Pedrood, B., Bagheri-Khaligh, A., Malek, S., Obfuscation-resilient, efficient, and accurate detection and family identification of android malware (2015) Technical Report, , Department of Computer Science, George Mason University; Gordon, M.I., Kim, D., Perkins, J.H., Gilham, L., Nguyen, N., Rinard, M.C., Information flow analysis of android applications in droidsafe. (2015) NDSS, , Citeseer; Grosse, K., Papernot, N., Manoharan, P., Backes, M., McDaniel, P., (2016), Adversarial perturbations against deep neural networks for malware classification., arXiv preprint arXiv:1606.04435; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I., Tygar, J., Adversarial machine learning (2011) Proceedings of the 4th ACM workshop on security and artificial intelligence, pp. 43-58. , ACM; Kearns, M., Li, M., Learning in the presence of malicious errors (1993) SIAM Journal on Computing, 22 (4), pp. 807-837; Klieber, W., Flynn, L., Bhosale, A., Jia, L., Bauer, L., Android taint flow analysis for app sets (2014) Proceedings of the 3rd ACM SIGPLAN international workshop on the state of the art in java program analysis, pp. 1-6. , ACM; Labs, M., (2016), http://www.mcafee.com/us/resources/reports/rp-quarterly-threats-may-2016.pdf, McAfee labs threats report. [Online; Accessed 19.07.2016]; Lakhotia, A., Walenstein, A., Miles, C., Singh, A., Vilo: A rapid learning nearest-neighbor classifier for malware triage (2013) Journal of Computer Virology and Hacking Techniques, 9 (3), pp. 109-123; Laskov, P., Lippmann, R., Machine learning in adversarial environments (2010) Machine Learning, 81 (2), pp. 115-119; Laskov, P., Practical evasion of a learning-based classifier: A case study (2014) 2014 IEEE symposium on security and privacy, pp. 197-211. , IEEE; Lowd, D., Meek, C., Adversarial learning (2005) Proceedings of the eleventh ACM SIGKDD international conference on knowledge discovery in data mining, pp. 641-647. , ACM; Maiorca, D., Corona, I., Giacinto, G., Looking at the bag is not enough to find the bomb: An evasion of structural methods for malicious pdf files detection (2013) Proceedings of the 8th ACM SIGSAC symposium on information, computer and communications security, pp. 119-130. , ACM; Meng, G., Xue, Y., Mahinthan, C., Narayanan, A., Liu, Y., Zhang, J., Mystique: Evolving android malware for auditing anti-malware tools (2016) Proceedings of the 11th ACM on Asia conference on computer and communications security, pp. 365-376. , ACM; Octeau, D., McDaniel, P., Jha, S., Bartel, A., Bodden, E., Klein, J., Effective inter-component communication mapping in android: An essential step towards holistic security analysis (2013) Presented as part of the 22nd USENIX security symposium (USENIX security 13), pp. 543-558; Pastrana, S., Orfila, A., Ribagorda, A., A functional framework to evade network ids (2011) System sciences (HICSS), 2011 44th Hawaii international conference on, pp. 1-10. , IEEE; Perdisci, R., Gu, G., Lee, W., Using an ensemble of one-class SVM classifiers to harden payload-based anomaly detection systems (2006) Sixth international conference on data mining (ICDM’06), pp. 488-498. , IEEE; Ptacek, T.H., Newsham, T.N., Insertion, evasion, and denial of service: Eluding network intrusion detection (1998) Technical Report, , DTIC Document; Rasthofer, S., Arzt, S., Bodden, E., A machine-learning approach for classifying and categorizing android sources and sinks. (2014) NDSS; Russu, P., Demontis, A., Biggio, B., Fumera, G., Roli, F., Secure kernel machines against evasion attacks (2016) Proceedings of the 2016 ACM workshop on artificial intelligence and security, pp. 59-69. , ACM; Sivanandam, S., Deepa, S., Introduction to genetic algorithms (2007), Springer Science & Business Media; Suarez-Tangil, G., Tapiador, J.E., Peris-Lopez, P., Blasco, J., Dendroid: A text mining approach to analyzing and classifying code structures in android malware families (2014) Expert Systems with Applications, 41 (4), pp. 1104-1117; Valiant, L.G., A theory of the learnable (1984) Communications of the ACM, 27 (11), pp. 1134-1142; Valiant, L.G., Learning disjunction of conjunctions. (1985) IJCAI, pp. 560-566; Vidas, T., Christin, N., Evading android runtime analysis via sandbox detection (2014) Proceedings of the 9th ACM symposium on information, computer and communications security, pp. 447-458. , ACM; Vigna, G., Robertson, W., Balzarotti, D., Testing network-based intrusion detection signatures using mutant exploits (2004) Proceedings of the 11th ACM conference on computer and communications security, pp. 21-30. , ACM; Wei, F., Roy, S., Ou, X., Amandroid: A precise and general inter-component data flow analysis framework for security vetting of android apps (2014) Proceedings of the 2014 ACM SIGSAC conference on computer and communications security, pp. 1329-1341. , ACM; Xiao, H., Biggio, B., Brown, G., Fumera, G., Eckert, C., Roli, F., Is feature selection secure against training data poisoning? (2015) JMLR W&CP-proceedings of the 32nd international conference on international conference on machine learning (ICML), 37, pp. 1689-1698. , Bach F. Blei D; Xu, W., Qi, Y., Evans, D., Automatically evading classifiers (2016) Proceedings of the 2016 network and distributed systems symposium; Xue, Y., Meng, G., Liu, Y., Tan, T.H., Chen, H., Sun, J., Zhang, J., Auditing anti-malware tools by evolving android malware and dynamic loading technique (2017) IEEE Transactions on Information Forensics and Security, 12 (7), pp. 1529-1544; Yang, C., Xu, Z., Gu, G., Yegneswaran, V., Porras, P., Droidminer: Automated mining and characterization of fine-grained malicious behaviors in android applications (2014) European symposium on research in computer security, pp. 163-182. , Springer; Yang, W., Xiao, X., Andow, B., Li, S., Xie, T., Enck, W., Appcontext: Differentiating malicious and benign mobile app behaviors using context (2015) 2015 IEEE/ACM 37th IEEE international conference on software engineering, 1, pp. 303-313. , IEEE; Zhang, M., Duan, Y., Yin, H., Zhao, Z., Semantics-aware android malware classification using weighted contextual api dependency graphs (2014) Proceedings of the 2014 ACM SIGSAC conference on computer and communications security, pp. 1105-1116. , ACM; Zheng, M., Lee, P.P., Lui, J.C., Adam: an automatic and extensible platform to stress test android anti-virus systems (2012) International conference on detection of intrusions and malware, and vulnerability assessment, pp. 82-101. , Springer; Zhou, Y., Jiang, X., Dissecting android malware: Characterization and evolution (2012) 2012 IEEE symposium on security and privacy, pp. 95-109. , IEEE; Zhou, Y., Wang, Z., Zhou, W., Jiang, X., Hey, you, get off of my market: Detecting malicious apps in official and alternative android markets (2012) NDSS, 25, pp. 50-52","Menéndez, H.D.; University College London (UCL), Gower Street, United Kingdom; email: h.menendez@ucl.ac.uk",,,"Elsevier Ltd",,,,,09574174,,ESAPE,,"English","Expert Sys Appl",Article,"Final","All Open Access, Hybrid Gold, Green",Scopus,2-s2.0-85035063925
"Liu I.-H., Fang T.-J., Li J.-S., Sun M.-W., Liu C.-G.","55949898900;57193601296;7410065268;57202013813;8521940300;","A new colluded adversarial VNet embeddings attack in cloud",2018,"Parallel and Distributed Computing, Applications and Technologies, PDCAT Proceedings","2017-December",,,"9","16",,,"10.1109/PDCAT.2017.00012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046778357&doi=10.1109%2fPDCAT.2017.00012&partnerID=40&md5=30cb704c1d7059ad99bd17e465e8d33d","Institute of Computer and Communication Engineering, National Cheng Kung University, Tainan, Taiwan; Department of Applied Informatics and Multimedia, Chia-Nan University of Pharmacy and Science, Tainan, Taiwan","Liu, I.-H., Institute of Computer and Communication Engineering, National Cheng Kung University, Tainan, Taiwan; Fang, T.-J., Institute of Computer and Communication Engineering, National Cheng Kung University, Tainan, Taiwan; Li, J.-S., Institute of Computer and Communication Engineering, National Cheng Kung University, Tainan, Taiwan; Sun, M.-W., Institute of Computer and Communication Engineering, National Cheng Kung University, Tainan, Taiwan; Liu, C.-G., Department of Applied Informatics and Multimedia, Chia-Nan University of Pharmacy and Science, Tainan, Taiwan","Nowadays, network virtualization has been widely investigated in order to prevent Internet ossification, and develop future emerging network applications flexibly. However, prior work by Pignolet et al. shows the possible attacking methodology with which the attackers can disclose the whole cloud topology while deploying virtual networks in cloud named Topology Disclosure Attack. In this attack model, the attacker pretends to deploy virtual networks in cloud by issuing the graph requests to service provider. And the service provider responds the requests to the attacker after examining his/her topology resources. With this request/reply model, Pignolet et al. believe this attack eventually infers the targeted topology. However, one vital reason leads this attack to the failure- too many virtual requests from one adversary in a time. This paper tries to provide a new topology disclosure attack model, which multiple attackers launch attacks at the same time with the assistance of proposed Query-Trie and network tomography technique. Hence, in this paper, we propose much more possible attack model in cloud and this topic also encourages the network researchers to develop resistance mechanism against it in the future. © 2017 IEEE.","Network virtualization; Topology disclosure attack; Vnet in cloud","Distributed computer systems; Internet service providers; Virtual reality; Virtualization; Attack model; Network applications; Network tomography; Network virtualization; New topologies; Resistance mechanisms; Service provider; Virtual networks; Topology",,,,,"Pignolet, Y.A., Schmid, S., Tredan, G., Adversarial topology discovery in network virtualization environments: A threat for isps (2015) Distributed Computing, 28 (2), pp. 91-109; Chowdhury, N.M., Boutaba, R., A survey of network virtualization (2010) Computer Networks, 54 (5), pp. 862-876; Turner, J.S., Taylor, D.E., Diversifying the internet (2005) Global Telecommunications Conference, 2005, pp. 755-760. , Saint Louis; Chowdhury, N.M.K., Boutaba, R., Network virtualization: State of the art and research challenges (2009) Communications Magazine, 47 (7), pp. 20-26; Nogueira, J., Melo, M., Carapinha, J., Sargento, S., Network virtualization system suite: Experimental network virtualization platform (2011) 7th International ICST Conference on Testbeds and Research Infrastructures for the Development of Networks and Communities; Chowdhury, N.M.K., Rahman, M.R., Boutaba, R., Virtual network embedding with coordinated node and link mapping (2009) INFOCOM 2009, pp. 783-791. , April, Brazil; Hu, Q., Wang, Y., Cao, X., Resolve the virtual network embedding problem: A column generation approach (2013) INFOCOM, 2013, pp. 410-414. , April Turin; Fukushima, M., Sugiyama, K., Hasegawa, T., Hasegawa, T., Nakao, A., Minimum disclosure routing for network virtualization and its experimental evaluation (2013) IEEE/ACM Transactions on Networking (TON), 21 (6), pp. 1839-1851; McKay, B.D., (1981) Practical Graph Isomorphism, , Department of Computer Science, Vanderbilt University; Caceres, R., Duffield, N.G., Horowitz, J., Towsley, D., Multicastbased inference of network-internal loss characteristics (1999) IEEE Trans. Inf. Theory, 45 (7), pp. 2462-2480; Coates, M., Hero, A.O., III, Nowak, R., Yu, B., Internet tomography (2002) IEEE Signal Process. Mag, 19 (3), pp. 47-65; Ni, J., Tatikonda, S., Explicit link parameter estimators based on end-to-end measurements (2007) Proc. Allerton Conference on Communication, Control, and Computing, pp. 174-181. , Monticello, Illinois; Ni, J., Xie, H., Tatikonda, S., Yang, Y.R., Efficient and dynamic routing topology inference from end-to-end measurements (2010) IEEE/ACM Transactions on Networking (TON), 18 (1), pp. 123-135; Anderson, T., Peterson, L., Shenker, S., Turner, J., Overcoming the internet impasse through virtualization (2005) Computer, (4), pp. 34-41; Andersen, D., Balakrishnan, H., Kaashoek, F., Morris, R., (2001) Resilient Overlay Networks, 35 (5), pp. 131-145; Nakao, A., Peterson, L., Bavier, A., A routing underlay for overlay networks (2003) Proceedings of the 2003 Conference on Applications, Technologies, Architectures, and Protocols for Computer Communications, 2003, pp. 11-18. , August Karlsruhe, German; Liu, C.-G., Fang, T.-J., Liu, I.-H., Li, J.-S., Liang, Y.-C., A useful data structure for adversarial vnet embeddings attack in cloud (2016) ICICE (Indexed by EI), 11, pp. 5-10. , Xi'an, China",,"Horng S.-J.","Institute of Information Science Academia Sinica;Ministry of Science and Technology;National Taiwan University of Science and Technology (NTUST;Southwest Jiaotong University","IEEE Computer Society","18th International Conference on Parallel and Distributed Computing, Applications and Technologies, PDCAT 2017","18 December 2017 through 20 December 2017",,135595,,9781538631515,,,"English","Parallel Distrib. Comput. Appl. Technol. PDCAT Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85046778357
"Saileshwar G., Nair P.J., Ramrakhyani P., Elsasser W., Qureshi M.K.","55022717900;7201717281;36091787600;57196477576;9041214800;","SYNERGY: Rethinking Secure-Memory Design for Error-Correcting Memories",2018,"Proceedings - International Symposium on High-Performance Computer Architecture","2018-February",,,"454","465",,27,"10.1109/HPCA.2018.00046","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046760015&doi=10.1109%2fHPCA.2018.00046&partnerID=40&md5=fb883b50b802b4094670ac168dc2e475","Georgia Institute of Technology, United States; IBM Research, United States; ARM Research, United States","Saileshwar, G., Georgia Institute of Technology, United States; Nair, P.J., IBM Research, United States; Ramrakhyani, P., ARM Research, United States; Elsasser, W., ARM Research, United States; Qureshi, M.K., Georgia Institute of Technology, United States","Building trusted data-centers requires resilient memories which are protected from both adversarial attacks and errors. Unfortunately, the state-of-the-art memory security solutions incur considerable performance overheads due to accesses for security metadata like Message Authentication Codes (MACs). At the same time, commercial secure memory solutions tend to be designed oblivious to the presence of memory reliability mechanisms (such as ECC-DIMMs), that provide tolerance to memory errors. Fortunately, ECC-DIMMs possess an additional chip for providing error correction codes (ECC), that is accessed in parallel with data, which can be harnessed for security optimizations. If we can re-purpose the ECC-chip to store some metadata useful for security and reliability, it can prove beneficial to both. To this end, this paper proposes Synergy, a reliability-security co-design that improves performance of secure execution while providing strong reliability for systems with 9-chip ECC-DIMMs. Synergy uses the insight that MACs being capable of detecting data tampering are also useful for detecting memory errors. Therefore, MACs are best suited for being placed inside the ECC chip, to be accessed in parallel with each data access. By co-locating MAC and Data, Synergy is able to avoid a separate memory access for MAC and thereby reduce the overall memory traffic for secure memory systems. Furthermore, Synergy is able to tolerate 1 chip failure out of 9 chips by using a parity that is constructed over 9 chips (8 Data and 1 MAC), which is used for reconstructing the data of the failed chip. For memory intensive workloads, Synergy provides a speedup of 20% and reduces system Energy Delay Product by 31% compared to a secure memory baseline with ECC-DIMMs. At the same time, Synergy increases reliability by 185x compared to ECC-DIMMs that provide Single-Error Correction, Double-Error Detection (SECDED) capability. Synergy uses commercial ECC-DIMMs and does not incur any additional hardware overheads or reduction of security. © 2018 IEEE.","ECC-DIMM; Memory-Security; Reliability","Error correction; Metadata; Reliability; Supercomputers; ECC-DIMM; Error correction code (ECC); Hardware overheads; Memory reliability; Message authentication codes; Security and reliabilities; Security solutions; Single error corrections; Memory architecture",,,,,"Halderman, J.A., Lest we remember: Cold-boot attacks on encryption keys (2009) CACM; Yitbarek, S.F., Cold boot attacks are still hot: Security analysis of memory scramblers in modern processors (2017) HPCA; Kim, Y., Flipping bits in memory without accessing them: An experimental study of dram disturbance errors (2017) ISCA; Seaborn, M., Dullien, T., Exploiting the dram rowhammer bug to gain kernel privileges (2015) Black Hat; Becher, M., Firewire: All your memory are belong to us (2005) CanSecWest; Gueron, S., A memory encryption engine suitable for general purpose processors (2016) IACR Cryptology EPrint Archive; Costan, V., Devadas, S., Intel sgx explained (2016) IACR Cryptology EPrint Archive; Sridharan, V., Liberty, D., A study of dram failures in the field (2012) SC; Schroeder, B., Dram errors in the wild: A large-scale field study (2009) SIGMETRICS; Huang, R., Suh, G.E., Ivec: Off-chip memory integrity protection for both security and reliability (2010) ISCA; Dell, T.J., A white paper on the benefits of chipkill-correct ecc for pc server main memory (1997) IBM Microelectronics Division, p. 11; Udipi, A.N., Lot-ecc: Localized and tiered reliability mechanisms for commodity memory systems (2012) ISCA; Nair, P.J., Xed: Exposing on-die error detection information for strong memory reliability (2016) ISCA; Rogers, B., Using address independent seed encryption and bonsai merkle trees to make secure processors os-and performancefriendly (2007) MICRO; Lehman, T.S., Poisonivy: Safe speculation for secure memory (2016) MICRO; Lipmaa, H., (2000) Comments to Nist Concerning Aes Modes of Operation: Ctr-mode Encryption; Yan, C., Improving cost, performance, and security of memory encryption and authentication (2006) ISCA; Gassend, B., Caches and hash trees for efficient memory integrity verification (2003) HPCA; Suh, G.E., Efficient memory integrity verification and encryption for secure processors (2003) MICRO; Merkle, R.C., Protocols for public key cryptosystems (1980) S&P (Oakland); Wegman, M.N., Carter, J.L., New classes and applications of hash functions (1979) FOCS; Schroeder, B., Gibson, G., A large-scale study of failures in highperformance computing systems (2010) IEEE Trans Dependable Secure Comput.; Chen, C., Hsiao, M., Error-correcting codes for semiconductor memory applications: A state-of-the-art review (1984) IBM JRD; Bose, R., Ray-Chaudhuri, D., On a class of error correcting binary group codes (1960) Information and Control; Reed, I.S., Solomon, G., Polynomial codes over certain finite fields (1960) SIAM J Appl Math; Beamer, S., (2015) The Gap Benchmark Suite; Chatterjee, N., (2012) Usimm: The Utah Simulated Memory Module, , University of Utah, Tech. Rep; (2012) Memory Scheduling Championship (Msc); Nair, P.J., Faultsim: A fast, configurable memory-reliability simulator for conventional and 3d-stacked systems (2015) ACM-TACO; Spec cpu2006 Benchmark Suite, , Standard Performance Evaluation Corporation; Hamilton, J., You Really Do Need Ecc Memory-perspectives, , http://perspectives.mvdirona.com/2009/10/you-really-do-need-eccmemory/; Intel Data Center Block for Secure Enclaves, , https://www.intel.com/content/www/us/en/data-center-blocks/business/secure-enclavesblocks.html; Stinson, D.R., On the connections between universal hashing, combinatorial designs and error-correcting codes (1996) Congressus Numerantium; Dubrova, E., Error-correcting message authentication for 5g (2016) MOBIMEDIA; Ge, R., Approximate message authentication codes for n-ary alphabets (2006) IEEE Trans. Inf. Forensic Secur.; Xie, L., Approximate image message authentication codes (2001) IEEE Trans. Multimed; Xiao, S., Boncelet, C.G., Efficient noise-tolerant message authentication codes using direct sequence spread spectrum technique (2006) CISS; Ur-Rehman, O., Error correcting and weighted noise tolerant message authentication codes (2011) ICSPCS; Tonien, D., Unconditionally secure approximate message authentication (2009) IWCC; Lee, J., Reducing the memory bandwidth overheads of hardware security support for multi-core processors (2016) IEEE Trans. Comput; Elbaz, R., Tec-tree: A low-cost, parallelizable tree for efficient defense against memory replay attacks (2007) CHES; Hall, W.E., Jutla, C.S., Parallelizable authentication trees (2005) SAC; Shi, W., Lee, H.H.S., Authentication control point and its implications for secure processor design (2006) MICRO; Goldreich, O., Ostrovsky, R., Software protection and simulation on oblivious rams (1996) JACM; Stefanov, E., Path oram: An extremely simple oblivious ram protocol (2013) CCS; Maas, M., Phantom: Practical oblivious computation in a secure processor (2013) CCS; Awad, A., Obfusmem: A low-overhead access obfuscation for trusted memories (2017) ISCA; Aga, S., Narayanasamy, S., Invisimem: Smart memory defenses for memory bus side channel (2017) ISCA; Ren, L., Integrity verification for path oblivious-ram (2013) HPEC; Fletcher, C.W., Freecursive oram: [Nearly] free recursion and integrity verification for position-based oblivious ram (2015) ASPLOS; Palframan, D.J., Cop: To compress and protect main memory (2015) ISCA; Kim, J., Frugal ecc: Efficient and versatile memory error protection through fine-grained compression (2015) SC; Yoon, D.H., Erez, M., Virtualized and flexible ecc for main memory (2010) ASPLOS; Kim, J., Bamboo ecc: Strong, safe, and flexible codes for reliable computer memory (2015) HPCA; Jian, X., Kumar, R., Adaptive reliability chipkill correct (arcc) (2013) HPCA; Jian, X., Low-power, low-storage-overhead chipkill correct via multi-line error correction (2013) SC; Nair, P.J., Citadel: Efficiently protecting stacked memory from large granularity failures (2014) MICRO; Jian, X., Parity helix: Efficient protection for singledimensional faults in multi-dimensional memory systems (2016) HPCA; Chen, L., Zhang, Z., Memguard: A low cost and energy efficient design to support and enhance memory system reliability (2014) ISCA",,,"Bitmain;DeePhi;et al.;Huawei;IBM;Intel","IEEE Computer Society","24th IEEE International Symposium on High Performance Computer Architecture, HPCA 2018","24 February 2018 through 28 February 2018",,135666,15300897,9781538636596,,,"English","Proc. Int. Symp. High Perform. Comput. Archit.",Conference Paper,"Final","",Scopus,2-s2.0-85046760015
"Buriro A., Gupta S., Crispo B., Frari F.D.","54790659000;57197760020;8379216600;56912398000;","Dialerauth: A motion-assisted touch-based smartphone user authentication scheme",2018,"CODASPY 2018 - Proceedings of the 8th ACM Conference on Data and Application Security and Privacy","2018-January",,,"267","276",,14,"10.1145/3176258.3176318","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052022924&doi=10.1145%2f3176258.3176318&partnerID=40&md5=84c815bb5354da48a85ba982b6ced057","University of Trento, Trento, Italy","Buriro, A., University of Trento, Trento, Italy; Gupta, S., University of Trento, Trento, Italy; Crispo, B., University of Trento, Trento, Italy; Frari, F.D., University of Trento, Trento, Italy","This paper introduces DialerAuth - a mechanism which leverages the way a smartphone user taps/enters any “text-independent"" 10-digit number (replicating the dialing process) and the hand’s micro-movements she makes while doing so. DialerAuth authenticates the user on the basis of timing differences in the entered 10-digit strokes. DialerAuth provides enhanced security by leveraging the transparent and unobservable layer based on another modality - user’s hand micro-movements. Furthermore, Dialerauth increases the usability and acceptability by utilizing the users’ familiarity with the dialing process and the flexibility of choosing any combination of 10-digit number. We implemented DialerAuth for both data collection and proof-of-concept real-time analysis. We collected, in total ≈10500 legitimate samples involving 97 users, through an extensive unsupervised field experiment, to evaluate the effectiveness of DialerAuth. Analysis using one-class Multilayer Perceptron (MLP) shows a TAR of 85.77% in identifying the genuine users. Security analysis involving ≈240 adversarial attempts proved DialerAuth as significantly resilient against random and mimic attacks. A usability study based on System Usability Scale (SUS) reflects a positive feedback on user acceptance (SUS score = 73.29). © 2018 Association for Computing Machinery.","Behavioral biometrics; Sensors; Smartphone Authentication","Data privacy; Feedback; Mobile security; Sensors; Smartphones; Behavioral biometrics; Multi layer perceptron; Real time analysis; Security analysis; System Usability Scale (SUS); Text independents; Usability studies; User authentication scheme; Authentication",,,,,"Akhtar, Z., (2012) Security of Multimodal Biometric Systems Against Spoof Attacks, , Ph.D. Dissertation. Department of Electrical and Electronic Engineering, University of Cagliari, Cagliari, Italy. Advisor(s) Fabio Roli; Bergadano, F., Gunetti, D., Picardi, C., User authentication through keystroke dynamics (2002) ACM Transactions on Information and System Security (TISSEC), 5 (4), pp. 367-397. , 2002; Breiman, L., Cutler, A., (2018) Random Forests, , https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#features/, 2018). Retrieved January 8, 2018 from; Buriro, A., (2017) Behavioral Biometrics for Smartphone User Authentication, , Ph.D. Dissertation. University of Trento, Italy. Advisor(s) Bruno Crispo; Buriro, A., Crispo, B., Frari, F.D., Klardie, J., Wrona, K., Itsme: Multi-modal and unobtrusive behavioural user authentication for smartphones (2015) International Conference on Passwords, pp. 45-61. , Springer; Buriro, A., Crispo, B., Frari, F.D., Wrona, K., Touchstroke: Smartphone user authentication based on touch-typing biometrics (2015) International Conference on Image Analysis and Processing, pp. 27-34. , Springer; Buriro, A., Crispo, B., Delfrari, F., Wrona, K., Hold and sign: A novel behavioral biometrics for smartphone user authentication (2016) IEEE Security and Privacy Workshops (SPW), pp. 276-285; Buriro, A., Crispo, B., Zhauniarovich, Y., Please hold on: Unobtrusive user authentication using smartphone’s built-in sensors (2017) IEEE International Conference on Identity, Security and Behavior Analysis (ISBA-2017); Buriro, A., Gupta, S., Crispo, B., (2017) Evaluation of Motion-Based Touch-Typing Biometrics for Online Banking, , 2017; De Luca, A., Hang, A., Zezschwitz, E.V., Huss-Mann, H., I Feel Like I’m Taking Selfies All Day!: Towards Understanding Biometric Authentication on Smartphones (2015) Proceedings of The 33rd Annual ACM Conference on Human Factors in Computing Systems, pp. 1411-1414; Derawi, M.O., Nickel, C., Bours, P., Busch, C., Unobtrusive user-authentication on mobile phones using biometric gait recognition (2010) Proceedings of The 6th IEEE International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP), pp. 306-311; Frank, M., Biedert, R., Ma, E., Martinovic, I., Song, D., Touchalytics: On the applicability of touchscreen input as a behavioral biometric for continuous authentication (2013) IEEE Transactions on Information Forensics and Security, 8 (1), pp. 136-148. , 2013; Gascon, H., Uellenbeck, S., Wolf, C., Rieck, K., Continuous authentication on mobile devices by analysis of typing motion behavior (2014) Sicherheit, pp. 1-12; Giuffrida, C., Majdanik, K., Conti, M., Bos, H., I sensed it was you: Authenticating mobile users with sensor-enhanced keystroke dynamics (2014) International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment, pp. 92-111. , Springer; Harbach, M., Zezschwitz, E.V., Fichtner, A., De Luca, A., Smith, M., It’s a hard lock life: A field study of smartphone (un) locking behavior and risk perception (2014) Symposium on Usable Privacy and Security (SOUPS), pp. 213-230; Ho, G., (2014) Tapdynamics: Strengthening User Authentication on Mobile Phones with Keystroke Dynamics, , Technical Report. Stanford University; Jain, A., Ross, A.A., Nandakumar, K., (2011) Introduction to Biometrics, , Springer Science & Business Media; Jakobsson, M., Shi, E., Golle, P., Chow, R., Implicit authentication for mobile devices (2009) Proceedings of The 4th USENIX Conference on Hot Topics in Security, p. 9; Lu, H., Yang, J., Liu, Z., Lane, N.D., Choudhury, T., Campbell, A.T., The Jigsaw continuous sensing engine for mobile phone applications (2010) Proceedings of The 8th ACM Conference on Embedded Networked Sensor Systems, pp. 71-84; Meng, Y., Wong, D.S., Schlegel, R., Touch gestures based biometric authentication scheme for touchscreen mobile phones (2012) International Conference on Information Security and Cryptology, pp. 331-350. , Springer; Miluzzo, E., Varshavsky, A., Balakrishnan, S., Choudhury, R.R., Tapprints: Your finger taps have fingerprints (2012) Proceedings of The 10th ACM International Conference on Mobile Systems, Applications, and Services, pp. 323-336; Van Nguyen, T., Sae-Bae, N., Memon, N., Draw-a-pin (2017) Computers and Security, 66, pp. 115-128. , C (2017; Nickel, C., Wirtl, T., Busch, C., Authentication of smartphone users based on the way they walk using k-nn algorithm (2012) Proceedings of The 8th IEEE International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP), pp. 16-20; Raza, M., Iqbal, M., Sharif, M., Haider, W., A survey of password attacks and comparative analysis on methods for secure authentication (2012) World Applied Sciences Journal, 19 (4), pp. 439-444. , 2012; Ross, A., Jain, A., Information fusion in biometrics (2003) Pattern Recognition Letters, 24 (13), pp. 2115-2125. , 2003; Sitova, Z., Sedenka, J., Yang, Q., Peng, G., Zhou, G., Gasti, P., Balagani, K., (2015) Hmog: A New Biometric Modality for Continuous Authentication of Smartphone Users, , arXiv preprint 2015; Stefan, D., Shu, X., Yao, D.D., Robustness of keystroke-dynamics based biometrics against synthetic forgeries (2012) Computers & Security, 31 (1), pp. 109-121. , 2012; Thirumuruganathan, S., (2010) A Detailed Introduction to K-Nearest Neighbor (KNN) Algorithm, , https://goo.gl/qvgpwc, May 2010). Retrieved Nov 20, 2017 from; Trewin, S., Swart, C., Koved, L., Martino, J., Singh, K., Ben-David, S., Biometric authentication on a mobile device: A study of user effort, error and task disruption (2012) Proceedings of The 28th ACM Annual Computer Security Applications Conference (ACSAC 2012), pp. 159-168; Wu, X., Kumar, V., Quinlan, J.R., Ghosh, J., Yang, Q., Motoda, H., McLachlan, G.J., Philip, S.Y.U., Top 10 algorithms in data mining (2008) Knowledge and Information Systems, 14 (1), pp. 1-37. , 2008; Yager, N., Dunstone, T., The biometric menagerie (2010) IEEE Transactions on Pattern Analysis and Machine Intelligence, 32 (2), pp. 220-230. , 2010; Zhang, H., Patel, V.M., Fathy, M., Chellappa, R., Touch gesture-based active user authentication using dictionaries (2015) Proceedings of The IEEE Winter Conference on Applications of Computer Vision (WACV), pp. 207-214",,,"ACM SIGSAC","Association for Computing Machinery, Inc","8th ACM Conference on Data and Application Security and Privacy, CODASPY 2018","19 March 2018 through 21 March 2018",,135355,,9781450356329,,,"English","CODASPY - Proc. ACM Conf. Data Appl. Secur. Priv.",Conference Paper,"Final","",Scopus,2-s2.0-85052022924
"Liao C., Zhu S., Zhong H., Squicciarini A.","56599610200;8886024500;57184830000;6506303417;","Server-based manipulation attacks against machine learning models",2018,"CODASPY 2018 - Proceedings of the 8th ACM Conference on Data and Application Security and Privacy","2018-January",,,"2","34",,3,"10.1145/3176258.3176321","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052017691&doi=10.1145%2f3176258.3176321&partnerID=40&md5=a608e18b8168dd7f520d217921b84a1b","College of Information Sciences and Technology, Pennsylvania State University, United States; Department of Computer Science and Engineering, Pennsylvania State University, United States; Department of Electrical Engineering, Pennsylvania State University, United States","Liao, C., College of Information Sciences and Technology, Pennsylvania State University, United States; Zhu, S., Department of Computer Science and Engineering, Pennsylvania State University, United States; Zhong, H., Department of Electrical Engineering, Pennsylvania State University, United States; Squicciarini, A., College of Information Sciences and Technology, Pennsylvania State University, United States","Machine learning approaches have been increasingly applied to various applications for data analytics (e.g. spam filtering, image classification). Further, with the growing adoption of cloud computing, various cloud services have provided an efficient way for users to train, store or deploy machine learning algorithms in an easy-to-use manner. However, the models deployed in the cloud may be exposed to potential malicious attacks launched at the server side. Attackers with access to the server can stealthily manipulate a machine learning model so as to enable misclassification or introduce bias. In this work, we study the problem of manipulation attacks as they occur at the server side. We consider not only traditional supervised learning models but also state-of-the-art deep learning models. In particular, a simple but effective gradient descent based approach is presented to exploit Logistic Regression (LR) and Convolutional Neural Networks (CNN)[16] models. We evaluate manipulation attacks against machine learning or deep learning systems using both Enron email text and MINIST image dataset[17]. Experimental results have demonstrated such attacks can manipulate the model that allows malicious samples to evade detection easily without compromising the overall performance of the systems. © 2018 Association for Computing Machinery.","Adversarial Machine Learning; Convolutional Neural Networks; Model Manipulation","Convolution; Data privacy; Deep learning; Network security; Neural networks; Convolutional neural network; Convolutional Neural Networks (CNN); Logistic regressions; Machine learning approaches; Machine learning models; Malicious attack; Misclassifications; State of the art; Learning algorithms",,,,,"Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Isard, M., Tensorflow: A system for large-scale machine learning (2016) OSDI, 16, pp. 265-283; Barga, R., Fontama, V., Predictive Analytics with Microsoft Azure Machine Learning, , n. d. Springer; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndić, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 387-402. , Springer; Biggio, B., Nelson, B., Laskov, P., (2012) Poisoning Attacks Against Support Vector Machines, , arXiv preprint 2012; Bottou, L., Large-scale machine learning with stochastic gradient descent (2010) Proceedings of COMPSTAT’2010, pp. 177-186. , Springer; Cao, X., Gong, N.Z., Mitigating evasion attacks to deep neural networks via region-based classification (2017) Proceedings of The 33rd Annual Computer Security Applications Conference, pp. 278-287. , ACM; Cortes, C., Vapnik, V., Support-vector networks (1995) Machine Learning, 20 (3), pp. 273-297. , 1995; Drucker, H., Wu, D., Vapnik, V.N., Support vector machines for spam categorization (1999) IEEE Transactions on Neural Networks, 10 (5), pp. 1048-1054. , 1999; Fierrez-Aguilar, J., Ortega-Garcia, J., Gonzalez-Rodriguez, J., Bigun, J., Discriminative multimodal biometric authentication based on quality measures (2005) Pattern Recognition, 38 (5), pp. 777-779. , 2005; Fredrikson, M., Jha, S., Ristenpart, T., Model inversion attacks that exploit confidence information and basic countermeasures (2015) Proceedings of The 22nd ACM SIGSAC Conference on Computer and Communications Security, pp. 1322-1333. , ACM; Fredrikson, M., Lantz, E., Jha, S., Lin, S., Page, D., Ristenpart, T., Privacy in Pharmacogenetics: An End-to-End Case Study of Personalized Warfarin Dosing, , n. d; TensorFlow, , https://www.tensorflow.org/, n. d. n. d; Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., (2017) On The (Statistical) Detection of Adversarial Examples, , arXiv preprint 2017; Jang, U., Wu, X., Jha, S., Objective Metrics and Gradient Descent Algorithms for Adversarial Examples in Machine Learning (2017) Proceedings of The 33rd Annual Computer Security Applications Conference, pp. 262-277. , ACM; Klimt, B., Yang, Y., Introducing the enron corpus (2004) CEAS; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; LeCun, Y., Cortes, C., Burges, C.J.C., (2010) MNIST Handwritten Digit Database, , http://yann. lecun. com/exdb/mnist 2, AT&T Labs Online. Available: 2010; McDaniel, P., Papernot, N., Celik, Z.B., Machine learning in adversarial settings (2016) IEEE Security & Privacy, 14 (3), pp. 68-72. , 2016; Metsis, V., Androutsopoulos, I., Paliouras, G., Spam filtering with naive bayes-which naive bayes? (2006) CEAS, 17, pp. 28-69; Azure Machine Learning Studio, , https://studio.azureml.net/, n. d. n. d; Dezfooli, S.M.M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Mozaffari-Kermani, M., Sur-Kolay, S., Raghunathan, A., Jha, N.K., Systematic poisoning attacks on and defenses for machine learning in healthcare (2015) IEEE Journal of Biomedical and Health Informatics, 19 (6), pp. 1893-1905. , 2015; Mukkamala, S., Janoski, G., Sung, A., Intrusion detection using neural networks and support vector machines (2002) Neural Networks, 2002. IJCNN’02. Proceedings of The 2002 International Joint Conference on, 2, pp. 1702-1707. , IEEE; Nielsen, M.A., (2015) Neural Networks and Deep Learning, , 2015; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of The 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519. , ACM; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387. , IEEE; Rumelhart, D.E., Hinton, G.E., Williams, R.J., Learning representations by back-propagating errors Cognitive Modeling, 5 (3), p. 1. , n. d. n. d; Shen, S., Tople, S., Saxena, P., A uror: Defending against poisoning attacks in collaborative deep learning systems (2016) Proceedings of The 32nd Annual Conference on Computer Security Applications, pp. 508-519. , ACM; Shin, H.-C., Roth, H.R., Gao, M., Lu, L., Xu, Z., Nogues, I., Yao, J., Summers, R.M., Deep convolutional neural networks for computer-aided detection: CNN architectures, dataset characteristics and transfer learning (2016) IEEE Transactions on Medical Imaging, 35 (5), pp. 1285-1298. , 2016; Tramèr, F., Zhang, F., Juels, A., Reiter, M.K., Ristenpart, T., Stealing machine learning models via prediction APIs (2016) USENIX Security Symposium, pp. 601-618",,,"ACM SIGSAC","Association for Computing Machinery, Inc","8th ACM Conference on Data and Application Security and Privacy, CODASPY 2018","19 March 2018 through 21 March 2018",,135355,,9781450356329,,,"English","CODASPY - Proc. ACM Conf. Data Appl. Secur. Priv.",Conference Paper,"Final","",Scopus,2-s2.0-85052017691
"Hossain M., Karim Y., Hasan R.","57221034478;57196219273;8529353900;","SecuPAN: A security scheme to mitigate fragmentation-based network attacks in 6lowpan",2018,"CODASPY 2018 - Proceedings of the 8th ACM Conference on Data and Application Security and Privacy","2018-January",,,"307","318",,7,"10.1145/3176258.3176326","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052012719&doi=10.1145%2f3176258.3176326&partnerID=40&md5=86ddb0c0037a732763f2aac8cb04f42d","SECRET Lab, Department of Computer ScienceUniversity of Alabama at, Birmingham, AL, United States","Hossain, M., SECRET Lab, Department of Computer ScienceUniversity of Alabama at, Birmingham, AL, United States; Karim, Y., SECRET Lab, Department of Computer ScienceUniversity of Alabama at, Birmingham, AL, United States; Hasan, R., SECRET Lab, Department of Computer ScienceUniversity of Alabama at, Birmingham, AL, United States","6LoWPAN is a widely used protocol for communication over IPV6 Low-power Wireless Personal Area Networks. Unfortunately, the 6LoWPAN packet fragmentation mechanism possesses vulnerabilities that adversaries can exploit to perform network attacks. Lack of fragment authentication, payload integrity verification, and sender IP address validation lead to fabrication, duplication, and impersonation attacks. Moreover, adversaries can abuse the poor reassembly buffer management technique of the 6LoWPAN layer to perform buffer exhaustion and selective forwarding attacks. In this paper, we propose SecuPAN – a security scheme for mitigating fragmentation-based network attacks in 6LoWPAN networks and devices. We propose a Message Authentication Code based per-fragment integrity and authenticity verification scheme to defend against fabrication and duplication attacks. We also present a mechanism for computing datagram-tag and IPv6 address cryptographically to mitigate impersonation attacks. Additionally, our reputation-based buffer management scheme protects 6LoWPAN devices from buffer reservation attacks. We provide an extensive security analysis of SecuPAN to demonstrate that SecuPAN is secure against strong adversarial scenarios. We also implemented a prototype of SecuPAN on Contiki enabled IoT devices and provided a performance analysis of our proposed scheme. © 2018 Association for Computing Machinery.","6LoWPAN; Adversary; Attack; Fragmentation; Internet of Things; Security Service; Threat","Authentication; Communication channels (information theory); Computer crime; Data privacy; Internet of things; Internet protocols; Low power electronics; Personal communication systems; 6LoWPAN; Adversary; Attack; Fragmentation; Security services; Threat; Network security",,,,,"Adams, J.T., An introduction to IEEE STD 802.15. 4 (2006) IEEE Aerospace Conference, , IEEE; Alam, K.M., Saini, M., Saddik, A.E., Toward social internet of vehicles: Concept, architecture, and applications (2015) IEEE Access, 3, pp. 343-357. , 2015; Aura, T., (2005) Cryptographically Generated Addresses (CGA), , IETF, RFC (2005; Becher, A., Benenson, Z., Dornseif, M., Tampering with motes: Real-world physical attacks on wireless sensor networks (2006) International Conference on Security in Pervasive Computing, , Springer; Bormann, C., (2013) Guidance for Light-Weight Implementations of The Internet Protocol Suite, , IETF, RFC (2013; (1997) CERT Advisory CA-1997-28 IP Denial-of-Service Attacks, , CERT Coordination Center. 1997; (2014) Explaining Implicit Certificates, , Certicom. Technical Report. Certicom; Chan, S., Wong, E.W.M., Ko, K.-T., Fair packet discarding for controlling ABR traffic in ATM networks (1997) IEEE Transactions on Communications, 45 (8), pp. 913-916. , 1997; Chowdhury, A.H., Ikram, M., Cha, H.-S., Red-Wan, H., Shams, S.M., Kim, K.-H., Yoo, S.-W., Route-over vs Mesh-under Routing in 6LoWPAN (2009) International Conference on Wireless Communications and Mobile Computing: Connecting The World Wirelessly, , ACM; Deng, J., Han, R., Mishra, S., Secure code distribution in dynamically programmable wireless sensor networks (2006) International Conference on Information Processing in Sensor Networks, pp. 292-300. , IEEE; Dutta, P.K., Hui, J.W., Chu, D.C., Culler, D.E., Securing the deluge network programming system (2006) International Conference on Information Processing in Sensor Networks, , IEEE; Frankel, S., Krishnan, S., (2011) IP Security (IPsec) and Internet Key Exchange (IKE) Document Roadmap, , IETF, RFC (2011; Gilad, Y., Herzberg, A., Fragmentation considered vulnerable: Blindly intercepting and discarding fragments (2011) Proceedings of The 5th USENIX Conference on Offensive Technologies, p. 2. , USENIX Association; Halcu, I., Stamatescu, G., Sgarciu, V., A security framework for a 6LoWPAN based industrial wireless sensor network (2016) University Politehnica of Bucharest Scientific Bulletin Series, 78 (4), pp. 57-68. , 2016; Hartke, K., Bergmann, O., (2012) Datagram Transport Layer Security in Constrained Environments, , 2012; Hartung, C., Balasalle, J., Han, R., (2005) Node Compromise in Sensor Networks: The Need for Secure Systems, , Department of Computer Science University of Colorado at Boulder (2005; Hummen, R., Hiller, J., Wirtz, H., Henze, M., Shafagh, H., Wehrle, K., 6LoWPAN fragmentation attacks and mitigation mechanisms (2013) Proceedings of The Sixth ACM Conference on Security and Privacy in Wireless and Mobile Networks, pp. 55-66. , ACM; Hummen, R., Ziegeldorf, J.H., Shafagh, H., Raza, S., Wehrle, K., Towards viable certificate-based authentication for the internet of things (2013) Proceedings of The 2nd ACM Workshop on Hot Topics on Wireless Network Security and Privacy, pp. 37-42. , ACM; Hussain, S.R., Mehnaz, S., Nirjon, S., Bertino, E., Secure seamless bluetooth low energy connection migration for unmodified IoT devices (2017) IEEE Transactions on Mobile Computing, , 2017; Hyun, S., Ning, P., Liu, A., Du, W., Seluge: Secure and dos-resistant code dissemination in wireless sensor networks (2008) International Conference on Information Processing in Sensor Networks, pp. 445-456. , IEEE; Kim, H., Protection against packet fragmentation attacks at 6low-pan adaptation layer (2008) International Conference on Convergence and Hybrid Information Technology, pp. 796-801. , IEEE; Kolbe, N., Kubler, S., Robert, J., Le Traon, Y., Zaslavsky, A., Towards semantic interoperability in an open IoT ecosystem for connected vehicle services (2017) Global Internet of Things Summit (GIoTS), pp. 1-5. , 2017. IEEE; Kolbe, N., Zaslavsky, A., Kubler, S., Robert, J., Le Traon, Y., Enriching a situation awareness framework for iot with knowledge base and reasoning components (2017) International and Interdisciplinary Conference on Modeling and Using Context, pp. 41-54. , Springer; Kushalnagar, N., Montenegro, G., Culler, D.E., Hui, J.W., (2007) Transmission of Ipv6 Packets over Ieee 802.15. 4 Networks, , IETF, RFC (2007; Kushalnagar, N., Montenegro, G., Schumacher, C., (2007) Rfc 4919: Ipv6 over Low-Power Wireless Personal Area Networks (6lowpans): Overview, , Assumptions, Problem Statement, and Goals (2007; Lanigan, P.E., Gandhi, R., Narasimhan, P., Sluice: Secure dissemination of code updates in sensor networks (2006) International Conference on Distributed Computing System, , IEEE; Le, A., Loo, J., Lasebae, A., Aiash, M., Luo, Y., 6LoWPAN: A study on QoS security threats and countermeasures using intrusion detection system approach (2012) International Journal of Communication Systems, 25 (9), pp. 1189-1212. , 2012; Lee, G., Seo, H., Park, T., Kim, H., Optimized implementation of chaskey MAC on 16-bit MSP430 (2017) Ninth International Conference on Ubiquitous and Future Networks (ICUFN); (2017) Contiki APIs for Accessing Realtime Clock, , http://www.eistec.se/docs/contiki/a02184.html, 2017; (2017) Contiki APIs for Measuring Energy Consumption, , http://contiki.sourceforge.net/docs/2.6/a00452_source.html, 2017; Contiki, O.S., (2016) An Open Source Operating System for The Internet of Things, , http://www.contiki-os.org/, 2016; Yogesh Patil, R., Ragha, L., A rate limiting mechanism for defending against flooding based distributed denial of service attack (2011) World Congress on Information and Communication Technologies; Perrig, A., Szewczyk, R., Tygar, J.D., Wen, V., Culler, D.E., SPINS: Security protocols for sensor networks (2002) Wireless Networks, 8 (5), pp. 521-534. , 2002; Ptacek, T.H., Newsham, T.N., (1998) Insertion, Evasion, and Denial of Service: Eluding Network Intrusion Detection, , Technical Report. DTIC Document; (2017) A 6LoWPAN IoT Device, , http://zolertia.io/z1, 2017; Romanow, A., Floyd, S., Dynamics of TCP traffic over ATM networks (1995) IEEE Journal on Selected Areas in Communications, 13 (4), pp. 633-641. , 1995; Rullo, A., Serra, E., Bertino, E., Lobo, J., Shortfall-Based Optimal Placement of Security Resources for Mobile IoT Scenarios (2017) European Symposium on Research in Computer Security, pp. 419-436. , Springer; (2004) The Rose Attack, , http://seclists.org/bugtraq/2004/Mar/351, 2004; Thubert, P., Hui, J., (2010) LoWPAN Fragment Forwarding and Recovery. Internet Draft Draft-Thubert-6lowpan-Simple-Fragment-Recovery-07, Work in Progress, , 2010; (2017) A 6LoWPan Border Router, , https://www.weptech.de/6LoWPAN_IoT_Gateway_EN.html, 2017; Winter, T., (2012) RPL: IPv6 Routing Protocol for Low-Power and Lossy Networks, , IETF, RFC (2012; (2014) The Internet of Things Will Transform The Data Center, , http://www.gartner.com/newsroom/id/2684616, www.gartner.com. 2014; Ziemba, G., Traina, P., Reed, D., Security considerations for IP fragment filtering (1995) RFC 1858, , 1995",,,"ACM SIGSAC","Association for Computing Machinery, Inc","8th ACM Conference on Data and Application Security and Privacy, CODASPY 2018","19 March 2018 through 21 March 2018",,135355,,9781450356329,,,"English","CODASPY - Proc. ACM Conf. Data Appl. Secur. Priv.",Conference Paper,"Final","",Scopus,2-s2.0-85052012719
[No author name available],[No author id available],"2018 IEEE 4th International Conference on Identity, Security, and Behavior Analysis, ISBA 2018",2018,"2018 IEEE 4th International Conference on Identity, Security, and Behavior Analysis, ISBA 2018","2018-January",,,"","",160,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050243826&partnerID=40&md5=c2ba625983c5e5e05283e4f7be916097",,"","The proceedings contain 25 papers. The topics discussed include: robust gender classification using extended multi-spectral imaging by exploring the spectral angle mapper; a novel set of pixel difference-based features for pedestrian detection; fusion analysis of soft biometrics for recognition at a distance; DyGazePass: a gaze gesture-based dynamic authentication system to counter shoulder surfing and video analysis attacks; a gender-specific behavioral analysis of mobile device usage data; analysis of head and torso movements for authentication; cloud-ID-screen: secure fingerprint data in the cloud; normalized face image generation with perceptron generative adversarial networks; multi-view gait recognition using 2D-EGEI and NMF; facial biometric presentation attack detection using temporal texture cooccurrence; secure smart metering based on LoRa technology; a longitudinal study of iris recognition in children; privacy preserving IP traceback; GHCLNet: a generalized hierarchically tuned contact lens detection network; biometric presentation attack detection using gaze alignment; on the use of convolutional neural networks for speech presentation attack detection; improved sequential fusion of heart-signal and fingerprint for anti-spoofing; adversarial domain adaptive subspace clustering; and prediction of human error using eye movements patterns for unintentional insider threat detection.",,,,,,,,,,"","Institute of Electrical and Electronics Engineers Inc.","4th IEEE International Conference on Identity, Security, and Behavior Analysis, ISBA 2018","11 January 2018 through 12 January 2018",,135227,,9781538622483,,,"English","IEEE Int. Conf. Identity, Secur., Behav. Anal., ISBA",Conference Review,"Final","",Scopus,2-s2.0-85050243826
"Jajodia S., Park N., Serra E., Subrahmanian V.S., Vs@dartmouth.edu","57190678016;55994517000;35812641000;7006050903;","SHARE: A stackelberg honey-based adversarial reasoning engine",2018,"ACM Transactions on Internet Technology","18","3","30","","",,11,"10.1145/3137571","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055875929&doi=10.1145%2f3137571&partnerID=40&md5=942f3a9ff9d03665c3cffd866dd7e5c6","Center for Secure Information Systems, George Mason University, 4400 University Drive, Fairfax, VA, United States; Department of Software and Information Systems, University of North Carolina, Charlotte, NC, United States; Computer Science Department, Boise State University, Boise, ID, United States; Computer Science Department, Dartmouth College, Hanover, NH, United States","Jajodia, S., Center for Secure Information Systems, George Mason University, 4400 University Drive, Fairfax, VA, United States; Park, N., Department of Software and Information Systems, University of North Carolina, Charlotte, NC, United States; Serra, E., Computer Science Department, Boise State University, Boise, ID, United States; Subrahmanian, V.S., Vs@dartmouth.edu, Computer Science Department, Dartmouth College, Hanover, NH, United States","A ""noisy-rich"" (NR) cyber-attacker (Lippmann et al. 2012) is one who tries all available vulnerabilities until he or she successfully compromises the targeted network. We develop an adversarial foundation, based on Stackelberg games, for how NR-attackers will explore an enterprise network and how they will attack it, based on the concept of a system vulnerability dependency graph. We develop a mechanism by which the network can be modified by the defender to induce deception by placing honey nodes and apparent vulnerabilities into the network to minimize the expected impact of the NR-attacker's attacks (according to multiple measures of impact). We also consider the case where the adversary learns from blocked attacks using reinforcement learning. We run detailed experiments with real network data (but with simulated attack data) and show that Stackelberg Honey-based Adversarial Reasoning Engine performs very well, even when the adversary deviates from the initial assumptions made about his or her behavior. We also develop a method for the attacker to use reinforcement learning when his or her activities are stopped by the defender. We propose two stopping policies for the defender: Stop Upon Detection allows the attacker to learn about the defender's strategy and (according to our experiments) leads to significant damage in the long run, whereas Stop After Delay allows the defender to introduce greater uncertainty into the attacker, leading to better defendability in the long run. © 2018 ACM.","Adversarial models; Computer security; Enterprise systems","Damage detection; Engines; Food products; Network security; Adversarial reasoning; Cyber attackers; Dependency graphs; Enterprise networks; Real network datum; Simulated attacks; Stackelberg Games; System vulnerability; Reinforcement learning",,,,,"Ablon, L., Libicki, M.C., Golay, A., (2014) Markets for Cybercrime Tools and Stole Data: Hackers Bazaar, , http://www.rand.org/pubs/research_reports/RR610.html, Technical Report; Aggarwal, P., Maqbool, Z., Grover, A., Pammi, V.S., Singh, S., Dutt, V., Cyber security: A game-theoretic analysis of defender and attacker strategies in defacing-website games (2015) Proceedings of the International Conference on Cyber Situational Awareness, Data Analytics and Assessment (CyberSA'15), pp. 1-8. , IEEE; Alpcan, T., Baar, T., (2010) Network Security: A Decision and Game-Theoretic Approach (1st Ed.), , Cambridge University Press; An, B., Kempe, D., Kiekintveld, C., Shieh, E., Singh, S., Tambe, M., Vorobeychik, Y., Security games with limited surveillance (2012) Proceedings of the Association for the Advancement of Artifcial Intelligence Conference on Artifcial Intelligence (AAAI'12)., pp. 1241-1248; Bao, N., Musacchio, J., Optimizing the decision to expel attackers from an information system (2009) Proceedings of the 47th Annual Allerton Conference on Communication, Control, and Computing., pp. 644-651; Basar, T., Jan Olsder, G., (1998) Dynamic Noncooperative Game Theory, , SIAM; Beattie, S., Arnold, S., Cowan, C., Wagle, P., Wright, C., Shostack, A., Timing the application of security patches for optimal uptime (2002) Proceedings of the Large Installation System Administration Conference (LISA'02), 2, pp. 233-242; Bercovitch, M., Renford, M., Hasson, L., Shabtai, A., Rokach, L., Elovici, Y., HoneyGen: An automated honeytokens generator (2011) Proceedings of the IEEE Conference on Intelligence and Security Informatics (ISI'11). IEEE, pp. 131-136; Borkar, A., Salunke, A., Barabde, A., Karlekar, N.P., Honeypot: A survey of technologies, tools and deployment (2011) Proceedings of the International Conference on Web Engineering and Technology (ICWET'11), pp. 1357-1357. , http://dx.doi.org/10.1145/1980022.1980327, ACM, New York, NY; Cai, J., Yegneswaran, V., Alfeld, C., (2009) An Attacker-Defender Game for Honeynets, pp. 7-16. , Springer, Berlin; Campbell, R.M., Padayachee, K., Masombuka, T., A survey of honeypot research: Trends and opportunities (2015) Proceedings of the 2015 10th International Conference for Internet Technology and Secured Transactions (ICITST'15)., pp. 208-212. , http://dx.doi.org/10.1109/ICITST.2015.7412090; Cavusoglu, H., Cavusoglu, H., Zhang, J., Economics of security patch management (2006) Proceedings of the Workshop on the Economics of Information Security (WEIS'06); Cavusoglu, H., Cavusoglu, H., Zhang, J., Security patch management: Share the burden or share the damage? (2008) Manage. Sci., 54 (4), pp. 657-670. , 2008; Deb, K., Pratap, A., Agarwal, S., Meyarivan, T., A fast elitist multi-objective genetic algorithm: NSGA-II (2000) IEEE Trans. Evol. Comput., 6 (2), pp. 182-197. , 2000; Dewri, R., Poolsappasit, N., Ray, I., Whitley, D., Optimal security hardening using multi-objective optimization on attack tree models of networks (2007) Proceedings of the 14th ACM Conference on Computer and Commu-nications Security (CCS'07). ACM, pp. 204-213; Dewri, R., Ray, I., Poolsappasit, N., Whitley, D., Optimal security hardening on attack tree models of networks: A cost-beneft analysis (2012) Int. J. Inf. Secur., 11 (3), pp. 167-188. , 2012; Dhillon, G., Torkzadeh, G., Value-focused assessment of information system security in organizations (2001) Proceedings of the International Conference on Information Systems (ICIS'01), pp. 561-566. , Veda C. Storey, Sumit Sarkar, and Janice I. DeGross (Eds.). Association for Information Systems; Dickerson, J.P., Simari, G.I., Subrahmanian, V.S., Kraus, S., A graph-theoretic approach to protect static and moving targets from adversaries (2010) Proceedings of the International Conference on Autonomous Agents and Multiagent Systems (AAMAS'10), 1, pp. 299-306. , IFAAMAS; Durkota, K., Lisy, V., Bošansky, B., Kiekintveld, C., Optimal network security hardening using attack graph games (2015) Proceedings of the 24th International Conference on Artifcial Intelligence (IJCAI'15), pp. 526-532. , http://dl.acm.org/citation.cfm?id=2832249.2832322, AAAI Press; Friedrich, T., Neumann, F., (2014) Maximizing Submodular Functions under Matroid Constraints by Multi-objective Evolutionary Algorithms, pp. 922-931. , Springer; Godfrey, P., Shipley, R., Gryz, J., Algorithms and analyses for maximal vector computation (2007) Int. J. VLDB, 16 (1), pp. 5-28. , 2007; Hart, S., Games in extensive and strategic forms (1992) Handbook of Game Theory with Economic Applications (1 Ed.), 1, pp. 19-40. , R. J. Aumann and S. Hart (Eds.)., Elsevier; Hutchins, E.M., Cloppert, M.J., Amin, R.M., Intelligence-driven computer network defense informed by analysis of adversary campaigns and intrusion kill chains (2011) Proceedings of the 6th Annual International Conference on Information Warfare and Security, 1, p. 80. , 2011; Jajodia, S., Noel, S., Topological vulnerability analysis (2010) Cyber Situational Awareness, 46, pp. 139-154. , Sushil Jajodia, Peng Liu, Vipin Swarup, and Clif Wang (Eds.). Advances in Information Security, Springer; Jajodia, S., Noel, S., Kalapa, P., Albanese, M., Williams, J., Cauldron: Mission-centric cyber situational awareness with defense in depth (2011) Proceedings of the Military Communications Conference (MILCOM'11); Jajodia, S., Shakarian, P., Subrahmanian, V.S., Swarup, V., Wang, C., Cyber Warfare-Building the Scientifc Foundation (2015) Advances in Information Security, 56. , http://dx.doi.org/10.1007/978-3-319-14039-1, Springer; Keeney, R.L., (1992) Value-Focused Thinking: A Path to Creative Decisionmaking, p. 416. , Ralph L. Keeney. Harvard University Press, Cambridge, MA, xvi; Keeney, R.L., Value-focused thinking: Identifying decision opportunities and creating alternatives (1996) Eur. J. Operat. Res., 92 (3), pp. 537-549. , http://dx.doi.org/10.1016/0377-2217(96)00004-5, 1996; Kiekintveld, C., Jain, M., Tsai, J., Pita, J., Ordóñez, F., Tambe, M., Computing optimal randomized resource allocations for massive security games (2009) Proceedings of the International Conference on Autonomous Agents and Multiagent Systems (AAMAS'09)., pp. 689-696. , http://dl.acm.org/citation.cfm?id=1558013.1558108; Kiekintveld, C., Jain, M., Tsai, J., Pita, J., Ordóñez, F., Tambe, M., Computing optimal randomized resource allocations for massive security games (2009) Proceedings of the International Conference on Autonomous Agents and Multiagent Systems (AAMAS'09)., pp. 689-696; Kiekintveld, C., Lisý, V., Píbil, R., Game-theoretic foundations for the strategic use of honey-pots in network security (2015) Cyber Warfare-Building the Scientifc Foundation., pp. 81-101. , http://dx.doi.org/10.1007/978-3-319-14039-1_5; Kim, A., Kang, M.H., (2011) Determining Asset Criticality for Cyber Defense, , www.dtic.mil/cgi-bin/GetTRDoc?AD=ADA550373; Kocsis, L., Szepesvári, C., Bandit based monte-carlo planning (2006) Proceedings of the 17th European Conference on Machine Learning (ECML'06), pp. 282-293. , http://dx.doi.org/10.1007/11871842_29, Springer-Verlag, Berlin; Korzhyk, D., Yin, Z., Kiekintveld, C., Conitzer, V., Tambe, M., Stackelberg vs. nash in security games: An extended investigation of interchangeability, equivalence, and uniqueness (2011) Proceedings of the 9th International Conference on Autonomous Agents and Multiagent Systems (AAMAS'10)., pp. 1139-1146; Kung, H., Luccio, F., Preparata, F.P., On fnding the maxima of a set of vectors (1975) J. ACM, 22 (4), pp. 469-476. , 1975; Letchford, J., Vorobeychik, Y., Optimal interdiction of attack plans (2013) Proceedings of the International Conference on Autonomous Agents and Multiagent Systems (AAMAS'13)., pp. 199-206. , http://dl.acm.org/citation.cfm?id=2484920.2484955; Lippmann, R.P., Riordan, J.F., Yu, T.H., Watson, K.K., (2012) Continuous Security Metrics for Prevalent Network Threats: Introduction and First Four Metrics, , Technical Report. DTIC Document; Lou, J., Smith, A.M., Vorobeychik, Y., Multidefender security games (2017) IEEE Intell. Syst., 32 (1), pp. 50-60. , http://dx.doi.org/10.1109/MIS.2017.11, 2017, Jan; Lye, K.-W., Wing, J.M., Game strategies in network security (2005) Int. J. Inf. Secur., 4 (1-2), pp. 71-86. , http://dx.doi.org/10.1007/s10207-004-0060-x, 2005; Mercuri., R.T., Analyzing security costs (2003) Commun. ACM, 46 (6), pp. 15-18. , 2003; Mirkovic, J., Reiher, P., A taxonomy of DDoS attack and DDoS defense mechanisms (2004) ACM SIGCOMM Comput. Commun. Rev., 34 (2), pp. 39-53. , 2004; (2017) National Vulnerability Database, , http://nvd.nist.gov, NIST; Paruchuri, P., Pearce, J.P., Marecki, J., Tambe, M., Ordonez, F., Kraus, S., Playing games for security: An efcient exact algorithm for solving bayesian stackelberg games (2008) Proceedings of the International Conference on Autonomous Agents and Multiagent Systems (AAMAS'08)., pp. 895-902; Pita, J., Jain, M., Marecki, J., Ordóñez, F., Portway, C., Tambe, M., Western, C., Kraus, S., Deployed ARMOR protection: The applicationof agame theoretic model for security at the los angeles international airport (2008) Proceedings of the International Conference on Autonomous Agents and Multiagent Systems (AAMAS'08)., pp. 125-132; Poolsappasit, N., Dewri, R., Ray, I., Dynamic security risk management using bayesian attack graphs (2012) IEEE Trans. Depend. Secur. Comput., 9 (1), pp. 61-74. , 2012; Pouget, F., Dacier, M., (2003) Honeypot, Honeynet: A Comparative Survey, , Institut EurÃl'com; Qian, C., Yu, Y., Zhou, Z.-H., On constrained boolean pareto optimization (2015) Proceedings of the 24th International Conference on Artifcial Intelligence (IJCAI'15), pp. 389-395. , AAAI Press; Serra, E., Jajodia, S., Pugliese, A., Rullo, A., Subrahmanian, V.S., Pareto-optimal adversarial defense of enterprise systems (2015) ACM Trans. Inf. Syst. Secur., 17 (3), p. 39. , http://dx.doi.org/10.1145/2699907, 2015, March; Shabtai, A., Elovici, Y., Rokach, L., Data leakage detection/prevention solutions (2012) A Survey of Data Leakage Detection and Prevention Solutions, pp. 17-37. , Springer; Shakarian, P., Paulo, D., Albanese, M., Jajodia, S., Keeping intrudors at large: A graph-theoretic approach to reducing the probability of successful network intrusions (2014) Proceedings of the International Conference on Security and Cryptography (SECRYPT'14)., pp. 19-30; Srinivasa, K.G., (2012) Application of Genetic Algorithms for Detecting Anomaly in Network Intrusion Detection Systems, pp. 582-591. , Springer, Berlin; Tankard, C., Advanced persistent threats and how to monitor and deter them (2011) Network Security 2011, 8, pp. 16-19; (2011) Common Weakness Scoring System (CWSSTM), , http://cwe.mitre.org/cwss/, The MITRE Corporation; Viegas, E., Olivo Santin, A., Franca, A., Jasinski, R., Pedroni, V.A., Oliveira, L.S., Towards an energy-efcient anomaly-based intrusion detection engine for embedded systems (2017) IEEE Trans. Comput., 66 (1), pp. 163-177. , http://dx.doi.org/doi.ieeecomputersociety.org/10.1109/TC.2016.2560839, 2017; Whitley, D., Rana, S., Heckendorn, R.B., The island model genetic algorithm: On separability, population size and convergence (1998) J. Comput. Inf. Technol., 7, pp. 33-47. , 1998",,,,"Association for Computing Machinery",,,,,15335399,,,,"English","ACM Trans. Internet Technol.",Article,"Final","All Open Access, Bronze",Scopus,2-s2.0-85055875929
"Sihag S., Tajer A.","57201668363;17436387600;","Secure parameter estimation: Fundamental tradeoffs",2018,"2017 IEEE Global Conference on Signal and Information Processing, GlobalSIP 2017 - Proceedings","2018-January",,,"482","486",,,"10.1109/GlobalSIP.2017.8308689","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048083509&doi=10.1109%2fGlobalSIP.2017.8308689&partnerID=40&md5=0ed3acd9ba269b8c9fed1ad626b9ba28","Electrical Computer and Systems Engineering Department, Rensselaer Polytechnic Institute, Troy, NY, United States","Sihag, S., Electrical Computer and Systems Engineering Department, Rensselaer Polytechnic Institute, Troy, NY, United States; Tajer, A., Electrical Computer and Systems Engineering Department, Rensselaer Polytechnic Institute, Troy, NY, United States","The problem of parameter estimation in an adversarial setting, in which an active adversary might decide to compromise the data for the purpose of subverting the estimation decisions, is considered. Forming secure estimation decisions entails two intertwined inference decisions. Specifically, on one hand, deciding whether the data is compromised, like any detection decision, is never perfect. On the other hand, missing any attack translates to degradation in the estimation quality. Based on these two observations, the paper aims to characterize the interplay between two figures of merit q and ß, where q captures how much estimation quality degrades when the objective is to miss the presence of an attacker with a probability not exceeding ß. The paper characterizes the optimal decision rules and compares the results with the existing literature. © 2017 IEEE.","Combined estimation and detection; parameter estimation; secure inference","Active adversary; Estimation and detection; Estimation quality; Figures of merits; Optimal decision-rule; secure inference; Parameter estimation",,,,,"Wilson, C., Veeravalli, V., MMSE estimation in a sensor network in the presence of an adversary (2016) Proc. IEEE International Symposium On Information Theory, Barcelona, Spain, pp. 2479-2483. , Jul; Vempaty, A., Tong, L., Varshney, P.K., Distributed inference with Byzantine data: State-of-the-art review on data falsification attacks (2013) IEEE Signal Processing Magazine, 30 (5), pp. 65-75. , Sep; Vempaty, A., Ozdemir, O., Agrawal, K., Chen, H., Varshney, P.K., Localization in wireless sensor networks: Byzantines and mitigation techniques (2013) IEEE Transactions On Signal Processing, 61 (6), pp. 1495-1508. , Mar; Ebinger, P., Wolthusen, S.D., Efficient state estimation and Byzantine behavior identification in tactical MANETs (2009) Proc. IEEE Military Communications Conference, Boston, MA, , Oct; Zhang, J., Blum, R.S., Lu, X., Conus, D., Asymptotically optimum distributed estimation in the presence of attacks (2015) IEEE Transactions On Signal Processing, 63 (5), pp. 1086-1101. , Mar; Zhang, J., Blum, R.S., Distributed estimation in the presence of attacks for large scale sensor networks (2014) Proc. Conference On Information Sciences and Systems, Princeton, NJ, , Mar; Rawat, A.S., Anand, P., Chen, H., Varshney, P.K., Countering Byzantine attacks in cognitive radio networks (2010) Proc. IEEE International Conference On Acoustics, Speech and Signal Processing, Dallas, TX, pp. 3098-3101. , Mar; Soltanmohammadi, E., Orooji, M., Naraghi-Pour, M., Decentralized hypothesis testing in wireless sensor networks in the presence of misbehaving nodes (2013) IEEE Transactions On Information Forensics and Security, 8 (1), pp. 205-215. , Jan; Vempaty, A., Agrawal, K., Varshney, P., Chen, H., Adaptive learning of Byzantines' behavior in cooperative spectrum sensing (2011) Proc. IEEE Wireless Communications and Networking Conference, Cancun, Mexico, pp. 1310-1315. , Mar; Fawzi, H., Tabuada, P., Diggavi, S., Secure state-estimation for dynamical systems under active adversaries (2011) Proc. Allerton Conference On Communication, Control, and Computing, Monticello, IL, pp. 337-344. , Sep; Fawzi, H., Tabuada, P., Diggavi, S., Secure estimation and control for cyber-physical systems under adversarial attacks (2014) IEEE Transactions On Automatic Control, 59 (6), pp. 1454-1467. , Jun; Yong, S.Z., Zhu, M., Frazzoli, E., Resilient state estimation against switching attacks on stochastic cyber-physical systems (2015) Proc. IEEE Conference On Decision and Control, Osaka, Japan, pp. 5162-5169. , Dec; Pajic, M., Tabuada, P., Lee, I., Pappas, G.J., Attack-resilient state estimation in the presence of noise (2015) Proc. IEEE Conference On Decision and Control, Osaka, Japan, pp. 5827-5832. , Dec; Shoukry, Y., Nuzzo, P., Puggelli, A., Sangiovanni-Vincentelli, A.L., Seshia, S.A., Tabuada, P., Secure state estimation for cyber physical systems under sensor attacks: A satisfiability modulo theory approach (2017) IEEE Transactions On Automatic Control, p. 99; Mishra, S., Shoukry, Y., Karamchandani, N., Diggavi, S., Tabuada, P., Secure state estimation: Optimal guarantees against sensor attacks in the presence of noise (2015) Proc. IEEE International Symposium On Information Theory, Hong Kong, China, pp. 2929-2933. , Jun; Pajic, M., Weimer, J., Bezzo, N., Tabuada, P., Sokolsky, O., Lee, I., Pappas, G.J., Robustness of attack-resilient state estimators (2014) Proc. IEEE International Conference On Cyber-Physical Systems, Berlin, Germany, pp. 163-174. , Apr; Bai, C.Z., Gupta, V., On Kalman filtering in the presence of a compromised sensor: Fundamental performance bounds (2014) Proc. American Control Conference, Portland, or, pp. 3029-3034. , Jun; Middleton, D., Esposito, R., Simultaneous optimum detection and estimation of signals in noise (1968) IEEE Transactions On Information Theory, 14 (3), pp. 434-444. , May; Zeitouni, O., Ziv, J., Merhav, N., When is the generalized likelihood ratio test optimal? (1992) IEEE Transactions On Information Theory, 38 (5), pp. 1597-1602. , Sep; Moustakides, G.V., Jajamovich, G.H., Tajer, A., Wang, X., Joint detection and estimation: Optimum tests and applications (2012) IEEE Transactions On Information Theory, 58 (7), pp. 4215-4229. , Jul; Jajamovich, G.H., Tajer, A., Wang, X., Minimax-optimal hypothesis testing with estimation-dependent costs (2012) IEEE Transactions On Signal Processing, 60 (12), pp. 6151-6165. , Dec; Poor, H.V., (1998) An Introduction to Signal Detection and Estimation, 2nd Ed, , New York: Springer-Verlag",,,"IEEE Signal Processing Society;The Institute of Electrical and Electronics Engineers (IEEE)","Institute of Electrical and Electronics Engineers Inc.","5th IEEE Global Conference on Signal and Information Processing, GlobalSIP 2017","14 November 2017 through 16 November 2017",,135166,,9781509059904,,,"English","IEEE Glob. Conf. Signal Inf. Process., GlobalSIP - Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85048083509
"Ntemos K., Plata-Chaves J., Kolokotronis N., Kalouptsidis N., Moonen M.","57188862282;35273120200;6602249466;7007129433;7006229574;","Secure Information Sharing in Adversarial Adaptive Diffusion Networks",2018,"IEEE Transactions on Signal and Information Processing over Networks","4","1",,"111","124",,2,"10.1109/TSIPN.2017.2787910","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049523787&doi=10.1109%2fTSIPN.2017.2787910&partnerID=40&md5=92350bf9d58b047d6c0ce8119a3c6681","Department of Informatics and Telecommunications, University of Athens, Athens, 157 72, Greece; Department of Electrical Engineering (ESAT-STADIUS), KU Leuven, Leuven, 3000, Belgium; Department of Informatics and Telecommunications, University of Peloponnese, Tripoli, 221 00, Greece","Ntemos, K., Department of Informatics and Telecommunications, University of Athens, Athens, 157 72, Greece; Plata-Chaves, J., Department of Electrical Engineering (ESAT-STADIUS), KU Leuven, Leuven, 3000, Belgium; Kolokotronis, N., Department of Informatics and Telecommunications, University of Peloponnese, Tripoli, 221 00, Greece; Kalouptsidis, N., Department of Informatics and Telecommunications, University of Athens, Athens, 157 72, Greece; Moonen, M., Department of Electrical Engineering (ESAT-STADIUS), KU Leuven, Leuven, 3000, Belgium","In this paper, information sharing over adversarial adaptive networks is considered. Defense against adversarial attacks is enforced by an attack detection mechanism that guides the diffusion strategy in the parameter estimation task and the transmission decisions of agents. The latter are taken to maximize long-term rewards, expressed in terms of estimation performance, communication cost, and illegal gains in a nonzero sum repeated game with imperfect action monitoring. In order to track agents' behavior and stimulate cooperation, a reputation protocol is designed, along with the deployment of a set of honest nodes whose behavior is consistent with the reputation protocol. An algorithm that promotes cooperation and can achieve secure parameter estimation is described and illustrated by simulations. © 2015 IEEE.","diffusion algorithm; distributed in-network processing; game theory; parameter estimation; Reputation design","Behavioral research; Diffusion; Game theory; Information analysis; Information dissemination; Adaptive diffusions; Communication cost; Diffusion algorithm; Diffusion strategies; Estimation performance; In-network processing; Information sharing; Secure information sharing; Parameter estimation",,,,,"Michiardi, P., Molva, R., Simulation-based analysis of security exposures in mobile ad hoc networks (2002) Proc. Eur. Wireless Conf., pp. 15-17. , Feb; Ahmed, A., Bakar, K.A., Chana, M.I., Haseeb, K., Khan, A.W., A survey on trust based detection and isolation of malicious nodes in ad-hoc and sensor networks (2015) Front. Comput. Sci., 9 (2), pp. 280-296; Momani, M., Challa, S., Survey of trust models in different network domains (2010) Int. J. Ad Hoc Sens. Ubiquitous Comput., 1 (3), pp. 1-19; Aliprantis, C.D., Camera, G., Puzzello, D., A random matching theory (2007) Games Econ. Behav., 59 (1), pp. 1-16; Xu, J., Schaar Der Van, M., Social norm design for information exchange systems with limited observations (2012) IEEE J. Sel. Areas Commun., 30 (11), pp. 2126-2135. , Dec; Gigerenzer, G., Selten, R., (2002) Bounded Rationality: The Adaptive Toolbox, , Cambridge, MA, USA: MIT Press; Ntemos, K., Kalouptsidis, N., Kolokotronis, N., Managing trust in diffusion adaptive networks with malicious agents (2015) Proc. Eur. Signal Process. Conf., pp. 91-95; Park, H., Schaar Der Van, M., On the impact of bounded rationality in peer-to-peer networks (2009) IEEE Signal Process. Lett., 16 (8), pp. 675-678. , Aug; Felegyhazi, M., Hubaux, J.-P., Buttyan, L., Nash equilibria of packet forwarding strategies in wireless ad hoc networks IEEE Trans. Mobile Comput., 5 (5), pp. 463-476. , May 2006; Jaramillo, J.J., Srikant, R., DARWIN: Distributed and adaptive reputation mechanism for wireless ad-hoc networks (2007) Proc. Int. Conf. Mobile Comput. Netw., pp. 87-98; Chen, Y., Liu, K.J.R., Indirect reciprocity game modelling for cooperation stimulation in cognitive networks (2011) IEEE Trans. Commun., 59 (1), pp. 159-168. , Jan; Gao, Y., Chen, Y., Liu, K.J.R., Cooperation stimulation in cooperative communications: An indirect reciprocity game (2012) Proc. IEEE Int. Conf. Commun., pp. 5163-5167; Tang, C., Li, A., Li, X., When reputation enforces evolutionary cooperation in unreliable MANETs (2015) IEEE Trans. Cybern., 45 (10), pp. 2190-2201. , Oct; Yu, C.-K., Schaar Der Van, M., Sayed, A.H., Reputation design for adaptive networks with selfish agents (2013) Proc. IEEE 14th Workshop Signal Process. Adv. Wireless Commun., pp. 160-164; Yu, C.-K., Schaar Der Van, M., Sayed, A.H., Information-sharing over adaptive networks with self-interested agents (2015) IEEE Trans. Signal Inf. Process. over Netw., 1 (1), pp. 2-19. , Mar; Xiao, L., Chen, Y., Lin, W.S., Liu, K.J.R., Indirect reciprocity security game for large-scale wireless networks (2012) IEEE Trans. Inf. Forensics Secur., 7 (4), pp. 1368-1380. , Aug; He, Q., Wu, D., Khosla, P., SORI: A secure and objective reputationbased incentive scheme for ad-hoc networks (2004) Proc. Wireless Commun. Netw. Conf., pp. 825-830; Buchegger, S., Le Boudec, J.-Y., Performance analysis of the CONFIDANT protocol (cooperation of nodes-fairness in dynamic ad-hoc networks) (2002) Proc. 3RD ACM Int. Symp. Mobile Ad Hoc Netw. Comput., pp. 226-236; Marti, S., Mitigating routing misbehavior in mobile ad hoc networks (2000) Proc. Int. Conf. Mobile Comput. Netw., pp. 255-265; Fudenberg, D., Tirole, J., (1991) Game Theory, p. 393. , Cambridge, MA, USA: MIT Press; Nisan, N., (2007) Algorithmic Game Theory, 1. , Cambridge U. K. : Cambridge Univ. Press; Mailath, G.J., Samuelson, L., (2006) Repeated Games and Reputations: Long-Run Relationships, , London, U. K. : Oxford Univ. Press; Tuyls, K., Weiss, G., Multiagent learning: Basics, challenges, and prospects (2012) AI Mag., 33 (3), pp. 41-52; Zhao, X., Sayed, A.H., Distributed clustering and learning over networks (2015) IEEE Trans. Signal Process., 63 (13), pp. 3285-3300. , Jul; Sayed, A.H., Adaptive networks (2014) Proc. IEEE, 102 (4), pp. 460-497. , Apr; Kekatos, V., Giannakis, G.B., Distributed robust power system state estimation IEEE Trans. Power Syst., 28 (2), pp. 1617-1626. , May 2013; Plata-Chaves, J., Bertrand, A., Moonen, M., Theodoridis, S., Zoubir, A.M., Heterogeneous and multitask wireless sensor networks-algorithms, applications, and challenges (2017) IEEE J. Sel. Topics Signal Process., 11 (3), pp. 450-465. , Apr; Shoham, Y., Leyton-Brown, K., (2008) Multiagent Systems: Algorithmic, Game Theoretic and Logical Foundations, , Cambridge, U. K. : Cambridge Univ. Press; Kreps, D.M., Milgrom, P., Roberts, J., Wilson, R., Rational cooperation in the finitely repeated prisoners' dilemma (1982) J. Econ. Theory, 27 (2), pp. 245-252; Busoniu, L., Babuska, R., De Schutter, B., A comprehensive survey of multiagent reinforcement learning (2008) IEEE Trans. Syst., Man, Cybern. C, Appl. Rev., 38 (2), pp. 156-172. , Mar; Littman, M.L., Value-function reinforcement learning in Markov games (2001) J. Cogn. Syst. Res., 2 (1), pp. 55-66","Ntemos, K.; Department of Informatics and Telecommunications, Greece; email: kdemos@di.uoa.gr",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,2373776X,,,,"English","IEEE Trans. Signal Inf. Process. Over Netw.",Article,"Final","",Scopus,2-s2.0-85049523787
"Wang C., Lu Z.","7501642219;54983839500;","Cyber Deception: Overview and the Road Ahead",2018,"IEEE Security and Privacy","16","2",,"80","85",,26,"10.1109/MSP.2018.1870866","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044832202&doi=10.1109%2fMSP.2018.1870866&partnerID=40&md5=9001ab2883a7463c41919df129422f23","Department of Electrical and Computer Engineering, North Carolina State University, United States; Department of Electrical Engineering, University of South Florida, United States","Wang, C., Department of Electrical and Computer Engineering, North Carolina State University, United States; Lu, Z., Department of Electrical Engineering, University of South Florida, United States","Since the concept of deception for cybersecurity was introduced decades ago, several primitive systems, such as honeypots, have been attempted. More recently, research on adaptive cyber defense techniques has gained momentum. The new research interests in this area motivate us to provide a high-level overview of cyber deception. We analyze potential strategies of cyber deception and its unique aspects. We discuss the research challenges of creating effective cyber deception-based techniques and identify future research directions. © 2003-2012 IEEE.","adversarial mind manipulation; cyber attack and defense; cyber deception; moving target defense; proactive cyber defense; proactive strategies; security","Computer networks; Electrical engineering; adversarial mind manipulation; cyber deception; Cyber defense; Cyber-attacks; Moving target defense; proactive strategies; security; Network security",,,,,"Croom, C., The cyber kill-chain: A foundation for a new cyber-security strategy (2010) High Frontier, 6 (4), pp. 52-56; Crouse, M., Prosser, B., Fulp, E.W., Probabilistic performance analysis of moving target and deception reconnaissance defenses (2015) Proc. of ACM MTD; Jajodia, S., (2011) Moving Target Defense: Creating Asymmetric Uncertainty for Cyber Threats, 54. , Springer Science & Business Media; Stoll, C.P., (1989) The Cuckoo's Egg: Tracking A Spy Through the Maze of Computer Espionage, , Doubleday; Yuill, J.J., (2006) Defensive Computer-Security Deception Operations: Processes, Principles and Techniques, , ProQuest; Juels, A., Rivest, R.L., Honeywords: Making password-cracking detectable (2013) Proc. of ACM CCS; Paxton, N.C., Utilizing network science and honeynets for software induced cyber incident analysis (2015) Proc. of HICSS; Almeshekah, M.H., Spafford, E.H., Planning and integrating deception into computer security defenses (2014) Proc. of NSPW; Dennett, D., Intentional systems theory (2009) The Oxford Handbook of Philosophy of Mind, pp. 339-350; Haselton, M.G., Nettle, D., Murray, D.R., The evolution of cognitive bias (2005) The Handbook of Evolutionary Psychology",,,,"Institute of Electrical and Electronics Engineers Inc.",,,,,15407993,,,,"English","IEEE Secur. Privacy",Review,"Final","",Scopus,2-s2.0-85044832202
"Chen S., Xue M., Fan L., Hao S., Xu L., Zhu H., Li B.","57190395316;56890437900;57197024797;57052159000;55846204400;19640836400;57188689924;","Automated poisoning attacks and defenses in malware detection systems: An adversarial machine learning approach",2018,"Computers and Security","73",,,"326","344",,106,"10.1016/j.cose.2017.11.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037536705&doi=10.1016%2fj.cose.2017.11.007&partnerID=40&md5=3171acfe07a4b294d223532e5b5a2d27","East China Normal University, Shanghai, China; Nanyang Technological University, Singapore; New York University Shanghai, Shanghai, China; Shanghai Jiao Tong University, Shanghai, China; University of Texas at Dallas, United States; University of California, Berkeley, United States","Chen, S., East China Normal University, Shanghai, China, Nanyang Technological University, Singapore; Xue, M., New York University Shanghai, Shanghai, China, Shanghai Jiao Tong University, Shanghai, China; Fan, L., East China Normal University, Shanghai, China, Nanyang Technological University, Singapore; Hao, S., University of Texas at Dallas, United States; Xu, L., East China Normal University, Shanghai, China; Zhu, H., Shanghai Jiao Tong University, Shanghai, China; Li, B., University of California, Berkeley, United States","The evolution of mobile malware poses a serious threat to smartphone security. Today, sophisticated attackers can adapt by maximally sabotaging machine-learning classifiers via polluting training data, rendering most recent machine learning-based malware detection tools (such as DREBIN, DROIDAPIMINER, and MAMADROID) ineffective. In this paper, we explore the feasibility of constructing crafted malware samples; examine how machine-learning classifiers can be misled under three different threat models; then conclude that injecting carefully crafted data into training data can significantly reduce detection accuracy. To tackle the problem, we propose KUAFUDET, a two-phase learning enhancing approach that learns mobile malware by adversarial detection. KUAFUDET includes an offline training phase that selects and extracts features from the training set, and an online detection phase that utilizes the classifier trained by the first phase. To further address the adversarial environment, these two phases are intertwined through a self-adaptive learning scheme, wherein an automated camouflage detector is introduced to filter the suspicious false negatives and feed them back into the training phase. We finally show that KUAFUDET can significantly reduce false negatives and boost the detection accuracy by at least 15%. Experiments on more than 250,000 mobile applications demonstrate that KUAFUDET is scalable and can be highly effective as a standalone system. © 2017 Elsevier Ltd","Adversarial machine learning; KUAFUDET; Malware detection; Manipulation; Poisoning attacks","Artificial intelligence; Classification (of information); Computer crime; Learning algorithms; Learning systems; Adversarial environments; KUAFUDET; Machine learning approaches; Malware detection; Manipulation; Poisoning attacks; Self-adaptive learning; Smartphone securities; Malware",,,,,"Aafer, Y., Du, W., Yin, H., DroidAPIMiner: mining API-level features for robust malware detection in Android (2013) Security and privacy in communication networks, pp. 86-103. , Springer; Arp, D., Spreitzenbarth, M., Hubner, M., Gascon, H., Rieck, K., DREBIN: effective and explainable detection of Android malware in your pocket (2014) Proceedings of the annual symposium on Network and Distributed System Security (NDSS); Arzt, S., Rasthofer, S., Fritz, C., Bodden, E., Bartel, A., Klein, J., FlowDroid: precise context, flow, field, object-sensitive and lifecycle-aware taint analysis for Android apps (2014) ACM SIGPLAN notices, 49, pp. 259-269. , ACM; Avdiienko, V., Kuznetsov, K., Gorla, A., Zeller, A., Arzt, S., Rasthofer, S., Mining apps for abnormal usage of sensitive data (2015) 2015 IEEE/ACM 37th IEEE international conference on software engineering, 1, pp. 426-436. , IEEE; Biggio, B., Fumera, G., Roli, F., Security evaluation of pattern classifiers under attack (2014) IEEE Trans Knowl Data Eng, 26 (4), pp. 984-996; Brunk, F., Intersection problems in combinatorics (2009), Ph.D. thesis; University of St Andrews; Brückner, M., Kanzow, C., Scheffer, T., Static prediction games for adversarial learning problems (2012) J Mach Learn Res, 13 (Sep), pp. 2617-2654; Cao, Y., Yang, J., Towards making systems forget with machine unlearning (2015) Security and privacy (SP), 2015 IEEE symposium on, pp. 463-480. , IEEE; Chen, S., Xue, M., Tang, Z., Xu, L., Zhu, H., StormDroid: a streaminglized machine learning-based system for detecting Android malware (2016) Proceedings of the 11th ACM on Asia conference on computer and communications security, pp. 377-388. , ACM; Chen, S., Xue, M., Xu, L., Poster: towards adversarial detection of mobile malware (2016) Proceedings of the 22nd annual international conference on mobile computing and networking, pp. 415-416. , ACM; Chen, W., Aspinall, D., Gordon, A.D., Sutton, C., Muttik, I., More semantics more robust: improving android malware classifiers (2016) Proceedings of the 9th ACM conference on security & privacy in wireless and mobile networks, pp. 147-158. , ACM; Dash, S.K., Suarez-Tangil, G., Khan, S., Tam, K., Ahmadi, M., Kinder, J., DroidScribe: classifying Android malware based on runtime behavior (2016) Mobile Security Technologies (MoST 2016), 7148, pp. 1-12; Debarr, D., Sun, H., Wechsler, H., Adversarial spam detection using the randomized hough transform-support vector machine (2013) Machine Learning and Applications (ICMLA), 2013 12th international conference on, 1, pp. 299-304. , IEEE; Deo, A., Dash, S.K., Suarez-Tangil, G., Vovk, V., Cavallaro, L., Prescience: probabilistic guidance on the retraining conundrum for malware detection (2016) Proceedings of the 2016 ACM workshop on artificial intelligence and security, pp. 71-82. , ACM; Enck, W., Gilbert, P., Han, S., Tendulkar, V., Chun, B.-G., Cox, L.P., TaintDroid: an information-flow tracking system for realtime privacy monitoring on smartphones (2014) ACM Transactions on Computer Systems (TOCS), 32 (2), p. 5; Fan, L., Xue, M., Chen, S., Xu, L., Zhu, H., Poster: accuracy vs. time cost: detecting android malware through pareto ensemble pruning (2016) Proceedings of the 2016 ACM SIGSAC conference on computer and communications security, pp. 1748-1750. , ACM; Feizollah, A., Anuar, N.B., Salleh, R., Suarez-Tangil, G., Furnell, S., Androdialysis: analysis of android intent effectiveness in malware detection (2017) Computers & Security, 65, pp. 121-134; Felt, A.P., Chin, E., Hanna, S., Song, D., Wagner, D., Android permissions demystified (2011) Proceedings of the 18th ACM conference on computer and communications security, pp. 627-638. , ACM; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2014), arXiv preprint arXiv:1412.6572; Gordon, M.I., Kim, D., Perkins, J.H., Gilham, L., Nguyen, N., Rinard, M.C., Information flow analysis of Android applications in DroidSafe (2015) Proceedings of the annual symposium on Network and Distributed System Security (NDSS); Graziano, M., Canali, D., Bilge, L., Lanzi, A., Balzarotti, D., Needles in a haystack: mining information from public dynamic analysis sandboxes for malware intelligence (2015) 24th USENIX Security Symposium (USENIX Security 15), pp. 1057-1072; Grosse, K., Papernot, N., Manoharan, P., Backes, M., McDaniel, P., Adversarial perturbations against deep neural networks for malware classification (2016), arXiv preprint arXiv:1606.04435; Hall, M., Frank, E., Holmes, G., Pfahringer, B., Reutemann, P., Witten, I.H., The WEKA data mining software: an update (2009) ACM SIGKDD Explorations Newsletter, 11, pp. 10-18; Idrees, F., Rajarajan, M., Conti, M., Chen, T., Rahulamathavan, Y., PIndroid: a novel android malware detection system using ensemble learning methods (2017) Computers & Security; Li, L., Bartel, A., Bissyandé, T.F., Klein, J., Le Traon, Y., Arzt, S., IccTA: detecting inter-component privacy leaks in Android apps (2015) Proceedings of the 37th international conference on software engineering, 1, pp. 280-291. , IEEE Press; Li, X., Li, F., Adversarial examples detection in deep networks with convolutional filter statistics (2016), arXiv preprint arXiv:1612.07767; Mariconti, E., Onwuzurike, L., Andriotis, P., De Cristofaro, E., Ross, G., Stringhini, G., MAMADROID: detecting Android malware by building Markov chains of behavioral models (2017) Proceedings of the annual symposium on Network and Distributed System Security (NDSS); McDaniel, P., Papernot, N., Celik, Z.B., Machine learning in adversarial settings (2016) IEEE Security & Privacy, 14 (3), pp. 68-72; Meng, G., Xue, Y., Mahinthan, C., Narayanan, A., Liu, Y., Zhang, J., Mystique: evolving Android malware for auditing anti-malware tools (2016) Proceedings of the 11th ACM on Asia conference on computer and communications security, pp. 365-376. , ACM; Octeau, D., Jha, S., Dering, M., McDaniel, P., Bartel, A., Li, L., Combining static analysis with probabilistic models to enable market-scale android inter-component analysis (2016) ACM SIGPLAN notices, 51, pp. 469-484. , ACM; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European symposium on, pp. 372-387. , IEEE; Poeplau, S., Fratantonio, Y., Bianchi, A., Kruegel, C., Vigna, G., Execute this! analyzing unsafe and malicious dynamic code loading in android applications (2014) NDSS, 14, pp. 23-26; Rasthofer, S., Arzt, S., Bodden, E., A machine-learning approach for classifying and categorizing Android sources and sinks (2014) Proceedings of the annual symposium on Network and Distributed System Security (NDSS); Rasthofer, S., Arzt, S., Miltenberger, M., Bodden, E., Harvesting runtime values in Android applications that feature anti-analysis techniques (2016) Proceedings of the annual symposium on Network and Distributed System Security (NDSS); Rastogi, V., Chen, Y., Jiang, X., Catch me if you can: evaluating Android anti-malware against transformation attacks (2014) IEEE Transactions on Information Forensics and Security, 9 (1), pp. 99-108; Schlegel, R., Zhang, K., Zhou, X., Intwala, M., Kapadia, A., Wang, X., Soundcomber: a stealthy and context-aware sound Trojan for smartphones (2011) Proceedings of the annual symposium on Network and Distributed System Security (NDSS), 11, pp. 17-33; Shabtai, A., Kanonov, U., Elovici, Y., Glezer, C., Weiss, Y., Andromaly: a behavioral malware detection framework for Android devices (2012) Journal of Intelligent Information Systems, 38 (1), pp. 161-190; Shen, S., Tople, S., Saxena, P., AUROR: defending against poisoning attacks in collaborative deep learning systems (2016) Proceedings of the 32nd annual conference on computer security applications, pp. 508-519. , ACM; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Intriguing properties of neural networks (2014) Proceedings of the 2014 international conference on learning representations. Computational and biological learning society; Tam, K., Khan, S.J., Fattori, A., Cavallaro, L., CopperDroid: automatic reconstruction of Android malware behaviors (2015) Proceedings of the annual symposium on Network and Distributed System Security (NDSS); Wang, B., Gao, J., Qi, Y., A theoretical framework for robustness of (deep) classifiers under adversarial noise (2016), arXiv preprint arXiv:1612.00334; Wang, F., Liu, W., Chawla, S., On sparse feature attacks in adversarial learning (2014) Data Mining (ICDM), 2014 IEEE international conference on, pp. 1013-1018. , IEEE; Wang, Y., Jha, S., Chaudhuri, K., Analyzing the robustness of nearest neighbors to adversarial examples (2017), arXiv preprint arXiv:1706.03922; Wong, M.Y., Lie, D., IntelliDroid: a targeted input generator for the dynamic analysis of Android malware (2016) Proceedings of the annual symposium on Network and Distributed System Security (NDSS); Wu, C., Zhou, Y., Patel, K., Liang, Z., Jiang, X., AirBag: boosting smartphone resistance to malware infection (2014) Proceedings of the annual symposium on Network and Distributed System Security (NDSS); Wu, D.-J., Mao, C.-H., Wei, T.-E., Lee, H.-M., Wu, K.-P., DroidMat: Android malware detection through manifest and API calls tracing (2012) Information security (Asia JCIS), 2012 seventh Asia joint conference on, pp. 62-69. , IEEE; Yan, L.K., Yin, H., DroidScope: seamlessly reconstructing the OS and Dalvik semantic views for dynamic Android malware analysis (2012) Presented as part of the 21st USENIX security symposium (USENIX Security 12), pp. 569-584; Yang, C., Xu, Z., Gu, G., Yegneswaran, V., Porras, P., DroidMiner: automated mining and characterization of fine-grained malicious behaviors in Android applications (2014) European symposium on research in computer security, pp. 163-182. , Springer; Yang, W., Xiao, X., Andow, B., Li, S., Xie, T., Enck, W., AppContext: differentiating malicious and benign mobile app behaviors using context (2015) Software Engineering (ICSE), 2015 IEEE/ACM 37th IEEE international conference on, 1, pp. 303-313. , IEEE; Zhang, F., Chan, P.P., Biggio, B., Yeung, D.S., Roli, F., Adversarial feature selection against evasion attacks (2016) IEEE Transactions on Cybernetics, 46 (3), pp. 766-777; Zhang, M., Duan, Y., Yin, H., Zhao, Z., Semantics-aware Android malware classification using weighted contextual API dependency graphs (2014) Proceedings of the 2014 ACM SIGSAC conference on computer and communications security, pp. 1105-1116. , ACM; Zhou, W., Zhou, Y., Grace, M., Jiang, X., Zou, S., Fast, scalable detection of piggybacked mobile applications (2013) Proceedings of the third ACM conference on data and application security and privacy, pp. 185-196. , ACM; Zhou, Y., Jiang, X., Dissecting Android malware: characterization and evolution (2012) Security and privacy (SP), 2012 IEEE symposium on, pp. 95-109. , IEEE; Zhou, Y., Wang, Z., Zhou, W., Jiang, X., Hey, you, get off of my market: detecting malicious apps in official and alternative Android markets (2012) NDSS, 25, pp. 50-52","Xu, L.; East China Normal UniversityChina; email: lhxu@cs.ecnu.edu.cn",,,"Elsevier Ltd",,,,,01674048,,CPSED,,"English","Comput Secur",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85037536705
"Zhang Y., Xiang Y., Huang X., Chen X., Alelaiwi A.","54890205800;57114147900;55814453300;35721744700;55546007800;","A matrix-based cross-layer key establishment protocol for smart homes",2018,"Information Sciences","429",,,"390","405",,14,"10.1016/j.ins.2017.11.039","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034867320&doi=10.1016%2fj.ins.2017.11.039&partnerID=40&md5=08c510a597bf9a6c86ade8f16112db59","School of Software and Electrical Engineering, Swinburne University of Technology, Hawthorn, VIC  3122, Australia; Fujian Provincial Key Laboratory of Network Security and Cryptology, School of Mathematics and Computer Science, Fujian Normal University, Fuzhou, China; State Key Laboratory of Integrated Service Networks, Xidian University, Xi'an, China; King Saud University, Riyadh, 11543, Saudi Arabia","Zhang, Y., School of Software and Electrical Engineering, Swinburne University of Technology, Hawthorn, VIC  3122, Australia; Xiang, Y., School of Software and Electrical Engineering, Swinburne University of Technology, Hawthorn, VIC  3122, Australia, State Key Laboratory of Integrated Service Networks, Xidian University, Xi'an, China; Huang, X., Fujian Provincial Key Laboratory of Network Security and Cryptology, School of Mathematics and Computer Science, Fujian Normal University, Fuzhou, China, State Key Laboratory of Integrated Service Networks, Xidian University, Xi'an, China; Chen, X., State Key Laboratory of Integrated Service Networks, Xidian University, Xi'an, China; Alelaiwi, A., King Saud University, Riyadh, 11543, Saudi Arabia","Wireless communications in smart homes are vulnerable to many adversarial attacks such as eavesdropping. To secure the communications, secret session keys need to be established between home appliances. In existing symmetric key establishment protocols, it is assumed that devices are pre-loaded with secrets. In practice, however, home appliances are manufactured by different companies. As a result, it is not a practical assumption that the appliances are pre-loaded with certain secrets when they leave companies. Motivated by these observations, this paper presents a matrix-based cross-layer key establishment protocol without the secret sharing assumption. Specifically, in our protocol, home appliances extract master keys (shared with the home gateway) at the physical layer using the wireless fading channels. Then, the home gateway distributes key seeds for home appliances by making use of the extracted master keys. Completing these operations, any two appliances can directly establish a secret session key at higher layers. Additionally, we prove the security of the proposed protocol and analyse the performance of it by comparing the new protocol with other closely related protocols. The comparison shows that appliances in our protocol can establish secret session keys when they do not pre-share any secrets, and it is achieved without introducing significant energy consumptions. © 2017 Elsevier Inc.","Cross-layer; Internet of things; Key establishment; Matrix; Security; Smart homes","Automation; Domestic appliances; Energy utilization; Equipment; Fading channels; Intelligent buildings; Internet of things; Matrix algebra; Network layers; Wireless telecommunication systems; Cross layer; Key establishment protocol; Key establishments; Physical layers; Security; Smart homes; Wireless communications; Wireless fading channels; Gateways (computer networks)",,,,,"Alam, M.R., Reaz, M.B.I., Ali, M.A.M., A review of smart homes - past, present, and future (2012) IEEE Trans. Syst. Man, Cybern. Part C, 42 (6), pp. 1190-1203; Bertino, E., Choo, K.R., Georgakopoulos, D., Nepal, S., Internet of things (IoT): smart and secure service delivery (2016) ACM Trans. Internet Technol., 16 (4), pp. 221-227; Blom, R., An optimal class of symmetric key generation systems (1984) Advances in Cryptology: Proceedings of EUROCRYPT 84, A Workshop on the Theory and Application of Cryptographic Techniques, Paris, France, April 9–11, 1984, Proceedings, Lecture Notes in Computer Science, 209, pp. 335-338. , T. Beth N. Cot I. Ingemarsson Springer; Cahyani, N.D.W., Martini, B., Choo, K.R., Al-Azhar, A.M.N., Forensic data acquisition from cloud-of-things devices: windows smartphones as a case study (2017) Concurrency Comput., 29 (14); Choo, K.R., Refuting security proofs for tripartite key exchange with model checker in planning problem setting (2006) 19th IEEE Computer Security Foundations Workshop, (CSFW-19 2006), 5–7 July 2006, Venice, Italy, pp. 297-308. , IEEE Computer Society; Choo, K.R., Secure Key Establishment (2009) Advances in Information Security, 41. , Springer; Choo, K.R., Boyd, C., Hitchcock, Y., Examining indistinguishability-based proof models for key establishment protocols (2005) Advances in Cryptology - ASIACRYPT 2005, 11th International Conference on the Theory and Application of Cryptology and Information Security, Chennai, India, December 4–8, 2005, Proceedings, Lecture Notes in Computer Science, 3788, pp. 585-604. , B.K. Roy Springer; Choo, K.R., Boyd, C., Hitchcock, Y., The importance of proofs of security for key establishment protocols: formal analysis of Jan–Chen, Yang–Shen–Shieh, Kim–Huh–Hwang–Lee, Lin–Sun–Hwang, and Yeh–Sun protocols (2006) Comput. Commun., 29 (15), pp. 2788-2797; Choo, K.R., Nam, J., Won, D., A mechanical approach to derive identity-based protocols from Diffie–Hellman-based protocols (2014) Inf. Sci., 281, pp. 182-200; Du, W., Deng, J., Han, Y.S., Varshney, P.K., A pairwise key pre-distribution scheme for wireless sensor networks (2003) Proceedings of the 10th ACM Conference on Computer and Communications Security, CCS 2003, Washington, DC, USA, October 27–30, 2003, pp. 42-51. , S. Jajodia V. Atluri T. Jaeger ACM; Du, W., Deng, J., Han, Y.S., Varshney, P.K., A key predistribution scheme for sensor networks using deployment knowledge (2006) IEEE Trans. Dependable Secure Comput., 3 (1), pp. 62-77; Du, W., Deng, J., Han, Y.S., Varshney, P.K., Katz, J., Khalili, A., A pairwise key predistribution scheme for wireless sensor networks (2005) ACM Trans. Inf. Syst. Secur., 8 (2), pp. 228-258; He, X., Yener, A., The role of feedback in two-way secure communications (2013) IEEE Trans. Inf. Theory, 59 (12), pp. 8115-8130; Jana, S., Premnath, S.N., Clark, M., Kasera, S.K., Patwari, N., Krishnamurthy, S.V., On the effectiveness of secret key extraction from wireless signal strength in real environments (2009) Proceedings of the 15th Annual International Conference on Mobile Computing and Networking, MOBICOM 2009, Beijing, China, September 20–25, 2009, pp. 321-332. , K.G. Shin Y. Zhang R. Bagrodia R. Govindan ACM; Kumar, P., Gurtov, A., Iinatti, J., Ylianttila, M., Sain, M., Lightweight and secure session-key establishment scheme in smart home environments (2016) IEEE Sens. J., 16 (1), pp. 254-264; Li, X., Niu, J., Kumari, S., Wu, F., Choo, K.-K.R., A robust biometrics based three-factor authentication scheme for global mobility networks in smart city (2017) Future Gener. Comput. Syst.; Luo, S., Wu, J., Li, J., Guo, L., A multi-stage attack mitigation mechanism for software-defined home networks (2016) IEEE Trans. Consum. Electron., 62 (2), pp. 200-207; Mathur, S., Trappe, W., Mandayam, N.B., Ye, C., Reznik, A., Radio-telepathy: extracting a secret key from an unauthenticated wireless channel (2008) Proceedings of the 14th Annual International Conference on Mobile Computing and Networking, MOBICOM 2008, San Francisco, California, USA, September 14–19, 2008, pp. 128-139. , J.J. Garcia-Luna-Aceves R. Sivakumar P. Steenkiste ACM; Nam, J., Choo, K.R., Han, S., Kim, M., Paik, J., Won, D., Efficient and anonymous two-factor user authentication in wireless sensor networks: achieving user anonymity with lightweight sensor computation (2015) PLoS ONE, 10 (4), p. e0116709; Palanisamy, S., Kumar, S.S., Narayanan, J.L., Secured wireless communication for industrial automation and control (2011) Electronics Computer Technology (ICECT), 2011 3rd International Conference on, 5, pp. 168-171. , IEEE; Parakh, A., Kak, S., Matrix based key agreement algorithms for sensor networks (2011) 2011 Fifth IEEE International Conference on Advanced Telecommunication Systems and Networks (ANTS), pp. 1-3; Perera, C., Ranjan, R., Wang, L., Khan, S.U., Zomaya, A.Y., Big data privacy in the internet of things era (2015) IT Prof., 17 (3), pp. 32-39; Pishva, D., Takeda, K., Product-based security model for smart home appliances (2008) IEEE Aerosp. Electron. Syst. Mag., 23 (10), pp. 32-41; Premnath, S.N., Jana, S., Croft, J., Gowda, P.L., Clark, M., Kasera, S.K., Patwari, N., Krishnamurthy, S.V., Secret key extraction from wireless signal strength in real environments (2013) IEEE Trans. Mobile Comput., 12 (5), pp. 917-930; Robles, R.J., hoon Kim, T., A review on security in smart home development (2010) Int. J. Adv. Sci. Technol., 15; Shannon, C.E., Communication theory of secrecy systems (1949) Bell Syst. Tech.J., 28 (4), pp. 656-715; Shimizu, T., Iwai, H., Sasaoka, H., Physical-layer secret key agreement in two-way wireless relaying systems (2011) IEEE Trans. Inf. Forensics Secur., 6 (3-1), pp. 650-660; Volner, R., Bores, P., Smrz, V., A product based security model for smart home appliances (2008) 2008 11th International Biennial Baltic Electronics Conference, pp. 221-222. , IEEE; Wang, Q., Su, H., Ren, K., Kim, K., Fast and scalable secret key generation exploiting channel phase randomness in wireless networks (2011) INFOCOM 2011. 30th IEEE International Conference on Computer Communications, Joint Conference of the IEEE Computer and Communications Societies, 10–15 April 2011, Shanghai, China, pp. 1422-1430. , IEEE; Wang, Q., Xu, K., Ren, K., Cooperative secret key generation from phase estimation in narrowband fading channels (2012) IEEE J. Sel. Areas Commun., 30 (9), pp. 1666-1674; Wu, C., Liao, C., Fu, L., Service-oriented smart-home architecture based on OSGi and mobile-agent technology (2007) IEEE Trans. Syst. Man, Cybern. Part C, 37 (2), pp. 193-205; Xu, L., Zhang, Y., Matrix-based pairwise key establishment for wireless mesh networks (2014) Future Gener. Comput. Syst., 30, pp. 140-145; Zan, B., Gruteser, M., Hu, F., Key agreement algorithms for vehicular communication networks based on reciprocity and diversity theorems (2013) IEEE Trans. Veh. Technol., 62 (8), pp. 4020-4027; Zeng, K., Wu, D., Chan, A.J., Mohapatra, P., Exploiting multiple-antenna diversity for shared secret key generation in wireless networks (2010) INFOCOM 2010. 29th IEEE International Conference on Computer Communications, Joint Conference of the IEEE Computer and Communications Societies, 15–19 March 2010, San Diego, CA, USA, pp. 1837-1845. , IEEE; Zhang, Y., Xu, L., Huang, X., Li, J., Matrix-based pairwise key establishment with pre and post deployment knowledge for wireless mesh networks (2013) Seventh International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing, IMIS 2013, Taichung, Taiwan, July 3–5, 2013, pp. 153-158. , L. Barolli I. You F. Xhafa F. Leu H. Chen IEEE Computer Society; Zhang, Y., Xu, L., Huang, X., Li, J., Matrix-based key pre-distribution schemes in WMNs using pre and post deployment knowledge (2015) Int. J. Ad Hoc Ubiquitous Comput., 20 (4), pp. 262-273; Zhang, Y., Xu, L., Xiang, Y., Huang, X., Matrix-based pairwise key establishment in wireless mesh networks using deployment knowledge (2013) Proceedings of IEEE International Conference on Communications, ICC 2013, Budapest, Hungary, June 9–13, 2013, pp. 1604-1608. , IEEE; Zhang, Y., Xu, L., Xiang, Y., Huang, X., A matrix-based pairwise key establishment scheme for wireless mesh networks using pre deployment knowledge (2013) IEEE Trans. Emerg. Top. Comput., 1 (2), pp. 331-340","Huang, X.; Fujian Provincial Key Laboratory of Network Security and Cryptology, China; email: xyhuang@fjnu.edu.cn",,,"Elsevier Inc.",,,,,00200255,,ISIJB,,"English","Inf Sci",Article,"Final","",Scopus,2-s2.0-85034867320
"Khreich W., Murtaza S.S., Hamou-Lhadj A., Talhi C.","35097304600;14056661100;24314702300;9275987500;","Combining heterogeneous anomaly detectors for improved software security",2018,"Journal of Systems and Software","137",,,"415","429",,12,"10.1016/j.jss.2017.02.050","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015698998&doi=10.1016%2fj.jss.2017.02.050&partnerID=40&md5=e5f241a92e9ae27c5b555c7c413959fc","Software Behaviour Analysis (SBA) Research Lab, Department of Electrical and Computer Engineering, Concordia University, Montreal, Canada; Department of Software Engineering and Information Technology, École de technologie supérieure, Montreal, Canada","Khreich, W., Software Behaviour Analysis (SBA) Research Lab, Department of Electrical and Computer Engineering, Concordia University, Montreal, Canada; Murtaza, S.S., Software Behaviour Analysis (SBA) Research Lab, Department of Electrical and Computer Engineering, Concordia University, Montreal, Canada; Hamou-Lhadj, A., Software Behaviour Analysis (SBA) Research Lab, Department of Electrical and Computer Engineering, Concordia University, Montreal, Canada; Talhi, C., Department of Software Engineering and Information Technology, École de technologie supérieure, Montreal, Canada","Host-based Anomaly Detection Systems (ADSs) monitor for significant deviations from normal software behavior. Several techniques have been investigated for detecting anomalies in system call sequences. Among these, Sequence Time-Delay Embedding (STIDE), Hidden Markov Model (HMM), and One-Class Support Vector Machine (OCSVM) have shown a high level of anomaly detection accuracy. Although ADSs can detect novel attacks, they generate a large number of false alarms due to the difficulty in obtaining complete descriptions of normal software behavior. This paper presents a multiple-detector ADS that efficiently combines the decisions from heterogeneous detectors (e.g., STIDE, HMM, and OCSVM), using Boolean combination in the Receiver Operating Characteristics (ROC) space, to reduce the false alarms. Results on two modern and large system call datasets generated from Linux and Windows operating systems show that the proposed ADS consistently outperforms an ADS based on a single best detector and on an ensemble of homogeneous detectors. At an operating point of zero percent alarm rate, the proposed multiple-detector ADS increased the true positive rate by 500% on the Linux dataset and by 25% on the Window dataset. Furthermore, the combinations of decisions from multiple heterogeneous detectors make the ADS more reliable and resilient against evasion and adversarial attacks. © 2017","Anomaly detection systems; Decision-level combination; Heterogeneous and reliable systems; Intrusion detection systems","Alarm systems; Computer operating systems; Deceleration; Errors; Hidden Markov models; Linux; Markov processes; Time delay; Windows operating system; Anomaly detection systems; Decision levels; Intrusion Detection Systems; Number of false alarms; One-class support vector machines (OCSVM); Receiver operating characteristics; Reliable systems; System-call sequence; Intrusion detection",,,,,"Baum, L.E., Petrie, G.S., Weiss, N., A maximization technique occuring in the statistical analysis of probabilistic functions of Markov chains (1970) Ann. Math. Stat., 41 (1), pp. 164-171; Bhatkar, S., Chaturvedi, A., Sekar, R., Dataflow anomaly detection (2006) IEEE Symposium on Security and Privacy; Canali, D., Lanzi, A., Balzarotti, D., Kruegel, C., Christodorescu, M., Kirda, E., A quantitative study of accuracy in system call-based malware detection (2012) Proceedings of the 2012 International Symposium on Software Testing and Analysis, ISSTA 2012, pp. 122-132. , ACM New York, NY, USA; Canzanese, R., Mancoridis, S., Kam, M., System call-based detection of malicious processes (2015) 2015 IEEE International Conference on Software Quality, Reliability and Security (QRS), pp. 119-124; Chen, S., Xu, J., Sezer, E.C., Gauriar, P., Iyer, R.K., Non-control-data attacks are realistic threats (2005) USENIX Security Symposium, 14. , 12–12; Chen, W.-H., Hsu, S.-H., Shen, H.-P., Application of SVM and ANN for intrusion detection (2005) Comput. Oper. Res., 32 (10), pp. 2617-2634; Chen, Y.-S., Chen, Y.-M., Combining incremental Hidden Markov Model and Adaboost algorithm for anomaly intrusion detection (2009) CSI-KDD ’09: Proceedings of the ACM SIGKDD Workshop on CyberSecurity and Intelligence Informatics, pp. 3-9. , ACM New York, NY, USA; Corona, I., Giacinto, G., Roli, F., Adversarial attacks against intrusion detection systems: taxonomy, solutions and open issues (2013) Inf. Sci., 239, pp. 201-225; Creech, G., Hu, J., Generation of a new ids test dataset: time to retire the kdd collection (2013) Wireless Communications and Networking Conference (WCNC), 2013 IEEE, Shanghai, China, pp. 4487-4492; Creech, G., Hu, J., A semantic approach to host-based intrusion detection systems using contiguous and discontiguous system call patterns (2013) IEEE Trans. Comput., 99; Du, Y., Wang, H., Pang, Y., A Hidden Markov Models-based anomaly intrusion detection method (2004) Proceedings of the World Congress on Intelligent Control and Automation (WCICA), 5, pp. 4348-4351; Fawcett, T., ROC Graphs: Notes and Practical Considerations for Researchers (2004) Tech. Rep. HPL-2003-4, , HP Laboratories, Palo Alto, CA, USA; Fawcett, T., An introduction to ROC analysis (2006) Pattern Recognit. Lett., 27 (8), pp. 861-874; Feng, H., Kolesnikov, O., Fogla, P., Lee, W., Gong, W., Anomaly detection using call stack information (2003) IEEE Symposium on Security and Privacy, pp. 62-75; Feng, H.H., Giffin, J.T., Huang, Y., Jha, S., Lee, W., Miller, B.P., Formalizing sensitivity in static analysis for intrusion detection (2004) Security and Privacy, 2004. Proceedings. 2004 IEEE Symposium on, pp. 194-208. , IEEE; Forrest, S., Hofmeyr, S., Somayaji, A., The evolution of system-call monitoring (2008) Computer Security Applications Conference, 2008. ACSAC 2008. Annual, pp. 418-430; Forrest, S., Hofmeyr, S.A., Somayaji, A., Longstaff, T.A., A sense of self for Unix processes (1996) Proceedings of the 1996 IEEE Symposium on Research in Security and Privacy, pp. 120-128; Gao, B., Ma, H.-Y., Yang, Y.-H., HMMs (Hidden Markov Models) based on anomaly intrusion detection method (2002) Proceedings of 2002 International Conference on Machine Learning and Cybernetics, 1, pp. 381-385; Gao, D., Reiter, M.K., Song, D., Gray-box extraction of execution graphs for anomaly detection (2004) Proceedings of the 11th ACM Conference on Computer and Communications Security, pp. 318-329. , ACM; Gao, D., Reiter, M.K., Song, D., On gray-box program tracking for anomaly detection (2004) USENIX Security Symposium - Volume 13, SSYM'04, USENIX Association, Berkeley, CA, USA, pp. 1-8; Ghosh, A.K., Schwartzbard, A., Schatz, M., Learning program behavior profiles for intrusion detection (1999) Proceedings of the Workshop on Intrusion Detection and Network Monitoring, pp. 51-62. , USENIX Association Berkeley, CA, USA; Giacinto, G., Roli, F., Didaci, L., Fusion of multiple classifiers for intrusion detection in computer networks (2003) Pattern Recognit. Lett., 24 (12), pp. 1795-1803; Giffin, J.T., Jha, S., Miller, B.P., Detecting manipulated remote call streams (2002) USENIX Security Symposium, pp. 61-79; Giffin, J.T., Jha, S., Miller, B.P., Efficient context-sensitive intrusion detection (2004) Proceedings of the Network and Distributed System Security Symposium; Han, J., Yan, Q., Deng, R., Gao, D., On detection of erratic arguments (2012) Security and Privacy in Communication Networks, Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering, 96, pp. 172-189. , Rajarajan M. Piper F. Wang H. Kesidis G. Springer Berlin Heidelberg; Hoang, X., Hu, J., An efficient Hidden Markov Model training scheme for anomaly intrusion detection of server applications based on system calls (2004) IEEE Int'l Conference on Networks, ICON, Vol. 2, Singapore, pp. 470-474; Hofmeyr, S.A., Forrest, S., Somayaji, A., Intrusion detection using sequences of system calls (1998) J. Comput. Secur., 6 (3), pp. 151-180; Hsu, K.-W., Srivastava, J., Diversity in combinations of heterogeneous classifiers (2009) Adv. Knowl. Discov. Data Min., 5476, pp. 923-932; Hu, J., Host-based anomaly intrusion detection (2010) Handbook of Information and Communication Security, pp. 235-255. , Stavroulakis P. Stamp M. Springer Berlin Heidelberg; Huang, G.-B., Zhu, Q.-Y., Siew, C.-K., Extreme learning machine: theory and applications (2006) Neurocomputing, 70 (1-3), pp. 489-501; Huang, J., Ling, C.X., Using AUC and accuracy in evaluating learning algorithms (2005) IEEE Trans. Knowl. Data Eng., 17 (3), pp. 299-310; Jha, S., Tan, K., Maxion, R., Markov chains, classifiers, and intrusion detection (2001) Proceedings of the Computer Security Foundations Workshop, pp. 206-219; Kang, D.-K., Fuller, D., Honavar, V., Learning classifiers for misuse detection using a bag of system calls representation (2005) Lect. Notes Comput. Sci., 3495, pp. 511-516; Kayacik, H., Zincir-Heywood, A., Mimicry attacks demystified: what can attackers do to evade detection? (2008) Privacy, Security and Trust, 2008. PST 08. Sixth Annual Conference on, pp. 213-223; Khreich, W., Granger, E., Miri, A., Sabourin, R., Boolean combination of classifiers in the ROC space (2010) 20th International Conference on Pattern Recognition, Istanbul, Turkey, pp. 4299-4303; Khreich, W., Granger, E., Miri, A., Sabourin, R., A survey of techniques for incremental learning of HMM parameters (2012) Inf. Sci., 197, pp. 105-130; Khreich, W., Granger, E., Sabourin, R., Miri, A., Combining Hidden Markov Models for anomaly detection (2009) International Conference on Communications (ICC), Dresden, Germany, pp. 1-6; Kittler, J., Hatef, M., Duin, R.P.W., Matas, J., On combining classifiers (1998) IEEE Trans. Pattern Anal. Mach. Intell., 20 (3), pp. 226-239; Kruegel, C., Kirda, E., Mutz, D., Robertson, W., Vigna, G., Automating mimicry attacks using static binary analysis (2005) USENIX Security Symposium, Baltimore, MD, USA, pp. 161-176; Kruegel, C., Mutz, D., Robertson, W., Valeur, F., Bayesian event classification for intrusion detection (2003) 19th Annual Computer Security Applications Conference, ACSAC, , IEEE Computer Society Washington, DC, USA; Kruegel, C., Mutz, D., Valeur, F., Vigna, G., On the detection of anomalous system call arguments (2003) Computer Security – ESORICS 2003, Lecture Notes in Computer Science, 2808, pp. 326-343. , Snekkenes E. Gollmann D. Springer Berlin Heidelberg; Kuncheva, L., Skurichina, M., Duin, R., An experimental study on diversity for bagging and boosting with linear classifiers (2002) Inf. Fusion, 3, pp. 245-258; Lee, W., Xiang, D., Information-theoretic measures for anomaly detection (2001) Proceedings of the 2001 IEEE Symposium on Security and Privacy, pp. 130-143; Liao, Y., Vemuri, V.R., Use of k-nearest neighbor classifier for intrusion detection (2002) Comput. Secur., 21 (5), pp. 439-448; Maggi, F., Matteucci, M., Zanero, S., Detecting intrusions through system call sequence and argument analysis (2010) IEEE Trans. Dependable Secure Comput., 7 (4), pp. 381-395; Marceau, C., Characterizing the behavior of a program using multiple-length n-grams (2000) NSPW ’00: Proceedings of the 2000 Workshop on New Security Paradigms, pp. 101-110. , ACM Press New York, NY, USA; Michael, C.C., Ghosh, A., Simple, state-based approaches to program-based anomaly detection (2002) ACM Trans. Inf. Syst. Secur., 5, pp. 203-237; Murtaza, S.S., Khreich, W., Hamou-Lhadj, A., Couture, M., A host-based anomaly detection approach by representing system calls as states of kernel modules (2013) 24th IEEE International Symposium on, Software Reliability Engineering (ISSRE), Pasadena, CA, pp. 431-440; Murtaza, S.S., Khreich, W., Hamou-Lhadj, A., Gagnon, S., Couture, M., A trace abstraction approach for host-based anomaly detection (2015) CISDA 2015: Proceedings of the Second IEEE International Conference on Computational Intelligence for Security and Defense Applications, Verona, NY, USA, pp. 1-8; Mutz, D., Robertson, W., Vigna, G., Kemmerer, R., Exploiting execution context for the detection of anomalous system calls (2007) RAID, pp. 1-20. , Springer; Parampalli, C., Sekar, R., Johnson, R., A practical mimicry attack against powerful system-call monitors (2008) Proceedings of the 2008 ACM Symposium on Information, Computer and Communications Security, ASIACCS ’08, pp. 156-167. , ACM New York, NY, USA; Provos, N., Improving host security with system call policies (2003) USENIX Security, 3; Provost, F.J., Fawcett, T., Robust classification for imprecise environments (2001) Mach. Learn., 42 (3), pp. 203-231; Rabiner, L., A tutorial on Hidden Markov Models and selected applications in speech recognition (1989) Proc. IEEE, 77 (2), pp. 257-286; Salton, G., Automatic Text Processing: The Transformation, Analysis, and Retrieval of Information by Computer (1989), Addison-Wesley; Scott, M.J., Niranjan, M., Prager, R.W., Realisable classifiers: improving operating performance on variable cost problems (1998) BMVC, pp. 1-10; Sekar, R., Bendre, M., Dhurjati, D., Bollineni, P., A fast automaton-based method for detecting anomalous program behaviors (2001) IEEE Symposium on Security and Privacy, S&P., pp. 144-155; Soudi, A., Khreich, W., Hamou-Lhadj, A., An anomaly detection system based on ensemble of detectors with effective pruning techniques (2015) IEEE International Conference on Software Quality, Reliability and Security, Vancouver, Canada; Tan, K., Maxion, R., “Why 6?” Defining the operational limits of stide, an anomaly-based intrusion detector (2002) IEEE Symposium on Security and Privacy, pp. 188-201; Tan, K.M.C., Killourhy, K.S., Maxion, R.A., Undermining an anomaly-based intrusion detection system using common exploits (2002) RAID-2002. Lecture Notes in Computer Science, pp. 54-73. , Springer-Verlag Berlin 2516; Tandon, G., Chan, P.K., Learning rules from system call arguments and sequences for anomaly detection (2003) Proceedings of the 3rd IEEE International Conference on Data Mining (ICDM) Workshop on Data Mining for Computer Security (DMSEC), Melbourne, Florida, USA; Ulvila, J.W., Gaffney, J.E., Jr, Evaluation of intrusion detection systems (2003) J. Res. Natl. Inst. Stand. Technol., 108 (6), p. 453; Wagner, D., Dean, D., Intrusion detection via static analysis (2001) Proceedings of the 2001 IEEE Symposium on Security and Privacy, , IEEE Computer Society Washington, DC, USA; Wagner, D., Soto, P., Mimicry attacks on host-based intrusion detection systems (2002) CCS 02: Proceedings of the 9th ACM Conference on Computer and Communications Security, Washington, DC, United States, pp. 255-264; Wang, P., Shi, L., Wang, B., Wu, Y., Liu, Y., Survey on HMM based anomaly intrusion detection using system calls (2010) Computer Science and Education (ICCSE), pp. 102-105. , 2010 5th International Conference on; Wang, W., Guan, X.-H., Zhang, X.-L., Modeling program behaviors by Hidden Markov Models for intrusion detection (2004) Proceedings of 2004 International Conference on Machine Learning and Cybernetics, 5, pp. 2830-2835; Warrender, C., Forrest, S., Pearlmutter, B., Detecting intrusions using system calls: alternative data models (1999) Proceedings of the IEEE Computer Society Symposium on Research in Security and Privacy, Oakland, CA, USA, pp. 133-145; Yolacan, E.N., Dy, J.G., Kaeli, D.R., System call anomaly detection using multi-HMMs (2014) IEEE Eighth International Conference on Software Security and Reliability-Companion (SERE-C), pp. 25-30. , IEEE; Zhang, D.D., Zhou, X.-H., Freeman, D.H., Freeman, J.L., A non-parametric method for the comparison of partial areas under roc curves and its application to large health care data sets (2002) Stat. Med., 21 (5), pp. 701-715; Zhang, X., Fan, P., Zhu, Z., A new anomaly detection method based on hierarchical HMM (2003) Parallel and Distributed Computing, Applications and Technologies, 2003, pp. 249-252. , PDCAT'2003. Proceedings of the Fourth International Conference on","Khreich, W.; Software Behaviour Analysis (SBA) Research Lab, Montreal, Canada; email: wkhreich@ece.concordia.ca",,,"Elsevier Inc.",,,,,01641212,,JSSOD,,"English","J Syst Software",Article,"Final","",Scopus,2-s2.0-85015698998
"Rajivan P., Gonzalez C.","55220183600;36135410100;","Creative persuasion: A study on adversarial behaviors and strategies in phishing attacks",2018,"Frontiers in Psychology","9","FEB","135","","",,21,"10.3389/fpsyg.2018.00135","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042357578&doi=10.3389%2ffpsyg.2018.00135&partnerID=40&md5=c478b222483b59eebd0a65fa0f60be9b","Dynamic Decision Making Laboratory, Social and Decision Sciences, Carnegie Mellon University, Pittsburgh, PA, United States","Rajivan, P., Dynamic Decision Making Laboratory, Social and Decision Sciences, Carnegie Mellon University, Pittsburgh, PA, United States; Gonzalez, C., Dynamic Decision Making Laboratory, Social and Decision Sciences, Carnegie Mellon University, Pittsburgh, PA, United States","Success of phishing attacks depend on effective exploitation of human weaknesses. This research explores a largely ignored, but crucial aspect of phishing: the adversarial behavior. We aim at understanding human behaviors and strategies that adversaries use, and how these may determine the end-user response to phishing emails. We accomplish this through a novel experiment paradigm involving two phases. In the adversarial phase, 105 participants played the role of a phishing adversary who were incentivized to produce multiple phishing emails that would evade detection and persuade end-users to respond. In the end-user phase, 340 participants performed an email management task, where they examined and classified phishing emails generated by participants in phase-one along with benign emails. Participants in the adversary role, self-reported the strategies they employed in each email they created, and responded to a test of individual creativity. Data from both phases of the study was combined and analyzed, to measure the effect of adversarial behaviors on end-user response to phishing emails. We found that participants who persistently used specific attack strategies (e.g., sending notifications, use of authoritative tone, or expressing shared interest) in all their attempts were overall more successful, compared to others who explored different strategies in each attempt. We also found that strategies largely determined whether an end-user was more likely to respond to an email immediately, or delete it. Individual creativity was not a reliable predictor of adversarial performance, but it was a predictor of an adversary's ability to evade detection. In summary, the phishing example provided initially, the strategies used, and the participants' persistence with some of the strategies led to higher performance in persuading end-users to respond to phishing emails. These insights may be used to inform tools and training procedures to detect phishing strategies in emails. © 2018 Rajivan and Gonzalez.","Adversarial behavior; Creativity; Deception; Persuasion; Phishing; Simulation; Strategy",,,,,,"Abbasi, Y.D., Ben-Asher, N., Gonzalez, C., Kar, D., Morrison, D., Sintov, N., Know your adversary: insights for a better adversarial behavioral model (2016) Proceeding of the Conference of Cognitive Science Society, , (Philedalphia, PA); Almahendra, R., Ambos, B., Exploration and exploitation: a 20-year review of evolution and reconceptualisation (2015) Int. J. Innovat. Manag, 19, p. 1550008; Amabile, T.M., Hill, K.G., Hennessey, B.A., Tighe, E.M., The work preference inventory: assessing intrinsic and extrinsic motivational orientations (1994) J. Pers. Soc. Psychol, 66, p. 950; Anderson, R.J., (2010) Security Engineering: A Guide to Building Dependable Distributed Systems, , Hoboken, NJ: John Wiley & Sons; (2016) Phishing Activity Trends Report q1, , http://docs.apwg.org/reports/apwg_trends_report_q1_2016.pdf; Beaussart, M.L., Andrews, C.J., Kaufman, J.C., Creative liars: the relationship between creativity and integrity (2013) Think. Skills Creat, 9, pp. 129-134; Buhrmester, M., Kwang, T., Gosling, S.D., Amazon's mechanical turk: a new source of inexpensive, yet high-quality, data? (2011) Perspect. Psychol. Sci, 6, pp. 3-5; Cialdini, R.B., The science of persuasion (2004) Sci. Am. Mind, 14, pp. 70-77; Cropley, D.H., Cropley, A.J., (2013) Creativity and Crime: A Psychological Analysis, , Cambridge, UK: Cambridge University Press; Dhamija, R., Tygar, J.D., Hearst, M., Why phishing works (2006) Proceedings of the SIGCHI conference on Human Factors in computing systems, pp. 581-590. , (Montreal: ACM); Downs, J.S., Holbrook, M.B., Cranor, L.F., Decision strategies and susceptibility to phishing (2006) Proceedings of the second symposium on Usable privacy and security, pp. 79-90. , (Pittsburgh, PA: ACM); Felegyhazi, M., Kreibich, C., Paxson, V., On the potential of proactive domain blacklisting (2010) Proceedings of the Third USENIX Workshop on Large-scale Exploits and Emergent Threats, 6. , http://dl.acm.org/citation.cfm?id=1855686.1855692, (LEET) (San Jose, CA: USENIX Association); Ferreira, A., Coventry, L., Lenzini, G., Principles of persuasion in social engineering and their use in phishing (2015) International Conference on Human Aspects of Information Security, Privacy, and Trust, pp. 36-47. , (Los Angeles, CA: Springer); Ferreira, A., Lenzini, G., An analysis of social engineering principles in effective phishing (2015) Socio-Technical Aspects in Security and Trust, pp. 9-16. , (STAST) 2015 Workshop on (Verona: IEEE); Fielder, A., Panaousis, E., Malacaria, P., Hankin, C., Smeraldi, F., Decision support approaches for cyber security investment (2016) Decis. Support Syst, 86, pp. 13-23; Fischbacher, U., Föllmi-Heusi, F., Lies in disguise-an experimental study on cheating (2013) J. Eur. Econ. Assoc, 11, pp. 525-547; Flach, F., Disorders of the pathways involved in the creative process (1990) Creat. Res. J, 3, pp. 158-165; Forest, C., (2017) Phishing is the Easiest Way to Steal Sensitive Data, Hackers Say, , http://www.techrepublic.com/article/phishing-is-the-easiest-way-to-steal-sensitive-data-hackers-say/; Frederick, S., Loewenstein, G., O'Donoghue, T., Time discounting and time preference: a critical review (2002) J. Econ. Literat, 40, pp. 351-401; Gino, F., Ariely, D., The dark side of creativity: original thinkers can be more dishonest (2012) J. Pers. Soc. Psychol, 102, p. 445; Gino, F., Ayal, S., Ariely, D., Self-serving altruism?. the lure of unethical actions that benefit others (2013) J. Econ. Behav. Organ, 93, pp. 285-292; Gonzalez, C., Ben-Asher, N., Oltramari, A., Lebiere, C., Cognition and technology (2014) Cyber Defense and Situational Awareness, pp. 93-117. , eds A. Kott, C. Wang, and R. F. Erbacher (New York, NY: Springer); Grossklags, J., Christin, N., Chuang, J., Secure or insure?: a game-theoretic analysis of information security games (2008) Proceedings of the 17th international conference on World Wide Web, pp. 209-218. , (Florence: ACM); Harris, A., Yates, D., Phishing attacks over time: a longitudinal study (2015) Proceedings of the 2015 Information Systems Security, Assurance and Privacy, , (SIGSEC) (Angers: AIS Electronic Library); Hong, J., The state of phishing attacks (2012) Commun. ACM, 55, pp. 74-81; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I., Tygar, J., Adversarial machine learning (2011) Proceedings of the 4th ACM Workshop on Security and Artificial Intelligence, pp. 43-58. , (Chicago, IL: ACM); Jones, D.N., Paulhus, D.L., Introducing the short dark triad (sd3) a brief measure of dark personality traits (2014) Assessment, 21, pp. 28-41; Kahneman, D., Tversky, A., Prospect theory: an analysis of decision under risk (1979) Econometrica, 47, pp. 263-291; Kelley, T., Kelley, T., Bertenthal, B.I., Bertenthal, B.I., Attention and past behavior, not security knowledge, modulate users decisions to login to insecure websites (2016) Inform. Comput. Secur, 24, pp. 164-176; Kirby, K.N., Marakovic, N.N., Modeling myopic decisions: evidence for hyperbolic delay-discounting within subjects and amounts (1995) Organ. Behav. Hum. Decis. Process, 64, pp. 22-30; Krol, K., Spring, J.M., Parkin, S., Sasse, M.A., (2016) ""Towards robust experimental design for user studies in security and privacy,"", pp. 21-31. , https://www.usenix.org/conference/laser2016/program/presentation/krol, Learning from Authoritative Security Experiment Results (LASER) (San Jose, CA: USENIX); Lakhani, K.R., Wolf, R.G., (2005) Why Hackers Do What They Do: Understanding Motivation and Effort in Free/Open Source Software Projects, , https://ssrn.com/abstract=443040, (MIT Sloan Working Paper No. 4425-03). (September 2003); Lastdrager, E.E., Achieving a consensual definition of phishing based on a systematic review of the literature (2014) Crime Sci, 3, p. 9; Laureiro-Martínez, D., Brusoni, S., Canessa, N., Zollo, M., Understanding the exploration-exploitation dilemma: an fMRI study of attention control and decision-making performance (2015) Strat. Manag. J, 36, pp. 319-338; Liang, B., Su, M., You, W., Shi, W., Yang, G., Cracking classifiers for evasion: a case study on the google's phishing pages filter (2016) Proceedings of the 25th International Conference on World Wide Web, pp. 345-356. , (Montreal: International World Wide Web Conferences Steering Committee); Ma, J., Saul, L.K., Savage, S., Voelker, G.M., Beyond blacklists: learning to detect malicious web sites from suspicious urls (2009) Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 1245-1254. , (London, UK: ACM); Mazar, N., Amir, O., Ariely, D., The dishonesty of honest people: a theory of self-concept maintenance (2008) J. Market. Res, 45, pp. 633-644; Moore, T., The economics of cybersecurity: principles and policy options (2010) Int. J. Crit. Infrastruct. Protect, 3, pp. 103-117; Mumford, M.D., Connelly, M.S., Baughman, W.A., Marks, M.A., Creativity and problem solving: cognition, adaptability, and wisdom (1994) Roeper Rev, 16, pp. 241-246; Mumford, M.D., Gustafson, S.B., Creativity syndrome: integration, application, and innovation (1988) Psychol. Bull, 103, p. 27; Nazario, J., (2016) Phishing Corpus, , https://monkey.org/~jose/phishing/; Nikitina, S., Hackers as tricksters of the digital age: creativity in hacker culture (2012) J. Popul. Cult, 45, pp. 133-152; Parsons, K., McCormac, A., Pattinson, M., Butavicius, M., Jerram, C., The design of phishing studies: challenges for researchers (2015) Comput. Secur, 52, pp. 194-206; (2016) Enterprise Phishing Susceptibility and Resiliency Report, , https://phishme.com/2016-enterprise-phishing-susceptibility-report/; Rajivan, P., Moriano, P., Kelley, T., Camp, L.J., Factors in an end user security expertise instrument (2017) Inform. Comput. Secur, 25, pp. 190-205; Runco, M.A., Acar, S., Divergent thinking as an indicator of creative potential (2012) Creat. Res. J, 24, pp. 66-75; Schuetz, S., Lowry, P.B., Thatcher, J., Defending against spear-phishing: Motivating users through fear appeal manipulations (2016) Pacific Asia Conference on Information Systems, p. 74. , (Chiayi: AISel); Shalvi, S., De Dreu, C.K., Oxytocin promotes group-serving dishonesty (2014) Proc. Natl. Acad. Sci. U.S.A, 111, pp. 5503-5507; Shekokar, N.M., Shah, C., Mahajan, M., Rachh, S., An ideal approach for detection and prevention of phishing attacks (2015) Proc. Comput. Sci, 49, pp. 82-91; Sheng, S., Magnien, B., Kumaraguru, P., Acquisti, A., Cranor, L.F., Hong, J., Anti-phishing phil: the design and evaluation of a game that teaches people not to fall for phish (2007) Proceedings of the 3rd Symposium on Usable Privacy and Security, pp. 88-99. , (Pittsburgh, PA: ACM); Shetty, N., Schwartz, G., Felegyhazi, M., Walrand, J., Competitive cyber-insurance and internet security (2010) Economics of Information Security and Privacy, pp. 229-247. , eds T. Moore, D. Pym, and C. Ioannidis (Boston, MA: Springer); Steinmetz, K.F., Craft (y) ness (2015) Brit. J. Criminol, 55, pp. 125-145; Su, Z., Ahn, B.-R., Eom, K.-Y., Kang, M.-K., Kim, J.-P., Kim, M.-K., Plagiarism detection using the levenshtein distance and smith-waterman algorithm (2008) Innovative Computing Information and Control, 2008. ICICIC'08 3rd International Conference on, pp. 569-569. , (Dalian: IEEE); Vishwanath, A., Harrison, B., Ng, Y.J., Suspicion, cognition, and automaticity model of phishing susceptibility (2016) Commun. Res, , [Epub ahead of print]; Vishwanath, A., Herath, T., Chen, R., Wang, J., Rao, H.R., Why do people get phished? Testing individual differences in phishing vulnerability within an integrated, information processing model (2011) Decis. Supp. Syst, 51, pp. 576-586; (2017) Quarterly Threat Trends-Phishing Attacks Growing in Scale and Sophistication, , https://s3-us-west-1.amazonaws.com/webroot-cms-cdn/8415/0585/3084/Webroot_Quarterly_Threat_Trends_September_2017.pdf; (2016) State of the Phish, , https://info.wombatsecurity.com/state-of-the-phish; Wright, R.T., Jensen, M.L., Thatcher, J.B., Dinger, M., Marett, K., Research note-ifluence techniques in phishinng attacks: an examination of vulnerability and resistance (2014) Inform. Syst. Res, 25, pp. 385-400; Wu, W.-H., Cheng, W., Chiou, W.-B., Episodic future thinking about the ideal self induces lower discounting, leading to a decreased tendency toward cheating (2017) Front. Psychol, 8, p. 287; Zielinska, O.A., Welk, A.K., Mayhorn, C.B., Murphy-Hill, E., A temporal analysis of persuasion principles in phishing emails (2016) Proceedings of the Human Factors and Ergonomics Society Annual Meeting, 60, pp. 765-769. , (Los Angeles, CA: SAGE Publications); Zini, M., Fabbri, M., Moneglia, M., Panunzi, A., Plagiarism detection through multilevel text comparison (2006) Automated Production of Cross Media Content for Multi-Channel Distribution, 2006. AXMEDIS'06. Second International Conference on, pp. 181-185. , (Leeds, UK: IEEE)","Rajivan, P.; Dynamic Decision Making Laboratory, United States; email: prajivan@andrew.cmu.edu",,,"Frontiers Media S.A.",,,,,16641078,,,,"English","Front. Psychol.",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85042357578
[No author name available],[No author id available],"Proceedings of the Asia and South Pacific Design Automation Conference, ASP-DAC",2018,"Proceedings of the Asia and South Pacific Design Automation Conference, ASP-DAC","2018-January",,,"","",768,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045335296&partnerID=40&md5=829eb157262ef0c65d36d7ace5519f26",,"","The proceedings contain 136 papers. The topics discussed include: multi-device collaborative management through knowledge sharing; DI-SSD: desymmetrized interconnection architecture and dynamic timing calibration for solid-state drives; multi-level droplet routing in active-matrix based digital-microfluidic biochips; scheduling and shaping of complex task activations for mixed-criticality systems; power conversion efficiency-aware mapping of multithreaded applications on heterogeneous architectures: a comprehensive parameter tuning; polymorphic gate based ic watermarking techniques; a machine learning attack resistant multi-PUF design on FPGA; a high-throughput and energy-efficient RRAM-based convolutional neural network using data encoding and dynamic quantization; DRL-Cloud: deep reinforcement learning-based resource provisioning and task scheduling for cloud service providers; pairing of microring-based silicon photonic transceivers for tuning power optimization; Neu-NoC: a high-efficient interconnection network for accelerated neuromorphic systems; ReGAN: a pipelined ReRAM-based accelerator for generative adversarial networks; a deep reinforcement learning framework for optimizing fuel economy of hybrid electric vehicles; process variation and temperature aware adaptive scrubbing for retention failures in STT-MRAM; a channel-sharable built-in self-test scheme for multi-channel DRAMs; a practical split manufacturing framework for Trojan prevention via simultaneous wire lifting and cell insertion; and a comparative investigation of approximate attacks on logic encryptions.",,,,,,,,,,"ACM SIGDA;Cadence Design Systems, Inc.;et al.;IEEE Circuits and Systems Society (CAS);IEEE Council on Electronic Design Automation (CEDA);SK Hynix","Institute of Electrical and Electronics Engineers Inc.","23rd Asia and South Pacific Design Automation Conference, ASP-DAC 2018","22 January 2018 through 25 January 2018",,134754,,9781509006021,,,"English","Proc Asia South Pac Des Autom Conf",Conference Review,"Final","",Scopus,2-s2.0-85045335296
"Liu Q., Liu T., Liu Z., Wang Y., Jin Y., Wen W.","57202841899;57201036884;57193625500;36555062200;24471712200;55301112800;","Security analysis and enhancement of model compressed deep learning systems under adversarial attacks",2018,"Proceedings of the Asia and South Pacific Design Automation Conference, ASP-DAC","2018-January",,,"721","726",,24,"10.1109/ASPDAC.2018.8297407","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045331830&doi=10.1109%2fASPDAC.2018.8297407&partnerID=40&md5=fb1d7e077ec3c70b90f58fe440df339b","Florida International University, United States; Syracuse University, United States; University of Florida, United States","Liu, Q., Florida International University, United States; Liu, T., Florida International University, United States; Liu, Z., Florida International University, United States; Wang, Y., Syracuse University, United States; Jin, Y., University of Florida, United States; Wen, W., Florida International University, United States","Thanks to recent machine learning model innovation and computing hardware advancement, the state-of-the-art of Deep Neural Network (DNN) is presenting human-level performance for many complex intelligent tasks in real-world applications. However, it also introduces ever-increasing security concerns for those intelligent systems. For example, the emerging adversarial attacks indicate that even very small and often imperceptible adversarial input perturbations can easily mislead the cognitive function of deep learning systems (DLS). Existing DNN adversarial studies are narrowly performed on the ideal software-level DNN models with a focus on single uncertainty factor, i.e. input perturbations, however, the impact of DNN model reshaping on adversarial attacks, which is introduced by various hardware-favorable techniques such as hash-based weight compression during modern DNN hardware implementation, has never been discussed. In this work, we for the first time investigate the multi-factor adversarial attack problem in practical model optimized deep learning systems by jointly considering the DNN model-reshaping (e.g. HashNet based deep compression) and the input perturbations. We first augment adversarial example generating method dedicated to the compressed DNN models by incorporating the software-based approaches and mathematical modeled DNN reshaping. We then conduct a comprehensive robustness and vulnerability analysis of deep compressed DNN models under derived adversarial attacks. A defense technique named 'gradient inhibition' is further developed to ease the generating of adversarial examples thus to effectively mitigate adversarial attacks towards both software and hardware-oriented DNNs. Simulation results show that 'gradient inhibition' can decrease the average success rate of adversarial attacks from 87.99% to 4.77% (from 86.74% to 4.64%) on MNIST (CIFAR-10) benchmark with marginal accuracy degradation across various DNNs. © 2018 IEEE.",,"Cognitive systems; Computer aided design; Hardware; Intelligent systems; Cognitive functions; Hardware implementations; Human-level performance; Input perturbation; Machine learning models; Software and hardwares; Uncertainty factors; Vulnerability analysis; Deep neural networks",,,,,"Krizhevsky, A., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; https://cloudplatform.googleblog.com/2016/05/Google-supercharges-machine-leaming-tasks-with-custom-chip.html; https://research.fb.com/category/facebook-ai-research-fair/; https://www.microsoft.com/en-us/research/research-area/artificial-intelligence/; Ciresan, D.C., Flexible, high performance convolutional neural networks for image classification (2011) IJCAI Proceedings-Intemational Joint Conference on Artificial Intelligence, 22 (1), p. 1237. , Barcelona, Spain; Vanhoucke, V., Improving the speed of neural networks on cpus (2011) Proc. Deep Learning and Unsupervised Feature Learning NIPS Workshop, 1, p. 4; Farabet, C., Large-scale FPGA-based convolutional networks (2011) Scaling Up Machine Learning: Parallel and Distributed Approaches, pp. 399-419; https://www.perspectiveapi.com/; Jouppi, N.P., (2017) Datacenter Performance Analysis of a Tensor Processing Unit, , arXiv preprint arXiv; https://cloud.google.com/blog/big-data/2017/05/an-in-depth-look-at-googles-first-tensor-processing-unit-tpu; Ghahramani, Z., Probabilistic machine learning and artificial intelligence (2015) Nature, 521 (7553), p. 452; Barreno, M., The security of machine learning (2010) Machine Learning, 81 (2), pp. 121-148; Goodfellow, I.J., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint arXiv; Papemot, N., (2016) Practical Black-box Attacks Against Deep Learning Systems Using Adversarial Examples, , arXiv preprint arXiv; Papemot, N., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387. , IEEE; Fawzi, A., (2015) Analysis of Classifiers' Robustness to Adversarial Perturbations, , arXiv preprint arXiv; Gu, S., (2014) Towards Deep Neural Network Architectures Robust to Adversarial Examples, , arXiv preprint arXiv; Papemot, N., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Security and Privacy (SP), 2016 IEEE Symposium on, pp. 582-597. , IEEE; Chen, W., Compressing neural networks with the hashing trick (2015) International Conference on Machine Learning, pp. 2285-2294; Cao, Z., (2017) Hashnet: Deep Learning to Hash by Continuation, , arXiv preprint arXiv; Han, S., Learning both weights and connections for efficient neural network (2015) Advances in Neural Information Processing Systems, pp. 1135-1143; Han, S., (2015) Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding, , arXiv preprint arXiv; LeCun, Y., (1998) The Mnist Database of Handwritten Digits, , http://yarm.lecun.com/exdbTmnist/; Krizhevsky, A., (2009) Learning Multiple Layers of Features from Tiny Images; Hinton, G.E., Reducing the dimensionality o f data with neural networks (2006) Science, 313 (5786), pp. 504-507; Simonyan, K., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition, , arXiv preprint arXiv; Szegedy, C., Going deeper with convolutions (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9; Cheng, Y., An exploration of parameter redundancy in deep networks with circulant projections (2015) Proceedings of the IEEE International Conference on Computer Vision, pp. 2857-2865; Han, S., Eie: Efficient inference engine on compressed deep neural network (2016) Proceedings of the 43rd International Symposium on Computer Architecture, pp. 243-254. , IEEE Press; Weinberger, K., Feature hashing for large scale multitask learning (2009) Proceedings of the 26th Annual International Conference on Machine Learning, pp. 1113-1120. , ACM",,,"ACM SIGDA;Cadence Design Systems, Inc.;et al.;IEEE Circuits and Systems Society (CAS);IEEE Council on Electronic Design Automation (CEDA);SK Hynix","Institute of Electrical and Electronics Engineers Inc.","23rd Asia and South Pacific Design Automation Conference, ASP-DAC 2018","22 January 2018 through 25 January 2018",,134754,,9781509006021,,,"English","Proc Asia South Pac Des Autom Conf",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85045331830
"Akhtar N., Mian A.","56287450900;7006066881;","Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey",2018,"IEEE Access","6",,,"14410","14430",,558,"10.1109/ACCESS.2018.2807385","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042198914&doi=10.1109%2fACCESS.2018.2807385&partnerID=40&md5=e65018d514ae7456445cb31af0947b2d","Department of Computer Science and Software Engineering, University of Western Australia, Crawley, WA  6009, Australia","Akhtar, N., Department of Computer Science and Software Engineering, University of Western Australia, Crawley, WA  6009, Australia; Mian, A., Department of Computer Science and Software Engineering, University of Western Australia, Crawley, WA  6009, Australia","Deep learning is at the heart of the current rise of artificial intelligence. In the field of computer vision, it has become the workhorse for applications ranging from self-driving cars to surveillance and security. Whereas, deep neural networks have demonstrated phenomenal success (often beyond human capabilities) in solving complex problems, recent studies show that they are vulnerable to adversarial attacks in the form of subtle perturbations to inputs that lead a model to predict incorrect outputs. For images, such perturbations are often too small to be perceptible, yet they completely fool the deep learning models. Adversarial attacks pose a serious threat to the success of deep learning in practice. This fact has recently led to a large influx of contributions in this direction. This paper presents the first comprehensive survey on adversarial attacks on deep learning in computer vision. We review the works that design adversarial attacks, analyze the existence of such attacks and propose defenses against them. To emphasize that adversarial attacks are possible in practical conditions, we separately review the contributions that evaluate adversarial attacks in the real-world scenarios. Finally, drawing on the reviewed literature, we provide a broader outlook of this research direction. © 2018 IEEE.","adversarial learning; adversarial perturbation; black-box attack; Deep learning; perturbation detection; white-box attack","Artificial heart; Artificial intelligence; Computer vision; Deep neural networks; Human computer interaction; Job analysis; Learning systems; Neural networks; Perturbation techniques; Surveys; Adversarial learning; adversarial perturbation; Black boxes; Computational model; Perturbation detection; Perturbation method; Predictive models; Task analysis; White box; Deep learning",,,,,"LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), pp. 436-444; Helmstaedter, M., Briggman, K.L., Turaga, S.C., Jain, V., Seung, H.S., Denk, W., Connectomic reconstruction of the inner plexiform layer in the mouse retina (2013) Nature, 500 (7461), pp. 168-174; Xiong, H.Y., The human splicing code reveals new insights into the genetic determinants of disease (2015) Science, 347 (6218), p. 1254806; Ma, J., Sheridan, R.P., Liaw, A., Dahl, G.E., Svetnik, V., Deep neural nets as a method for quantitative structure-activity relationships (2015) J. Chem. Inf. Model., 55 (2), pp. 263-274; Ciodaro, T., Deva, D., De Seixas, J.M., Damazio, D., Online particle detection with neural networks based on topological calorimetry information (2012) J. Phys., Conf. Series., 368 (1), p. 012030; (2014) Higgs Boson Machine Learning Challenge., , https://www.kaggle.com/c/higgs-boson, [Online]; Hinton, G., Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups (2012) IEEE Signal Process. Mag., 29 (6), pp. 82-97. , Nov; Sutskever, I., Vinyals, O., Le, Q.V., Sequence to sequence learning with neural networks (2014) Proc, Adv. Neural Inf. Process. Syst., pp. 3104-3112; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Proc. Adv. Neural Inf. Process. Syst., pp. 1097-1105; LeCun, Y., Backpropagation applied to handwritten zip code recognition (1989) Neural Comput., 1 (4), pp. 541-551; Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L., ImageNet: A large-scale hierarchical image database (2009) Proc. IEEE Conf. Comput. Vis. Patt. Recognit., pp. 248-255. , Jun; Ackerman, E., How Drive.ai Is Mastering Autonomous Driving with Deep Learning., , https://spectrum.ieee.org/cars-that-think/transportation/self-driving/how-driveai-is-mastering-autonomous-driving-with-deep-learning, Accessed: Dec. 2017. [Online]; Najafabadi, M.M., Villanustre, F., Khoshgoftaar, T.M., Seliya, N., Wald, R., Muharemagic, E., Deep learning applications and challenges in big data analytics (2015) J. Big Data, 2 (1), pp. 1-21; Silver, D., Mastering the game of go without human knowledge (2017) Nature, 550 (7676), pp. 354-359; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 770-778. , Jun; Moosavi-Dezfooli, S.M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 86-94. , Jul; Chatfield, K., Simonyan, K., Vedaldi, A., Zisserman, A., (2014) Return of the Devil in the Details: Delving Deep into Convolutional Nets., , https://arxiv.org/abs/1405.3531, [Online]; Szegedy, C., Going deeper with convolutions (2015) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 1-9. , Jun; Lu, J., Sibai, H., Fabry, E., Forsyth, D., (2017) Standard Detectors Aren't (Currently) Fooled by Physical Adversarial Stop Signs, , https://arxiv.org/abs/1710.03337, [Online]; Fletcher, R., (2013) Practical Methods of Optimization., , Hoboken, NJ, USA; Wiley; Esteva, A., Dermatologist-level classification of skin cancer with deep neural networks (2017) Nature, 542 (7639), pp. 115-118; Szegedy, C., (2014) Intriguing Properties of Neural Networks., , https://arxiv.org/abs/1312.6199, [Online]; Goodfellow, I.J., Shlens, J., Szegedy, C., (2015) Explaining and Harnessing Adversarial Examples, , https://arxiv.org/abs/1412.6572, [Online]; Gu, S., Rigazio, L., (2015) Towards Deep Neural Network Architectures Robust to Adversarial Examples, , https://arxiv.org/abs/1412.5068, [Online]; Tabacof, P., Valle, E., Exploring the space of adversarial images (2016) Proc. IEEE Int. Joint Conf. Neural Netw., pp. 426-433. , Jul; Sabour, S., Cao, Y., Faghri, F., Fleet, D.J., (2015) Adversarial Manipulation of Deep Representations, , https://arxiv.org/abs/1511.05122s, [Online]; Shaham, U., Yamada, Y., Negahban, S., (2016) Understanding Adversarial Training: Increasing Local Stability of Neural Nets Through Robust Optimization, , https://arxiv.org/abs/1511.05432, [Online]; Lyu, C., Huang, K., Liang, H.-N., A unified gradient regularization family for adversarial examples (2015) Proc. IEEE Int. Conf. Data Mining, pp. 301-309. , Nov; Evtimov, I., (2017) Robust Physical-world Attacks on Deep Learning Models, , https://arxiv.org/abs/1707.08945, [Online]; Lu, J., Sibai, H., Fabry, E., Forsyth, D., (2017) No Need to Worry about Adversarial Examples in Object Detection in Autonomous Vehicles, , https://arxiv.org/abs/1707.03501, [Online]; Liu, Y., Zhang, W., Li, S., Yu, N., (2017) Enhanced Attacks on Defensively Distilled Deep Neural Networks, , https://arxiv.org/abs/1711.05934, [Online]; Hosseini, H., Chen, Y., Kannan, S., Zhang, B., Poovendran, R., (2017) Blocking Transferability of Adversarial Examples in Black-box Learning Systems, , https://arxiv.org/abs/1703.04318, [Online]; Gu, T., Dolan-Gavitt, B., Garg, S., (2017) BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain, , https://arxiv.org/abs/1708.06733, [Online]; Papernot, N., McDaniel, P., Sinha, A., Wellman, M., (2016) Towards the Science of Security and Privacy in Machine Learning, , https://arxiv.org/abs/1611.03814, [Online]; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , https://arxiv.org/abs/1607.02533, [Online]; Carlini, N., Wagner, D., (2016) Towards Evaluating the Robustness of Neural Networks, , https://arxiv.org/abs/1608.04644, [Online]; Das, N., (2017) Keeping the Bad Guys Out: Protecting and Vaccinating Deep Learning with JPEG Compression, , https://arxiv.org/abs/1705.02900, [Online]; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Proc. IEEE Symp. Secur. Privacy (SP), pp. 582-597. , May; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proc. ACM Asia Conf. Comput. Commun. Secur., pp. 506-519; Xu, X., Chen, X., Liu, C., Rohrbach, A., Darell, T., Song, D., (2017) Can You Fool AI with Adversarial Examples on a Visual Turing Test?, , https://arxiv.org/abs/1709.08693, [Online]; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., ZOO: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) Proc. 10th ACMWorkshop Artif. Intell. Secur. (AISEC), pp. 15-26; Baluja, S., Fischer, I., (2017) Adversarial Transformation Networks: Learning to Generate Adversarial Examples, , https://arxiv.org/abs/1703.09387, [Online]; Xu, W., Evans, D., Qi, Y., (2017) Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks., , https://arxiv.org/abs/1704.01155, [Online]; Nguyen, L., Wang, S., Sinha, A., (2017) A Learning and Masking Approach to Secure Learning, , https://arxiv.org/abs/1709.04447, [Online]; Meng, D., Chen, H., MagNet: A two-pronged defense against adversarial examples (2017) Proc. ACM Conf. Comput. Commun. Secur. (CCS), pp. 135-147; Zantedeschi, V., Nicolae, M.-I., Rawat, A., (2017) Efficient Defenses Against Adversarial Attacks, , https://arxiv.org/abs/1707.06728, [Online]; Hayes, J., Danezis, G., (2017) Machine Learning As An Adversarial Service: Learning Black-box Adversarial Examples, , https://arxiv.org/abs/1708.05207, [Online]; Graese, A., Rozsa, A., Boult, T.E., Assessing threat of adversarial examples on deep neural networks (2016) Proc. IEEE Int. Conf. Mach. Learn. Appl., pp. 69-74. , Dec; Carlini, N., Wagner, D., (2017) Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods, , https://arxiv.org/abs/1705.07263, [Online]; Liang, B., Li, H., Su, M., Li, X., Shi, W., Wang, X., (2017) Detecting Adversarial Examples in Deep Networks with Adaptive Noise Reduction', , https://arxiv.org/abs/1705.08378, [Online]; Arnab, A., Miksik, O., Torr, P.H.S., (2017) On the Robustness of Semantic Segmentation Models to Adversarial Attacks, , https://arxiv.org/abs/1711.09856, [Online]; Ross, A.S., Doshi-Velez, F., (2017) Improving the Adversarial Robustness and Interpretability of Deep Neural Networks by Regularizing Their Input Gradients, , https://arxiv.org/abs/1711.09404, [Online]; Song, Y., Kim, T., Nowozin, S., Ermon, S., Kushman, N., (2017) PixelDefend: Leveraging Generative Models to Understand and Defend Against Adversarial Examples, , https://arxiv.org/abs/1710.10766, [Online]; Narodytska, N., Kasiviswanathan, S.P., (2016) Simple Blackbox Adversarial Perturbations for Deep Networks, , https://arxiv.org/abs/1612.06299, [Online]; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , https://arxiv.org/abs/1706.06083, [Online]; Sun, Z., Ozay, M., Okatani, T., (2017) HyperNetworks with Statistical Filtering for Defending Adversarial Examples, , https://arxiv.org/abs/1711.01791, [Online]; Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., (2017) On the (Statistical) Detection of Adversarial Examples, , https://arxiv.org/abs/1702.06280, [Online]; Shen, S., Jin, G., Gao, K., Zhang, Y., (2017) APE-GAN: Adversarial Perturbation Elimination with GAN, , https://arxiv.org/abs/1707.05474, [Online]; Carlini, N., Katz, G., Barrett, C., Dill, D.L., (2017) Groundtruth Adversarial Examples, , https://arxiv.org/abs/1709.10207, [Online]; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Proc. IEEE Eur. Symp. Secur. Privacy, pp. 372-387. , Mar; Grosse, K., Papernot, N., Manoharan, P., Backes, M., McDaniel, P., (2016) Adversarial Perturbations Against Deep Neural Networks for Malware Classification, , https://arxiv.org/abs/1606.04435, [Online]; Huang, S., Papernot, N., Goodfellow, I., Duan, Y., Abbeel, P., (2017) Adversarial Attacks on Neural Network Policies, , https://arxiv.org/abs/1702.02284, [Online]; Melis, M., Demontis, A., Biggio, B., Brown, G., Fumera, G., Roli, F., (2017) Is Deep Learning Safe for Robot Vision? Adversarial Examples Against the ICub Humanoid, , https://arxiv.org/abs/1708.06939, [Online]; Rosenberg, I., Shabtai, A., Rokach, L., Elovici, Y., (2017) Generic Black-box End-to-end Attack Against State of the Art API Call Based Malware Classifiers, , https://arxiv.org/abs/1707.05970, [Online]; Athalye, A., Engstrom, L., Ilyas, A., Kwok, K., (2017) Synthesizing Robust Adversarial Examples, , https://arxiv.org/abs/1707.07397, [Online]; Lu, J., Issaranon, T., Forsyth, D., (2017) SafetyNet: Detecting and Rejecting Adversarial Examples Robustly, , https://arxiv.org/abs/1704.00103, [Online]; Metzen, J.H., Kumar, M.C., Brox, T., Fischer, V., Universal adversarial perturbations against semantic image segmentation (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 2755-2764. , Oct; Su, J., Vargas, D.V., Kouichi, S., (2017) One Pixel Attack for Fooling Deep Neural Networks, , https://arxiv.org/abs/1710.08864, [Online]; Fawzi, A., Moosavi-Dezfooli, S., Frossard, P., Robustness of classifiers: From adversarial to random noise (2016) Proc. Adv. Neural Inf. Process. Syst., pp. 1632-1640; Moosavi-Dezfooli, S., Fawzi, A., Fawzi, O., Frossard, P., Soatto, S., (2017) Analysis of Universal Adversarial Perturbations., , https://arxiv.org/abs/1705.09554, [Online]; Fawzi, A., Fawzi, O., Frossard, P., (2015) Analysis of Classifiers' Robustness to Adversarial Perturbations., , https://arxiv.org/abs/1502.02590, [Online]; Moosavi-Dezfooli, S., Fawzi, A., Frossard, P., DeepFool: A simple and accurate method to fool deep neural networks (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 2574-2582. , Jun; Kanbak, C., Moosavi-Dezfooli, S.-M., Frossard, P., (2017) Geometric Robustness of Deep Networks: Analysis and Improvement., , https://arxiv.org/abs/1711.09115, [Online]; Tanay, T., Griffin, L., (2016) A Boundary Tilting Persepective on the Phenomenon of Adversarial Examples., , https://arxiv.org/abs/1608.07690, [Online]; Evtimov, I., (2017) Robust Physical-world Attacks on Deep Learning Models., , https://arxiv.org/abs/1707.08945, [Online]; He, W., Wei, J., Chen, X., Carlini, N., Song, D., (2017) Adversarial Example Defenses: Ensembles of Weak Defenses Are Not Strong., , https://arxiv.org/abs/1706.04701, [Online]; Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses., , https://arxiv.org/abs/1705.07204, [Online]; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., (2017) On Detecting Adversarial Perturbations., , https://arxiv.org/abs/1702.04267, [Online]; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., (2017) Mitigating Adversarial Effects Through Randomization., , https://arxiv.org/abs/1711.01991, [Online]; Kurakin, A., Goodfellow, I., Bengio, S., (2017) Adversarial Machine Learning at Scale., , https://arxiv.org/abs/1611.01236, [Online]; Akhtar, N., Liu, J., Mian, A., (2017) Defense Against Universal Adversarial Perturbations., , https://arxiv.org/abs/1711.05929, [Online]; Guo, C., Rana, M., Cisse, M., Van der Maaten, L., (2017) Countering Adversarial Images Using Input Transformations., , https://arxiv.org/abs/1711.00117, [Online]; Galloway, A., Taylor, G.W., Moussa, M., (2017) Attacking Binarized Neural Networks., , https://arxiv.org/abs/1711.00449, [Online]; Papernot, N., McDaniel, P., (2017) Extending Defensive Distillation., , https://arxiv.org/abs/1705.05264, [Online]; Na, T., Ko, J.H., Mukhopadhyay, S., (2017) Cascade Adversarial Machine Learning Regularized with a Unified Embedding., , https://arxiv.org/abs/1708.02582, [Online]; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts., , https://arxiv.org/abs/1703.00410, [Online]; Zeng, X., (2017) Adversarial Attacks beyond the Image Space., , https://arxiv.org/abs/1711.07183, [Online]; Liu, Y., Chen, X., Liu, C., Song, D., (2017) Delving into Transferable Adversarial Examples and Black-box Attacks., , https://arxiv.org/abs/1611.02770, [Online]; Strauss, T., Hanselmann, M., Junginger, A., Ulmer, H., (2017) Ensemble Methods As a Defense to Adversarial Perturbations Against Deep Neural Networks., , https://arxiv.org/abs/1709.03423, [Online]; Sankaranarayanan, S., Jain, A., Chellappa, R., Lim, S.N., (2017) Regularizing Deep Networks Using Efficient Layerwise Adversarial Training., , https://arxiv.org/abs/1705.07819, [Online]; Cubuk, E.D., Zoph, B., Schoenholz, S.S., Le, Q.V., (2017) Intriguing Properties of Adversarial Examples., , https://arxiv.org/abs/1711.02846, [Online]; Gebhart, T., Schrater, P., (2017) Adversary Detection in Neural Networks Via Persistent Homology., , https://arxiv.org/abs/1711.10056, [Online]; Bradshaw, J., Matthews, A.G.D.G., Ghahramani, Z., (2017) Adversarial Examples, Uncertainty, and Transfer Testing Robustness in Gaussian Process Hybrid Deep Networks., , https://arxiv.org/abs/1707.02476, [Online]; Rozsa, A., Rudd, E.M., Boult, T.E., (2016) Adversarial Diversity and Hard Positive Generation., , https://arxiv.org/abs/1605.01775, [Online]; Bastani, O., Ioannou, Y., Lampropoulos, L., Vytiniotis, D., Nori, A., Criminisi, A., (2017) Measuring Neural Net Robustness with Constraints., , https://arxiv.org/abs/1605.07262, [Online]; Kolter, J.Z., Wong, E., (2017) Provable Defenses Against Adversarial Examples Via the Convex Outer Adversarial Polytope., , https://arxiv.org/abs/1711.00851, [Online]; Rozsa, A., Günther, M., Boult, T.E., Are accuracy and robustness correlated (2016) Proc. IEEE Int. Conf. Mach. Learn. Appl., pp. 227-232. , Dec; Hosseini, H., Xiao, B., Jaiswal, M., Poovendran, R., (2017) On the Limitation of Convolutional Neural Networks in Recognizing Negative Images., , https://arxiv.org/abs/1703.06857, [Online]; Cisse, M., Bojanowski, P., Grave, E., Dauphin, Y., Usunier, N., (2017) Parseval Networks: Improving Robustness to Adversarial Examples., , https://arxiv.org/abs/1704.08847, [Online]; Cheney, N., Schrimpf, M., Kreiman, G., (2017) On the Robustness of Convolutional Neural Networks to Internal Architecture and Weight Perturbations., , https://arxiv.org/abs/1703.08245, [Online]; Lee, H., Han, S., Lee, J., (2017) Generative Adversarial Trainer: Defense to Adversarial Perturbations with GAN., , https://arxiv.org/abs/1705.03387, [Online]; Rozsa, A., Gunther, M., Boult, T.E., (2017) Towards Robust Deep Neural Networks with BANG., , https://arxiv.org/abs/1612.00138, [Online]; Miyato, T., Maeda, S.-I., Koyama, M., Ishii, S., (2017) Virtual Adversarial Training: A Regularization Method for Supervised and Semisupervised Learning., , https://arxiv.org/abs/1704.03976, [Online]; Arpit, D., (2017) A Closer Look at Memorization in Deep Networks., , https://arxiv.org/abs/1706.05394, [Online]; Li, X., Li, F., Adversarial examples detection in deep networks with convolutional filter statistics (2017) Proc. Int. Conf. Comput. Vis., pp. 1-9; Lee, T., Choi, M., Yoon, S., (2016) Manifold Regularized Deep Neural Networks Using Adversarial Examples., , https://arxiv.org/abs/1511.06381, [Online]; Grosse, K., Papernot, N., Manoharan, P., Backes, M., McDaniel, P., Adversarial examples for malware detection (2017) Proc. Eur. Symp. Res. Comput. Secur., pp. 62-79; Papernot, N., McDaniel, P., (2016) On the Effectiveness of Defensive Distillation., , https://arxiv.org/abs/1607.05113, [Online]; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples., , https://arxiv.org/abs/1605.07277, [Online]; Papernot, N., McDaniel, P., Swami, A., Harang, R., Crafting adversarial input sequences for recurrent neural networks (2016) Proc. IEEE Military Commun. Conf., pp. 49-54; Papernot, N., (2016) Cleverhans v2.0.0: An Adversarial Machine Learning Library., , https://arxiv.org/abs/1610.00768, [Online]; Goodfellow, I., (2016) Cleverhans v2.0.0: An Adversarial Machine Learning Library., , https://arxiv.org/abs/1610.00768, [Online]; Miyato, T., Dai, A.M., Goodfellow, I., (2016) Adversarial Training Methods for Semi-supervised Text Classification., , https://arxiv.org/abs/1605.07725, [Online]; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 427-436; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., (2017) Adversarial Examples for Semantic Segmentation and Object Detection., , https://arxiv.org/abs/1703.08603, [Online]; Zheng, S., Song, Y., Leung, T., Goodfellow, I., Improving the robustness of deep neural networks via stability training (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 4480-4488. , Jun; Fawzi, A., Fawzi, O., Frossard, P., Fundamental limits on adversarial robustness (2015) Proc. ICML, Workshop Deep Learn., pp. 1-7; Luo, Y., Boix, X., Roig, G., Poggio, T., Zhao, Q., (2015) Foveationbased Mechanisms Alleviate Adversarial Examples., , https://arxiv.org/abs/1511.06292, [Online]; Jin, J., Dundar, A., Culurciello, E., (2015) Robust Convolutional Neural Networks under Adversarial Noise., , https://arxiv.org/abs/1511.06306, [Online]; Kos, J., Fischer, I., Song, D., (2017) Adversarial Examples for Generative Models., , https://arxiv.org/abs/1702.06832, [Online]; Wang, Q., (2016) Adversary Resistant Deep Neural Networks with An Application to Malware Detection., , https://arxiv.org/abs/1610.01239, [Online]; Dziugaite, G.K., Ghahramani, Z., Roy, D.M., (2016) A Study of the Effect of JPG Compression on Adversarial Images., , https://arxiv.org/abs/1608.00853, [Online]; Nayebi, A., Ganguli, S., (2017) Biologically Inspired Protection of Deep Networks from Adversarial Attacks., , https://arxiv.org/abs/1703.09202, [Online]; Hu, W., Tan, Y., (2017) Generating Adversarial Malware Examples for Black-box Attacks Based on GAN., , https://arxiv.org/abs/1702.05983, [Online]; Katz, G., Barrett, C., Dill, D.L., Julian, K., Kochenderfer, M.J., (2017) Towards Proving the Adversarial Robustness of Deep Neural Networks., , https://arxiv.org/abs/1709.02802, [Online]; Krotov, D., Hopfield, J.J., (2017) Dense Associative Memory Is Robust to Adversarial Inputs., , https://arxiv.org/abs/1701.00939, [Online]; Tabacof, P., Tavares, J., Valle, E., (2016) Adversarial Images for Variational Autoencoders., , https://arxiv.org/abs/1612.00155, [Online]; Wang, Q., (2016) Using Non-invertible Data Transformations to Build Adversarial-robust Neural Networks., , https://arxiv.org/abs/1610.01934, [Online]; Rozsa, A., Günther, M., Rudd, E.M., Boult, T.E., (2018) Facial Attributes: Accuracy and Adversarial Robustness., , https://arxiv.org/abs/1801.02480, [Online]; Cisse, M., Adi, Y., Neverova, N., Keshet, J., (2017) Houdini: Fooling Deep Structured Prediction Models., , https://arxiv.org/abs/1707.05373, [Online]; Tramèr, F., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2017) The Space of Transferable Adversarial Examples., , https://arxiv.org/abs/1704.03453, [Online]; Oh, S.J., Fritz, M., Schiele, B., (2017) Adversarial Image Perturbation for Privacy Protection-A Game Theory Perspective., , https://arxiv.org/abs/1703.09471, [Online]; Lin, Y.-C., Hong, Z.-W., Liao, Y.-H., Shih, M.-L., Liu, M.-Y., Sun, M., (2017) Tactics of Adversarial Attack on Deep Reinforcement Learning Agents., , https://arxiv.org/abs/1703.06748, [Online]; Mopuri, K.R., Garg, U., Babu, R.V., (2017) Fast Feature Fool: A Data Independent Approach to Universal Adversarial Perturbations., , https://arxiv.org/abs/1707.05572, [Online]; Kardan, N., Stanley, K.O., Mitigating fooling with competitive overcomplete output layer neural networks (2017) Proc. Int. Joint Conf. Neural Netw., pp. 518-525. , May; Dong, Y., Su, H., Zhu, J., Bao, F., (2017) Towards Interpretable Deep Neural Networks by Leveraging Adversarial Examples., , https://arxiv.org/abs/1708.05493, [Online]; Wang, Q., (2016) Learning Adversary-resistant Deep Neural Networks., , https://arxiv.org/abs/1612.01401, [Online]; Gao, J., Wang, B., Lin, Z., Xu, W., Qi, Y., (2017) DeepCloak: Masking Deep Neural Network Models for Robustness Against Adversarial Samples., , https://arxiv.org/abs/1702.06763, [Online]; Xu, W., Evans, D., Qi, Y., (2017) Feature Squeezing Mitigates and Detects Carlini/Wagner Adversarial Examples., , https://arxiv.org/abs/1705.10686, [Online]; Bai, W., Quan, C., Luo, Z., Alleviating adversarial attacks via convolutional autoencoder (2017) Proc. Int. Conf. Softw. Eng., Artif. Intell., Netw. Parallel/Distrib. Comput. (SNPD), pp. 53-58. , Jun; Norton, A.P., Qi, Y., Adversarial-Playground: A visualization suite showing how adversarial examples fool deep learning (2017) Proc. IEEE Symp. Vis. Cyber Secur., pp. 1-4. , Oct; Dong, Y., Liao, F., Pang, T., Hu, X., Zhu, J., (2017) Discovering Adversarial Examples with Momentum., , https://arxiv.org/abs/1710.06081, [Online]; Shen, S., Furuta, R., Yamasaki, T., Aizawa, K., Fooling neural networks in face attractiveness evaluation: Adversarial examples with high attractiveness score but lowsubjective score (2017) Proc. IEEE 3rd Int. Conf. Multimedia Big Data, pp. 66-69. , Apr; Szegedy, C., Vincent, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 2818-2826. , Jun; Sarkar, S., Bansal, A., Mahbub, U., Chellappa, R., (2017) UPSET and ANGRI: Breaking High Performance Image Classifiers., , https://arxiv.org/abs/1707.01159, [Online]; Das, S., Suganthan, P.N., Differential evolution: A survey of the state-of-the-art (2011) IEEE Trans. Evol. Comput., 15 (1), pp. 4-31. , Feb; Redmon, J., Farhadi, A., (2016) YOLO9000: Better, Faster, Stronger., , https://arxiv.org/abs/1612.08242, [Online]; Ren, S., He, K., Girshick, R., Sun, J., Faster R-CNN: Towards real-time object detection with region proposal networks (2015) Proc. Adv. Neural Inf. Process. Syst., pp. 91-99; Amodei, D., (2015) Deep Speech 2: End-to-end Speech Recognition in English and Mandarin., , https://arxiv.org/abs/1512.02595, [Online]; Krizhevsky, A., (2009) Learning Multiple Layers of Features from Tiny Images, , M.S. thesis, Dept. Comput. Sci., Univ. Toronto, Toronto, ON, Canada; Kingma, D.P., Welling, M., (2013) Auto-encoding Variational Bayes., , https://arxiv.org/abs/1312.6114, [Online]; Bengio, Y., Learning deep architectures for AI (2009) Found. Trends Mach. Learn., 2 (1), pp. 1-127; Rumelhart, D.E., Hinton, G.E., Williams, R.J., Learning representations by back-propagating errors (1986) Nature, 323, pp. 533-536. , Oct; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput., 9 (8), pp. 1735-1780; Mnih, V., Human-level control through deep reinforcement learning (2015) Nature, 518, pp. 529-533; Volodymyr, M., Asynchronous methods for deep reinforcement learning (2016) Proc. Int. Conf. Mach. Learn., pp. 1-10; Long, J., Shelhamer, E., Darrell, T., Fully convolutional networks for semantic segmentation (2015) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 3431-3440. , Jun; Rozsa, A., Günther, M., Rudd, E.M., Boult, T.E., Are facial attributes adversarially robust? (2016) Proc. Int. Conf. Pattern Recognit., pp. 3121-3127. , Dec; Liu, Z., Luo, P., Wang, X., Tang, X., Deep learning face attributes in the wild (2015) Proc. Int. Conf. Comput. Vis., pp. 3730-3738; Mirjalili, V., Ross, A., Soft biometric privacy: Retaining biometric utility of face images while perturbing gender (2017) Proc. Int. Joint Conf. Biometrics, pp. 1-10; Simonyan, K., Zisserman, A., (2015) Very Deep Convolutional Networks for Large-scale Image Recognition., , https://arxiv.org/abs/1409.1556, [Online]; Krotov, D., Hopfield, J.J., Dense associative memory for pattern recognition (2016) Proc. Adv. Neural Inf. Process. Syst., pp. 1172-1180; Hahnloser, R.H.R., Sarpeshkar, R., Mahowald, M.A., Douglas, R.J., Seung, H.S., Digital selection and analogue amplification coexist in a cortex-inspired silicon circuit (2000) Nature, 405 (6789), pp. 947-951. , Jun; Hinton, G., Vinyals, O., Dean, J., (2014) Distilling the Knowledge in a Neural Network., , https://arxiv.org/abs/1503.02531, [Online]; Drucker, H., Le Cun, Y., Improving generalization performance using double backpropagation (1992) IEEE Trans. Neural Netw., 3 (6), pp. 991-997. , Nov; Huang, G., Liu, Z., Van der Maaten, L., Weinberger, K.Q., (2016) Densely Connected Convolutional Networks., , https://arxiv.org/abs/1608.06993, [Online]; Bhagoji, A.N., Cullina, D., Sitawarin, C., Mittal, P., (2017) Enhancing Robustness of Machine Learning Systems Via Data Transformations., , https://arxiv.org/abs/1704.02654, [Online]; Dong, Y., (2017) Boosting Adversarial Attacks with Momentum., , https://arxiv.org/abs/1710.06081, [Online]; Goodfellow, I., Generative adversarial nets (2014) Proc. Adv. Neural Inf. Process. Syst., pp. 2672-2680; Kovačević, J., Amina, C., An introduction to frames (2008) Found. Trends Signal Process., 2 (1), pp. 1-94; Rifai, S., Vincent, P., Muller, X., Glorot, X., Bengio, Y., Contractive auto-encoders: Explicit invariance during feature extraction (2011) Proc. Int. Conf. Mach. Learn., pp. 833-840; Liew, S.S., Khalil-Hani, M., Bakhteri, R., Bounded activation functions for enhanced training stability of deep neural networks on visual pattern recognition problems (2016) Neurocomputing, 216, pp. 718-734. , Dec; Abbasi, M., Gagné, C., (2017) Robustness to Adversarial Examples Through An Ensemble of Specialists., , https://arxiv.org/abs/1702.06856, [Online]; Mogelmose, A., Trivedi, M.M., Moeslund, T.B., Vision-based traffic sign detection and analysis for intelligent driver assistance systems: Perspectives and survey (2012) IEEE Trans. Intell. Transp. Syst., 13 (4), pp. 1484-1497. , Dec; Vedaldi, A., Lenc, K., MatConvNet-Convolutional neural networks for MATLAB (2015) Proc. ACM Int. Conf. Multimedia, pp. 689-692; Jia, Y., (2014) Caffe: Convolutional Architecture for Fast Feature Embedding., , https://arxiv.org/abs/1408.5093, [Online]; Abadi, M., (2015) TensorFlow: Large-scale Machine Learning on Heterogeneous Distributed Systems., , https://arxiv.org/abs/1603.04467, [Online]; Giusti, A., A machine learning approach to visual perception of forest trails for mobile robots (2016) IEEE Robot. Autom. Lett., 1 (2), pp. 661-667. , Jul; Objects Detection Machine Learning TensorFlow Demo., , https://play.google.com/store/apps/details?id=org.tensorflow.detect&hl=en, Accessed: Dec. 2017. [Online]; Class Central, Deep Learning for Self-Driving Cars., , https://www.class-central.com/mooc/8132/6-s094-deep-learning-for-self-driving-cars, Accessed: Dec. 2017. [Online]; Middlehurst, C., (2015) China Unveils World's First Facial Recognition ATM., , http://www.telegraph.co.uk/news/worldnews/asia/china/11643314/China-unveils-worlds-first-facialrecognitionATM.html, [Online]; About Face ID Advanced Technology., , https://support.apple.com/en-au/HT208108, Accessed: Dec. 2017. [Online]; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proc. ACM SIGSAC Conf. Comput. Commun. Secur., pp. 1528-1540; Shin, R., Song, D., JPEG-resistant adversarial images (2017) Proc. Mach. Learn. Comput. Secur. Workshop, pp. 1-6; Brendel, W., Bethge, M., (2017) Comment on Biologically Inspired Protection of Deep Networks from Adversarial Attacks, , https://arxiv.org/abs/1704.01547, Apr. [Online]; Carlini, N., Wagner, D., (2017) MagNet and 'Efficient Defenses Against Adversarial Attacks' Are Not Robust to Adversarial Examples, , https://arxiv.org/abs/1711.08478, (Nov.) [Online]","Akhtar, N.; Department of Computer Science and Software Engineering, Australia; email: naveed.akhtar@uwa.edu.au",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Review,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85042198914
"Li Z., Xiao Z., Zhu Y., Pattarachanyakul I., Zhao B.Y., Zheng H.","57202877017;57200006971;56872024200;57202496543;7403058954;7403440632;","Adversarial localization against wireless cameras",2018,"HotMobile 2018 - Proceedings of the 19th International Workshop on Mobile Computing Systems and Applications","2018-February",,,"87","92",,11,"10.1145/3177102.3177106","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048546072&doi=10.1145%2f3177102.3177106&partnerID=40&md5=62cf3b4c3af4fb7a62bb93b6720ac851","UC Santa Barbara, United States; University of Chicago, United States","Li, Z., UC Santa Barbara, United States; Xiao, Z., University of Chicago, United States; Zhu, Y., UC Santa Barbara, United States; Pattarachanyakul, I., UC Santa Barbara, United States; Zhao, B.Y., University of Chicago, United States; Zheng, H., University of Chicago, United States","This paper identifies and empirically evaluates the effectiveness of adversarial localization attacks against wireless IoT devices, e.g., wireless security cameras in the home. We use experiments in home and office settings to show that attackers can accurately pinpoint the location of WiFi cameras, using a small amount of stealthy, passive, exterior measurements coupled with unsupervised learning techniques. We also show that current defenses have minimal impact against these attacks, and are also easily circumvented via countermeasures. Thus significant work is needed to develop robust defenses against these attacks. © 2018 Association for Computing Machinery.",,"Mobile computing; Iot devices; Wireless cameras; Wireless security; Cameras",,,,,"(2013) Burglars Confess: Why Your Home Is A Target, , http://www.alarm.org/HomeSafety/BurglarsSpillAboutSecuritySystems.aspx; (2016) MinimizeBlindSpots, , http://www.vivint.com/neighborhood/tech-neighbor/minimize-blind-spots-for-your-security-camera-system/; (2016) Security Camera Blind Spots: How to Find and Avoid Them, , https://reolink.com/find-and-avoid-security-camera-blind-spots/; Anjum, F., Pandey, S., Agrawal, P., Secure localization in sensor networks using transmission range variation (2005) Proc. of MASS; Bahl, P., Padmanabhan, V.N., RADAR: An in-building RF-based user location and tracking system (2000) Proc. of INFOCOM; Bauer, K., The directional attack on wireless localization (2009) Proc. of GLOBECOM; Bloessl, B., Segata, M., Sommer, C., Dressler, F., An IEEE 802.11 a/g/p OFDM receiver for GNU radio (2013) SRIF; Chan, J., Zheng, C., Zhou, X., 3d printing your wireless coverage (2015) Proc. of HotWireless.; Chintalapudi, K., Iyer, A.P., Padmanabhan, V.N., Indoor localization without the pain (2010) Proc. of MobiCom.; Dutta, N., Saxena, A., Chellappan, S., Defending wireless sensor networks against adversarial localization (2010) Proc. of MDM; El-Badry, R., Sultan, A., Youssef, M., Hyberloc: Providing physical layer location privacy in hybrid sensor networks (2010) Proc. of ICC; Jiang, T., Wang, H.J., Hu, Y., Preserving location privacy in wireless LANs (2007) Proc. of MobiSys.; Kamat, P., Zhang, Y., Trappe, W., Ozturk, C., Enhancing source-location privacy in sensor network routing (2005) Proc. of ICDCS; Kim, Y.S., Tague, P., Lee, H., Kim, H., Carving secure Wi-Fi zones with defensive jamming (2012) Proc. of Asia CCS; Kotaru, M., Joshi, K., Bharadia, D., Katti, S., Spotfi: Decimeter level localization using wifi (2015) Proc. of SIGCOMM; Lee, J.H., Buehrer, R.M., Location estimation using differential RSS with spatially correlated shadowing (2009) Proc. of GLOBECOM; Li, L., Experiencing and handling the diversity in data density and environmental locality in an indoor positioning service (2014) Proc. of MobiCom.; Li, X., Chen, Y., Yang, J., Zheng, X., Designing localization algorithms robust to signal strength attacks (2011) Proc. of INFOCOM; Li, Z., Nika, A., Zhang, X., Zhu, Y., Yao, Y., Zhao, B., Zheng, H., Identifying value in crowdsourced wireless signal measurements (2017) Proc. of WWW; Mariakakis, A.T., Sen, S., Lee, J., Kim, K., Sail: Single access point-based indoor localization (2014) Proc. of MobiSys.; Martin, J., (2017) A Study of MAC Address Randomization in Mobile Devices and When It Fails, , arXiv preprint (2017); Mehta, K., Liu, D., Wright, M., Protecting location privacy in sensor networks against a global eavesdropper (2012) IEEE Transactions on Mobile Computing, 11, p. 2. , 2012; Oh, S., Vu, T., Gruteser, M., Banerjee, S., Phantom: Physical layer cooperation for location privacy protection (2012) Proc. of INFOCOM; Qiao, Y., PhyCloak: Obfuscating sensing from communication signals (2016) Proc. of NSDI; Sanders, C., (2011) Practical Packet Analysis: Using Wireshark to Solve Real-World Network Problems, , Starch Press; Shekhar, S., Chawla, S., Spatial databases: A tour (2003) Introduction to Spatial Data Mining, , Pearson; Siby, S., Maiti, R.R., Tippenhauer, N.O., IoTScanner: Detecting privacy threats in IoT neighborhoods (2017) IoTPTS; Wang, J., Lifs: Low human-effort, device-free localization with fine-grained subcarrier information (2016) Proc. of MobiCom.; Wang, T., Yang, Y., Location privacy protection from RSS localization system using antenna pattern synthesis (2011) Proc. of INFOCOM; Xi, Y., Schwiebert, L., Shi, W., Preserving source location privacy in monitoring-based wireless sensor networks (2006) Proc. of IPDPS; Xiong, J., Jamieson, K., ArrayTrack: A fine-grained indoor location system (2013) Proc. of NSDI; Youssef, M., Pinpoint: An asynchronous time-based location determination system (2006) Proc. of MobiCom.",,,"ACM SIGMOBILE","Association for Computing Machinery, Inc","19th International Workshop on Mobile Computing Systems and Applications, HotMobile 2018","12 February 2018 through 13 February 2018",,134487,,9781450356305,,,"English","HotMobile - Proc. Int. Workshop Mob. Comput. Syst. Appl.",Conference Paper,"Final","",Scopus,2-s2.0-85048546072
[No author name available],[No author id available],"2017 10th International Conference on Contemporary Computing, IC3 2017",2018,"2017 10th International Conference on Contemporary Computing, IC3 2017","2018-January",,,"","",470,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046858367&partnerID=40&md5=451de24b101c6dcd24bb32de6c109983",,"","The proceedings contain 77 papers. The topics discussed include: no-escape search: design and implementation of cloud based directory content search; a study on the minimum dominating set problem approximation in parallel; an efficient algorithm for sampling of a single large graph; biometric identifier based on hand and hand-written signature contour information; adversarial attacks on computer vision algorithms using natural perturbations; analyzing fault prediction usefulness from cost perspective using source code metrics; image based search engine using deep learning; fixed and dynamic threshold selection criteria in energy detection for cognitive radio communication systems; neural network with multiple training methods for web service quality of service parameter prediction; are tweets the real estimators of election results?; fault tolerant streaming of live news using multi-node Cassandra; authorship attribution for textual data on online social networks; CPLAG: efficient plagiarism detection using bit-wise operations; secure live virtual machine migration through runtime monitors; deep sequential model for review rating prediction; a frequent itemset reduction algorithm for global pattern mining on distributed data streams; and cryptographic key generation from multimodal template using fuzzy extractor.",,,,,,,,,"Prasad S.Patel P.Xia Y.Sureka A.Ucar B.Kothapalli K.Govindaraju M.Goel S.Halappanavar M.Madduri K.Saxena V.Alum S.Kalyanararnan A.Barnas M.","","Institute of Electrical and Electronics Engineers Inc.","10th International Conference on Contemporary Computing, IC3 2017","10 August 2017 through 12 August 2017",,134614,,9781538630778,,,"English","Int. Conf. Contemp. Comput., IC3",Conference Review,"Final","",Scopus,2-s2.0-85046858367
"Ramanathan A., Pullum L., Husein Z., Raj S., Torosdagli N., Pattanaik S., Jha S.K.","57204334274;7004505147;57170698400;57194457254;57170785500;7003680065;57218716753;","Adversarial attacks on computer vision algorithms using natural perturbations",2018,"2017 10th International Conference on Contemporary Computing, IC3 2017","2018-January",,,"1","6",,4,"10.1109/IC3.2017.8284294","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046363473&doi=10.1109%2fIC3.2017.8284294&partnerID=40&md5=cc5a88da48dea621d30d48995bc5b931","Computational Science and Engineering Division, Oak Ridge National Laboratory, Oak Ridge, TN, United States; Computer Science Department, University of Central Florida, 4000 Central Florida Blvd, Orlando, FL, United States","Ramanathan, A., Computational Science and Engineering Division, Oak Ridge National Laboratory, Oak Ridge, TN, United States; Pullum, L., Computational Science and Engineering Division, Oak Ridge National Laboratory, Oak Ridge, TN, United States; Husein, Z., Computer Science Department, University of Central Florida, 4000 Central Florida Blvd, Orlando, FL, United States; Raj, S., Computer Science Department, University of Central Florida, 4000 Central Florida Blvd, Orlando, FL, United States; Torosdagli, N., Computer Science Department, University of Central Florida, 4000 Central Florida Blvd, Orlando, FL, United States; Pattanaik, S., Computer Science Department, University of Central Florida, 4000 Central Florida Blvd, Orlando, FL, United States; Jha, S.K., Computer Science Department, University of Central Florida, 4000 Central Florida Blvd, Orlando, FL, United States","Verifying the correctness of intelligent embedded systems is notoriously difficult due to the use of machine learning algorithms that cannot provide guarantees of deterministic correctness. In this paper, our validation efforts demonstrate that the OpenCV Histogram of Oriented Gradients (HOG) implementation for human detection is susceptible to errors due to both malicious perturbations and naturally occurring fog phenomena. To the best of our knowledge, we are the first to explicitly employ a natural perturbation (like fog) as an adversarial attack using methods from computer graphics. Our experimental results show that computer vision algorithms are susceptible to errors under a small set of naturally occurring perturbations even if they are robust to a majority of such perturbations. Our methods and results may be of interest to the designers, developers and validation teams of intelligent cyber-physical systems such as autonomous cars. © 2017 IEEE.",,"Computer graphics; Embedded systems; Learning algorithms; Learning systems; Autonomous car; Computer vision algorithms; Histogram of oriented gradients (HOG); Human detection; Natural perturbations; Naturally occurring; Computer vision",,,,,"Thrun, S., Toward robotic cars (2010) Communications of the ACM, 53 (4), pp. 99-106; Mack, C., The multiple lives of moore's law (2015) IEEE Spectrum, 52 (4), p. 31; Markov, I.L., Limits on fundamental limits to computation (2014) Nature, 512 (7513), pp. 147-154; Dalal, N., Triggs, B., Histograms of oriented gradients for human detection Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on, 1 (2005), pp. 886-893. , IEEE; Bradski, G., Kaebler, A., (2008) Computer Vision with the Opencv Library; Hwang, C.-R., Simulated annealing: Theory and applications (1988) Acta Applicandae Mathematicae, 12 (1), pp. 108-111; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint arXiv: 1412, 6572; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 427-436. , IEEE; Ramanathan, A., Pullum, L.L., Hussain, F., Chakrabarty, D., Jha, S.K., Integrating symbolic and statistical methods for testing intelligent systems: Applications to machine learning and computer vision (2016) 2016 Design, Automation & Test in Europe Conference & Exhibition (DATE), pp. 786-791. , IEEE; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint arXiv:1607 02533; Pacula, M., (2011) Unit-testing Statistical Software, , http://blog.mpacula.com/2011/02/17/unit-testing-statistical-software/, February [Online]; Grosse, R.B., Duvenaud, D.K., (2014) Testing Mcmc Code, , arXiv preprint arXiv:1412,5218; Ball, T., Cook, B., Levin, V., Rajamani, S.K., Slam and static driver verifier: Technology transfer of formal methods inside microsoft (2004) International Conference on Integrated Formal Methods, pp. 1-20. , Springer; Fix, L., Fifteen years of formal property verification in intel (2008) 25 Years of Model Checking, pp. 139-144. , Springer; Kaivola, R., Ghughal, R., Narasimhan, N., Telfer, A., Whittemore, J., Pandav, S., Slobodová, A., Reeber, E., Replacing testing with formal verification in intel coretm i7 processor execution engine validation (2009) International Conference on Computer Aided Verification, pp. 414-429. , Springer; Klein, G., Elphinstone, K., Heiser, G., Andronick, J., Cock, D., Derrin, P., Elkaduwe, D., Norrish, M., Sel4: Formal verification of an os kernel (2009) Proceedings of the ACM SIGOPS 22nd Symposium on Operating Systems Principles. ACM, pp. 207-220; Gupta, A., Formal hardware verification methods: A survey (1993) Computer-Aided Verification, pp. 5-92. , Springer; Clarke, E.M., Grumberg, O., Peled, D., (1999) Model Checking, , MIT press; Kwiatkowska, M., Norman, G., Parker, D., Stochastic model checking (2007) Formal Methods for Performance Evaluation, pp. 220-270. , Springer; Burch, J.R., Clarke, E.M., McMillan, K.L., Dill, D.L., Hwang, L.-J., Symbolic model checking: 10 20 states and beyond Logic in Computer Science 1990. LICS'90, Proceedings., Fifth Annual IEEE Symposium on E. IEEE, 1990, pp. 428-439; Legay, A., Delahaye, B., Bensalem, S., Statistical model checking: An overview (2010) Runtime Verification, pp. 122-135. , Springer; Kirkpatrick, S., Optimization by simulated annealing: Quantitative stud-ies (1984) Journal of Statistical Physics, 34 (5-6), pp. 975-986; Aarts, E., Korst, J., Michiels, W., Simulated annealing (2014) Search Methodologies, pp. 265-285. , Springer; Aarts, E., Korst, J., (1988) Simulated Annealing and Boltzmann Machines; Mantiuk, R., Kim, K.J., Rempel, A.G., Heidrich, W., Hdr-vdp-2: A calibrated visual metric for visibility and quality predictions in all luminance conditions (2011) ACM Transactions on Graphics (TOG), 30 (4), p. 40. , ACM; Perlin, K., An image synthesizer (1985) SIGGRAPH Comput. Graph, 19 (3), pp. 287-296. , http://doi.acm.org/10.1145/325165.325247, Jul [Online]; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., (2016) Practical Black-box Attacks Against Deep Learning Systems Using Adversarial Examples, , ArXiv Preprint ArXiv: 1602 02697",,"Prasad S.Patel P.Xia Y.Sureka A.Ucar B.Kothapalli K.Govindaraju M.Goel S.Halappanavar M.Madduri K.Saxena V.Alum S.Kalyanararnan A.Barnas M.","","Institute of Electrical and Electronics Engineers Inc.","10th International Conference on Contemporary Computing, IC3 2017","10 August 2017 through 12 August 2017",,134614,,9781538630778,,,"English","Int. Conf. Contemp. Comput., IC3",Conference Paper,"Final","",Scopus,2-s2.0-85046363473
"Lai C.-M., Lu C.-Y., Lee H.-M.","57155590100;57205540738;35242881500;","Implementation of adversarial scenario to malware analytic",2018,"ACM International Conference Proceeding Series",,,,"127","132",,,"10.1145/3184066.3184078","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060475663&doi=10.1145%2f3184066.3184078&partnerID=40&md5=c8097cdb3efa17461c9cc0347028a0fa","National Taiwan University of Science and Technology, No.43, Keelung Rd., Sec.4, Da'an Dist., Taipei, Taiwan; Institute for Information Industry, 11F., No.106, Sec. 2, Heping E. Rd., Da'an Dist., Taipei, Taiwan","Lai, C.-M., National Taiwan University of Science and Technology, No.43, Keelung Rd., Sec.4, Da'an Dist., Taipei, Taiwan; Lu, C.-Y., Institute for Information Industry, 11F., No.106, Sec. 2, Heping E. Rd., Da'an Dist., Taipei, Taiwan; Lee, H.-M., National Taiwan University of Science and Technology, No.43, Keelung Rd., Sec.4, Da'an Dist., Taipei, Taiwan","As the worldwide internet has non-stop developments, it comes with enormous amount automatically generated malware. Those malware had become huge threaten to computer users. A comprehensive malware family classifier can help security researchers to quickly identify characteristics of malware which help malware analysts to investigate in more efficient way. However, despite the assistance of the artificial intelligent (AI) classifiers, it has been shown that the AI-based classifiers are vulnerable to so-called adversarial attacks. In this paper, we demonstrate how the adversarial settings can be applied to the classifier of malware families classification. Our experimental results achieved high successful rate through the adversarial attack. We also find the important features which are ignored by malware analysts but useful in the future analysis. © Association for Computing Machinery. All rights reserved.","Adversarial setting; Deep neural network; Malware analysis","Artificial intelligence; Computer crime; Deep neural networks; Soft computing; Artificial intelligent; Automatically generated; Computer users; Important features; Malware analysis; Malware families; Non stops; Malware",,,,,"Dahl, G.E., Stokes, J.W., Deng, L., Yu, D., Large-scale malware classification using random projections and neural networks (2013) Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on, pp. 3422-3426. , IEEE; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint arXiv; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387. , IEEE; Microsoft Malware Classification Challenge (BIG 2015), , https://www.kaggle.com/c/malware-classification; Egele, M., Scholte, T., Kirda, E., Kruegel, C., A survey on automated dynamic malware-analysis techniques and tools (2012) ACM Computing Surveys, 44, pp. 1-42. , Feb; Damodaran, A., Di Troia, F., Visaggio, C.A., Austin, T.H., Stamp, M., A comparison of static, dynamic, and hybrid analysis for malware detection (2017) Journal of Computer Virology and Hacking Techniques, 13 (1), pp. 1-12; Wang, X., Yiu, S.M., (2016) A Multi-task Learning Model for Malware Classification with Useful File Access Pattern from API Call Sequence, , arXiv preprint arXiv; McCulloch, W.S., Pitts, W., A logical calculus of the ideas immanent in nervous activity (1990) Bulletin of Mathematical Biology, 52 (1), pp. 99-115; Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradientbased learning applied to document recognition (1998) Proceedings of the IEEE, 86, pp. 2278-2324. , Nov; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., (2015) Going Deeper with Convolutions, pp. 1-9. , June; Silver, D., Huang, A., Maddison, C.J., Guez, A., Sifre, L., Driessche, Schrittwieser, J., Hassabis, D., Mastering the game of Go with deep neural networks and tree search (2016) Nature, 529, pp. 484-489. , Jan; Sutton, R.S., McAllester, D.A., Singh, S.P., Mansour, Y., Policy gradient methods for reinforcement learning with function approximation (2000) Advances in Neural Information Processing Systems, pp. 1057-1063; Coulom, R., Efficient selectivity and backup operators in monte-carlo tree search (2007) Proceedings of the 5th International Conference on Computers and Games, CG'06, pp. 72-83. , (Berlin, Heidelberg), Springer-Verlag; Ciregan, D., Meier, U., Schmidhuber, J., Multi-column deep neural networks for image classification (2012) 2012 IEEE Conference on Computer Vision and Pattern Recognition, pp. 3642-3649. , June; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., (2017) Practical Black-Box Attacks Against Machine Learning, pp. 506-519. , ACM Press; Biggio, B., Fumera, G., Roli, F., Pattern recognition systems under attack: Design issues and research challenges (2014) International Journal of Pattern Recognition and Artificial Intelligence, 28 (7), p. 1460002; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I., Tygar, J.D., Adversarial machine learning (2011) Proceedings of the 4th ACM Workshop on Security and Artificial Intelligence, pp. 43-58. , ACM; Goodfellow, I., Papernot, N., McDaniel, P., (2016) Cleverhans v0. 1: An Adversarial Machine Learning Library, , arXiv preprint arXiv; Simonyan, K., Vedaldi, A., Zisserman, A., Deep inside convolutional networks: Visualising image classification models and saliency maps (2013) CoRR, ABS1312.6034; VirTool:Win32/Obfuscator.ACY Threat Description - Windows Defender Security Intelligence",,,,"Association for Computing Machinery","2nd International Conference on Machine Learning and Soft Computing, ICMLSC 2018","2 February 2018 through 4 February 2018",,135972,,9781450363365,,,"English","ACM Int. Conf. Proc. Ser.",Conference Paper,"Final","",Scopus,2-s2.0-85060475663
"Kamhoua G.A., Pissinou N., Iyengar S.S., Beltran J., Miller J., Kamhoua C.A., Njilla L.L.","57195369430;7004116359;57204520228;57195364750;57203033964;36918490600;57038923900;","Approach to detect non-adversarial overlapping collusion in crowdsourcing",2018,"2017 IEEE 36th International Performance Computing and Communications Conference, IPCCC 2017","2018-January",,,"1","8",,2,"10.1109/PCCC.2017.8280462","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047384583&doi=10.1109%2fPCCC.2017.8280462&partnerID=40&md5=aab92423595690de4cacd166d1261124","School of Computing and Information Sciences, Florida International University, Miami, FL, United States; US Army Research Laboratory, Network Security Branch, Aldelphi, MD, United States; Air Force Research Lab, Cyber Assurance Branch, Rome, NY, United States","Kamhoua, G.A., School of Computing and Information Sciences, Florida International University, Miami, FL, United States; Pissinou, N., School of Computing and Information Sciences, Florida International University, Miami, FL, United States; Iyengar, S.S., School of Computing and Information Sciences, Florida International University, Miami, FL, United States; Beltran, J., School of Computing and Information Sciences, Florida International University, Miami, FL, United States; Miller, J., School of Computing and Information Sciences, Florida International University, Miami, FL, United States; Kamhoua, C.A., US Army Research Laboratory, Network Security Branch, Aldelphi, MD, United States; Njilla, L.L., Air Force Research Lab, Cyber Assurance Branch, Rome, NY, United States","Crowdsourcing services have become one of the most common ways organizations can gather ideas for new products and services from large crowds of consumers by offering monetary rewards depending on the tasks. However, this monetary reward has begun to attract malicious crowds of users who wish to complete the task with minimal effort through collaboration. For instance, a task based on reviews of a product can be degraded when malicious users copy each other with minimal edits of the review, giving a misrepresentation of the true quality of the product. More specifically, we investigate the case where different malicious crowd sizes cooperate on different tasks, known as overlapping groups. Such sophisticated and hard to detect malicious crowds provide unfair evaluations and misleading results to the crowdsourcers. To overcome this type of attack, we propose two methods to point out such groups with high accuracy. The first method detects similar reviews by including a new proposed similarity between review texts and show the results outperform the vectorial similarity measures used in prior works. The second method is based on community detection on networks and exploits the semantic similarity of the reviews. The experiments were conducted on reviews from Ott dataset on Amazon Mechanical Turk. © 2017 IEEE.","colluding attackers; Crowdsourcing; security","Semantics; Amazon mechanical turks; colluding attackers; Community detection; Overlapping groups; Products and services; security; Semantic similarity; Similarity measure; Crowdsourcing",,,,,"Tarable, A., Nordio, A., Leonardi, E., Marsan, M.A., The importance of being earnest in crowdsourcing systems (2015) Computer Communications (INFOCOM), 2015 IEEE Conference on, , IEEE; Garcia-Molina, H., Joglekar, M., Marcus, A., Parameswaran, A., Verroios, V., Challenges in data crowdsourcing (2016) IEEE Transactions on Knowledge and Data Engineering, 28 (4), pp. 901-911; Von Ahn, L., Dabbish, L., Designing games with a purpose (2008) Communications of the ACM, 51 (8), pp. 58-67; Wang, J., Kraska, T., Franklin, M.J., Feng, J., Crowder: Crowdsourcing entity resolution (2012) Proceedings of the VLDB Endowment, 5 (11), pp. 1483-1494; Snow, R., O'Connor, B., Jurafsky, D., Ng, A.Y., Cheap and fast-but is it good?: Evaluating non-expert annotations for natural language tasks (2008) Proceedings of the Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics; Snavely, N., Seitz, S.M., Szeliski, R., Photo tourism: Exploring photo collections in 3D (2006) ACM Transactions on Graphics (TOG), 25 (3). , ACM; Crowdsourcing Is Not New-The History of Crowdsourcing (1714 to 2010), , https://blog.designcrowd.co.in/article/202/crowdsourcing-is-not-new-the-history-of-crowdsourcing-1714-to-2010; Mukherjee, A., Liu, B., Glance, N., Spotting fake reviewer groups in consumer reviews (2012) Proceedings of the 21st International Conference on World Wide Web, , ACM; Lim, E.P., Nguyen, V.A., Jindal, N., Liu, B., Lauw, H.W., Detect-ing product review spammers using rating behaviors (2010) Proceedings of the 19th ACM International Conference on Information and Knowledge Management, , ACM; Allahbakhsh, M., Ignjatovic, A., Benatallah, B., Beheshti, S.M.R., Foo, N., Bertino, E., (2012) Detecting, Representing and Querying Collusion in Online Rating Systems, , arXiv preprint; KhudaBukhsh, A.R., Carbonell, J.G., Jansen, P.J., Detecting non-adversarial collusion in crowdsourcing (2014) Second AAAI Conference on Human Computation and Crowdsourcing; Allahbakhsh, M., Ignjatovic, A., An iterative method for calculating robust rating scores (2015) IEEE Transactions on Parallel and Distributed Systems, 26 (2), pp. 340-350; Allahbakhsh, M., Ignjatovic, A., Benatallah, B., Bertino, E., Foo, N., Collusion detection in online rating systems (2013) Asia-Pacific Web Conference, , Springer, Berlin, Heidelberg; Kamvar, S.D., Schlosser, M.T., Garcia-Molina, H., The eigentrust algorithm for reputation management in p2p networks (2003) Proceedings of the 12th International Conference on World Wide Web, , ACM; Lian, Q., Zhang, Z., Yang, M., Zhao, B.Y., Dai, Y., Li, X., An em-pirical study of collusion behavior in the Maze P2P file-sharing system (2007) Distributed Computing Systems, 2007. ICDCS'07. 27th International Conference on, , IEEE; Liu, Y., Yang, Y., Sun, Y.L., Detection of collusion behaviors in online reputation systems (2008) Signals, Systems and Computers, 2008 42nd Asilomar Conference on, , IEEE; Yang, Y., Sun, Y.L., Kay, S., Yang, Q., Defending online reputation systems against collaborative unfair raters through signal modeling and trust (2009) Proceedings of the 2009 ACM Symposium on Applied Computing, , ACM; Shen, H., Lin, Y., Sapra, K., Li, Z., Enhancing collusion resilience in reputation systems (2016) IEEE Transactions on Parallel and Distributed Systems, 27 (8), pp. 2274-2287; Trushkowsky, B., Kraska, T., Franklin, M.J., Sarkar, P., Crowd-sourced enumeration queries (2013) Data Engineering (ICDE), 2013 IEEE 29th International Conference on, , IEEE; Mihalcea, R., Corley, C., Strapparava, C., Corpus-based and knowledge-based measures of text semantic similarity (2006) AAAI, 6; Sandulescu, V., Ester, M., Detecting singleton review spammers using semantic similarity (2015) Proceedings of the 24th International Conference on World Wide Web, , ACM; Agrawal, R., Srikant, R., Fast algorithms for mining association rules (1994) Proc. 20th Int. Conf. Very Large Data Bases, VLDB, 1215; Daubert, J., Grube, T., Mühlhäuser, M., Fischer, M., Internal at-tacks in anonymous publish-subscribe P2P overlays (2015) Networked Systems (NetSys), 2015 International Conference and Workshops on, , IEEE; Niu, J., Wang, L., Chen, Y., He, W., Detecting collusive cheating in online shopping systems through characteristics of social networks (2014) Com-puter Communications Workshops (INFOCOM WKSHPS), 2014 IEEE Conference on, , IEEE; Li, Z., Shen, H., Sapra, K., Leveraging social networks to combat collusion in reputation systems for peer-to-peer networks (2011) Parallel & Distributed Processing Symposium (IPDPS), 2011 IEEE International, , IEEE; Chen, K., Liu, G., Shen, H., Qi, F., Sociallink: Utilizing social network and transaction links for effective trust management in P2P file sharing systems. Utilizing (2015) Peer-to-Peer Computing (P2P), 2015 IEEE Interna-tional Conference on, , IEEE; Kamhoua, G., Pissinou, N., Iyengar, S., Beltran, J., Kamhoua, C., Hernandez, B., Njilla, L., Makki, A., Preventing colluding identity clone attacks in online social networks (2017) Distributed Computing Systems Workshops (ICDCSW), 2017 IEEE 37th International Conference on, , IEEE; Mason, W., Watts, D.J., Financial incentives and the performance of crowds (2010) ACM SigKDD Explorations Newsletter, 11 (2), pp. 100-108; Wang, G., Wang, T., Zheng, H., Zhao, B.Y., Man vs. Machine: Practical adversarial detection of malicious crowdsourcing workers (2014) USENIX Security Symposium; Monge, A.E., Elkan, C., The field matching problem: Algorithms and applications (1996) KDD; Jaro, M.A., Probabilistic linkage of large public health data files (1995) Statistics in Medicine, 14 (5-7), pp. 491-498; Wang, J., Li, G., Fe, J., Fast-join: An efficient method for fuzzy token matching based string similarity join (2011) Data Engineering (ICDE), 2011 IEEE 27th International Conference on, , IEEE; Soundarajan, S., Hopcroft, J.E., Use of local group information to identify communities in networks (2015) ACM Transactions on Knowledge Discovery from Data (TKDD), 9 (3), p. 21; Ott, M., Choi, Y., Cardie, C., Hancock, J.T., Finding deceptive opinion spam by any stretch of the imagination (2011) Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1, , Association for Computational Linguistics; Ott, M., Cardie, C., Hancock, J.T., Negative deceptive opinion spam (2013) HLT-NAACL; Toutanova, K., Klein, D., Manning, C.D., Singer, Y., Feature-rich part-of-speech tagging with a cyclic dependency network (2003) Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology-Volume 1, , Association for Computational Linguistics",,,"","Institute of Electrical and Electronics Engineers Inc.","36th IEEE International Performance Computing and Communications Conference, IPCCC 2017","10 December 2017 through 12 December 2017",,134551,,9781509064687,,,"English","IEEE Int. Perform. Comput. Commun. Conf., IPCCC",Conference Paper,"Final","",Scopus,2-s2.0-85047384583
"Ditzler G., Prater A.","36019949100;57203188005;","Fine tuning lasso in an adversarial environment against gradient attacks",2018,"2017 IEEE Symposium Series on Computational Intelligence, SSCI 2017 - Proceedings","2018-January",,,"1","7",,3,"10.1109/SSCI.2017.8280924","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046103334&doi=10.1109%2fSSCI.2017.8280924&partnerID=40&md5=ecff971a39be7697ff90f9f7d26f75a3","Department of Electrical and Computer Engineering, University of Arizona, Tucson, AZ  85721, United States; Information Directorate, Air Force Research Laboratory, Rome, NY  13441, United States","Ditzler, G., Department of Electrical and Computer Engineering, University of Arizona, Tucson, AZ  85721, United States; Prater, A., Information Directorate, Air Force Research Laboratory, Rome, NY  13441, United States","Machine learning and data mining algorithms typically assume that the training and testing data are sampled from the same fixed probability distribution; however, this violation is often violated in practice. The field of domain adaptation addresses the situation where this assumption of a fixed probability between the two domains is violated; however, the difference between the two domains (training/source and testing/target) may not be known a priori. There has been a recent thrust in addressing the problem of learning in the presence of an adversary, which we formulate as a problem of domain adaption to build a more robust classifier. This is because the overall security of classifiers and their preprocessing stages have been called into question with the recent findings of adversaries in a learning setting. Adversarial training (and testing) data pose a serious threat to scenarios where an attacker has the opportunity to ""poison"" the training or ""evade"" on the testing data set(s) in order to achieve something that is not in the best interest of the classifier. Recent work has begun to show the impact of adversarial data on several classifiers; however, the impact of the adversary on aspects related to preprocessing of data (i.e., dimensionality reduction or feature selection) has widely been ignored in the revamp of adversarial learning research. Furthermore, variable selection, which is a vital component to any data analysis, has been shown to be particularly susceptible under an attacker that has knowledge of the task. In this work, we explore avenues for learning resilient classification models in the adversarial learning setting by considering the effects of adversarial data and how to mitigate its effects through optimization. Our model forms a single convex optimization problem that uses the labeled training data from the source domain and known weaknesses of the model for an adversarial component. We benchmark the proposed approach on synthetic data and show the trade-off between classification accuracy and skew-insensitive statistics. © 2017 IEEE.","Adversarial Machine Learning; Feature Selection; Supervised Learning","Artificial intelligence; Convex optimization; Data mining; Economic and social effects; Feature extraction; Learning algorithms; Learning systems; Probability distributions; Statistical tests; Supervised learning; Adversarial environments; Classification accuracy; Classification models; Convex optimization problems; Data mining algorithm; Dimensionality reduction; Pre-processing of data; Pre-processing stages; Classification (of information)",,,,,"Barreno, M., Nelson, B., Sears, R., Joseph, A., Tygar, J.D., Can machine learning be secure? (2006) ACM Symposium on Inform Ation, Computer and Communications Security; Šrndic, N., Laskov, P., Detection of malicious pdf files based on hierarchical document structure (2013) Annual Network and Distribributed Systems Security Symposium; Maiorca, D., Corona, I., Giacinto, G., Looking at the bag is not enough to find the bomb: An evasion of structural methods for malicious pdf files detection (2013) ACM Symposium on Inform Ation, Computer and Communications Security, pp. 119-130; Xiao, H., Biggio, B., Brown, G., Fumera, G., Eckert, C., Roli, F., Is feature selection secure against training data poisoning? (2015) International Conference on Machine Learning; Beigi, E.B., Jazi, H.H., Stakhanova, N., Ghorbani, A.A., Towards effective feature selection in machine learning-based botnet detection approaches (2014) IEEE Conference on Communications and Network Security; Bekerman, D., Shapira, B., Rokach, L., Bar, A., Unknown malware detection using network traffic classification (2015) IEEE Conference on Communications and Network Security, pp. 134-142; Lin, C.-T., Wang, N.-J., Xiao, H., Eckert, C., Feature selection and extraction for malware classification (2015) Journal of Information Science and Engineering, 31, pp. 965-992; Pehlivan, U., Baltaci, N., Acartürk, C., Baykal, N., The analysis of feature selection methods and classification algorithms in permission based android malware detection (2014) IEEE Symposium Series on Computational Intelligence in Cyber Security, pp. 1-8; Zhang, F., Chan, P.P.K., Biggio, B., Yeung, D., Roli, F., Adversarial feature selection against evasion attacks (2016) IEEE Transactions on Cybernetics, 46 (3), pp. 766-777; Dietterich, T.G., Bakiri, G., Solving multiclass learning problems via error correcting output codes (1995) Journal of Artificial Intelligence Research, pp. 263-286; Rifkin, R., Klautau, A., In defense of one-vs-all classification (2004) Journal of Machine Learning Research, 5, pp. 101-141; Brown, G., Pocock, A., Zhao, M.-J., Luján, M., Conditional likelihood maximisation: A unifying framework for information theoretic feature selection (2012) Journal of Machine Learning Research, 13, pp. 27-66; Yang, H., Moody, J., Data visualization and feature selection: New algorithms for non-Gaussian data (1999) Advances in Neural Information Processing Systems; Liu, H., Ditzler, G., A fast information-theoretic approximation of joint mutual information feature selection (2017) IEEE/INNS International Joint Conference on Neural Networks; Tibshirani, R., Regression shrinkage and selection via the lasso (1996) Journal of Royal Statistics Society, 58 (1), pp. 267-288; Laszka, A., Vorobeychik, Y., Koutsoukos, X., Resilient observation selection in adversarial settings (2015) IEEE Conference on Decision and Control; Das, A., Kempe, D., Submodular meets spectral: Greedy algorithms for subset selection, sparse approximation and dictionary selection (2011) International Conference on Machine Learning; Wu, X., Yu, K., Wang, H., Ding, W., Online streaming feature selection (2010) International Conference on Machine Learning; Zhou, J., Foster, D., Stine, R., Ungar, L., Streamwise feature selection (2006) Journal of Machine Learning Research, 7, pp. 1861-1885; Wang, J., Zhao, P., Hoi, S., Zhu, J., Online feature selection and its applications (2013) IEEE Transactions on Knowledge and Data Engineering, 26 (3), pp. 698-710; Ditzler, G., Polikar, R., Rosen, G., A bootstrap based neyman-pearson test for identifying variable importance (2015) IEEE Transactions on Neural Networks and Learning Systems, 26 (4), pp. 880-886; Altschuler, J., Bhaskara, A., Fu, G., Mirrokni, V., Rostamizadeh, A., Zadimoghaddam, M., Greedy column subset selection: New bounds and distributed algorithms (2016) International Conference on Machine Learning; Ditzler, G., Roveri, M., Alippi, C., Polikar, R., Adaptive strategies for learning in nonstationary environments: A survey (2015) Computational Intelligence Magazine, 10 (4), pp. 12-25; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2014) International Conference on Learning Representations; Stevens, D., Lowd, D., On the hardness of evading combinations of linear classifiers (2013) ACM Workshop on Artificial Intelligence and Security; Wang, F., Liu, W., Chawla, S., On sparse feature attacks in adversarial learning (2014) IEEE International Conference on Data Mining, pp. 1013-1018; Liu, W., Chawla, S., Mining adversarial patterns via regularized loss minimization (2010) Machine Learning, 81, pp. 69-83; Ben-David, S., Blitzer, J., Crammer, K., Kulesza, A., Pereira, F., Wortman Vaughan, J., A theory of learning from different domains (2010) Machine Learning, 79, pp. 151-175; Chawla, N.V., Bowyer, K.W., Hall, L.O., Kegelmeyer, W.P., SMOTE: Synthetic minority over-sampling technique (2002) Journal of Artificial Intelligence Research, 16, pp. 321-357; Valenzuela, M., Rozenblit, J., Learning using anti-training with sacrificial data (2016) Journal of Machine Learning Research, 17 (24), pp. 1-42",,,"","Institute of Electrical and Electronics Engineers Inc.","2017 IEEE Symposium Series on Computational Intelligence, SSCI 2017","27 November 2017 through 1 December 2017",,134337,,9781538627259,,,"English","IEEE Symp. Ser. Comput. Intell., SSCI - Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85046103334
"Truong N.D., Haw J.Y., Assad S.M., Lam P.K., Kavehei O.","57194467238;56000989900;6602314643;7202365902;56011177700;","Machine Learning Cryptanalysis of a Quantum Random Number Generator",2018,"IEEE Transactions on Information Forensics and Security","14","2","8396276","403","414",,11,"10.1109/TIFS.2018.2850770","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049125619&doi=10.1109%2fTIFS.2018.2850770&partnerID=40&md5=e4cd8c209426f983a8f81fd473403460","Nano-Neuro-Inspired Research Laboratory, School of Electrical and Information Engineering, University of Sydney, Sydney, NSW  2006, Australia; Department of Quantum Science, Centre of Excellence for Quantum Computation and Communication Technology, Research School of Physics and Engineering, Australian National University, Canberra, ACT  2601, Australia","Truong, N.D., Nano-Neuro-Inspired Research Laboratory, School of Electrical and Information Engineering, University of Sydney, Sydney, NSW  2006, Australia; Haw, J.Y., Department of Quantum Science, Centre of Excellence for Quantum Computation and Communication Technology, Research School of Physics and Engineering, Australian National University, Canberra, ACT  2601, Australia; Assad, S.M., Department of Quantum Science, Centre of Excellence for Quantum Computation and Communication Technology, Research School of Physics and Engineering, Australian National University, Canberra, ACT  2601, Australia; Lam, P.K., Department of Quantum Science, Centre of Excellence for Quantum Computation and Communication Technology, Research School of Physics and Engineering, Australian National University, Canberra, ACT  2601, Australia; Kavehei, O., Nano-Neuro-Inspired Research Laboratory, School of Electrical and Information Engineering, University of Sydney, Sydney, NSW  2006, Australia","Random number generators (RNGs) that are crucial for cryptographic applications have been the subject of adversarial attacks. These attacks exploit environmental information to predict generated random numbers that are supposed to be truly random and unpredictable. Though quantum random number generators (QRNGs) are based on the intrinsic indeterministic nature of quantum properties, the presence of classical noise in the measurement process compromises the integrity of a QRNG. In this paper, we develop a predictive machine learning (ML) analysis to investigate the impact of deterministic classical noise in different stages of an optical continuous variable QRNG. Our ML model successfully detects inherent correlations when the deterministic noise sources are prominent. After appropriate filtering and randomness extraction processes are introduced, our QRNG system, in turn, demonstrates its robustness against ML. We further demonstrate the robustness of our ML approach by applying it to uniformly distributed random numbers from the QRNG and a congruential RNG. Hence, our result shows that ML has potentials in benchmarking the quality of RNG devices. © 2005-2012 IEEE.","cryptoanalysis; machine learning; Quantum random number generator","Artificial intelligence; Benchmarking; Convolution; Cryptography; Entropy; Extraction; Feature extraction; Gas generators; Learning systems; Noise generators; Number theory; Personnel training; Spurious signal noise; Continuous variables; Cryptoanalysis; Cryptographic applications; Environmental information; Machine learning approaches; Quantum random number generators; Random number generators; Randomness extractions; Random number generation",,,,,"Rukhin, A., Soto, J., Nechvatal, J., Smid, M., Barker, E., (2001) A Statistical Test Suite for Random and Pseudorandom Number Generators for Cryptographic Applications, , Booz-Allen Hamilton, McLean, VA, USA, Tech. Rep; Heninger, N., Durumeric, Z., Wustrow, E., Halderman, J.A., Mining your Ps and Qs: Detection of widespread weak keys in network devices (2012) Proc. USENIX Secur. Symp., 8, p. 1; Hastings, M., Fried, J., Heninger, N., Weak keys remain widespread in network devices (2016) Proc. ACM Internet Meas. Conf., pp. 49-63; Barker, E.B., Kelsey, J.M., Recommendation for random number generation using deterministic random bit generators (2015) Nat. Inst. Standards Technol, , Gaithersburg, MD, USA, Tech. Rep. NIST SP 800-90A, Rev 1; Kelsey, J., Schneier, B., Wagner, D., Hall, C., Cryptanalytic attacks on pseudorandom number generators (1998) Fast Software Encryption, , S. Vaudenay, Ed. Berlin, Germany: Springer; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Proc. Adv. Neural Inf. Process. Syst., pp. 1097-1105; Meliá-Seguí, J., Garcia-Alfaro, J., Herrera-Joancomartí, J., A practical implementation attack on weak pseudorandom number generator designs for EPC Gen2 tags (2011) Wireless Pers. Commun., 59 (1), pp. 27-42; Kanter, I., Aviad, Y., Reidler, I., Cohen, E., Rosenbluh, M., An optical ultrafast random bit generator (2010) Nature Photon., 4, pp. 58-61. , Jan; Herrero-Collantes, M., Garcia-Escartin, J.C., Quantum random number generators (2017) Rev. Mod. Phys., 89 (1), p. 015004; Ma, X., Yuan, X., Cao, Z., Qi, B., Zhang, Z., Quantum random number generation (2016) Npj Quantum Inf., 2, p. 16021. , Jun; Sakurai, J.J., Commins, E.D., (1995) Modern Quantum Mechanics; Ma, X., Xu, F., Xu, H., Tan, X., Qi, B., Lo, H.-K., Postprocessing for quantum random-number generators: Entropy evaluation and randomness extraction (2013) Phys. Rev. A, Gen. Phys., 87 (6), p. 062327. , Apr; Cao, Z., Zhou, H., Yuan, X., Ma, X., Source-independent quantum random number generation (2016) Phys. Rev. X, 6 (1), p. 011020; Wei, K., Ma, H., Yang, X., Trustworthiness of devices in a quantum random number generator based on a symmetric beam splitter (2017) J. Opt. Soc. Amer. B, Opt. Phys., 34 (10), pp. 2185-2189; Law, Y.Z., Bancal, J.-D., Scarani, V., Quantum randomness extraction for various levels of characterization of the devices (2014) J. Phys. A, Math. Theor., 47 (42), p. 424028; Pironio, S., Random numbers certified by Bell's theorem (2010) Nature, 464 (7291), p. 1021; Christensen, B., Detection-loophole-free test of quantum nonlocality, and applications (2013) Phys. Rev. Lett., 111 (13), p. 130406; Vallone, G., Marangon, D.G., Tomasin, M., Villoresi, P., Quantum randomness certified by the uncertainty principle (2014) Phys. Rev. A, Gen. Phys., 90 (5), p. 052327; Haw, J.Y., Maximization of extractable randomness in a quantum random-number generator (2015) Phys. Rev. Appl., 3 (5), p. 54004; Kelsey, J., McKay, K.A., Turan, M.S., Predictive models for min-entropy estimation (2015) Cryptographic Hardware and Embedded Systems, , T. Güneysu and H. Handschuh, Eds. Berlin, Germany: Springer; Symul, T., Assad, S.M., Lam, P.K., Real time demonstration of high bitrate quantum random number generation with coherent laser light (2011) Appl. Phys. Lett., 98 (23), p. 231103. , Jun; Gabriel, C., A generator for unique quantum random numbers based on vacuum states (2010) Nature Photon., 4 (10), pp. 711-715. , Oct; Bachor, H.-A., Ralph, T.C., (2004) A Guide to Experiments in Quantum Optics, , Hoboken NJ USA: Wiley; Shen, Y., Tian, L., Zou, H., Practical quantum random number generator based on measuring the shot noise of vacuum states (2010) Phys. Rev. A, Gen. Phys., 81 (6), p. 063814. , Jun; Sutskever, I., Vinyals, O., Le, Q.V., Sequence to sequence learning with neural networks (2014) Proc. Adv. Neural Inf. Process. Syst., pp. 3104-3112; Donahue, J., Long-term recurrent convolutional networks for visual recognition and description (2015) Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit, pp. 2625-2634. , Jun; Konig, R., Renner, R., Schaffner, C., The operational meaning of min-And max-entropy (2009) IEEE Trans. Inf. Theory, 55 (9), pp. 4337-4347. , Sep; Lam, P.K., (1998) Applications of Quantum Electro-Optic Control and Squeezed Light, , Ph.D. dissertation, Australian Nat. Univ., Canberra, Australia; (2001) Federal Information Processing Standards Publication 197, NIST FIPS Pub., , Advanced Encryption Standard (AES; Tezuka, S., (2012) Uniform Random Numbers: Theory and Practice, , Springer; Marangon, D.G., Vallone, G., Villoresi, P., Source-deviceindependent ultrafast quantum random number generation (2017) Phys. Rev. Lett., 118 (6), p. 060503","Kavehei, O.; Nano-Neuro-Inspired Research Laboratory, Australia; email: omid.kavehei@sydney.edu.au",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,15566013,,,,"English","IEEE Trans. Inf. Forensics Secur.",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85049125619
"Abuzainab N., Saad W.","36182092800;57203259001;","Dynamic Connectivity Game for Adversarial Internet of Battlefield Things Systems",2018,"IEEE Internet of Things Journal","5","1","8240980","378","390",,18,"10.1109/JIOT.2017.2786546","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040062280&doi=10.1109%2fJIOT.2017.2786546&partnerID=40&md5=34e8f218f57d56e9e9fa722b2f8e6213","Department of Electrical and Computer Engineering, Virginia Polytechnic Institute and State University, Blacksburg, VA  24061, United States","Abuzainab, N., Department of Electrical and Computer Engineering, Virginia Polytechnic Institute and State University, Blacksburg, VA  24061, United States; Saad, W., Department of Electrical and Computer Engineering, Virginia Polytechnic Institute and State University, Blacksburg, VA  24061, United States","In this paper, the problem of network connectivity is studied for an adversarial Internet of Battlefield Things (IoBT) system in which an attacker aims at disrupting the connectivity of the network by choosing to compromise one of the IoBT nodes at each time epoch. To counter such attacks, an IoBT defender attempts to reestablish the IoBT connectivity by either deploying new IoBT nodes or by changing the roles of existing nodes. This problem is formulated as a dynamic multistage Stackelberg connectivity game that extends classical connectivity games and that explicitly takes into account the characteristics and requirements of the IoBT network. In particular, the defender's payoff captures the IoBT latency as well as the sum of weights of disconnected nodes at each stage of the game. Due to the dependence of the attacker's and defender's actions at each stage of the game on the network state, the feedback Stackelberg solution [feedback Stackelberg equilibrium (FSE)] is used to solve the IoBT connectivity game. Then, sufficient conditions under which the IoBT system will remain connected, when the FSE solution is used, are determined analytically. Numerical results show that the expected number of disconnected sensors, when the FSE solution is used, decreases up to 46% compared to a baseline scenario in which a Stackelberg game with no feedback is used, and up to 43% compared to a baseline equal probability policy. © 2014 IEEE.","Game theory; Internet of Battlefield Things (IoBT); Internet of Things (IoT); security","Feedback; Internet of things; Connectivity games; Games; Government; Network connectivity; Numerical results; Robot sensing system; Stackelberg Games; Stackelberg solution; Wearable sensors",,,,,"Suri, N., Analyzing the applicability of Internet of Things to the battlefield environment (2016) Proc. Int. Conf. Military Commun. Inf. Syst. (ICMCIS), Brussels, Belgium, pp. 1-8. , May; Tortonesi, M., Leveraging Internet of Things within the military network environment-Challenges and solutions (2016) Proc. IEEE World Forum Internet Things (WF-IoT), Reston, VA, USA, Dec., pp. 111-116; Ray, P.P., Towards an Internet of Things based architectural framework for defence (2015) Proc. Int. Conf. Control Instrum. Commun. Comput. Technol. (ICCICCT), Kumarakovil, India, pp. 411-416. , Dec; Lee, W.-H., Choi, J., Lee, J.-H., Kim, Y.-H., Kim, S.-C., Distributed power control-based connectivity reconstruction game in wireless localization (2017) IEEE Commun. Lett., 21 (2), pp. 334-337. , Feb; Roy, A., Mondal, A., Misra, S., Connectivity re-establishment in the presence of dumb nodes in sensor-cloud infrastructure: A game theoretic approach (2014) Proc. IEEE 6th Int. Conf. Cloud Comput. Technol. Sci., Singapore, Dec., pp. 847-852; Goratti, L., Baykas, T., Rasheed, T., Kato, S., NACRP: A connectivity protocol for star topology wireless sensor networks (2016) IEEE Wireless Commun. Lett., 5 (2), pp. 120-123. , Apr; Dou, R., Nan, G., Optimizing sensor network coverage and regional connectivity in industrial IoT systems (2017) IEEE Syst. J., 11 (3), pp. 1351-1360. , Sep; Xu, Z., Chen, L., Chen, C., Guan, X., Joint clustering and routing design for reliable and efficient data collection in large-scale wireless sensor networks (2016) IEEE Internet Things J., 3 (4), pp. 520-532. , Aug; Zhao, X., Zhang, Y., Jiang, C., Yuan, J., Cao, J., Mobile-aware topology control potential game: Equilibrium and connectivity (2016) IEEE Internet Things J., 3 (6), pp. 1267-1273. , Dec; Chen, P.-Y., Cheng, S.-M., Chen, K.-C., Information fusion to defend intentional attack in Internet of Things (2014) IEEE Internet Things J., 1 (4), pp. 337-348. , Aug; Han, Y., Chen, Y., Wang, B., Liu, K.J.R., Enabling heterogeneous connectivity in Internet of Things: A time-reversal approach (2016) IEEE Internet Things J., 3 (6), pp. 1036-1047. , Dec; Grüner, S., Radmacher, F.G., Thomas, W., Connectivity games over dynamic networks (2013) Theor. Comput. Sci., 493, pp. 46-65. , Jul; Zhang, Y., Zheng, J., Ma, M., (2008) Handbook of Research on Wireless Security, , Hershey, PA, USA: Inf. Sci. Ref; Han, Z., Niyato, D., Saad, W., Başar, T., Hjørungnes, A., (2012) Game Theory in Wireless and Communication Networks: Theory, Models, and Applications, , Cambridge, U.K.: Cambridge Univ. Press; Pawgasame, W., A survey in adaptive hybrid wireless sensor network for military operations (2016) Proc. 2nd Asian Conf. Defence Technol. (ACDT), Chiang Mai, Thailand, pp. 78-83. , Jan; Başar, T., Olsder, G.J., (1998) Dynamic Noncooperative Game Theory, 2nd Ed, , Philadelphia, PA, USA: SIAM; An, B., Tambe, M., Sinha, A., Stackelberg security games (SSG) basics and application overview (2016) Improving Homeland Security Decisions, , Cambridge, U.K.: Cambridge Univ. Press; Başar, T., Haurie, A., Feedback equilibria in differential games with structural and modal uncertainties (1984) Advances in Large Scale Systems, pp. 163-201. , Greenwich, CT, USA: JAE Press ch. 1; Conitzer, V., On Stackelberg mixed strategies (2016) Synthese, 193 (3), pp. 689-703. , Mar; Babayev, D.A., Mardanov, S.S., Reducing the number of variables in integer and linear programming problems (1994) Comput. Optim. Appl., 3 (2), pp. 99-109. , May","Abuzainab, N.; Department of Electrical and Computer Engineering, United States; email: nof@vt.edu",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,23274662,,,,"English","IEEE Internet Things J.",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85040062280
"Chan P.P.K., Liu W., Chen D., Yeung D.S., Zhang F., Wang X., Hsu C.-C.","7403497727;57202889283;57201087337;7103391375;56601914400;9734213500;7404947474;","Face Liveness Detection Using a Flash Against 2D Spoofing Attack",2018,"IEEE Transactions on Information Forensics and Security","13","2","8055588","521","534",,40,"10.1109/TIFS.2017.2758748","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030768411&doi=10.1109%2fTIFS.2017.2758748&partnerID=40&md5=6a6fe166ba6ec3942e49738f3a5630e1","School of Computer Science and Engineering, South China University of Technology, Guangzhou, 510006, China; Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong; SMC Society of IEEE, China; College of Computer and Information Engineering, Henan Normal University, Xinxiang, 453007, China; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, 518060, China; Computer Science and Information Engineering, Fu Jen Catholic University, Taipei, 24205, Taiwan","Chan, P.P.K., School of Computer Science and Engineering, South China University of Technology, Guangzhou, 510006, China; Liu, W., Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong; Chen, D., SMC Society of IEEE, China; Yeung, D.S., School of Computer Science and Engineering, South China University of Technology, Guangzhou, 510006, China; Zhang, F., College of Computer and Information Engineering, Henan Normal University, Xinxiang, 453007, China; Wang, X., College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, 518060, China; Hsu, C.-C., Computer Science and Information Engineering, Fu Jen Catholic University, Taipei, 24205, Taiwan","Face recognition technique has been widely applied to personal identification systems due to its satisfying performance. However, its security may be a crucial issue, since many studies have shown that face recognition systems may be vulnerable in an adversarial environment, in which an adversary can camouflage as a legitimate user in order to mislead the system. Although face liveness detection methods have been proposed to distinguish real and fake faces, they are either time-consuming, costly, or sensitive to noise and illumination. This paper proposes a face liveness detection method with flash against 2D spoofing attack. Flash not only can enhance the differentiation between legitimate and illegitimate users, but it also reduces the influence of environmental factors. Two images are taken from a subject, one with flash and another without flash. Four texture and 2D structure descriptors with low computational complexity are used to capture information of the two images in our model. Advantages of our method include low installation cost of flash and no user cooperation required. A data set of 50 subjects collected under different scenarios is used in the experiments to evaluate the proposed method. The experimental results indicate that the proposed model performs better than existing liveness detection methods in different environmental scenarios. This paper confirms that the use of flash successfully improves face liveness detection in terms of accuracy, robustness, and running time. © 2005-2012 IEEE.","2D spoofing attack; adversarial learning; Face liveness detection; flash light","Cameras; Feature extraction; Lighting; Adversarial learning; Face; Face liveness; Spoofing attacks; Time complexity; Two-dimensional displays; Face recognition",,,,,"Jain, A.K., Ross, A., Prabhakar, S., An introduction to biometric recognition (2004) IEEE Trans. Circuits Syst. Video Technol, 14 (1), pp. 4-20. , Jan; Uludag, U., Pankanti, S., Prabhakar, S., Jain, A.K., Biometric cryptosystems: Issues and challenges (2004) Proc IEEE, 92 (6), pp. 948-960. , Jun; Zhao, W., Chellappa, R., Phillips, P.J., Rosenfeld, A., Face recognition: A literature survey (2003) ACM Comput. Surv, 35 (4), pp. 399-458; Abate, A.F., Nappi, M., Riccio, D., Sabatino, G., 2D and 3D face recognition: A survey (2007) Pattern Recognit. Lett, 28 (14), pp. 1885-1906. , Oct; Wagner, A., Wright, J., Ganesh, A., Zhou, Z., Mobahi, H., Ma, Y., Toward a practical face recognition system: Robust alignment and illumination by sparse representation (2012) IEEE Trans. Pattern Anal. Mach. Intell, 34 (2), pp. 372-386. , Feb; Wei, C.-P., Chen, C.-F., Wang, Y.-C.F., Robust face recognition with structurally incoherent low-rank matrix decomposition (2014) IEEE Trans. Image Process, 23 (8), pp. 3294-3307. , Aug; Gao, S., Zhang, Y., Jia, K., Lu, J., Zhang, Y., Single sample face recognition via learning deep supervised autoencoders (2015) IEEE Trans. Inf. Forensics Security, 10 (10), pp. 2108-2118. , Oct; Chingovska, I., Dos Anjos, A.R., Marcel, S., Biometrics evaluation under spoofing attacks (2014) IEEE Trans. Inf. Forensics Security, 9 (12), pp. 2264-2276. , Dec; Biggio, B., Akhtar, Z., Fumera, G., Marcialis, G.L., Roli, F., Security evaluation of biometric authentication systems under real spoofing attacks (2012) IET Biometrics, 1 (1), pp. 11-24. , Mar; Akhtar, Z., Micheloni, C., Foresti, G.L., Biometric liveness detection: Challenges and research opportunities (2015) IEEE Security Privacy, 13 (5), pp. 63-72. , Sep./Oct; Tronci, R., Fusion of multiple clues for photo-Attack detection in face recognition systems (2011) Proc IEEE Int. Joint Conf. Biometrics (IJCB), Washington, DC, USA, pp. 1-6. , Oct; Chingovska, I., The 2nd competition on counter measures to 2D face spoofing attacks (2013) Proc. IAPR Int. Conf. Biometrics (ICB), Madrid, Spain, pp. 1-6. , Jun; Anjos, A., Marcel, S., Counter-measures to photo attacks in face recognition: A public database and a baseline (2011) Proc IEEE Int. Joint Conf. Biometrics (IJCB), Washington, DC, USA, pp. 1-7. , Oct; Tan, X., Li, Y., Liu, J., Jiang, L., Face liveness detection from a single image with sparse low rank bilinear discriminative model (2010) Proc. 11th Eur. Conf. Comput. Vis. (ECCV), Heraklion, Greece, pp. 504-517. , Sep; Wen, D., Han, H., Jain, A.K., Face spoof detection with image distortion analysis (2015) IEEE Trans. Inf. Forensics Security, 10 (4), pp. 746-761. , Apr; Zhang, Z., Yan, J., Liu, S., Lei, Z., Yi, D., Li, S.Z., A face antispoofing database with diverse attacks (2012) Proc. 5th IAPR Int. Conf. Biometrics (ICB), New Delhi, India, Mar./Apr, pp. 26-31; Chingovska, I., Anjos, A., Marcel, S., On the effectiveness of local binary patterns in face anti-spoofing (2012) Proc. Int. Conf. Biometrics Special Interest Group (BIOSIG), Darmstadt, Germany, pp. 1-7. , Sep; Kim, W., Suh, S., Han, J.-J., Face liveness detection from a single image via diffusion speed model (2015) IEEE Trans. Image Process, 24 (8), pp. 2456-2465. , Aug; Chakraborty, S., Das, D., (2014) An Overview of Face Liveness Detection, , https://arxiv.org/abs/1405.2227; Li, J., Wang, Y., Tan, T., Live face detection based on the analysis of Fourier spectra (2004) Proc. SPIE, 5404, pp. 296-303. , Apr; Määttä, J., Hadid, A., Pietikäinen, M., Face spoofing detection from single images using micro-Texture analysis (2011) Proc. Int. Joint Conf. Biometrics (IJCB), Washington, DC, USA, pp. 1-7. , Oct; Bao, W., Li, H., Li, N., Jiang, W., A liveness detection method for face recognition based on optical flow field (2009) Proc. Int. Conf. Image Anal. Signal Process. (IASP), Taizhou, China, pp. 233-236. , Apr; Choudhury, T., Clarkson, B., Jebara, T., Pentland, A., Multimodal person recognition using unconstrained audio and video (1999) Proc. Int. Conf. Audio Video-Based Person Authentication, pp. 176-181; Li, J.-W., Eye blink detection based on multiple Gabor response waves (2008) Proc. Int. Conf. Mach. Learn. Cybern. (ICMLC, 5, pp. 2852-2856. , Jul; Yu, H., Ng, T.-T., Sun, Q., Recaptured photo detection using specularity distribution (2008) Proc. 15th IEEE Int. Conf. Image Process. (ICIP, pp. 3140-3143. , Oct; Galbally, J., Marcel, S., Fierrez, J., Image quality assessment for fake biometric detection: Application to iris, fingerprint, and face recognition (2014) IEEE Trans. Image Process, 23 (2), pp. 710-724. , Feb; Kim, G., Eum, S., Suhr, J.K., Kim, D.I., Park, K.R., Kim, J., Face liveness detection based on texture and frequency analyses (2012) Proc. 5th IAPR Int. Conf. Biometrics (ICB), New Delhi, India, Mar./Apr, pp. 67-72; Tirunagari, S., Poh, N., Windridge, D., Iorliam, A., Suki, N., Ho, A., Detection of face spoofing using visual dynamics (2015) IEEE Trans. Inf. Forensics Security, 10 (4), pp. 762-777. , Apr; Chetty, G., Biometric liveness detection based on cross modal fusion (2009) Proc. 12th Int. Conf. Inf. Fusion (FUSION). Seattle, WA, USA, pp. 2255-2262. , Jul; Kollreider, K., Fronthaler, H., Bigun, J., Evaluating liveness by face images and the structure tensor (2005) Proc. 4th IEEE Workshop Automat. Identificat. Adv. Technol., Buffalo, NY, USA, pp. 75-80. , Oct; Pinto, A., Schwartz, W.R., Pedrini, H., Rocha, A., Using visual rhythms for detecting video-based facial spoof attacks (2015) IEEE Trans. Inf. Forensics Security, 10 (5), pp. 1025-1038. , May; Zhang, Z., Yi, D., Lei, Z., Li, S.Z., Face liveness detection by learning multispectral reflectance distributions (2011) Proc. FG, Santa Barbara, CA, USA, pp. 436-441. , Mar; Liu, W., Face liveness detection using analysis of Fourier spectra based on hair (2014) Proc. Int. Conf. Wavelet Anal. Pattern Recognit. (ICWAPR), Lanzhou, China, pp. 75-80. , Jul; Ojala, T., Pietikäinen, M., Mäenpää, T., Multiresolution gray-scale and rotation invariant texture classification with local binary patterns (2002) IEEE Trans. Pattern Anal. Mach. Intell, 24 (7), pp. 971-987. , Jul; Boulkenafet, Z., Komulainen, J., Hadid, A., Face spoofing detection using colour texture analysis IEEE Trans. Inf. Forensics Security, 11 (8), pp. 1818-1830. , Aug. 2016; Smiatacz, M., Liveness measurements using optical flow for biometric person authentication (2012) Metrol. Meas. Syst, 19 (2), pp. 257-268; Anjos, A., Chakka, M.M., Marcel, S., Motion-based countermeasures to photo attacks in face recognition (2014) IET Biometrics, 3 (3), pp. 147-158. , Sep; Jee, H.K., Jung, S.U., Yoo, J.H., Liveness detection for embedded face recognition system (2006) Proc. World Acad. Sci., Eng. Technol., Vienna, Austria, pp. 29-32. , Dec; Pan, G., Sun, L., Wu, Z., Lao, S., Eyeblink-based anti-spoofing in face recognition from a generic webcamera (2007) Proc IEEE 11th Int. Conf. Comput. Vis. (ICCV), Rio de Janeiro, Brazil, pp. 1-8. , Oct; Chetty, G., Wagner, M., Multi-level liveness verification for facevoice biometric authentication (2006) Proc. Biometrics Symp., Special Session Res. Biometric Consortium Conf., Baltimore, MD, USA, pp. 1-6. , Sep; Patel, K., Han, H., Jain, A.K., Secure face unlock: Spoof detection on smartphones IEEE Trans. Inf. Forensics Security, 11 (10), pp. 2268-2283. , Oct. 2016; Dhamecha, T.I., Nigam, A., Singh, R., Vatsa, M., Disguise detection and face recognition in visible and thermal spectrums (2013) Proc. Int. Conf. Biometrics, pp. 1-8. , Jun; Lagorio, A., Tistarelli, M., Cadoni, M., Fookes, C., Sridharan, S., Liveness detection based on 3D face shape analysis (2013) Proc. 1st Int. Workshop Biometrics Forensics (IWBF), Lisbon, Portugal, pp. 1-4. , Apr; Kim, S., Ban, Y., Lee, S., Face liveness detection using a light field camera (2014) Sensors, 14 (12), pp. 22471-22499. , Jan; Pan, G., Sun, L., Wu, Z., Wang, Y., Monocular camera-based face liveness detection by combining eyeblink and scene context (2011) Telecommun. Syst, 47, pp. 215-225. , Aug; Kim, Y., Yoo, J.-H., Choi, K., A motion and similarity-based fake detection method for biometric face recognition systems (2011) IEEE Trans. Consum. Electron, 57 (2), pp. 756-762. , May; Socolinsky, D.A., Selinger, A., Neuheisel, J.D., Face recognition with visible and thermal infrared imagery (2003) Comput. Vis. Image Understand, 91 (1-2), pp. 72-114. , Jun./Aug; Chetty, G., Wagner, M., Biometric person authentication with liveness detection based on audio-visual fusion (2009) Int. J. Biometrics, 1 (4), pp. 463-478; Chetty, G., Biometric liveness checking using multimodal fuzzy fusion (2010) Proc IEEE Int. Conf. Fuzzy Syst., Barcelona, Spain, pp. 1-8. , Jul; Wang, T., Yang, J., Lei, Z., Liao, S., Li, S.Z., Face liveness detection using 3D structure recovered from a single camera (2013) Proc. ICB, Madrid, Spain, pp. 1-6. , Jun; Nilsson, M., Nordberg, J., Claesson, I., Face detection using local smqt features and split up snow classifier (2007) Proc IEEE Int. Conf. Acoust., Speech, Signal Process. (ICASSP, 2, pp. II589-II592. , Apr; Ahonen, T., Hadid, A., Pietikäinen, M., Face recognition with local binary patterns (2004) Proc. 8th Eur. Conf. Comput. Vis., Prague, Czech Republic, pp. 469-481. , May; Basri, R., Jacobs, D.W., Lambertian reflectance and linear subspaces (2003) IEEE Trans. Pattern Anal. Mach. Intell, 25 (2), pp. 218-233. , Feb; Liu, P., Zafar, F., Badano, A., The effect of ambient illumination on handheld display image quality (2014) J. Digit. Imag, 27 (1), pp. 12-18. , Feb; (2017) Microsoft Webcam: LifeCam Studio | Microsoft Accessories, , https://www.microsoft.com/accessories/en-us/products/webcams/lifecamstudio/q2f-00013, Accessed: Oct 12; (2017) F60M External Flash for Multi-Interface Shoe | HVL-F60M | Sony US, , https://www.sony.com/electronics/interchangeable-lens-cameras-flashes-lights/hvl-f60m, Accessed: Oct 12; (2017) F43M External Flash for Multi-Interface Shoe | HVL-F43M | Sony US, 12. , https://www.sony.com/electronics/interchangeable-lens-cameras-flashes-lights/hvl-f43m, Accessed: Oct; (2017) Seek CompactXR-Android, , http://obtain.thermal.com/product-p/ut-Aaa.htm, Accessed: Oct 12; Chang, C.-C., Lin, C.-J., LIBSVM: A library for support vector machines (2011) ACM Trans. Intell. Syst. Technol, 2 (3), pp. 271-2727","Zhang, F.; College of Computer and Information Engineering, China; email: zhangfei@htu.edu.cn",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,15566013,,,,"English","IEEE Trans. Inf. Forensics Secur.",Article,"Final","",Scopus,2-s2.0-85030768411
"Zhang Y., Xiang Y., Wang T., Wu W., Shen J.","54890205800;57114147900;56336387000;56562081200;55964982500;","An over-the-air key establishment protocol using keyless cryptography",2018,"Future Generation Computer Systems","79",,,"284","294",,9,"10.1016/j.future.2016.12.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009384653&doi=10.1016%2fj.future.2016.12.013&partnerID=40&md5=e06456ba0bb2b2bb088c02c283bf59bf","Centre for Cyber Security Research, Deakin University, Geelong, VIC 3220, Australia; The State Key Laboratory of Integrated Services Networks, Xidian University, China; University of South Florida, Tampa, FL  33620, United States; Fujian Provincial Key Laboratory of Network Security and Cryptology, School of Mathematics and Computer Science, Fujian Normal University, Fuzhou, China; School of Computer and Software, Nanjing University of Information Science and Technology, Nanjing, China","Zhang, Y., Centre for Cyber Security Research, Deakin University, Geelong, VIC 3220, Australia, The State Key Laboratory of Integrated Services Networks, Xidian University, China; Xiang, Y., Centre for Cyber Security Research, Deakin University, Geelong, VIC 3220, Australia, The State Key Laboratory of Integrated Services Networks, Xidian University, China; Wang, T., University of South Florida, Tampa, FL  33620, United States; Wu, W., Fujian Provincial Key Laboratory of Network Security and Cryptology, School of Mathematics and Computer Science, Fujian Normal University, Fuzhou, China; Shen, J., School of Computer and Software, Nanjing University of Information Science and Technology, Nanjing, China","Today, an increasing number of devices wirelessly communicate with each other. However, due to the nature of wireless transmission, the communications are vulnerable to many adversarial attacks such as eavesdropping. Key establishment is one of the fundamental and widely studied countermeasures for securing the communications. In certain applications, the wireless devices may be energy-constrained, such as sensor nodes. Thus, energy intensive asymmetric key establishment protocols are infeasible. Additionally, in some scenarios, it is not practical to assume that all the devices pre-share certain secrets. Motivated by these observations, this paper presents an over-the-air key establishment protocol using keyless cryptography. Specifically, the proposed protocol is designed without using asymmetric key cryptography and pre-shared secrets. More specifically, our protocol provides a concrete construction to transform the wireless channel into an anonymous channel, and two wireless devices can establish a secret key by directly sending random signals to each other. The performance analysis shows that the energy consumption of our protocol is around 176 times cheaper than that of the Diffie–Hellman key exchange protocol. Additionally, it takes only 159.04 ms to establish a key with 112 secret bits. © 2016 Elsevier B.V.","Anonymous channel; Key establishment; Security; Source indistinguishability","Energy utilization; Sensor nodes; Anonymous channel; Asymmetric key cryptography; Diffie-Hellman key exchange protocol; Indistinguishability; Key establishment protocol; Key establishments; Security; Wireless transmissions; Cryptography",,,,,"Chen, P., Desmet, L., Huygens, C., A study on advanced persistent threats (2014) Communications and Multimedia Security - 15th IFIP TC 6/TC 11 International Conference, CMS 2014, Aveiro, Portugal, September 25–26, 2014. Proceedings, Lecture Notes in Computer Science, 8735, pp. 63-72. , B.D. Decker A. Zúquete Springer; Brewer, R., Advanced persistent threats: Minimising the damage (2014) Netw. Secur., 2014, pp. 5-9; Diffie, W., Hellman, M.E., New directions in cryptography (1976) IEEE Trans. Inf. Theory, 22, pp. 644-654; Eschenauer, L., Gligor, V.D., A key-management scheme for distributed sensor networks (2002) Proceedings of the 9th ACM Conference on Computer and Communications Security, CCS 2002, Washington, DC, USA, November 18–22, 2002, pp. 41-47. , V. Atluri ACM; Chan, H., Perrig, A., Song, D.X., Random key predistribution schemes for sensor networks (2003) 2003 IEEE Symposium on Security and Privacy (S&P 2003), 11–14 May 2003, Berkeley, CA, USA, p. 197. , IEEE Computer Society; Wang, T., Liu, Y., Vasilakos, A.V., Survey on channel reciprocity based key establishment techniques for wireless systems (2015) Wirel. Netw., 21, pp. 1835-1846; Zhang, J., Duong, T.Q., Marshall, A.J., Woods, R.F., Key generation from wireless channels: A review (2016) IEEE Access, 4, pp. 614-626; Alpern, B., Schneider, F.B., Key exchange using ‘keyless cryptography’ (1983) Inform. Process. Lett., 16, pp. 79-81; Yung, M.M., A secure and useful keyless cryptosystem (1985) Inform. Process. Lett., 21, pp. 35-38; Castelluccia, C., Mutaf, P., Shake them up!: A movement-based pairing protocol for CPU-constrained devices (2005) Proceedings of the 3rd International Conference on Mobile Systems, Applications, and Services, MobiSys 2005, Seattle, Washington, USA, June 6–8, 2005, pp. 51-64. , K.G. Shin D. Kotz B.D. Noble ACM; Pietro, R.D., Oligeri, G., COKE crypto-less over-the-air key establishment (2013) IEEE Trans. Inf. Forensics Secur., 8, pp. 163-173; Pietro, R.D., Oligeri, G., ESC: An efficient, scalable, and crypto-less solution to secure wireless networks (2015) Comput. Netw., 84, pp. 46-63; Haselsteiner, E., Breitfuß, K., Security in near field communication (NFC) Workshop on RFID Security RFIDSec; Allah, M.M.A., Strengths and weaknesses of near field communication (NFC) technology (2011) Glob. J. Comput. Sci. Technol., 11; Choi, J.I., Jain, M., Srinivasan, K., Levis, P., Katti, S., Achieving single channel, full duplex wireless communication (2010) Proceedings of the 16th Annual International Conference on Mobile Computing and Networking, MOBICOM 2010, Chicago, Illinois, USA, September 20–24, 2010, pp. 1-12. , N.H. Vaidya S. Banerjee D. Katabi ACM; Jain, M., Choi, J.I., Kim, T., Bharadia, D., Seth, S., Srinivasan, K., Levis, P., Sinha, P., Practical, real-time, full duplex wireless (2011) Proceedings of the 17th Annual International Conference on Mobile Computing and Networking, MOBICOM 2011, Las Vegas, Nevada, USA, September 19–23, 2011, pp. 301-312. , P. Ramanathan T. Nandagopal B.N. Levine ACM; Jin, R., Du, X., Deng, Z., Zeng, K., Xu, J., Practical secret key agreement for full-duplex near field communications (2014) 9th ACM Symposium on Information, Computer and Communications Security, ASIA CCS ’14, Kyoto, Japan - June 03–06, 2014, pp. 217-228. , S. Moriai T. Jaeger K. Sakurai ACM; Bharadia, D., McMilin, E., Katti, S., Full duplex radios (2013) ACM SIGCOMM 2013 Conference, SIGCOMM’13, Hong Kong, China, August 12–16, 2013, pp. 375-386. , D.M. Chiu J. Wang P. Barford S. Seshan ACM; Zeng, K., Physical layer key generation in wireless networks: Challenges and opportunities (2015) IEEE Commun. Mag., 53, pp. 33-39; Patwari, N., Kasera, S.K., Robust location distinction using temporal link signatures (2007) Proceedings of the 13th Annual International Conference on Mobile Computing and Networking, MOBICOM 2007, Montréal, Québec, Canada, September 9–14, 2007, pp. 111-122. , E. Kranakis J.C. Hou R. Ramanathan ACM; He, X., Dai, H., Shen, W., Ning, P., Is link signature dependable for wireless security? (2013) Proceedings of the IEEE INFOCOM 2013, Turin, Italy, April 14–19, 2013, pp. 200-204. , IEEE; Gerdes, R.M., Daniels, T.E., Mina, M., Russell, S., Device identification via analog signal fingerprinting: A matched filter approach (2006) Proceedings of the Network and Distributed System Security Symposium, NDSS 2006, , The Internet Society San Diego, California, USA; Danev, B., Luecken, H., Capkun, S., Defrawy, K.M.E., Attacks on physical-layer identification (2010) Proceedings of the Third ACM Conference on Wireless Network Security, WISEC 2010, Hoboken, New Jersey, USA, March 22–24, 2010, pp. 89-98. , S. Wetzel C. Nita-Rotaru F. Stajano ACM; Danev, B., Zanetti, D., Capkun, S., On physical-layer identification of wireless devices (2012) ACM Comput. Surv., 45, p. 6; (2011), pp. 1-314. , IEEE standard for local and metropolitan area networks–part 15.4: Low-rate wireless personal area networks (LR-WPANs), IEEE Std 802.15.4-2011 (Revision of IEEE Std 802.15.4-2006); Pelechrinis, K., Iliofotou, M., Krishnamurthy, S.V., Denial of service attacks in wireless networks: The case of jammers (2011) IEEE Commun. Surv. Tutor., 13, pp. 245-257; Rasmussen, K.B., Capkun, S., Implications of radio fingerprinting on the security of sensor networks (2007) Third International Conference on Security and Privacy in Communication Networks and the Workshops, SecureComm 2007, Nice, France, 17–21 September, 2007, pp. 331-340. , IEEE; Lauwens, B., Scheers, B., de Capelle, A.V., Performance analysis of unslotted CSMA/CA in wireless networks (2010) Telecommun. Syst., 44, pp. 109-123; Karlof, C., Sastry, N., Wagner, D., Tinysec: A link layer security architecture for wireless sensor networks (2004) Proceedings of the 2nd International Conference on Embedded Networked Sensor Systems, SenSys 2004, Baltimore, MD, USA, November 3–5, 2004, pp. 162-175. , J.A. Stankovic A. Arora R. Govindan ACM; Menezes, A., van Oorschot, P.C., Vanstone, S.A., Handbook of Applied Cryptography (1996), CRC Press","Wu, W.; Fujian Provincial Key Laboratory of Network Security and Cryptology, China; email: weiwu@fjnu.edu.cn",,,"Elsevier B.V.",,,,,0167739X,,FGCSE,,"English","Future Gener Comput Syst",Article,"Final","",Scopus,2-s2.0-85009384653
"Rozsa A., Günther M., Boult T.E.","57023748000;27867634700;35561535500;","LOTS about attacking deep features",2018,"IEEE International Joint Conference on Biometrics, IJCB 2017","2018-January",,,"168","176",,13,"10.1109/BTAS.2017.8272695","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046253892&doi=10.1109%2fBTAS.2017.8272695&partnerID=40&md5=cb2ab6a91fa0af980ee55b543b23b8a6","Vision and Security Technology (VAST) Lab, University of Colorado, Colorado Springs, United States","Rozsa, A., Vision and Security Technology (VAST) Lab, University of Colorado, Colorado Springs, United States; Günther, M., Vision and Security Technology (VAST) Lab, University of Colorado, Colorado Springs, United States; Boult, T.E., Vision and Security Technology (VAST) Lab, University of Colorado, Colorado Springs, United States","Deep neural networks provide state-of-the-art performance on various tasks and are, therefore, widely used in real world applications. DNNs are becoming frequently utilized in biometrics for extracting deep features, which can be used in recognition systems for enrolling and recognizing new individuals. It was revealed that deep neural networks suffer from a fundamental problem, namely, they can unexpectedly misclassify examples formed by slightly perturbing correctly recognized inputs. Various approaches have been developed for generating these so-called adversarial examples, but they aim at attacking end-to-end networks. For biometrics, it is natural to ask whether systems using deep features are immune to or, at least, more resilient to attacks than end-to-end networks. In this paper, we introduce a general technique called the layerwise origin-target synthesis (LOTS) that can be efficiently used to form adversarial examples that mimic the deep features of the target. We analyze and compare the adversarial robustness of the end-to-end VGG Face network with systems that use Euclidean or cosine distance between gallery templates and extracted deep features. We demonstrate that iterative LOTS is very effective and show that systems utilizing deep features are easier to attack than the end-to-end network. © 2017 IEEE.",,"Biometrics; Iterative methods; End to end; End-to-end network; Euclidean; Layer-wise; Real-world; Recognition systems; State-of-the-art performance; Deep neural networks",,,,,"Chen, J.-C., Patel, V.M., Chellappa, R., Unconstrained face verification using deep CNN features (2016) Winter Conference On Applications of Computer Vision (WACV), , IEEE,. 2; Doddington, G.R., Liggett, W., Martin, A.F., Przybocki, M.A., Reynolds, D.A., Sheep, goats, lambs and wolves: A statistical analysis of speaker performance in the NIST 1998 speaker recognition evaluation (1998) International Conference On Spoken Language Processing (ICSPL), , 5, 6; Donahue, J., Jia, Y., Vinyals, O., Hoffman, J., Zhang, N., Tzeng, E., Darrell, T., DeCAF: A deep convolutional activation feature for generic visual recognition (2014) International Conference On Machine Learning (ICML), , 1; Evangelidis, G.D., Psarakis, E.Z., Parametric image alignment using enhanced correlation coefficient maximization (2008) Transactions On Pattern Analysis and Machine Intelligence (TPAMI), 30 (10). , 4; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference On Learning Representation (ICLR), , 2, 3; Günther, M., El Shafey, L., Marcel, S., (2016) Face Recognition Across the Imaging Spectrum, Chapter Face Recognition in Challenging Environments: An Experimental and Reproducible Research Survey, , Springer, 1 edition,. 2; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Conference On Computer Vision and Pattern Recognition (CVPR)., , IEEE,. 1; Jafri, R., Arabnia, H.R., A survey of face recognition techniques (2009) Journal of Information Processing Systems (JIPS), 5 (2). , 2; Klare, B.F., Klein, B., Taborsky, E., Blanton, A., Cheney, J., Allen, K., Grother, P., Jain, A.K., Pushing the frontiers of unconstrained face detection and recognition: IARPA Janus benchmark A (2015) Conference On Computer Vision and Pattern Recognition (CVPR), , IEEE,. 2; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial machine learning at scale (2017) International Conference On Learning Representation (ICLR), , 2; Liu, Z., Luo, P., Wang, X., Tang, X., Deep learning face attributes in the wild (2015) International Conference On Computer Vision (ICCV), , IEEE,. 1; O'Toole, A.J., Phillips, P.J., Jiang, F., Ayyad, J., Penard, N., Abdi, H., Face recognition algorithms surpass humans matching faces over changes in illumination (2007) Transactions On Pattern Analysis and Machine Intelligence (TPAMI), 29. , 2; Parkhi, O.M., Vedaldi, A., Zisserman, A., Deep face recognition (2015) British Machine Vision Conference (BMVC), , 1, 2, 3, 8; Ranjan, R., Castillo, C.D., Chellappa, R., L2-constrained Softmax Loss for Discriminative Face Verification, 2017, , under review; arXiV preprint:. 2; Razavian, A.S., Azizpour, H., Sullivan, J., Carlsson, S., CNN features off-the-shelf: An astounding baseline for recognition (2014) Conference On Computer Vision and Pattern Recognition (CVPR) Workshops, , IEEE,. 1; Rozsa, A., Rudd, E.M., Boult, T.E., Adversarial diversity and hard positive generation (2016) Conference On Computer Vision and Pattern Recognition (CVPR) Workshops, , IEEE,. 2, 3, 4, 5; Sabour, S., Cao, Y., Faghri, F., Fleet, D.J., Adversarial manipulation of deep representations (2016) International Conference On Learning Representation (ICLR), , 2, 4; Sankaranarayanan, S., Alavi, A., Castillo, C.D., Chellappa, R., Triplet probabilistic embedding for face verification and clustering (2016) Biometrics Theory, Applications and Systems (BTAS), , IEEE,. 8; Schroff, F., Kalenichenko, D., Philbin, J., FaceNet: A unified embedding for face recognition and clustering (2015) Conference On Computer Vision and Pattern Recognition (CVPR), , IEEE,. 1; Serrano, Á., De Diego, I.M., Conde, C., Cabello, E., Recent advances in face biometrics with Gabor wavelets: A review (2010) Pattern Recognition Letters, 31 (5). , 2; Sun, Y., Chen, Y., Wang, X., Tang, X., Deep learning face representation by joint identification-verification (2014) Neural Information Processing Systems (NIPS), , 2; Sun, Y., Wang, X., Tang, X., Deep learning face representation from predicting 10,000 classes (2014) Conference On Computer Vision and Pattern Recognition (CVPR), , IEEE,. 1; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) Conference On Computer Vision and Pattern Recognition (CVPR)., , IEEE, 1; Szegedy, C.J., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference On Learning Representation (ICLR), , 1, 2; Taigman, Y., Yang, M., Ranzato, M., Wolf, L., Deepface: Closing the gap to human-level performance in face verification (2014) Conference On Computer Vision and Pattern Recognition (CVPR), , IEEE,. 1, 2; Tan, X., Chen, S., Zhou, Z.-H., Zhang, F., Face recognition from a single image per person: A survey (2006) Pattern Recognition, 39. , 2; Wang, Z., Bovik, A.C., Sheikh, H.R., Simoncelli, E.P., Image quality assessment: From error visibility to structural similarity (2004) Transactions On Image Processing (TIP), 13 (4). , 4",,,"","Institute of Electrical and Electronics Engineers Inc.","2017 IEEE International Joint Conference on Biometrics, IJCB 2017","1 October 2017 through 4 October 2017",,134336,,9781538611241,,,"English","IEEE Int. Jt. Conf. Biom., IJCB",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85046253892
"Kohli N., Yadav D., Vatsa M., Singh R., Noore A.","55545940600;25957802100;55908650100;15061841400;6701728917;","Synthetic iris presentation attack using iDCGAN",2018,"IEEE International Joint Conference on Biometrics, IJCB 2017","2018-January",,,"674","680",,12,"10.1109/BTAS.2017.8272756","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046252639&doi=10.1109%2fBTAS.2017.8272756&partnerID=40&md5=d118183d1800dc81550099efd92f6649","West Virginia University, United States; IIIT Delhi, India","Kohli, N., West Virginia University, United States; Yadav, D., West Virginia University, United States; Vatsa, M., West Virginia University, United States, IIIT Delhi, India; Singh, R., West Virginia University, United States, IIIT Delhi, India; Noore, A., IIIT Delhi, India","Reliability and accuracy of iris biometric modality has prompted its large-scale deployment for critical applications such as border control and national ID projects. The extensive growth of iris recognition systems has raised apprehensions about susceptibility of these systems to various attacks. In the past, researchers have examined the impact of various iris presentation attacks such as textured contact lenses and print attacks. In this research, we present a novel presentation attack using deep learning based synthetic iris generation. Utilizing the generative capability of deep con-volutional generative adversarial networks and iris quality metrics, we propose a new framework, named as iDCGAN (iris deep convolutional generative adversarial network) for generating realistic appearing synthetic iris images. We demonstrate the effect of these synthetically generated iris images as presentation attack on iris recognition by using a commercial system. The state-of-the-art presentation attack detection framework, DESIST is utilized to analyze if it can discriminate these synthetically generated iris images from real images. The experimental results illustrate that mitigating the proposed synthetic presentation attack is of paramount importance. © 2017 IEEE.",,"Deep learning; Adversarial networks; Attack detection; Commercial systems; Critical applications; Iris recognition; Iris recognition systems; Large-scale deployment; State of the art; Biometrics",,,,,"Bharadwaj, S., Vatsa, M., Singh, R., Biometric quality: A review of fingerprint, iris, and face (2014) EURASIP Journal on Image and Video Processing, 2014 (1), p. 34; Chen, X., Duan, Y., Houthooft, R., Schulman, J., Sutskever, I., Abbeel, P., InfoGAN: Interpretable representation learning by information maximizing generative adversarial nets (2016) Advances in Neural Information Processing Systems, pp. 2172-2180; Cui, J., Wang, Y., Huang, J., Tan, T., Sun, Z., An iris image synthesis method based on PCA and super-resolution (2004) International Conference on Pattern Recognition, pp. 471-474; Daugman, J., How iris recognition works (2004) IEEE Transactions on Circuits and Systems for Video Technology, 14 (1), pp. 21-30; Denton, E.L., Chintala, S., Fergus, R., Deep generative image models using a Laplacian pyramid of adversarial networks (2015) Advances in Neural Information Processing Systems, pp. 1486-1494; Galbally, J., Ross, A., Gomez-Barrero, M., Fierrez, J., Ortega-Garcia, J., Iris image reconstruction from binary templates: An efficient probabilistic approach based on genetic algorithms (2013) Computer Vision and Image Understanding, 117 (10), pp. 1512-1525; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, pp. 2672-2680; Gupta, P., Behera, S., Vatsa, M., Singh, R., On iris spoofing using print attack (2014) International Conference on Pattern Recognition, pp. 1681-1686; Information Technology-Biometric Sample Quality, , Standard ISO/IEC 29794-6:2015-Part 6-Iris image data; Kalka, N.D., Zuo, J., Schmid, N.A., Cukic, B., Image quality assessment for iris biometric (2006) Defense and Security Symposium, p. 62020D. , International Society for Optics and Photonics; Kingma, D.P., Welling, M., Auto-encoding variational bayes (2013) International Conference on Learning Representations, (2014), pp. 1-14; Kohli, N., Yadav, D., Vatsa, M., Singh, R., Revisiting iris recognition with color cosmetic contact lenses (2013) International Conference on Biometrics, pp. 1-7; Kohli, N., Yadav, D., Vatsa, M., Singh, R., Noore, A., Detecting medley of iris spoofing attacks using DESIST (2016) IEEE International Conference on Biometrics Theory, Applications and Systems, pp. 1-6; Kumar, A., Passi, A., Comparison and combination of iris matchers for reliable personal authentication (2010) Pattern Recognition, 43 (3), pp. 1016-1026; Ledig, C., Theis, L., Huszar, F., Caballero, J., Aitken, A.P., Tejani, A., Totz, J., Shi, W., Photo-realistic single image super-resolution using a generative adversarial network (2016) CoRR, ABS1609.04802; Mirza, M., Osindero, S., Conditional generative adversarial nets (2014) CoRR, ABS1411.1784; Radford, A., Metz, L., Chintala, S., Unsupervised representation learning with deep convolutional generative adversarial networks (2015) CoRR, ABS1511.06434; Ratha, N.K., Connell, J.H., Bolle, R.M., Enhancing security and privacy in biometrics-based authentication systems (2001) IBM Systems Journal, 40 (3), pp. 614-634; Shah, S., Ross, A., Generating synthetic irises by feature agglomeration (2006) IEEE International Conference on Image Processing, pp. 317-320; Shrivastava, A., Pfister, T., Tuzel, O., Susskind, J., Wang, W., Webb, R., Learning from simulated and unsupervised images through adversarial training (2017) IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-10; Vatsa, M., Singh, R., Noore, A., Improving iris recognition performance using segmentation, quality enhancement, match score fusion, and indexing (2008) IEEE Transactions on Systems, Man, and Cybernetics, Part B, 38 (4), pp. 1021-1035; http://www.neurotechnology.com/verieye.html; Wang, X., Gupta, A., Generative image modeling using style and structure adversarial networks (2016) European Conference on Computer Vision, pp. 318-335; Yadav, D., Kohli, N., Doyle, J.S., Singh, R., Vatsa, M., Bowyer, K.W., Unraveling the effect of textured contact lenses on iris recognition (2014) IEEE Transactions on Information Forensics and Security, 9 (5), pp. 851-862; Yeh, R., Chen, C., Lim, T., Hasegawa-Johnson, M., Do, M.N., Semantic image inpainting with perceptual and contextual losses (2016) CoRR, ABS1607.07539; Zuo, J., Schmid, N.A., Chen, X., On generation and analysis of synthetic iris images (2007) IEEE Transactions on Information Forensics and Security, 2 (1), pp. 77-90",,,"","Institute of Electrical and Electronics Engineers Inc.","2017 IEEE International Joint Conference on Biometrics, IJCB 2017","1 October 2017 through 4 October 2017",,134336,,9781538611241,,,"English","IEEE Int. Jt. Conf. Biom., IJCB",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85046252639
"Yan J., Ren X., Mo Y.","57200184357;56337887100;26422460300;","Sequential detection in adversarial environment",2018,"2017 IEEE 56th Annual Conference on Decision and Control, CDC 2017","2018-January",,,"170","175",,3,"10.1109/CDC.2017.8263661","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046263611&doi=10.1109%2fCDC.2017.8263661&partnerID=40&md5=bbae84ae954000ae2502037b31747957","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore","Yan, J., School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Ren, X., School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Mo, Y., School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore","In this paper, we consider the problem of sequential detection with m sensors in adversarial environment. An attacker intends to increase the detection error by modifying n out of m sensors' measurements. On the other hand, the detector needs to be designed to achieve the optimal performance during the attack. The problem is formulated as a game between detector and adversary in this paper. We study both cases where m > 2n and m ≤ 2n, and obtain an equilibrium strategy pair of detection rule and attack scheme for both cases. Furthermore, we investigate the efficiency of our proposed detection strategy in the absence of attacker. © 2017 IEEE.",,"Adversarial environments; Detection error; Detection rules; Equilibrium strategy; Optimal performance; Sequential detection; Control engineering",,,,,"Ding, J.-Y., You, K., Song, S., Wu, C., Likelihood ratio based scheduler for secure detection in cyber physical systems (2017) IEEE Transactions on Control of Network Systems; Cardenas, A.A., Amin, S., Sastry, S., Secure control: Towards survivable cyber-physical systems (2008) Distributed Computing Systems Workshops, pp. 495-500. , 2008. ICDCS'08. 28th International Conference on. IEEE; Gibbons, R., (1992) A Primer in Game Theory, , Harvester Wheatsheaf; Reinhard, D., Fauß, M., Zoubir, A.M., An approach to joint sequential detection and estimation with distributional uncertainties (2016) Signal Processing Conference (EUSIPCO), pp. 2201-2205. , 24th European. IEEE, 2016; Bayat, F., Wei, S., Sequential detection of disjoint subgraphs over boolean mac channels: A probabilistic approach (2016) Globecom Workshops (GC Wkshps), pp. 1-6. , 2016 IEEE. IEEE; Wald, A., Wolfowitz, J., Optimum character of the sequential probability ratio test (1948) The Annals of Mathematical Statistics, pp. 326-339; Lu, R., Lin, X., Zhu, H., Liang, X., Shen, X., Becan: A bandwidthefficient cooperative authentication scheme for filtering injected false data in wireless sensor networks (2012) IEEE Transactions on Parallel and Distributed Systems, 23 (1), pp. 32-43; Marburger, J.H., Kvamme, E.F., Scalise, G., Reed, D.A., Leadership under challenge: Information technology r&d in a competitive world. An assessment of the federal networking and information technology r&d program (2007) DTIC Document, Tech. Rep; Bayram, S., Gezici, S., On the restricted neyman-pearson approach for composite hypothesis-testing in presence of prior distribution uncertainty (2011) IEEE Transactions on Signal Processing, 59 (10), pp. 5056-5065; Mo, Y., Hespanha, J.P., Sinopoli, B., Resilient detection in the presence of integrity attacks (2014) IEEE Transactions on Signal Processing, 62 (1), pp. 31-43; Vamvoudakis, K.G., Hespanha, J.P., Sinopoli, B., Mo, Y., Detection in adversarial environments (2014) IEEE Transactions on Automatic Control, 59 (12), pp. 3209-3223; Chernoff, H., A measure of asymptotic efficiency for tests of a hypothesis based on the sum of observations (1952) The Annals of Mathematical Statistics, pp. 493-507; Schmock, U., Large deviations techniques and applications (2000) Journal of the American Statistical Association, 95 (452), p. 1380; Berger, J.O., (1985) Statistical Decision Theory and Bayesian Analysis",,,"ANCA Motion;City of Melbourne;Mathworks;The University of Melbourne;The University of Newcastle;United Technologies Research Center (UTRC)","Institute of Electrical and Electronics Engineers Inc.","56th IEEE Annual Conference on Decision and Control, CDC 2017","12 December 2017 through 15 December 2017",,133780,,9781509028733,,,"English","IEEE Annu. Conf. Decis. Control, CDC",Conference Paper,"Final","",Scopus,2-s2.0-85046263611
"Showkatbakhsh M., Shoukry Y., Chen R.H., Diggavi S., Tabuada P.","55640653000;35776891900;7406313050;7003736362;6603754297;","An SMT-based approach to secure state estimation under sensor and actuator attacks",2018,"2017 IEEE 56th Annual Conference on Decision and Control, CDC 2017","2018-January",,,"157","162",,4,"10.1109/CDC.2017.8263659","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046261293&doi=10.1109%2fCDC.2017.8263659&partnerID=40&md5=f5ad0a93c39b57e00d097e52f49bd1c5","UCLA Electrical Engineering Department, Los Angeles, CA, United States; NG Next, Redondo Beach, CA, United States; Department of Electrical and Computer Engineering, University of Maryland, College Park, MD, United States","Showkatbakhsh, M., UCLA Electrical Engineering Department, Los Angeles, CA, United States; Shoukry, Y., Department of Electrical and Computer Engineering, University of Maryland, College Park, MD, United States; Chen, R.H., NG Next, Redondo Beach, CA, United States; Diggavi, S., UCLA Electrical Engineering Department, Los Angeles, CA, United States; Tabuada, P., UCLA Electrical Engineering Department, Los Angeles, CA, United States","This paper addresses the problem of state estimation of a linear time-invariant system when some of the sensors or/and actuators are under adversarial attack. In our set-up, the adversarial agent attacks a sensor (actuator) by manipulating its measurement (input), and we impose no constraint on how the measurements (inputs) are corrupted. We introduce the notion of 'sparse strong observability' to characterize systems for which the state estimation is possible, given bounds on the number of attacked sensors and actuators. Furthermore, we develop a secure state estimator based on Satisfiability Modulo Theory (SMT) solvers. © 2017 IEEE.",,"Actuators; Invariance; Linear systems; Time varying control systems; Adversarial agent; Linear time invariant systems; Satisfiability modulo Theories; Sensor and actuators; Sensors and actuators; State Estimators; Strong observabilities; State estimation",,,,,"Langner, R., Stuxnet: Dissecting a cyberwarfare weapon (2011) IEEE Security & Privacy, 9 (3), pp. 49-51; Greenberg, A., (2015) Hackers Remotely Kill a Jeep on the Highway, with Me in It, , http://www.wired.com/2015/07/hackers-remotelykill-jeep-highway, [online]; Kelion, L., (2016) Nissan Leaf Electric Cars Hack Vulnerability Disclosed, , http://www.bbc.com/news/technology-35642749, [online]; Ćardenas, A.A., Amin, S., Sastry, S., Research challenges for the security of control systems (2008) HotSec; Sundaram, S., Pajic, M., Hadjicostis, C.N., Mangharam, R., Pappas, G.J., The wireless control network: Monitoring for malicious behavior (2010) 49th IEEE Conference on Decision and Control (CDC), pp. 5979-5984; Amin, S., Schwartz, G.A., Hussain, A., In quest of benchmarking security risks to cyber-physical systems (2013) IEEE Network, 27 (1), pp. 19-24; Mo, Y., Kim, T.H.-J., Brancik, K., Dickinson, D., Lee, H., Perrig, A., Sinopoli, B., Cyber-physical security of a smart grid infrastructure (2012) Proceedings of the IEEE, 100 (1), pp. 195-209; Zhu, M., Martinez, S., On the performance analysis of resilient networked control systems under replay attacks (2014) IEEE Transactions on Automatic Control, 59 (3), pp. 804-808; Persis, C.D., Tesi, P., Input-to-state stabilizing control under denial-of-service (2015) IEEE Transactions on Automatic Control, 60 (11), pp. 2930-2944; Senejohnny, D., Tesi, P., Persis, C.D., (2016) A Jamming-resilient Algorithm for Self-triggered Network Coordination, , arXiv preprint arXiv:1603.02563; Gupta, A., Langbort, C., Basar, T., Optimal control in the presence of an intelligent jammer with limited actions (2010) 49th IEEE Conference on Decision and Control (CDC), pp. 1096-1101; Mo, Y., Sinopoli, B., Secure control against replay attacks (2009) 47th Annual Allerton Conference on Communication, Control, and Computing, pp. 911-918. , IEEE; Smith, R.S., Covert misappropriation of networked control systems: Presenting a feedback structure (2015) Control Systems Magazine, 35 (1), pp. 82-92. , IEEE; Mo, Y., Garone, E., Casavola, A., Sinopoli, B., False data injection attacks against state estimation in wireless sensor networks (2010) N 49th IEEE Conference on Decision and Control (CDC), pp. 5967-5972; Fawzi, H., Tabuada, P., Diggavi, S., Secure estimation and control for cyber-physical systems under adversarial attacks (2014) IEEE Transactions on Automatic Control, 59 (6), pp. 1454-1467; Shoukry, Y., Tabuada, P., Event-triggered state observers for sparse sensor noise/attacks (2016) IEEE Transactions on Automatic Control, 61 (8), pp. 2079-2091; Chong, M.S., Wakaiki, M., Hespanha, J.P., Observability of linear systems under adversarial attacks (2015) American Control Conference (ACC), pp. 2439-2444; Nakahira, Y., Mo, Y., Dynamic state estimation in the presence of compromised sensory data (2015) 54th Annual Conference on Decision and Control (CDC), pp. 5808-5813. , IEEE; Mishra, S., Shoukry, Y., Karamchandani, N., Diggavi, S., Tabuada, P., Secure state estimation: Optimal guarantees against sensor attacks in the presence of noise (2017) IEEE Transactions on Control of Network Systems, 4 (1), pp. 49-59; Shoukry, Y., Nuzzo, P., Puggelli, A., Sangiovanni-Vincentelli, A.L., Seshia, S.A., Tabuada, P., Secure state estimation for cyber physical systems under sensor attacks: A satisfiability modulo theory approach (2017) IEEE Transactions on Automatic Control, , To be appeared on; Yong, S.Z., Foo, M.Q., Frazzoli, E., Robust and resilient estimation for cyber-physical systems under adversarial attacks (2016) American Control Conference (ACC), pp. 308-315. , IEEE; Pajic, M., Weimer, J., Bezzo, N., Tabuada, P., Sokolsky, O., Lee, I., Pappas, G.J., Robustness of attack-resilient state estimators (2014) ICCPS'14: ACM/IEEE 5th International Conference on Cyber- Physical Systems (With CPS Week 2014), pp. 163-174; Tiwari, A., Dutertre, B., Jovanovíc, D., Candia, T.D., Lincoln, P.D., Rushby, J., Sadigh, D., Seshia, S., Safety envelope for security (2014) ACM Proceedings of the 3rd International Conference on High Confidence Networked Systems, pp. 85-94; Showkatbakhsh, M., Tabuada, P., Diggavi, S., System identification in the presence of adversarial outputs (2016) Decision and Control (CDC), IEEE 55th Conference on, pp. 7177-7182. , IEEE; Showkatbakhsh, M., Tabuada, P., Diggavi, S., Secure system identification (2016) 54th Annual Allerton Conference on Communication, Control, and Computing, pp. 1137-1141. , IEEE; Blanke, M., Kinnaert, M., Lunze, J., Staroswiecki, M., Schröder, J., (2006) Diagnosis and Fault-tolerant Control, 691. , Springer; Jones, H.L., (1973) Failure Detection in Linear Systems, , PhD thesis, Massachusetts Institute of Technology; Harirchi, F., Ozay, N., (2016) Guaranteed Model-based Fault Detection in Cyber-physical Systems: A Model Invalidation Approach, , arXiv preprint arXiv:1609.05921; Pasqualetti, F., Dorfler, F., Bullo, F., Attack detection and identification in cyber-physical systems (2013) IEEE Transactions on Automatic Control, 58 (11), pp. 2715-2729; Sandberg, H., Teixeira, A.M., From control system security indices to attack identifiability (2016) Science of Security for Cyber-Physical Systems Workshop (SOSCYPS), pp. 1-6. , IEEE; Showkatbakhsh, M., Shoukry, Y., Chen, R.H., Diggavi, S., Tabuada, P., An SMT-based Approach to Secure State Estimation under Sensor and Actuator Attacks, , http://www.cyphylab.ee.ucla.edu/Home/publications, Technical Report UCLA-CyPhyLab-2017-02, 2017. Electronically; Yoshikawa, T., Bhattacharyya, S., Partial uniqueness: Observability and input identifiability (1975) IEEE Transactions on Automatic Control, 20 (5), pp. 713-714; Barrett, C.W., Sebastiani, R., Seshia, S.A., Tinelli, C., Satisfiability modulo theories (2009) Handbook of Satisfiability, 185, pp. 825-885; Berre, D.L., Parrain, A., The sat4j library, release 2.2, system description (2010) Journal on Satisfiability, Boolean Modeling and Computation, 7, pp. 59-64",,,"ANCA Motion;City of Melbourne;Mathworks;The University of Melbourne;The University of Newcastle;United Technologies Research Center (UTRC)","Institute of Electrical and Electronics Engineers Inc.","56th IEEE Annual Conference on Decision and Control, CDC 2017","12 December 2017 through 15 December 2017",,133780,,9781509028733,,,"English","IEEE Annu. Conf. Decis. Control, CDC",Conference Paper,"Final","",Scopus,2-s2.0-85046261293
"Chen K., Gupta V., Huang Y.-F.","57191619228;57201852777;7501575331;","Minimum variance unbiased estimation in the presence of an adversary",2018,"2017 IEEE 56th Annual Conference on Decision and Control, CDC 2017","2018-January",,,"151","156",,2,"10.1109/CDC.2017.8263658","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046258402&doi=10.1109%2fCDC.2017.8263658&partnerID=40&md5=8a0855cfd8b9903f914b979f75f2f66d","Department of Electrical Engineering, University of Notre DameIN  46556, United States","Chen, K., Department of Electrical Engineering, University of Notre DameIN  46556, United States; Gupta, V., Department of Electrical Engineering, University of Notre DameIN  46556, United States; Huang, Y.-F., Department of Electrical Engineering, University of Notre DameIN  46556, United States","Consider a setup in which a central estimator seeks to estimate an unknown deterministic parameter using measurements from multiple sensors. Some of the sensors may be adversarial in that their utility increases with the Euclidean distance between the estimate of the central estimator and their own local estimate. These sensors may misreport their measurements to the central estimator at a falsification cost. We formulate a Stackelberg game in which the central estimator acts as the leader and the adversarial sensors act as the follower. We present the optimal linear fusion scheme for the estimator and the optimal attack pattern for the adversarial sensors in the Nash equilibrium sense. Interestingly, the estimate at the central estimator may be better than if the measurements from the adversarial sensors were altogether ignored. © 2017 IEEE.",,"Attack patterns; Euclidean distance; Linear fusions; Minimum variance; Multiple sensors; Nash equilibria; Stackelberg Games; Unbiased estimation; Control engineering",,,,,"Gao, H., Liu, C.H., Wang, W., Zhao, J., Song, Z., Su, X., Crowcroft, J., Leung, K.K., A survey of incentive mechanisms for participartory sensing (2015) Communication Surveys & Tutorials, IEEE, 17 (2), pp. 918-943; Restuccia, F., Das, S.K., Payton, J., (2015) Incentive Mechanisms for Participatory Sensing: Survey and Research Challenges, , arXiv preprint arXiv:1502.07687; Reddy, S., Estrin, D., Hansen, M., Srivastava, M., Examining micropayments for participatory sensing data collections (2010) Proceedings of the 12th ACM International Conference on Ubiquitous Computing, pp. 33-36. , ACM; Zhang, Y., Schaar, M.V.D., Reputation-based incentive protocols in crowdsourcing application (2012) INFOCOM, 2012 Proceedings IEEE, pp. 2140-2148; Naghizadeh, P., Liu, M., (2013) Perceptions and Truth: A Mechanism Design Approach to Crowd-sourcing Reputation; Lee, J.-S., Hoh, B., Sell your experiences: A market mechanism based incentive for participatory sensing (2010) Pervasive Computing and Communications (PerCom), pp. 60-68. , 2010 IEEE International Conference on. IEEE; Lee, J.-S., Hoh, B., Dynamic pricing incentive for participatory sensing (2010) Pervasive and Mobile Computing, 6 (6), pp. 693-708; Chen, K., Gupta, V., Huang, Y.F., On auction design for crowd sensing (2016) 19th International Conference on Information Fusion (FUSION), pp. 334-339; Dobakhshari, D.G., Li, N., Gupta, V., An incentive-based approach to distributed estimation with strategic sensors (2016) Conference on Decision and Control (CDC), pp. 6141-6146. , 2016, IEEE; Bai, C.Z., Pasqualetti, F., Gupta, V., Security in stochastic control systems: Fundamental limitations and performance bounds (2015) American Control Conference (ACC), pp. 195-200. , 2015. IEEE; Bai, C.Z., Gupta, V., On Kalman filtering in the presence of a compromised sensor: Fundamental performance bounds (2014) American Control Conference (ACC), pp. 3029-3034. , 2014. IEEE; Amini, S., Pasqualetti, F., Mohsenian-Rad, H., Dynamic load altering attacks against power system stability: Attack models and protection schemes (2016) IEEE Trans. Smart Grid, , to appear; Mo, Y., Sinopoli, B., Secure estimation in the presence of integrity attacks (2015) IEEE Trans. Smart Automatic Control, 60 (4), pp. 1145-1151; Li, Y., Quevedo, D.E., Dey, S., Shi, L., SINR-based dos attack on remote state estimation: A game-theoretic approach (2016) IEEE Trans. Control Netw. Syst, , to appear; Maharjan, S., Zhu, Q., Zhang, Y., Gjessing, S., Basar, T., Dependable demand response management in the smart grid: A Stackelberg game approach (2013) IEEE Trans. Smart Grid, 4 (1), pp. 120-132; Wilson, C., Veeravalli, V., MMSE estimation in a sensor network in the presence of an adversary (2016) International Symposium on Information Theory (ISIT), pp. 2479-2483. , IEEE, 2016; Marano, S., Matta, V., Tong, L., Distributed detection in the presence of Byzantine attacks (2009) IEEE Trans. Signal Process., 57 (1), pp. 16-29; Leyton-Brown, K., Shoha, Y., Essentials of game theory: A consice multidisciplinary introduction (2008) Synthesis Lectures on Artificial Intelligence and Machine Learning, , ser. San Francisco, CA: Morgan Claypool Publ",,,"ANCA Motion;City of Melbourne;Mathworks;The University of Melbourne;The University of Newcastle;United Technologies Research Center (UTRC)","Institute of Electrical and Electronics Engineers Inc.","56th IEEE Annual Conference on Decision and Control, CDC 2017","12 December 2017 through 15 December 2017",,133780,,9781509028733,,,"English","IEEE Annu. Conf. Decis. Control, CDC",Conference Paper,"Final","",Scopus,2-s2.0-85046258402
"Yan Y., Xia M., Rahnama A., Antsaklis P.","56119110300;55760921900;55253410100;7005190857;","A passivity-based self-Triggered strategy for cyber physical systems under denial-of-service attack",2018,"2017 IEEE 56th Annual Conference on Decision and Control, CDC 2017","2018-January",,,"6082","6087",,5,"10.1109/CDC.2017.8264578","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046137180&doi=10.1109%2fCDC.2017.8264578&partnerID=40&md5=9ab4dce79f1354fd3288971f4bdcd4cd","Electrical Engineering Department, University of Notre Dame, Notre Dame, IN  46556, United States; MathWorks Inc., Natick, MA  01760, United States","Yan, Y., Electrical Engineering Department, University of Notre Dame, Notre Dame, IN  46556, United States; Xia, M., MathWorks Inc., Natick, MA  01760, United States; Rahnama, A., Electrical Engineering Department, University of Notre Dame, Notre Dame, IN  46556, United States; Antsaklis, P., Electrical Engineering Department, University of Notre Dame, Notre Dame, IN  46556, United States","Networked control systems are vulnerable to adversarial attacks, such as Denial-of-Service (DoS) attacks, which intend to jam control channels and hence degrade system performance. In this paper, we design a passivity-based mechanism that preserves the security level and control performance under time-varying delays and control packets dropouts. We develop a switching controller framework over an imperfect network and present a class of self-Triggered feedback control laws to mitigate DoS attacks with local information. By deducing the maximal tolerant period of each attack, the QSR-dissipativity and hence L2 stability is preserved under the proposed triggering conditions. © 2017 IEEE.",,"Control theory; Cyber Physical System; Embedded systems; Mobile telecommunication systems; Networked control systems; Time varying control systems; Control channels; Control packets; Control performance; Denial of Service; Feedback control law; Local information; Switching controllers; Time varying- delays; Denial-of-service attack",,,,,"Blumenthal, E., Weise, E., (2016) Hacked Home Devices Caused Massive Internet Outage, , http://www.usatoday.com/story/tech/2016/10/21/cyber-Attacktakes-down-east-coast-netflix-spotify-Twitter/92507806/, October (accessed February 23, 2017). [Online]; Networks, A., (2016) Worldwide Infrastructure Security Report, , https://www.arbornetworks.com/insight-into-The-global-Threatlandscape, (accessed February 23, 2017). [Online]; Yuan, Y., Zhu, Q., Sun, F., Wang, Q., Baar, T., Resilient control of cyber-physical systems against denial-of-service attacks (2013) 2013 6th International Symposium on Resilient Control Systems (ISRCS), pp. 54-59. , Aug; Li, Y., Shi, L., Cheng, P., Chen, J., Quevedo, D.E., Jamming attacks on remote state estimation in cyber-physical systems: A game-Theoretic approach (2015) IEEE Transactions on Automatic Control, 60 (10), pp. 2831-2836. , Oct; Senejohnny, D., Tesi, P., Persis, C.D., Self-Triggered coordination over a shared network under denial-of-service (2015) 2015 54th IEEE Conference on Decision and Control (CDC), pp. 3469-3474. , Dec; Lee, P., Clark, A., Bushnell, L., Poovendran, R., (2013) Modeling and Designing Network Defense Against Control Channel Jamming Attacks: A Passivity-Based Approach. Heidelberg, pp. 161-175. , Springer International Publishing; Lozano, R., Chopra, N., Spong, M., Passivation of force reflecting bilateral teleoperators with time varying delay (2002) Proceedings of the 8. Mechatronics Forum, pp. 24-26; Wang, Y., Xia, M., Gupta, V., Antsaklis, P.J., On feedback passivity of discrete-Time nonlinear networked control systems with packet drops (2015) IEEE Transactions on Automatic Control, 60 (9), pp. 2434-2439. , Sept; Willems, J.C., Dissipative dynamical systems part i: General theory (1972) Archive for Rational Mechanics and Analysis, 45 (5), pp. 321-351. , http://dx.doi.org/10.1007/BF00276493; Hill, D., Moylan, P., The stability of nonlinear dissipative systems (1976) IEEE Transactions on Automatic Control, 21 (5), pp. 708-711. , Oct; (2007) Dissipativity and Passivity, pp. 5-41. , London Springer London; Fettweis, A., Wave digital filters: Theory and practice (1986) Proceedings of the IEEE, 74 (2), pp. 270-327; McCourt, M.J., Antsaklis, P.J., Stability of networked passive switched systems (2010) 49th IEEE Conference on Decision and Control (CDC), pp. 1263-1268. , Dec; Yan, Y., Antsaklis, P., Stabilizing nonlinear model predictive control scheme based on passivity and dissipativity (2016) 2016 American Control Conference (ACC), pp. 4476-4481. , July; Xia, M., Antsaklis, P.J., Gupta, V., Passivity indices and passivation of systems with application to systems with input/output delay (2014) 53rd IEEE Conference on Decision and Control, pp. 783-788. , Dec; (2017) LMI Solvers, , http://www.usatoday.com/story/tech/2016/10/21/cyberattack-Takes-down-east-coast-netflix-spotify-Twitter/92507806/, (accessed March 11, 2017). [Online]. MathWorks; Pasqualetti, F., Zhu, Q., Design and operation of secure cyberphysical systems (2015) IEEE Embedded Systems Letters, 7 (1), pp. 3-6. , March; Meijaard, J., Papadopoulos, J.M., Ruina, A., Schwab, A., (2007) Linearized Dynamics Equations for the Balance and Steer of A Bicycle: A Benchmark and Review, 463 (2084), pp. 1955-1982",,,"ANCA Motion;City of Melbourne;Mathworks;The University of Melbourne;The University of Newcastle;United Technologies Research Center (UTRC)","Institute of Electrical and Electronics Engineers Inc.","56th IEEE Annual Conference on Decision and Control, CDC 2017","12 December 2017 through 15 December 2017",,133780,,9781509028733,,,"English","IEEE Annu. Conf. Decis. Control, CDC",Conference Paper,"Final","",Scopus,2-s2.0-85046137180
"Tzoumas V., Gatsis K., Jadbabaie A., Pappas G.J.","55533930600;36632196000;9636293200;57203254826;","Resilient monotone submodular function maximization",2018,"2017 IEEE 56th Annual Conference on Decision and Control, CDC 2017","2018-January",,,"1362","1367",,19,"10.1109/CDC.2017.8263844","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046135405&doi=10.1109%2fCDC.2017.8263844&partnerID=40&md5=cd075d5626968ed72304a3564e3fcb6e","Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA  19104-6228, United States; Institute for Data Systems and Society, Massachusetts Institute of Technology, Cambridge, MA  02139, United States","Tzoumas, V., Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA  19104-6228, United States; Gatsis, K., Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA  19104-6228, United States; Jadbabaie, A., Institute for Data Systems and Society, Massachusetts Institute of Technology, Cambridge, MA  02139, United States; Pappas, G.J., Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA  19104-6228, United States","In this paper, we focus on applications in machine learning, optimization, and control that call for the resilient selection of a few elements, e.g. features, sensors, or leaders, against a number of adversarial denial-of-service attacks or failures. In general, such resilient optimization problems are hard, and cannot be solved exactly in polynomial time, even though they often involve objective functions that are monotone and submodular. Notwithstanding, in this paper we provide the first scalable algorithm for their approximate solution, that is valid for any number of attacks or failures, and which, for functions with low curvature, guarantees superior approximation performance. Notably, the curvature has been known to tighten approximations for several non-resilient maximization problems, yet its effect on resilient maximization had hitherto been unknown. We complement our theoretical analyses with supporting empirical evaluations. © 2017 IEEE.",,"Denial-of-service attack; Learning systems; Polynomial approximation; Approximate solution; Approximation performance; Empirical evaluations; Maximization problem; Objective functions; Optimization problems; Scalable algorithms; Submodular functions; Approximation algorithms",,,,,"Krause, A., Singh, A., Guestrin, C., Near-optimal sensor placements in Gaussian processes: Theory, efficient algorithms and empirical studies (2008) J.l of Machine Learning Research, 9, pp. 235-284; Das, A., Kempe, D., Submodular meets spectral: Greedy algorithms for subset selection, sparse approximation and dictionary selection (2011) Proceedings of the 28th International Conference On Machine Learning, pp. 1057-1064; Clark, A., Alomair, B., Bushnell, L., Poovendran, R., (2016) Submodularity in Dynamics and Control of Networked Systems, , Springer; Olshevsky, A., Minimal controllability problems (2014) IEEE Transactions On Control of Network Systems, 1 (3), pp. 249-258; Pasqualetti, F., Zampieri, S., Bullo, F., Controllability metrics, limitations and algorithms for complex networks (2014) IEEE Transactions On Control of Network Systems, 1 (1), pp. 40-52. , March; Pequito, S., Kar, S., Aguiar, A., A framework for structural input/output and control configuration selection in large-scale systems (2016) IEEE Trans. On Automatic Control, 61 (2), pp. 303-318; Summers, T.H., Cortesi, F.L., Lygeros, J., On submodularity and controllability in complex dynamical networks (2016) IEEE Transactions On Control of Network Systems, 3 (1), pp. 91-101; Tzoumas, V., Rahimian, M.A., Pappas, G.J., Jadbabaie, A., Minimal actuator placement with bounds on control effort (2016) IEEE Trans. On Control of Network Systems, 3 (1), pp. 67-78; Nozari, E., Pasqualetti, F., Cortes, J., (2016) Time-varying Actuator Scheduling in Complex Networks, , arXiv preprint: 1611.06485; Jawaid, S.T., Smith, S.L., Submodularity and greedy algorithms in sensor scheduling for linear dynamical systems (2015) Automatica, 61, pp. 282-288; Sharma, D., Kapoor, A., Deshpande, A., On greedy maximization of entropy (2015) Proceedings of the 32nd International Conference On Machine Learning, pp. 1330-1338; Tzoumas, V., Jadbabaie, A., Pappas, G.J., Near-optimal sensor scheduling for batch state estimation (2016) IEEE 55th Conference On Decision and Control, pp. 2695-2702; Tzoumas, V., Atanasov, N.A., Jadbabaie, A., Pappas, G.J., Scheduling nonlinear sensors for stochastic process estimation (2017) IEEE American Control Conference, , to appear; Zhang, H., Ayoub, R., Sundaram, S., Sensor selection for kalman filtering of linear dynamical systems: Complexity, limitations and greedy algorithms (2017) Automatica, 78, pp. 202-210; Carlone, L., Karaman, S., (2016) Attention and Anticipation in Fast Visualinertial Navigation, , arXiv preprint:1610.03344; Iyer, R., Jegelka, S., Bilmes, J., Fast semidifferential-based submodular function optimization (2013) Proceedings of the 30th International Conference On International Conference On Machine Learning, pp. 855-863; Krause, A., Leskovec, J., Guestrin, C., VanBriesen, J., Faloutsos, C., Efficient sensor placement optimization for securing large water distribution networks (2008) Journal of Water Resources Planning and Management, 134 (6), pp. 516-526. , November; Nemhauser, G.L., Wolsey, L.A., Best algorithms for approximating the maximum of a submodular set function (1978) Mathematics of Operations Research, 3 (3), pp. 177-188; Krause, A., McMahan, H.B., Guestrin, C., Gupta, A., Robust submodular observation selection (2008) Journal of Machine Learning Research, 9, pp. 2761-2801; Globerson, A., Roweis, S., Nightmare at test time: Robust learning by feature deletion (2006) Proceedings of the 23rd International Conference On Machine Learning, pp. 353-360; Clark, A., Bushnell, L., Poovendran, R., Leader selection games under link noise injection attacks (2012) Proceedings of the 1st International Conf. On High Confidence Networked Systems, pp. 31-40; Pequito, S., Ramos, G., Kar, S., Aguiar, A.P., Ramos, J., (2014) On the Exact Solution of the Minimal Controllability Problem, , arXiv preprint: 1401.4209; Das, A., Kempe, D., Sensor selection for minimizing worst-case prediction error (2008) Proceedings of the 7th International Conference On Information Processing in Sensor Networks, pp. 97-108; Laszka, A., Vorobeychik, Y., Koutsoukos, X., Resilient observation selection in adversarial settings (2015) 2015 54th IEEE Conference On Decision and Control (CDC), pp. 7416-7421. , Dec; Xu, W., Ma, K., Trappe, W., Zhang, Y., Jamming sensor networks (2006) IEEE Network, 20 (3), pp. 41-47; Orlin, J.B., Schulz, A.S., Udwani, R., Robust monotone submodular function maximization (2016) 18th International Conf. On Integer Programming and Combinatorial Optimization, pp. 312-324; Shoukry, Y., Chong, M., Wakaiki, M., Nuzzo, P., Sangiovanni-Vincentelli, A.L., Seshia, S.A., Hespanha, J.P., Tabuada, P., SMT-based observer design for cyber-physical systems under sensor attacks (2016) Proc. of the 7th International Conf. On Cyber-Physical Systems; Orlin, J.B., Schulz, A.S., Udwani, R., (2015) Robust Monotone Submodular Function Maximization, , arXiv preprint: 1507.06616; Chong, M.S., Wakaiki, M., Hespanha, J.P., Observability of linear systems under adversarial attacks (2015) American Control Conference, pp. 2439-2444; Jegelka, S., (2012) Combinatorial Problems with Submodular Coupling in Machine Learning and Computer Vision, , Ph.D. dissertation, ETH Zurich; Lin, H., Bilmes, J., How to select a good training-data subset for transcription: Submodular active selection for sequences (2009) 10th Annual Conf. of the International Speech Comm. Association; Bishop, C.M., (2006) Pattern Recognition and Machine Learning, , Springer; Nemhauser, G., Wolsey, L., Fisher, M., An analysis of approximations for maximizing submodular set functions-I (1978) Mathematical Programming, 14 (1), pp. 265-294; Myerson, R.B., (2013) Game Theory: Analysis of Conflict, , Harvard University Press; Iyer, R.K., Jegelka, S., Bilmes, J.A., Curvature and optimal algorithms for learning and minimizing submodular functions (2013) Advances in Neural Inform. Processing Systems, pp. 2742-2750; Sviridenko, M., Vondrak, J., Ward, J., Optimal approximation for submodular and supermodular optimization with bounded curvature (2015) Proceedings of the 26th Annual ACM-SIAM Symposium On Discrete Algorithms, pp. 1134-1148; Lin, H., Bilmes, J., A class of submodular functions for document summarization (2011) Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, 1, pp. 510-520; Jegelka, S., Bilmes, J., Submodularity beyond submodular energies: Coupling edges in graph cuts (2011) IEEE Conference On Computer Vision and Pattern Recognition, pp. 1897-1904; Conforti, M., Cornuejols, G., Submodular set functions, matroids and the greedy algorithm: Tight worst-case bounds and some generalizations of the rado-edmonds theorem (1984) Discrete Applied Mathematics, 7 (3), pp. 251-274; Vondrak, J., Submodularity and curvature: The optimal algorithm RIMS Kokyuroku Bessatsu, 23 (2010), pp. 253-266; Tzoumas, V., Rahimian, M., Pappas, G., Jadbabaie, A., (2014) Minimal Actuator Placement with Bounds On Control Effort, , arXiv preprint: 1409.3289",,,"ANCA Motion;City of Melbourne;Mathworks;The University of Melbourne;The University of Newcastle;United Technologies Research Center (UTRC)","Institute of Electrical and Electronics Engineers Inc.","56th IEEE Annual Conference on Decision and Control, CDC 2017","12 December 2017 through 15 December 2017",,133780,,9781509028733,,,"English","IEEE Annu. Conf. Decis. Control, CDC",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85046135405
"Jin X., Haddad W.M., Hayakawa T.","55541046800;35461378700;7402974582;","An adaptive control architecture for cyber-physical system security in the face of sensor and actuator attacks and exogenous stochastic disturbances",2018,"2017 IEEE 56th Annual Conference on Decision and Control, CDC 2017","2018-January",,,"1380","1385",,4,"10.1109/CDC.2017.8263847","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046120898&doi=10.1109%2fCDC.2017.8263847&partnerID=40&md5=277bb71a4a212032e0d17c2924accd90","School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA  30332-0150, United States; Department of Mechanical and Environmental Informatics, Tokyo Institute of Technology, Tokyo, 152-8552, Japan","Jin, X., School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA  30332-0150, United States; Haddad, W.M., School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA  30332-0150, United States; Hayakawa, T., Department of Mechanical and Environmental Informatics, Tokyo Institute of Technology, Tokyo, 152-8552, Japan","In this paper, we propose a novel adaptive control architecture for addressing security and safety in cyber-physical systems subject to exogenous disturbances. Specifically, we develop an adaptive controller for time-invariant, state-dependent adversarial sensor and actuator attacks in the face of stochastic exogenous disturbances. We show that the proposed controller guarantees uniform ultimate boundedness of the closed-loop dynamical system in a mean-square sense. We further discuss the practicality of the proposed approach and provide a numerical example involving the lateral directional dynamics of an aircraft to illustrate the efficacy of the proposed adaptive control architecture. © 2017 IEEE.",,"Actuators; Controllers; Cyber Physical System; Dynamical systems; Embedded systems; Stochastic systems; Adaptive control architecture; Adaptive controllers; Cyber-physical system securities; Directional dynamics; Exogenous disturbances; Sensor and actuators; Stochastic disturbances; Uniform ultimate boundedness; Adaptive control systems",,,,,"Antsaklis, P., Goals and challenges in cyber-physical systems research (2014) IEEE Transactions On Automatic Control, 59 (12), pp. 3117-3119; Massoumnia, M.-A., Verghese, G.C., Willsky, A.S., Failure detection and identification (1989) IEEE Transactions On Automatic Control, 34 (3), pp. 316-321; Blanke, M., Schroder, J., (2006) Diagnosis and Fault-Tolerant Control, 691. , Springer; Hwang, I., Kim, S., Kim, Y., Seah, C.E., A survey of fault detection, isolation, and reconfiguration methods (2010) IEEE Transactions On Control Systems Technology, 18 (3), pp. 636-653; Yucelen, T., Haddad, W.M., Feron, E.M., Adaptive control architectures for mitigating sensor attacks in cyber-physical systems (2016) Cyber-Physical Systems, 2 (2), pp. 24-52; Jin, X., Haddad, W.M., Yucelen, T., An adaptive control architecture for mitigating sensor and actuator attacks in cyber-physical systems IEEE Transactions On Automatic Control, , to appear; Khasminskii, R.Z., (2012) Stochastic Stability of Differential Equations, , Berlin Heidelberg: Springer; Arnold, L., (1974) Stochastic Differential Equations: Theory and Applications, , USA: A Wiley-Interscience Publication; Ksendal, B., (1995) Stochastic Differential Equations: An Introduction with Applications, , Verlag Berlin, Heidelberg: Springer; Wu, Z.J., Xie, X.J., Shi, P., Xia, Y.Q., Backstepping controller design for a class of stochastic nonlinear systems with Markovian switching (2009) Automatica, 45, pp. 101-127; Wang, H.Q., Chen, B., Lin, C., Adaptive neural tracking control for a class of stochastic nonlinear systems (2014) International Journal of Robust and Nonlinear Control, 24 (7), pp. 1262-1280; Zhao, X., Shi, P., Zheng, X., Zhang, L., Adaptive tracking control for switched stochastic nonlinear systems with unknown actuator deadzone (2015) Automatica, 60, pp. 193-200; Hua, D., Kristic, M., Williams, R., Stabilization of stochastic nonlinear systems driven by noise of unknown covariance (2001) IEEE Transactions On Automatic Control, 48, pp. 1237-1253; Arapostathis, A., Borkar, V.S., Ghosh, M.K., (2012) Ergodic Control of Diffusion Processes, , Cambridge U.K.: Cambridge University Press; Haddad, W.M., Chellaboina, V., (2008) Nonlinear Dynamical Systems and Control: A Lyapunov-Based Approach, , Princeton University Press; Polycarpou, M.M., Ioannou, P.A., A robust adaptive nonlinear control design (1996) Automatica, 32 (3), pp. 423-427; Liu, M., Zhang, L., Shi, P., Karimi, H.R., Robust control of stochastic systems against bounded disturbances with application to flight control (2014) IEEE Transactions On Industrial Electronics, 61 (3), pp. 1504-1515; Fravolini, M.L., Yucelen, T., Campa, G., Set theoretic performance verification of low-frequency learning adaptive controllers (2015) International Journal of Adaptive Control and Signal Processing, 29 (10), pp. 1243-1258",,,"ANCA Motion;City of Melbourne;Mathworks;The University of Melbourne;The University of Newcastle;United Technologies Research Center (UTRC)","Institute of Electrical and Electronics Engineers Inc.","56th IEEE Annual Conference on Decision and Control, CDC 2017","12 December 2017 through 15 December 2017",,133780,,9781509028733,,,"English","IEEE Annu. Conf. Decis. Control, CDC",Conference Paper,"Final","",Scopus,2-s2.0-85046120898
"Weerakkody S., Liu X., Sinopoli B.","55906061400;55905612500;23570052500;","Robust structural analysis and design of distributed control systems to prevent zero dynamics attacks",2018,"2017 IEEE 56th Annual Conference on Decision and Control, CDC 2017","2018-January",,,"1356","1361",,12,"10.1109/CDC.2017.8263843","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046120037&doi=10.1109%2fCDC.2017.8263843&partnerID=40&md5=9556e6b15cc1737d1fcec1f5b5179e11","Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA  15213, United States","Weerakkody, S., Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA  15213, United States; Liu, X., Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA  15213, United States; Sinopoli, B., Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA  15213, United States","We consider the design and analysis of robust distributed control systems (DCSs) to ensure the detection of integrity attacks. DCSs are often managed by independent agents and are implemented using a diverse set of sensors and controllers. However, the heterogeneous nature of DCSs along with their scale leave such systems vulnerable to adversarial behavior. To mitigate this reality, we provide tools that allow operators to prevent zero dynamics attacks when as many as p agents and sensors are corrupted. Such a design ensures attack detectability in deterministic systems while removing the threat of a class of stealthy attacks in stochastic systems. To achieve this goal, we use graph theory to obtain necessary and sufficient conditions for the presence of zero dynamics attacks in terms of the structural interactions between agents and sensors. We then formulate and solve optimization problems which minimize communication networks while also ensuring a resource limited adversary cannot perform a zero dynamics attacks. Polynomial time algorithms for design and analysis are provided. © 2017 IEEE.",,"Control system analysis; Dynamics; Graph theory; Polynomial approximation; Stochastic control systems; Stochastic systems; Design and analysis; Deterministic systems; Independent agents; Integrity attacks; Optimization problems; Polynomial-time algorithms; Structural analysis and designs; Structural interactions; Distributed parameter control systems",,,,,"Cardenas, A.A., Amin, S., Sastry, S., Secure control: Towards survivable cyber-physical systems (2008) The 28th International Conference On Distributed Computing Systems Workshops, pp. 495-500; Langner, R., To kill a centrifuge: A technical analysis of what Stuxnet's creators tried to achieve (2013) Langner Communications, Tech. Rep., , Www.langner.com/en/wpcontent/uploads/2013/11/To-kill-a-centrifuge.pdf, November [Online]; Slay, J., Miller, M., Lessons learned from the Maroochy water breach (2008) Critical Infrastructure Protection, pp. 73-82. , Springer US; Vander Woude, J., The generic number of invariant zeros of a structured linear system (1999) SIAM Journal On Control and Optimization, 38 (1), pp. 1-21; Boukhobza, T., Hamelin, F., Martinez-Martinez, S., State and input observability for structured linear systems: A graph-theoretic approach (2007) Automatica, 43 (7), pp. 1204-1210; Boukhobza, T., Hamelin, F., State and input observability recovering by additional sensor implementation: A graph-theoretic approach (2009) Automatica, 45 (7), pp. 1737-1742; Liu, Y., Reiter, M., Ning, P., False data injection attacks against state estimation in electric power grids (2009) Proceedings of the 16th ACM Conference On Computer and Communications Security, , Chicago, IL; Mo, Y., Garone, E., Casavola, A., Sinopoli, B., False data injection attacks against state estimation in wireless sensor networks (2010) 49th IEEE Conference On Decision and Control, pp. 5967-5972. , Atlanta, Georgia; Teixeira, A., Shames, I., Sandberg, H., Johansson, K.H., A secure control framework for resource-limited adversaries (2015) Automatica, 51, pp. 135-148; Pasqualetti, F., Dorfler, F., Bullo, F., Attack detection and identification in cyber-physical systems (2013) IEEE Transactions On Automatic Control, 58 (11), pp. 2715-2729; Sundaram, S., Hadjicostis, C., Distributed function calculation via linear iterative strategies in the presence of malicious agents (2011) IEEE Transactions On Automatic Control, 56 (7), pp. 1495-1508; Pasqualetti, F., Bicchi, A., Bullo, F., Consensus computation in unreliable networks: A system theoretic approach (2012) IEEE Transactions On Automatic Control, 57 (1), pp. 90-104; Weerakkody, S., Liu, X., Son, S.H., Sinopoli, B., A graph theoretic characterization of perfect attackability for secure design of distributed control systems (2017) IEEE Transactions On Control of Network Systems, 4 (1), pp. 60-70; Weerakkody, S., Liu, X., Son, S.H., Sinopoli, B., A graph theoretic characterization of perfect attackability and detection in distributed control systems (2016) American Control Conference (ACC), 2016, pp. 1171-1178. , IEEE; Weerakkody, S., Sinopoli, B., Kar, S., Datta, A., Information flow for security in control systems (2016) 55th IEEE Conference On Decision and Control (CDC), pp. 5065-5072. , IEEE; Trentelman, H., Stoorvogel, A.A., Hautus, M., (2012) Control Theory for Linear Systems, , Springer Science & Business Media; Menger, K., Zur allgemeinen kurventheorie (1927) Fundamenta Mathematicae, 1 (10), pp. 96-115; Dinic, E.A., An algorithm for the solution of the max-flow problem with the polynomial estimation (1970) Doklady Akademii Nauk, 194 (4), pp. 1277-1280; Even, S., Tarjan, R.E., Network flow and testing graph connectivity (1975) SIAM Journal On Computing, 4 (4), pp. 507-518",,,"ANCA Motion;City of Melbourne;Mathworks;The University of Melbourne;The University of Newcastle;United Technologies Research Center (UTRC)","Institute of Electrical and Electronics Engineers Inc.","56th IEEE Annual Conference on Decision and Control, CDC 2017","12 December 2017 through 15 December 2017",,133780,,9781509028733,,,"English","IEEE Annu. Conf. Decis. Control, CDC",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85046120037
"Zhang R., Zhu Q.","57164157500;24767254400;","A game-theoretic defense against data poisoning attacks in distributed support vector machines",2018,"2017 IEEE 56th Annual Conference on Decision and Control, CDC 2017","2018-January",,,"4582","4587",,11,"10.1109/CDC.2017.8264336","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037166233&doi=10.1109%2fCDC.2017.8264336&partnerID=40&md5=07cd4d9288201aab285579e434bcf756","Department of Electrical and Computer Engineering, New York University, Brooklyn, NY  11201, United States","Zhang, R., Department of Electrical and Computer Engineering, New York University, Brooklyn, NY  11201, United States; Zhu, Q., Department of Electrical and Computer Engineering, New York University, Brooklyn, NY  11201, United States","With a large number of sensors and control units in networked systems, distributed support vector machines (DSVMs) play a fundamental role in scalable and efficient multi-sensor classification and prediction tasks. However, DSVMs are vulnerable to adversaries who can modify and generate data to deceive the system to misclassification and misprediction. This work aims to design defense strategies for DSVM learner against a potential adversary. We use a game-theoretic framework to capture the conflicting interests between the DSVM learner and the attacker. The Nash equilibrium of the game allows predicting the outcome of learning algorithms in adversarial environments, and enhancing the resilience of the machine learning through dynamic distributed algorithms. We develop a secure and resilient DSVM algorithm with rejection method, and show its resiliency against adversary with numerical experiments. © 2017 IEEE.",,"Learning algorithms; Network security; Networked control systems; Numerical methods; Support vector machines; Adversarial environments; Dynamic distributed algorithm; Misclassifications; Networked systems; Numerical experiments; Poisoning attacks; Prediction tasks; Rejection methods; Game theory",,,,,"Banerjee, T.P., Das, S., Multi-sensor data fusion using support vector machine for motor fault detection (2012) Information Sciences, 217, pp. 96-107; Waske, B., Benediktsson, J.A., Fusion of support vector machines for classification of multisensor data (2007) Geoscience and Remote Sensing, IEEE Transactions on, 45 (12), pp. 3858-3866; Zhao, X.-H., Gang, W., Zhao, K.-K., Tan, D.-J., On-line least squares support vector machine algorithm in gas prediction (2009) Mining Science and Technology (China), 19 (2), pp. 194-198; Durrant-Whyte, H.F., Rao, B., Hu, H., Toward a fully decentralized architecture for multi-sensor data fusion (1990) Robotics and Automation, 1990. Proceedings., 1990 IEEE International Conference on, pp. 1331-1336. , IEEE; Tsang, I.W., Kwok, J.T., Cheung, P.-M., Core vector machines: Fast SVM training on very large data sets (2005) Journal of Machine Learning Research, pp. 363-392; Dong, J.-X., Krzyzak, A., Suen, C.Y., Fast SVM training algorithm with decomposition on very large data sets (2005) Pattern Analysis and Machine Intelligence, IEEE Transactions on, 27 (4), pp. 603-618; Forero, P.A., Cano, A., Giannakis, G.B., Consensus-based distributed support vector machines (2010) The Journal of Machine Learning Research, 11, pp. 1663-1707; Chen, R., Park, J.-M., Bian, K., Robust distributed spectrum sensing in cognitive radio networks (2008) INFOCOM 2008. The 27th Conference on Computer Communications, , IEEE, IEEE; Wang, D., Zhou, Y., Distributed support vector machines: An overview (2012) Control and Decision Conference (CCDC), 2012 24th Chinese, pp. 3897-3901. , IEEE; Zhang, R., Zhu, Q., Secure and resilient distributed machine learning under adversarial environments (2015) Information Fusion (Fusion), 2015 18th International Conference on, pp. 644-651. , IEEE; Zhang, R., Zhu, Q., A game-theoretic analysis of label flipping attacks on distributed support vector machines (2017) Information Sciences and Systems (CISS), 2017 51st Annual Conference on, pp. 1-6. , IEEE; Chan, H., Perrig, A., Security and privacy in sensor networks (2003) Computer, 36 (10), pp. 103-105; Boyd, S., Parikh, N., Chu, E., Peleato, B., Eckstein, J., Distributed optimization and statistical learning via the alternating direction method of multipliers (2011) Foundations and Trends R in Machine Learning, 3 (1), pp. 1-122; Dalponte, M., Bruzzone, L., Gianelle, D., Fusion of hyperspectral and lidar remote sensing data for classification of complex forest areas (2008) Geoscience and Remote Sensing, IEEE Transactions on, 46 (5), pp. 1416-1427; Hert, J., Willett, P., Wilton, D.J., Acklin, P., Azzaoui, K., Jacoby, E., Schuffenhauer, A., New methods for ligand-based virtual screening: Use of data fusion and machine learning to enhance the effectiveness of similarity searching (2006) Journal of Chemical Information and Modeling, 46 (2), pp. 462-470; Barreno, M., Nelson, B., Sears, R., Joseph, A.D., Tygar, J.D., Can machine learning be secure? (2006) Proceedings of the 2006 ACM Symposium on Information, Computer and Communications Security, pp. 16-25. , ACM; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I., Tygar, J., Adversarial machine learning (2011) Proceedings of the 4th ACM Workshop on Security and Artificial Intelligence, pp. 43-58. , ACM; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Srndic, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Machine Learning and Knowledge Discovery in Databases, pp. 387-402. , Springer; Liu, W., Chawla, S., A game theoretical model for adversarial learning (2009) Data Mining Workshops, 2009. ICDMW'09. IEEE International Conference on, pp. 25-30. , IEEE; Kantarcioglu, M., Xi, B., Clifton, C., A game theoretical framework for adversarial learning (2008) CERIAS 9th Annual Information Security Symposium, Citeseer; Manshaei, M.H., Zhu, Q., Alpcan, T., Bacşar, T., Hubaux, J.-P., Game theory meets network security and privacy (2013) ACM Computing Surveys (CSUR), 45 (3), p. 25; Shen, D., Chen, G., Blasch, E., Tadda, G., Adaptive markov game theoretic data fusion approach for cyber network defense (2007) Military Communications Conference, 2007. MILCOM 2007. IEEE, pp. 1-7. , IEEE; Jiang, W., Tian, Z.-H., Zhang, H.-L., Song, X.-F., A stochastic game theoretic approach to attack prediction and optimal active defense strategy decision (2008) Networking, Sensing and Control, 2008. ICNSC 2008. IEEE International Conference on, pp. 648-653. , IEEE; Xu, H., Caramanis, C., Mannor, S., Robustness and regularization of support vector machines (2009) The Journal of Machine Learning Research, 10, pp. 1485-1510; Eckstein, J., Yao, W., Augmented lagrangian and alternating direction methods for convex optimization: A tutorial and some illustrative computational results (2012) RUTCOR Research Reports, 32; Zhang, R., Zhu, Q., A Game-theoretic Approach to Design Secure and Resilient Distributed Support Vector Machines, , https://wp.nyu.edu/quanyan/wp-content/uploads/sites/2123/2015/06/CDC_Zhang_Long.pdf; He, B., Yuan, X., On non-ergodic convergence rate of douglas-rachford alternating direction method of multipliers (2012) Numerische Mathematik, 130 (3), pp. 567-577; Frank, A., Asuncion, A., UCI machine learning repository [http://archive. ics. uci. edu/ml]. irvine, ca: University of California (2010) School of Information and Computer Science, 213",,,"ANCA Motion;City of Melbourne;Mathworks;The University of Melbourne;The University of Newcastle;United Technologies Research Center (UTRC)","Institute of Electrical and Electronics Engineers Inc.","56th IEEE Annual Conference on Decision and Control, CDC 2017","12 December 2017 through 15 December 2017",,133780,,9781509028733,,,"English","IEEE Annu. Conf. Decis. Control, CDC",Conference Paper,"Final","",Scopus,2-s2.0-85037166233
"Li W., Meng W., Kwok L.F.","57189107700;56062319900;56133027600;","Investigating the influence of special on-off attacks on challenge-based collaborative intrusion detection networks",2018,"Future Internet","10","1","6","","",,20,"10.3390/fi10010006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041306150&doi=10.3390%2ffi10010006&partnerID=40&md5=82f8872878ec5c482b4158ccd2eb72dd","Department of Computer Science, City University of Hong Kong, Hong Kong; Department of Applied Mathematics and Computer Science, Technical University of Denmark, Kongens Lyngby, 2800, Denmark","Li, W., Department of Computer Science, City University of Hong Kong, Hong Kong; Meng, W., Department of Applied Mathematics and Computer Science, Technical University of Denmark, Kongens Lyngby, 2800, Denmark; Kwok, L.F., Department of Computer Science, City University of Hong Kong, Hong Kong","Intrusions are becoming more complicated with the recent development of adversarial techniques. To boost the detection accuracy of a separate intrusion detector, the collaborative intrusion detection network (CIDN) has thus been developed by allowing intrusion detection system (IDS) nodes to exchange data with each other. Insider attacks are a great threat for such types of collaborative networks, where an attacker has the authorized access within the network. In literature, a challenge-based trust mechanism is effective at identifying malicious nodes by sending challenges. However, such mechanisms are heavily dependent on two assumptions, which would cause CIDNs to be vulnerable to advanced insider attacks in practice. In this work, we investigate the influence of advanced on-off attacks on challenge-based CIDNs, which can respond truthfully to one IDS node but behave maliciously to another IDS node. To evaluate the attack performance, we have conducted two experiments under a simulated and a real CIDN environment. The obtained results demonstrate that our designed attack is able to compromise the robustness of challenge-based CIDNs in practice; that is, some malicious nodes can behave untruthfully without a timely detection. © 2018 by the authors.","Challenge-based mechanism; Collaborative network; Intrusion detection; On-off attack; Trust computation and management","Mercury (metal); Network security; Collaborative network; Detection accuracy; Intrusion Detection Systems; Intrusion detectors; Malicious nodes; On-off attack; Trust computations; Trust mechanism; Intrusion detection",,,,,"Scarfone, K., Mell, P., (2007) Guide to Intrusion Detection and Prevention Systems (IDPS), pp. 800-894. , NIST Special Publication: Gaithersburg, MD, USA; Gong, F., (2003) Next Generation Intrusion Detection Systems (IDS), , McAfee Network Security Technologies Group: Santa Clara, CA, USA; Duma, C., Karresand, M., Shahmehri, N., Caronni, G., A Trust-Aware, P2P-Based Overlay for Intrusion Detection (2006) Proceedings of the 17th International Workshop on Database and Expert Systems Applications, pp. 692-697. , Krakow, Poland, 4-8 September; Wu, Y.-S., Foo, B., Mei, Y., Bagchi, S., Collaborative Intrusion Detection System (CIDS): A Framework for Accurate and Efficient IDS (2003) Proceedings of the 2003 Annual Computer Security Applications Conference (ACSAC), pp. 234-244. , Las Vegas, NV, USA, 8-12 December; Fung, C.J., Boutaba, R., Design and management of collaborative intrusion detection networks (2013) Proceedings of the 2013 IFIP/IEEE International Symposium on Integrated Network Management (IM), pp. 955-961. , Ghent, Belgium, 27-31 May; Fung, C.J., Baysal, O., Zhang, J., Aib, I., Boutaba, R., Trust Management for Host-Based Collaborative Intrusion Detection (2008) DSOM 2008;Lecture Notes in Computer Science (LNCS) 5273, pp. 109-122. , De Turck:F., Kellerer, W., Kormentzas, G., Eds.; Springer: Berlin, Germany; Fung, C.J., Zhang, J., Aib, I., Boutaba, R., Robust and scalable trust management for collaborative intrusion detection (2009) Proceedings of the 11th IFIP/IEEE International Conference on Symposium on Integrated Network Management (IM), pp. 33-40. , Long Island, NY, USA, 1-5 June; Li, W., Meng, Y., Kwok, L.-F., Ip, H.H.S., PMFA: Toward Passive Message Fingerprint Attacks on Challenge-based Collaborative Intrusion Detection Networks (2016) Proceedings of the 10th International Conference on Network and System Security (NSS), pp. 433-449. , Taipei, Taiwan, 28-30 September; Meng, M., Luo, X., Li, W., Li, Y., Design and Evaluation of Advanced Collusion Attacks on Collaborative Intrusion Detection Networks in Practice (2016) Proceedings of the 15th IEEE International Conference on Trust, pp. 1061-1068. , Security and Privacy in Computing and Communications (TrustCom), Tianjin, China, 23-26 August; Li, W., Meng, Y., Kwok, L.-F., SOOA: Exploring Special On-Off Attacks on Challenge-Based Collaborative Intrusion Detection Networks (2017) Proceedings of the 12th International Conference on Green, pp. 402-415. , Pervasive, and Cloud Computing (GPC), Cetara, Italy, 11-14 May; Meng, Y., Li, W., Xiang, Y., Choo, K.-K.R., A Bayesian Inference-based Detection Mechanism to Defend Medical Smartphone Networks against Insider Attacks (2017) J. Netw. Comput. Appl, 78, pp. 162-169; Donovan, S., Feamster, N., Alternative trust sources: Reducing DNSSEC signature verification operations with TLS (2015) Proceedings of the 2015 ACM Conference on Special Interest Group on Data Communication (SIGCOMM), pp. 353-354. , London, UK, 17-21 August; Kolias, C., Kolias, V., Kambourakis, G., TermID: A distributed swarm intelligence-based approach for wireless intrusion detection (2017) Int. J. Inf. Secur, 16, pp. 401-416; Meng, Y., Li, W., Kwok, L.-F., Evaluation of detecting malicious nodes using Bayesian model in wireless intrusion detection (2013) Proceedings of the 7th International Conference on Network and System Security (NSS), pp. 40-53. , Helsinki, Finland, 21-23 August 2013; Lecture Notes in Computer Science 7873; Springer: Berlin, Germany; Meng, W., Au, M.H., Towards statistical trust computation for medical smartphone networks based on behavioral profiling (2017) Proceedings of the 11th IFIP WG 11.11 International Conference on Trust Management (IFIPTM), pp. 152-159. , Gothenburg, Sweden, 12-16 June; Meng, W., Li, W., Wang, Y., Au, M.H., Detecting malicious nodes in medical smartphone networks through euclidean distance-based behavioral profiling (2017) Proceedings of the 9th International Symposium on Cyberspace Safety and Security (CSS), pp. 163-175. , Xi'an, China, 23-25 October; Meng, W., Li, W., Su, C., Zhou, J., Lu, R., Enhancing Trust Management forWireless Intrusion Detection via Traffic Sampling in the Era of Big Data (2017) IEEE Access; Ramos, A., Lazar, M., Filho, R.H., Rodrigues, J.J.P.C., A security metric for the evaluation of collaborative intrusion detection systems in wireless sensor networks (2017) Proceedings of the IEEE International Conference on Communications (ICC), , Paris, France, 21-25 May; Li, W., Meng, Y., Kwok, L.-F., Ip, H.H.S., Developing Advanced Fingerprint Attacks on Challenge-based Collaborative Intrusion Detection Networks (2017) Clust. Comput, pp. 1-12; Li, W., Meng, Y., Kwok, L.-F., Enhancing Trust Evaluation Using Intrusion Sensitivity in Collaborative Intrusion Detection Networks: Feasibility and Challenges (2013) Proceedings of the 9th International Conference on Computational Intelligence and Security (CIS), pp. 518-522. , Leshan, China, 14-15 December; Li, W., Meng, W., Kwok, L.-F., Design of intrusion sensitivity-based trust management model for collaborative intrusion detection networks (2014) Trust Management VIII, IFIP AICT, 430, pp. 61-76. , Zhou, J., Gal-Oz, N., Zhang, J., Gudes, E., Eds.; Springer: Heidelberg, Germany; Li, W., Meng, Y., Kwok, L.-F., Ip, H.H.S., Enhancing Collaborative Intrusion Detection Networks Against Insider Attacks Using Supervised Intrusion Sensitivity-Based Trust Management Model (2017) J. Netw. Comput. Appl, 77, pp. 135-145; Li, W., Meng, W., Enhancing collaborative intrusion detection networks using intrusion sensitivity in detecting pollution attacks (2016) Inf. Comput. Secur, 24, pp. 265-276; Cho, J.-H., Chan, K., Adali, S., A Survey on Trust Modeling (2015) ACM Comput. Surv, 48; Douceur, J., The sybil attack (2002) IPTPS 2002. LNCS, 2429. , Druschel P., Kaashoek, M.F., Rowstron, A., Eds.; Springer: Heidelberg, Germany; Perrone, L.P., Nelson, S.C., A Study of On-Off Attack Models for Wireless Ad Hoc Networks (2006) Proceedings of the 2006 Workshop on Operator-Assisted Community Networks, pp. 1-10. , Berlin, Germany, 18-19 September; Homepage, , http://www.snort.org/, (accessed on 8 January 2018)","Meng, W.; Department of Applied Mathematics and Computer Science, Denmark; email: weme@dtu.dk",,,"MDPI AG",,,,,19995903,,,,"English","Future Internet",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85041306150
"Shukla R.M., Sengupta S., Chatterjee M.","57193420913;57200399811;26643549700;","Sofware-defined network and cloud-edge collaboration for smart and connected vehicles",2018,"ACM International Conference Proceeding Series",,,"a6","","",,9,"10.1145/3170521.3170527","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045739136&doi=10.1145%2f3170521.3170527&partnerID=40&md5=c274b7cefbf07ec9dceb252879e991e5","University of Nevada, Reno Reno, NV, United States; University of Central Florida, Orlando, FL, United States","Shukla, R.M., University of Nevada, Reno Reno, NV, United States; Sengupta, S., University of Nevada, Reno Reno, NV, United States; Chatterjee, M., University of Central Florida, Orlando, FL, United States","Smart and connected communities are envisioned to include millions of sensors and devices tied together through the Internet. This has ushered the demand to investigate intensive communication and computing solutions for their realization to facilitate human life. Connected vehicles can be considered as a significant realm of the smart and connected communities. This paper presents the importance and challenges of Software-Defined Networks (SDN) for providing better network management in smart and connected vehicles. We also describe the significance and challenges in embracing cloud, edge and fog computing for processing enormous amount of data generated from the network of interconnected vehicles. Further, a portrayal of some of the open research issues for better realization of the connected world is provided. © 2018 Association for Computing Machinery.","Adversarial attack; Cascade failure; Cloud computing; Cloudlet; Connected vehicles; Edge computing; Smart and connected communities; Software-defined network","Cloud computing; Edge computing; Software defined networking; Vehicles; Adversarial attack; Cascade failure; Cloudlet; Computing solutions; Connected vehicles; Human lives; Research issues; Fog computing",,,,,"Baer, D., (2016) Machine Learning is a Revolution as Big as the Internet or Personal Computers, , http://www.businessinsider.com/machine-learning-as-important-as-the-internet-2016-3, (April 2016); Bonomi, F., Milito, R., Zhu, J., Addepalli, S., Fog computing and its role in the internet of things (2012) Proc. Of First Edition of the MCC Workshop on Mobile Cloud Computing, pp. 13-16. , New York, NY, USA; Caswell, V., (2016) 5 Mobile Apps to Increase Driving Experience, , http://www.trueautoprotection.com/auto-warranty-and-maintenance-blog/topic/spotify#.Wgk7mcanHIV, (March 2016); Chen, Z., Jiang, L., Hu, W., Ha, K., Amos, B., Pillai, P., Hauptmann, A., Mahadev, S., Early implementation experience with wearable cognitive assistance applications (2015) Proc. Of the Workshop on Wearable Systems and Applications (WearSys) (WearSys '15), pp. 33-38. , ACM, New York, NY, USA; (2016) State of the Plug-in Electric Vehicle Market, , http://www.electrificationcoalition.org/sites/default/files/, (2016); Cuervo, E., Balasubramanian, A., Cho, D., Wolman, A., Saroiu, S., Chandra, R., Bahl, P., MAUI: Making smartphones last longer with code offload (2010) Proc. Of International Conference on Mobile Systems, Applications, and Services, pp. 49-62. , San Francisco, California, USA; Gerla, M., Lee, E.K., Pau, G., Lee, U., Internet of vehicles: From intelligent grid to autonomous cars and vehicular clouds (2014) IEEE World Forum on Internet of Things (WF-IoT), pp. 241-246; Goodfellow, I., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , (2014); Hakiri, A., Gokhale, A., Berthou, P., Schmidt, D.C., Gayraud, T., Software-defined networking: Challenges and research opportunities for future internet (2014) Journal of Computer Networks, 75, pp. 453-471. , (2014); Heller, B., Sherwood, R., McKeown, N., The controller placement problem (2012) Proc. Of First Workshop on Hot Topics in Software Defined Networks, pp. 7-12. , ACM, New York, NY, USA; Hu, Y., Patel, M., Sabella, D., Sprecher, N., Young, V., Mobile edge computing - A key technology towards 5G (2015) ETSI White Paper 11, 11, pp. 1-16. , (2015); Kreutz, D., Ramos, F.M.V., Verissimo, P.E., Rothenberg, C.E., Azodolmolky, S., Uhlig, S., Software-defined networking: A comprehensive survey (2015) Proc. IEEE, 103 (1), pp. 14-76. , (January 2015); Ku, I., Lu, Y., Gerla, M., Gomes, R.L., Ongaro, F., Cerqueira, E., Towards software-defined VANET: Architecture and services (2014) Proc. Of Annual Mediterranean Ad Hoc Networking Workshop (MED-HOC-NET), pp. 103-110; Luan, T., Gao, L., Li, Z., Xiang, Y., Wei, G., Sun, L., (2015) Fog Computing: Focusing on Mobile Users at the Edge, , (2015); Zhang, D., Wasserman, M., Hartman, S., (2012) Security Analysis of the Open Networking Foundation (ONF) OpenFlow Switch Specification, , https://tools.ietf.org/id/draft-mrw-sdnsec-openflow-analysis-00.html, (April 2012); Meola, A., (2016) Automotive Industry Trends: IoT Connected Smart Cars and Vehicles, , http://www.businessinsider.com/internet-of-things-connected-smart-cars-2016-10, (December 2016); Mikhailov, E., Trusov, R., (2017) How Adversarial Attacks Work, , http://blog.ycombinator.com/how-adversarial-attacks-work/, (2017); Mwasilu, F., Justo, J., Kim, E., Do, T., Jung, J., Electric vehicles and smart grid interaction: A review on vehicle to grid and renewable energy sources integration (2014) Renewable and Sustainable Energy Reviews, 34, pp. 501-516. , (2014); Pan, J., Jain, R., Paul, S., Vu, T., Saifullah, A., Sha, M., An internet of things framework for smart energy in buildings: Designs, prototype, and experiments (2015) IEEE Internet of Things Journal, 2 (6), pp. 527-537. , (December 2015); Patel, M., Hu, Y., Hédé, P., Joubert, J., Thornton, C., Naughton, B., Ramos, J.R., Klas, G., Mobile-edge computing (2014) ETSI White Paper; Patil, P., Hakiri, A., Barve, Y., Gokhale, A., Enabling software-defined networking for wireless mesh networks in smart environments (2016) Proc. Of International Symposium on Network Computing and Applications, pp. 153-157; Rabinovich, M., Xiao, Z., Aggarwal, A., (2004) Computing on the Edge: A Platform for Replicating Internet Applications, pp. 57-77. , Springer Netherlands, Dordrecht; Roman, R., Lopez, J., Mambo, M., Mobile edge computing, fog et al.: A survey and analysis of security threats and challenges (2018) Journal of Future Generation Computer Systems, 78, pp. 680-698. , (2018); Ruj, S., Pal, A., Analyzing cascading failures in smart grids under random and targeted attacks (2014) Proc. Of IEEE International Conference on Advanced Information Networking and Applications, pp. 226-233; Satyanarayanan, M., Bahl, P., Caceres, R., Davies, N., The case for VM-based cloudlets in mobile computing (2009) Journal of IEEE Pervasive Computing, 8 (4), pp. 14-23. , (October 2009); Satyanarayanan, M., Chen, Z., Ha, K., Hu, W., Richter, W., Pillai, P., Cloudlets: At the leading edge of mobile-cloud convergence (2014) Proc. Of IEEE International Conference on Mobile Computing, Applications and Services (Mobi-CASE), pp. 1-9. , Austin, Texas; Shapochka, A., (2015) 4 Challenges Lying in the Wait of SDN, , http://www.nojitter.com/post/240169834/4-challenges-lying-in-the-wait-of-sdn, (April 2015); Sharma, S.K., Wang, X., (2017) Live Data Analytics with Collaborative Edge and Cloud Processing in Wireless IoT Networks, 5, pp. 4621-4635. , IEEE Access (March 2017); Shukla, R., Sengupta, S., A novel software-defined network based approach for charging station allocation to plugged-in electric vehicles (2017) Proc. Of IEEE International Symposium on Network Computing and Applications (NCA), pp. 437-441. , Boston, Massachusetts; (2016) U.S. DOT Advances Deployment of Connected Vehicle Technology to Prevent Hundreds of Thousands of Crashes, , https://www.nhtsa.gov/press-releases, (July 2016); Sultan, S., Al-Doori, M., Al-Bayatti, A., Zedan, H., A comprehensive survey on vehicular ad hoc network (2014) Journal of Network and Computer Applications, 37, pp. 380-392. , (January 2014); Sun, Y., Song, H., Jara, A.J., Bie, R., Internet of things and big data analytics for smart and connected communities (2016) IEEE Access Journal, 4, pp. 766-773. , (February 2016)",,,"","Association for Computing Machinery","19th International Conference on Distributed Computing and Networking, ICDCN 2018","4 January 2018 through 7 January 2018",,135443,,9781450363976,,,"English","ACM Int. Conf. Proc. Ser.",Conference Paper,"Final","",Scopus,2-s2.0-85045739136
"Jin X., Haddad W.M., Hayakawa T.","55541046800;35461378700;7402974582;","An adaptive control architecture for cyber-physical system security in the face of sensor and actuator attacks and exogenous stochastic disturbances",2018,"Cyber-Physical Systems","4","1",,"39","56",,11,"10.1080/23335777.2018.1484818","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053425305&doi=10.1080%2f23335777.2018.1484818&partnerID=40&md5=e674251f3f053501937ab379696a2a03","School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA, United States; Department of Mechanical and Environmental Informatics, Tokyo Institute of Technology, Tokyo, Japan","Jin, X., School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA, United States; Haddad, W.M., School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA, United States; Hayakawa, T., Department of Mechanical and Environmental Informatics, Tokyo Institute of Technology, Tokyo, Japan","In this paper, we propose a novel adaptive control architecture for addressing security and safety in cyber-physical systems subject to exogenous disturbances. Specifically, we develop an adaptive controller for time-invariant, state-dependent adversarial sensor and actuator attacks in the face of stochastic exogenous disturbances modelled as Markov processes. We show that the proposed controller guarantees uniform ultimate boundedness of the closed-loop dynamical system in a mean-square sense. We further discuss the practicality of the proposed approach and provide a numerical example involving the lateral directional dynamics of an aircraft to illustrate the efficacy of the proposed adaptive control architecture. © 2018, © 2018 Taylor & FrancisInforma UK Limited, trading as Taylor & Francis Group.","cyber-physical systems; Markov processes; Sensor and actuator attacks; adaptive control; stochastic disturbances; uniform boundedness in probability","Actuators; Computer architecture; Controllers; Cyber Physical System; Dynamical systems; Embedded systems; Markov processes; Stochastic systems; Adaptive Control; Adaptive control architecture; Adaptive controllers; Boundedness; Cyber-physical system securities; Exogenous disturbances; Stochastic disturbances; Uniform ultimate boundedness; Adaptive control systems",,,,,"Antsaklis, P., Goals and challenges in cyber-physical systems research (2014) IEEE Trans Autom Control, 59 (12), pp. 3117-3119; Teixeira, A., Shames, I., Sandberg, H., A secure control framework for resource-limited adversaries (2015) Automatica, 51, pp. 135-148; Khaitan, S.K., McCalley, J.D., Design techniques and applications of cyberphysical systems: a survey (2015) IEEE Syst J, 9 (2), pp. 350-365; Massoumnia, M.A., Verghese, G.C., Willsky, A.S., Failure detection and identification (1989) IEEE Trans Autom Control, 34 (3), pp. 316-321; Blanke, M., Schröder, J., (2006) Diagnosis and fault-tolerant control, 691. , Berlin, Germany: Springer; Hwang, I., Kim, S., Kim, Y., A survey of fault detection, isolation, and reconfiguration methods (2010) IEEE Trans Control Syst Technol, 18 (3), pp. 636-653; Schenato, L., Sinopoli, B., Franceschetti, M., Foundations of control and estimation over lossy networks (2007) Proc IEEE, 95 (1), pp. 163-187; Gupta, A., Langbort, C., Basar, T., Optimal control in the presence of an intelligent jammer with limited actions (2010) IEEE Conference on Decision and Control, Atlanta, GA, pp. 1096-1101. , In:,.\pagination{\break} p; Pasqualetti, F., Dorfler, F., Bullo, F., Attack detection and identification in cyber-physical systems (2013) IEEE Trans Autom Control, 58 (11), pp. 2715-2729; Fawzi, H., Tabuada, P., Diggavi, S., Secure estimation and control for cyber-physical systems under adversarial attacks (2014) IEEE Trans Autom Control, 59 (6), pp. 1454-1467; Weimer, J., Bezzo, N., Pajic, M., Resilient parameter-invariant control with application to vehicle cruise control (2013) Control of cyber-physical systems, pp. 197-216. , Heidelberg, Germany: Springer,. In:,. p; Sou, K.C., Sandberg, H., Johansson, K.H., On the exact solution to a smart grid cyber-security analysis problem (2013) IEEE Trans Smart Grid, 4 (2), pp. 856-865; Kosut, O., Jia, L., Thomas, R.J., Malicious data attacks on the smart grid (2011) IEEE Trans Smart Grid, 2 (4), pp. 645-658; Kim, T.T., Poor, H.V., Strategic protection against data injection attacks on power grids (2011) IEEE Trans Smart Grid, 2 (2), pp. 326-333; Vamvoudakis, K.G., Hespanha, J.P., Sinopoli, B., Detection in adversarial environments (2014) IEEE Trans Autom Control, 59 (12), pp. 3209-3223; Garcia, H.E., Lin, W.C., Meerkov, S.M., Resilient monitoring systems: architecture, design, and application to boiler/turbine plant (2014) IEEE Trans Cybern, 44 (11), pp. 2010-2023; Weerakkody, S., Sinopoli, B., Kar, S., Information flow for security in control systems (2016) IEEE Conference on Decision and Control, Las Vegas, NV, pp. 5065-5072. , In:,. p; Lucia, W., Sinopoli, B., Franze, G., A set-theoretic approach for secure and resilient control of cyber-physical systems subject to false data injection attacks (2016) Science of Security for Cyber-Physical Systems Workshop, Vienna, Austria, pp. 1-5. , In:,. p; Li, Y., Chen, T., Stochastic detector against linear deception attacks on remote state estimation (2016) IEEE Conference on Decision and Control, Las Vegas, NV, pp. 6291-6296. , In:,. p; Li, Y., Shi, L., Chen, T., Detection against linear deception attacks on multi-sensor remote state estimation (2018) IEEE Trans Control Netw Syst, , Forthcoming; Yucelen, T., Haddad, W.M., Feron, E.M., Adaptive control architectures for mitigating sensor attacks in cyber-physical systems (2016) Cyber Phys Syst, 2 (2), pp. 24-52; Jin, X., Haddad, W.M., Yucelen, T., An adaptive control architecture for mitigating sensor and actuator attacks in cyber-physical systems (2017) IEEE Trans Autom Control, 62 (11), pp. 6058-6064; Manandhar, K., Cao, X., Hu, F., Detection of faults and attacks including false data injection attack in smart grid using kalman filter (2014) IEEE Trans Control Netw Syst, 1 (4), pp. 370-379; Paridari, K., Mady, A.E.D., La Porta, S., Cyber-physical-security framework for building energy management system (2016) 2016 ACM/IEEE 7th International Conference on Cyber-Physical Systems (ICCPS), Vienna, Austria, pp. 1-9. , In:,. p; Ding, D., Wang, Z., Ho, D.W., Observer-based event-triggering consensus control for multiagent systems with lossy sensors and cyber-attacks (2017) IEEE Trans Cybern, 47 (8), pp. 1936-1947; Arabi, E., Yucelen, T., Haddad, W.M., Mitigating the effects of sensor uncertainties in networked multiagent systems (2017) ASME J Dyn Syst Meas Control, 139 (4), pp. 1-11; Jin, X., Haddad, W.M., Hayakawa, T., An adaptive control architecture for cyber-physical system security in the face of sensor and actuator attacks and stochastic distrubances (2017) Proceedings of IEEE Conference on Decision and Control, pp. 1380-1385. , Melbourne, Australia:. In:,. p; Kushner, H.J., (1967) Stochastic stability and control, , New York (NY): Academic Press; Khasminskii, R.Z., (2012) Stochastic stability of differential equations, , Berlin: Springer; Kushner, H.J., (1971) Introduction to stochastic control, , New York (NY): Holt, Rinehart and Winston, Inc; Arnold, L., (1974) Stochastic differential equations: theory and applications, , New York (NY): A Wiley-Interscience Publication; Sharov, V., Stability and stabilization of stochastic systems vis-a-vis some of the variables (1978) Avtomat Telemekh, 11, pp. 63-71. , Russian; Øksendal, B., (1995) Stochastic differential equations: an introduction with applications, , Verlag Berlin, Heidelberg: Springer; Wang, H.Q., Chen, B., Lin, C., Adaptive neural tracking control for a class of stochastic nonlinear systems (2014) Int J Robust Nonlinear Control, 24 (7), pp. 1262-1280; Zhao, X., Shi, P., Zheng, X., Adaptive tracking control for switched stochastic nonlinear systems with unknown actuator dead-zone (2015) Automatica, 60, pp. 193-200; Hua, D., Kristić, M., Williams, R., Stabilization of stochastic nonlinear systems driven by noise of unknown covariance (2001) IEEE Trans Autom Control, 48, pp. 1237-1253; Arapostathis, A., Borkar, V.S., Ghosh, M.K., (2012) Ergodic control of diffusion processes, , Cambridge: Cambridge University Press; Haddad, W.M., Chellaboina, V., (2008) Nonlinear dynamical systems and control: a Lyapunov-based approach, , Princeton, NJ: Princeton University Press; Lavretsky, E., Wise, K., (2012) Robust and adaptive control with aerospace applications, , London: Springer; Polycarpou, M.M., Ioannou, P.A., A robust adaptive nonlinear control design (1996) Automatica, 32 (3), pp. 423-427; Yucelen, T., Haddad, W.M., Low-frequency learning and fast adaptation in model reference adaptive control (2013) IEEE Trans Autom Control, 58 (2), pp. 1080-1085; Liu, M., Zhang, L., Shi, P., Robust control of stochastic systems against bounded disturbances with application to flight control (2014) IEEE Trans Indus Electron, 61 (3), pp. 1504-1515; Fravolini, M.L., Yucelen, T., Campa, G., Set theoretic performance verification of low-frequency learning adaptive controllers (2015) Int J Adapt Control Signal Process, 29 (10), pp. 1243-1258","Haddad, W.M.; School of Aerospace Engineering, United States; email: wm.haddad@aerospace.gatech.edu",,,"Taylor and Francis Ltd.",,,,,23335785,,,,"English","Cyber Phy. Sys.",Article,"Final","",Scopus,2-s2.0-85053425305
"Ebrahimi J., Lowd D., Dou D.","55390988100;12140683600;22733517600;","On adversarial examples for character-level neural machine translation",2018,"COLING 2018 - 27th International Conference on Computational Linguistics, Proceedings",,,,"653","663",,46,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119433384&partnerID=40&md5=897b7e0947022f91aeaa854ff37fdb7d","Computer and Information Science Department, University of Oregon, United States","Ebrahimi, J., Computer and Information Science Department, University of Oregon, United States; Lowd, D., Computer and Information Science Department, University of Oregon, United States; Dou, D., Computer and Information Science Department, University of Oregon, United States","Evaluating on adversarial examples has become a standard procedure to measure robustness of deep learning models. Due to the difficulty of creating white-box adversarial examples for discrete text input, most analyses of the robustness of NLP models have been done through black-box adversarial examples. We investigate adversarial examples for character-level neural machine translation (NMT), and contrast black-box adversaries with a novel white-box adversary, which employs differentiable string-edit operations to rank adversarial changes. We propose two novel types of attacks which aim to remove or change a word in a translation, rather than simply break the NMT. We demonstrate that white-box adversarial examples are significantly stronger than their black-box counterparts in different attack scenarios, which show more serious vulnerabilities than previously known. In addition, after performing adversarial training, which takes only 3 times longer than regular training, we can improve the model’s robustness significantly. © 2018 COLING 2018 - 27th International Conference on Computational Linguistics, Proceedings. All rights reserved.",,"Computational linguistics; Computer aided language translation; Deep learning; Attacks scenarios; Black boxes; Character level; Different attacks; Learning models; Standard procedures; Text input; White box; Neural machine translation",,,,,"Belinkov, Yonatan, Bisk, Yonatan, Synthetic and natural noise both break neural machine translation (2018) Proceedings of ICLR; Berger, Yotam, (2017) Israel arrests Palestinian because Facebook translated’good morning’ to’attack them, , https://www.haaretz.com, Retrieved from; Chancellor, Stevie, Pater, Jessica Annette, Clear, Trustin, Gilbert, Eric, De Choudhury, Munmun, # thyghgapp: Instagram content moderation and lexical variation in pro-eating disorder communities (2016) Proceedings of the 19th ACM Conference on Computer-Supported Cooperative Work & Social Computing, pp. 1201-1213. , ACM; Costa-Jussa, Marta R, Fonollosa, José AR, Character-based neural machine translation (2016) Proceedings of ACL; Dalvi, Nilesh, Domingos, Pedro, Sanghai, Sumit, Verma, Deepak, Adversarial classification (2004) Proceedings of KDD, pp. 99-108; Ebrahimi, Javid, Rao, Anyi, Lowd, Daniel, Dou, Dejing, Hotflip: White-box adversarial examples for text classification (2018) Proceedings of ACL; Goodfellow, Ian J, Shlens, Jonathon, Szegedy, Christian, Explaining and harnessing adversarial examples (2015) Proceedings of ICLR; Jia, Robin, Liang, Percy, Adversarial examples for evaluating reading comprehension systems (2017) Proceedings of EMNLP; Kim, Yoon, Jernite, Yacine, Sontag, David, Rush, Alexander M, Character-aware neural language models (2016) Proceedings of AAAI; Lee, Jason, Cho, Kyunghyun, Hofmann, Thomas, Fully character-level neural machine translation without explicit segmentation (2017) TACL; Lowd, Daniel, Meek, Christopher, Adversarial learning (2005) Proceedings of KDD, pp. 641-647; Luong, Minh-Thang, Pham, Hieu, Manning, Christopher D, Effective approaches to attention-based neural machine translation (2015) Proceedings of EMNLP; Madry, Aleksander, Makelov, Aleksandar, Schmidt, Ludwig, Tsipras, Dimitris, Vladu, Adrian, (2017) Towards deep learning models resistant to adversarial attacks, , arXiv preprint arXiv:1706.06083; Mauro, Cettolo, Jan, Niehues, Sebastian, Stüker, Luisa, Bentivogli, Roldano, Cattoni, Marcello, Federico, The iwslt 2016 evaluation campaign (2016) International Workshop on Spoken Language Translation; Miyato, Takeru, Dai, Andrew M, Goodfellow, Ian, Adversarial training methods for semi-supervised text classification (2017) Proceedings of ICLR; Sennrich, Rico, Haddow, Barry, Birch, Alexandra, Neural machine translation of rare words with subword units (2016) Proceedings of ACL; Shaham, Uri, Yamada, Yutaro, Negahban, Sahand, (2015) Understanding adversarial training: Increasing local stability of neural nets through robust optimization, , arXiv preprint arXiv:1511.05432; Tramèr, Florian, Kurakin, Alexey, Papernot, Nicolas, Boneh, Dan, McDaniel, Patrick, Ensemble adversarial training: Attacks and defenses (2018) Proceedings of ICLR; Wiseman, Sam, Rush, Alexander M, Sequence-to-sequence learning as beam-search optimization (2016) Proceedings of EMNLP; Zhao, Zhengli, Dua, Dheeru, Singh, Sameer, Generating natural adversarial examples (2018) Proceedings of ICLR; Zubiaga, Arkaitz, Liakata, Maria, Procter, Rob, Hoi, Geraldine Wong Sak, Tolmie, Peter, Analysing how people orient to and spread rumours in social media by looking at conversational threads (2016) PloS one, 11 (3), p. e0150989",,"Bender E.M.Derczynski L.Isabelle P.","Amazon Alexa;Baidu;Disney Research;et al.;Lenovo;Linguist List","Association for Computational Linguistics (ACL)","27th International Conference on Computational Linguistics, COLING 2018","20 August 2018 through 26 August 2018",,172932,,9781948087506,,,"English","COLING - Int. Conf. Comput. Linguist., Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85119433384
"Block A.R., Gupta D., Maji H.K., Nguyen H.H.","57195490607;29767577700;35113564800;57195490164;","Secure Computation Using Leaky Correlations (Asymptotically Optimal Constructions)",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11240 LNCS",,,"36","65",,1,"10.1007/978-3-030-03810-6_2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115049215&doi=10.1007%2f978-3-030-03810-6_2&partnerID=40&md5=38045640c6b8af08ded469e5cf7b966c","Department of Computer Science, Purdue University, West Lafayette, IN, United States; Microsoft Research, Bangalore, India","Block, A.R., Department of Computer Science, Purdue University, West Lafayette, IN, United States; Gupta, D., Microsoft Research, Bangalore, India; Maji, H.K., Department of Computer Science, Purdue University, West Lafayette, IN, United States; Nguyen, H.H., Department of Computer Science, Purdue University, West Lafayette, IN, United States","Most secure computation protocols can be effortlessly adapted to offload a significant fraction of their computationally and cryptographically expensive components to an offline phase so that the parties can run a fast online phase and perform their intended computation securely. During this offline phase, parties generate private shares of a sample generated from a particular joint distribution, referred to as the correlation. These shares, however, are susceptible to leakage attacks by adversarial parties, which can compromise the security of the secure computation protocol. The objective, therefore, is to preserve the security of the honest party despite the leakage performed by the adversary on her share. Prior solutions, starting with n-bit leaky shares, either used 4 messages or enabled the secure computation of only sub-linear size circuits. Our work presents the first 2-message secure computation protocol for 2-party functionalities that have circuit-size despite -bits of leakage, a qualitatively optimal result. We compose a suitable 2-message secure computation protocol in parallel with our new 2-message correlation extractor. Correlation extractors, introduced by Ishai, Kushilevitz, Ostrovsky, and Sahai (FOCS–2009) as a natural generalization of privacy amplification and randomness extraction, recover “fresh” correlations from the leaky ones, which are subsequently used by other cryptographic protocols. We construct the first 2-message correlation extractor that produces -bit fresh correlations even after -bit leakage. Our principal technical contribution, which is of potential independent interest, is the construction of a family of multiplication-friendly linear secret sharing schemes that is simultaneously a family of small-bias distributions. We construct this family by randomly “twisting then permuting” appropriate Algebraic Geometry codes over constant-size fields. © 2018, International Association for Cryptologic Research.",,,,,,,"Alon, N., Goldreich, O., Håstad, J., Peralta, R., Simple constructions of almost k-wise independent random variables (1990) 31St FOCS, pp. 544-553. , , pp. , IEEE Computer Society Press, October; Alon, N., Roichman, Y., Random cayley graphs and expanders (1994) Random Struct. Algorithms, 5 (2), pp. 271-284; Applebaum, B., Garbled circuits as randomized encodings of functions: A primer. Cryptology ePrint Archive (2017) Report 2017/385, , http://eprint.iacr.org/2017/385; Applebaum, B., Damgård, I., Ishai, Y., Nielsen, M., Zichron, L.: Secure arithmetic computation with constant computational overhead. In: Katz, J., Shacham, H. (eds.) CRYPTO 2017. LNCS, vol. 10401, pp. 223–254. Springer, Cham (2017). https://doi.org/10.1007/978-3-319-63688-7 8; Applebaum, B., Ishai, Y., Kushilevitz, E., (2004) Cryptography in Nc0 . In: 45Th FOCS, pp. 166-175. , , pp. , IEEE Computer Society Press, October; Beaver, D.: Efficient multiparty protocols using circuit randomization. In: Feigenbaum, J. (ed.) CRYPTO 1991. LNCS, vol. 576, pp. 420–432. Springer, Heidelberg (1992). https://doi.org/10.1007/3-540-46766-1 34; Ben-David, A., Nisan, N., Pinkas, B., FairplayMP: A system for secure multi-party computation (2008) ACM CCS, (2008), pp. 257-266. , Ning, P., Syverson, P.F., Jha, S. (eds.), pp. , ACM Press, October; Block, A.R., Gupta, D., Maji, H.K., Nguyen, H.H., Secure computation using leaky correlations (Asymptotically optimal constructions). Cryptology ePrint Archive (2018) Report 2018/372, , https://eprint.iacr.org/2018/372; Block, A.R., Maji, H.K., Nguyen, H.H.: Secure computation based on leaky correlations: high resilience setting. In: Katz, J., Shacham, H. (eds.) CRYPTO 2017. LNCS, vol. 10402, pp. 3–32. Springer, Cham (2017). https://doi.org/10.1007/978-3-319-63715-0 1; Canetti, R., Security and composition of multiparty cryptographic protocols (2000) J. Cryptology, 13 (1), pp. 143-202; Cascudo, I., Damgård, I., Farràs, O., Ranellucci, S.: Resource-efficient OT combiners with active security. In: Kalai, Y., Reyzin, L. (eds.) TCC 2017. LNCS, vol. 10678, pp. 461–486. Springer, Cham (2017). https://doi.org/10.1007/978-3-319-70503-3 15; Cenk, M., Özbudak, F., On multiplication in finite fields (2010) J. Complex., 26 (2), pp. 172-186; Chen, H., Cramer, R.: Algebraic geometric secret sharing schemes and secure multi-party computations over small fields. In: Dwork, C. (ed.) CRYPTO 2006. LNCS, vol. 4117, pp. 521–536. Springer, Heidelberg (2006). https://doi.org/10. 1007/11818175 31; Chudnovsky, D.V., Chudnovsky, G.V., Algebraic complexities and algebraic curves over finite fields (1987) Proc. Natl. Acad. Sci., 84 (7), pp. 1739-1743; Damgård, I., Pastro, V., Smart, N., Zakarias, S.: Multiparty computation from somewhat homomorphic encryption. In: Safavi-Naini, R., Canetti, R. (eds.) CRYPTO 2012. LNCS, vol. 7417, pp. 643–662. Springer, Heidelberg (2012). https://doi.org/10.1007/978-3-642-32009-5 38; Dodis, Y., Ostrovsky, R., Reyzin, L., Smith, A., Fuzzy extractors: How to generate strong keys from biometrics and other noisy data (2008) SIAM J. Comput., 38 (1), pp. 97-139. , http://dx.doi.org/10.1137/060651380; Dodis, Y., Smith, A., Correcting errors without leaking partial information (2005) 37Th ACM STOC, pp. 654-663. , Gabow, H.N., Fagin, R. (eds.), pp. , ACM Press, May; Döttling, N., Ghosh, S., Nielsen, J.B., Nilges, T., Trifiletti, R., TinyOLE: Efficient actively secure two-party computation from oblivious linear function evaluation (2017) ACM CCS 17, pp. 2263-2276. , Thuraisingham, B.M., Evans, D., Malkin, T., Xu, D. (eds.), pp. , ACM Press, October/November; Garcia, A., Stichtenoth, H., On the asymptotic behaviour of some towers of function fields over finite fields (1996) J. Number Theory, 61 (2), pp. 248-273; Goldreich, O., Wigderson, A., Tiny families of functions with random properties: A quality-size trade-off for hashing (1997) Random Struct. Algorithms, 11 (4), pp. 315-343. , https://doi.org/10.1002/(SICI)1098-2418(199712)11:4; Goppa, V.D., Codes on algebraic curves (1981) Soviet Math. Dokl., Pp. 170–172; Gupta, D., Ishai, Y., Maji, H.K., Sahai, A.: Secure computation from leaky correlated randomness. In: Gennaro, R., Robshaw, M. (eds.) CRYPTO 2015. LNCS, vol. 9216, pp. 701–720. Springer, Heidelberg (2015). https://doi.org/10.1007/978-3-662-48000-7 34; Harnik, D., Ishai, Y., Kushilevitz, E., Nielsen, J.B.: OT-combiners via secure computation. In: Canetti, R. (ed.) TCC 2008. LNCS, vol. 4948, pp. 393–411. Springer, Heidelberg (2008). https://doi.org/10.1007/978-3-540-78524-8 22; Harnik, D., Kilian, J., Naor, M., Reingold, O., Rosen, A.: On robust combiners for oblivious transfer and other primitives. In: Cramer, R. (ed.) EUROCRYPT 2005. LNCS, vol. 3494, pp. 96–113. Springer, Heidelberg (2005). https://doi.org/10.1007/11426639 6; Ishai, Y., Kushilevitz, E.: Perfect constant-round secure computation via perfect randomizing polynomials. In: Widmayer, P., Ruiz, F.T., Bueno, R.M., Hennessy, M., Eidenbenz, S., Conejo, R. (eds.) ICALP 2002. LNCS, vol. 2380, pp. 244–256. Springer, Heidelberg (2002). https://doi.org/10.1007/3-540-45465-9 22; Ishai, Y., Kushilevitz, E., Ostrovsky, R., Sahai, A., Extracting correlations (2009) 50Th FOCS, pp. 261-270. , , pp. , IEEE Computer Society Press, October; Ishai, Y., Maji, H.K., Sahai, A., Wullschleger, J., Single-use OT combiners with near-optimal resilience (2014) 2014 IEEE International Symposium on Information Theory, Honolulu, HI, USA, 29 June–4 July 2014, Pp. 1544–1548; Ishai, Y., Prabhakaran, M., Sahai, A.: Founding cryptography on oblivious transfer – efficiently. In: Wagner, D. (ed.) CRYPTO 2008. LNCS, vol. 5157, pp. 572–591. Springer, Heidelberg (2008). https://doi.org/10.1007/978-3-540-85174-5 32; Keller, M., Orsini, E., Scholl, P., MASCOT: Faster malicious arithmetic secure computation with oblivious transfer (2016) ACM CCS, (2016), pp. 830-842. , Weippl, E.R., Katzenbeisser, S., Kruegel, C., Myers, A.C., Halevi, S. (eds.), pp. , ACM Press, October; Kilian, J., A general completeness theorem for two-party games (1991) 23Rd ACM STOC, pp. 553-560. , , pp. , ACM Press, May; Malkhi, D., Nisan, N., Pinkas, B., Sella, Y., Fairplay-secure two-party computation system (2004) Proceedings of the 13Th USENIX Security Symposium, 9–13 August 2004, San Diego, pp. 287-302. , , pp; Massey, J.L., Some applications of coding theory in cryptography (1995) Codes and Ciphers: Cryptography and Coding IV, pp. 33-47. , , pp; Meier, R., Przydatek, B.: On robust combiners for private information retrieval and other primitives. In: Dwork, C. (ed.) CRYPTO 2006. LNCS, vol. 4117, pp. 555–569. Springer, Heidelberg (2006). https://doi.org/10.1007/11818175 33; Meier, R., Przydatek, B., Wullschleger, J.: Robuster combiners for oblivious transfer. In: Vadhan, S.P. (ed.) TCC 2007. LNCS, vol. 4392, pp. 404–418. Springer, Heidelberg (2007). https://doi.org/10.1007/978-3-540-70936-7 22; Naor, J., Naor, M., Small-bias probability spaces: Efficient constructions and applications (1990) 22Nd ACM STOC, pp. 213-223. , , pp. , ACM Press, May; Naor, M., Pinkas, B., Computationally secure oblivious transfer (2005) J. Cryptology, 18 (1), pp. 1-35; Nielsen, J.B., Nordholt, P.S., Orlandi, C., Burra, S.S.: A new approach to practical active-secure two-party computation. In: Safavi-Naini, R., Canetti, R. (eds.) CRYPTO 2012. LNCS, vol. 7417, pp. 681–700. Springer, Heidelberg (2012). https://doi.org/10.1007/978-3-642-32009-5 40; Pless, V., (2011) Introduction to the Theory of Error-Correcting Codes, 48. , , vol. , Wiley; Przydatek, B., Wullschleger, J.: Error-tolerant combiners for oblivious primitives. In: Aceto, L., Damgård, I., Goldberg, L.A., Halldórsson, M.M., Ingólfsdóttir, A., Walukiewicz, I. (eds.) ICALP 2008. LNCS, vol. 5126, pp. 461–472. Springer, Heidelberg (2008). https://doi.org/10.1007/978-3-540-70583-3 38; Rao, A., An exposition of bourgain’s 2-source extractor (2007) ECCCTR: Electronic Colloquium on Computational Complexity Technical Reports; Vladut, S., Nogin, D., Tsfasman, M., (2007) Algebraic Geometric Codes: Basic Notions, , American Mathematical Society, Boston; Wolf, S., Wullschleger, J.: Oblivious transfer is symmetric. In: Vaudenay, S. (ed.) EUROCRYPT 2006. LNCS, vol. 4004, pp. 222–232. Springer, Heidelberg (2006). https://doi.org/10.1007/11761679 14","Block, A.R.; Department of Computer Science, United States; email: block9@purdue.edu","Beimel A.Dziembowski S.",,"Springer Science and Business Media Deutschland GmbH","16th International Conference on Theory of Cryptography, TCC 2018","11 November 2018 through 14 November 2018",,268329,03029743,9783030038090,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","",Scopus,2-s2.0-85115049215
"Li Y., Bertino E., Abdcl-Khalik H.S.","57196442761;7102307605;57223666016;","Online adversarial learning of reactor state",2018,"International Conference on Physics of Reactors, PHYSOR 2018: Reactor Physics Paving the Way Towards More Efficient Systems","Part F168384-6",,,"3594","3602",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106007445&partnerID=40&md5=89d00b1ac89f01a528407e553f06e349","School of Nuclear Engineering, Purdue University, 400 Central Drive, West Lafayette, IN  47907, United States; Computer Science Department, Purdue University, 305 N University St., West Lafayette, IN  47907, United States","Li, Y., School of Nuclear Engineering, Purdue University, 400 Central Drive, West Lafayette, IN  47907, United States; Bertino, E., Computer Science Department, Purdue University, 305 N University St., West Lafayette, IN  47907, United States; Abdcl-Khalik, H.S., School of Nuclear Engineering, Purdue University, 400 Central Drive, West Lafayette, IN  47907, United States","This paper is in support of our recent efforts to designing intelligent defenses against false data injection attacks, where false data are injected in the raw data used to control the reactor. Adopting a game-model between the attacker and the defender, we focus here on how the attacker may estimate reaetor state in order to inject an attack that can bypass normal reactor anomaly and outlier detection checks. This approach is essential to designing defensive strategies that can anticipate the attackers moves. More importantly, it is to alert the community that defensive methods based on approximate physics models could be bypassed by the attacker who can approximate the models in an online mode during a lie-in-wait period. For illustration, we employ a simplified point kinetics model and show how an attacker, once gaining access to the reactor raw data, i.e.. instrumentation readings, can inject small perturbations to learn die reaetor dynamic behavior. In our context, this equates to estimating the reactivity feedback coefficients, e.g., Doppler. Xenon poisoning, etc. We employ a non-parametric learning approach that employs alternating conditional estimation in conjunction with discrete Fourier transform and curve fitting techniques to estimate reactivity coefficients. An Iranian model of the Bushehr reactor is employed for demonstration. Results indicate that very accurate estimation of reaetor state could be achieved using the proposed learning method. © 2018 by PHYSOR 2018. All Rights Reserved.","ACE; Fast Fourier transform; Inverse method","Curve fitting; Discrete Fourier transforms; E-learning; Pavements; Adversarial learning; Curve fitting technique; Defensive strategies; False data injection attacks; Point-kinetics models; Reactivity coefficients; Reactivity feedback; Small perturbations; Learning systems",,,,,"Bunn, M., Sagan, S. D., A Worst Practices Guide to Insider Threats: Lessons from Past Mistakes (2014) AMERICAN ACADEMY OF ARTS & SCIENCES; Kind, A., Stoecklin, M. P., Dimitropoulos, X., Histogram-Based Traffic Anomaly Detection (2009) IEEE Transactions on Network Service Management, 6 (2). , June; Liu, Y., Ning, P., Reiter, M. K., (2011) False data injection attacks against state estimation in electric power grids, 14 (1); Hashemian, H. M., (2006) Maintenance of Process Instrumentation in Nuclear Power Plants, , Springer; Fantoni, P., Mazzola, A., (1990) Applications Of Autoassociative Neural Networksfor Signal Validation In Accident Management, 37 (2), pp. 1040-1047; Fantoni, P., Experiences And Applications Of Peano For Online Monitoring In Power Plants (2005) Progress in Nuclear Energy, 46 (2-3), pp. 206-225; https://en.wikipedia.org/wiki/Nonparametricregression; Breiman, L., Friedman, J. H., Estimating Optimal Transformations Multiple Regression and Correlation (1985) Journal of the American Statistical Association, 80 (391). , September Theory and Method; Zarei, M., Ghaderi, R., Minuchehr, A., Progress in Nuclear Energy Space independent xenon oscillations control in VVER reactor: A bifurcation analysis approach (2016) Progress in Nuclear Energy, 88, pp. 19-27; Touran, N. W., (2012), https://github.com/partofihething/ace",,,,"Sociedad Nuclear Mexicana, A.C.","2018 International Conference on Physics of Reactors: Reactor Physics Paving the Way Towards More Efficient Systems, PHYSOR 2018","22 April 2018 through 26 April 2018",,168384,,9781713808510,,,"English","Int. Conf. Phys. React., PHYSOR: React. Phys. Paving Way Towards More Effic. Syst.",Conference Paper,"Final","",Scopus,2-s2.0-85106007445
"Kim K., Woo S.S.","57211947608;57202046772;","When george clooney is not george clooney: Using genattack to deceive amazon’s and naver’s celebrity recognition apis",2018,"IFIP Advances in Information and Communication Technology","529",,,"355","369",,1,"10.1007/978-3-319-99828-2_25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090288555&doi=10.1007%2f978-3-319-99828-2_25&partnerID=40&md5=bf7ddce07b31bb884d067faf25a40264","The State University of New York, Korea (SUNY-Korea), Incheon, South Korea; Stony Brook University, Stony Brook, NY, United States; Artificial Intelligence Research Institute (AIRI), Seongnam, South Korea","Kim, K., The State University of New York, Korea (SUNY-Korea), Incheon, South Korea, Stony Brook University, Stony Brook, NY, United States, Artificial Intelligence Research Institute (AIRI), Seongnam, South Korea; Woo, S.S., The State University of New York, Korea (SUNY-Korea), Incheon, South Korea, Stony Brook University, Stony Brook, NY, United States","In recent years, significant advancements have been made in detecting and recognizing contents of images using Deep Neural Networks (DNNs). As a result, many companies offer image recognition APIs for use in diverse applications. However, image classification algorithms trained with DNNs can misclassify adversarial examples, posing a significant threat to critical applications. In this work, we present a novel way to generate adversarial example images using an evolutionary genetic algorithm (GA). Our algorithm builds adversarial images by iteratively adding noise to the original images. Unlike DNN based adversarial example generations by other researchers, our approach does not require GPU resources and access to the target DNNs’ parameters. We design, GenAttack, a simple yet powerful attack algorithm to create adversarial examples using complex celebrity images and evaluate those with real-world celebrity recognition APIs from Amazon and Naver. With our attack, we successfully deceive Amazon’s and Naver’s APIs with a success probability of 86.6% and 100%, respectively. Our work demonstrates the practicability of generating adversarial examples and successfully fooling the state-of-the-art commercial image recognition systems. © IFIP International Federation for Information Processing 2018.","Adversarial example; Black-box attack; Genetic algorithm","Computer privacy; Data privacy; Deep neural networks; Image recognition; Iterative methods; Critical applications; Diverse applications; Image classification algorithms; Image recognition system; Original images; Real-world; State of the art; Genetic algorithms",,,,,"Amazon recognition - deep learning-based image analysis, , https://aws.amazon.com/rekognition, Accessed 30 Dec 2017; Naver - clova face recognition, , https://www.ncloud.com/product/aiService/cfr, Accessed 30 Dec 2017; Barreno, M., Nelson, B., Joseph, A.D., Tygar, J., The security of machine learning (2010) Mach. Learn, 81 (2), pp. 121-148; Biggio, B., Evasion attacks against machine learning at test time (2013) ECML PKDD 2013. LNCS (LNAI), 8190, pp. 387-402. , https://doi.org/10.1007/978-3-642-40994-325, Blockeel, H., Kersting, K., Nijssen, S., ˇZelezn´y, F. (eds) Springer, Heidelberg; Bradshaw, J., Matthews, A.G.d.G., Ghahramani, Z., (2017) Adversarial examples, uncertainty, and transfer testing robustness in Gaussian process hybrid deep networks, , arXiv preprint arXiv:1707.02476; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP), pp. 39-57. , IEEE; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and harnessing adversarial examples, , arXiv preprint arXiv:1412.6572; He, K., Gkioxari, G., Doll´ar, P., Girshick, R., (2017) Mask R-CNN, , arXiv preprint arXiv:1703.06870; Hosseini, H., Xiao, B., Poovendran, R., (2017) Deceiving Google’s cloud video intelligence API built for summarizing videos, , arXiv preprint arXiv:1703.09793; Hosseini, H., Xiao, B., Poovendran, R., (2017) Googles cloud vision API is not robust to noise, , arXiv preprint arXiv:1704.05051; Huang, R., Xu, B., Schuurmans, D., Szepesv´ari, C., (2015) Learning with a strong adversary, , arXiv preprint arXiv:1511.03034; Kurakin, A., Goodfellow, I.J., Bengio, S., (2016) Adversarial machine learning at scale, , arXiv preprint arXiv:1611.01236; Lu, J., Issaranon, T., Forsyth, D.A., (2017) SafetyNet: Detecting and rejecting adversarial examples robustly, , CoRR, abs/1704.00103; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards deep learning models resistant to adversarial attacks, , arXiv preprint arXiv:1706.06083; Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , EPFL-CONF-218057; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 427-436; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519. , ACM; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) 2016 IEEE European Symposium on Security and Privacy (EuroS&P), pp. 372-387. , IEEE; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) 2016 IEEE Symposium on Security and Privacy (SP), pp. 582-597. , IEEE; Ren, S., He, K., Girshick, R., Sun, J., (2016) Faster r-CNN: Towards real-time object detection with region proposal networks, , arXiv preprint arXiv:1506.01497; Song, Y., Kim, T., Nowozin, S., Ermon, S., Kushman, N., (2017) Pixeldefend: Leveraging generative models to understand and defend against adversarial examples, , arXiv preprint arXiv:1710.10766; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A., (2016) Inception-v4, inception-resnet and the impact of residual connections on learning, , arXiv preprint arXiv:1602.07261; Szegedy, C., (2013) Intriguing properties of neural networks, , arXiv preprint arXiv:1312.6199; Tram`er, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., (2017) Ensemble adversarial training: Attacks and defenses, , arXiv preprint arXiv:1705.07204; Vidnerov´a, P., Neruda, R., Evolutionary generation of adversarial examples for deep and shallow machine learning models (2016) Proceedings of the 3rd Multidisciplinary International Social Networks Conference on Social Informatics 2016, Data Science 2016, p. 43. , ACM; Yuan, X., He, P., Zhu, Q., Bhat, R.R., Li, X., (2017) Adversarial examples: Attacks and defenses for deep learning, , arXiv preprint arXiv:1712.07107","Woo, S.S.; The State University of New York, South Korea; email: simon.woo@sunykorea.ac.kr
Woo, S.S.; Stony Brook UniversityUnited States; email: simon.woo@sunykorea.ac.kr","Janczewski L.J.Kutylowski M.",,"Springer",,,,218249,18684238,9783319998275,,,"English","IFIP Advances in Information and Communication Technology",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85090288555
"Eykholt K., Evtimov I., Fernandes E., Li B., Rahmati A., Tramèr F., Prakash A., Kohno T., Song D.","57195202771;57207759307;54918888300;57207865075;57076113200;56878876400;7202316627;7201820043;7402443870;","Physical adversarial examples for object detectors",2018,"12th USENIX Workshop on Offensive Technologies, WOOT 2018, co-located with USENIX Security 2018",,,,"","",,74,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084164612&partnerID=40&md5=0bbb45b90f37d6eddcafdaf834e8dc37","University of Michigan, United States; University of Washington, United States; University of California, Berkeley, United States; Stony Brook University, United States; Stanford University, United States; Samsung Research America, United States","Eykholt, K., University of Michigan, United States; Evtimov, I., University of Washington, United States; Fernandes, E., University of Washington, United States; Li, B., University of California, Berkeley, United States; Rahmati, A., Stony Brook University, United States, Samsung Research America, United States; Tramèr, F., Stanford University, United States; Prakash, A., University of Michigan, United States; Kohno, T., University of Washington, United States; Song, D., University of California, Berkeley, United States","Deep neural networks (DNNs) are vulnerable to adversarial examples—maliciously crafted inputs that cause DNNs to make incorrect predictions. Recent work has shown that these attacks generalize to the physical domain, to create perturbations on physical objects that fool image classifiers under a variety of real-world conditions. Such attacks pose a risk to deep learning models used in safety-critical cyber-physical systems. In this work, we extend physical attacks to more challenging object detection models, a broader class of deep learning algorithms widely used to detect and label multiple objects within a scene. Improving upon a previous physical attack on image classifiers, we create perturbed physical objects that are either ignored or mislabeled by object detection models. We implement a Disappearance Attack, in which we cause a Stop sign to “disappear” according to the detector—either by covering the sign with an adversarial Stop sign poster, or by adding adversarial stickers onto the sign. In a video recorded in a controlled lab environment, the state-of-the-art YOLO v2 detector failed to recognize these adversarial Stop signs in over 85% of the video frames. In an outdoor experiment, YOLO was fooled by the poster and sticker attacks in 72.5% and 63.5% of the video frames respectively. We also use Faster R-CNN, a different object detection model, to demonstrate the transferability of our adversarial perturbations. The created poster perturbation is able to fool Faster R-CNN in 85.9% of the video frames in a controlled lab environment, and 40.2% of the video frames in an outdoor environment. Finally, we present preliminary results with a new Creation Attack, wherein innocuous physical stickers fool a model into detecting nonexistent objects. © 2018 USENIX Association. All rights reserved.",,"Deep neural networks; Embedded systems; Image classification; Image enhancement; Learning algorithms; Object recognition; Safety engineering; Image Classifiers; Multiple objects; Object detectors; Outdoor environment; Outdoor experiment; Physical attacks; Physical objects; State of the art; Object detection",,,,,"Athalye, A., Sutskever, I., (2017) Synthesizing Robust Adversarial Examples, , arXiv preprint; Brown, T.B., Mané, D., Roy, A., Abadi, M., Gilmer, J., (2017) Adversarial Patch, , arXiv preprint; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium on, pp. 39-57. , IEEE; Evtimov, I., Eykholt, K., Fernandes, E., Kohno, T., Li, B., Prakash, A., Rahmati, A., Song, D., Robust physical-world attacks on machine learning models (2018) CVPR’18; Girshick, R., Fast R-CNn (2015) Proceedings of the International Conference on Computer Vision (ICCV); Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint; Kos, J., Fischer, I., Song, D., (2017) Adversarial Examples for Generative Models, , arXiv preprint; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint; Lillicrap, T.P., Hunt, J.J., Pritzel, A., Heess, N., Erez, T., Tassa, Y., Silver, D., Wierstra, D., (2015) Continuous Control with Deep Reinforcement Learning, , arXiv preprint; Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., Fu, C.-Y., Berg, A.C., SSD: Single shot multibox detector (2016) European Conference on Computer Vision, pp. 21-37. , Springer; Lu, J., Sibai, H., Fabry, E., Forsyth, D.A., NO need to worry about adversarial examples in object detection in autonomous vehicles (2017) CoRR, , abs/1707.03501; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., (2015) Deepfool: A Simple and Accurate Method to Fool Deep Neural Networks, , arXiv preprint; Nguyen, A., Yosinski, J., Cluneand, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Computer Vision and Pattern Recognition (CVPR); Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387. , IEEE; Redmon, J., Divvala, S., Girshick, R., Farhadi, A., You only look once: Unified, real-time object detection (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 779-788; Redmon, J., Farhadi, A., YOLO9000: Better, faster, stronger (2016) CoRR, , abs/1612.08242; Sabour, S., Cao, Y., Faghri, F., Fleet, D.J., (2015) Adversarial Manipulation of Deep Representations, , arXiv preprint; Sermanet, P., Eigen, D., Zhang, X., Mathieu, M., Fergus, R., Lecun, Y., Overfeat: Integrated recognition, localization and detection using convolutional networks (2013) International Conference on Learning Representations (ICLR) (Banff); Shaoqing, R.E.N., Kaiming, H.E., (2015) Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks, , R. G. J. S. arXiv preprint; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540. , ACM; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A.L., Adversarial examples for semantic segmentation and object detection (2017) CoRR, , abs/1703.08603",,,,"USENIX Association","12th USENIX Workshop on Offensive Technologies, WOOT 2018, co-located with USENIX Security 2018","13 August 2018 through 14 August 2018",,156097,,,,,"English","USENIX Workshop Offensive Technol., WOOT, co-located USENIX Secur.",Conference Paper,"Final","",Scopus,2-s2.0-85084164612
"Garofalo G., Rimmer V., van Hamme T., Preuveneers D., Joosen W.","36508897200;57195926268;57194765851;8850023700;57202521929;","Fishy faces: Crafting adversarial images to poison face authentication",2018,"12th USENIX Workshop on Offensive Technologies, WOOT 2018, co-located with USENIX Security 2018",,,,"","",,3,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084161060&partnerID=40&md5=a91d8f0d8ed60b22173b65b720bce6da","Imec-DistriNet, KU Leuven, Belgium","Garofalo, G., Imec-DistriNet, KU Leuven, Belgium; Rimmer, V., Imec-DistriNet, KU Leuven, Belgium; van Hamme, T., Imec-DistriNet, KU Leuven, Belgium; Preuveneers, D., Imec-DistriNet, KU Leuven, Belgium; Joosen, W., Imec-DistriNet, KU Leuven, Belgium","Face recognition systems are becoming a prevalent authentication solution on smartphones. This work is the first to deploy a poisoning attack against an authentication system based on a state-of-the-art face recognition technique. The attack is executed against the underlying SVM learning model that classifies face templates extracted by the FaceNet deep neural network. We demonstrate how an intelligent attacker can undermine the reliability of the authentication system through injecting a single intelligently crafted adversarial image to its training data. The most successful attacks within our evaluation framework trigger an authentication error of more than 50%. Our research illustrates the urge to evaluate and protect face authentication against adversarial machine learning. © 2018 USENIX Association. All rights reserved.",,"Authentication; Deep neural networks; Authentication solutions; Authentication systems; Evaluation framework; Face authentication; Face recognition systems; Face recognition technique; Poisoning attacks; State of the art; Face recognition",,,,,"Amos, B., Ludwiczuk, B., Satyanarayanan, M., (2016) Openface: A General-Purpose Face Recognition Library with Mobile Applications, , Tech. rep., CMU-CS-16-118, CMU School of Computer Science; Biggio, B., Didaci, L., Fumera, G., Roli, F., Poisoning attacks to compromise face templates (2013) 2013 International Conference on Biometrics (ICB), pp. 1-7. , June; Biggio, B., Nelson, B., Laskov, P., (2012) Poisoning Attacks against Support Vector Machines, , arXiv preprint; Bradski, G., The OpenCV library (2000) Dr. Dobb’s Journal of Software Tools; Gadaleta, M., Rossi, M., IDNet: Smartphone-based gait recognition with convolutional neural networks (2018) Pattern Recognition, 74, pp. 25-37; Galbally, J., Marcel, S., Fierrez, J., Biometric antispoofing methods: A survey in face recognition (2014) IEEE Access, 2, pp. 1530-1552; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, pp. 2672-2680; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and Harnessing Adversarial Examples; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations; King, D.E., Dlib-mL: A machine learning toolkit (2009) Journal of Machine Learning Research, 10, pp. 1755-1758; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial Examples in the Physical World; Matovu, R., Serwadda, A., Your substance abuse disorder is an open secret! gleaning sensitive personal information from templates in an EEG-based authentication system (2016) 2016 IEEE 8th International Conference on Biometrics Theory, Applications and Systems (BTAS), pp. 1-7. , Sept; Ng, H.W., Winkler, S., A data-driven approach to cleaning large face datasets (2014) 2014 IEEE International Conference on Image Processing (ICIP), pp. 343-347. , Oct; Nogueira, R.F., de Alencar Lotufo, R., Machado, R.C., Fingerprint liveness detection using convolutional neural networks (2016) IEEE Transactions on Information Forensics and Security, 11 (6), pp. 1206-1213. , June; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519. , New York, NY, USA, ASIA CCS’17, ACM; Papernot, N., McDaniel, P.D., Goodfellow, I.J., Transferability in machine learning: From phenomena to black-box attacks using adversarial samples (2016) CoRR, , abs/1605.07277; Patel, K., Han, H., Jain, A.K., Secure face unlock: Spoof detection on smartphones (2016) IEEE Transactions on Information Forensics and Security, 11 (10), pp. 2268-2283. , Oct; Schölkopf, B., Williamson, R., Smola, A., Shawetaylor, J., Platt, J., Support vector method for novelty detection (1999) Proceedings of the 12th International Conference on Neural Information Processing Systems, pp. 582-588. , Cambridge, MA, USA, NIPS’99, MIT Press; Schroff, F., Kalenichenko, D., Philbin, J., FaceNet: A unified embedding for face recognition and clustering (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 815-823; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540. , ACM; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., (2017) Adversarial Generative Nets: Neural Network Attacks on State-of-The-Art Face Recognition, , arXiv preprint; Smutz, C., Stavrou, A., Malicious pdf detection using metadata and structural features (2012) Proceedings of the 28th Annual Computer Security Applications Conference, pp. 239-248. , New York, NY, USA, ACSAC’12, ACM; Suciu, O., Marginean, R., Kaya, Y., III, Dumitras, T., When does machine learning fail? Generalized transferability for evasion and poisoning attacks (2018) CoRR, , H. D., AND abs/1803.06975; Turk, M.A., Pentland, A.P., Face recognition using eigenfaces (1991) Proceedings. 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pp. 586-591. , Jun; Xiao, H., Xiao, H., Eckert, C., Adversarial label flips attack on support vector machines (2012) Proceedings of the 20thEuropeanConferenceonArtificialIntelligence, pp. 870-875. , Amsterdam, The Netherlands, The Netherlands, ECAI’12, IOS Press",,,,"USENIX Association","12th USENIX Workshop on Offensive Technologies, WOOT 2018, co-located with USENIX Security 2018","13 August 2018 through 14 August 2018",,156097,,,,,"English","USENIX Workshop Offensive Technol., WOOT, co-located USENIX Secur.",Conference Paper,"Final","",Scopus,2-s2.0-85084161060
"Beigi G.","56465110300;","Social media and user privacy",2018,"2018 International Conference on Social Computing, Behavioral-Cultural Modeling, and Prediction and Behavior Representation in Modeling and Simulation, BRiMS 2018",,,,"","",,1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084097093&partnerID=40&md5=c7c9fd683b46aae8c437bbd41b905867","Arizona State University, Tempe, AZ, United States","Beigi, G., Arizona State University, Tempe, AZ, United States","Online users generate tremendous amounts of data. To better serve users, it is required to share the user-related data among researchers, advertisers and application developers. Publishing such datawould raise more concerns on user privacy. To encourage data sharingand mitigate user privacy concerns, a number of anonymization and deanonymization algorithms have been developed to help protect privacyof users. This paper reviews my doctoral research on online users privacyspecifically in social media. In particular, I propose a new adversarial attack specialized for social media data. I further provide a principled wayto assess effectiveness of anonymizing different aspects of social mediadata. My work sheds light on new privacy risks in social media data dueto innate heterogeneity of user-generated data. © 2018 Curran Associates Inc.. All rights reserved.","Anonymization; De-anonymization; Privacy; Social Media","Social networking (online); Anonymization; Application developers; Deanonymization; Doctoral research; Privacy risks; Social media; Social media datum; User-generated; Data privacy",,,,,"Beigi, G., Shu, K., Zhang, Y., Liu, H., Securing Social Media User Data-An Adversarial Approach The 29th ACM International Conference on Hypertext and Social Media (HT-18; Beigi, G., Liu, H., Similar but Different: Exploiting Users' Congruity for Recommendation Systems (2018) International Conference on Social Computing, Behavioral-Cultural Modeling, and Prediction, , Springer; Narayanan, A., Shmatikov, V., De-anonymizing social networks (2009) IEEE Symposium on Security and Privacy; Alvari, H., Shakarian, P., Snyder, J.E.K., Semi-supervised learning for detecting human trafficking (2017) Security Informatics 6, 1 (1); Terzi, E., Liu, K., Towards identity anonymization on graphs (2008) Conference on Management of Data; Christin, N., Yanagihara, S., Kamataki, K., Dissecting one click frauds (2010) Proceedings of ACM Conference on Computer and Communications Security; Alvari, H., Hajibagheri, A., Sukthankar, G., Lakkaraju, K., Identifying community structures in dynamic networks (2016) Social Network Analysis and Mining 6, 77 (1); Zhang, J., Sun, J., Zhang, R., Zhang, Y., Privacy-Preserving Social Media Data Outsourcing (2018) INFOCOM; Su, J., Shukla, A., Goel, S., Narayanan, A., De-anonymizing web browsing data with social networks (2017) Proceedings of WSDM","Beigi, G.; Arizona State UniversityUnited States; email: gbeigi@asu.edu",,,"The BRIMS Society","2018 International Conference on Social Computing, Behavioral-Cultural Modeling, and Prediction and Behavior Representation in Modeling and Simulation, BRiMS 2018","10 July 2018 through 13 July 2018",,154221,,,,,"English","Int. Conf. Soc. Comput., Behav.-Cult. Model., Predict. Behav. Represent. Model. Simul., BRiMS",Conference Paper,"Final","",Scopus,2-s2.0-85084097093
"Sinha A., Namkoong H., Duchi J.","57216469719;57194213292;26221757400;","Certifying some distributional robustness with principled adversarial training",2018,"6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings",,,,"","",,141,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083954224&partnerID=40&md5=336a910995bc73c4b899fa2ce42f5729","Department of Electrical Engineering, Stanford University, Stanford, CA  94305, United States; Department of Management Science and Engineering, Stanford University, Stanford, CA  94305, United States; Department of Statistics, Stanford University, Stanford, CA  94305, United States","Sinha, A., Department of Electrical Engineering, Stanford University, Stanford, CA  94305, United States; Namkoong, H., Department of Management Science and Engineering, Stanford University, Stanford, CA  94305, United States; Duchi, J., Department of Electrical Engineering, Stanford University, Stanford, CA  94305, United States, Department of Statistics, Stanford University, Stanford, CA  94305, United States","Neural networks are vulnerable to adversarial examples and researchers have proposed many heuristic attack and defense mechanisms. We address this problem through the principled lens of distributionally robust optimization, which guarantees performance under adversarial input perturbations. By considering a Lagrangian penalty formulation of perturbing the underlying data distribution in a Wasserstein ball, we provide a training procedure that augments model parameter updates with worst-case perturbations of training data. For smooth losses, our procedure provably achieves moderate levels of robustness with little computational or statistical cost relative to empirical risk minimization. Furthermore, our statistical guarantees allow us to efficiently certify robustness for the population loss. For imperceptible perturbations, our method matches or outperforms heuristic approaches. © Learning Representations, ICLR 2018 - Conference Track Proceedings.All right reserved.",,"Optimization; Population statistics; Distributional robustness; Empirical risk minimization; Heuristic approach; Input perturbation; Penalty formulation; Robust optimization; Statistical guarantee; Training procedures; Heuristic methods",,,,,"Bartlett, P.L., Mendelson, S., Rademacher and Gaussian complexities: Risk bounds and structural results (2002) Journal of Machine Learning Research, 3, pp. 463-482; Bartlett, P.L., Foster, D.J., Telgarsky, M.J., Spectrally-normalized margin bounds for neural networks (2017) Advances in Neural Information Processing Systems, pp. 6241-6250; Ben-David, S., Blitzer, J., Crammer, K., Kulesza, A., Pereira, F., Vaughan, J., A theory of learning from different domains (2010) Machine Learning, 79, pp. 151-175; Ben-Tal, A., Ghaoui, L.E., Nemirovski, A., (2009) Robust Optimization, , Princeton University Press; Ben-Tal, A., Den Hertog, D., Waegenaere, A.D., Melenberg, B., Rennen, G., Robust solutions of optimization problems affected by uncertain probabilities (2013) Management Science, 59 (2), pp. 341-357; Bertsimas, D., Gupta, V., Kallus, N., (2013) Data-Driven Robust Optimization, , http://arxiv.org/abs/1401.0212, math.OC; Billingsley, P., (1999) Convergence of Probability Measures, , Wiley, Second edition; Blanchet, J., Murthy, K., (2016) Quantifying Distributional Model Risk Via Optimal Transport, , math.PR; Blanchet, J., Kang, Y., Murthy, K., (2016) Robust Wasserstein Profile Inference and Applications to Machine Learning, , math.ST; Bonnans, J.F., Shapiro, A., (2013) Perturbation Analysis of Optimization Problems, , Springer Science & Business Media; Boucheron, S., Bousquet, O., Lugosi, G., Theory of classification: A survey of some recent advances (2005) ESAIM: Probability and Statistics, 9, pp. 323-375; Boucheron, S., Lugosi, G., Massart, P., (2013) Concentration Inequalities: A Nonasymptotic Theory of Independence, , Oxford University Press; Brown, T., Mane, D., Roy, A., Abadi, M., Gilmer, J., Adversarial patch (2017) Machine Learning and Computer Security Workshop, Neural Information Processing Systems; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium on, pp. 39-57. , IEEE; Chen, X., Sim, M., Sun, P., A robust optimization perspective on stochastic programming (2007) Operations Research, 55 (6), pp. 1058-1071; Chen, Y., Lan, G., Ouyang, Y., (2014) Accelerated Schemes for A Class of Variational Inequalities, , math.OC; Clevert, D.-A., Unterthiner, T., Hochreiter, S., (2015) Fast and Accurate Deep Network Learning by Exponential Linear Units (Elus), , arXiv preprint; Delage, E., Ye, Y., Distributionally robust optimization under moment uncertainty with application to data-driven problems (2010) Operations Research, 58 (3), pp. 595-612; Duchi, J.C., Glynn, P.W., Namkoong, H., (2016) Statistics of Robust Optimization: A Generalized Empirical Likelihood Approach, , https://arxiv.org/abs/1610.03425, stat.ML; Dziugaite, G.K., Roy, D.M., (2017) Computing Nonvacuous Generalization Bounds for Deep (Stochastic) Neural Networks with Many More Parameters Than Training Data, , cs.LG; Esfahani, P.M., Kuhn, D., (2015) Data-Driven Distributionally Robust Optimization Using the Wasserstein Metric: Performance Guarantees and Tractable Reformulations, , math.OC; Ghadimi, S., Lan, G., Stochastic first- And zeroth-order methods for nonconvex stochastic programming (2013) SIAM Journal on Optimization, 23 (4), pp. 2341-2368; Goh, J., Sim, M., Distributionally robust optimization and its tractable approximations (2010) Operations Research, 58 (4), pp. 902-917; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations; He, W., Wei, J., Chen, X., Carlini, N., Song, D., (2017) Adversarial Example Defenses: Ensembles of Weak Defenses Are Not Strong, , cs.LG; Huang, X., Kwiatkowska, M., Wang, S., Wu, M., Safety verification of deep neural networks (2017) International Conference on Computer Aided Verification, pp. 3-29. , Springer; Juditsky, A., Nemirovski, A., Tauvel, C., Solving variational inequalities with the stochastic mirror-prox algorithm (2011) Stochastic Systems, 1 (1), pp. 17-58; Katz, G., Barrett, C., Dill, D., Julian, K., Kochenderfer, M., (2017) Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks, , cs.AI; Katz, G., Barrett, C., Dill, D.L., Julian, K., Kochenderfer, M.J., (2017) Towards Proving the Adversarial Robustness of Deep Neural Networks, , cs.LG; Kolter, J.Z., Wong, E., (2017) Provable Defenses against Adversarial Examples Via the Convex Outer Adversarial Polytope, , https://arxiv.org/abs/1711.00851, cs.LG; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Machine Learning at Scale, , cs.CV; Lam, H., Zhou, E., Quantifying input uncertainty in stochastic optimization (2015) Proceedings of the 2015 Winter Simulation Conference, , IEEE; Lee, J., Raginsky, M., (2017) Minimax Statistical Learning and Domain Adaptation with Wasserstein Distances, , cs.LG; Luenberger, D., (1969) Optimization by Vector Space Methods, , Wiley; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , stat.ML; Miyato, T., Maeda, S., Koyama, M., Nakae, K., Ishii, S., (2015) Distributional Smoothing with Virtual Adversarial Training, , stat.ML; Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.A., Veness, J., Bellemare, M.G., Graves, A., Ostrovski, G., Human-level control through deep reinforcement learning (2015) Nature, 518 (7540), pp. 529-533; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Namkoong, H., Duchi, J.C., Stochastic gradient methods for distributionally robust optimization with f-divergences (2016) Advances in Neural Information Processing Systems, 29; Namkoong, H., Duchi, J.C., Variance regularization with convex objectives (2017) Advances in Neural Information Processing Systems, 30; Neyshabur, B., Bhojanapalli, S., McAllester, D., Srebro, N., Exploring generalization in deep learning (2017) Advances in Neural Information Processing Systems, pp. 5949-5958; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 427-436; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., (2016) Practical Black-Box Attacks against Deep Learning Systems Using Adversarial Examples, , cs.CR; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387. , IEEE; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Security and Privacy (SP), 2016 IEEE Symposium on, pp. 582-597. , IEEE; Parikh, N., Boyd, S., Proximal algorithms (2013) Foundations and Trends in Optimization, 1 (3), pp. 123-231; Raghunathan, A., Steinhardt, J., Liang, P., (2018) Certified Defenses against Adversarial Examples, , https://arxiv.org/abs/1801.09344, cs.LG; Ratliff, N., Bagnell, J.A., Zinkevich, M., Maximum margin planning (2006) Proceedings of the 23rd International Conference on Machine Learning; Rockafellar, R.T., Wets, R.J.B., (1998) Variational Analysis, , Springer, New York; Rozsa, A., Gunther, M., Boult, T.E., (2016) Towards Robust Deep Neural Networks with Bang, , cs.CV; Shafieezadeh-Abadeh, S., Esfahani, P.M., Kuhn, D., Distributionally robust logistic regression (2015) Advances in Neural Information Processing Systems, pp. 1576-1584; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , cs.CV; Szepesvári, C., Littman, M.L., A unified analysis of value-function-based reinforcement-learning algorithms (1999) Neural Computation, 11 (8), pp. 2017-2060; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses, , stat.ML; Van der Vaart, A.W., Wellner, J.A., (1996) Weak Convergence and Empirical Processes: With Applications to Statistics, , Springer, New York; Villani, C., (2009) Optimal Transport: Old and New, , Springer; Xu, H., Caramanis, C., Mannor, S., Robustness and regularization of support vector machines (2009) The Journal of Machine Learning Research, 10, pp. 1485-1510; Xu, H., Caramanis, C., Mannor, S., A distributional interpretation of robust optimization (2012) Mathematics of Operations Research, 37 (1), pp. 95-110",,,,"International Conference on Learning Representations, ICLR","6th International Conference on Learning Representations, ICLR 2018","30 April 2018 through 3 May 2018",,149806,,,,,"English","Int. Conf. Learn. Represent., ICLR - Conf. Track Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85083954224
"Madry A., Makelov A., Schmidt L., Tsipras D., Vladu A.","24171757000;57210646305;56198602500;57190878878;36919560800;","Towards deep learning models resistant to adversarial attacks",2018,"6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings",,,,"","",,1014,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083954061&partnerID=40&md5=84bf66031966d7b8f24a2260e59ff64c","Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, Cambridge, MA  02139, United States","Madry, A., Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, Cambridge, MA  02139, United States; Makelov, A., Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, Cambridge, MA  02139, United States; Schmidt, L., Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, Cambridge, MA  02139, United States; Tsipras, D., Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, Cambridge, MA  02139, United States; Vladu, A., Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, Cambridge, MA  02139, United States","Recent work has demonstrated that neural networks are vulnerable to adversarial examples, i.e., inputs that are almost indistinguishable from natural data and yet classified incorrectly by the network. To address this problem, we study the adversarial robustness of neural networks through the lens of robust optimization. This approach provides us with a broad and unifying view on much prior work on this topic. Its principled nature also enables us to identify methods for both training and attacking neural networks that are reliable and, in a certain sense, universal. In particular, they specify a concrete security guarantee that would protect against a well-defined class of adversaries. These methods let us train networks with significantly improved resistance to a wide range of adversarial attacks. They also suggest robustness against a first-order adversary as a natural security guarantee. We believe that robustness against such well-defined classes of adversaries is an important stepping stone towards fully resistant deep learning models. © Learning Representations, ICLR 2018 - Conference Track Proceedings.All right reserved.",,"Optimization; Concrete securities; First order; Learning models; Robust optimization; Stepping stone; Through the lens; Deep learning",,,,,"(2017) Tensor Flow Models Repository, , https://github.com/tensorflow/models/tree/master/resnet; Ben-Tal, A., Ghaoui, L.E., Nemirovski, A., (2009) Robust Optimization, , Princeton University Press; Carlini, N., Wagner, D., (2016) Defensive Distillation Is Not Robust to Adversarial Examples, , arXiv preprint; Carlini, N., Wagner, D., (2016) Towards Evaluating the Robustness of Neural Networks, , arXiv preprint; Carlini, N., Wagner, D., (2017) Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods, , arXiv preprint; Carlini, N., Katz, G., Barrett, C., Dill, D.L., (2017) Ground-Truth Adversarial Examples, , arXiv preprint; Dalvi, N., Domingos, P., Mausam, Sanghai, S., Verma, D., Adversarial classification (2004) International Conference on Knowledge Discovery and Data Mining (KDD); Fawzi, A., Fawzi, O., Frossard, P., (2015) Analysis of Classifiers’ Robustness to Adversarial Perturbations, , arXiv preprint; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint; Gu, S., Rigazio, L., (2014) Towards Deep Neural Network Architectures Robust to Adversarial Examples, , arXiv preprint; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; He, W., Wei, J., Chen, X., Carlini, N., Song, D., (2017) Adversarial Example Defenses: Ensembles of Weak Defenses Are Not Strong, , arXiv preprint; Huang, R., Xu, B., Schuurmans, D., Szepesvári, C., (2015) Learning with A Strong Adversary, , arXiv preprint; Kurakin, A., Goodfellow, I.J., Bengio, S., (2016) Adversarial Machine Learning at Scale, , arXiv preprint; Lyu, C., Huang, K., Liang, H.-N., A unified gradient regularization family for adversarial examples (2015) Data Mining (ICDM), 2015 IEEE International Conference on, pp. 301-309; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) 2016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2016, pp. 2574-2582. , Las Vegas, NV, USA, June 27-30, 2016; Nguyen, A.M., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2015, pp. 427-436. , Boston, MA, USA, June 7-12, 2015; Papernot, N., McDaniel, P.D., (2016) On the Effectiveness of Defensive Distillation, , arXiv preprint; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Security and Privacy (SP), 2016 IEEE Symposium on, pp. 582-597; Papernot, N., McDaniel, P.D., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2016) IEEE European Symposium on Security and Privacy, EuroS&P 2016, pp. 372-387. , Saarbrücken, Germany, March 21-24, 2016; Rozsa, A., Günther, M., Boult, T.E., (2016) Towards Robust Deep Neural Networks with BANG, , arXiv preprint; Shaham, U., Yamada, Y., Negahban, S., (2015) Understanding Adversarial Training: Increasing Local Stability of Neural Nets through Robust Optimization, , arXiv preprint; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540. , Vienna, Austria, October 24-28, 2016; Sokolic, J., Giryes, R., Sapiro, G., Rodrigues, M.R.D., (2016) Robust Large Margin Deep Neural Networks, , arXiv preprint; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint; Torkamani, M., (2016) Robust Large Margin Approaches for Machine Learning in Adversarial Settings, , PhD thesis, University of Oregon; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P.D., (2017) Ensemble Adversarial Training: Attacks and Defenses, , arXiv preprint; Tramèr, F., Papernot, N., Goodfellow, I.J., Boneh, D., McDaniel, P.D., (2017) The Space of Transferable Adversarial Examples, , http://arxiv.org/abs/1704.03453; Wald, A., Contributions to the theory of statistical estimation and testing hypotheses (1939) The Annals of Mathematical Statistics, 10 (4), pp. 299-326; Wald, A., Statistical decision functions which minimize the maximum risk (1945) Annals of Mathematics, pp. 265-280; Wald, A., Statistical decision functions (1992) Breakthroughs in Statistics, pp. 342-357. , Springer; Xu, W., Evans, D., Qi, Y., (2017) Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks, , arXiv preprint",,,,"International Conference on Learning Representations, ICLR","6th International Conference on Learning Representations, ICLR 2018","30 April 2018 through 3 May 2018",,149806,,,,,"English","Int. Conf. Learn. Represent., ICLR - Conf. Track Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85083954061
"Brendel W., Rauber J., Bethge M.","57207550476;57208446440;57210225326;","Decision-based adversarial attacks: Reliable attacks against black-box machine learning models",2018,"6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings",,,,"","",,189,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083954048&partnerID=40&md5=d2646cdf5c872ab2eaf5119b5338131f","Werner Reichardt Centre for Integrative Neuroscience, Eberhard Karls University, Tübingen, Germany","Brendel, W., Werner Reichardt Centre for Integrative Neuroscience, Eberhard Karls University, Tübingen, Germany; Rauber, J., Werner Reichardt Centre for Integrative Neuroscience, Eberhard Karls University, Tübingen, Germany; Bethge, M., Werner Reichardt Centre for Integrative Neuroscience, Eberhard Karls University, Tübingen, Germany","Many machine learning algorithms are vulnerable to almost imperceptible perturbations of their inputs. So far it was unclear how much risk adversarial perturbations carry for the safety of real-world machine learning applications because most methods used to generate such perturbations rely either on detailed model information (gradient-based attacks) or on confidence scores such as class probabilities (score-based attacks), neither of which are available in most real-world scenarios. In many such cases one currently needs to retreat to transfer-based attacks which rely on cumbersome substitute models, need access to the training data and can be defended against. Here we emphasise the importance of attacks which solely rely on the final model decision. Such decision-based attacks are (1) applicable to real-world black-box models such as autonomous cars, (2) need less knowledge and are easier to apply than transfer-based attacks and (3) are more robust to simple defences than gradient- or score-based attacks. Previous attacks in this category were limited to simple models or simple datasets. Here we introduce the Boundary Attack, a decision-based attack that starts from a large adversarial perturbation and then seeks to reduce the perturbation while staying adversarial. The attack is conceptually simple, requires close to no hyperparameter tuning, does not rely on substitute models and is competitive with the best gradient-based attacks in standard computer vision tasks like ImageNet. We apply the attack on two black-box algorithms from Clarifai.com. The Boundary Attack in particular and the class of decision-based attacks in general open new avenues to study the robustness of machine learning models and raise new questions regarding the safety of deployed machine learning systems. An implementation of the attack is available as part of Foolbox (https://github.com/bethgelab/foolbox). © Learning Representations, ICLR 2018 - Conference Track Proceedings.All right reserved.",,"Learning algorithms; Risk perception; Safety engineering; Black box algorithms; Class probabilities; Confidence score; Detailed modeling; Machine learning applications; Machine learning models; Modeling decisions; Real-world scenario; Machine learning",,,,,"Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndić, N., Laskov, P., Giacinto, G.-G., Roli, F., Evasion attacks against machine learning at test time (2013) Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 387-402. , Springer; Brendel, W., Bethge, M., Comment on “biologically inspired protection of deep networks from adversarial attacks” (2017) CoRR, , http://arxiv.org/abs/1704.01547, abs/1704.01547; Carlini, N., Wagner, D.A., Towards evaluating the robustness of neural networks (2016) CoRR, , http://arxiv.org/abs/1608.04644, abs/1608.04644; Carlini, N., Wagner, D.A., Defensive distillation is not robust to adversarial examples (2016) CoRR, , http://arxiv.org/abs/1607.04311, abs/1607.04311; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) CoRR, , http://arxiv.org/abs/1708.03999, abs/1708.03999; Cisse, M., Adi, Y., Neverova, N., Keshet, J., Houdini: Fooling deep structured prediction models (2017) CoRR, , http://arxiv.org/abs/1707.05373, abs/1707.05373; Dalvi, N., Domingos, P., Mausam, Sanghai, S., Verma, D., Adversarial classification (2004) Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD’04, pp. 99-108. , http://doi.acm.org/10.1145/1014052.1014066, New York, NY, USA, ACM; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., ImageNet: A large-scale hierarchical image database (2009) Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pp. 248-255. , IEEE; Hayes, J., Danezis, G., Machine learning as an adversarial service: Learning black-box adversarial examples (2017) CoRR, , http://arxiv.org/abs/1708.05207, abs/1708.05207; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2015) CoRR, , http://arxiv.org/abs/1512.03385, abs/1512.03385; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images, , Technical report, University of Toronto; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial examples in the physical world (2016) CoRR, , http://arxiv.org/abs/1607.02533, abs/1607.02533; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proceedings of the IEEE, 86 (11), pp. 2278-2324; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2016) CoRR, , http://arxiv.org/abs/1611.02770, abs/1611.02770; Lowd, D., Meek, C., Adversarial learning (2005) Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining, KDD’05, pp. 641-647. , http://doi.acm.org/10.1145/1081870.1081950, New York, NY, USA, ACM; Lu, J., Issaranon, T., Forsyth, D.A., SafeTyNet: Detecting and rejecting adversarial examples robustly (2017) CoRR, , http://arxiv.org/abs/1704.00103, abs/1704.00103; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2015) CoRR, , http://arxiv.org/abs/1511.04599, abs/1511.04599; Narodytska, N., Kasiviswanathan, S.P., Simple black-box adversarial perturbations for deep networks (2016) CoRR, , http://arxiv.org/abs/1612.06299, abs/1612.06299; Nayebi, A., Ganguli, S., Biologically inspired protection of deep networks from adversarial attacks (2017) CoRR, , http://arxiv.org/abs/1703.09202, abs/1703.09202; Nelson, B., Rubinstein, B.I.P., Huang, L., Joseph, A.D., Lee, S.J., Rao, S., Tygar, J.D., Query strategies for evading convex-inducing classifiers (2012) J. Mach. Learn. Res., 13, pp. 1293-1332. , http://dl.acm.org/citation.cfm?id=2188385.2343688, May; Papernot, N., McDaniel, P.D., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2015) CoRR, , http://arxiv.org/abs/1511.07528, abs/1511.07528; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Security and Privacy (SP), 2016 IEEE Symposium on, pp. 582-597. , IEEE; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519. , ACM; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, Asia CCS’17, pp. 506-519. , http://doi.acm.org/10.1145/3052973.3053009, New York, NY, USA, ACM; Rauber, J., Brendel, W., Bethge, M., Foolbox v0.8.0: A python toolbox to benchmark the robustness of machine learning models (2017) CoRR, , http://arxiv.org/abs/1707.04131, abs/1707.04131; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2014) CoRR, , http://arxiv.org/abs/1409.1556, abs/1409.1556; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R., Intriguing properties of neural networks (2013) CoRR, , http://arxiv.org/abs/1312.6199, abs/1312.6199; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2015) CoRR, , http://arxiv.org/abs/1512.00567, abs/1512.00567; Tramer, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2017) CoRR, , http://arxiv.org/abs/1705.07204, abs/1705.07204, May",,,,"International Conference on Learning Representations, ICLR","6th International Conference on Learning Representations, ICLR 2018","30 April 2018 through 3 May 2018",,149806,,,,,"English","Int. Conf. Learn. Represent., ICLR - Conf. Track Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85083954048
"Weng T.-W., Zhang H., Chen P.-Y., Yi J., Su D., Gao Y., Hsieh C.-J., Daniel L.","56448283400;57192486575;36930105800;36095116600;35727155500;57204286267;24502954900;7102917670;","Evaluating the robustness of neural networks: An extreme value theory approach",2018,"6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings",,,,"","",,56,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083954035&partnerID=40&md5=ddef678f16a13ebebb9fd408b089c574","Massachusetts Institute of Technology, Cambridge, MA  02139, United States; University of California, Davis, CA  95616, United States; IBM Research AI, Yorktown Heights, NY  10598, United States; Tencent AI Lab, Bellevue, WA  98004, United States","Weng, T.-W., Massachusetts Institute of Technology, Cambridge, MA  02139, United States; Zhang, H., University of California, Davis, CA  95616, United States; Chen, P.-Y., IBM Research AI, Yorktown Heights, NY  10598, United States; Yi, J., Tencent AI Lab, Bellevue, WA  98004, United States; Su, D., IBM Research AI, Yorktown Heights, NY  10598, United States; Gao, Y., IBM Research AI, Yorktown Heights, NY  10598, United States; Hsieh, C.-J., University of California, Davis, CA  95616, United States; Daniel, L., Massachusetts Institute of Technology, Cambridge, MA  02139, United States","The robustness of neural networks to adversarial examples has received great attention due to security implications. Despite various attack approaches to crafting visually imperceptible adversarial examples, little has been developed towards a comprehensive measure of robustness. In this paper, we provide a theoretical justification for converting robustness analysis into a local Lipschitz constant estimation problem, and propose to use the Extreme Value Theory for efficient evaluation. Our analysis yields a novel robustness metric called CLEVER, which is short for Cross Lipschitz Extreme Value for nEtwork Robustness. The proposed CLEVER score is attack-agnostic and computationally feasible for large neural networks. Experimental results on various networks, including ResNet, Inception-v3 and MobileNet, show that (i) CLEVER is aligned with the robustness indication measured by the 2 and ∞ norms of adversarial examples from powerful attacks, and (ii) defended networks using defensive distillation or bounded ReLU indeed achieve better CLEVER scores. To the best of our knowledge, CLEVER is the first attack-independent robustness metric that can be applied to any neural network classifier. © Learning Representations, ICLR 2018 - Conference Track Proceedings.All right reserved.",,"Estimation problem; Extreme value theory; Lipschitz constant; Network robustness; Neural network classifier; Robustness analysis; Security implications; Various attacks; Distillation",,,,,"Bastani, O., Ioannou, Y., Lampropoulos, L., Vytiniotis, D., Nori, A., Criminisi, A., Measuring neural net robustness with constraints (2016) Advances in Neural Information Processing Systems, pp. 2613-2621; Carlini, N., Wagner, D., (2017) Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods, , arXiv preprint; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy (SP), pp. 39-57; Chen, H., Zhang, H., Chen, P.-Y., Yi, J., Hsieh, C.-J., Show-and-fool: Crafting adversarial examples for neural image captioning (2017) CoRR, , abs/1712.02051; Chen, P.-Y., Sharma, Y., Zhang, H., Yi, J., Hsieh, C.-J., (2017) Ead: Elastic-Net Attacks to Deep Neural Networks Via Adversarial Examples, , arXiv preprint; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., (2017) Zoo: Zeroth Order Optimization Based Black-Box Attacks to Deep Neural Networks without Training Substitute Models, , arXiv preprint; De Haan, L., Ferreira, A., (2007) Extreme Value Theory: An Introduction, , Springer Science & Business Media; Ehlers, R., (2017) Formal Verification of Piece-Wise Linear Feed-Forward Neural Networks, , arXiv preprint; Evtimov, I., Eykholt, K., Fernandes, E., Kohno, T., Li, B., Prakash, A., Rahmati, A., Song, D., (2017) Robust Physical-World Attacks on Machine Learning Models, , arXiv preprint; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR’15, , arXiv preprint; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Hein, M., Andriushchenko, M., (2017) Formal Guarantees on the Robustness of A Classifier against Adversarial Manipulation, , arXiv preprint; Hinton, G., Vinyals, O., Dean, J., (2015) Distilling the Knowledge in A Neural Network, , arXiv preprint; Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H., (2017) Mobilenets: Efficient Convolutional Neural Networks for Mobile Vision Applications, , arXiv preprint; Huang, X., Kwiatkowska, M., Wang, S., Wu, M., Safety verification of deep neural networks (2017) International Conference on Computer Aided Verification, pp. 3-29. , Springer; Katz, G., Barrett, C., Dill, D., Julian, K., Kochenderfer, M., (2017) Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks, , arXiv preprint; Katz, G., Barrett, C., Dill, D.L., Julian, K., Kochenderfer, M.J., (2017) Towards Proving the Adversarial Robustness of Deep Neural Networks, , arXiv preprint; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2016) ICLR’17, , arXiv preprint; Liu, X., Cheng, M., Zhang, H., Hsieh, C.-J., (2017) Towards Robust Neural Networks Via Random Self-Ensemble, , arXiv preprint; Liu, Y., Chen, X., Liu, C., Song, D., (2016) Delving into Transferable Adversarial Examples and Black-Box Attacks, , arXiv preprint; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , arXiv preprint; Meng, D., Chen, H., (2017) Magnet: A Two-Pronged Defense against Adversarial Examples, , arXiv preprint; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) IEEE Symposium on Security and Privacy (SP), pp. 582-597; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) ACM Asia Conference on Computer and Communications Security, pp. 506-519; Papineni, K., Roukos, S., Ward, T., Zhu, W.-J., BLEU: A method for automatic evaluation of machine translation (2002) Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, pp. 311-318. , Association for Computational Linguistics; Paulavičius, R., Žilinskas, J., Analysis of different norms and corresponding lipschitz constants for global optimization (2006) Technological and Economic Development of Economy, 12 (4), pp. 301-306; Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., Chen, X., Improved techniques for training gans (2016) Advances in Neural Information Processing Systems, pp. 2234-2242; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses, , arXiv preprint; Wang, B., Gao, J., Qi, Y., (2016) A Theoretical Framework for Robustness of (Deep) Classifiers under Adversarial Noise, , arXiv preprint; Wood, G.R., Zhang, B.P., Estimation of the lipschitz constant of a function (1996) Journal of Global Optimization, 8 (1), pp. 91-103; Xu, W., Evans, D., Qi, Y., (2017) Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks, , arXiv preprint; Zantedeschi, V., Nicolae, M.-I., Rawat, A., (2017) Efficient Defenses against Adversarial Attacks, , arXiv preprint",,,,"International Conference on Learning Representations, ICLR","6th International Conference on Learning Representations, ICLR 2018","30 April 2018 through 3 May 2018",,149806,,,,,"English","Int. Conf. Learn. Represent., ICLR - Conf. Track Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85083954035
"Dhillon G.S., Azizzadenesheli K., Lipton Z.C., Bernstein J., Kossaifi J., Khanna A., Anandkumar A.","57205624334;57204800638;56358302800;57195551573;56040739900;57195940772;16068201100;","Stochastic activation pruning for robust adversarial defense",2018,"6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings",,,,"","",,127,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083953694&partnerID=40&md5=4a5023b7f24bce33b2f2c618e5d4e357","Amazon AI; UT Austin, United States; UC Irvine, United States; CMU, United States; Caltech; Imperial College London, United Kingdom","Dhillon, G.S., Amazon AI, UT Austin, United States; Azizzadenesheli, K., UC Irvine, United States; Lipton, Z.C., Amazon AI, CMU, United States; Bernstein, J., Amazon AI, Caltech; Kossaifi, J., Amazon AI, Imperial College London, United Kingdom; Khanna, A., Amazon AI; Anandkumar, A., Amazon AI, Caltech","Neural networks are known to be vulnerable to adversarial examples. Carefully chosen perturbations to real images, while imperceptible to humans, induce misclassification and threaten the reliability of deep learning systems in the wild. To guard against adversarial examples, we take inspiration from game theory and cast the problem as a minimax zero-sum game between the adversary and the model. In general, for such games, the optimal strategy for both players requires a stochastic policy, also known as a mixed strategy. In this light, we propose Stochastic Activation Pruning (SAP), a mixed strategy for adversarial defense. SAP prunes a random subset of activations (preferentially pruning those with smaller magnitude) and scales up the survivors to compensate. We can apply SAP to pretrained networks, including adversarially trained models, without fine-tuning, providing robustness against adversarial examples. Experiments demonstrate that SAP confers robustness against attacks, increasing accuracy and preserving calibration. © Learning Representations, ICLR 2018 - Conference Track Proceedings.All right reserved.",,"Chemical activation; Clustering algorithms; Deep learning; Game theory; Network security; Misclassifications; Mixed strategy; Optimal strategies; Random subsets; Real images; Stochastic policy; Without fine-tuning; Zero-sum game; Stochastic systems",,,,,"Behzadan, V., Munir, A., (2017) Vulnerability of Deep Reinforcement Learning to Policy Induction Attacks, , arXiv preprint; Bellemare, M.G., Naddaf, Y., Veness, J., Bowling, M., The arcade learning environment: An evaluation platform for general agents (2013) J. Artif. Intell. Res.(JAIR), 47, pp. 253-279; Chen, T., Li, M., Li, Y., Lin, M., Wang, N., Wang, M., Xiao, T., Zhang, Z., (2015) Mxnet: A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems, , arXiv preprint; Fawzi, A., Fawzi, O., Frossard, P., Analysis of classifiers’ robustness to adversarial perturbations (2018) Machine Learning, 107 (3), pp. 481-508; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint; Guo, C., Pleiss, G., Sun, Y., Weinberger, K.Q., (2017) On Calibration of Modern Neural Networks, , arXiv preprint; Han, S., Mao, H., Dally, W.J., (2015) Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding, , arXiv preprint; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Huang, S., Papernot, N., Goodfellow, I., Duan, Y., Abbeel, P., (2017) Adversarial Attacks on Neural Network Policies, , arXiv preprint; Kos, J., Song, D., (2017) Delving into Adversarial Attacks on Deep Policies, , arXiv preprint; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , arXiv preprint; Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.A., Veness, J., Bellemare, M.G., Graves, A., Ostrovski, G., Human-level control through deep reinforcement learning (2015) Nature, 518 (7540), pp. 529-533; Nayebi, A., Ganguli, S., (2017) Biologically Inspired Protection of Deep Networks from Adversarial Attacks, , arXiv preprint; Osborne, M.J., Rubinstein, A., (1994) A Course in Game Theory, , MIT press; Papernot, N., McDaniel, P., (2016) On the Effectiveness of Defensive Distillation, , arXiv preprint; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519; Srivastava, N., Hinton, G.E., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., Dropout: A simple way to prevent neural networks from overfitting (2014) Journal of Machine Learning Research, 15 (1), pp. 1929-1958; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses, , arXiv preprint; Tramèr, F., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2017) The Space of Transferable Adversarial Examples, , arXiv preprint",,,,"International Conference on Learning Representations, ICLR","6th International Conference on Learning Representations, ICLR 2018","30 April 2018 through 3 May 2018",,149806,,,,,"English","Int. Conf. Learn. Represent., ICLR - Conf. Track Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85083953694
"He W., Li B., Song D.","57207135651;57188689924;7402443870;","Decision boundary analysis of adversarial examples",2018,"6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings",,,,"","",,28,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083953535&partnerID=40&md5=43b2213473db88abddf58b647dc02d1a","Computer Science Division, University of California, Berkeley, United States","He, W., Computer Science Division, University of California, Berkeley, United States; Li, B., Computer Science Division, University of California, Berkeley, United States; Song, D., Computer Science Division, University of California, Berkeley, United States","Deep neural networks (DNNs) are vulnerable to adversarial examples, which are carefully crafted instances aiming to cause prediction errors for DNNs. Recent research on adversarial examples has examined local neighborhoods in the input space of DNN models. However, previous work has limited what regions to consider, focusing either on low-dimensional subspaces or small balls. In this paper, we argue that information from larger neighborhoods, such as from more directions and from greater distances, will better characterize the relationship between adversarial examples and the DNN models. First, we introduce an attack, OPTMARGIN, which generates adversarial examples robust to small perturbations. These examples successfully evade a defense that only considers a small ball around an input instance. Second, we analyze a larger neighborhood around input instances by looking at properties of surrounding decision boundaries, namely the distances to the boundaries and the adjacent classes. We find that the boundaries around these adversarial examples do not resemble the boundaries around benign examples. Finally, we show that, under scrutiny of the surrounding decision boundaries, our OPTMARGIN examples do not convincingly mimic benign examples. Although our experiments are limited to a few specific attacks, we hope these findings will motivate new, more evasive attacks and ultimately, effective defenses. © Learning Representations, ICLR 2018 - Conference Track Proceedings.All right reserved.",,"Decision boundary; Decision boundary analysis; Input space; Local neighborhoods; Low-dimensional subspace; Prediction errors; Recent researches; Small perturbations; Deep neural networks",,,,,"Cao, X., Gong, N.Z., Mitigating evasion attacks to deep neural networks via region-based classification (2017) Annual Computer Security Applications Conference (ACSAC); Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) ACM Workshop on Artificial Intelligence and Security (AISEC); Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium on, pp. 39-57. , IEEE; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts, , arXiv preprint; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) 3rd International Conference on Learning Representations (ICLR); He, W., Wei, J., Chen, X., Carlini, N., Song, D., Adversarial example defense: Ensembles of weak defenses are not strong (2017) 11th USENIX Workshop on Offensive Technologies (WOOT 17), , https://www.usenix.org/conference/woot17/workshop-program/presentation/he, Vancouver, BC, USENIX Association. URL; Hinton, G.E., Srivastava, N., Krizhevsky, A., Sutskever, I., Salakhutdi-Nov, R.R., (2012) Improving Neural Networks by Preventing Co-Adaptation of Feature Detectors, , arXiv preprint; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images; LeCun, Y., (1998) The MNIST Database of Handwritten Digits, , http://yann.lecun.com/exdb/mnist/; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) 5th International Conference on Learning Representations (ICLR); Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , arXiv preprint; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Fei-Fei, L., ImageNet large scale visual recognition challenge (2015) International Journal of Computer Vision (IJCV), 115 (3), pp. 211-252; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., Inception-v4, Inception-ResNet and the impact of residual connections on learning (2017) AAAI, pp. 4278-4284; Tabacof, P., Valle, E., Exploring the space of adversarial images (2016) Neural Networks (IJCNN), 2016 International Joint Conference on, pp. 426-433. , IEEE; Tramèr, F., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2017) The Space of Transferable Adversarial Examples, , arXiv preprint",,,,"International Conference on Learning Representations, ICLR","6th International Conference on Learning Representations, ICLR 2018","30 April 2018 through 3 May 2018",,149806,,,,,"English","Int. Conf. Learn. Represent., ICLR - Conf. Track Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85083953535
"Ma X., Li B., Wang Y., Erfani S.M., Wijewickrema S., Schoenebeck G., Song D., Houle M.E., Bailey J.","57195682647;57188689924;57188869413;54791054200;16178559900;22938696100;7402443870;7004045789;7404350735;","Characterizing adversarial subspaces using local intrinsic dimensionality",2018,"6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings",,,,"","",,162,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083953489&partnerID=40&md5=962057fd5a524f43ac895d11711d29f5","University of Melbourne, Parkville, Australia; University of California, Berkeley, United States; Tsinghua University, Beijing, China; University of Michigan, Ann Arbor, United States; National Institute of Informatics, Tokyo, Japan","Ma, X., University of Melbourne, Parkville, Australia; Li, B., University of California, Berkeley, United States; Wang, Y., Tsinghua University, Beijing, China; Erfani, S.M., University of Melbourne, Parkville, Australia; Wijewickrema, S., University of Melbourne, Parkville, Australia; Schoenebeck, G., University of Michigan, Ann Arbor, United States; Song, D., University of California, Berkeley, United States; Houle, M.E., National Institute of Informatics, Tokyo, Japan; Bailey, J., University of Melbourne, Parkville, Australia","Deep Neural Networks (DNNs) have recently been shown to be vulnerable against adversarial examples, which are carefully crafted instances that can mislead DNNs to make errors during prediction. To better understand such attacks, a characterization is needed of the properties of regions (the so-called ‘adversarial subspaces’) in which adversarial examples lie. We tackle this challenge by characterizing the dimensional properties of adversarial regions, via the use of Local Intrinsic Dimensionality (LID). LID assesses the space-filling capability of the region surrounding a reference example, based on the distance distribution of the example to its neighbors. We first provide explanations about how adversarial perturbation can affect the LID characteristic of adversarial regions, and then show empirically that LID characteristics can facilitate the distinction of adversarial examples generated using state-of-the-art attacks. As a proof-of-concept, we show that a potential application of LID is to distinguish adversarial examples, and the preliminary results show that it can outperform several state-of-the-art detection measures by large margins for five attack strategies considered in this paper across three benchmark datasets . Our analysis of the LID characteristic for adversarial regions not only motivates new directions of effective adversarial defense, but also opens up more challenges for developing new attacks to better understand the vulnerabilities of DNNs. © Learning Representations, ICLR 2018 - Conference Track Proceedings.All right reserved.",,"Benchmarking; Large dataset; Attack strategies; Benchmark datasets; Dimensional properties; Distance distributions; Intrinsic dimensionalities; Large margins; Proof of concept; State of the art; Deep neural networks",,,,,"Amsaleg, L., Chelly, O., Furon, T., Girard, S., Houle, M.E., Kawarabayashi, K.-I., Nett, M., Estimating local intrinsic dimensionality (2015) SIGKDD, pp. 29-38; Amsaleg, L., Bailey, J., Barbe, D., Erfani, S., Houle, M.E., Nguyen, V., Radovanovic, M., The vulnerability of learning to adversarial perturbation increases with intrinsic dimensionality (2017) WIFS; Carlini, N., Wagner, D., (2017) Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) S&P, pp. 39-57; Coles, S., Bawa, J., Trenner, L., Dorazio, P., (2001) An Introduction to Statistical Modeling of Extreme Values, 208. , Springer; Evtimov, I., Eykholt, K., Fernandes, E., Kohno, T., Li, B., Prakash, A., Rahmati, A., Song, D., (2017) Robust Physical-World Attacks on Machine Learning Models; Fawzi, A., Moosavi-Dezfooli, S.-M., Frossard, P., Robustness of classifiers: From adversarial to random noise (2016) NIPS, pp. 1632-1640; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., (2017) On the (Statistical) Detection of Adversarial Examples; Gu, S., Rigazio, L., (2014) Towards Deep Neural Network Architectures Robust to Adversarial Examples; He, W., Wei, J., Chen, X., Carlini, N., Song, D., (2017) Adversarial Example Defenses: Ensembles of Weak Defenses Are Not Strong; Hinton, G., Deng, L., Yu, D., Dahl, G.E., Mohamed, A.-R., Jaitly, N., Senior, A., Kingsbury, B., Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups (2012) Signal Processing Magazine, 29 (6), pp. 82-97; Houle, M.E., Local intrinsic dimensionality I: An extreme-value-theoretic foundation for similarity applications (2017) SISAP, pp. 64-79; Houle, M.E., Local intrinsic dimensionality II: Multivariate analysis and distributional support (2017) SISAP, pp. 80-95; Houle, M.E., Kashima, H., Nett, M., Generalized expansion dimension (2012) ICDMW, pp. 587-594; Karger, D.R., Ruhl, M., Finding nearest neighbors in growth-restricted metrics (2002) STOC, pp. 741-750; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) NIPS, pp. 1097-1105; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World; LeCun, Y., Boser, B.E., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W.E., Jackel, L.D., Handwritten digit recognition with a back-propagation network (1990) Advances in Neural Information Processing Systems, pp. 396-404; Li, B., Vorobeychik, Y., Feature cross-substitution in adversarial classification (2014) Advances in Neural Information Processing Systems, pp. 2087-2095; Li, B., Vorobeychik, Y., Scalable optimization of randomized operational decisions in adversarial classification settings (2015) Artificial Intelligence and Statistics, pp. 599-607; Li, X., Li, F., (2016) Adversarial Examples Detection in Deep Networks with Convolutional Filter Statistics; Liu, Y., Chen, X., Liu, C., Song, D., (2016) Delving into Transferable Adversarial Examples and Black-Box Attacks; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., (2017) On Detecting Adversarial Perturbations; Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., Ng, A.Y., Reading digits in natural images with unsupervised feature learning (2011) NIPS Workshop on Deep Learning and Unsupervised Feature Learning, 2011, p. 5; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) CVPR, pp. 427-436; Papernot, N., Goodfellow, I., Sheatsley, R., Feinman, R., McDaniel, P., (2016) Cleverhans V1. 0.0: An Adversarial Machine Learning Library; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-Box Attacks Using Adversarial Samples; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2016) EuroS&P, pp. 372-387; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) S&P, pp. 582-597; Rouhani, B.D., Samragh, M., Javidi, T., Koushanfar, F., (2017) Curtail: Characterizing and Thwarting Adversarial Deep Learning; Rouhani, B.D., Samragh, M., Javidi, T., Koushanfar, F., (2018) Towards Safe Deep Learning: Unsupervised Defense against Generic Adversarial Attacks; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks; Tanay, T., Griffin, L., (2016) A Boundary Tilting Persepective on the Phenomenon of Adversarial Examples; Tramèr, F., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2017) The Space of Transferable Adversarial Examples; Warde-Farley, D., Goodfellow, I., Hazan, T., Papandreou, G., Tarlow, D., Adversarial perturbations of deep neural networks (2016) Perturbations, Optimization, and Statistics, pp. 1-32; Xu, W., Evans, D., Qi, Y., (2017) Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks",,,,"International Conference on Learning Representations, ICLR","6th International Conference on Learning Representations, ICLR 2018","30 April 2018 through 3 May 2018",,149806,,,,,"English","Int. Conf. Learn. Represent., ICLR - Conf. Track Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85083953489
"Tramèr F., Kurakin A., Papernot N., Goodfellow I., Boneh D., McDaniel P.","56878876400;57202499592;56732917800;35956088800;7003748305;7006537016;","Ensemble adversarial training: Attacks and defenses",2018,"6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings",,,,"","",,340,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083953449&partnerID=40&md5=bf2f71b308c2b1ad53207565cf750d26","Stanford University, United States; Google Brain, United States; Pennsylvania State University, United States","Tramèr, F., Stanford University, United States; Kurakin, A., Google Brain, United States; Papernot, N., Pennsylvania State University, United States; Goodfellow, I., Google Brain, United States; Boneh, D., Stanford University, United States; McDaniel, P., Pennsylvania State University, United States","Adversarial examples are perturbed inputs designed to fool machine learning models. Adversarial training injects such examples into training data to increase robustness. To scale this technique to large datasets, perturbations are crafted using fast single-step methods that maximize a linear approximation of the model’s loss. We show that this form of adversarial training converges to a degenerate global minimum, wherein small curvature artifacts near the data points obfuscate a linear approximation of the loss. The model thus learns to generate weak perturbations, rather than defend against strong ones. As a result, we find that adversarial training remains vulnerable to black-box attacks, where we transfer perturbations computed on undefended models, as well as to a powerful novel single-step attack that escapes the non-smooth vicinity of the input data via a small random step. We further introduce Ensemble Adversarial Training, a technique that augments training data with perturbations transferred from other models. On ImageNet, Ensemble Adversarial Training yields models with strong robustness to black-box attacks. In particular, our most robust model won the first round of the NIPS 2017 competition on Defenses against Adversarial Attacks (Kurakin et al., 2017c). © Learning Representations, ICLR 2018 - Conference Track Proceedings.All right reserved.",,"Large datasets; Linear approximations; Machine learning models; Robust modeling; Single-step method; Strong robustness; Training data; Weak perturbation; Large dataset",,,,,"Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G.S., Zheng, X., (2015) TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems, , https://www.tensorflow.org/.Softwareavailablefromtensorflow.org; Amodei, D., Olah, C., Steinhardt, J., Christiano, P., Schulman, J., Mané, D., (2016) Concrete Problems in Ai Safety, , arXiv preprint; Athalye, A., Carlini, N., Wagner, D., (2018) Obfuscated Gradients Give A False Sense of Security: Circumventing Defenses to Adversarial Examples, , arXiv preprint; Baluja, S., Fischer, I., (2017) Adversarial Transformation Networks: Learning to Generate Adversarial Examples, , arXiv preprint; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndić, N., Laskov, P., Giacinto, G.-G., Roli, F., Evasion attacks against machine learning at test time (2013) ECML-KDD, pp. 387-402. , Springer; Brendel, W., Bethge, M., (2017) Comment on” Biologically Inspired Protection of Deep Networks from Adversarial Attacks, , arXiv preprint; Buckman, J., Roy, A., Raffel, C., Goodfellow, I., Thermometer encoding: One hot way to resist adversarial examples (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=S18Su-CW; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy; Carlini, N., Wagner, D., (2017) Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods, , arXiv preprint; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 15-26; Cisse, M., Piotr, B., Edouard, G., Yann, D., Nicolas, U., (2017) Parseval Networks: Improving Robustness to Adversarial Examples, , arXiv preprint; Colbourn, C.J., (2010) CRC Handbook of Combinatorial Designs, , CRC press; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., ImageNet: A large-scale hierarchical image database (2009) CVPR09; Engstrom, L., Tsipras, D., Schmidt, L., Madry, A., (2017) A Rotation and A Translation Suffice: Fooling Cnns with Simple Transformations, , arXiv preprint; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, pp. 2672-2680; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint; Gu, S., Rigazio, L., (2014) Towards Deep Neural Network Architectures Robust to Adversarial Examples, , arXiv preprint; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Zico Kolter, J., Wong, E., (2017) Provable Defenses against Adversarial Examples Via the Convex Outer Adversarial Polytope, , arXiv preprint; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2017) ICLR; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2017) ICLR; Kurakin, A., Goodfellow, I.J., Bengio, S., (2017) Nips 2017: Defense against Adversarial Attack, , https://www.kaggle.com/c/nips-2017-defense-against-adversarial-attack; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proceedings of the IEEE, 86 (11), pp. 2278-2324; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) ICLR; Luo, Y., Boix, X., Roig, G., Poggio, T., Zhao, Q., (2015) Foveation-Based Mechanisms Alleviate Adversarial Examples, , arXiv preprint; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , arXiv preprint; Mansour, Y., Mohri, M., Rostamizadeh, A., (2009) Domain Adaptation: Learning Bounds and Algorithms, , arXiv preprint; Mishkin, D., Sergievskiy, N., Matas, J., Systematic evaluation of convolution neural network advances on the imagenet (2017) Computer Vision and Image Understanding; Nayebi, A., Ganguli, S., (2017) Biologically Inspired Protection of Deep Networks from Adversarial Attacks, , arXiv preprint; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387; Papernot, N., McDaniel, P., Sinha, A., Wellman, M., (2016) Towards the Science of Security and Privacy in Machine Learning, , arXiv preprint; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Security and Privacy (SP), 2016 IEEE Symposium on, pp. 582-597; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) Asia Conference on Computer and Communications Security (ASIACCS), pp. 506-519; Raghunathan, A., Steinhardt, J., Liang, P., Certified defenses against adversarial examples (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=Bys4ob-Rb; Sinha, A., Namkoong, H., Duchi, J., Certifiable distributional robustness with principled adversarial training (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=Hk6kPgZA; Srivastava, N., Hinton, G.E., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., Dropout: A simple way to prevent neural networks from overfitting (2014) Journal of Machine Learning Research, 15 (1), pp. 1929-1958; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A., (2016) Inception-V4, Inception-Resnet and the Impact of Residual Connections on Learning, , arXiv preprint; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) CVPR, pp. 2818-2826; Tramèr, F., Zhang, F., Juels, A., Reiter, M.K., Ristenpart, T., Stealing machine learning models via prediction apis (2016) Usenix Security; Tramèr, F., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2017) The Space of Transferable Adversarial Examples, , arXiv preprint; Xiao, C., Li, B., Zhu, J.-Y., He, W., Liu, M., Song, D., (2018) Generating Adversarial Examples with Adversarial Networks, , https://openreview.net/forum?id=HknbyQbC; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., Mitigating adversarial effects through randomization (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=Sk9yuql0Z; Zhang, C., Zhang, L., Ye, J., Generalization bounds for domain adaptation (2012) Advances in Neural Information Processing Systems, pp. 3320-3328",,,,"International Conference on Learning Representations, ICLR","6th International Conference on Learning Representations, ICLR 2018","30 April 2018 through 3 May 2018",,149806,,,,,"English","Int. Conf. Learn. Represent., ICLR - Conf. Track Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85083953449
"Ritter H., Botev A., Barber D.","57202449998;57196024416;24921457500;","A scalable laplace approximation for neural networks",2018,"6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings",,,,"","",,47,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083953439&partnerID=40&md5=a837705277e26e2aaebb6b072feb07c5","University College London, United Kingdom; Alan Turing Institute, India","Ritter, H., University College London, United Kingdom; Botev, A., University College London, United Kingdom; Barber, D., University College London, United Kingdom, Alan Turing Institute, India","We leverage recent insights from second-order optimisation for neural networks to construct a Kronecker factored Laplace approximation to the posterior over the weights of a trained network. Our approximation requires no modification of the training procedure, enabling practitioners to estimate the uncertainty of their models currently used in production without having to retrain them. We extensively compare our method to using Dropout and a diagonal Laplace approximation for estimating the uncertainty of a network. We demonstrate that our Kronecker factored method leads to better uncertainty estimates on out-of-distribution data and is more robust to simple adversarial attacks. Our approach only requires calculating two square curvature factor matrices for each layer. Their size is equal to the respective square of the input and output size of the layer, making the method efficient both computationally and in terms of memory usage. We illustrate its scalability by applying it to a state-of-the-art convolutional network architecture. © Learning Representations, ICLR 2018 - Conference Track Proceedings.All right reserved.",,"Laplace transforms; Network architecture; Convolutional networks; Input and outputs; Laplace approximation; Optimisations; Second orders; State of the art; Training procedures; Uncertainty estimates; Uncertainty analysis",,,,,"Balan, A.K., Rathod, V., Murphy, K.P., Welling, M., Bayesian dark knowledge (2015) Advances in Neural Information Processing Systems, pp. 3438-3446; Barber, D., Bishop, C.M., Ensemble Learning for Multi-layer Networks (1998) Advances in Neural Information Processing Systems, pp. 395-401; Blundell, C., Cornebise, J., Kavukcuoglu, K., Wierstra, D., Weight uncertainty in neural networks (2015) ICML, pp. 1613-1622; Botev, A., Ritter, H., Barber, D., Practical Gauss-Newton optimisation for deep learning (2017) ICML, pp. 557-565; Dieleman, S., Schlüter, J., Raffel, C., Olson, E., Sønderby, S.K., Nouri, D., (2015) Lasagne: First Release, , August; Gal, Y., Ghahramani, Z., (2015) Bayesian Convolutional Neural Networks with BernoulliAap-Proximate Variational Inference, , arXiv preprint; Gal, Y., Ghahramani, Z., Dropout as a Bayesian approximation: Representing model uncertainty in deep learning (2016) ICML, pp. 1050-1059; Ghosh, S., Delle Fave, F.M., Yedidia, J.S., Assumed density filtering methods for learning Bayesian neural networks (2016) AAAI, pp. 1589-1595; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint; Graves, A., Practical variational inference for neural networks (2011) Advances in Neural Information Processing Systems, pp. 2348-2356; Grosse, R., Martens, J., A Kronecker-factored Approximate Fisher Matrix for Convolution Layers (2016) ICML, pp. 573-582; Gupta, A.K., Nagar, D.K., (1999) Matrix Variate Distributions, 104. , CRC Press; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; He, K., Zhang, X., Ren, S., Sun, J., Identity mappings in deep residual networks (2016) European Conference on Computer Vision, pp. 630-645. , Springer; Hernández-Lobato, J.M., Adams, R., Probabilistic backpropagation for scalable learning of Bayesian neural networks (2015) ICML, pp. 1861-1869; Hinton, G.E., Van Camp, D., Keeping the neural networks simple by minimizing the description length of the weights (1993) COLT, pp. 5-13; Ioffe, S., Szegedy, C., Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015) ICML, pp. 448-456; Kingma, D.P., Welling, M., (2013) Auto-Encoding Variational Bayes, , arXiv preprint; Kingma, D.P., Salimans, T., Welling, M., Variational Dropout and the Local Repa-rameterization Trick (2015) Advances in Neural Information Processing Systems, pp. 2575-2583; Kirkpatrick, J., Pascanu, R., Rabinowitz, N., Veness, J., Desjardins, G., Rusu, A.A., Milan, K., Grabska-Barwinska, A., Overcoming catastrophic forgetting in neural networks (2017) Proceedings of the National Academy of Sciences, p. 201611835; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images; Lakshminarayanan, B., Pritzel, A., Blundell, C., (2016) Simple and Scalable Predictive Uncertainty Estimation Using Deep Ensembles, , arXiv preprint; LeCun, Y., Denker, J.S., Solla, S.A., Optimal brain damage (1990) Advances in Neural Information Processing Systems, pp. 598-605; Li, Y., Gal, Y., (2017) Dropout Inference in Bayesian Neural Networks with Alpha-Divergences, , arXiv preprint; Louizos, C., Welling, M., Structured and efficient variational deep learning with matrix Gaussian posteriors (2016) ICML, pp. 1708-1716; Louizos, C., Welling, M., Multiplicative normalizing flows for variational Bayesian neural networks (2017) ICML, pp. 2218-2227; MacKay, D.J.C., A practical Bayesian framework for backpropagation networks (1992) Neural Computation, 4 (3), pp. 448-472; Martens, J., Grosse, R., Optimizing Neural Networks with Kronecker-factored Approximate Curvature (2015) ICML, pp. 2408-2417; Neal, R.M., Bayesian learning via stochastic dynamics (1993) Advances in Neural Information Processing Systems, pp. 475-482; Srivastava, N., Hinton, G.E., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., Dropout: A simple way to prevent neural networks from overfitting (2014) Journal of Machine Learning Research, 15 (1), pp. 1929-1958; Sun, S., Chen, C., Carin, L., Learning structured weight uncertainty in Bayesian neural networks (2017) Artificial Intelligence and Statistics, pp. 1283-1292; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint; (2016) Theano: A Python Framework for Fast Computation of Mathematical Expressions, , arXiv e-prints, abs/1605.02688, May; Zagoruyko, S., Komodakis, N., (2016) Wide Residual Networks, , arXiv preprint","Ritter, H.; University College LondonUnited Kingdom; email: j.ritter@cs.ucl.ac.uk",,,"International Conference on Learning Representations, ICLR","6th International Conference on Learning Representations, ICLR 2018","30 April 2018 through 3 May 2018",,149806,,,,,"English","Int. Conf. Learn. Represent., ICLR - Conf. Track Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85083953439
"Raghunathan A., Steinhardt J., Liang P.","57213439635;56461039200;56646712700;","Certified defenses against adversarial examples",2018,"6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings",,,,"","",,165,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083952881&partnerID=40&md5=d672de5339238f376a22ef71e0256da4","Department of Computer Science, Stanford University, United States","Raghunathan, A., Department of Computer Science, Stanford University, United States; Steinhardt, J., Department of Computer Science, Stanford University, United States; Liang, P., Department of Computer Science, Stanford University, United States","While neural networks have achieved high accuracy on standard image classification benchmarks, their accuracy drops to nearly zero in the presence of small adversarial perturbations to test inputs. Defenses based on regularization and adversarial training have been proposed, but often followed by new, stronger attacks that defeat these defenses. Can we somehow end this arms race? In this work, we study this problem for neural networks with one hidden layer. We first propose a method based on a semidefinite relaxation that outputs a certificate that for a given network and test input, no attack can force the error to exceed a certain value. Second, as this certificate is differentiable, we jointly optimize it with the network parameters, providing an adaptive regularizer that encourages robustness against all attacks. On MNIST, our approach produces a network and a certificate that no attack that perturbs each pixel by at most = 0.1 can cause more than 35% test error. © Learning Representations, ICLR 2018 - Conference Track Proceedings.All right reserved.",,"High-accuracy; Network parameters; Neural networks with one hidden layer; Regularizer; Semidefinite relaxation; Standard images; Test errors; Test inputs; Multilayer neural networks",,,,,"Barreno, M., Nelson, B., Joseph, A.D., Tygar, J.D., The security of machine learning (2010) Machine Learning, 81 (2), pp. 121-148; Başar, T., Bernhard, P., (2008) H-Infinity Optimal Control and Related Minimax Design Problems: A Dynamic Game Approach, , Springer Science & Business Media; Bastani, O., Ioannou, Y., Lampropoulos, L., Vytiniotis, D., Nori, A., Criminisi, A., Measuring neural net robustness with constraints (2016) Advances in Neural Information Processing Systems (NIPS), pp. 2613-2621; Bertsimas, D., Brown, D.B., Caramanis, C., Theory and applications of robust optimization (2011) SIAM Review, 53 (3), pp. 464-501; Biggio, B., Fumera, G., Roli, F., Security evaluation of pattern classifiers under attack (2014) IEEE Transactions on Knowledge and Data Engineering, 26 (4), pp. 984-996; Biggio, B., Rieck, K., Ariu, D., Wressnegger, C., Corona, I., Giacinto, G., Roli, F., Poisoning behavioral malware clustering (2014) Workshop on Artificial Intelligence and Security (AISec); Carlini, N., Wagner, D., (2016) Defensive Distillation Is Not Robust to Adversarial Examples; Carlini, N., Wagner, D., (2017) Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy, pp. 39-57; Carlini, N., Mishra, P., Vaidya, T., Zhang, Y., Sherr, M., Shields, C., Wagner, D., Zhou, W., Hidden voice commands (2016) USENIX Security; Carlini, N., Katz, G., Barrett, C., Dill, D.L., (2017) Ground-Truth Adversarial Examples; Chen, P., Sharma, Y., Zhang, H., Yi, J., Hsieh, C., (2017) EAD: Elastic-Net Attacks to Deep Neural Networks Via Adversarial Examples; Cisse, M., Bojanowski, P., Grave, E., Dauphin, Y., Usunier, N., Parseval networks: Improving robustness to adversarial examples (2017) International Conference on Machine Learning (ICML), pp. 854-863; Evtimov, I., Eykholt, K., Fernandes, E., Kohno, T., Li, B., Prakash, A., Rahmati, A., Song, D., (2017) Robust Physical-World Attacks on Machine Learning Models; Gardiner, J., Nagaraja, S., On the security of machine learning in malware c&c detection: A survey (2016) ACM Computing Surveys (CSUR), 49 (3); Goemans, M., Williamson, D., Improved approximation algorithms for maximum cut and satisfia-bility problems using semidefinite programming (1995) Journal of the ACM (JACM), 42 (6), pp. 1115-1145; Goodfellow, I., Papernot, N., McDaniel, P., (2016) Cleverhans V2.0.0: An Adversarial Machine Learning Library; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations (ICLR); He, K., Zhang, X., Ren, S., Sun, J., (2015) Delving Deep into Rectifiers: Surpassing Human-Level Performance on Imagenet Classification, , arXiv preprint; Hein, M., Andriushchenko, M., Formal guarantees on the robustness of a classifier against adversarial manipulation (2017) Advances in Neural Information Processing Systems (NIPS), pp. 2263-2273; Huang, X., Kwiatkowska, M., Wang, S., Wu, M., Safety verification of deep neural networks (2017) Computer Aided Verification (CAV), pp. 3-29; Katz, G., Barrett, C., Dill, D., Julian, K., Kochenderfer, M., (2017) Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks, , arXiv preprint; Katz, G., Barrett, C., Dill, D.L., Julian, K., Kochenderfer, M.J., (2017) Towards Proving the Adversarial Robustness of Deep Neural Networks; Kingma, D., Ba, J., (2014) Adam: A Method for Stochastic Optimization, , arXiv preprint; Kolter, J.Z., Wong, E., (2017) Provable Defenses against Adversarial Examples Via the Convex Outer Adversarial Polytope, , arXiv preprint; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World; Laskov, P., Šrndic, N., Practical evasion of a learning-based classifier: A case study (2014) Symposium on Security and Privacy; Löfberg, J., YALMiP: A toolbox for modeling and optimization in MATLAB (2004) CACSD; Lyapunov, A.M., (1892) The General Problem of the Stability of Motion (in Russian), , PhD thesis, Kharkov Mathematical Society; Lyapunov, A.M., The general problem of the stability of motion (1992) International Journal of Control, 55 (3), pp. 531-534; Lygeros, J., Tomlin, C., Sastry, S., Controllers for reachability specifications for hybrid systems (1999) Automatica, 35 (3), pp. 349-370; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks; Mitchell, I.M., Bayen, A.M., Tomlin, C.J., A time-dependent Hamilton-Jacobi formulation of reachable sets for continuous dynamic games (2005) IEEE Transactions on Automatic Control, 50 (7), pp. 947-957; Miyato, T., Maeda, S., Koyama, M., Nakae, K., Ishii, S., (2015) Distributional Smoothing with Virtual Adversarial Training; Nayebi, A., Ganguli, S., (2017) Biologically Inspired Protection of Deep Networks from Adversarial Attacks, , arXiv preprint; Newsome, J., Karp, B., Song, D., Paragraph: Thwarting signature learning by training maliciously (2006) International Workshop on Recent Advances in Intrusion Detection; O’Kelly, M., Abbas, H., Gao, S., Shiraishi, S., Kato, S., Mangharam, R., (2016) APEX: Autonomous Vehicle Plan Verification and Execution, , Technical report, University of Pennsylvania; O’Kelly, M., Abbas, H., Mangharam, R., (2017) Computer-Aided Design for Safe Autonomous Vehicles, , Technical report, University of Pennsylvania; Papachristodoulou, A., Prajna, S., On the construction of lyapunov functions using the sum of squares decomposition (2002) IEEE Conference on Decision and Control; Papachristodoulou, A., Prajna, S., Analysis of non-polynomial systems using the sum of squares decomposition (2005) Positive Polynomials in Control; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387; Papernot, N., McDaniel, P., Sinha, A., Wellman, M., (2016) Towards the Science of Security and Privacy in Machine Learning; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) IEEE Symposium on Security and Privacy, pp. 582-597; Parrilo, P.A., Semidefinite programming relaxations for semialgebraic problems (2003) Mathematical Programming, 96 (2), pp. 293-320; Rice, H.G., Classes of recursively enumerable sets and their decision problems (1953) Transactions of the American Mathematical Society, 74 (2), pp. 358-366; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540; Silver, D., Huang, A., Maddison, C.J., Guez, A., Sifre, L., Driessche, G.V.D., Schrittwieser, J., Lanctot, M., Mastering the game of go with deep neural networks and tree search (2016) Nature, 529 (7587), pp. 484-489; Sivaraman, A., Winstein, K., Thaker, P., Balakrishnan, H., An experimental study of the learnability of congestion control (2014) SIGCOMM; Steinhardt, J., Koh, P.W., Liang, P., Certified defenses for data poisoning attacks (2017) Advances in Neural Information Processing Systems (NIPS); Sturm, J.F., Using SeDuMi 1.02, a MATLAB toolbox for optimization over symmetric cones (1999) Optimization Methods and Software, 11, pp. 625-653; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations (ICLR); Tedrake, R., Manchester, I.R., Tobenkin, M.M., Roberts, J.W., LQR-trees: Feedback motion planning via sums of squares verification (2010) International Journal of Robotics Research, 29, pp. 1038-1052; Tobenkin, M.M., Manchester, I.R., Tedrake, R., Invariant funnels around trajectories using sum-of-squares programming (2011) IFAC Proceedings Volumes, 44; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses, , arXiv preprint; Winstein, K., Balakrishnan, H., TCP ex machina: Computer-generated congestion control (2013) SIGCOMM; Xiong, W., Droppo, J., Huang, X., Seide, F., Seltzer, M., Stolcke, A., Yu, D., Zweig, G., (2016) Achieving Human Parity in Conversational Speech Recognition",,,,"International Conference on Learning Representations, ICLR","6th International Conference on Learning Representations, ICLR 2018","30 April 2018 through 3 May 2018",,149806,,,,,"English","Int. Conf. Learn. Represent., ICLR - Conf. Track Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85083952881
"Sharma Y., Chen P.-Y.","57198896649;36930105800;","Attacking the Madry defense model with L1-based adversarial examples",2018,"6th International Conference on Learning Representations, ICLR 2018 - Workshop Track Proceedings",,,,"","",,8,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083952830&partnerID=40&md5=cbad86ce36c97054258b515b1e7ee618","The Cooper Union, New York, NY  10003, United States; IBM Research, Yorktown Heights, NY  10598, United States","Sharma, Y., The Cooper Union, New York, NY  10003, United States; Chen, P.-Y., IBM Research, Yorktown Heights, NY  10598, United States","The Madry Lab recently hosted a competition designed to test the robustness of their adversarially trained MNIST model. Attacks were constrained to perturb each pixel of the input image by a scaled maximal L∞distortion = 0.3. This decision discourages the use of attacks which are not optimized on the L∞distortion metric. Our experimental results demonstrate that by relaxing the L∞constraint of the competition, the elastic-net attack to deep neural networks (EAD) can generate transferable adversarial examples which, despite their high average L∞distortion, have minimal visual distortion. These results call into question the use of L∞as a sole measure for visual distortion, and further demonstrate the power of EAD at generating robust adversarial examples. © 6th International Conference on Learning Representations, ICLR 2018 - Workshop Track Proceedings. All rights reserved.",,"Signal distortion; Average l; Distortion metrics; Elastic net; Input image; Maximal l; Visual distortion; Deep neural networks",,,,,"Beck, A., Teboulle, M., A fast iterative shrinkage-thresholding algorithm for linear inverse problems (2009) SIAM Journal on Imaging Sciences, 2 (1), pp. 183-202; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy (SP), pp. 39-57; Chen, P.Y., Sharma, Y., Zhang, H., Yi, J., Hsieh, C.J., (2017) Ead: Elastic-Net Attacks to Deep Neural Networks Via Adversarial Examples; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR’15; Kingma, D., Ba, J., (2014) Adam: A Method for Stochastic Optimization; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2016) ICLR’17; Liu, Y., Chen, X., Liu, C., Song, D., (2016) Delving into Transferable Adversarial Examples and Black-Box Attacks; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-Box Attacks Using Adversarial Samples; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses",,,,"International Conference on Learning Representations, ICLR","6th International Conference on Learning Representations, ICLR 2018","30 April 2018 through 3 May 2018",,149807,,,,,"English","Int. Conf. Learn. Represent., ICLR - Workshop Track Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85083952830
"Hinton G., Sabour S., Frosst N.","7006699573;57202058686;57201639852;","Matrix capsules with EM routing",2018,"6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings",,,,"","",,392,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083952562&partnerID=40&md5=4dac4eeb2b5015f699847cc0b789eefe","Google Brain, Toronto, Canada","Hinton, G., Google Brain, Toronto, Canada; Sabour, S., Google Brain, Toronto, Canada; Frosst, N., Google Brain, Toronto, Canada","A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagat-ing through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network. © Learning Representations, ICLR 2018 - Conference Track Proceedings.All right reserved.",,"Image segmentation; Iterative methods; Maximum principle; Neural networks; Convolutional neural network; Expectation-maximization algorithms; State of the art; Test errors; Transformation matrices; Viewpoint invariant; White box; Linear transformations",,,,,"Brendel, W., Bethge, M., (2017) Comment on” Biologically Inspired Protection of Deep Networks from Adversarial Attacks, , arXiv preprint; Ciresan, D., Meier, U., Schmidhuber, J., Multi-column deep neural networks for image classification (2012) Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, pp. 3642-3649; Cireşan, D.C., Meier, U., Masci, J., Gambardella, L.M., Schmidhuber, J., (2011) High-Performance Neural Networks for Visual Object Classification, , arXiv preprint; Cohen, T., Welling, M., Group equivariant convolutional networks (2016) International Conference on Machine Learning, pp. 2990-2999; Dai, J., Qi, H., Xiong, Y., Li, Y., Zhang, G., Hu, H., Wei, Y., (2017) Deformable Convolutional Networks, , arXiv preprint; De Brabandere, B., Jia, X., Tuytelaars, T., Van Gool, L., Dynamic filter networks (2016) Neural Information Processing Systems (NIPS); Dieleman, S., De Fauw, J., Kavukcuoglu, K., Exploiting cyclic symmetry in convolutional neural networks (2016) Proceedings of the 33rd International Conference on International Conference on Machine Learning - Volume 48, ICML’16, pp. 1889-1898. , http://dl.acm.org/citation.cfm?id=3045390.3045590, JMLR.org; Fasel, B., Gatica-Perez, D., Rotation-invariant neoperceptron (2006) Pattern Recognition, 2006. ICPR 2006. 18th International Conference on, 3, pp. 336-339; Gens, R., Domingos, P.M., Deep symmetry networks (2014) Advances in Neural Information Processing Systems, pp. 2537-2545; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint; Gregor, K., Danihelka, I., Graves, A., Rezende, D., Wierstra, D., Draw: A recurrent neural network for image generation (2015) International Conference on Machine Learning, pp. 1462-1471; Guermeur, Y., Monfrini, E., A quadratic loss multi-class SVM for which a radius–margin bound applies (2011) Informatica, 22 (1), pp. 73-96; Hinton, G.E., Krizhevsky, A., Wang, S.D., Transforming auto-encoders (2011) International Conference on Artificial Neural Networks, pp. 44-51. , Springer; Jaderberg, M., Simonyan, K., Zisserman, A., Kavukcuoglu, K., Spatial transformer networks (2015) Advances in Neural Information Processing Systems, pp. 2017-2025; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint; Laptev, D., Savinov, N., Buhmann, J.M., Pollefeys, M., Ti-pooling: Transformation-invariant pooling for feature learning in convolutional neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 289-297; LeCun, Y., Boser, B.E., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W.E., Jackel, L.D., Handwritten digit recognition with a back-propagation network (1990) Advances in Neural Information Processing Systems, pp. 396-404; LeCun, Y., Huang, F.J., Bottou, L., Learning methods for generic object recognition with invariance to pose and lighting (2004) Computer Vision and Pattern Recognition, 2004. CVPR 2004. Proceedings of the 2004 IEEE Computer Society Conference on, 2, pp. II–104; Lenc, K., Vedaldi, A., Learning covariant feature detectors (2016) Computer Vision–ECCV 2016 Workshops, pp. 100-117. , Springer; Oyallon, E., Mallat, S., Deep roto-translation scattering for object classification (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2865-2873; Sabour, S., Fross, N., Hinton, G.E., Dynamic routing between capsules (2017) Neural Information Processing Systems (NIPS); Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, L., Polosukhin, I., Attention is all you need (2017) Neural Information Processing Systems (NIPS); Worrall, D.E., Garbin, S.J., Turmukhambetov, D., Brostow, G.J., Harmonic networks: Deep translation and rotation equivariance (2017) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , July",,,,"International Conference on Learning Representations, ICLR","6th International Conference on Learning Representations, ICLR 2018","30 April 2018 through 3 May 2018",,149806,,,,,"English","Int. Conf. Learn. Represent., ICLR - Conf. Track Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85083952562
"Na T., Ko J.H., Mukhopadhyay S.","57189643082;56921245400;8330116700;","Cascade adversarial machine learning regularized with a unified embedding",2018,"6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings",,,,"","",,22,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083952353&partnerID=40&md5=d39378dd2eeb4062726e0f94111c4ff8","School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA  30332, United States","Na, T., School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA  30332, United States; Ko, J.H., School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA  30332, United States; Mukhopadhyay, S., School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA  30332, United States","Injecting adversarial examples during training, known as adversarial training, can improve robustness against one-step attacks, but not for unknown iterative attacks. To address this challenge, we first show iteratively generated adversarial images easily transfer between networks trained with the same strategy. Inspired by this observation, we propose cascade adversarial training, which transfers the knowledge of the end results of adversarial training. We train a network from scratch by injecting iteratively generated adversarial images crafted from already defended networks in addition to one-step adversarial images from the network being trained. We also propose to utilize embedding space for both classification and low-level (pixel-level) similarity learning to ignore unknown pixel level perturbation. During training, we inject adversarial images without replacing their corresponding clean images and penalize the distance between the two embeddings (clean and adversarial). Experimental results show that cascade adversarial training together with our proposed low-level similarity learning efficiently enhances the robustness against iterative attacks, but at the expense of decreased robustness against one-step attacks. We show that combining those two techniques can also improve robustness under the worst case black box attack scenario. © Learning Representations, ICLR 2018 - Conference Track Proceedings.All right reserved.",,"Embeddings; Machine learning; Pixels; Attack scenarios; Black boxes; Clean images; Pixel level; Similarity learning; Iterative methods",,,,,"Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) Proceedings of the International Conference on Learning Representations (ICLR); He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) 2016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2016, pp. 770-778. , http://dx.doi.org/10.1109/CVPR.2016.90, Las Vegas, NV, USA, June 27-30, 2016; Huang, R., Xu, B., Schuurmans, D., Szepesvári, C., Learning with a strong adversary (2015) CoRR, , http://arxiv.org/abs/1511.03034, abs/1511.03034; Krizhevsky, A., (2009) Learning Multiple Layers of Features from Tiny Images, , Technical report; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial machine learning at scale (2017) Proceedings of the International Conference on Learning Representations (ICLR); LeCun, Y., Cortes, C., (2010) MNIST Handwritten Digit Database, , http://yann.lecun.com/exdb/mnist/; Parkhi, O.M., Vedaldi, A., Zisserman, A., Deep face recognition (2015) Proceedings of the British Machine Vision Conference (BMVC); Schroff, F., Kalenichenko, D., Philbin, J., FaceNet: A unified embedding for face recognition and clustering (2015) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , June; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2017) CoRR, , http://arxiv.org/abs/1705.07204, abs/1705.07204; Wen, Y., Zhang, K., Li, Z., Qiao, Y., A discriminative feature learning approach for deep face recognition (2016) Computer Vision - ECCV 2016 - 14th European Conference, pp. 499-515. , http://dx.doi.org/10.1007/978-3-319-46478-7_31, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, VII",,,,"International Conference on Learning Representations, ICLR","6th International Conference on Learning Representations, ICLR 2018","30 April 2018 through 3 May 2018",,149806,,,,,"English","Int. Conf. Learn. Represent., ICLR - Conf. Track Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85083952353
"Samangouei P., Kabkab M., Chellappa R.","57188766185;55452982000;57203078416;","Defense-Gan: Protecting classifiers against adversarial attacks using generative models",2018,"6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings",,,,"","",,273,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083952288&partnerID=40&md5=89d3e0934167ea8524dd3ea46d84758e","Department of Electrical and Computer Engineering, University of Maryland Institute for Advanced Computer Studies, University of Maryland, College Park, MD  20742, United States","Samangouei, P., Department of Electrical and Computer Engineering, University of Maryland Institute for Advanced Computer Studies, University of Maryland, College Park, MD  20742, United States; Kabkab, M., Department of Electrical and Computer Engineering, University of Maryland Institute for Advanced Computer Studies, University of Maryland, College Park, MD  20742, United States; Chellappa, R., Department of Electrical and Computer Engineering, University of Maryland Institute for Advanced Computer Studies, University of Maryland, College Park, MD  20742, United States","In recent years, deep neural network approaches have been widely adopted for machine learning tasks, including classification. However, they were shown to be vulnerable to adversarial perturbations: carefully crafted small perturbations can cause misclassification of legitimate images. We propose Defense-GAN, a new framework leveraging the expressive capability of generative models to defend deep neural networks against such attacks. Defense-GAN is trained to model the distribution of unperturbed images. At inference time, it finds a close output to a given image which does not contain the adversarial changes. This output is then fed to the classifier. Our proposed method can be used with any classification model and does not modify the classifier structure or training procedure. It can also be used as a defense against any attack as it does not assume knowledge of the process for generating the adversarial examples. We empirically show that Defense-GAN is consistently effective against different attack methods and improves on existing defense strategies. © Learning Representations, ICLR 2018 - Conference Track Proceedings.All right reserved.",,"Deep neural networks; Classification models; Defense strategy; Different attacks; Generative model; Misclassifications; Small perturbations; Training procedures; Network security",,,,,"Abadi, M., (2015) TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems, , http://tensorflow.org/.Softwareavailablefromtensorflow.org; Arjovsky, M., (2017) Soumith Chintala, and Léon Bottou. Wasserstein GAN, , arXiv preprint; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations; Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., Courville, A., (2017) Improved Training of Wasserstein GANs, , arXiv preprint; Hendrycks, D., Gimpel, K., Early methods for detecting adversarial images (2017) International Conference on Learning Representations, Workshop Track; Hinton, G., Vinyals, O., Dean, J., (2014) Distilling the Knowledge in A Neural Network; Kabkab, M., Samangouei, P., Chellappa, R., Task-aware compressed sensing with generative models (2018) AAAI Conference on Artificial Intelligence; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2017) International Conference on Learning Representations, Workshop Track; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proceedings of the IEEE, 86 (11), pp. 2278-2324; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) International Conference on Learning Representations; Liu, Z., Luo, P., Wang, X., Tang, X., Deep learning face attributes in the wild (2015) IEEE International Conference on Computer Vision; Meng, D., Chen, H., (2017) MagNet: A Two-Pronged Defense against Adversarial Examples, , arXiv preprint; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) IEEE Conference on Computer Vision and Pattern Recognition; Papernot, N., Goodfellow, I., Sheatsley, R., Feinman, R., McDaniel, P., (2016) Clev-Erhans V1. 0.0: An Adversarial Machine Learning Library, , arXiv preprint; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) IEEE Symposium on Security and Privacy; Papernot, N., McDaniel, P., Sinha, A., Wellman, M., (2016) Towards the Science of Security and Privacy in Machine Learning, , arXiv preprint; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) IEEE Symposium on Security and Privacy; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) ACM Asia Conference on Computer and Communications Security; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations, Workshop Track; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses, , arXiv preprint; Xiao, H., Rasul, K., Vollgraf, R., (2017) Fashion-MNIST: A Novel Image Dataset for Benchmarking Machine Learning Algorithms, , arXiv preprint",,,,"International Conference on Learning Representations, ICLR","6th International Conference on Learning Representations, ICLR 2018","30 April 2018 through 3 May 2018",,149806,,,,,"English","Int. Conf. Learn. Represent., ICLR - Conf. Track Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85083952288
"Oh S.J., Augustin M., Schiele B., Fritz M.","57189659529;57210637371;55267534700;14035495500;","Towards reverse-engineering black-box neural networks",2018,"6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings",,,,"","",,38,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083952255&partnerID=40&md5=9d23f5c5cb866585940b9de7b2236274","Max-Planck Institute for Informatics, Saarland Informatics Campus, Saarbrücken, Germany","Oh, S.J., Max-Planck Institute for Informatics, Saarland Informatics Campus, Saarbrücken, Germany; Augustin, M., Max-Planck Institute for Informatics, Saarland Informatics Campus, Saarbrücken, Germany; Schiele, B., Max-Planck Institute for Informatics, Saarland Informatics Campus, Saarbrücken, Germany; Fritz, M., Max-Planck Institute for Informatics, Saarland Informatics Campus, Saarbrücken, Germany","Many deployed learned models are black boxes: given input, returns output. Internal information about the model, such as the architecture, optimisation procedure, or training data, is not disclosed explicitly as it might contain proprietary information or make the system more vulnerable. This work shows that such attributes of neural networks can be exposed from a sequence of queries. This has multiple implications. On the one hand, our work exposes the vulnerability of black-box neural networks to different types of attacks – we show that the revealed internal information helps generate more effective adversarial examples against the black box model. On the other hand, this technique can be used for better protection of private content from automatic recognition models using adversarial examples. Our paper suggests that it is actually hard to draw a line between white box and black box models. The code is available at goo.gl/MbYfsv. © Learning Representations, ICLR 2018 - Conference Track Proceedings.All right reserved.",,"Automatic recognition; Black boxes; Black-box model; Optimisation procedures; Proprietary information; Training data; White box; Reverse engineering",,,,,"Ateniese, G., Felici, G., Mancini, L.V., Spognardi, A., Villani, A., Vitali, D., Hacking smart machines with smarter ones: How to extract meaningful data from machine learning classifiers (2015) IJSN; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) ACMCCS-W; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR; Hayes, J., Danezis, G., (2017) Machine Learning as An Adversarial Service: Learning Black-Box Adversarial Examples; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) CVPR; Huang, G., Liu, Z., Van Der Maaten, L., Weinberger, K.Q., Densely connected convolutional networks (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Iandola, F.N., Han, S., Moskewicz, M.W., Ashraf, K., Dally, W.J., Keutzer, K., (2016) Squeezenet: Alexnet-Level Accuracy with 50x Fewer Parameters and <0.5mb Model Size, , arXiv; Ioffe, S., Szegedy, C., Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015) ICML; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proceedings of the IEEE; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) ICLR; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) CVPR; Narodytska, N., Kasiviswanathan, S.P., Simple black-box adversarial perturbations for deep networks (2017) CVPRW; Oh, S.J., Fritz, M., Schiele, B., Adversarial image perturbation for privacy protection a game theory perspective (2017) ICCV; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-Box Attacks Using Adversarial Samples, , arXiv; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., (2016) Practical Black-Box Attacks against Deep Learning Systems Using Adversarial Examples; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against deep learning systems using adversarial examples (2017) ASIACCS; Shokri, R., Stronati, M., Song, C., Shmatikov, V., Membership inference attacks against machine learning models (2017) SP; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) ICLR; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) ICLR; Tramer, F., Zhang, F., Juels, A., Reiter, M.K., Ristenpart, T., Stealing machine learning models via prediction apis (2016) USENIX; Van Der Maaten, L.J.P., Hinton, G.E., Visualizing high-dimensional data using t-sne (2008) Journal of Machine Learning Research, 9, p. 25792605. , Nov",,,,"International Conference on Learning Representations, ICLR","6th International Conference on Learning Representations, ICLR 2018","30 April 2018 through 3 May 2018",,149806,,,,,"English","Int. Conf. Learn. Represent., ICLR - Conf. Track Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85083952255
"Guo C., Rana M., Cissé M., Van Der Maaten L.","57202811398;57215331330;55252498700;23092276000;","Countering adversarial images using input transformations",2018,"6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings",,,,"","",,200,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083952128&partnerID=40&md5=4d770c0351c721edd89fba53f92aeb64","Cornell University, United States; Facebook AI Research, United States","Guo, C., Cornell University, United States; Rana, M., Facebook AI Research, United States; Cissé, M., Facebook AI Research, United States; Van Der Maaten, L., Facebook AI Research, United States","This paper investigates strategies that defend against adversarial-example attacks on image-classification systems by transforming the inputs before feeding them to the system. Specifically, we study applying image transformations such as bit-depth reduction, JPEG compression, total variance minimization, and image quilting before feeding the image to a convolutional network classifier. Our experiments on ImageNet show that total variance minimization and image quilting are very effective defenses in practice, in particular, when the network is trained on transformed images. The strength of those defenses lies in their non-differentiable nature and their inherent randomness, which makes it difficult for an adversary to circumvent the defenses. Our best defense eliminates 60% of strong gray-box and 90% of strong black-box attacks by a variety of major attack methods. © Learning Representations, ICLR 2018 - Conference Track Proceedings.All right reserved.",,"Attack methods; Convolutional networks; Image classification systems; Image transformations; Input transformation; JPEG compression; Non-differentiable; Total variance; Image compression",,,,,"Amodei, D., Anubhai, R., Battenberg, E., Case, C., Casper, J., Catanzaro, B., Chen, J.-D., Diamos, G., Deep Speech 2: End-to-end speech recognition in English and Mandarin (2015) CoRR, , abs/1512.02595; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndić, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Proc. ECML, pp. 387-402; Bojarski, M., Testa, D.D., Dworakowski, D., Firner, B., Flepp, B., Goyal, P., Jackel, L.D., Zhang, J., End-to-end learning for self-driving cars (2016) CoRR, , abs/1604.07316; Boykov, Y., Veksler, O., Zabih, R., Fast approximate energy minimization via graph cuts (2001) IEEE Transactions on Pattern Analysis and Machine Intelligence, 23 (11), pp. 1222-1239; Buades, A., A non-local algorithm for image denoising (2005) Proc. CVPR, pp. 60-65; Carlini, N., Wagner, D.A., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy, pp. 39-57; Cisse, M., Adi, Y., Neverova, N., Keshet, J., Houdini: Fooling deep structured prediction models (2017) CoRR, , abs/1707.05373; Cisse, M., Bojanowski, P., Grave, E., Dauphin, Y., Usunier, N., Parseval networks: Improving robustness to adversarial examples (2017) CoRR, , abs/1704.08847; Dong, W., Zhang, L., Shi, G., Centralized sparse representation for image restoration (2011) Proc. ICCV, pp. 1259-1266; Dziugaite, G.K., Ghahramani, Z., Roy, D., A study of the effect of JPG compression on adversarial images (2016) CoRR, , abs/1608.00853; Efros, A., Freeman, W., Image quilting for texture synthesis and transfer (2001) Proc. SIGGRAPH, pp. 341-346; Fawzi, A., Fawzi, O., Frossard, P., Analysis of classifiers’ robustness to adversarial perturbations (2015) CoRR, , abs/1502.02590; Fawzi, A., Moosavi-Dezfooli, S.-M., Frossard, P., Robustness of classifiers: From adversarial to random noise (2016) Proc. NIPS, pp. 1632-1640; Goldstein, T., Osher, S., The split Bregman method for L1-regularized problems (2009) SIAM Journal of Imaging Science, 2 (2), pp. 323-343. , April; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) Proc. ICLR; Graese, A., Rozsa, A., Boult, T.E., Assessing threat of adversarial examples on deep neural networks (2016) CoRR, , abs/1610.04256; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. CVPR, pp. 770-778; Huang, G., Liu, Z., Weinberger, K., Van Der Maaten, L., Densely connected convolutional networks (2017) Proc. CVPR, pp. 2261-2269; Kerckhoffs, A., La cryptographie militaire (1883) Journal Des Sciences Militaires, 9 (5-83). , 161–191; Kingma, D., Ba, J., ADaM: A method for stochastic optimization (2014) CoRR, , abs/1412.6980; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2016) CoRR, , abs/1611.01236; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial examples in the physical world (2016) CoRR, , abs/1607.02533; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2016) CoRR, , abs/1611.02770; Lu, J., Sibai, H., Fabry, E., Forsyth, D., No need to worry about adversarial examples in object detection in autonomous vehicles (2017) CoRR, , abs/1707.03501; Maddison, C., Mnih, A., Teh, Y.-W., The concrete distribution: A continuous relaxation of discrete random variables (2017) Proc. ICLR; Melis, M., Demontis, A., Biggio, B., Brown, G., Fumera, G., Roli, F., Is deep learning safe for robot vision? Adversarial examples against the icub humanoid (2017) CoRR, , abs/1708.06939; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proc. CVPR, pp. 2574-2582; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) Proc. CVPR, pp. 86-94; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) IEEE Symposium on Security and Privacy, pp. 582-597; Rudin, L., Osher, S., Fatemi, E., Nonlinear total variation based noise removal algorithms (1992) Physica D, 60, pp. 259-268; Shaham, U., Yamada, Y., Negahban, S., Understanding adversarial training: Increasing local stability of neural nets through robust optimization (2015) CoRR, , abs/1511.05432; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) Proc. ICLR, , In; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proc. CVPR, pp. 2818-2826; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A., Inception-v4, Inception-ResNet and the impact of residual connections on learning (2017) Proc. AAAI, pp. 4278-4284; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P.D., Ensemble adversarial training: Attacks and defenses (2017) CoRR, , abs/1705.07204; Wang, Q., Guo, W., Zhang, K., Ororbia, A.G., II, Xing, X., Lee Giles, C., Liu, X., Adversary resistant deep neural networks with an application to malware detection (2016) CoRR, , abs/1610.01239; Wang, Q., Guo, W., Zhang, K., Ororbia, A.G., II, Xing, X., Lee Giles, C., Liu, X., Learning adversary-resistant deep neural networks (2016) CoRR, , abs/1612.01401; Xu, W., Evans, D., Qi, Y., Feature squeezing: Detecting adversarial examples in deep neural networks (2017) CoRR, , abs/1704.01155; Zhang, G., Yan, C., Ji, X., Zhang, T., Zhang, T., Xu, W., Dolphi-natack: Inaudible voice commands (2017) CoRR, , abs/1708.09537",,,,"International Conference on Learning Representations, ICLR","6th International Conference on Learning Representations, ICLR 2018","30 April 2018 through 3 May 2018",,149806,,,,,"English","Int. Conf. Learn. Represent., ICLR - Conf. Track Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85083952128
"Bhagoji A.N., He W., Li B., Song D.","57189365305;57207135651;57188689924;7402443870;","Black-box attacks on deep neural networks via gradient estimation",2018,"6th International Conference on Learning Representations, ICLR 2018 - Workshop Track Proceedings",,,,"","",,4,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083951878&partnerID=40&md5=35e486887c2c9ae62fe265d7cd8cc93c","Department of Electrical Engineering, Princeton University, United States; EECS Department, University of California, Berkeley, United States; UC Berkeley, United States","Bhagoji, A.N., Department of Electrical Engineering, Princeton University, United States, UC Berkeley, United States; He, W., EECS Department, University of California, Berkeley, United States; Li, B., EECS Department, University of California, Berkeley, United States; Song, D., EECS Department, University of California, Berkeley, United States","In this paper, we propose novel Gradient Estimation black-box attacks to generate adversarial examples with query access to the target model’s class probabilities, which do not rely on transferability. We also propose strategies to decouple the number of queries required to generate each adversarial example from the dimensionality of the input. An iterative variant of our attack achieves close to 100% attack success rates for both targeted and untargeted attacks on DNNs. We show that the proposed Gradient Estimation attacks outperform all other black-box attacks we tested on both MNIST and CIFAR-10 datasets, achieving attack success rates similar to well known, state-of-the-art white-box attacks. We also apply the Gradient Estimation attacks successfully against a real-world content moderation classifier hosted by Clarifai. © 6th International Conference on Learning Representations, ICLR 2018 - Workshop Track Proceedings. All rights reserved.",,"Black boxes; Class probabilities; Gradient estimation; Real-world; State of the art; Target model; White box; Deep neural networks",,,,,"Benenson, R., Classification Datasets Results, , http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#494c5356524332303132207461736b2031, Accessed: 2017-08-22; Bhagoji, A.N., He, W., Li, B., Song, D., (2017) Exploring the Space of Black-Box Attacks on Deep Neural Networks; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy, , 2017; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., (2017) Zoo: Zeroth Order Optimization Based Black-Box Attacks to Deep Neural Networks without Training Substitute Models; Clarifai | Image & Video Recognition API, , https://clarifai.com, Accessed: 2017-08-22; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Hildebrand, F.B., (1962) Advanced Calculus for Applications, 63. , Prentice-Hall Engle-wood Cliffs, NJ; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World; LeCun, Y., Cortes, C., (1998) The MNIST Database of Handwritten Digits; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., (2016) Universal Adversarial Perturbations; Narodytska, N., Kasiviswanathan, S.P., (2016) Simple Black-Box Adversarial Perturbations for Deep Networks; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-Box Attacks Using Adversarial Samples; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against deep learning systems using adversarial examples (2017) Proceedings of the 2017 ACM Asia Conference on Computer and Communications Security; Shlens, J., (2014) A Tutorial on Principal Component Analysis; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations; Tensorflow Resnet Models, , https://github.com/tensorflow/models/tree/master/resnet, Accessed: 2017-08-22; Zagoruyko, S., Komodakis, N., (2016) Wide Residual Networks",,,,"International Conference on Learning Representations, ICLR","6th International Conference on Learning Representations, ICLR 2018","30 April 2018 through 3 May 2018",,149807,,,,,"English","Int. Conf. Learn. Represent., ICLR - Workshop Track Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85083951878
[No author name available],[No author id available],"Intriguing properties of adversarial examples",2018,"6th International Conference on Learning Representations, ICLR 2018 - Workshop Track Proceedings",,,,"","",,6,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083951571&partnerID=40&md5=55d73a98677410a45939db39b68f4640",,"","It is becoming increasingly clear that many machine learning classifiers are vulnerable to adversarial examples. In attempting to explain the origin of adversarial examples, previous studies have typically focused on the fact that neural networks operate on high dimensional data, they overfit, or they are too linear. Here we show that distributions of logit differences have a universal functional form. This functional form is independent of architecture, dataset, and training protocol; nor does it change during training. This leads to adversarial error having a universal scaling, as a power-law, with respect to the size of the adversarial perturbation. We show that this universality holds for a broad range of datasets (MNIST, CIFAR10, ImageNet, and random data), models (including state-of-the-art deep networks, linear models, adversarially trained networks, and networks trained on randomly shuffled labels), and attacks (FGSM, step l.l., PGD). Motivated by these results, we study the effects of reducing prediction entropy on adversarial robustness. Finally, we study the effect of network architectures on adversarial sensitivity. To do this, we use neural architecture search with reinforcement learning to find adversarially robust architectures on CIFAR10. Our resulting architecture is more robust to white and black box attacks compared to previous attempts. © 6th International Conference on Learning Representations, ICLR 2018 - Workshop Track Proceedings. All rights reserved.",,"Clustering algorithms; Machine learning; Reinforcement learning; Black boxes; Functional forms; High dimensional data; Neural architectures; Power-law; Random data; State of the art; Universal scaling; Network architecture",,,,,"Cisse, M., Bojanowski, P., Grave, E., Dauphin, Y., Usunier, N., Parseval networks: Improving robustness to adversarial examples (2017) International Conference on Machine Learning, pp. 854-863; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Hinton, G., Vinyals, O., Dean, J., (2015) Distilling the Knowledge in A Neural Network; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Machine Learning at Scale; LeCun, Y., Cortes, C., The Mnist Database of Handwritten Digits, , http://yann.lecun.com/exdb/mnist/; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks; Miyato, T., Maeda, S.-I., Koyama, M., Ishii, S., (2017) Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning; Nayebi, A., Ganguli, S., (2017) Biologically Inspired Protection of Deep Networks from Adversarial Attacks; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., (2016) Practical Black-Box Attacks against Deep Learning Systems Using Adversarial Examples; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Security and Privacy (SP), 2016 IEEE Symposium on, pp. 582-597. , IEEE; Pereyra, G., Tucker, G., Chorowski, J., Kaiser, Ł., Hinton, G., (2017) Regularizing Neural Networks by Penalizing Confident Output Distributions; Poole, B., Lahiri, S., Raghu, M., Sohl-Dickstein, J., Ganguli, S., Exponential expressivity in deep neural networks through transient chaos (2016) Advances in Neural Information Processing Systems, pp. 3360-3368; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Bernstein, M., Imagenet large scale visual recognition challenge (2015) International Journal of Computer Vision, 115 (3), pp. 211-252; Schoenholz, S.S., Gilmer, J., Ganguli, S., Sohl-Dickstein, J., (2016) Deep Information Propagation; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., Inception-v4, inception-resnet and the impact of residual connections on learning (2017) AAAI, pp. 4278-4284; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses; Xu, W., Evans, D., Qi, Y., (2017) Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks; Zhang, C., Bengio, S., Hardt, M., Recht, B., Vinyals, O., (2016) Understanding Deep Learning Requires Rethinking Generalization; Zoph, B., Le, Q.V., (2016) Neural Architecture Search with Reinforcement Learning; Zoph, B., Vasudevan, V., Shlens, J., Le, Q.V., (2017) Learning Transferable Architectures for Scalable Image Recognition",,,,"International Conference on Learning Representations, ICLR","6th International Conference on Learning Representations, ICLR 2018","30 April 2018 through 3 May 2018",,149807,,,,,"English","Int. Conf. Learn. Represent., ICLR - Workshop Track Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85083951571
"Song Y., Nowozin S., Kushman N., Kim T., Ermon S.","57192167461;22234870700;36707949600;57200078405;35791579200;","PixelDefend: Leveraging generative models to understand and defend against adversarial examples",2018,"6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings",,,,"","",,84,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083951380&partnerID=40&md5=fc309a71484ccfc202395fd6cd80a1b2","Stanford University, United States; Microsoft Research, United States; Université de Montréal, Canada","Song, Y., Stanford University, United States; Nowozin, S., Microsoft Research, United States; Kushman, N., Microsoft Research, United States; Kim, T., Université de Montréal, Canada; Ermon, S., Stanford University, United States","Adversarial perturbations of normal images are usually imperceptible to humans, but they can seriously confuse state-of-the-art machine learning models. What makes them so special in the eyes of image classifiers? In this paper, we show empirically that adversarial examples mainly lie in the low probability regions of the training distribution, regardless of attack types and targeted models. Using statistical hypothesis testing, we find that modern neural density models are surprisingly good at detecting imperceptible image perturbations. Based on this discovery, we devised PixelDefend, a new approach that purifies a maliciously perturbed image by moving it back towards the distribution seen in the training data. The purified image is then run through an unmodified classifier, making our method agnostic to both the classifier and the attacking method. As a result, PixelDefend can be used to protect already deployed models and be combined with other model-specific defenses. Experiments show that our method greatly improves resilience across a wide variety of state-of-the-art attacking methods, increasing accuracy on the strongest attack from 63% to 84% for Fashion MNIST and from 32% to 70% for CIFAR-10. © Learning Representations, ICLR 2018 - Conference Track Proceedings.All right reserved.",,"Testing; Density models; Generative model; Image Classifiers; Low probability; Machine learning models; New approaches; State of the art; Statistical hypothesis testing; Probability distributions",,,,,"Amodei, D., Olah, C., Steinhardt, J., Christiano, P., Schulman, J., Mané, D., (2016) Concrete Problems in Ai Safety, , arXiv preprint; Bengio, Y., Simard, P., Frasconi, P., Learning long-term dependencies with gradient descent is difficult (1994) IEEE Transactions on Neural Networks, 5 (2), pp. 157-166; Byrd, R.H., Lu, P., Nocedal, J., Zhu, C., A limited memory algorithm for bound constrained optimization (1995) SIAM Journal on Scientific Computing, 16 (5), pp. 1190-1208; Carlini, N., Wagner, D., (2017) Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods, , arXiv preprint; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium on, pp. 39-57. , IEEE; Cisse, M., Bojanowski, P., Grave, E., Dauphin, Y., Usunier, N., Parseval networks: Improving robustness to adversarial examples (2017) International Conference on Machine Learning, pp. 854-863; Efron, B., Tibshirani, R.J., (1994) An Introduction to the Bootstrap, , CRC press; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts, , arXiv preprint; Gong, Z., Wang, W., Ku, W.-S., (2017) Adversarial and Clean Data Are Not Twins, , arXiv preprint; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint; Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., (2017) On the (Statistical) Detection of Adversarial Examples, , arXiv preprint; Gu, S., Rigazio, L., (2014) Towards Deep Neural Network Architectures Robust to Adversarial Examples, , arXiv preprint; He, K., Zhang, X., Ren, S., Sun, J., Delving deep into rectifiers: Surpassing human-level performance on imagenet classification (2015) Proceedings of the IEEE International Conference on Computer Vision, pp. 1026-1034; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Hein, M., Maier, M., Manifold denoising (2007) Advances in Neural Information Processing Systems, pp. 561-568; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images; Krizhevsky, A., Nair, V., Hinton, G., Cifar-10 (Canadian Institute for Advanced Research), , http://www.cs.toronto.edu/~kriz/cifar.html; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Machine Learning at Scale, , arXiv preprint; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proceedings of the IEEE, 86 (11), pp. 2278-2324; Li, Y., Gal, Y., (2017) Dropout Inference in Bayesian Neural Networks with Alpha-Divergences, , arXiv preprint; Liu, Y., Chen, X., Liu, C., Song, D., (2016) Delving into Transferable Adversarial Examples and Black-Box Attacks, , arXiv preprint; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , arXiv preprint; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., (2017) On Detecting Adversarial Perturbations, , arXiv preprint; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Nayebi, A., Ganguli, S., (2017) Biologically Inspired Protection of Deep Networks from Adversarial Attacks, , arXiv preprint; Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., Ng, A.Y., Reading digits in natural images with unsupervised feature learning (2011) NIPS Workshop on Deep Learning and Unsupervised Feature Learning, 2011, p. 5; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-Box Attacks Using Adversarial Samples, , arXiv preprint; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387. , IEEE; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Security and Privacy (SP), 2016 IEEE Symposium on, pp. 582-597. , IEEE; Ramachandran, P., Le Paine, T., Khorrami, P., Babaeizadeh, M., Chang, S., Zhang, Y., Hasegawa-Johnson, M.A., Huang, T.S., (2017) Fast Generation for Convolutional Autoregressive Models, , arXiv preprint; Salimans, T., Karpathy, A., Chen, X., Kingma, D.P., (2017) Pixelcnn++: Improving the Pixelcnn with Discretized Logistic Mixture Likelihood and Other Modifications, , arXiv preprint; Sasaki, H., Hyvärinen, A., Sugiyama, M., Clustering via mode seeking by direct estimation of the gradient of a log-density (2014) Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 19-34. , Springer; Shimodaira, H., Improving predictive inference under covariate shift by weighting the log-likelihood function (2000) Journal of Statistical Planning and Inference, 90 (2), pp. 227-244; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2014) CoRR, , abs/1409.1556; Sutskever, I., Vinyals, O., Le, Q.V., Sequence to sequence learning with neural networks (2014) Advances in Neural Information Processing Systems, pp. 3104-3112; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint; Tramèr, F., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2017) The Space of Transferable Adversarial Examples, , arXiv preprint; Van den Oord, A., Kalchbrenner, N., Espeholt, L., Vinyals, O., Graves, A., Conditional image generation with pixelcnn decoders (2016) Advances in Neural Information Processing Systems, pp. 4790-4798; Van den Oord, A., Kalchbrenner, N., Kavukcuoglu, K., (2016) Pixel Recurrent Neural Networks, , arXiv preprint; Vincent, P., Larochelle, H., Bengio, Y., Manzagol, P.-A., Extracting and composing robust features with denoising autoencoders (2008) Proceedings of the 25th International Conference on Machine Learning, pp. 1096-1103. , ACM; Warde-Farley, D., Goodfellow, I., 11 adversarial perturbations of deep neural networks (2016) Perturbations, Optimization, and Statistics, p. 311; Xiao, H., Rasul, K., Vollgraf, R., (2017) Fashion-Mnist: A Novel Image Dataset for Benchmarking Machine Learning Algorithms; Xu, W., Evans, D., Qi, Y., (2017) Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks, , arXiv preprint; Xu, W., Evans, D., Qi, Y., (2017) Feature Squeezing Mitigates and Detects Carlini/Wagner Adversarial Examples, , arXiv preprint; Zhu, C., Byrd, R.H., Lu, P., Nocedal, J., Algorithm 778: L-bfgs-b: Fortran subroutines for large-scale bound-constrained optimization (1997) ACM Transactions on Mathematical Software (TOMS), 23 (4), pp. 550-560",,,,"International Conference on Learning Representations, ICLR","6th International Conference on Learning Representations, ICLR 2018","30 April 2018 through 3 May 2018",,149806,,,,,"English","Int. Conf. Learn. Represent., ICLR - Conf. Track Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85083951380
"Buckman J., Roy A., Raffel C., Goodfellow I.","57204809464;57188827520;55354986300;35956088800;","Thermometer encoding: One hot way to resist adversarial examples",2018,"6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings",,,,"","",,189,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083951342&partnerID=40&md5=6beddf60656d9a1617ba83e51b163516","Google Brain, Mountain View, CA, United States","Buckman, J., Google Brain, Mountain View, CA, United States; Roy, A., Google Brain, Mountain View, CA, United States; Raffel, C., Google Brain, Mountain View, CA, United States; Goodfellow, I., Google Brain, Mountain View, CA, United States","It is well known that it is possible to construct “adversarial examples” for neural networks: inputs which are misclassified by the network yet indistinguishable from true data. We propose a simple modification to standard neural network architectures, thermometer encoding, which significantly increases the robustness of the network to adversarial examples. We demonstrate this robustness with experiments on the MNIST, CIFAR-10, CIFAR-100, and SVHN datasets, and show that models with thermometer-encoded inputs consistently have higher accuracy on adversarial examples, without decreasing generalization. State-of-the-art accuracy under the strongest known white-box attack was increased from 93.20% to 94.30% on MNIST and 50.00% to 79.16% on CIFAR-10. We explore the properties of these networks, providing evidence that thermometer encodings help neural networks to find more-non-linear decision boundaries. © Learning Representations, ICLR 2018 - Conference Track Proceedings.All right reserved.",,"Encoding (symbols); Network architecture; Neural networks; Thermometers; Encodings; Non linear; Simple modifications; Standard neural; State of the art; Thermometer encoding; White box; Signal encoding",,,,,"Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndić, N., Laskov, P., Giacinto, G.-G., Roli, F., Evasion attacks against machine learning at test time (2013) Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 387-402. , Springer; Cisse, M., Bojanowski, P., Grave, E., Dauphin, Y., Usunier, N., Parseval networks: Improving robustness to adversarial examples (2017) International Conference on Machine Learning, pp. 854-863; Goodfellow, I.J., Warde-Farley, D., Mirza, M., Courville, A., Bengio, Y., (2013) Maxout Networks, , arXiv preprint; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint; Han, J., Moraga, C., The influence of the sigmoid function parameters on the speed of backpropagation learning (1995) From Natural to Artificial Neural Computation, pp. 195-201; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9 (8), pp. 1735-1780; Huang, G., Sun, Y., Liu, Z., Sedra, D., Weinberger, K.Q., Deep networks with stochastic depth (2016) European Conference on Computer Vision, pp. 646-661. , Springer; Jang, E., Gu, S., Poole, B., (2016) Categorical Reparameterization with Gumbel-Softmax, , arXiv preprint; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Machine Learning at Scale, , arXiv preprint; Lin, M., Chen, Q., Yan, S., (2013) Network in Network, , arXiv preprint; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2016) CoRR, , http://arxiv.org/abs/1611.02770, abs/1611.02770; Maddison, C.J., Mnih, A., Teh, Y.W., (2016) The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables, , arXiv preprint; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , arXiv preprint; Van Den Oord, A., Kalchbrenner, N., Kavukcuoglu, K., (2016) Pixel Recurrent Neural Networks, , arXiv preprint; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., (2016) Practical Black-Box Attacks against Deep Learning Systems Using Adversarial Examples, , arXiv preprint; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R., Intriguing properties of neural networks (2014) ICLR, , http://arxiv.org/abs/1312.6199, abs/1312.6199; Xu, W., Evans, D., Qi, Y., (2017) Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks, , arXiv preprint; Zagoruyko, S., Komodakis, N., (2016) Wide Residual Networks, , arXiv preprint",,,,"International Conference on Learning Representations, ICLR","6th International Conference on Learning Representations, ICLR 2018","30 April 2018 through 3 May 2018",,149806,,,,,"English","Int. Conf. Learn. Represent., ICLR - Conf. Track Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85083951342
"Galloway A., Taylor G.W., Moussa M.","57202364429;55377841000;35894523000;","Attacking binarized neural networks",2018,"6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings",,,,"","",,14,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083951287&partnerID=40&md5=22e34dc2d0297abd8676cb73e0791fc8","School of Engineering, University of Guelph, Canada; Canadian Institute for Advanced Research, Canada; Vector Institute for Artificial Intelligence, Canada","Galloway, A., School of Engineering, University of Guelph, Canada; Taylor, G.W., School of Engineering, University of Guelph, Canada, Canadian Institute for Advanced Research, Canada, Vector Institute for Artificial Intelligence, Canada; Moussa, M., School of Engineering, University of Guelph, Canada","Neural networks with low-precision weights and activations offer compelling efficiency advantages over their full-precision equivalents. The two most frequently discussed benefits of quantization are reduced memory consumption, and a faster forward pass when implemented with efficient bitwise operations. We propose a third benefit of very low-precision neural networks: improved robustness against some adversarial attacks, and in the worst case, performance that is on par with full-precision models. We focus on the very low-precision case where weights and activations are both quantized to ±1, and note that stochastically quantizing weights in just one layer can sharply reduce the impact of iterative attacks. We observe that non-scaled binary neural networks exhibit a similar effect to the original defensive distillation procedure that led to gradient masking, and a false notion of security. We address this by conducting both black-box and white-box experiments with binary models that do not artificially mask gradients.1 © Learning Representations, ICLR 2018 - Conference Track Proceedings.All right reserved.",,"Distillation; Binary models; Binary neural networks; Bitwise operations; Black boxes; Distillation procedure; Precision model; Reduced memory; White box; Chemical activation",,,,,"Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G.S., Zheng, X., (2015) TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems, , https://www.tensorflow.org/.Softwareavailablefromtensorflow.org; Bengio, Y., Léonard, N., Courville, A.C., Estimating or propagating gradients through stochastic neurons for conditional computation (2013) CoRR, , http://arxiv.org/abs/1308.3432, abs/1308.3432; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndić, N., Laskov, P., Giacinto, G.-G., Roli, F., (2013) Evasion Attacks against Machine Learning at Test Time, pp. 387-402. , Springer Berlin Heidelberg, Berlin, Heidelberg; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium on, pp. 39-57; Courbariaux, M., Bengio, Y., (2016) Binarynet: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1, , arXiv preprint; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) Proceedings of the International Conference on Learning Representations; Ioffe, S., Szegedy, C., Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015) ICML; Krizhevsky, A., (2009) Learning Multiple Layers of Features from Tiny Images, , Technical report; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial machine learning at scale (2017) Proceedings of the International Conference on Learning Representations; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial examples in the physical world (2017) Proceedings of the International Conference on Learning Representations (Workshop); LeCun, Y., Cortes, C., (1998) The Mnist Database of Handwritten Digits, , http://yann.lecun.com/exdb/mnist/; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , arXiv preprint; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., (2015) Deepfool: A Simple and Accurate Method to Fool Deep Neural Networks, , http://arxiv.org/abs/1511.04599, abs/1511.04599; Papernot, N., McDaniel, P.D., (2017) Extending Defensive Distillation, , http://arxiv.org/abs/1705.05264, arXiv, abs/1705.05264; Papernot, N., McDaniel, P.D., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., (2015) The Limitations of Deep Learning in Adversarial Settings, , http://arxiv.org/abs/1511.07528, abs/1511.07528; Papernot, N., Carlini, N., Goodfellow, I., Feinman, R., Faghri, F., Matyasko, A., Hambardzumyan, K., Lin, Y.-C., (2017) Cleverhans V2.0.0: An Adversarial Machine Learning Library, , arXiv preprint; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, ASIA CCS’17, pp. 506-519. , New York, NY, USA, ACM; Rastegari, M., Ordonez, V., Redmon, J., Farhadi, A., XNOR-Net: Imagenet classification using binary convolutional neural networks (2016) ECCV; Rauber, J., Brendel, W., Bethge, M., (2017) Foolbox V0.8.0: A Python Toolbox to Benchmark the Robustness of Machine Learning Models, , arXiv preprint; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint; Tang, W., Hua, G., Wang, L., How to train a compact binary neural network with high accuracy? (2017) Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence; Tramèr, F., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2017) The Space of Transferable Adversarial Examples, , https://arxiv.org/abs/1704.03453; Zhou, S., Wu, Y., Ni, Z., Zhou, X., Wen, H., Zou, Y., (2016) Dorefa-Net: Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients, , arXiv preprint",,,,"International Conference on Learning Representations, ICLR","6th International Conference on Learning Representations, ICLR 2018","30 April 2018 through 3 May 2018",,149806,,,,,"English","Int. Conf. Learn. Represent., ICLR - Conf. Track Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85083951287
"Gopalakrishnan S., Marzi Z., Madhow U., Pedarsani R.","24491814400;56380560200;7003746022;36574033500;","Combating adversarial attacks using sparse representations",2018,"6th International Conference on Learning Representations, ICLR 2018 - Workshop Track Proceedings",,,,"","",,7,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083951265&partnerID=40&md5=ea39545ad291f5ad921f86e6746f82c1","Department of Electrical and Computer Engineering, University of California, Santa Barbara, Santa Barbara, CA  93106, United States","Gopalakrishnan, S., Department of Electrical and Computer Engineering, University of California, Santa Barbara, Santa Barbara, CA  93106, United States; Marzi, Z., Department of Electrical and Computer Engineering, University of California, Santa Barbara, Santa Barbara, CA  93106, United States; Madhow, U., Department of Electrical and Computer Engineering, University of California, Santa Barbara, Santa Barbara, CA  93106, United States; Pedarsani, R., Department of Electrical and Computer Engineering, University of California, Santa Barbara, Santa Barbara, CA  93106, United States","It is by now well-known that small adversarial perturbations can induce classification errors in deep neural networks (DNNs). In this paper, we make the case that sparse representations of the input data are a crucial tool for combating such attacks. For linear classifiers, we show that a sparsifying front end is provably effective against `∞-bounded attacks, reducing output distortion due to the attack by a factor of roughly K/N where N is the data dimension and K is the sparsity level. We then extend this concept to DNNs, showing that a “locally linear” model can be used to develop a theoretical foundation for crafting attacks and defenses. Experimental results for the MNIST dataset show the efficacy of the proposed sparsifying front end. © 6th International Conference on Learning Representations, ICLR 2018 - Workshop Track Proceedings. All rights reserved.",,"Classification errors; Data dimensions; Front end; Input datas; Linear classifiers; Sparse representation; Theoretical foundations; Deep neural networks",,,,,"Bhagoji, A.N., Cullina, D., Sitawarin, C., Mittal, P., (2017) Enhancing Robustness of Machine Learning Systems Via Data Transformations; Cohen, A., Daubechies, I., Feauveau, J.-C., Biorthogonal bases of compactly supported wavelets (1992) Communications on Pure and Applied Mathematics, 45 (5), pp. 485-560; Das, N., Shanbhogue, M., Chen, S.-T., Hohman, F., Chen, L., Kounavis, M.E., Chau, D.H., (2017) Keeping the Bad Guys Out: Protecting and Vaccinating Deep Learning with JPEG Compression; Fawzi, A., Moosavi-Dezfooli, S.-M., Frossard, P., Soatto, S., (2017) Classification Regions of Deep Neural Networks; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations (ICLR); Guo, C., Rana, M., Cisse, M., Van Der Maaten, L., Countering adversarial images using input transformations (2018) International Conference on Learning Representations (ICLR); Ilyas, A., Jalal, A., Asteri, E., Daskalakis, C., Dimakis, A.G., (2017) The Robust Manifold Defense: Adversarial Training Using Generative Models; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proceedings of the IEEE, 86 (11), pp. 2278-2324; Marzi, Z., Gopalakrishnan, S., Madhow, U., Pedarsani, R., Sparsity-based defense against adversarial attacks on linear classifiers (2018) IEEE International Symposium on Information Theory (ISIT), , To appear; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2574-2582; Nielsen, M.A., (2015) Neural Networks and Deep Learning, , Determination Press; Poole, B., Lahiri, S., Raghu, M., Sohl-Dickstein, J., Ganguli, S., Exponential expressivity in deep neural networks through transient chaos (2016) Advances in Neural Information Processing Systems (NIPS), pp. 3360-3368; Samangouei, P., Kabkab, M., Chellappa, R., Defense-Gan: Protecting classifiers against adversarial attacks using generative models (2018) International Conference on Learning Representations (ICLR); Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations (ICLR)",,,,"International Conference on Learning Representations, ICLR","6th International Conference on Learning Representations, ICLR 2018","30 April 2018 through 3 May 2018",,149807,,,,,"English","Int. Conf. Learn. Represent., ICLR - Workshop Track Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85083951265
"Xie C., Zhang Z., Yuille A.L., Wang J., Ren Z.","57200616617;57200612412;7006372632;57142698500;23005801300;","Mitigating adversarial effects through randomization",2018,"6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings",,,,"","",,126,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083951215&partnerID=40&md5=5749186c588b6c99c900c599053a4d6a","Department of Computer Science, Johns Hopkins University, Baltimore, MD  21218, United States; Baidu Research USA, Sunnyvale, CA  94089, United States; Snap Inc, Venice, CA  90291, United States","Xie, C., Department of Computer Science, Johns Hopkins University, Baltimore, MD  21218, United States; Zhang, Z., Department of Computer Science, Johns Hopkins University, Baltimore, MD  21218, United States; Yuille, A.L., Department of Computer Science, Johns Hopkins University, Baltimore, MD  21218, United States; Wang, J., Baidu Research USA, Sunnyvale, CA  94089, United States; Ren, Z., Snap Inc, Venice, CA  90291, United States","Convolutional neural networks have demonstrated high accuracy on various tasks in recent years. However, they are extremely vulnerable to adversarial examples. For example, imperceptible perturbations added to clean images can cause convolutional neural networks to fail. In this paper, we propose to utilize randomization at inference time to mitigate adversarial effects. Specifically, we use two randomization operations: random resizing, which resizes the input images to a random size, and random padding, which pads zeros around the input images in a random manner. Extensive experiments demonstrate that the proposed randomization method is very effective at defending against both single-step and iterative attacks. Our method provides the following advantages: 1) no additional training or fine-tuning, 2) very few additional computations, 3) compatible with other adversarial defense methods. By combining the proposed randomization method with an adversarially trained model, it achieves a normalized score of 0.924 (ranked No.2 among 107 defense teams) in the NIPS 2017 adversarial examples defense challenge, which is far better than using adversarial training alone with a normalized score of 0.773 (ranked No.56). The code is public available at https://github.com/cihangxie/NIPS2017_adv_challenge_defense. © Learning Representations, ICLR 2018 - Conference Track Proceedings.All right reserved.",,"Convolution; Iterative methods; Network security; Neural networks; Clean images; Convolutional neural network; Fine tuning; High-accuracy; Input image; Normalized scores; Single-step; Random processes",,,,,"Biggio, B., Laskov, P., Poisoning attacks against support vector machines (2012) International Conference on Machine Learning; Cao, X., Gong, N.Z., Mitigating evasion attacks to deep neural networks via region-based classification (2017) Proceedings of the 33rd Annual Computer Security Applications Conference; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy; Chen, L.-C., Papandreou, G., Kokkinos, I., Murphy, K., Yuille, A.L., Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs (2017) IEEE Transactions on Pattern Analysis and Machine Intelligence; Cisse, M., Adi, Y., Neverova, N., Keshet, J., (2017) Houdini: Fooling Deep Structured Prediction Models, , arXiv preprint; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., ImageNet: A large-scale hierarchical image database (2009) Computer Vision and Pattern Recognition; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts, , arXiv preprint; Fischer, V., Kumar, M.C., Metzen, J.H., Brox, T., (2017) Adversarial Examples for Semantic Image Segmentation, , arXiv preprint; Girshick, R., Fast R-CNn (2015) International Conference on Computer Vision; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Computer Vision and Pattern Recognition; He, K., Zhang, X., Ren, S., Sun, J., Identity mappings in deep residual networks (2016) European Conference on Computer Vision, , Springer; Koh, P.W., Liang, P., (2017) Understanding Black-Box Predictions Via Influence Functions, , arXiv preprint; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2017) International Conference on Learning Representations; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) International Conference on Learning Representations; Long, J., Shelhamer, E., Darrell, T., Fully convolutional networks for semantic segmentation (2015) Computer Vision and Pattern Recognition; Meng, D., Chen, H., (2017) Magnet: A Two-Pronged Defense against Adversarial Examples, , arXiv preprint; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., On detecting adversarial perturbations (2017) International Conference on Learning Representations; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Computer Vision and Pattern Recognition; Papernot, N., Goodfellow, I., Sheatsley, R., Feinman, R., McDaniel, P., (2016) Cleverhans V1.0.0: An Adversarial Machine Learning Library, , arXiv preprint; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) IEEE Symposium on Security and Privacy; Ren, S., He, K., Girshick, R., Sun, J., Faster R-CNN: Towards real-time object detection with region proposal networks (2015) Advances in Neural Information Processing Systems; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) International Conference on Learning Representations; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Computer Vision and Pattern Recognition; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., Inception-v4, inception-resnet and the impact of residual connections on learning (2017) AAAI; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses, , arXiv preprint; Wang, J., Zhang, Z., Xie, C., Zhou, Y., Premachandran, V., Zhu, J., Xie, L., Yuille, A., (2017) Visual Concepts and Compositional Voting, , arXiv preprint; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., Adversarial examples for semantic segmentation and object detection (2017) International Conference on Computer Vision; Zhang, Z., Qiao, S., Xie, C., Shen, W., Wang, B., Yuille, A.L., (2017) Single-Shot Object Detection with Enriched Semantics, , arXiv preprint",,,,"International Conference on Learning Representations, ICLR","6th International Conference on Learning Representations, ICLR 2018","30 April 2018 through 3 May 2018",,149806,,,,,"English","Int. Conf. Learn. Represent., ICLR - Conf. Track Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85083951215
"Jetley S., Lord N.A., Lee N., Torr P.H.S.","55599580900;57201336704;57190136574;56821543600;","Learn to pay attention",2018,"6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings",,,,"","",,171,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083950708&partnerID=40&md5=f8387c9a6734f67f25610707577c03bc","Department of Engineering Science, University of Oxford, United Kingdom","Jetley, S., Department of Engineering Science, University of Oxford, United Kingdom; Lord, N.A., Department of Engineering Science, University of Oxford, United Kingdom; Lee, N., Department of Engineering Science, University of Oxford, United Kingdom; Torr, P.H.S., Department of Engineering Science, University of Oxford, United Kingdom","We propose an end-to-end-trainable attention module for convolutional neural network (CNN) architectures built for image classification. The module takes as input the 2D feature vector maps which form the intermediate representations of the input image at different stages in the CNN pipeline, and outputs a 2D matrix of scores for each map. Standard CNN architectures are modified through the incorporation of this module, and trained under the constraint that a convex combination of the intermediate 2D feature vectors, as parameterised by the score matrices, must alone be used for classification. Incentivised to amplify the relevant and suppress the irrelevant or misleading, the scores thus assume the role of attention values. Our experimental observations provide clear evidence to this effect: the learned attention maps neatly highlight the regions of interest while suppressing background clutter. Consequently, the proposed function is able to bootstrap standard CNN architectures for the task of image classification, demonstrating superior generalisation over 6 unseen benchmark datasets. When binarised, our attention maps outperform other CNN-based attention maps, traditional saliency maps, and top object proposals for weakly supervised segmentation as demonstrated on the Object Discovery dataset. We also demonstrate improved robustness against the fast gradient sign method of adversarial attack. © Learning Representations, ICLR 2018 - Conference Track Proceedings.All right reserved.",,"Classification (of information); Image segmentation; Network architecture; Neural networks; Background clutter; Benchmark datasets; Convex combinations; Convolutional neural network; Different stages; Intermediate representations; Regions of interest; Supervised segmentation; Image classification",,,,,"Arbeláez, P., Pont-Tuset, J., Barron, J.T., Marques, F., Malik, J., Multiscale combinatorial grouping (2014) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 328-335; Bahdanau, D., Cho, K., Bengio, Y., (2014) Neural Machine Translation by Jointly Learning to Align and Translate, , arXiv preprint; Cao, C., Liu, X., Yang, Y., Yu, Y., Wang, J., Wang, Z., Huang, Y., Huang, T.S., Look and think twice: Capturing top-down visual attention with feedback convolutional neural networks (2015) ICCV; Chen, X., Shrivastava, A., Gupta, A., Enriching visual knowledge bases via object discovery and segmentation (2014) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2027-2034; Coates, A., Lee, H., Ng, A.Y., (2010) An Analysis of Single-Layer Networks in Unsupervised Feature Learning, p. 2. , http://cs.stanford.edu/acoates/stl10, Ann Arbor; Jain, S.D., Grauman, K., Active image segmentation propagation (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2864-2873; Fei-Fei, L., Fergus, R., Perona, P., One-shot learning of object categories (2006) IEEE Transactions on Pattern Analysis and Machine Intelligence, 28 (4), pp. 594-611; Gao, J., Wang, B., Qi, Y., DeepMask: Masking DNN models for robustness against adversarial samples (2017) CoRR, , abs/1702.06763; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2014) CoRR, , http://arxiv.org/abs/1412.6572, abs/1412.6572; Griffin, G., Holub, A., Perona, P., (2007) Caltech-256 Object Category Dataset; He, K., Zhang, X., Ren, S., Sun, J., (2015) Deep Residual Learning for Image Recognition, , arXiv preprint; Hong, S., Oh, J., Lee, H., Han, B., Learning transferrable knowledge for semantic segmentation with deep convolutional neural network (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3204-3212; Jaderberg, M., Simonyan, K., Zisserman, A., Spatial transformer networks (2015) Advances in Neural Information Processing Systems, pp. 2017-2025; Jiang, B., Zhang, L., Lu, H., Yang, C., Yang, M.-H., Saliency detection via absorbing markov chain (2013) Proceedings of the IEEE International Conference on Computer Vision, pp. 1665-1672; Joulin, A., Bach, F., Ponce, J., Discriminative clustering for image co-segmentation (2010) Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, pp. 1943-1950. , IEEE; Joulin, A., Bach, F., Ponce, J., Multi-class cosegmentation (2012) Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, pp. 542-549. , IEEE; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images; Li, L.-J., Fei-Fei, L., What, where and who? Classifying events by scene and object recognition (2007) Computer Vision, 2007. ICCV 2007. IEEE 11th International Conference on, pp. 1-8. , IEEE; Mnih, V., Heess, N., Graves, A., Recurrent models of visual attention (2014) Advances in Neural Information Processing Systems, pp. 2204-2212; Mun, J., Cho, M., Han, B., Text-guided attention model for image captioning (2016) CoRR, , abs/1612.03557; Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., Ng, A.Y., Reading digits in natural images with unsupervised feature learning (2011) NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011; Quattoni, A., Torralba, A., Recognizing indoor scenes (2009) Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pp. 413-420. , IEEE; Redmon, J., Divvala, S., Girshick, R., Farhadi, A., (2015) You Only Look Once: Unified, Real-Time Object Detection, , arXiv preprint; Rubinstein, M., Joulin, A., Kopf, J., Liu, C., Unsupervised joint object discovery and segmentation in internet images (2013) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1939-1946; Seo, P.H., Lin, Z., Cohen, S., Shen, X., Han, B., Hierarchical attention networks (2016) CoRR, , abs/1606.02393; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-Scale Image Recognition, , arXiv preprint; Simonyan, K., Vedaldi, A., Zisserman, A., (2013) Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps, , arXiv preprint; Wah, C., Branson, S., Welinder, P., Perona, P., Belongie, S., (2011) The Caltech-UCSD Birds-200-2011 Dataset, , Technical report, California Institute of Technology; Wang, B., Gao, J., Qi, Y., (2016) A Theoretical Framework for Robustness of (Deep) Classifiers under Adversarial Noise, , arXiv preprint; Xu, H., Saenko, K., (2016) Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering, , Springer International Publishing; Xu, K., Ba, J., Kiros, R., Cho, K., Courville, A., Salakhutdinov, R., Zemel, R., Bengio, Y., Show, attend and tell: Neural image caption generation with visual attention (2015) International Conference on Machine Learning (ICML), 2 (3), p. 5; Yang, Z., He, X., Gao, J., Deng, L., Smola, A., (2016) Stacked Attention Networks for Image Question Answering, , 06; Yao, B., Jiang, X., Khosla, A., Lin, A.L., Guibas, L., Fei-Fei, L., Human action recognition by learning bases of action attributes and parts (2011) Computer Vision (ICCV), 2011 IEEE International Conference on, pp. 1331-1338. , IEEE; You, Q., Jin, H., Wang, Z., Fang, C., Luo, J., Image captioning with semantic attention (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4651-4659; Zagoruyko, S., Komodakis, N., Paying more attention to attention: Improving the performance of convolutional neural networks via attention transfer (2016) CoRR, , abs/1612.03928; Zhang, J., Sclaroff, S., Saliency detection: A boolean map approach (2013) Proceedings of the IEEE International Conference on Computer Vision, pp. 153-160; Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., Torralba, A., Learning deep features for discriminative localization (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2921-2929",,,,"International Conference on Learning Representations, ICLR","6th International Conference on Learning Representations, ICLR 2018","30 April 2018 through 3 May 2018",,149806,,,,,"English","Int. Conf. Learn. Represent., ICLR - Conf. Track Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85083950708
"Lu P.-H., Chen P.-Y., Yu C.-M.","57200512365;36930105800;14322694600;","On the limitation of local intrinsic dimensionality for characterizing the subspaces of adversarial examples",2018,"6th International Conference on Learning Representations, ICLR 2018 - Workshop Track Proceedings",,,,"","",,7,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083950196&partnerID=40&md5=a14473bcb9ec28acc1ed744ef13e724d","National Chung Hsing University, Taichung, Taiwan; IBM Research NY, United States","Lu, P.-H., National Chung Hsing University, Taichung, Taiwan; Chen, P.-Y., IBM Research NY, United States; Yu, C.-M., National Chung Hsing University, Taichung, Taiwan","Understanding and characterizing the subspaces of adversarial examples aid in studying the robustness of deep neural networks (DNNs) to adversarial perturbations. Very recently, Ma et al. (2018) proposed to use local intrinsic dimensionality (LID) in layer-wise hidden representations of DNNs to study adversarial subspaces. It was demonstrated that LID can be used to characterize the adversarial subspaces associated with different attack methods, e.g., the Carlini and Wagner’s (C&W) attack and the fast gradient sign attack. In this paper, we use MNIST and CIFAR-10 to conduct two new sets of experiments that are absent in existing LID analysis and report the limitation of LID in characterizing the corresponding adversarial subspaces, which are (i) oblivious attacks and LID analysis using adversarial examples with different confidence levels; and (ii) black-box transfer attacks. For (i), we find that the performance of LID is very sensitive to the confidence parameter deployed by an attack, and the LID learned from ensembles of adversarial examples with varying confidence levels surprisingly gives poor performance. For (ii), we find that when adversarial examples are crafted from another DNN model, LID is ineffective in characterizing their adversarial subspaces. These two findings together suggest the limited capability of LID in characterizing the subspaces of adversarial examples. © 6th International Conference on Learning Representations, ICLR 2018 - Workshop Track Proceedings. All rights reserved.",,"Black boxes; Confidence levels; Different attacks; Intrinsic dimensionalities; Layer-wise; Poor performance; Deep neural networks",,,,,"Athalye, A., Carlini, N., Wagner, D., (2018) Obfuscated Gradients Give A False Sense of Security: Circumventing Defenses to Adversarial Examples; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy (S&P), pp. 39-57; Chen, P.-Y., Sharma, Y., Zhang, H., Yi, J., Hsieh, C.-J., (2017) Ead: Elastic-Net Attacks to Deep Neural Networks Via Adversarial Examples; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR’15; Houle, M.E., Kashima, H., Nett, M., Generalized expansion dimension (2012) IEEE International Conference onData Mining Workshops (ICDMW), pp. 587-594; Karger, D.R., Ruhl, M., Finding nearest neighbors in growth-restricted metrics (2002) ACM Symposium on Theory of Computing, pp. 741-750; Liu, Y., Chen, X., Liu, C., Song, D., (2016) Delving into Transferable Adversarial Examples and Black-Box Attacks; Ma, X., Li, B., Wang, Y., Erfani, S.M., Wijewickrema, S., Houle, M.E., Schoenebeck, G., Bailey, J., (2018) Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality; Meng, D., Chen, H., Magnet: A two-pronged defense against adversarial examples (2017) ACM CCS; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-Box Attacks Using Adversarial Samples; Sharma, Y., Chen, P.-Y., (2017) Attacking the Madry Defense Model with L1-Based Adversarial Examples; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks",,,,"International Conference on Learning Representations, ICLR","6th International Conference on Learning Representations, ICLR 2018","30 April 2018 through 3 May 2018",,149807,,,,,"English","Int. Conf. Learn. Represent., ICLR - Workshop Track Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85083950196
"Xiao C., Zhu J.-Y., Li B., He W., Liu M., Song D.","56379538100;56316642900;57188689924;57207135651;9733562100;7402443870;","Spatially transformed adversarial examples",2018,"6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings",,,,"","",,74,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083950011&partnerID=40&md5=47233aaea208a0f537bf4805515281ee","University of Michigan, Ann Arbor, United States; Massachusetts Institute of TechnologyMA, United States; University of California, Berkeley, United States","Xiao, C., University of Michigan, Ann Arbor, United States; Zhu, J.-Y., Massachusetts Institute of TechnologyMA, United States; Li, B., University of California, Berkeley, United States; He, W., University of California, Berkeley, United States; Liu, M., University of Michigan, Ann Arbor, United States; Song, D., University of California, Berkeley, United States","Recent studies show that widely used deep neural networks (DNNs) are vulnerable to carefully crafted adversarial examples. Many advanced algorithms have been proposed to generate adversarial examples by leveraging the Lp distance for penalizing perturbations. Researchers have explored different defense methods to defend against such adversarial attacks. While the effectiveness of Lp distance as a metric of perceptual quality remains an active research area, in this paper we will instead focus on a different type of perturbation, namely spatial transformation, as opposed to manipulating the pixel values directly as in prior works. Perturbations generated through spatial transformation could result in large Lp distance measures, but our extensive experiments show that such spatially transformed adversarial examples are perceptually realistic and more difficult to defend against with existing defense systems. This potentially provides a new direction in adversarial example generation and the design of corresponding defenses. We visualize the spatial transformation based perturbation for different examples and show that our technique can produce realistic adversarial examples with smooth image deformation. Finally, we visualize the attention of deep networks with different types of adversarial examples to better understand how these examples are interpreted. © Learning Representations, ICLR 2018 - Conference Track Proceedings.All right reserved.",,"Network security; Defense system; Distance measure; Image deformation; Perceptual quality; Pixel values; Spatial transformation; Deep neural networks",,,,,"Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndić, N., Laskov, P., Giacinto, G.-G., Roli, F., Evasion attacks against machine learning at test time (2013) Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 387-402. , Springer; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy, 2017; Carlini, N., Wagner, D., (2017) Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods, , arXiv preprint; Collobert, R., Weston, J., A unified architecture for natural language processing: Deep neural networks with multitask learning (2008) Proceedings of the 25th International Conference on Machine Learning, pp. 160-167; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., ImageNet: A large-scale hierarchical image database (2009) CVPR, pp. 248-255; Evtimov, I., Eykholt, K., Fernandes, E., Kohno, T., Li, B., Prakash, A., Rahmati, A., Song, D., (2017) Robust Physical-World Attacks on Machine Learning Models, , arXiv preprint; Fawzi, A., Frossard, P., (2015) Manitest: Are Classifiers Really Invariant?, , arXiv preprint; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations; Grosse, K., Papernot, N., Manoharan, P., Backes, M., McDaniel, P., (2016) Adversarial Perturbations against Deep Neural Networks for Malware Classification, , arXiv preprint; Gu, S., Rigazio, L., (2014) Towards Deep Neural Network Architectures Robust to Adversarial Examples, , arXiv preprint; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; He, W., Wei, J., Chen, X., Carlini, N., Song, D., (2017) Adversarial Example Defenses: Ensembles of Weak Defenses Are Not Strong, , arXiv preprint; Hinton, G., Deng, L., Yu, D., Dahl, G.E., Mohamed, A.-R., Jaitly, N., Senior, A., Sainath, T.N., Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups (2012) IEEE Signal Processing Magazine, 29 (6), pp. 82-97; Hinton, G.E., Krizhevsky, A., Wang, S.D., Transforming auto-encoders (2011) International Conference on Artificial Neural Networks, pp. 44-51. , Springer; Isola, P., Zhu, J.-Y., Zhou, T., Efros, A.A., Image-to-image translation with conditional adversarial networks (2017) CVPR; Jaderberg, M., Simonyan, K., Zisserman, A., Spatial transformer networks (2015) NIPS, pp. 2017-2025; Johnson, J., Alahi, A., Fei-Fei, L., Perceptual losses for real-time style transfer and super-resolution (2016) European Conference on Computer Vision; Kanbak, C., (2017) Measuring Robustness of Classifiers to Geometric Transformations, , Technical report; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Krizhevsky, A., Nair, V., Hinton, G., (2014) The Cifar-10 Dataset, , http://www.cs.toronto.edu/kriz/cifar.html, online; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint; LeCun, Y., Cortes, C., (1998) The MNIST Database of Handwritten Digits; Li, X., Li, F., (2016) Adversarial Examples Detection in Deep Networks with Convolutional Filter Statistics, , arXiv preprint; Liu, D.C., Nocedal, J., On the limited memory bfgs method for large scale optimization (1989) Mathematical Programming, 45 (1), pp. 503-528; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) ICLR; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., (2015) Deepfool: A Simple and Accurate Method to Fool Deep Neural Networks, , arXiv preprint; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., (2016) Universal Adversarial Perturbations, , arXiv preprint; Mopuri, K.R., Garg, U., Venkatesh Babu, R., (2017) Fast Feature Fool: A Data Independent Approach to Universal Adversarial Perturbations, , arXiv preprint; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , cs, stat, June; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-Box Attacks Using Adversarial Samples, , arXiv preprint; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2016) 2016 IEEE European Symposium on Security and Privacy (EuroS&P), pp. 372-387; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Security and Privacy (SP), 2016 IEEE Symposium on, pp. 582-597; Rudin, L.I., Osher, S., Fatemi, E., Nonlinear total variation based noise removal algorithms (1992) Physica D: Nonlinear Phenomena, 60 (1-4), pp. 259-268; Shannon, C.E., Communication theory of secrecy systems (1949) Bell Labs Technical Journal, 28 (4), pp. 656-715; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826; Szeliski, R., (2010) Computer Vision: Algorithms and Applications, , Springer Science & Business Media; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses, , arXiv preprint; Viterbi, A.J., An intuitive justification and a simplified implementation of the map decoder for convolutional codes (1998) IEEE Journal on Selected Areas in Communications, 16 (2), pp. 260-264; Xu, W., Evans, D., Qi, Y., (2017) Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks, , arXiv preprint; Zagoruyko, S., Komodakis, N., (2016) Wide Residual Networks, , arXiv preprint; Zhang, R., Isola, P., Efros, A.A., Colorful image colorization (2016) European Conference on Computer Vision, pp. 649-666. , Springer; Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., Torralba, A., Learning deep features for discriminative localization (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2921-2929; Zhou, T., Tulsiani, S., Sun, W., Malik, J., Efros, A.A., View synthesis by appearance flow (2016) ECCV, pp. 286-301. , Springer",,,,"International Conference on Learning Representations, ICLR","6th International Conference on Learning Representations, ICLR 2018","30 April 2018 through 3 May 2018",,149806,,,,,"English","Int. Conf. Learn. Represent., ICLR - Conf. Track Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85083950011
"Anitha Kumari K., Sudha Sadasivam G.","49361105600;6602243161;","An efficient 3D Diffie-Hellman based Two-Server password-only authenticated key exchange",2018,"Journal of Applied Research and Technology","16","1",,"9","21",,2,"10.22201/ICAT.16656423.0.16.1.698","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081580445&doi=10.22201%2fICAT.16656423.0.16.1.698&partnerID=40&md5=2f5683be40fd697f8f8a7fd2f6e76ccc","Department of IT, PSG College of Technology, India; Department of CSE PSC College of Technology, India","Anitha Kumari, K., Department of IT, PSG College of Technology, India; Sudha Sadasivam, G., Department of CSE PSC College of Technology, India","In emerging technological world, security potentially remains as a highest challenge in the large-scale distributed systems, as it is suffering extensively with adversarial attacks due to insufficient mutual authentication. In order to address this, a state-of-art tetrahedron (3D) based two-server Password Authenticated and Key Exchange (PAKE) protocol has been formulated with formal proof of security by incorporating the elementary properties of plane geometry. The main intention of this work is, obtaining a password from the stored credentials must be infeasible when both the servers compromised together. At the outset to realize these goals, in this paper, the properties of the tetrahedron are utilized along with Diffie-Hellman (DH) key exchange algorithm to withstand against malicious attacks. A significant aspect of the proposed 3D PAKE protocol is, client side complexity has been reduced to a greater extent in terms of computation and communication. Both theoretically and practically, 3D PAKE protocol is the first demonstrable secure two-server PAKE protocol that breaks the assumptions of the Yang et al. and Yi et al. protocol that the two servers must not compromise together. Computational complexity, communication complexity, security key principles, best of all attacks happening dubiously are considered as the evaluation parameters to compare the performance of the proposed 3D PAKE protocol. © 2018 Universidad Nacional Autonoma de Mexico. All rights reserved.","3D PAKE protocol; Diffie-Hellman key exchange; Tetrahedron property analysis",,,,,,"Abdalla, M., Chevassut, O., Fouque, P.A., Pointcheval, D., A simple threshold authenticated key exchange from short secrets (2005) Lecture Notes in Computer Science., 3788, pp. 566-584; Bellare, M., Rogaway, P., Random oracles are practical: A paradigm for designing efficient protocols (1993) 1st ACM Conference on Computer and Communications Security, pp. 62-73; Bellovin, S.M., Merritt, M., Limitations of the Kerberos authentication system (1990) ACM SIGCOMM Computer Communication Review, 20 (5), pp. 119-132; Bellovin, S.M., Merritt, M., Encrypted key exchange: Password-based protocols secure against dictionary attacks (1992) IEEE Proceedings of the Symposium on Security and Privacy, pp. 72-84. , IEEE; Boneh, D., The decision diffie-hellman problem (1998) Lecture Notes in Computer Science, 1423, pp. 48-63; Byun, J.W., Lee, D.H., Lim, J.I., Security analysis and improvement of a gateway-oriented password-based authenticated key exchange protocol (2006) IEEE Communications Letters, 10 (9), pp. 683-685; Chien, H.Y., Wu, T.C., Yeh, M.K., Provably secure gateway-oriented password-based authenticated key exchange protocol resistant to password guessing attacks (2013) Journal of Information Science and Engineering, 29 (2), pp. 249-265; Choate, J., (1976) Tetrahedral Treats, , http://www.zebragrapli.com/Geometers_Corner_files/tetrahedraltreats.pdf; Chouksey, A., Yogadhar, P., An efficient password based two-server authentication and pre-shared key exchange system using smart cards (2013) International Journal of Computer Science and Information Technologies, 4 (1), pp. 117-120; Dennis, F., (2012) Final Report on Diginotar Hack Shows Total Compromise of CA Servers, , https://threatpost.com/final-report-diginotar-hack-shows-total-compromise-ca-servers-103112/77170/; Jack, D., (2008) Construction of A Triangle from Circumcenter., , https://www.cut-the-knot.org/triangle/0-H-I.shtml, (2008) Orthocenter and Incenter; Jin, H., Wong, D.S., Xu, Y., An efficient password-only two-server authenticated key exchange system (2007) Lecture Notes in Computer Science, pp. 44-56; Katz, J., MacKenzie, P., Taban, G., Gligor, V., Two-server password-only authenticated key exchange (2005) Lecture Notes in Computer Science, 3531, pp. 1-16; Kumari, K.A., Sadasivam, G.S., Akash, S.A., A secure android application with integration of wearables for healthcare monitoring system using 3D ECCDH PAKE protocol (2016) Journal of Medical Imaging and Health Informatics, 6 (6), pp. 1548-1551; Kumari, K.A., Sadasivam, G.S., Rohini, L., An efficient 3d elliptic curve diffie-hellman (ECDH) based two-server password-only authenticated key exchange protocol with provable security (2016) IETE Journal Oj Research, 62 (6), pp. 762-773; Lee, J.H., Lee, D.H., Secure and efficient password-based authenticated key exchange protocol for two-server architecture (2007) International Conference on Convergence Information Technology, pp. 2102-2107. , IEEE; Lin, C.L., Sun, H.M., Hwang, T., Three-party encrypted key exchange: Attacks and a solution (2000) ACM SIGOPS Operating Systems Review, 34 (A), pp. 12-20; MacKenzie, P., Shrimpton, T., Jakobsson, M., Threshold password-authenticated key exchange (2002) Lecture Notes in Computer Science, 2442, pp. 385-400; Pooja, D., Shilpi, C., Sujata, S., Vinita, G., Secured authentication: 3d password (2012) International Journal Oj Engineering and Management Sciences, 3 (2), pp. 242-245; Rajan, S., Review and investigations on future research directions of mobile based telecare system for cardiac surveillance (2015) Journal of Applied Research and Technology, 13 (4), pp. 454-460; Sood, S.K., Dynamic identity based authentication protocol for two-server architecture (2012) Journal Oj Information Security, 3, p. 326; Wan, Z., Deng, R.H., Bao, F., Preneel, B., NPAKE+: A hierarchical group password-authenticated key exchange protocol using different passwords (2007) Lecture Notes in Computer Science, 4861, pp. 31-43; Yang, Y., Deng, R.H., Bao, F., A practical password-based two-server authentication and key exchange system (2006) IEEE Transactions on Dependable and Secure Computing, 3 (2), pp. 105-114; Yi, X., Ling, S., Wang, H., Efficient two-server password-only authenticated key exchange (2013) IEEE Transactions on Parallel and Distributed Systems, 24 (9), pp. 1773-1782","Anitha Kumari, K.; Department of IT, India; email: anitha.psgsoft@gmail.com",,,"Universidad Nacional Autonoma de Mexico",,,,,16656423,,,,"English","J. Appl. Res. Technol.",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85081580445
"Jia J., Gong N.Z.","57196063178;37101758300;","AttriGuard: A practical defense against attribute inference attacks via adversarial machine learning",2018,"Proceedings of the 27th USENIX Security Symposium",,,,"513","529",,31,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075932097&partnerID=40&md5=996d8722528fc16c776fca9a7748cddd","ECE Department, Iowa State University, United States","Jia, J., ECE Department, Iowa State University, United States; Gong, N.Z., ECE Department, Iowa State University, United States","Users in various web and mobile applications are vulnerable to attribute inference attacks, in which an attacker leverages a machine learning classifier to infer a target user's private attributes (e.g., location, sexual orientation, political view) from its public data (e.g., rating scores, page likes). Existing defenses leverage game theory or heuristics based on correlations between the public data and attributes. These defenses are not practical. Specifically, game-theoretic defenses require solving intractable optimization problems, while correlation-based defenses incur large utility loss of users' public data. In this paper, we present AttriGuard, a practical defense against attribute inference attacks. AttriGuard is computationally tractable and has small utility loss. Our AttriGuard works in two phases. Suppose we aim to protect a user's private attribute. In Phase I, for each value of the attribute, we find a minimum noise such that if we add the noise to the user's public data, then the attacker's classifier is very likely to infer the attribute value for the user. We find the minimum noise via adapting existing evasion attacks in adversarial machine learning. In Phase II, we sample one attribute value according to a certain probability distribution and add the corresponding noise found in Phase I to the user's public data. We formulate finding the probability distribution as solving a constrained convex optimization problem. We extensively evaluate AttriGuard and compare it with existing methods using a real-world dataset. Our results show that AttriGuard substantially outperforms existing methods. Our work is the first one that shows evasion attacks can be used as defensive techniques for privacy protection. © 2018 Proceedings of the 27th USENIX Security Symposium. All rights reserved.",,"Constrained optimization; Convex optimization; Game theory; Network security; Probability distributions; Attribute values; Constrained convex optimizations; Inference attacks; Mobile applications; Optimization problems; Political views; Privacy protection; Sexual orientations; Machine learning",,,,,"Zheleva, E., Getoor, L., To join or not to join: The illusion of privacy in social networks with mixed public and private user profiles (2009) WWW; Chaabane, A., Acs, G., Kaafar, M.A., You are what you like! information leakage through users' interests (2012) NDSS; Kosinski, M., Stillwell, D., Graepel, T., Private traits and attributes are predictable from digital records of human behavior (2013) PNAS; Gong, N.Z., Talwalkar, A., Mackey, L., Huang, L., Shin, E.C.R., Stefanov, E., Shi, E., Song, D., Joint link prediction and attribute inference using a social-attribute network (2014) ACM TIST, 5 (2). , Runting; Gong, N.Z., Liu, B., You are who you know and how you behave: Attribute inference attacks via users' social friends and behaviors (2016) USENIX Security Symposium; Jia, J., Wang, B., Zhang, L., Gong, N.Z., AttriInfer: Inferring user attributes in online social networks using Markov random fields (2017) WWW; Gong, N.Z., Liu, B., Attribute inference attacks in online social networks (2018) ACM TOPS, 21 (1); Otterbacher, J., Inferring gender of movie reviewers: Exploiting writing style, content and metadata (2010) CIKM; Weinsberg, U., Bhagat, S., Ioannidis, S., Taft, N., Blurme: Inferring and obfuscating user gender based on ratings (2012) RecSys; Michalevsky, Y., Nakibly, G., Schulman, A., Boneh, D., Powerspy: Location tracking using mobile device power analysis (2015) USENIX Security Symposium; Narain, S., Vo-Huu, T.D., Block, K., Noubir, G., Inferring user routes and locations using zero-permission mobile sensors (2016) IEEE S & P; (2018) Cambridge Analytica, , https://goo.gl/PqRjjX, May; Shokri, R., Theodorakopoulos, G., Troncoso, C., Protecting location privacy: Optimal strategy against localization attacks (2012) ACM CCS; Shokri, R., Privacy games: Optimal user-centric data obfuscation (2015) PETS; Shokri, R., Theodorakopoulos, G., Troncoso, C., Privacy games along location traces: A game-theoretic framework for optimizing location privacy (2016) ACM TOPS, 19 (4); Du Pin Calmon, N.F.F., Privacy against statistical inference (2012) Allerton; Heatherly, R., Kantarcioglu, M., Thuraisingham, B., Preventing private information inference attacks on social networks (2013) IEEE TKDE; Chen, T., Boreli, R., Kaafar, M.-A., Friedman, A., On the effectiveness of obfuscation techniques in online social networks (2014) PETS; Salamatian, S., Zhang, A., Du Pin Calmon, F., Bhamidipati, S., Fawaz, N., Kveton, B., Oliveira, P., Taft, N., Managing your private and public data: Bringing down inference attacks against your privacy (2015) IEEE Journal of Selected Topics in Signal Processing; Barreno, M., Nelson, B., Sears, R., Joseph, A.D., Doug Tygar, J., Can machine learning be secure? (2006) ACM ASIACCS; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Laskov, N.S.P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) ECML-PKDD; Goodfellow, J.S.I.J., Szegedy, C., Explaining and harnessing adversarial examples (2014) ICLR; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2016) EuroS&P; Sharif, M., Bhagavatula, S., Bauer, L., Michael Reiter, K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) ACM CCS; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE S & P; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) AsiaCCS; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) ICLR; (2004) Convex Optimization, , Cambridge University Press; Fredrikson, M., Lantz, E., Jha, S., Lin, S., Page, D., Ristenpart, T., Privacy in pharmacogenetics: An end-to-end case study of personalized warfarin dosing (2014) USENIX Security Symposium; Fredrikson, M., Jha, S., Ristenpart, T., Model inversion attacks that exploit confidence information and basic countermeasures (2015) ACM CCS; Lerman, L., Bontempi, G., Markowitch, O., Side channel attack: An approach based on machine learning (2011) COSADE; Zhang, Y., Juels, A., Reiter, M.K., Ristenpart, T., Cross-vm side channels and their use to extract private keys (2012) CCS; Warner, S., Randomized response: A survey technique for eliminating evasive answer bias (1965) Journal of the American Statistical Association, 60 (309); Duchi, J.C., Jordan, M.I., Wainwright, M.J., Local privacy and statistical minimax rates (2013) FOCS; Erlingsson, A.K.U., Pihur, V., Rappor: Randomized aggregatable privacy-preserving ordinal response (2014) ACM CCS; Bassily, R., Smith, A.D., Local, private, efficient protocols for succinct histograms (2015) STOC; Qin, Z., Yang, Y., Yu, T., Khalil, I., Xiao, X., Ren, K., Heavy hitter estimation over set-valued data with local differential privacy (2016) ACM CCS; Smith, A., Thakurta, A., Upadhyay, J., Is interaction necessary for distributed private learning? (2017) IEEE S & P; Avent, B., Korolova, A., Zeber, D., Hovden, T., Livshits, B., Blender: Enabling local search with a hybrid differential privacy model (2017) USENIX Security Symposium; Wang, T., Blocki, J., Li, N., Jha, S., Locally differentially private protocols for frequency estimation (2017) USENIX Security Symposium; Dwork, C., McSherry, F., Nissim, K., Smith, A., Calibrating noise to sensitivity in private data analysis (2006) TCC; Gong, N.Z., Xu, W., Huang, L., Mittal, P., Stefanov, E., Sekar, V., Song, D., Evolution of social-attribute networks: Measurements, modeling, and implications using google+ (2012) IMC; Nair, V., Hinton, G.E., Rectified linear units improve restricted boltzmann machines (2010) ICML; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) IEEE S & P; Cao, X., Gong, N.Z., Mitigating evasion attacks to deep neural networks via region-based classification (2017) ACSAC; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2017) ICLR; Metzen, J.H., Genewein, T., Fischer, V., Bischof, B., On detecting adversarial perturbations (2017) ICLR; Xu, W., Evans, D., Qi, Y., Feature squeezing: Detecting adversarial examples in deep neural networks (2018) NDSS; Meng, D., Chen, H., Magnet: A two-pronged defense against adversarial examples (2017) CCS; Ma, X., Li, B., Wang, Y., Erfani, S.M., Wijewickrema, S., Houle, M.E., Schoenebeck, G., Bailey, J., Characterizing adversarial subspaces using local intrinsic dimensionality (2018) ICLR; He, W., Li, B., Song, D., Decision boundary analysis of adversarial examples (2018) ICLR",,,"Baidu;Dropbox;Facebook;Google;NSF;The USENIX Association","USENIX Association","27th USENIX Security Symposium","15 August 2018 through 17 August 2018",,155142,,9781939133045,,,"English","Proc. USENIX Secur. Symp.",Conference Paper,"Final","",Scopus,2-s2.0-85075932097
"Chen I.-T., Sirkeci-Mergen B.","57211180591;55663933300;","A comparative study of autoencoders against adversarial attacks",2018,"Proceedings of the 2018 International Conference on Image Processing, Computer Vision, and Pattern Recognition, IPCV 2018",,,,"132","136",,7,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072893321&partnerID=40&md5=54e0fe3f7ee4a92d7139b2e3ecbd5e2f","Electrical Engineering, San Jose State University, San Jose, CA  95192, United States","Chen, I.-T., Electrical Engineering, San Jose State University, San Jose, CA  95192, United States; Sirkeci-Mergen, B., Electrical Engineering, San Jose State University, San Jose, CA  95192, United States","Many machine learning models can be fooled by adversarial examples. The adversarial examples are the subtly perturbed inputs crafted to fool the machine learning models. While the models correctly classify the original inputs, the perturbed adversarial inputs are misclassified to other classes. The perturbations added to the original inputs are usually not easily perceived by human eyes. Therefore the malicious attacks with the adversarial examples are serious security risks because the attacks can remain stealth. This paper compares various denoising autoencoders applied to inputs before the classifiers to filter the fast gradient sign method (FGSM) adversarial perturbations in the inputs. Both the capacity of removing the attacks and performance change on the original un-attacked inputs are analyzed. © 2018 International Conference on Image Processing, Computer Vision, and Pattern Recognition, IPCV 2018.All right reserved.","Adversarial examples; Autoencoders; Machine learning models; Security","Machine learning; Network security; Adversarial examples; Autoencoders; Comparative studies; De-noising; Machine learning models; Malicious attack; Security; Security risks; Computer vision",,,,,"Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2323; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-Box Attacks Using Adversarial Samples; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR, , [stat.ML]; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2017) ICLR, , [cs.CV]; Evtimov, I., Eykholt, K., Fernandes, E., Kohno, T., Li, B., Prakash, A., Rahmati, A., Song, D., (2017) Robust Physical-World Attacks on Deep Learning Models; Hendrycks, D., Gimpel, K., Early methods for detecting adversarial images (2017) ICLR, , [cs.LG]; Bhagoji, A.N., Cullina, D., Sitawarin, C., Mittal, P., (2017) Enhancing Robustness of Machine Learning Systems Via Data Transformations; Gu, S., Rigazio, L., Towards deep neural network architectures robust to adversarial examples (2015) ICLR, , [cs.LG]; Vincent, P., Larochelle, H., Bengio, Y., Manzagol, P.-A., Extracting and composing robust features with denoising autoencoders (2008) ICML; Bengio, Y., Lamblin, P., Popovici, D., Larochelle, H., Greedy layer-wise training of deep networks (2007) NIPS; Papernot, N., Carlini, N., Goodfellow, I., Feinman, R., Faghri, F., Matyasko, A., Hambardzumyan, K., Lin, Y., (2017) Cleverhans V2.0.0: An Adversarial Machine Learning Library; Zeiler, M.D., Fergus, R., Visualizing and understanding convolutional networks (2014) Computer Vision - ECCV 2014 Lecture Notes in Computer Science, pp. 818-833",,"Arabnia H.R.Deligiannidis L.Tinetti F.G.",,"CSREA Press","2018 International Conference on Image Processing, Computer Vision, and Pattern Recognition, IPCV 2018","30 July 2018 through 2 August 2018",,150155,,1601324855; 9781601324856,,,"English","Proc. Int. Conf. Image Process., Comput. Vis., Pattern Recognit., IPCV",Conference Paper,"Final","",Scopus,2-s2.0-85072893321
"Montasari R., Hosseinian-Far A., Hill R.","56939033500;53979921000;7404753515;","Policies, innovative self-adaptive techniques and understanding psychology of cybersecurity to counter adversarial attacks in network and cyber environments",2018,"Advanced Sciences and Technologies for Security Applications",,,,"71","93",,6,"10.1007/978-3-319-97181-0_4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072861800&doi=10.1007%2f978-3-319-97181-0_4&partnerID=40&md5=3e7777d9f1c72c01f95284c088950021","School of Computing and Digital Technology, Birmingham City University, Birmingham, United Kingdom; Department of Business Systems & Operations, University of Northampton, Northampton, United Kingdom; Head of Department of Computer Science, University of Huddersfield, Huddersfield, United Kingdom","Montasari, R., School of Computing and Digital Technology, Birmingham City University, Birmingham, United Kingdom; Hosseinian-Far, A., Department of Business Systems & Operations, University of Northampton, Northampton, United Kingdom; Hill, R., Head of Department of Computer Science, University of Huddersfield, Huddersfield, United Kingdom","Despite the increasing evolution of the cyber environment, enterprises seem to find it challenging to identify a solution to create an effective defensive posture. As the cyber phenomenon becomes a fundamental part of our society, it is essential to identify adaptive methods to increase the worldwide defensive condition in the most effective manner possible. A decade ago, it was not possible to imagine today’s cyber-threat landscape. Cybercriminals have adapted their methods to circumvent traditional defences and hide undetected on systems for months or even years. There are different reasons for such attacks, and understanding the psychology of attacks are essential. Therefore, enterprise security also needs to be adapted with an intelligence, multi-layered approach to IT security. This paper surveys the latest research on the foundation of Adaptive Enterprise Security (AEC). To this end, it discusses potential security policies and strategies that are easy to develop, are established, and have a major effect on an enterprise’s security practices. These policies and strategies can then efficiently be applied to an enterprise’s cyber policies for the purposes of enhancing security and defence. Moreover, it will take into briefly discuss the need for a thorough understanding of human factors and psychology of attacks. The study also discusses various adaptive security measures that enterprises can adopt to continue with securing their network and cyber environments. To this end, the paper continues to survey and analyse the effectiveness of some of the latest adaptation techniques deployed to secure these network and cyber environments. © Springer Nature Switzerland AG 2018.",,,,,,,"Aagedal, J.O., Den Braber, F., Dimitrakos, T., Gran, B.A., Raptis, D., Stolen, K., Modelbased risk assessment to improve enterprise security (2002) The 6Th International Conference on Enterprise Distributed Object Computing, pp. 51-62. , (pp; Anderson, B., McGrew, D., (2017) OS Fingerprinting: New Techniques and a Study of Information Gain and Obfuscation. Cisco Systems, Inc. Arxiv Preprint Arxiv: 1706.08003; Apostolaki, M., Zohar, A., Vanbever, L., Hijacking bitcoin: Routing attacks on cryptocurrencies (2017) In IEEE Symposium on Security and Privacy (SP) (Pp, pp. 375-392; Bada, M., Creese, S., Goldsmith, M., Mitchell, C., Phillips, E., (2014) Computer Security Incident Response Teams (Csirts) an Overview. Global Cyber Security Capacity Centre, pp. 1-23. , (pp; Chen, B., Peng, X., Yu, Y., Nuseibeh, B., Zhao, W., Self-adaptation through incremental generative model transformations at runtime (2014) The 36Th International Conference on Software Engineering, pp. 676-687. , (pp; Cheswick, W.R., Bellovin, S.M., Rubin, A.D., (2003) Firewalls and Internet Security: Repelling the Wily Hacker, , 2nd ed.). London: Addison-Wesley Longman Publishing; Cybenko, G., Jajodia, S., Wellman, M.P., Liu, P., Adversarial and uncertain reasoning for adaptive cyber defense: Building the scientific foundation (2014) International Conference on Information Systems Security, pp. 1-8. , (pp., Cham: Springer; Debruhl, B., Tague, P., Keeping up with the jammers: Observe-and-adapt algorithms for studying mutually adaptive opponents (2014) Pervasive and Mobile Computing, 12, pp. 244-257; de Castro, L.N., Timmis, J., (2002) Artificial Immune Systems: A New Computational Intelligence Approach, , London: Springer Science & Business Media; Durumeric, Z., Ma, Z., Springall, D., Barnes, R., Sullivan, N., Bursztein, E., Bailey, M., Paxson, V., The security impact of HTTPS interception (2017) Symposium (NDSS’17) on Network and Distributed Systems, pp. 1-14. , (pp; Elkhodary, A., Whittle, J., A survey of approaches to adaptive application security (2007) International Workshop on Software Engineering for Adaptive and Self-Managing Systems, p. 16. , (p; Enisa, S.I., Ltd, L., (2009) Good Practice Guide Network Security Information Exchanges (Special Publication (ENISA) – Rev. 1); Formby, D., Srinivasan, P., Leonard, A., Rogers, J., Beyah, R.A., Who’s in control of your control system? (2016) Device Fingerprinting for Cyber-Physical Systems (NDSS). Internetsociety.Org; Geer, D., Bace, R., Gutmann, P., Metzger, P., Pfleeger, C., Querterman, J., Scheier, B., (2003) Cyberinsecurity: The Cost of Monopoly-How The Dominance of microsoft’s Products Poses a Risk to Security, , Washington, DC: Computer and Communications Industry Association; Godin, A., (2017) Using COIN Doctrine to Improve Cyber Security Policies, , https://www.sans.org/reading-room/whitepapers/policyissues/coin-doctrine-improvecyber-security-policies-37557; Greenwald, L.G., Thomas, T.J., Toward undetected operating system fingerprinting (2007) USENIX Workshop on Offensive Technologies (WOOT), pp. 1-10. , (pp; (2017) Minipwner Penetration Testing Toolbox, , http://hackerwarehouse.com/product/minipwner/.Accessed28thAug2017, Available at; Haley, C., Laney, R., Moffett, J., Nuseibeh, B., Security requirements engineering: A framework for representation and analysis (2008) IEEE Transactions on Software Engineering, 34 (1), pp. 133-153; Hosseinpournajarkolaei, A., Jahankhani, H., Hosseinian-Far, A., Vulnerability considerations for power line communication’s supervisory control and data acquisition (2014) International Journal of Electronic Security and Digital Forensics, 6 (2), pp. 104-114. , Inderscience; Husák, M., Cermák, M., Jirsík, T., Celeda, P., Network-based HTTPS client identification using SSL/TLS fingerprinting (2015) In 2015 10Th International Conference on Availability, Reliability and Security (ARES) (Pp, pp. 389-396; Jahankhani, H., Hosseinian-Far, A., (2017) Challenges of Cloud Forensics, pp. 1-18. , V. Chang et al. (Eds.), Enterprise security (pp., Cham: Springer; Jahankhani, H., Hosseinian-Far, A., Digital forensics education, training, and awareness (2014) Cyber Crime and Cyber Terrorism investigator’s Handbook, 1, pp. 91-100. , (Vol., pp., Waltham: Elsevier; Jahankhani, H., Al-Nemrat, A., Hosseinian-Far, A., Cyber crime classification and characteristics (2014) Cyber Crime and Cyber Terrorism investigator’s Handbook, 1, pp. 149-164. , (Vol., pp., Massachusetts: Elsevier; Jajodia, S., Ghosh, A.K., Swarup, V., Wang, C., Wang, X.S., (2011) Moving Target Defense: Creating Asymmetric Uncertainty for Cyber Threats, 54. , (Vol., New York: Springer Science & Business Media; Jajodia, S., Ghosh, A.K., Subrahmanian, V.S., Swarup, V., Wang, C., Wang, X.S., (2012) Moving Target Defense II: Application of Game Theory and Adversarial Modeling, 100. , (Vol., New York: Springer Science & Business Media; Janssen, M., Kuk, G., A complex adaptive system perspective of enterprise architecture in electronic government (2006) The 39Th Annual Hawaii International Conference on System Sciences, 4, pp. 71b-71b. , (Vol., pp; Jones, M.T., (2015) Artificial Intelligence: a Systems Approach. Massachusetts: Jones & Bartlett Learning, , Sudbury, MA; (2016) Kaspersky Security Solutions for Enterprise: Securing the Enterprise, , http://media.kaspersky.com/pdf/b2b/; Knowles, W., Prince, D., Hutchison, D., Disso, J.F.P., Jones, K., A survey of cyber security management in industrial control systems (2015) International Journal of Critical Infrastructure Protection, 9, pp. 52-80; Kohno, T., Broido, A., Claffy, K.C., Remote physical device fingerprinting (2005) IEEE Transactions on Dependable and Secure Computing, 2 (2), pp. 93-108; Lamsweerde, A.V., Elaborating security requirements by construction of intentional antimodels (2004) 26Th International Conference on Software Engineering, pp. 148-157. , (pp; Lei, C., Zhang, H.Q., Ma, D.H., Yang, Y.J., Network moving target defense technique based on self-adaptive end-point hopping (2017) Arabian Journal for Science and Engineering, 42, pp. 1-14; Lippmann, R., Fried, D., Piwowarski, K., Streilein, W., Passive operating system identification from TCP/IP packet headers (2003) IEEE Workshop on Data Mining for Computer Security, pp. 40-49. , (pp; Ludlow, P., What is a ‘Hacktivist (2013) Nytimes. Available, , https://opinionator.blogs.nytimes.com/2013/01/13/what-is-a-hacktivist/; Macdonald, N., Firstbrook, P., (2014) Designing an Adaptive Security Architecture for Protection from Advanced Attacks, , https://www.gartner.com/doc/2665515/designingadaptive-security-architecture-protection; Markmann, C., Darkow, I.L., von der Gracht, H., A Delphi-based risk analysis? Identifying and assessing future challenges for supply chain security in a multi-stakeholder environment (2013) Technological Forecasting and Social Change, 80 (9), pp. 1815-1833; McAlaney, J., Thackray, H., Taylor, A., The social psychology of cybersecurity (2016) The British Psychological Society, 29, pp. 686-689; Michie, S., van Stralen, M.M., West, R., The behaviour change wheel: A new method for characterising and designing behaviour change interventions (2011) Implementation Science, 6 (42), pp. 2-11. , ) (pp; Moffett, J., Nuseibeh, A., (2003) A Framework for Security Requirements Engineering, pp. 1-30. , Report University of York, Department of Computer Science YCS (pp; Mowery, K., Bogenreif, D., Yilek, S., Shacham, H., Fingerprinting information in javascript implementations (2011) Proceedings of W2SP, pp. 180-193. , (pp; Nagurney, A., Daniele, P., Shukla, S., A supply chain network game theory model of cybersecurity investments with nonlinear budget constraints (2017) Annals of Operations Research, 248 (1-2), pp. 405-427. , IGI Global; (2017) The National Cyber Security Centre: A Part of GCHQ., , https://www.ncsc.gov.uk/; Nhlabatsi, A., Nuseibeh, B., Yu, Y., Security requirements engineering for evolving software systems: A survey (2012) Security-Aware Systems Applications and Software Development Methods, pp. 108-128. , K. M. Khan (Ed.), (pp., Hershey: IGI Global; Security for industrial control systems – Improve awareness and skills: A good practice guide (PACG Special Publication). PA Consulting Group, 123 Buckingham Palace Road, London SW1W 9SR (2015) United Kingdom, , (a); Security for industrial control systems: Improve awareness and skills – A good practice guide (Special Publication (CPNI), Rev. 1). PA Consulting Group, 123 Buckingham Palace Road, London SW1W 9SR (2015) United Kingdom, , (b); Pasquale, L., Ghezzi, C., Menghi, C., Tsigkanos, C., Nuseibeh, B., Topology aware adaptive security (2014) The 9Th International Symposium on Software Engineering for Adaptive and Self-Managing Systems, pp. 43-48. , (pp; Peltier, T., Information security policies, procedures, and standards: Guidelines for effective information security management (2016) CRC Press, , Taylor and Francis Group: New York; Salehie, M., Pasquale, L., Omoronyia, I., Ali, R., Nuseibeh, B., Requirements-driven adaptive security: Protecting variable assets at runtime (2012) 20Th IEEE International Conference on Requirements Engineering, pp. 111-120. , (pp; Shu, G., Lee, D., Network protocol system fingerprinting – A formal approach (2006) 25Th IEEE International Conference on Computer Communications, pp. 1-12. , (pp; Spitzner, I., (2008) Know Your Enemy: Passive Fingerprinting. Available At, , https://www.honeynet.org/papers/finger, Accessed August 23, 2017; Stoneburner, G., Goguen, A., Feringa, A., (2002) Risk Management Guide for Information Technology Systems and Underlying Technical Models for Information Technology Security, , Pennsylvania: Diane Publishing Company; Stouffer, K., Pillitteri, V., Lightman, S., Abrams, M., Hahn, A., (2015) Guide to Industrial Control Systems (ICS) Security (Special Publication (NIST SP)-800-82 Rev 2), , Gaithersburg, MD; Sun, K., Jajodia, S., Protecting enterprise networks through attack surface expansion (2014) In ACM Workshop on Cyber Security Analytics, Intelligence and Automation, 2014, pp. 29-32; (2009) Good Practice Guide Network Security Information Exchanges, , ENISA; Tague, P., (2017) Inference-Based Adaptation Techniques for Next Generation Jamming and Anti-Jamming Capabilities, , https://www.cylab.cmu.edu/research/projects/2013/inference-based-adaptation-jamming.html; Tyagi, R., Paul, T., Manoj, B.S., Thanudas, B., Packet inspection for unauthorized OS detection in enterprises (2015) IEEE Security & Privacy, 13 (4), pp. 60-65; (2017) Information Sharing Specifications for Cybersecurity, , https://www.us-cert.gov/Information-Sharing-Specifications-Cybersecurity, Available at, Accessed August 24, 2017; (2016) How Vectra Enables the Implementation of an Adaptive Security Architecture, , https://info.vectranetworks.com/hubfs/how-vectra-enables-the-implementationof-an-adaptive-security-architecture.pdf?t=1487862985000, Available at, Accessed August 28, 2017; Virvilis, N., Gritzalis, D., The big four-what we did wrong in advanced persistent threat detection (2013) In 8Th International Conference on Availability, Reliability and Security (ARES) (Pp, pp. 248-254; Wang, L., Wu, D., Moving target defense against network reconnaissance with software defined networking (2016) International Conference on Information Security, pp. 203-217. , (pp; Wei, W., Suh, K., Wang, B., Gu, Y., Kurose, J., Towsley, D., Passive online rogue access point detection using sequential hypothesis testing with TCP ACK-pairs (2007) 7Th ACM SIGCOMM Conference on Internet Measurement, pp. 365-378. , (pp; Weise, J., (2008) Designing an Adaptive Security Architecture, pp. 1-18. , (pp., Sun Global Systems Engineering Security Office; Wilk, J., Mind, nature and emerging science of change: An introduction to metamorphology (1999) Metadebates on Science, 24, pp. 71-87. , G. C. Cornelis (Ed.), (Vol., pp., Dordrecht: Springer Netherlands; Wilkinson, M., Designing an ‘adaptive’ enterprise architecture (2006) BT Technology Journal, 24 (4), pp. 81-92; Xu, H., Chapin, S.J., Address-space layout randomization using code islands (2009) Journal of Computer Security, 17 (3), pp. 331-362; Zalewski, M., (2014) P0f – Passive OS Fingerprinting Tool, , http://lcamtuf.coredump.cx/p0f3, Available at, Accessed August 16, 2017","Montasari, R.; School of Computing and Digital Technology, United Kingdom; email: Reza.Montasari@bcu.ac.uk",,,"Springer",,,,,16135113,,,,"English","Adv. Sci. Tech. Sec. Appl.",Book Chapter,"Final","All Open Access, Green",Scopus,2-s2.0-85072861800
"Ülger O., Stol M., Mensink T.","57211111952;57211109671;24829859100;","Evaluating the effectiveness of adversarial patch attacks on convolutional neural networks",2018,"Belgian/Netherlands Artificial Intelligence Conference",,,,"281","282",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072664254&partnerID=40&md5=384272ba6a91928f580be40d8a60e163","University of Amsterdam, Amsterdam, Netherlands; BrainCreators, Amsterdam, Netherlands","Ülger, O., University of Amsterdam, Amsterdam, Netherlands; Stol, M., BrainCreators, Amsterdam, Netherlands; Mensink, T., University of Amsterdam, Amsterdam, Netherlands",[No abstract available],,,,,,,"Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , e-prints; Brown, T.B., Mané, D., Abadi, M., Gilmer, J., (2017) Adversarial Patch, , e-prints; Bendale, A., Boult, T.E., Towards open set deep networks (2016) CVPR","Ülger, O.; University of AmsterdamNetherlands; email: o.ulger@uva.nl","Atzmueller M.Duivesteijn W.","BNVKI;DIKW;SIKS;SNN Adaptive Intelligence;Stichting Knowledge-Based Systems (SKBS);Target Holding","University of Groningen","30th Benelux Conference on Artificial Intelligence, BNAIC 2018","8 November 2018 through 9 November 2018",,150826,15687805,,,,"English","Belgian/Netherlands Artif. Intell. Conf.",Conference Paper,"Final","",Scopus,2-s2.0-85072664254
"Cuan B., Damien A., Delaplace C., Valois M.","57189660430;57205653133;57191252573;57209607110;","Malware detection in PDF files using machine learning",2018,"ICETE 2018 - Proceedings of the 15th International Joint Conference on e-Business and Telecommunications","2",,,"412","419",,2,"10.5220/0006884704120419","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071429401&doi=10.5220%2f0006884704120419&partnerID=40&md5=560050f22025271fe6a14bcd61b6d683","INSA Lyon, CNRS, LIRIS, Lyon, France; Thales Group, Toulouse, France; CNRS, LAAS, Toulouse, France; Univ Rennes 1, CNRS, IRISA, Rennes, 35000, France; Univ. Lille, CRIStAL, Villeneuve d’Ascq, 59655, France; Normandie Univ., UNICAEN, ENSICAEN, CNRS, GREYC, Caen, 14000, France","Cuan, B., INSA Lyon, CNRS, LIRIS, Lyon, France; Damien, A., Thales Group, Toulouse, France, CNRS, LAAS, Toulouse, France; Delaplace, C., Univ Rennes 1, CNRS, IRISA, Rennes, 35000, France, Univ. Lille, CRIStAL, Villeneuve d’Ascq, 59655, France; Valois, M., Normandie Univ., UNICAEN, ENSICAEN, CNRS, GREYC, Caen, 14000, France","We present how we used machine learning techniques to detect malicious behaviours in PDF files. At this aim, we first set up a SVM (Support Machine Vector) classifier that was able to detect 99.7% of malware. However, this classifier was easy to lure with malicious PDF files, which we forged to make them look like clean ones. For instance, we implemented a gradient-descent attack to evade this SVM. This attack was almost 100% successful. Next, we provided counter-measures to this attack: a more elaborated features selection and the use of a threshold allowed us to stop up to 99.99% of this attack. Finally, using adversarial learning techniques, we were able to prevent gradient-descent attacks by iteratively feeding the SVM with malicious forged PDF files. We found that after 3 iterations, every gradient-descent forged PDF file were detected, completely preventing the attack. Copyright © 2018 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved","Adversarial Learning; Evasion Attacks; Feature Selections; Gradient-Descent; Malicious PDF Detection; SVM","Electronic commerce; Feature extraction; Gradient methods; Learning algorithms; Machine learning; Adversarial learning; Evasion Attacks; Features selection; Gradient descent; Machine learning techniques; Malicious pdf; Malware detection; PDF files; Malware",,,,,"Aizerman, M.A., Braverman, E.A., Rozonoer, L., Theoretical foundations of the potential function method in pattern recognition learning (1964) Automation and Remote Control; Ateniese, G., Felici, G., Mancini, L.V., Spognardi, A., Vil-Lani, A., Vitali, D., Hacking smart machines with smarter ones: How to extract meaningful data from machine learning classifiers (2013) CoRR; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndić, N., Laskov, P., Giacinto, G., Roli, F., (2013) Evasion Attacks against Machine Learning at Test Time; Borg, K., (2013) Real Time Detection and Analysis of Pdf-Files, , Master’s thesis; Boser, B.E., Guyon, I.M., Vapnik, V.N., A training algorithm for optimal margin classifiers (1992) COLT’92; (2013) Contagio: Malware Dump, , http://contagiodump.blogspot.fr/2013/03/16800-clean-and-11960-malicious-files.html; (2017) Adobe Vulnerabilities Statistics, , https://www.cvedetails.com/product/497/Adobe-Acrobat-Reader.html; Kittilsen, J., (2011) Detecting Malicious Pdf Documents, , Master’s thesis; Maiorca, D., Giacinto, G., Corona, I., (2012) A Pattern Recognition System for Malicious PDF Files Detection; Stevens, D., (2006) Didier Stevens Blog, , https://blog.didierstevens.com/; Torres, J., De Los Santos, J., (2018) Malicious Pdf Documents Detection Using Machine Learning Techniques",,"Samarati P.Obaidat M.S.Obaidat M.S.","Institute for Systems and Technologies of Information, Control and Communication (INSTICC)","SciTePress","15th International Joint Conference on e-Business and Telecommunications, ICETE 2018","26 July 2018 through 28 July 2018",,150360,,9789897583193,,,"English","ICETE - Proc. Int. Jt. Conf. e-Business Telecommun.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85071429401
"Shi H., Mao J., Xiao T., Jiang Y., Sun J.","57190578999;57201377790;57201373816;36836028000;56333360900;","Learning visually-grounded semantics from contrastive adversarial samples",2018,"COLING 2018 - 27th International Conference on Computational Linguistics, Proceedings",,,,"3715","3727",,17,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071184007&partnerID=40&md5=7d88fe0326792bdafe4c8f78c859e512","School of Electronics Engineering and Computer Science, Peking University, China; ITCS, Institute for Interdisciplinary Information Sciences, Tsinghua University, China; Megvii, Inc.","Shi, H., School of Electronics Engineering and Computer Science, Peking University, China; Mao, J., ITCS, Institute for Interdisciplinary Information Sciences, Tsinghua University, China; Xiao, T., School of Electronics Engineering and Computer Science, Peking University, China; Jiang, Y., Megvii, Inc.; Sun, J., Megvii, Inc.","We study the problem of grounding distributional representations of texts on the visual domain, namely visual-semantic embeddings (VSE for short). Begin with an insightful adversarial attack on VSE embeddings, we show the limitation of current frameworks and image-text datasets (e.g., MS-COCO) both quantitatively and qualitatively. The large gap between the number of possible constitutions of real-world semantics and the size of parallel data, to a large extent, restricts the model to establish a strong link between textual semantics and visual concepts. We alleviate this problem by augmenting the MS-COCO image captioning datasets with textual contrastive adversarial samples. These samples are synthesized using language priors of human and the WordNet knowledge base, and enforce the model to ground learned embeddings to concrete concepts within the image. This simple but powerful technique brings a noticeable improvement over the baselines on a diverse set of downstream tasks, in addition to defending known-type adversarial attacks. Codes are available at https://github.com/ExplorerFreda/VSE-C. © 2018 COLING 2018 - 27th International Conference on Computational Linguistics, Proceedings. All rights reserved.",,"Computational linguistics; Image processing; Knowledge based systems; Semantics; 'current; Embeddings; Image texts; Parallel data; Real-world; Semantic concept; Semantic embedding; Strong link; Visual semantics; Visually-grounded semantics; Embeddings",,,,,"Andrew, Galen, Arora, Raman, Bilmes, Jeff, Livescu, Karen, Deep Canonical Correlation Analysis (2013) Proc. of ICML; Castrejon, Lluis, Aytar, Yusuf, Vondrick, Carl, Pirsiavash, Hamed, Torralba, Antonio, Learning Aligned Cross-Modal Representations from Weakly Aligned Data (2016) Proc. of CVPR; Chen, Danqi, Bolton, Jason, Manning, Christopher D, A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task (2016) Proc. of ACL; Cheng, Jianpeng, Dong, Li, Lapata, Mirella, Long Short-Term Memory-Networks for Machine Reading (2016) Proc. of EMNLP.; Faghri, Fartash, Fleet, David J, Kiros, Jamie Ryan, Fidler, Sanja, (2017) VSE++: Improved Visual-Semantic Embeddings, , arXiv preprint arXiv:1707.05612; Frome, Andrea, Corrado, Greg S, Shlens, Jon, Bengio, Samy, Dean, Jeff, Mikolov, Tomas, Devise: A Deep Visual-Semantic Embedding Model (2013) Proc. of NIPS; Gong, Yichen, Luo, Heng, Zhang, Jian, Natural Language Inference over Interaction Space (2018) Proc. of ICLR; He, Kaiming, Zhang, Xiangyu, Ren, Shaoqing, Sun, Jian, Deep Residual Learning for Image Recognition (2016) Proc. of CVPR; Honnibal, Matthew, Johnson, Mark, An Improved Non-Monotonic Transition System for Dependency Parsing (2015) Proc. of EMNLP.; Hotelling, Harold, Relations between two sets of variates (1936) Biometrika, 28 (3), pp. 321-377. , (/4); Huang, Yan, Wang, Wei, Wang, Liang, Instance-Aware Image and Sentence Matching with Selective Multimodal LSTM (2017) Proc. of CVPR; Inan, Hakan, Khosravi, Khashayar, Socher, Richard, Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling (2017) Proc. of ICLR; Jia, Robin, Liang, Percy, Adversarial Examples for Evaluating Reading Comprehension Systems (2017) Proc. of EMNLP.; Karpathy, Andrej, Fei-Fei, Li, Deep Visual-Semantic Alignments for Generating Image Descriptions (2015) Proc. of CVPR; Kingma, Diederik P, Ba, Jimmy, Adam: A Method for Stochastic Optimization (2015) Proc. of ICLR; Kiros, Ryan, Salakhutdinov, Ruslan, Zemel, Richard S, (2014) Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models, , arXiv preprint arXiv:1411.2539; Kos, Jernej, Song, Dawn, (2017) Delving into Adversarial Attacks on Deep Policies, , arXiv preprint arXiv:1705.06452; Kumar, Ankit, Irsoy, Ozan, Ondruska, Peter, Iyyer, Mohit, Bradbury, James, Gulrajani, Ishaan, Zhong, Victor, Socher, Richard, Ask Me Anything: Dynamic Memory Networks for Natural Language Processing (2016) Proc. of ICML; Li, Yangyan, Su, Hao, Qi, Charles Ruizhongtai, Fish, Noa, Cohen-Or, Daniel, Guibas, Leonidas J, Joint embeddings of shapes and images via cnn image purification (2015) ACM Trans. Graph; Li, Hang, Learning to rank for information retrieval and natural language processing (2011) Synthesis Lectures on Human Language Technologies, 4 (1), pp. 1-113; Lin, Tsung-Yi, Maire, Michael, Belongie, Serge, Hays, James, Perona, Pietro, Ramanan, Deva, Dollár, Piotr, Zitnick, C Lawrence, Microsoft COCO: Common Objects in Context (2014) Proc. of ECCV; Malinowski, Mateusz, Rohrbach, Marcus, Fritz, Mario, Ask Your Neurons: A Neural-Based Approach to Answering Questions about Images (2015) Proc. of ICCV; Mao, Junhua, Xu, Jiajing, Jing, Kevin, Yuille, Alan L, Training and Evaluating Multimodal Word Embeddings with Large-Scale Web Annotated Images (2016) Proc. of NIPS; Mikolov, Tomas, Chen, Kai, Corrado, Greg, Dean, Jeffrey, (2013) Efficient Estimation of Word Representations in Vector Space, , arXiv preprint arXiv:1301.3781; Miller, George A, WordNet: A Lexical Database for English (1995) Communications of the ACM; Nam, Hyeonseob, Ha, Jung-Woo, Kim, Jeonghee, Dual Attention Networks for Multimodal Reasoning and Matching (2017) Proc. of CVPR; Ngiam, Jiquan, Khosla, Aditya, Kim, Mingyu, Nam, Juhan, Lee, Honglak, Ng, Andrew Y, Multimodal Deep Learning (2011) Proc. of ICML; Nguyen, Anh, Yosinski, Jason, Clune, Jeff, Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images (2015) Proc. of CVPR; Niu, Zhenxing, Zhou, Mo, Wang, Le, Gao, Xinbo, Hua, Gang, Hierarchical Multimodal LSTM for Dense Visual-Semantic Embedding (2017) Proc. of CVPR; Pennington, Jeffrey, Socher, Richard, Manning, Christopher D., GloVe: Global Vectors for Word Representation (2014) Proc. of EMNLP.; Reed, Scott, Akata, Zeynep, Schiele, Bernt, Lee, Honglak, Learning Deep Representations of Fine-Grained Visual Descriptions (2016) Proc. of CVPR; Shen, Yelong, Huang, Po-Sen, Gao, Jianfeng, Chen, Weizhu, Reasonet: Learning to stop reading in machine comprehension (2017) Proc. of SIGKDD; Socher, Richard, Karpathy, Andrej, Le, Quoc V, Manning, Christopher D, Ng, Andrew Y, Grounded Compositional Semantics for Finding and Describing Images with Sentences (2014) TACL; Turney, Peter D, Neuman, Yair, Assaf, Dan, Cohen, Yohai, Literal and Metaphorical Sense Identification through Concrete and Abstract Context (2011) Proc. of EMNLP.; Turpin, Andrew, Scholer, Falk, User Performance versus Precision Measures for Simple Search Tasks (2006) Proc. of SIGIR; Wang, Liwei, Li, Yin, Lazebnik, Svetlana, Learning Deep Structure-Preserving Image-Text Embeddings (2016) Proc. of CVPR; Xie, Cihang, Wang, Jianyu, Zhang, Zhishuai, Zhou, Yuyin, Xie, Lingxi, Yuille, Alan, Adversarial examples for semantic segmentation and object detection (2017) Proc. of ICCV; Young, Peter, Lai, Alice, Hodosh, Micah, Hockenmaier, Julia, From Image Descriptions to Visual Denotations: New Similarity Metrics for Semantic Inference over Event Descriptions (2014) TACL; Zou, Will Y, Socher, Richard, Cer, Daniel, Manning, Christopher D, Bilingual Word Embeddings for Phrase-Based Machine Translation (2013) Proc. of EMNLP.; Zwicky, Arnold M, Heads (1985) Journal of Linguistics","Shi, H.; School of Electronics Engineering and Computer Science, China; email: hyshi@pku.edu.cn
Mao, J.; ITCS, China; email: mjy14@mails.tsinghua.edu.cn
Xiao, T.; School of Electronics Engineering and Computer Science, China; email: jasonhsiao97@pku.edu.cn","Bender E.M.Derczynski L.Isabelle P.","Amazon Alexa;Baidu;Disney Research;et al.;Lenovo;Linguist List","Association for Computational Linguistics (ACL)","27th International Conference on Computational Linguistics, COLING 2018","20 August 2018 through 26 August 2018",,172932,,9781948087506,,,"English","COLING - Int. Conf. Comput. Linguist., Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85071184007
"Tu Y., Lin Z., Lee I., Hei X.","57203371826;12763207100;56876051600;36930304000;","Injected and delivered: Fabricating implicit control over actuation systems by spoofing inertial sensors",2018,"Proceedings of the 27th USENIX Security Symposium",,,,"1545","1562",,30,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069775820&partnerID=40&md5=f2caad1233f438030634b8efe5370889","University of Louisiana, Lafayette, United States; Ohio State University, United States; University of Pennsylvania, United States","Tu, Y., University of Louisiana, Lafayette, United States; Lin, Z., Ohio State University, United States; Lee, I., University of Pennsylvania, United States; Hei, X., University of Louisiana, Lafayette, United States","Inertial sensors provide crucial feedback for control systems to determine motional status and make timely, automated decisions. Prior efforts tried to control the output of inertial sensors with acoustic signals. However, their approaches did not consider sample rate drifts in analog-to-digital converters as well as many other realistic factors. As a result, few attacks demonstrated effective control over inertial sensors embedded in real systems. This work studies the out-of-band signal injection methods to deliver adversarial control to embedded MEMS inertial sensors and evaluates consequent vulnerabilities exposed in control systems relying on them. Acoustic signals injected into inertial sensors are out-of-band analog signals. Consequently, slight sample rate drifts could be amplified and cause deviations in the frequency of digital signals. Such deviations result in fluctuating sensor output; nevertheless, we characterize two methods to control the output: digital amplitude adjusting and phase pacing. Based on our analysis, we devise non-invasive attacks to manipulate the sensor output as well as the derived inertial information to deceive control systems. We test 25 devices equipped with MEMS inertial sensors and find that 17 of them could be implicitly controlled by our attacks. Furthermore, we investigate the generalizability of our methods and show the possibility to manipulate the digital output through signals with relatively low frequencies in the sensing channel. © 2018 Proceedings of the 27th USENIX Security Symposium. All rights reserved.",,"Acoustic waves; Analog to digital conversion; Control system analysis; Embedded systems; Acoustic signals; Actuation systems; Analog to digital converters; Digital signals; Inertial sensor; MEMS inertial sensors; Sensing channels; Signal injection method; Inertial navigation systems",,,,,"A Video Demonstration of Automatic Switching Attacks to Spoof GoogleMaps, , https://youtu.be/dy6gm9ZLKuY; A Video Demonstration of Conservative Side-Swing Attacks on a Gyroscopic Screwdriver, , https://youtu.be/SCAYbyMIJAc; A Video Demonstration of dos Attacks on a Soldering Iron, , https://youtu.be/itgmOl21zoc; A Video Demonstration of Side-Swing Attacks on a 3D Mouse, , https://youtu.be/YoYpNeIJh5U; A Video Demonstration of Side-Swing Attacks on a Self-balancing Robot, , https://youtu.be/oy3B1X41u5s; A Video Demonstration of Side-Swing Attacks on a Self-balancing Scooter, , https://youtu.be/Y1LLiyhCn9I; A Video Demonstration of Side-Swing Attacks on a Smartphone, , https://youtu.be/Wl6c_zBGlpU; A Video Demonstration of Side-Swing Attacks on a Stabilizer, , https://youtu.be/FDxaLUtgaCM; A Video Demonstration of Switching Attacks on a 3D Mouse, , https://youtu.be/iWXTJ6We0UY; A Video Demonstration of Switching Attacks on a Kinetic Controller, , https://youtu.be/MtXxcSzWcQA; A Video Demonstration of Switching Attacks on a Self-balancing Scooter, , https://youtu.be/D-etuH04pms; A Video Demonstration of Switching Attacks on a Smartphone, , https://youtu.be/psuOhyUvDQk; A Video Demonstration of Switching Attacks on a Stabilizer, , https://youtu.be/JcA_WXHrUEs; A Video Demonstration of Switching Attacks on a VR Headset, , https://youtu.be/Jf9xHAW1PJY; Device Teardown Reports, , https://www.ifixit.com/https://www.chipworks.com/; Goldwood Sound Directivity Horns, , http://www.goldwoodparts.com/directivity-horns, Accessed: 2018-05-05; Goldwood Sound GT-1188 Piezo Tweeter Speaker, , http://www.goldwoodparts.com/gt-1188.shtml, Accessed: 2018-05-05; LRAD 2000X Datasheet, , https://www.dropbox.com/s/4qth9beayjx5gxr/LRAD_Datasheet_2000X.pdf, Accessed: 2018-04-25; Myskunkworks 10"" Long-range Horn, , http://myskunkworks.net/index.php?route=product/product&path=61&product_id=63, Accessed: 2018-05-05; Myskunkworks 130dB Tweeter Speaker, , http://myskunkworks.net/index.php?route=product/product&path=61&product_id=79, Accessed: 2018-05-05; Pyle PDBT78 Tweeter Speaker, , https://www.amazon.com/Pyle-PDBT78-2-Inch-Titanium-Tweeter/dp/B000JLBO6E, Accessed: 2018-05-05; SainSmart UDB1002S DDS Signal Generator, , https://www.amazon.com/SainSmart-UDB1002S-Signal-Generator-Function/dp/B00JTR66CG/, Accessed: 2018-05-05; Sound Pressure, , http://en.wikipedia.org/wiki/Sound_pressure, Accessed: 2018-06-01; SparkFun MiniGen Mini Signal Generator Board, , https://www.sparkfun.com/products/11420, Accessed: 2018-05-05; Total SPL Adding of Coherent Sound Sources, , http://www.sengpielaudio.com/calculator-coherentsources.htm, Accessed: 2018-06-01; UltraElectronics HyperShield Datasheet, , https://www.ultra-hyperspike.com/Data/Pages/fe14c65c8b5fa0e0b19b46fca45fa01d-HyperShield_Dat_Sheet.pdf, Accessed: 2017-05-30; (2011) STMicroelectronics L3G4200D Datasheet, , https://www.elecrow.com/download/L3G4200_AN3393.pdf, Accessed: 2017-06-12; (2012) STMicroelectronics LSM330 Datasheet, , www.st.com/resource/en/datasheet/dm00037200.pdf, Accessed: 2018-06-14; (2013) InvenSense MPU-6500 Datasheet, , https://store.invensense.com/datasheets/invensense/MPU_6500_Rev1.0.pdf, Accessed: 2017-06-12; (2013) STMicroelectronics L3GD20 Datasheet, , http://www.st.com/en/mems-and-sensors/l3gd20.html, Accessed: 2017-06-12; (2015) Future Vision. MINI Augmented Reality Glasses Make the Future a Reality, , http://www.bmwgroupdesignworks.com/work/mini-ar-glasses/, Accessed: 2017-05-16; (2016) Hope in a Glove for Parkinson's Patients, , https://www.technologyreview.com/s/545456/hope-in-a-glove-for-parkinsons-patients/, Accessed: 2018-02-01; (2017) Heads-up Display to Give Soldiers Improved Situational Awareness, , https://www.army.mil/article/188088, Accessed: 2017-12-19; Altmann, J., Acoustic weapons - A prospective assessment (2001) Science & Global Security, 9 (3), pp. 165-234; Anand, S.A., Saxena, N., Speechless: Analyzing the threat to speech privacy from smartphone motion sensors (2018) IEEE Symposium on Security and Privacy; Antonello, R., Oboe, R., MEMS gyroscopes for consumers and industrial applications (2011) Microsensors. InTech; Aviv, A.J., Sapp, B., Blaze, M., Smith, J.M., Practicality of accelerometer side channels on smartphones (2012) Proceedings of the 28th Annual Computer Security Applications Conference; Bhuyan, A.I., Mallick, T.C., Gyro-accelerometer based control of a robotic arm using AVR microcontroller (2014) 9th International Forum on Strategic Technology (IFOST); Block, K., Narain, S., Noubir, G., An autonomic and permissionless android covert channel (2017) Proceedings of the 10th ACM Conference on Security and Privacy in Wireless and Mobile Networks; Cai, L., Chen, H., On the practicality of motion based keystroke inference attack (2012) International Conference on Trust and Trustworthy Computing, , Springer; Castro, S., Dean, R., Roth, G., Flowers, G.T., Grantham, B., Influence of acoustic noise on the dynamic performance of MEMS gyroscopes (2007) ASME International Mechanical Engineering Congress and Exposition; Davidson, D., Wu, H., Jellinek, R., Singh, V., Ristenpart, T., Controlling UAVs with sensor input spoofing attacks (2016) 10th USENIX Workshop on Offensive Technologies (WOOT); Dean, R., Burch, N., Black, M., Beal, A., Flowers, G., Microfibrous metallic cloth for acoustic isolation of a MEMS gyroscope (2011) Proceedings of Industrial and Commercial Applications of Smart Structures Technologies, , Society of Photo-Optical Instrumentation Engineers; Dean, R.N., Castro, S.T., Flowers, G.T., Roth, G., Ahmed, A., Hodel, A.S., Grantham, B.E., Brunsch, J.P., A characterization of the performance of a MEMS gyroscope in acoustically harsh environments (2011) IEEE Transactions on Industrial Electronics; Dean, R.N., Flowers, G.T., Hodel, A.S., Roth, G., Castro, S., Zhou, R., Moreira, A., Grantham, B.E., On the degradation of MEMS gyroscope performance in the presence of high power acoustic noise (2007) IEEE International Symposium on Industrial Electronics; Farshteindiker, B., Hasidim, N., Grosz, A., Oren, Y., How to phone home with someone else's phone: Information exfiltration using intentional sound noise on gyroscopic sensors (2016) 10th USENIX Workshop on Offensive Technologies (WOOT); Gallego-Juárez, J.A., Rodriguez-Corral, G., Gaete-Garreton, L., An ultrasonic transducer for high power applications in gases (1978) Ultrasonics, 16 (6), pp. 267-271; Kranz, M., Whitley, M., Rudd, C., Craven, J.D., Clark, S.D., Dean, R.N., Flowers, G.T., Environmentally isolating packaging for MEMS sensors (2017) International Symposium on Microelectronics, , International Microelectronics Assembly and Packaging Society; Kune, D.F., Backes, J., Clark, S.S., Kramer, D., Reynolds, M., Fu, K., Kim, Y., Xu, W., Ghost talk: Mitigating EMI signal injection attacks against analog sensors (2013) IEEE Symposium on Security and Privacy; Lebeck, K., Ruth, K., Kohno, T., Roesner, F., Securing augmented reality output (2017) IEEE Symposium on Security and Privacy; Lebeck, K., Ruth, K., Kohno, T., Roesner, F., Towards security and privacy for multi-user augmented reality: Foundations with end users (2018) IEEE Symposium on Security and Privacy; Liu, X., Zhou, Z., Diao, W., Li, Z., Zhang, K., When good becomes evil: Keystroke inference with smartwatch (2015) Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security; Michalevsky, Y., Boneh, D., Nakibly, G., Gyrophone: Recognizing speech from gyroscope signals (2014) Proceedings of USENIX Security Symposium; Miluzzo, E., Varshavsky, A., Balakrishnan, S., Choudhury, R.R., Tapprints: Your finger taps have fingerprints (2012) Proceedings of the 10th International Conference on Mobile Systems, Applications, and Services; Nasiri, S., A critical review of MEMS gyroscopes technology and commercialization status InvenSense Whitepaper; Nighswander, T., Ledvina, B., Diamond, J., Brumley, R., Brumley, D., GPS software attacks (2012) Proceedings of the 2012 ACM Conference on Computer and Communications Security; Park, Y., Son, Y., Shin, H., Kim, D., Kim, Y., This ain't your dose: Sensor spoofing attack on medical infusion pump (2016) 10th USENIX Workshop on Offensive Technologies (WOOT); Passaro, V., Cuccovillo, A., Vaiani, L., Carlo, M.D., Campanella, C.E., Gyroscope technology and applications: A review in the industrial perspective (2017) Sensors, 17 (10); Petracca, G., Reineh, A.-A., Sun, Y., Grossklags, J., Jaeger, T., Aware: Preventing abuse of privacy-sensitive sensors via operation bindings (2017) Proceedings of USENIX Security Symposium; Psiaki, M.L., O'Hanlon, B.W., Powell, S.P., Bhatti, J.A., Wesson, K.D., Humphreys, T.E., GNSS spoofing detection using two-antenna differential carrier phase (2014) Proceedings of the 27th International Technical Meeting of the Satellite Division of the Institute of Navigation; Shin, H., Kim, D., Kwon, Y., Kim, Y., Illusion and dazzle: Adversarial optical channel exploits against lidars for automotive applications (2017) International Conference on Cryptographic Hardware and Embedded Systems, , Springer; Shoukry, Y., Martin, P., Tabuada, P., Srivastava, M., Non-invasive spoofing attacks for anti-lock braking systems (2013) Cryptographic Hardware and Embedded Systems, , Springer; Sikder, A., Aksu, H., Uluagac, A.S., 6thSense: A context-aware sensor-based attack detector for smart devices (2017) Proceedings of USENIX Security Symposium; Son, Y., Shin, H., Kim, D., Park, Y., Noh, J., Choi, K., Choi, J., Kim, Y., Rocking drones with intentional sound noise on gyroscopic sensors (2015) Proceedings of USENIX Security Symposium; Soobramaney, P., Flowers, G., Dean, R., Mitigation of the effects of high levels of high-frequency noise on MEMS gyroscopes using microfibrous cloth (2015) ASME 2015 International Design Engineering Technical Conferences and Computers and Information in Engineering Conference; Takeda, S., Morioka, I., Miyashita, K., Okumura, A., Yoshida, Y., Matsumoto, K., Age variation in the upper limit of hearing (1992) European Journal of Applied Physiology and Occupational Physiology, 65 (5), pp. 403-408; Tian, J., Yang, W., Peng, Z., Tang, T., Li, Z., Application of MEMS accelerometers and gyroscopes in fast steering mirror control systems (2016) Sensors, 16 (4); Trippel, T., Weisse, O., Xu, W., Honeyman, P., Fu, K., Walnut: Waging doubt on the integrity of MEMS accelerometers with acoustic injection attacks (2017) Proceedings of IEEE European Symposium on Security and Privacy; Wang, C., Guo, X., Wang, Y., Chen, Y., Liu, B., Friend or foe?: Your wearable devices reveal your personal pin (2016) Proceedings of the 11th ACM on Asia Conference on Computer and Communications Security; Wang, H., Lai, T.T.-T., Roy Choudhury, R., Mole: Motion leaks through smartwatch sensors (2015) Proceedings of the 21st Annual International Conference on Mobile Computing and Networking; Wang, Z., Wang, K., Yang, B., Li, S., Pan, A., (2017) Sonic Gun to Smart Devices: Your Devices Lose Control under Ultrasound/sound, , Blackhat USA; Wang, Z., Zhu, W., Miao, J., Zhu, H., Chao, C., Tan, O.K., Micromachined thick film piezoelectric ultrasonic transducer array (2006) Sensors and Actuators A: Physical, 130, pp. 485-490; Wygant, I.O., Kupnik, M., Windsor, J.C., Wright, W.M., Wochner, M.S., Yaralioglu, G.G., Hamilton, M.F., Khuri-Yakub, B.T., 50 kHz capacitive micromachined ultrasonic transducers for generation of highly directional sound with parametric arrays (2009) IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control, 56 (1), pp. 193-203; Yan, C., Xu, W., Liu, J., Can you trust autonomous vehicles: Contactless attacks against sensors of self-driving vehicle (2016) DEF CON, 24; Yunker, W.N., Soobramaney, P., Black, M., Dean, R.N., Flowers, G.T., Ahmed, A., The underwater effects of high power, high frequency acoustic noise on MEMS gyroscopes (2011) ASME 2011 International Design Engineering Technical Conferences and Computers and Information in Engineering Conference; Yunker, W.N., Stevens, C.B., Flowers, G.T., Dean, R.N., Sound attenuation using microelectromechanical systems fabricated acoustic metamaterials (2013) Journal of Applied Physics; Zhang, G., Yan, C., Ji, X., Zhang, T., Zhang, T., Xu, W., Dolphinattack: Inaudible voice commands (2017) Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security",,,"Baidu;Dropbox;Facebook;Google;NSF;The USENIX Association","USENIX Association","27th USENIX Security Symposium","15 August 2018 through 17 August 2018",,155142,,9781939133045,,,"English","Proc. USENIX Secur. Symp.",Conference Paper,"Final","",Scopus,2-s2.0-85069775820
"Mahloujifar S., Diochnos D.I., Mahmoody M.","57196952100;23008516600;36237413200;","Learning under p-tampering attacks",2018,"International Symposium on Artificial Intelligence and Mathematics, ISAIM 2018",,,,"","",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069648953&partnerID=40&md5=508774820e63253848b95b500ae950bb","University of Virginia, United States; University of Virginia, United States; University of Virginia, United States","Mahloujifar, S., University of Virginia, United States; Diochnos, D.I., University of Virginia, United States; Mahmoody, M., University of Virginia, United States","Recently, Mahloujifar and Mahmoody (TCC’17) studied attacks against learning algorithms using a special case of Valiant’s malicious noise, called p-tampering, in which the adversary gets to change any training example with independent probability p but is limited to choose ‘adversarial’ examples only with correct labels. They obtained p-tampering attacks that increase the error probability in the so called ‘targeted’ poisoning model in which the adversary’s goal is to increase the loss of the trained hypothesis over a particular test example. At the heart of their attack was an efficient algorithm to bias the average of any bounded real-valued function through p-tampering. In this work, we present new improved biasing attacks for biasing the average output of bounded real-valued functions. Our new biasing attacks achieve in polynomial-time the best bias achieved by MM16 through an exponential time p-tampering attack. Our improved biasing attacks, directly imply improved ptampering attacks against learners in the targeted poisoning model. As a bonus, our improved attacks come also with much simpler analysis compared to previous attacks. We also study the possibility of PAC learning under p-tampering attacks in the non-targeted (aka indiscriminate) setting where the adversary’s goal is to increase the risk of the hypothesis (for a random test example). We show that PAC learning is possible under p-tampering poisoning attacks basically whenever it is possible in the realizable setting without attacks. © 2018 University of Virginia. All rights reserved.",,"Artificial intelligence; Polynomial approximation; Error probabilities; Exponential time; Poisoning attacks; Poisoning model; Polynomial-time; Real-valued functions; Tampering attacks; Training example; Learning algorithms",,,,,"Angluin, D., Queries and concept learning (1987) Machine Learning, 2 (4), pp. 319-342. , 8; Aumann, Y., Lindell, Y., Security against covert adversaries: Efficient protocols for realistic adversaries (2007) Theory of Cryptography, pp. 137-156. , 2; Austrin, P., Chung, K.-M., Mahmoody, M., Pass, R., Seth, K., On the impossibility of cryptography with tamperable randomness (2014) International Cryptology Conference, pp. 462-479. , Springer, 3; Awasthi, P., Balcan, M.F., Long, P.M., The power of localization for efficiently learning linear separators with noise (2014) Proceedings of the 46th Annual ACM Symposium on Theory of Computing, pp. 449-458. , ACM, 1, 2; Beigi, S., Etesami, O., Gohari, A., Deterministic randomness extraction from generalized and distributed santha–vazirani sources (2017) SIAM Journal on Computing, 46 (1), pp. 1-36. , 3; Benedek, G.M., Itai, A., Learnability with respect to fixed distributions (1991) Theoretical Computer Science, 86 (2), pp. 377-390. , 1; Bentov, I., Gabizon, A., Zuckerman, D., (2016) Bitcoin Beacon, p. 2. , arXiv preprint 3; Biggio, B., Fumera, G., Roli, F., Security evaluation of pattern classifiers under attack (2014) IEEE Transactions on Knowledge and Data Engineering, 26 (4), pp. 984-996. , 2; Blumer, A., Ehrenfeucht, A., Haussler, D., Warmuth, M.K., Learnability and the Vapnik-Chervonenkis dimension (1989) Journal of the ACM, 36 (4), pp. 929-965. , October 1; Blumer, A., Ehrenfeucht, A., Haussler, D., Warmuth, M.K., Occam’s Razor (1987) Information Processing Letters, 24 (6), pp. 377-380. , 8; Bshouty, N.H., Eiron, N., Kushilevitz, E., PAC learning with nasty noise (2002) Theoretical Computer Science, 288 (2), pp. 255-275. , 1; Canetti, R., Feige, U., Goldreich, O., Naor, M., Adaptively secure multi-party computation (1996) 28th Annual ACM Symposium on Theory of Computing, pp. 639-648. , Philadephia, PA, USA, May 22–24, ACM Press. 3, 8; Carlini, N., Wagner, D.A., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy, SP 2017, pp. 39-57. , San Jose, CA, USA, May 22-26, 2017, 2; Chor, B., Goldreich, O., Unbiased bits from sources of weak randomness and probabilistic communication complexity (1985) Proc. 26th FOCS, pp. 429-442. , IEEE, 3; Cleve, R., Impagliazzo, R., Martingales, collective coin flipping and discrete control processes (1993) Other Words, 1 (5), p. 8; Diochnos, D.I., On the evolution of monotone conjunctions: Drilling for best approximations (2016) ALT, pp. 98-112. , 8; Dodis, O., Prabhakaran, Sahai, On the (im)possibility of cryptography with imperfect randomness (2004) FOCS: IEEE Symposium on Foundations of Computer Science (FOCS), p. 3; Dodis, Y., Yao, Y., Privacy with imperfect randomness (2015) Annual Cryptology Conference, pp. 463-482. , Springer, 3; Ehrenfeucht, A., Haussler, D., Kearns, M.J., Valiant, L.G., A general lower bound on the number of examples needed for learning (1989) Information and Computation, 82 (3), pp. 247-261. , 1; Goldwasser, S., Kalai, Y.T., Park, S., Adaptively secure coin-flipping, revisited (2015) International Colloquium on Automata, Languages, and Programming, pp. 663-674. , Springer, 3, 8; González, C.R., Abu-Mostafa, Y.S., Mismatched training and test distributions can outperform matched ones (2015) Neural Computation, 27 (2), pp. 365-387. , 2; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR, p. 2; Haitner, I., Ishai, Y., Kushilevitz, E., Lindell, Y., Petrank, E., Black-box constructions of protocols for secure computation (2010) Cryptology ePrint Archive, p. 2. , http://eprint.iacr.org/2010/164, Report; Kearns, M.J., Li, M., Learning in the presence of malicious errors (1993) SIAM Journal on Computing, 22 (4), pp. 807-837. , 1; Lichtenstein, D., Linial, N., Saks, M., Some extremal problems arising from discrete control processes (1989) Combinatorica, 9 (3), pp. 269-287. , 8; Mahloujifar, S., Diochnos, D.I., Mahmoody, M., (2017) Learning Under P-Tampering Attacks, p. 3. , arXiv preprint 6, 8; Mahloujifar, S., Mahmoody, M., Blockwise p-tampering attacks on cryptographic primitives, extractors, and learners (2017) Theory of Cryptography Conference (TCC) 2017, p. 2. , http://eprint.iacr.org/2017/950, Cryptology ePrint Archive, Report 2017/950, 3, 4, 5; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) CVPR, pp. 2574-2582. , 2; Nakamoto, S., (2008) Bitcoin: A Peer-to-Peer Electronic Cash System, p. 2; Nelson, B., Rubinstein, B.I.P., Huang, L., Joseph, A.D., Lee, S.J., Rao, S., Tygar, J.D., Query strategies for evading convex-inducing classifiers (2012) Journal of Machine Learning Research, 13 (May), pp. 1293-1332. , 2; Pitt, L., Valiant, L.G., Computational limitations on learning from examples (1988) Journal of the ACM, 35 (4), pp. 965-984. , 8; Reingold, O., Vadhan, S., Wigderson, A., (2004) A Note on Extracting Randomness from Santha-Vazirani Sources, p. 3. , Unpublished manuscript; Rubinstein, B.I.P., Nelson, B., Huang, L., Joseph, A.D., Lau, S.-H., Rao, S., Taft, N., Tygar, J.D., Antidote: Understanding and defending against poisoning of anomaly detectors (2009) Proceedings of the 9th ACM SIGCOMM Conference on Internet Measurement Conference, pp. 1-14. , ACM, 1; Rubinstein, B.I.P., Nelson, B., Huang, L., Joseph, A.D., Lau, S.-H., Rao, S., Taft, N., Tygar, J.D., Stealthy poisoning attacks on PCA-based anomaly detectors (2009) ACM SIGMETRICS Performance Evaluation Review, 37 (2), pp. 73-74. , 1; Santha, M., Vazirani, U.V., Generating quasi-random sequences from semi-random sources (1986) J. Comput. Syst. Sci., 33 (1), pp. 75-87. , 3; Shen, S., Tople, S., Saxena, P., A uror: Defending against poisoning attacks in collaborative deep learning systems (2016) Proceedings of the 32nd Annual Conference on Computer Security Applications, pp. 508-519. , ACM, 1, 2; Sloan, R.H., Four types of noise in data for PAC learning (1995) Information Processing Letters, 54 (3), pp. 157-162. , 2; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) ICLR, p. 2; Valiant, L.G., A theory of the learnable (1984) Communications of the ACM, 27 (11), pp. 1134-1142. , 1, 8; Valiant, L.G., Learning disjunctions of conjunctions (1985) IJCAI, pp. 560-566. , 1; Neumann, J.V., 13. Various techniques used in connection with random digits (1951) Appl. Math Ser, 12, pp. 36-38. , 3; Xiao, H., Biggio, B., Brown, G., Fumera, G., Eckert, C., Roli, F., Is feature selection secure against training data poisoning? (2015) ICML, pp. 1689-1698. , 1, 2; Xu, H., Mannor, S., Robustness and generalization (2012) Machine Learning, 86 (3), pp. 391-423. , 2; Xu, W., Evans, D., Qi, Y., Feature squeezing: Detecting adversarial examples in deep neural networks (2017) CoRR, p. 2; Yamazaki, K., Kawanabe, M., Watanabe, S., Sugiyama, M., Müller, K.-R., Asymptotic bayesian generalization error when training and test distributions are different (2007) ICML, pp. 1079-1086. , 2",,,,"University of Virginia","2018 International Symposium on Artificial Intelligence and Mathematics, ISAIM 2018","3 January 2018 through 5 January 2018",,149220,,,,,"English","Int. Symp. Artif. Intell. Math., ISAIM",Conference Paper,"Final","",Scopus,2-s2.0-85069648953
"Guo Y., Zhang C., Zhang C., Chen Y.","57194152792;57199501660;7405490589;18036763500;","Sparse DnNs with improved adversarial robustness",2018,"Advances in Neural Information Processing Systems","2018-December",,,"242","251",,28,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064848229&partnerID=40&md5=c2a096f9828a1b66fb8ab9b784c88355","Intel Labs China, China; Institute for Artificial Intelligence, Tsinghua University (THUAI), State Key Lab of Intelligent Technologies and Systems, Beijing National Research Center for Information Science and Technology (BNRis), Department of Automation, Tsinghua University, China; Academy for Advanced Interdisciplinary Studies, Center for Data Science, Peking University, China","Guo, Y., Intel Labs China, China, Institute for Artificial Intelligence, Tsinghua University (THUAI), State Key Lab of Intelligent Technologies and Systems, Beijing National Research Center for Information Science and Technology (BNRis), Department of Automation, Tsinghua University, China; Zhang, C., Academy for Advanced Interdisciplinary Studies, Center for Data Science, Peking University, China; Zhang, C., Institute for Artificial Intelligence, Tsinghua University (THUAI), State Key Lab of Intelligent Technologies and Systems, Beijing National Research Center for Information Science and Technology (BNRis), Department of Automation, Tsinghua University, China; Chen, Y., Intel Labs China, China","Deep neural networks (DNNs) are computationally/memory-intensive and vulnerable to adversarial attacks, making them prohibitive in some real-world applications. By converting dense models into sparse ones, pruning appears to be a promising solution to reducing the computation/memory cost. This paper studies classification models, especially DNN-based ones, to demonstrate that there exists intrinsic relationships between their sparsity and adversarial robustness. Our analyses reveal, both theoretically and empirically, that nonlinear DNN-based classifiers behave differently under l2 attacks from some linear ones. We further demonstrate that an appropriately higher model sparsity implies better robustness of nonlinear DNNs, whereas over-sparsified models can be more difficult to resist adversarial examples. © 2018 Curran Associates Inc..All rights reserved.",,"Classification models; Real-world; Deep neural networks",,,,,"Bartlett, P.L., Foster, D.J., Telgarsky, M.J., Spectrally-normalized margin bounds for neural networks (2017) NIPS; Candès, E.J., Romberg, J., Tao, T., Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency information (2006) IEEE Transactions on Information Theory, 52 (2), pp. 489-509; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) SP; Cisse, M., Bojanowski, P., Grave, E., Dauphin, Y., Usunier, N., Parseval networks: Improving robustness to adversarial examples (2017) ICML; D'Aspremont, A., Bach, F., Ghaoui, L.E., Optimal solutions for sparse principal component analysis (2008) JMLR, 9, pp. 1269-1294. , July; Denil, M., Shakibi, B., Dinh, L., De Freitas, N., Predicting parameters in deep learning (2013) NIPS, , Marc'Aurelio Ranzato, and; Dhillon, G.S., Azizzadenesheli, K., Lipton, Z.C., Bernstein, J., Kossaifi, J., Khanna, A., Anandkumar, A., Stochastic activation pruning for robust adversarial defense (2018) ICLR; Donoho, D.L., Compressed sensing (2006) IEEE Transactions on Information Theory, 52 (4), pp. 1289-1306; Galloway, A., Taylor, G.W., Moussa, M., Attacking binarized neural networks (2018) ICLR; Gao, J., Wang, B., Lin, Z., Xu, W., Qi, Y., DeepCloak: Masking deep neural network models for robustness against adversarial samples (2017) ICLR Workshop; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR; Gopalakrishnan, S., Marzi, Z., Madhow, U., Pedarsani, R., Combating adversarial attacks using sparse representations (2018) ICLR Workshop; Guo, Y., Yao, A., Chen, Y., Dynamic network surgery for efficient dnns (2016) NIPS; Han, S., Pool, J., Tran, J., Dally, W., Learning both weights and connections for efficient neural network (2015) NIPS; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) CVPR; Hein, M., Andriushchenko, M., Formal guarantees on the robustness of a classifier against adversarial manipulation (2017) NIPS; Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadarrama, S., Darrell, T., Caffe: Convolutional architecture for fast feature embedding (2014) MM; Lu, J., Issaranon, T., Forsyth, D., SafeTyNet: Detecting and rejecting adversarial examples robustly (2017) ICCV; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) ICLR; Marzi, Z., Gopalakrishnan, S., Madhow, U., Pedarsani, R., (2018) Sparsity-Based Defense Against Adversarial Attacks on Linear Classifiers, , arXiv preprint; Molchanov, D., Ashukha, A., Vetrov, D., Variational dropout sparsifies deep neural networks (2017) ICML; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) CVPR; Neklyudov, K., Molchanov, D., Ashukha, A., Vetrov, D.P., Structured Bayesian pruning via log-normal multiplicative noise (2017) NIPS; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) SP; Park, J., Li, S., Wen, W., Tang, P.T.P., Li, H., Chen, Y., Dubey, P., Faster cnns with direct sparse convolutions and guided pruning (2017) ICLR; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) ICLR; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2018) ICLR; Ullrich, K., Meeds, E., Welling, M., Soft weight-sharing for neural network compression (2017) ICLR; Wang, L., Ding, G.W., Huang, R., Cao, Y., Lui, Y.C., Adversarial robustness of pruned neural networks (2018) ICLR Workshop Submission; Weng, T.-W., Zhang, H., Chen, P.-Y., Yi, J., Su, D., Gao, Y., Hsieh, C.-J., Daniel, L., Evaluating the robustness of neural networks: An extreme value theory approach (2018) ICLR; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., Mitigating adversarial effects through randomization (2018) ICLR; Ye, S., Wang, S., Wang, X., Yuan, B., Wen, W., Lin, X., Defending DNN adversarial attacks with pruning and logits augmentation (2018) ICLR Workshop Submission",,"Garnett R.Grauman K.Larochelle H.Wallach H.Cesa-Bianchi N.Grauman K.Bengio S.",,"Neural information processing systems foundation","32nd Conference on Neural Information Processing Systems, NeurIPS 2018","2 December 2018 through 8 December 2018",,147412,10495258,,,,"English","Adv. neural inf. proces. syst.",Conference Paper,"Final","",Scopus,2-s2.0-85064848229
"Jetley S., Lord N.A., Torr P.H.S.","55599580900;57201336704;56821543600;","With friends like these, who needs adversaries?",2018,"Advances in Neural Information Processing Systems","2018-December",,,"10749","10759",,13,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064841979&partnerID=40&md5=798b5c4eadf1e6b0a737555ca9b73f3d","Department of Engineering Science, University of Oxford, United Kingdom; Oxford Research Group, FiveAI Ltd., United Kingdom","Jetley, S., Department of Engineering Science, University of Oxford, United Kingdom; Lord, N.A., Department of Engineering Science, University of Oxford, United Kingdom, Oxford Research Group, FiveAI Ltd., United Kingdom; Torr, P.H.S., Department of Engineering Science, University of Oxford, United Kingdom, Oxford Research Group, FiveAI Ltd., United Kingdom","The vulnerability of deep image classification networks to adversarial attack is now well known, but less well understood. Via a novel experimental analysis, we illustrate some facts about deep convolutional networks for image classification that shed new light on their behaviour and how it connects to the problem of adversaries. In short, the celebrated performance of these networks and their vulnerability to adversarial attack are simply two sides of the same coin: the input image-space directions along which the networks are most vulnerable to attack are the same directions which they use to achieve their classification performance in the first place. We develop this result in two main steps. The first uncovers the fact that classes tend to be associated with specific image-space directions. This is shown by an examination of the class-score outputs of nets as functions of 1D movements along these directions. This provides a novel perspective on the existence of universal adversarial perturbations. The second is a clear demonstration of the tight coupling between classification performance and vulnerability to adversarial attack within the spaces spanned by these directions. Thus, our analysis resolves the apparent contradiction between accuracy and vulnerability. It provides a new perspective on much of the prior art and reveals profound implications for efforts to construct neural nets that are both accurate and robust to adversarial attack.1 © 2018 Curran Associates Inc.All rights reserved.",,"Classification networks; Classification performance; Convolutional networks; Experimental analysis; Image space; Input image; Prior arts; Tight coupling; Image classification",,,,,"(2017) NIPS: 2017 Competition on Adversarial Attacks and Defenses, , https://www.kaggle.com/nips-2017-adversarial-learning-competition, accessed: 2018-03-12; Moosavi-Dezfooli, S.M., Fawzi, A., Fawzi, O., Frossard, P., Soatto, S., Robustness of classifiers to universal perturbations: A geometric perspective (2018) International Conference on Learning Representations; Lin, M., Chen, Q., Yan, S., Network in network (2013) International Conference on Learning Representations; Moosavi-Dezfooli, S.M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on, pp. 86-94. , IEEE; Gao, J., Wang, B., Lin, Z., Xu, W., Qi, Y., DeepCloak: Masking deep neural network models for robustness against adversarial samples (2017) International Conference on Learning Representations; Zhao, Q., Griffin, L.D., Suppressing the unusual: Towards robust cnns using symmetric activation functions (2016) CoRR, , abs/1603.05145; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations; Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , Number EPFL-CONF-218057; Sabour, S., Cao, Y., Faghri, F., Fleet, D.J., Adversarial manipulation of deep representations (2016) International Conference on Learning Representations; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Proceedings of The IEEE Conference on Computer Vision and Pattern Recognition, pp. 427-436; Stanley, K.O., Compositional pattern producing networks: A novel abstraction of development (2007) Genetic Programming and Evolvable Machines, 8 (2), pp. 131-162; Wang, B., Gao, J., Qi, Y., (2016) A Theoretical Framework for Robustness of (Deep) Classifiers Under Adversarial Noise, , arXiv preprint; Maharaj, A.V., (2015) Improving The Adversarial Robustness of Convnets by Reduction of Input Dimensionality; Das, N., Shanbhogue, M., Chen, S., Hohman, F., Chen, L., Kounavis, M.E., Chau, D.H., Keeping the bad guys out: Protecting and vaccinating deep learning with JPEG compression (2017) CoRR, , abs/1705.02900; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A.L., Mitigating adversarial effects through randomization (2017) CoRR, , abs/1711.01991; Tanay, T., Griffin, L., (2016) A Boundary Tilting Persepective on The Phenomenon of Adversarial Examples, , arXiv preprint; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) International Conference on Learning Representations; Lu, J., Issaranon, T., Forsyth, D., SafeTyNet: Detecting and rejecting adversarial examples robustly (2017) Proceedings of The IEEE Conference on Computer Vision and Pattern Recognition, pp. 446-454; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., (2017) On Detecting Adversarial Perturbations, , arXiv preprint; Zhang, H., Cisse, M., Dauphin, Y., Lopez-Paz, D., MixUp: Beyond empirical risk minimization (2018) International Conference on Learning Representations; Fawzi, A., Moosavi-Dezfooli, S.M., Frossard, P., Robustness of classifiers: From adversarial to random noise (2016) Advances in Neural Information Processing Systems, pp. 1632-1640; Fawzi, A., Moosavi-Dezfooli, S.M., Frossard, P., Soatto, S., (2017) Classification Regions of Deep Neural Networks, , arXiv preprint; Fawzi, A., Moosavi-Dezfooli, S.M., Frossard, P., The robustness of deep networks: A geometrical perspective (2017) IEEE Signal Processing Magazine, 34 (6), pp. 50-62; Simonyan, K., Vedald, A., Zisserman, A., (2013) Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps, , arXiv preprint; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Fei-Fei, L., ImageNet large scale visual recognition challenge (2015) International Journal of Computer Vision (IJCV), 115 (3), pp. 211-252; Dalal, N., Triggs, B., Histograms of oriented gradients for human detection (2005) Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on., 1, pp. 886-893. , IEEE; Do Carmo, M., (1976) Differential Geometry of Curves and Surfaces, , Prentice-Hall",,"Grauman K.Cesa-Bianchi N.Garnett R.Wallach H.Bengio S.Larochelle H.Grauman K.",,"Neural information processing systems foundation","32nd Conference on Neural Information Processing Systems, NeurIPS 2018","2 December 2018 through 8 December 2018",,147412,10495258,,,,"English","Adv. neural inf. proces. syst.",Conference Paper,"Final","",Scopus,2-s2.0-85064841979
"Song Y., Kushman N., Shu R., Ermon S.","57192167461;36707949600;57189354182;35791579200;","Constructing unrestricted adversarial examples with generative models",2018,"Advances in Neural Information Processing Systems","2018-December",,,"8312","8323",,61,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064836449&partnerID=40&md5=ddbe078fbdec9057879af2aa68271fa7","Stanford University, United States; Microsoft Research, United States","Song, Y., Stanford University, United States; Kushman, N., Microsoft Research, United States; Shu, R., Stanford University, United States; Ermon, S., Stanford University, United States","Adversarial examples are typically constructed by perturbing an existing data point within a small matrix norm, and current defense methods are focused on guarding against this type of attack. In this paper, we propose unrestricted adversarial examples, a new threat model where the attackers are not restricted to small norm-bounded perturbations. Different from perturbation-based attacks, we propose to synthesize unrestricted adversarial examples entirely from scratch using conditional generative models. Specifically, we first train an Auxiliary Classifier Generative Adversarial Network (AC-GAN) to model the class-conditional distribution over data samples. Then, conditioned on a desired class, we search over the AC-GAN latent space to find images that are likely under the generative model and are misclassified by a target classifier. We demonstrate through human evaluation that unrestricted adversarial examples generated this way are legitimate and belong to the desired class. Our empirical results on the MNIST, SVHN, and CelebA datasets show that unrestricted adversarial examples can bypass strong adversarial training and certified defense methods designed for traditional adversarial attacks. © 2018 Curran Associates Inc.All rights reserved.",,"Adversarial networks; Conditional distribution; Data points; Generative model; Human evaluation; Matrix norms; Norm-bounded perturbation; Threat modeling; Network security",,,,,"Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint; Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Xiao, C., Prakash, A., Song, D., Robust physical-world attacks on deep learning visual classification (2018) Computer Vision and Pattern Recognition (CVPR); Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., Adversarial examples for semantic segmentation and object detection (2017) International Conference on Computer Vision; Carlini, N., Mishra, P., Vaidya, T., Zhang, Y., Sherr, M., Shields, C., Wagner, D., Zhou, W., Hidden voice commands (2016) USENIX Security Symposium, pp. 513-530; Zhang, G., Yan, C., Ji, X., Zhang, T., Zhang, T., Xu, W., Dol-phinattack: Inaudible voice commands (2017) Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pp. 103-117; Cisse, M., Adi, Y., Neverova, N., Keshet, J., (2017) Houdini: Fooling Deep Structured Prediction Models, , arXiv preprint; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Machine Learning at Scale, , arXiv preprint; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , arXiv preprint; Sinha, A., Namkoong, H., Duchi, J., (2017) Certifiable Distributional Robustness with Principled Adversarial Training, , arXiv preprint; Gu, S., Rigazio, L., (2014) Towards Deep Neural Network Architectures Robust to Adversarial Examples, , arXiv preprint; Song, Y., Kim, T., Nowozin, S., Ermon, S., Kushman, N., PixelDefend: Leveraging generative models to understand and defend against adversarial examples (2018) International Conference on Learning Representations; Samangouei, P., Kabkab, M., Chellappa, R., (2018) Defense-Gan: Protecting Classifiers Against Adversarial Attacks Using Generative Models; Cisse, M., Bojanowski, P., Grave, E., Dauphin, Y., Usunier, N., Parseval networks: Improving robustness to adversarial examples (2017) International Conference on Machine Learning, pp. 854-863; Raghunathan, A., Steinhardt, J., Liang, P., Certified defenses against adversarial examples (2018) International Conference on Learning Representations; Zico Kolter, J., Wong, E., (2017) Provable Defenses Against Adversarial Examples Via the Convex Outer Adversarial Polytope, , arXiv preprint; Brown, T.B., Mané, D., Roy, A., Abadi, M., Gilmer, J., (2017) Adversarial Patch, , arXiv preprint; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, pp. 2672-2680; Odena, A., Olah, C., Shlens, J., Conditional image synthesis with auxiliary classifier gans (2017) International Conference on Machine Learning, pp. 2642-2651; Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., Courville, A.C., Improved training of wasserstein gans (2017) Advances in Neural Information Processing Systems, pp. 5769-5779; Buhrmester, M., Kwang, T., Gosling, S.D., Amazon's mechanical turk: A new source of inexpensive, yet high-quality, data? (2011) Perspectives on Psychological Science, 6 (1), pp. 3-5; Xiao, C., Li, B., Zhu, J.-Y., He, W., Liu, M., Song, D., (2018) Generating Adversarial Examples with Adversarial Networks, , arXiv preprint; Brown, T.B., Carlini, N., Zhang, C., Olsson, C., Christiano, P., Goodfellow, I., (2018) Unrestricted Adversarial Examples, , arXiv preprint; LeCun, Y., Boser, B., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W., Jackel, L.D., Backpropagation applied to handwritten zip code recognition (1989) Neural Computation, 1 (4), pp. 541-551; Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., Ng, A.Y., Reading digits in natural images with unsupervised feature learning (2011) NIPS Workshop on Deep Learning and Unsupervised Feature Learning, 2011, p. 5; Liu, Z., Luo, P., Wang, X., Tang, X., Deep learning face attributes in the wild (2015) Proceedings of International Conference on Computer Vision (ICCV); Nocedal, J., Updating quasi-Newton matrices with limited storage (1980) Mathematics of Computation, 35 (151), pp. 773-782; Dezfooli, S.M.M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , number EPFL-CONF-218057; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium on, pp. 39-57; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) International Conference on Learning Representations; Athalye, A., Carlini, N., Wagner, D., (2018) Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples, , arXiv preprint; Arjovsky, M., Chintala, S., Bottou, L., (2017) Wasserstein Gan, , arXiv preprint; Grover, A., Dhar, M., Ermon, S., Flow-GaN: Combining maximum likelihood and adversarial learning in generative models (2018) AAAI Conference on Artificial Intelligence; Song, J., Ren, H., Sadigh, D., Ermon, S., (2018) Multi-Agent Generative Adversarial Imitation Learning; Xiao, H., Rasul, K., Vollgraf, R., (2017) Fashion-Mnist: A Novel Image Dataset for Benchmarking Machine Learning Algorithms, , arXiv preprint; Krizhevsky, A., (2009) Learning Multiple Layers of Features from Tiny Images; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Mnist Adversarial Examples Challenge; Van Der Maaten, L., Hinton, G., Visualizing data using t-sne (2008) Journal of Machine Learning Research, 9, pp. 2579-2605; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540; Fawzi, A., Frossard, P., Measuring the effect of nuisance variables on classifiers (2016) British Machine Vision Conference (BMVC), , number EPFL-CONF-220613; Hosseini, H., Poovendran, R., (2018) Semantic Adversarial Examples, , arXiv preprint; Zhao, Z., Dua, D., Singh, S., Generating natural adversarial examples (2018) International Conference on Learning Representations; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 427-436; Anderson, H.S., Woodbridge, J., Filar, B., DeepDGA: Adversarially-tuned domain generation and detection (2016) Proceedings of the 2016 ACM Workshop on Artificial Intelligence and Security, pp. 13-21; Baluja, S., Fischer, I., (2017) Adversarial Transformation Networks: Learning to Generate Adversarial Examples, , arXiv preprint; Lee, H., Han, S., Lee, J., (2017) Generative Adversarial Trainer: Defense to Adversarial Perturbations with Gan, , arXiv preprint; Shimodaira, H., Improving predictive inference under covariate shift by weighting the log-likelihood function (2000) Journal of Statistical Planning and Inference, 90 (2), pp. 227-244; Vapnik, V., The nature of statistical learning theory (2013) Springer Science & Business Media; Shu, R., Bui, H.H., Narui, H., Ermon, S., A DIRT-T approach to unsupervised domain adaptation (2018) International Conference on Learning Representations; Tao, T., (2012) Topics in Random Matrix Theory, 132. , American Mathematical Soc; Rigollet, P., High-dimensional statistics (2015) Lecture Notes for Course 18S997",,"Bengio S.Larochelle H.Grauman K.Cesa-Bianchi N.Wallach H.Grauman K.Garnett R.",,"Neural information processing systems foundation","32nd Conference on Neural Information Processing Systems, NeurIPS 2018","2 December 2018 through 8 December 2018",,147412,10495258,,,,"English","Adv. neural inf. proces. syst.",Conference Paper,"Final","",Scopus,2-s2.0-85064836449
"Bafna M., Murtagh J., Vyas N.","57193310824;57031526800;57188557129;","Thwarting adversarial examples: An l0-robust sparse Fourier transform",2018,"Advances in Neural Information Processing Systems","2018-December",,,"10075","10085",,13,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064832864&partnerID=40&md5=77a79a69d290fe8a57c32e1d45d1dda2","School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, United States; Department of Electrical Engineering and Computer Science, MIT, Cambridge, MA, United States","Bafna, M., School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, United States; Murtagh, J., School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, United States; Vyas, N., Department of Electrical Engineering and Computer Science, MIT, Cambridge, MA, United States","We give a new algorithm for approximating the Discrete Fourier transform of an approximately sparse signal that has been corrupted by worst-case L0 noise, namely a bounded number of coordinates of the signal have been corrupted arbitrarily. Our techniques generalize to a wide range of linear transformations that are used in data analysis such as the Discrete Cosine and Sine transforms, the Hadamard transform, and their high-dimensional analogs. We use our algorithm to successfully defend against well known L0 adversaries in the setting of image classification. We give experimental results on the Jacobian-based Saliency Map Attack (JSMA) and the Carlini Wagner (CW) L0 attack on the MNIST and Fashion-MNIST datasets as well as the Adversarial Patch on the ImageNet dataset. © 2018 Curran Associates Inc.All rights reserved.",,"Cosine transforms; Discrete Fourier transforms; Hadamard transforms; Discrete cosines; High-dimensional; Jacobians; Saliency map; Sine transforms; Sparse signals; Linear transformations",,,,,"Baraniuk, R.G., Cevher, V., Duarte, M.F., Hegde, C., Model-based compressive sensing (2010) IEEE Trans. Information Theory, 56 (4), pp. 1982-2001. , BCDH10; Blumensath, T., Davies, M.E., Iterative hard thresholding for compressed sensing (2008) CoRR, , BD08 abs/0805.0510; Backurs, A., Indyk, P., Schmidt, L., Better approximations for tree sparsity in nearly-linear time (2017) Proceedings of the Twenty-Eighth Annual ACM-SIAM Symposium on Discrete Algorithms, SODA 2017, pp. 2215-2229. , BIS17 Barcelona, Spain, Hotel Porta Fira, January 16-19; Brown, T.B., Mané, D., Roy, A., Abadi, M., Gilmer, J., Adversarial patch (2017) CoRR, , BMR+17 abs/1712.09665; Candès, E.J., Li, X., Ma, Y., Wright, J., Robust principal component analysis? (2011) J. ACM, 58 (3), pp. 111-1137. , CLMW11; Candès, E.J., Romberg, J.K., Tao, T., Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency information (2006) IEEE Trans. Information Theory, 52 (2), pp. 489-509. , CRT06; Carlini, N., Wagner, D.A., Towards evaluating the robustness of neural networks (2016) CoRR, , CW16 abs/1608.04644; Evtimov, I., Eykholt, K., Fernandes, E., Kohno, T., Li, B., Prakash, A., Rahmati, A., Song, D., Robust physical-world attacks on machine learning models (2017) CoRR, , EEF+17 abs/1707.08945; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations, , GSS15; Hassanieh, H., Indyk, P., Katabi, D., Price, E., Nearly optimal sparse fourier transform (2012) Proceedings of the 44th Symposium on Theory of Computing Conference, STOC 2012, pp. 563-578. , HIKP12a New York, NY, USA, May 19 22, 2012; Hassanieh, H., Indyk, P., Katabi, D., Price, E., Simple and practical algorithm for sparse fourier transform (2012) Proceedings of the Twenty-Third Annual ACM-SIAM Symposium on Discrete Algorithms, SODA 2012, pp. 1183-1194. , HIKP12b Kyoto, Japan, January 17-19, 2012; Hegde, C., Indyk, P., Schmidt, L., Nearly linear-time model-based compressive sensing (2014) Automata, Languages, and Programming - 41st International Colloquium, ICALP 2014, pp. 588-599. , HIS14 Copenhagen, Denmark, July 8-11, 2014, Proceedings, Part I; Hegde, C., Indyk, P., Schmidt, L., Approximation algorithms for model-based compressive sensing (2015) IEEE Trans. Information Theory, 61 (9), pp. 5129-5147. , HIS15; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2015) CoRR, , HZRS15 abs/1512.03385; Indyk, P., Kapralov, M., Price, E., (Nearly) sample-optimal sparse Fourier transform (2014) Proceedings of the Twenty-Fifth Annual ACM-SIAM Symposium on Discrete Algorithms, SODA 2014, pp. 480-499. , IKP14 Portland, Oregon, USA, January 5-7, 2014; LeCun, Y., (1998) The Mnist Database of Handwritten Digits, , http://yann.lecun.com/exdb/mnist/, LeC98; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2015) CoRR, , MFF15 abs/1511.04599; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2017) CoRR, , MMS+17 abs/1706.06083; Needell, D., Tropp, J.A., (2008) Cosamp: Iterative Signal Recovery from Incomplete and Inaccurate Samples, , NT08 arXiv preprint; Papernot, N., McDaniel, P.D., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2015) CoRR, , PMJ+15 abs/1511.07528; Papernot, N., McDaniel, P.D., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) IEEE Symposium on Security and Privacy, SP 2016, pp. 582-597. , PMW+16 San Jose, CA, USA, May 22-26, 2016; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540. , SBBR16 ACM; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R., Intriguing properties of neural networks (2013) CoRR, , SZS+13 abs/1312.6199; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses, , TKP+17 arXiv preprint; Xiao, H., Rasul, K., Vollgraf, R., Fashion-mnist: A novel image dataset for benchmarking machine learning algorithms (2017) CoRR, , XRV17 abs/1708.07747",,"Bengio S.Grauman K.Cesa-Bianchi N.Grauman K.Garnett R.Wallach H.Larochelle H.",,"Neural information processing systems foundation","32nd Conference on Neural Information Processing Systems, NeurIPS 2018","2 December 2018 through 8 December 2018",,147412,10495258,,,,"English","Adv. neural inf. proces. syst.",Conference Paper,"Final","",Scopus,2-s2.0-85064832864
"Hayes J., Ohrimenko O.","57192153560;23398171400;","Contamination attacks and mitigation in multi-party machine learning",2018,"Advances in Neural Information Processing Systems","2018-December",,,"6604","6615",,22,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064832142&partnerID=40&md5=9b9140bfd9fd0f61ccf0665ee547ff59","Univeristy College, London, United Kingdom; Microsoft Research, United States","Hayes, J., Univeristy College, London, United Kingdom; Ohrimenko, O., Microsoft Research, United States","Machine learning is data hungry; the more data a model has access to in training, the more likely it is to perform well at inference time. Distinct parties may want to combine their local data to gain the benefits of a model trained on a large corpus of data. We consider such a case: parties get access to the model trained on their joint data but do not see each others individual datasets. We show that one needs to be careful when using this multi-party model since a potentially malicious party can taint the model by providing contaminated data. We then show how adversarial training can defend against such attacks by preventing the model from learning trends specific to individual parties data, thereby also guaranteeing party-level membership privacy. © 2018 Curran Associates Inc.All rights reserved.",,"Large corpora; Local data; Machine learning",,,,,"Abadi, M., Chu, A., Goodfellow, I., McMahan, H.B., Mironov, I., Talwar, K., Zhang, L., Deep learning with differential privacy (2016) ACM Conference on Computer and Communications Security (CCS), pp. 308-318; Alfeld, S., Zhu, X., Barford, P., Data poisoning attacks against autoregressive models (2016) Association for the Advancement of Artificial Intelligence (AAAI), pp. 1452-1458; Allen, J., Ding, B., Kulkarni, J., Nori, H., Ohrimenko, O., Yekhanin, S., (2018) An Algorithmic Framework for Differentially Private Data Analysis on Trusted Processors, , CoRR, abs/1807.00736; Biggio, B., Nelson, B., Laskov, P., Poisoning attacks against support vector machines (2012) International Conference on Machine Learning (ICML), pp. 1467-1474; Bittau, A., Erlingsson, U., Maniatis, P., Mironov, I., Raghunathan, A., Lie, D., Rudominer, M., Seefeld, B., Prochlo: Strong privacy for analytics in the crowd (2017) ACM Symposium on Operating Systems Principles (SOSP); Bonawitz, K., Ivanov, V., Kreuter, B., Marcedone, A., McMahan, H.B., Patel, S., Ramage, D., Seth, K., Practical secure aggregation for privacy-preserving machine learning (2017) ACM Conference on Computer and Communications Security (CCS), pp. 1175-1191; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy (S&P), pp. 39-57; Chen, X., Liu, C., Li, B., Lu, K., Song, D., (2017) Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning, , arXiv preprint; Dwork, C., Hardt, M., Pitassi, T., Reingold, O., Zemel, R., Fairness through awareness (2012) Conference on Innovations in Theoretical Computer Science Conference (ITCS); Edwards, H., Storkey, A., Censoring representations with an adversary (2016) International Conference on Learning Representations (ICLR), , 2; Gilad-Bachrach, R., Dowlin, N., Laine, K., Lauter, K., Naehrig, M., Wernsing, J., Cryptonets: Applying neural networks to encrypted data with high throughput and accuracy (2016) International Conference on Machine Learning (ICML), pp. 201-210; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Conference on Neural Information Processing Systems (NIPS), pp. 2672-2680; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint; Gu, T., Dolan-Gavitt, B., Garg, S., (2017) Badnets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain, , arXiv preprint; Hamm, J., Minimax filter: Learning to preserve privacy from inference attacks (2017) Journal of Machine Learning Research, 18, pp. 1291-12931; Hamm, J., Cao, P., Belkin, M., Learning privately from multiparty data (2016) International Conference on Machine Learning (ICML), pp. 555-563; Hayes, J., Melis, L., Danezis, G., De Cristofaro, E., Membership inference attacks against generative models (2018) Proceedings on Privacy Enhancing Technologies (PoPETs); Hesamifard, E., Takabi, H., Ghasemi, M., Wright, R.N., Privacy-preserving machine learning as a service (2018) Proceedings on Privacy Enhancing Technologies (PoPETs), (3), pp. 123-142. , 2018; Hitaj, B., Ateniese, G., Perez-Cruz, F., Deep models under the GaN: Information leakage from collaborative deep learning (2017) ACM Conference on Computer and Communications Security (CCS), pp. 603-618; Hoekstra, M., Lal, R., Pappachan, P., Rozas, C., Phegade, V., Del Cuvillo, J., Using innovative instructions to create trustworthy software solutions (2013) Workshop on Hardware and Architectural Support for Security and Privacy (HASP); Jagielski, M., Oprea, A., Biggio, B., Liu, C., Nita-Rotaru, C., Li, B., Manipulating machine learning: Poisoning attacks and countermeasures for regression learning (2018) IEEE Symposium on Security and Privacy (S&P), pp. 19-35; Kim, Y., Convolutional neural networks for sentence classification (2014) Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 1746-1751; Koh, P.W., Liang, P., Understanding black-box predictions via influence functions (2017) International Conference on Machine Learning (ICML), pp. 1885-1894; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint; Long, Y., Bindschaedler, V., Wang, L., Bu, D., Wang, X., Tang, H., Gunter, C.A., Chen, K., (2018) Understanding Membership Inferences on Well-Generalized Learning Models, , arXiv preprint; Louppe, G., Kagan, M., Cranmer, K., Learning to pivot with adversarial networks (2017) Conference on Neural Information Processing Systems (NIPS), pp. 982-991; McMahan, H.B., Moore, E., Ramage, D., Y Arcas, B.A., (2016) Federated Learning of Deep Networks Using Model Averaging, , CoRR, abs/1602.05629; McMahan, H.B., Ramage, D., Talwar, K., Zhang, L., Learning differentially private recurrent language models (2018) International Conference on Learning Representations (ICLR); Mohassel, P., Zhang, Y., SecureML: A system for scalable privacy-preserving machine learning (2017) IEEE Symposium on Security and Privacy (S&P), pp. 19-38; Moosavi-Dezfooli, S., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2574-2582; Nasr, M., Shokri, R., Houmansadr, A., Machine learning with membership privacy using adversarial regularization (2018) ACM Conference on Computer and Communications Security (CCS), pp. 634-646; Nikolaenko, V., Ioannidis, S., Weinsberg, U., Joye, M., Taft, N., Boneh, D., Privacy-preserving matrix factorization (2013) ACM Conference on Computer and Communications Security (CCS), pp. 801-812; Ohrimenko, O., Schuster, F., Fournet, C., Mehta, A., Nowozin, S., Vaswani, K., Costa, M., Oblivious multi-party machine learning on trusted processors (2016) USENIX Security Symposium, pp. 619-636; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) IEEE European Symposium on Security and Privacy (EuroS&P), pp. 372-387; Pathak, M.A., Rane, S., Raj, B., Multiparty differential privacy via aggregation of locally trained classifiers (2010) Conference on Neural Information Processing Systems (NIPS), pp. 1876-1884; Rajkumar, A., Agarwal, S., A differentially private stochastic gradient descent algorithm for multiparty classification (2012) Conference on Artificial Intelligence and Statistics (AISTATS), pp. 933-941; Schuster, F., Costa, M., Fournet, C., Gkantsidis, C., Peinado, M., Mainar-Ruiz, G., Russinovich, M., V C3: Trustworthy data analytics in the cloud using SGX (2015) IEEE Symposium on Security and Privacy (S&P), pp. 38-54; Shen, S., Tople, S., Saxena, P., Auror: Defending against poisoning attacks in collaborative deep learning systems (2016) Conference on Computer Security Applications (ACSAC), pp. 508-519; Shokri, R., Shmatikov, V., Privacy-preserving deep learning (2015) ACM Conference on Computer and Communications Security (CCS), pp. 1310-1321; Shokri, R., Stronati, M., Song, C., Shmatikov, V., Membership inference attacks against machine learning models (2017) IEEE Symposium on Security and Privacy (S&P), pp. 3-18; Song, C., Ristenpart, T., Shmatikov, V., Machine learning models that remember too much (2017) ACM Conference on Computer and Communications Security (CCS), pp. 587-601; Xiao, H., Biggio, B., Brown, G., Fumera, G., Eckert, C., Roli, F., Is feature selection secure against training data poisoning? (2015) International Conference on Machine Learning (ICML), pp. 1689-1698; Xiao, H., Biggio, B., Nelson, B., Xiao, H., Eckert, C., Roli, F., Support vector machines under adversarial label contamination (2015) Neurocomputing, 160, pp. 53-62; Zafar, M.B., Valera, I., Gomez-Rodriguez, M., Gummadi, K.P., Fairness constraints: Mechanisms for fair classification (2017) Conference on Artificial Intelligence and Statistics (AISTATS), pp. 962-970; Zemel, R.S., Wu, Y., Swersky, K., Pitassi, T., Dwork, C., Learning fair representations (2013) International Conference on Machine Learning (ICML), pp. 325-333",,"Cesa-Bianchi N.Grauman K.Grauman K.Wallach H.Garnett R.Bengio S.Larochelle H.",,"Neural information processing systems foundation","32nd Conference on Neural Information Processing Systems, NeurIPS 2018","2 December 2018 through 8 December 2018",,147412,10495258,,,,"English","Adv. neural inf. proces. syst.",Conference Paper,"Final","",Scopus,2-s2.0-85064832142
"Ye N., Zhu Z.","57202057254;57200340512;","Bayesian adversarial learning",2018,"Advances in Neural Information Processing Systems","2018-December",,,"6892","6901",,10,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064827140&partnerID=40&md5=ffa6f0ba3126aade03d9e002fa0e8127","University of Cambridge, Cambridge, United Kingdom; Center for Data Science, Peking University Beijing Institute of Big Data Research (BIBDR), Beijing, China","Ye, N., University of Cambridge, Cambridge, United Kingdom; Zhu, Z., Center for Data Science, Peking University Beijing Institute of Big Data Research (BIBDR), Beijing, China","Deep neural networks have been known to be vulnerable to adversarial attacks, raising lots of security concerns in the practical deployment. Popular defensive approaches can be formulated as a (distributionally) robust optimization problem, which minimizes a ""point estimate"" of worst-case loss derived from either per-datum perturbation or adversary data-generating distribution within certain predefined constraints. This point estimate ignores potential test adversaries that are beyond the pre-defined constraints. The model robustness might deteriorate sharply in the scenario of stronger test adversarial data, fn this work, a novel robust training framework is proposed to alleviate this issue, Bayesian Robust Learning, in which a distribution is put on the adversarial data-generating distribution to account for the uncertainty of the adversarial data-generating process. The uncertainty directly helps to consider the potential adversaries that are stronger than the point estimate in the cases of distributionally robust optimization. The uncertainty of model parameters is also incorporated to accommodate the full Bayesian framework. We design a scalable Markov Chain Monte Carlo sampling strategy to obtain the posterior distribution over model parameters. Various experiments are conducted to verify the superiority of BAL over existing adversarial training methods. The code for BAL is available at h t t p s: / / t i n y u r l . com/yexsaewr. © 2018 Curran Associates Inc.All rights reserved.",,"Deep neural networks; Markov processes; Monte Carlo methods; Optimization; Uncertainty analysis; Adversarial learning; Bayesian frameworks; Markov chain monte carlo samplings; Model robustness; Posterior distributions; Robust optimization; Robust trainings; Training methods; Statistical tests",,,,,"Akhtar, N., Mian, A., (2018) Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey, , arXiv preprint; Ben-Tal, A., Nemirovski, A., Robust convex optimization (1998) Mathematics of Operations Research, 23 (4), pp. 769-805; Briickner, M., Kanzow, C., Scheffer, T., Static prediction games for adversarial learning problems (2012) Journal of Machine Learning Research, 13, pp. 2617-2654. , Sep; Bule, S.R., Biggio, B., Pillai, I., Pelillo, M., Roli, F., Randomized prediction games for adversarial machine learning (2017) IEEE Transactions on Neural Networks and Learning Systems, 28 (11), pp. 2466-2478; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium on, pp. 39-57. , IEEE; Chen, T., Fox, E., Guestrin, C., Stochastic gradient Hamiltonian Monte Carlo (2014) International Conference on Machine Learning, pp. 1683-1691; Delage, E., Ye, Y., Distributionally robust optimization under moment uncertainty with application to data-driven problems (2010) Operations Research, 58 (3), pp. 595-612; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint; GroBhans, M., Sawade, C., Bruckner, M., Scheffer, T., Bayesian games for adversarial regression problems (2013) International Conference on Machine Learning, pp. 55-63; He, W., Wei, J., Chen, X., Carlini, N., Song, D., (2017) Adversarial Example Defenses: Ensembles of Weak Defenses Are Not Strong, , arXiv preprint; Jaderberg, M., Simonyan, K., Zisserman, A., Kavukcuoglu, K., Spatial transformer networks (2015) Advances in Neural Information Processing Systems, 28, pp. 2017-2025. , C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors, Curran Associates, Inc; Kingma, D.P., Welling, M., Auto-encoding variational Bayes (2014) International Conference on Learning Representations; Zico Kolter, J., Wong, E., (2017) Provable Defenses Against Adversarial Examples Via the Convex Outer Adversarial Polytope, , arXiv preprint; Kos, J., Fischer, I., Song, D., (2017) Adversarial Examples for Generative Models, , arXiv preprint; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Machine Learning at Scale, , arXiv preprint; Lindbo Larsen, A.B., Sonderby, S.K., Larochelle, H., Winther, O., Autoencoding beyond pixels using a learned similarity metric (2016) International Conference on Machine Learning, pp. 1558-1566; MacKay, D.J.C., A practical Bayesian framework for backpropagation networks (1992) Neural Computation, 4 (3), pp. 448-472; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , arXiv preprint; Ritter, H., Botev, A., Barber, D., A scalable laplace approximation for neural networks (2018) International Conference on Learning Representations; Saatci, Y., Wilson, A.G., Bayesian gan (2017) Advances in Neural Information Processing Systems, 30, pp. 3622-3631. , I. Guyon, U. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, Curran Associates, Inc; Shaham, U., Yamada, Y., Negahban, S., (2015) Understanding Adversarial Training: Increasing Local Stability of Neural Nets Through Robust Optimization, , arXiv preprint; Sinha, A., Namkoong, H., Duchi, J., Certifying some distributional robustness with principled adversarial training (2018) International Conference on Learning Representations; Springenberg, J.T., Klein, A., Falkner, S., Hutter, F., Bayesian optimization with robust Bayesian neural networks (2016) Advances in Neural Information Processing Systems, 29, pp. 4134-4142. , D. D. Lee, M. Sugiyama, U. Luxburg, I. Guyon, and R. Garnett, editors, Curran Associates, Inc; Stallkamp, J., Schlipsing, M., Salmen, J., Igel, C., Man vs. Computer: Benchmarking machine learning algorithms for traffic sign recognition (2012) Neural Networks, , 0; Szegedy, C., Zaremba, W., Sutskever, D., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint; Tramer, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., (2011) Ensemble Adversarial Training: Attacks and Defenses, , arXiv preprint; Welling, M., Teh, Y.W., Bayesian learning via stochastic gradient langevin dynamics (2011) ICML, pp. 681-688. , Lise Getoor and Tobias Scheffer, editors, Omnipress; Xiao, C., Li, B., Zhu, J.-Y., He, W., Liu, M., Song, D., (2018) Generating Adversarial Examples with Adversarial Networks, , arXiv preprint; Xiao, C., Zhu, J.-Y., Li, B., He, W., Liu, M., Song, D., Spatially transformed adversarial examples (2018) International Conference on Learning Representations; Xiao, H., Rasul, K., Vollgraf, R., (2017) Fashion-Mnist: A Novel Image Dataset for Benchmarking Machine Learning Algorithms, , CoRR, abs/1708.07747","Zhu, Z.; Center for Data Science, China; email: zhanxing.zhu@pku.edu.en","Garnett R.Larochelle H.Grauman K.Bengio S.Wallach H.Cesa-Bianchi N.Grauman K.",,"Neural information processing systems foundation","32nd Conference on Neural Information Processing Systems, NeurIPS 2018","2 December 2018 through 8 December 2018",,147412,10495258,,,,"English","Adv. neural inf. proces. syst.",Conference Paper,"Final","",Scopus,2-s2.0-85064827140
"Orhan E.","57208437595;","A simple cache model for image recognition",2018,"Advances in Neural Information Processing Systems","2018-December",,,"10107","10116",,2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064825071&partnerID=40&md5=f4356879ea22b4884faf7c2a9cec3c85","Baylor College of Medicine, New York University, United States","Orhan, E., Baylor College of Medicine, New York University, United States","Training large-scale image recognition models is computationally expensive. This raises the question of whether there might be simple ways to improve the test performance of an already trained model without having to re-train or fine-tune it with new data. Here, we show that, surprisingly, this is indeed possible. The key observation we make is that the layers of a deep network close to the output layer contain independent, easily extractable class-relevant information that is not contained in the output layer itself. We propose to extract this extra class-relevant information using a simple key-value cache memory to improve the classification performance of the model at test time. Our cache memory is directly inspired by a similar cache model previously proposed for language modeling (Grave et al., 2017). This cache component does not require any training or fine-tuning; it can be applied to any pre-trained model and, by properly setting only two hyper-parameters, leads to significant improvements in its classification performance. Improvements are observed across several architectures and datasets. In the cache component, using features extracted from layers close to the output (but not from the output layer itself) as keys leads to the largest improvements. Concatenating features from multiple layers to form keys can further improve performance over using single-layer features as keys. The cache component also has a regularizing effect, a simple consequence of which is that it substantially increases the robustness of models against adversarial attacks. © 2018 Curran Associates Inc.All rights reserved.",,"Classification (of information); Image recognition; Modeling languages; Classification performance; Hyper-parameter; Image-recognition model; Improve performance; Language model; Multiple layers; Robustness of model; Test performance; Cache memory",,,,,"Candès, E., Tao, T., Near-optimal signal recovery from random projections: Universal encoding strategies? (2006) IEEE Trans Inf Theory, 52, pp. 5406-5425; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Grave, E., Joulin, A., Usunier, N., Improving neural language models with a continuous cache (2017) ICLR 2017; Grave, E., Cisse, M., Joulin, A., Unbounded cache model for online language modeling with open vocabulary (2017) NIPS 2017; He, K., Zhang, X., Ren, S., Sun, J., (2015) Deep Residual Learning for Image Recognition; He, K., Zhang, X., Ren, S., Sun, J., (2016) Identity Mappings in Deep Residual Networks; Huang, G., Liu, Z., Weinberger, K.Q., Van Der Maaten, L., Densely connected convolutional networks (2016) CVPR 2017; Kaiser, L., Nachum, O., Roy, A., Bengio, S., Learning to remember rare events (2017) ICLR 2017; Kurakin, A., Goodfellow, I.J., Bengio, S., (2016) Adversarial Examples in the Physical World; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2015) CVPR 2016; Novak, R., Bahri, Y., Abolafia, D.A., Pennington, J., Sohl-Dickstein, Sensitivity and generalization in neural networks: An empirical study (2018) ICLR 2018; Papernot, N., McDaniel, P., (2018) Deep K-Nearest Neighbors: Towards Confident, Interpretable and Robust Deep Learning; Pritzel, A., Neural episodic control (2017) ICML 2017; Rauber, J., Brendel, W., Bethge, M., (2017) Foolbox: A Python Toolbox to Benchmark the Robustness of Machine Learning Models; Su, J., Vargas, V., Kouichi, S., (2017) One Pixel Attack for Fooling Deep Neural Networks; Wang, Y., Jha, S., Chaudhuri, K., Analyzing the robustness of nearest neighbors to adversarial examples (2018) ICML 2018; Zhang, H., Cisse, M., Dauphin, Y., Lopez-Paz, D., MixUp: Beyond empirical risk minimization (2017) ICLR 2018; Zhao, J., Cho, K., (2018) Retrieval-Augmented Convolutional Neural Networks for Improved Robustness Against Adversarial Examples","Orhan, E.; Baylor College of Medicine, United States; email: aeminorhan@gmail.com","Bengio S.Grauman K.Cesa-Bianchi N.Garnett R.Larochelle H.Wallach H.Grauman K.",,"Neural information processing systems foundation","32nd Conference on Neural Information Processing Systems, NeurIPS 2018","2 December 2018 through 8 December 2018",,147412,10495258,,,,"English","Adv. neural inf. proces. syst.",Conference Paper,"Final","",Scopus,2-s2.0-85064825071
"Lee K., Lee K., Lee H., Shin J.","57190815749;57192165991;15056237200;55834885800;","A simple unified framework for detecting out-of-distribution samples and adversarial attacks",2018,"Advances in Neural Information Processing Systems","2018-December",,,"7167","7177",,234,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064822451&partnerID=40&md5=ed7d4489422d4e8f072fb9146ddf8761","Korea Advanced Institute of Science and Technology (KAIST), South Korea; University of Michigan, United States; Google Brain, United States; AItrics, South Korea","Lee, K., Korea Advanced Institute of Science and Technology (KAIST), South Korea; Lee, K., University of Michigan, United States; Lee, H., University of Michigan, United States, Google Brain, United States; Shin, J., Korea Advanced Institute of Science and Technology (KAIST), South Korea, AItrics, South Korea","Detecting test samples drawn sufficiently far away from the training distribution statistically or adversarially is a fundamental requirement for deploying a good classifier in many real-world machine learning applications. However, deep neural networks with the softmax classifier are known to produce highly overconfident posterior distributions even for such abnormal samples. In this paper, we propose a simple yet effective method for detecting any abnormal samples, which is applicable to any pre-trained softmax neural classifier. We obtain the class conditional Gaussian distributions with respect to (low- and upper-level) features of the deep models under Gaussian discriminant analysis, which result in a confidence score based on the Mahalanobis distance. While most prior methods have been evaluated for detecting either out-of-distribution or adversarial samples, but not both, the proposed method achieves the state-of-the-art performances for both cases in our experiments. Moreover, we found that our proposed method is more robust in harsh cases, e.g., when the training dataset has noisy labels or small number of samples. Finally, we show that the proposed method enjoys broader usage by applying it to class-incremental learning: whenever out-of-distribution samples are detected, our classification rule can incorporate new classes well without further training deep models. © 2018 Curran Associates Inc.All rights reserved.",,"Discriminant analysis; Human computer interaction; Knowledge engineering; Neural networks; Classification rules; Conditional Gaussian distribution; Incremental learning; Machine learning applications; Mahalanobis distances; Neural classifiers; Posterior distributions; State-of-the-art performance; Deep neural networks",,,,,"Amodei, D., Ananthanarayanan, S., Anubhai, R., Bai, J., Battenberg, E., Case, C., Casper, J., Chen, G., Deep speech 2: End-to-end speech recognition in english and Mandarin (2016) ICML; Amodei, D., Olah, C., Steinhardt, J., Christiano, P., Schulman, J., Mané, D., (2016) Concrete Problems in Ai Safety, , arXiv preprint; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) ACM Workshop on AISec; Chrabaszcz, P., Loshchilov, I., Hutter, F., (2017) A Downsampled Variant of Imagenet as an Alternative to the Cifar Datasets, , arXiv preprint; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., ImageNet: A large-scale hierarchical image database (2009) CVPR; Evtimov, I., Eykholt, K., Fernandes, E., Kohno, T., Li, B., Prakash, A., Rahmati, A., Song, D., Robust physical-world attacks on machine learning models (2018) CVPR; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts, , arXiv preprint; Gal, Y., Islam, R., Ghahramani, Z., Deep Bayesian active learning with image data (2017) ICML; Girshick, R., Fast R-CNn (2015) ICCV; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR; Guo, C., Rana, M., Cissé, M., Van Der Maaten, L., (2017) Countering Adversarial Images Using Input Transformations, , arXiv preprint; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) CVPR; Hendrycks, D., Gimpel, K., A baseline for detecting misclassified and out-of-distribution examples in neural networks (2017) ICLR; Huang, G., Liu, Z., Densely connected convolutional networks (2017) CVPR; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint; Lasserre, J.A., Bishop, C.M., Minka, T.P., Principled hybrids of generative and discriminative models (2006) CVPR; Lee, K., Lee, K., Min, K., Zhang, Y., Shin, J., Lee, H., Hierarchical novelty detection for visual object recognition (2018) CVPR; Lee, K., Hwang, C., Park, K., Shin, J., Confident multiple choice learning (2017) ICML; Lee, K., Lee, H., Lee, K., Shin, J., Training confidence-calibrated classifiers for detecting out-of-distribution samples (2018) ICLR; Liang, S., Li, Y., Srikant, R., Principled detection of out-of-distribution examples in neural networks (2018) ICLR; Ma, X., Li, B., Wang, Y., Erfani, S.M., Wijewickrema, S., Houle, M.E., Schoenebeck, G., Bailey, J., Characterizing adversarial subspaces using local intrinsic dimensionality (2018) ICLR; Maaten, L.V.D., Hinton, G., Visualizing data using t-sne (2008) Journal of Machine Learning Research; McCloskey, M., Cohen, N.J., Catastrophic interference in connectionist networks: The sequential learning problem (1989) Psychology of Learning and Motivation, , Elsevier; Mensink, T., Verbeek, J., Perronnin, F., Csurka, G., Distance-based image classification: Generalizing to new classes at near-zero cost (2013) IEEE Transactions on Pattern Analysis and Machine Intelligence; Dezfooli, M., Mohsen, S., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) CVPR; Murphy, K.P., (2012) Machine Learning: A Probabilistic Perspective; Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., Ng, A.Y., Reading digits in natural images with unsupervised feature learning (2011) NIPS Workshop; Rebuffi, Sylvestre-Alvise, Kolesnikov, A., ICARL: Incremental classifier and representation learning (2017) CVPR; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) ACM SIGSAC; Vinyals, O., Blundell, C., Lillicrap, T., Wierstra, D., Matching networks for one shot learning (2016) NIPS; Yu, F., Seff, A., Zhang, Y., Song, S., Funkhouser, T., Xiao, J., (2015) Lsun: Construction of a Large-Scale Image Dataset Using Deep Learning with Humans in the Loop, , arXiv preprint",,"Grauman K.Bengio S.Wallach H.Grauman K.Larochelle H.Cesa-Bianchi N.Garnett R.",,"Neural information processing systems foundation","32nd Conference on Neural Information Processing Systems, NeurIPS 2018","2 December 2018 through 8 December 2018",,147412,10495258,,,,"English","Adv. neural inf. proces. syst.",Conference Paper,"Final","",Scopus,2-s2.0-85064822451
"Jun K.-S., Ma Y., Li L., Zhu X.","36470289800;57204513838;55730767800;55696704600;","Adversarial attacks on stochastic bandits",2018,"Advances in Neural Information Processing Systems","2018-December",,,"3640","3649",,23,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064820089&partnerID=40&md5=4b873c149c83fd1a2ca84eab0b7c9a04","Boston University, United States; UW-Madison, United States; Google Brain, United States","Jun, K.-S., Boston University, United States; Ma, Y., UW-Madison, United States; Li, L., Google Brain, United States; Zhu, X., UW-Madison, United States","We study adversarial attacks that manipulate the reward signals to control the actions chosen by a stochastic multi-armed bandit algorithm. We propose the first attack against two popular bandit algorithms: -greedy and UCB, without knowledge of the mean rewards. The attacker is able to spend only logarithmic effort, multiplied by a problem-specific parameter that becomes smaller as the bandit problem gets easier to attack. The result means the attacker can easily hijack the behavior of the bandit algorithm to promote or obstruct certain actions, say, a particular medical treatment. As bandits are seeing increasingly wide use in practice, our study exposes a significant security threat. © 2018 Curran Associates Inc..All rights reserved.",,"Bandit problems; Medical treatment; Multi armed bandit; Security threats; Stochastic systems",,,,,"Abbasi-Yadkori, Y., Pál, D., Szepesvári, C., Improved algorithms for linear stochastic bandits (2011) Advances in Neural Information Processing Systems (NIPS), pp. 2312-2320; Agarwal, A., Hsu, D., Kale, S., Langford, J., Li, L., Schapire, R.E., Taming the monster: A fast and simple algorithm for contextual bandits (2014) Proceedings of the International Conference on Machine Learning (ICML), pp. 1638-1646; Agarwal, A., Bird, S., Cozowicz, M., Hoang, L., Langford, J., Lee, S., Li, J., Slivkins, A., (2016) Making Contextual Decisions with Low Technical Debt, , CoRR abs/1606.03966; Agrawal, S., Goyal, N., Analysis of Thompson Sampling for the Multi-armed Bandit Problem (2012) Proceedings of the Conference on Learning Theory (COLT), 23, pp. 391-3926. , In; Agrawal, S., Goyal, N., Thompson sampling for contextual bandits with linear payoffs (2013) Proceedings of the International Conference on Machine Learning (ICML), pp. 127-135; Auer, P., Cesa-Bianchi, N., Fischer, P., Finite-time analysis of the multiarmed bandit problem (2002) Machine Learning, 47 (2-3), pp. 235-256; Auer, P., Cesa-Bianchi, N., Freund, Y., Schapire, R.E., The nonstochastic multiarmed bandit problem (2002) SIAM Journal on Computing, 32 (1), pp. 48-77; Bubeck, S., Cesa-Bianchi, N., Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems (2012) Foundations and Trends in Machine Learning, 5, pp. 1-122; Chapelle, O., Manavoglu, E., Rosales, R., Simple and scalable response prediction for display advertising (2014) ACM Transactions on Intelligent Systems and Technology, 5 (4), pp. 611-6134; Dorigo, M., Colombetti, L.M., (1997) Robot Shaping: An Experiment in Behavior Engineering, , MIT Press; Even-Dar, E., Kakade, S.M., Mansour, Y., Online Markov decision processes (2009) Mathematics of Operations Research, 34 (3), pp. 726-736; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations (ICLR); Greenewald, K., Tewari, A., Murphy, S.A., Klasnja, P.V., Action centered contextual bandits (2017) Advances in Neural Information Processing Systems 30 (NIPS), pp. 5979-5987; Huang, S., Papernot, N., Goodfellow, I., Duan, Y., Abbeel, P., (2017) Adversarial Attacks on Neural Network Policies; Joseph, A.D., Nelson, B., Rubinstein, B.I.P., Tygar, J.D., (2018) Adversarial Machine Learning, , Cambridge University Press; Kuleshov, V., Precup, D., (2014) Algorithms for Multi-Armed Bandit Problems, , CoRR abs/1402.6028; Kveton, B., Szepesvári, C., Wen, Z., Ashkan, A., Cascading bandits: Learning to rank in the cascade model (2015) Proceedings of the 32nd International Conference on Machine Learning (ICML), pp. 767-776; Li, L., Chu, W., Langford, J., Schapire, R.E., A contextual-bandit approach to personalized news article recommendation (2010) Proceedings of the Nineteenth International Conference on World Wide Web (WWW), pp. 661-670; Lin, Y.-C., Hong, Z.-W., Liao, Y.-H., Shih, M.-L., Liu, M.-Y., Sun, M., Tactics of adversarial attack on deep reinforcement learning agents (2017) Proceedings of the 26th International Joint Conference on Artificial Intelligence (IJCAI), pp. 3756-3762; Lykouris, T., Mirrokni, V., Paes Leme, Stochastic bandits robust to adversarial corruptions (2018) Proceedings of the Annual ACM SIGACT Symposium on Theory of Computing (STOC), pp. 114-122; Ma, Y., Jun, K.-S., Li, L., Zhu, X., Data poisoning attacks in contextual bandits (2018) Conference on Decision and Game Theory for Security (GameSec); Ng, A.Y., Harada, D., Russell, S.J., Policy invariance under reward transformations: Theory and application to reward shaping (1999) Proceedings of the 16th International Conference on Machine Learning (ICML), pp. 278-287; Thompson, W.R., On the likelihood that one unknown probability exceeds another in view of the evidence of two samples (1933) Biometrika, 25 (3-4), p. 285; Zhu, X., (2018) An Optimal Control View of Adversarial Machine Learning",,"Wallach H.Larochelle H.Grauman K.Cesa-Bianchi N.Grauman K.Bengio S.Garnett R.",,"Neural information processing systems foundation","32nd Conference on Neural Information Processing Systems, NeurIPS 2018","2 December 2018 through 8 December 2018",,147412,10495258,,,,"English","Adv. neural inf. proces. syst.",Conference Paper,"Final","",Scopus,2-s2.0-85064820089
"Havens A.J., Jiang Z., Sarkar S.","57208443850;57188639977;55066244300;","Online robust policy learning in the presence of unknown adversaries",2018,"Advances in Neural Information Processing Systems","2018-December",,,"9916","9926",,13,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064819024&partnerID=40&md5=9e4d5894b2e7f4238d17b1ea8a366db4","Department of Mechanical Engineering, Iowa State University, Ames, IA  50011, United States","Havens, A.J., Department of Mechanical Engineering, Iowa State University, Ames, IA  50011, United States; Jiang, Z., Department of Mechanical Engineering, Iowa State University, Ames, IA  50011, United States; Sarkar, S., Department of Mechanical Engineering, Iowa State University, Ames, IA  50011, United States","The growing prospect of deep reinforcement learning (DRL) being used in cyber-physical systems has raised concerns around safety and robustness of autonomous agents. Recent work on generating adversarial attacks have shown that it is computationally feasible for a bad actor to fool a DRL policy into behaving sub optimally. Although certain adversarial attacks with specific attack models have been addressed, most studies are only interested in off-line optimization in the data space (e.g., example fitting, distillation). This paper introduces a Meta-Learned Advantage Hierarchy (MLAH) framework that is attack model-agnostic and more suited to reinforcement learning, via handling the attacks in the decision space (as opposed to data space) and directly mitigating learned bias introduced by the adversary. In MLAH, we learn separate sub-policies (nominal and adversarial) in an online manner, as guided by a supervisory master agent that detects the presence of the adversary by leveraging the advantage function for the sub-policies. We demonstrate that the proposed algorithm enables policy learning with significantly lower bias as compared to the state-of-the-art policy learning approaches even in the presence of heavy state information attacks. We present algorithm analysis and simulation results using popular OpenAI Gym environments. © 2018 Curran Associates Inc.All rights reserved.",,"Autonomous agents; Deep learning; Distillation; E-learning; Embedded systems; Machine learning; Algorithm analysis; Attack model; Data space; Decision space; Off-line optimization; Policy learning; State information; State of the art; Reinforcement learning",,,,,"Shih, C.-S., Chou, J.-J., Reijers, N., Kuo, T.-W., Designing cps/iot applications for smart buildings and cities (2016) IET Cyber-Physical Systems: Theory & Applications, 1 (1), pp. 3-12; Rawat, D.B., Bajracharya, C., Yan, G., Towards intelligent transportation cyber-physical systems: Real-time computing and communications perspectives (2015) Southeast-Con 2015, pp. 1-6. , IEEE; Antoniou, A., Angelov, P., A general purpose intelligent surveillance system for mobile devices using deep learning (2016) Neural Networks (IJCNN), 2016 International Joint Conference on, pp. 2879-2886. , IEEE; Sutton, R.S., Barto, A.G., Williams, R.J., Reinforcement learning is direct adaptive optimal control (1992) IEEE Control Systems, 12 (2), pp. 19-22; Sutton, R.S., Barto, A.G., (2017) Reinforcement Learning: An Introduction (in Preparation); Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.A., Veness, J., Bellemare, M.G., Graves, A., Ostrovski, G., Human-level control through deep reinforcement learning (2015) Nature, 518 (7540), p. 529; Mnih, V., Badia, A.P., Mirza, M., Graves, A., Lillicrap, T., Harley, T., Silver, D., Kavukcuoglu, K., Asynchronous methods for deep reinforcement learning (2016) International Conference on Machine Learning, pp. 1928-1937; Van Hasselt, H., Guez, A., Silver, D., Deep reinforcement learning with double q-learning (2016) AAAI, 16, pp. 2094-2100; Lillicrap, T.P., Hunt, J.J., Pritzel, A., Heess, N., Erez, T., Tassa, Y., Silver, D., Wierstra, D., (2015) Continuous Control with Deep Reinforcement Learning, , ArXiv e-prints, September; Levine, S., Finn, C., Darrell, T., Abbeel, P., End-to-end training of deep visuomotor policies (2016) Journal of Machine Learning Research, 17 (39), pp. 1-40; Schulman, J., Levine, S., Abbeel, P., Jordan, M., Moritz, P., Trust region policy optimization (2015) International Conference on Machine Learning, pp. 1889-1897; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , arXiv preprint; Lin, Y.-C., Liu, M.-Y., Sun, M., Huang, J.-B., (2017) Detecting Adversarial Attacks on Neural Network Policies with Visual Foresight, , ArXiv e-prints, October; Brockman, G., Cheung, V., Pettersson, L., Schneider, J., Schulman, J., Tang, J., Zaremba, W., (2016) Openai Gym; Pattanaik, A., Tang, Z., Liu, S., Bommannan, G., Chowdhary, G., (2017) Robust Deep Reinforcement Learning with Adversarial Attacks, , ArXiv e-prints, December; Pinto, L., Davidson, J., Sukthankar, R., Gupta, A., (2017) Robust Adversarial Reinforcement Learning, , ArXiv e-prints, March; Schulman, J., Wolski, F., Dhariwal, P., Radford, A., Klimov, O., (2017) Proximal Policy Optimization Algorithms, , arXiv preprint; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , ArXiv e-prints, December; Huang, S., Papernot, N., Goodfellow, I., Duan, Y., Abbeel, P., (2017) Adversarial Attacks on Neural Network Policies, , arXiv preprint; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium on, pp. 39-57. , IEEE; Kos, J., Song, D., (2017) Delving into Adversarial Attacks on Deep Policies, , arXiv preprint; Mandlekar, A., Zhu, Y., Garg, A., Fei-Fei, L., Savarese, S., Adversarially robust policy learning: Active construction of physically-plausible perturbations (2017) IEEE International Conference on Intelligent Robots and Systems, , to appear; Rajeswaran, A., Ghotra, S., Ravindran, B., Levine, S., (2016) Epopt: Learning Robust Neural Network Policies Using Model Ensembles, , arXiv preprint; Schulman, J., Moritz, P., Levine, S., Jordan, M., Abbeel, P., (2015) High-Dimensional Continuous Control Using Generalized Advantage Estimation, , ArXiv e-prints, June; Frans, K., Ho, J., Chen, X., Abbeel, P., Schulman, J., (2017) Meta Learning Shared Hierarchies, , ArXiv e-prints, October; Havens, A.J., Jiang, Z., Sarkar, S., (2018) Online Robust Policy Learning in the Presence of Unknown Adversaries, , arXiv preprint; Fox, E., Sudderth, E.B., Jordan, M.I., Willsky, A.S., Bayesian nonparametric inference of switching dynamic linear models (2011) IEEE Transactions on Signal Processing, 59 (4), pp. 1569-1585",,"Grauman K.Grauman K.Bengio S.Larochelle H.Wallach H.Garnett R.Cesa-Bianchi N.",,"Neural information processing systems foundation","32nd Conference on Neural Information Processing Systems, NeurIPS 2018","2 December 2018 through 8 December 2018",,147412,10495258,,,,"English","Adv. neural inf. proces. syst.",Conference Paper,"Final","",Scopus,2-s2.0-85064819024
"Cullina D., Bhagoji A.N., Mittal P.","55390517400;57189365305;24825217800;","PAC-learning in the presence of evasion adversaries",2018,"Advances in Neural Information Processing Systems","2018-December",,,"230","241",,18,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064817063&partnerID=40&md5=1df45bae9c48a1f407fa59507e5cb17f","Princeton University, United States","Cullina, D., Princeton University, United States; Bhagoji, A.N., Princeton University, United States; Mittal, P., Princeton University, United States","The existence of evasion attacks during the test phase of machine learning algorithms represents a significant challenge to both their deployment and understanding. These attacks can be carried out by adding imperceptible perturbations to inputs to generate adversarial examples and finding effective defenses and detectors has proven to be difficult. In this paper, we step away from the attack-defense arms race and seek to understand the limits of what can be learned in the presence of an evasion adversary. In particular, we extend the Probably Approximately Correct (PAC)-learning framework to account for the presence of an adversary. We first define corrupted hypothesis classes which arise from standard binary hypothesis classes in the presence of an evasion adversary and derive the Vapnik-Chervonenkis (VC)-dimension for these, denoted as the adversarial VC-dimension. We then show that sample complexity upper bounds from the Fundamental Theorem of Statistical learning can be extended to the case of evasion adversaries, where the sample complexity is controlled by the adversarial VC-dimension. We then explicitly derive the adversarial VC-dimension for halfspace classifiers in the presence of a sample-wise norm-constrained adversary of the type commonly studied for evasion attacks and show that it is the same as the standard VC-dimension. Finally, we prove that the adversarial VC-dimension can be either larger or smaller than the standard VC-dimension depending on the hypothesis class and adversary, making it an interesting object of study in its own right. © 2018 Curran Associates Inc..All rights reserved.",,"Learning algorithms; Binary hypothesis; Fundamental theorems; PAC learning; Probably approximately correct learning; Sample complexity; Statistical learning; Vapnik-Chervonenkis dimensions; VC dimension; Machine learning",,,,,"Abbasi, M., Gagné, C., (2017) Robustness to Adversarial Examples Through an Ensemble of Specialists, , arXiv preprint; Angluin, D., Laird, P., Learning from noisy examples (1988) Machine Learning, 2 (4), pp. 343-370; Arnab, A., Miksik, O., Torr, P.H.S., On the robustness of semantic segmentation models to adversarial attacks (2018) CVPR; Bagnall, A., Bunescu, R., Stewart, G., (2017) Training Ensembles to Detect Adversarial Examples, , arXiv preprint; Bhagoji, A.N., Cullina, D., Mittal, P., (2017) Dimensionality Reduction as a Defense Against Evasion Attacks on Machine Learning Classifiers, , arXiv preprint; Bhagoji, A.N., He, W., Li, B., Song, D., Black-box attacks on deep neural networks via gradient estimation (2018) ICLR Workshop; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndić, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 387-402. , Springer; Biggio, B., Nelson, B., Laskov, P., Poisoning attacks against support vector machines (2012) Proceedings of the 29th International Conference on Machine Learning (ICML-12), pp. 1807-1814; Biggio, B., Roli, F., (2017) Wild Patterns: Ten Years After the Rise of Adversarial Machine Learning, , arXiv preprint; Brendel, W., Rauber, J., Bethge, M., Decision-based adversarial attacks: Reliable attacks against black-box machine learning models (2018) ICLR; Brown, N., Sandholm, T., Superhuman ai for heads-up no-limit poker: Libratus beats top professionals (2017) Science; Carlini, N., Wagner, D., (2016) Defensive Distillation Is Not Robust to Adversarial Examples, , arXiv preprint; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) AISec; Carlini, N., Wagner, D., (2017) Magnet and “Efficient Defenses Against Adversarial Attacks” Are Not Robust to Adversarial Examples, , arXiv preprint; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium on, pp. 39-57; Carlini, N., Wagner, D., Audio adversarial examples: Targeted attacks on speech-to-text (2018) DLS (IEEE SP); Carlini, N., Wagner, D.A., Towards evaluating the robustness of neural networks (2016) CoRR, , abs/1608.04644; Chen, P.-Y., Sharma, Y., Zhang, H., Yi, J., Hsieh, C.-J., EAD: Elastic-net attacks to deep neural networks via adversarial examples (2018) AAAI; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 15-26; Chen, S.-T., Cornelius, C., Martin, J., Chau, D.H., (2018) Robust Physical Adversarial Attack on Faster R-Cnn Object Detector, , arXiv preprint; Cisse, M., Adi, Y., Neverova, N., Keshet, J., Houdini: Fooling deep structured prediction models (2017) NIPS; Collobert, R., Weston, J., Bottou, L., Karlen, M., Kavukcuoglu, K., Kuksa, P., Natural language processing (almost) from scratch (2011) Journal of Machine Learning Research, 12, pp. 2493-2537. , Aug; Das, N., Shanbhogue, M., Chen, S.-T., Hohman, F., Li, S., Chen, L., Kounavis, M.E., Chau, D.H., (2018) Shield: Fast, Practical Defense and Vaccination for Deep Learning Using Jpeg Compression, , arXiv preprint; Deng, L., Hinton, G., Kingsbury, B., New types of deep neural network learning for speech recognition and related applications: An overview (2013) Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on, pp. 8599-8603; Dudley, R., Sizes of compact subsets of hilbert space and continuity of Gaussian processes (1967) J. Funct. Anal., 1, pp. 290-330; Dziugaite, G.K., Ghahramani, Z., Roy, D.M., (2016) A Study of the Effect of JPG Compression on Adversarial Images, , arXiv preprint; Evtimov, I., Eykholt, K., Fernandes, E., Kohno, T., Li, B., Prakash, A., Rahmati, A., Song, D., Robust physical-world attacks on machine learning models (2018) CVPR; Fawzi, A., Fawzi, O., Frossard, P., Analysis of classifiers' robustness to adversarial perturbations (2018) Machine Learning, 107 (3), pp. 481-508; Fawzi, A., Moosavi-Dezfooli, S.-M., Frossard, P., Robustness of classifiers: From adversarial to random noise (2016) NIPS; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts, , arXiv preprint; Fischer, V., Kumar, M.C., Metzen, J.H., Brox, T., Adversarial examples for semantic image segmentation (2017) ICLR Workshop; Gilmer, J., Metz, L., Faghri, F., Schoenholz, S.S., Raghu, M., Wattenberg, M., Goodfellow, I., Adversarial spheres (2018) ICLR; Gong, Z., Wang, W., Ku, W.-S., (2017) Adversarial and Clean Data Are Not Twins, , arXiv preprint; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations; Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., (2017) On the (Statistical) Detection of Adversarial Examples, , arXiv preprint; Grosse, K., Papernot, N., Manoharan, P., Backes, M., McDaniel, P., Adversarial examples for malware detection (2017) European Symposium on Research in Computer Security, pp. 62-79. , Springer; Haussler, D., Decision theoretic generalizations of the PAC model for neural net and other learning applications (1992) Information and Computation, 100 (1); Hein, M., Andriushchenko, M., Formal guarantees on the robustness of a classifier against adversarial manipulation (2017) Advances in Neural Information Processing Systems, pp. 2263-2273; Hinton, G., Deng, L., Yu, D., Dahl, G.E., Mohamed, A.-R., Jaitly, N., Senior, A., Sainath, T.N., Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups (2012) IEEE Signal Processing Magazine, 29 (6), pp. 82-97; Huang, S., Papernot, N., Goodfellow, I., Duan, Y., Abbeel, P., Adversarial attacks on neural network policies (2017) ICLR; Jagielski, M., Oprea, A., Biggio, B., Liu, C., Nita-Rotaru, C., Li, B., Manipulating machine learning: Poisoning attacks and countermeasures for regression learning (2018) IEEE Security and Privacy; Julian, K.D., Lopez, J., Brush, J.S., Owen, M.P., Kochenderfer, M.J., Policy compression for aircraft collision avoidance systems (2016) Digital Avionics Systems Conference (DASC), 2016 IEEE/AIAA 35th, pp. 1-10; Kantchelian, A., Tygar, J.D., Joseph, A.D., Evasion and hardening of tree ensemble classifiers (2016) Proceedings of the 33rd International Conference on Machine Learning (ICML-16); Kearns, M., Li, M., Learning in the presence of malicious errors (1993) SIAM Journal on Computing, 22 (4), pp. 807-837; Zico Kolter, J., Wong, E., Provable defenses against adversarial examples via the convex outer adversarial polytope (2018) ICML; Kos, J., Fischer, I., Song, D., (2017) Adversarial Examples for Generative Models, , arXiv preprint; Kos, J., Song, D., Delving into adversarial attacks on deep policies (2017) ICLR Workshop; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Proceedings of the 25th International Conference on Neural Information Processing Systems - 1, NIPS'12, pp. 1097-1105. , USA, Curran Associates Inc; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint; Liu, Q., Li, P., Zhao, W., Cai, W., Yu, S., Leung, V.C.M., A survey on security threats and defensive techniques of machine learning: A data driven view (2018) IEEE Access, 6, pp. 12103-12117; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) ICLR; Lu, J., Sibai, H., Fabry, E., (2017) Adversarial Examples That Fool Detectors, , arXiv preprint; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) ICLR; Meng, D., Chen, H., Magnet: A two-pronged defense against adversarial examples (2017) Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pp. 135-147; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) CVPR; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) CVPR; Moravčík, M., Schmid, M., Burch, N., Lisy, V., Morrill, D., Bard, N., Davis, T., Bowling, M., DeepStack: Expert-level artificial intelligence in heads-up no-limit poker (2017) Science, 356 (6337), pp. 508-513; Mozaffari-Kermani, M., Sur-Kolay, S., Raghunathan, A., Jha, N.K., Systematic poisoning attacks on and defenses for machine learning in healthcare (2015) IEEE Journal of Biomedical and Health Informatics, 19 (6), pp. 1893-1905; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: from Phenomena to Black-Box Attacks Using Adversarial Samples, , arXiv preprint; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against deep learning systems using adversarial examples (2017) Proceedings of the 2017 ACM Asia Conference on Computer and Communications Security; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2016) 2016 IEEE European Symposium on Security and Privacy (EuroS&P), pp. 372-387; Papernot, N., McDaniel, P., Sinha, A., Wellman, M., (2016) Towards the Science of Security and Privacy in Machine Learning, , arXiv preprint; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Security and Privacy (SP), 2016 IEEE Symposium on, pp. 582-597; Raghunathan, A., Steinhardt, J., Liang, P., Certified defenses against adversarial examples (2018) ICLR; Rubinstein, B.I.P., Nelson, B., Huang, L., Joseph, A.D., Lau, S.-H., Rao, S., Taft, N., Tygar, J.D., Stealthy poisoning attacks on PCA-based anomaly detectors (2009) ACM SIGMETRICS Performance Evaluation Review, 37 (2), pp. 73-74; Schmidt, L., Santurkar, S., Tsipras, D., Talwar, K., Madry, A., (2018) Adversarially Robust Generalization Requires More Data, , arXiv preprint; Shaham, U., Garritano, J., Yamada, Y., Weinberger, E., Cloninger, A., Cheng, X., Stanton, K., Kluger, Y., (2018) Defending Against Adversarial Images Using Basis Functions Transformations, , arXiv preprint; Shalev-Shwartz, S., Ben-David, S., (2014) Understanding Machine Learning: From Theory to Algorithms, , Cambridge university press; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540; Silver, D., Schrittwieser, J., Simonyan, K., Antonoglou, I., Huang, A., Guez, A., Hubert, T., Bolton, A., Mastering the game of go without human knowledge (2017) Nature, 550 (7676), p. 354; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-Scale Image Recognition, , arXiv preprint; Sinha, A., Namkoong, H., Duchi, J., Certifiable distributional robustness with principled adversarial training (2018) ICLR; Sitawarin, C., Bhagoji, A.N., Mosenia, A., Mittal, P., Chiang, M., Rogue signs: Deceiving traffic sign recognition with malicious ads and logos (2018) DLS (IEEE SP); Smutz, C., Stavrou, A., When a tree falls: Using diversity in ensemble classifiers to identify evasion in malware detectors (2016) NDSS; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2018) ICLR; Wang, Q., Guo, W., Zhang, K., Ororbia, A.G., II, Xing, X., Liu, X., Lee Giles, C., Adversary resistant deep neural networks with an application to malware detection (2017) Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 1145-1153; Wang, Y., Jha, S., Chaudhuri, K., Analyzing the robustness of nearest neighbors to adversarial examples (2018) ICML; Weng, T.-W., Zhang, H., Chen, P.-Y., Yi, J., Su, D., Gao, Y., Hsieh, C.-J., Daniel, L., Evaluating the robustness of neural networks: An extreme value theory approach (2018) ICLR; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., Adversarial examples for semantic segmentation and object detection (2017) International Conference on Computer Vision; Xu, W., Evans, D., Qi, Y., Feature squeezing: Detecting adversarial examples in deep neural networks (2018) NDSS; Xu, W., Qi, Y., Evans, D., Automatically evading classifiers (2016) Proceedings of the 2016 Network and Distributed Systems Symposium; Yuan, X., Chen, Y., Zhao, Y., Long, Y., Liu, X., Chen, K., Zhang, S., Gunter, C.A., CommanderSong: A systematic approach for practical adversarial voice recognition (2018) USENIX Security",,"Larochelle H.Cesa-Bianchi N.Wallach H.Garnett R.Grauman K.Bengio S.Grauman K.",,"Neural information processing systems foundation","32nd Conference on Neural Information Processing Systems, NeurIPS 2018","2 December 2018 through 8 December 2018",,147412,10495258,,,,"English","Adv. neural inf. proces. syst.",Conference Paper,"Final","",Scopus,2-s2.0-85064817063
"Yan Z., Guo Y., Zhang C.","57201250280;57194152792;7405490589;","Deep defense: Training DnNs with improved adversarial robustness",2018,"Advances in Neural Information Processing Systems","2018-December",,,"419","428",,30,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064813421&partnerID=40&md5=ed62574422259bf72676a6edfe15244d","Institute for Artificial Intelligence, Tsinghua University (THUAI), State Key Lab of Intelligent Technologies and Systems, Beijing National Research Center for Information Science and Technology (BNRist), Department of Automation, Tsinghua University, Beijing, China; Intel Labs China, China","Yan, Z., Institute for Artificial Intelligence, Tsinghua University (THUAI), State Key Lab of Intelligent Technologies and Systems, Beijing National Research Center for Information Science and Technology (BNRist), Department of Automation, Tsinghua University, Beijing, China; Guo, Y., Institute for Artificial Intelligence, Tsinghua University (THUAI), State Key Lab of Intelligent Technologies and Systems, Beijing National Research Center for Information Science and Technology (BNRist), Department of Automation, Tsinghua University, Beijing, China, Intel Labs China, China; Zhang, C., Institute for Artificial Intelligence, Tsinghua University (THUAI), State Key Lab of Intelligent Technologies and Systems, Beijing National Research Center for Information Science and Technology (BNRist), Department of Automation, Tsinghua University, Beijing, China","Despite the efficacy on a variety of computer vision tasks, deep neural networks (DNNs) are vulnerable to adversarial attacks, limiting their applications in security-critical systems. Recent works have shown the possibility of generating imperceptibly perturbed image inputs (a.k.a., adversarial examples) to fool well-trained DNN classifiers into making arbitrary predictions. To address this problem, we propose a training recipe named “deep defense”. Our core idea is to integrate an adversarial perturbation-based regularizer into the classification objective, such that the obtained models learn to resist potential attacks, directly and precisely. The whole optimization problem is solved just like training a recursive network. Experimental results demonstrate that our method outperforms training with adversarial/Parseval regularizations by large margins on various datasets (including MNIST, CIFAR-10 and ImageNet) and different DNN architectures. Code and models for reproducing our results are available at https://github.com/ZiangYan/deepdefense.pytorch. © 2018 Curran Associates Inc..All rights reserved.",,"Large dataset; Network security; Image inputs; Large margins; Optimization problems; Potential attack; Regularizer; Security-critical; Deep neural networks",,,,,"Alemi, A.A., Fischer, I., Dillon, J.V., Murphy, K., Deep variational information bottleneck (2017) ICLR; Buckman, J., Roy, A., Raffel, C., Goodfellow, I., Thermometer encoding: One hot way to resist adversarial examples (2018) ICLR; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) ACM Workshop on Artificial Intelligence and Security; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy (SP); Cisse, M., Bojanowski, P., Grave, E., Dauphin, Y., Usunier, N., Parseval networks: Improving robustness to adversarial examples (2017) ICML; Dhillon, G.S., Azizzadenesheli, K., Lipton, Z.C., Bernstein, J., Kossaifi, J., Khanna, A., Anandkumar, A., Stochastic activation pruning for robust adversarial defense (2018) ICLR; Fawzi, A., Moosavi-Dezfooli, S.-M., Frossard, P., Robustness of classifiers: From adversarial to random noise (2016) NIPS; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR; Gu, S., Rigazio, L., Towards deep neural network architectures robust to adversarial examples (2015) ICLR Workshop; Guo, Y., Yao, A., Chen, Y., Dynamic network surgery for efficient dnns (2016) NIPS; Han, S., Pool, J., Tran, J., Dally, W., Learning both weights and connections for efficient neural network (2015) NIPS; He, K., Zhang, X., Ren, S., Sun, J., Delving deep into rectifiers: Surpassing human-level performance on imagenet classification (2015) ICCV; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) CVPR; Hein, M., Andriushchenko, M., Formal guarantees on the robustness of a classifier against adversarial manipulation (2017) NIPS; Hinton, G.E., Srivastava, N., Krizhevsky, A., Sutskever, I., Salakhutdinov, R.R., (2012) Improving Neural Networks by Preventing Co-Adaptation of Feature Detectors, , arXiv preprint; Ioffe, S., Szegedy, C., Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015) ICML; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) NIPS; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2017) ICLR; LeCun, Y., Haffner, P., Bottou, L., Bengio, Y., Object recognition with gradient-based learning (1999) Shape, Contour and Grouping in Computer Vision, p. 823; Lin, M., Chen, Q., Yan, S., Network in network (2014) ICLR; Lu, J., Issaranon, T., Forsyth, D., SafeTyNet: Detecting and rejecting adversarial examples robustly (2017) ICCV; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) ICLR; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., On detecting adversarial perturbations (2017) ICLR; Miyato, T., Maeda, S.-I., Koyama, M., Ishii, S., (2017) Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning, , arXiv preprint; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) CVPR; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) CVPR; Noh, H., Hong, S., Han, B., Learning deconvolution network for semantic segmentation (2015) ICCV; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) Asia Conference on Computer and Communications Security; Papernot, N., McDaniel, P., Sinha, A., Wellman, M., Towards the science of security and privacy in machine learning (2018) IEEE European Symposium on Security and Privacy; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) IEEE Symposium on Security and Privacy (SP); Ross, A.S., Doshi-Velez, F., Improving the adversarial robustness and interpretability of deep neural networks by regularizing their input gradients (2018) AAAI; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Fei-Fei, L., Imagenet large scale visual recognition challenge (2015) IJCV; Sokolic, J., Giryes, R., Sapiro, G., Rodrigues, M.R.D., Robust large margin deep neural networks (2017) IEEE Transactions on Signal Processing; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) ICLR; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., Mitigating adversarial effects through randomization (2018) ICLR; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., Adversarial examples for semantic segmentation and object detection (2017) ICCV; Xu, H., Mannor, S., Robustness and generalization (2012) Machine Learning, 86 (3), pp. 391-423; Zeiler, M.D., Fergus, R., Visualizing and understanding convolutional networks (2014) ECCV",,"Cesa-Bianchi N.Garnett R.Bengio S.Grauman K.Grauman K.Wallach H.Larochelle H.",,"Neural information processing systems foundation","32nd Conference on Neural Information Processing Systems, NeurIPS 2018","2 December 2018 through 8 December 2018",,147412,10495258,,,,"English","Adv. neural inf. proces. syst.",Conference Paper,"Final","",Scopus,2-s2.0-85064813421
"Matyasko A., Chau L.-P.","56816988100;7102672302;","Improved network robustness with adversary critic",2018,"Advances in Neural Information Processing Systems","2018-December",,,"10578","10587",,2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064813322&partnerID=40&md5=9f515bda7ea4d7594e6fbd10105adcb5","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore","Matyasko, A., School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Chau, L.-P., School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore","Ideally, what confuses neural network should be confusing to humans. However, recent experiments have shown that small, imperceptible perturbations can change the network prediction. To address this gap in perception, we propose a novel approach for learning robust classifier. Our main idea is: adversarial examples for the robust classifier should be indistinguishable from the regular data of the adversarial target. We formulate a problem of learning robust classifier in the framework of Generative Adversarial Networks (GAN), where the adversarial attack on classifier acts as a generator, and the critic network learns to distinguish between regular and adversarial images. The classifier cost is augmented with the objective that its adversarial examples should confuse the adversary critic. To improve the stability of the adversarial mapping, we introduce adversarial cycle-consistency constraint which ensures that the adversarial mapping of the adversarial examples is close to the original. In the experiments, we show the effectiveness of our defense. Our method surpasses in terms of robustness networks trained with adversarial training. Additionally, we verify in the experiments with human annotators on MTurk that adversarial examples are indeed visually confusing. © 2018 Curran Associates Inc.All rights reserved.",,"Adversarial networks; Consistency constraints; Critic network; Network prediction; Network robustness; Mapping",,,,,"He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) CVPR; Hinton, G., Deng, L., Yu, D., Dahl, G.E., Mohamed, A.R., Jaitly, N., Senior, A., Kingsbury, B., Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups (2012) IEEE Signal Processing Magazine; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2013) ICLR; Carlini, N., Wagner, D., (2018) Audio Adversarial Examples: Targeted Attacks on Speech-to-Text, , arXiv preprint; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proceedings of The 2016 ACM SIGSAC Conference on Computer and Communications Security; Papernot, N., McDaniel, P.D., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2016) IEEE European Symposium on Security and Privacy; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2017) ICLR; Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2018) ICLR; Carlini, N., Wagner, D.A., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy; Goodfellow, I.J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A.C., Bengio, Y., Generative adversarial nets (2014) NIPS; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in The Physical World, , arXiv preprint; Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) CVPR; Papernot, N., McDaniel, P.D., Goodfellow, I.J., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of The 2017 ACM on Asia Conference on Computer and Communications Security; Baluja, S., Fischer, I., Learning to attack: Adversarial transformation networks (2018) AAAI; Miyato, T., Maeda, S.-I., Koyama, M., Nakae, K., Ishii, S., Distributional smoothing with virtual adversarial training (2015) ICLR; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) ICLR; Zheng, S., Song, Y., Leung, T., Goodfellow, I., Improving the robustness of deep neural networks via stability training (2016) CVPR; Matyasko, A., Chau, L.-P., Margin maximization for robust classification using deep learning (2017) IJCNN; Elsayed, G.F., Krishnan, D., Mobahi, H., Regan, K., Bengio, S., Large margin deep networks for classification (2018) NIPS; Cissé, M., Bojanowski, P., Grave, E., Dauphin, Y., Usunier, N., Parseval networks: Improving robustness to adversarial examples (2017) ICML; Hendrik Metzen, J., Genewein, T., Fischer, V., Bischoff, B., On detecting adversarial perturbations (2017) ICLR; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts, , arXiv preprint; Carlini, N., Wagner, D.A., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) Proceedings of The 10th ACM Workshop on Artificial Intelligence and Security; Samangouei, P., Kabkab, M., Chellappa, R., Defense-Gan: Protecting classifiers against adversarial attacks using generative models (2018) ICLR; Lee, H., Han, S., Lee, J., (2017) Generative Adversarial Trainer: Defense to Adversarial Perturbations with GAN, , arXiv preprint; Chongxuan, L.I., Xu, T., Zhu, J., Zhang, B., Triple generative adversarial nets (2017) NIPS; Xu, H., Caramanis, C., Mannor, S., Robust regression and lasso (2009) NIPS; Xu, H., Caramanis, C., Mannor, S., Robustness and regularization of support vector machines (2009) Journal of Machine Learning Research; Shaham, U., Yamada, Y., Negahban, S., (2015) Understanding Adversarial Training: Increasing Local Stability of Neural Nets Through Robust Optimization, , arXiv preprint; Bertsimas, D., Gupta, V., Kallus, N., Data-driven robust optimization (2018) Mathematical Programming; Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., Courville, A.C., Improved training of wasserstein gans (2017) NIPS; Zhu, J., Park, T., Isola, P., Efros, A.A., Unpaired image-to-image translation using cycle-consistent adversarial networks (2017) ICCV; Bengio, Y., Léonard, N., Courville, A.C., (2015) Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation, , arXiv preprint; (2015) TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems, , arXiv preprint; Kingma, D.P., Ba, J., (2015) Adam: A Method for Stochastic Optimization, , arXiv preprint",,"Cesa-Bianchi N.Grauman K.Wallach H.Garnett R.Bengio S.Grauman K.Larochelle H.",,"Neural information processing systems foundation","32nd Conference on Neural Information Processing Systems, NeurIPS 2018","2 December 2018 through 8 December 2018",,147412,10495258,,,,"English","Adv. neural inf. proces. syst.",Conference Paper,"Final","",Scopus,2-s2.0-85064813322
"Balduzzi D., Tuyls K., Perolat J., Graepel T.","24447971900;23391251900;56427885600;6601966753;","Re-evaluating evaluation",2018,"Advances in Neural Information Processing Systems","2018-December",,,"3268","3279",,24,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064810117&partnerID=40&md5=eb1cb1ff1c435911b11e5332d6a2b55e","DeepMind, United States","Balduzzi, D., DeepMind, United States; Tuyls, K., DeepMind, United States; Perolat, J., DeepMind, United States; Graepel, T., DeepMind, United States","“What we observe is not nature itself, but nature exposed to our method of questioning.” - Werner Heisenberg Progress in machine learning is measured by careful evaluation on problems of outstanding common interest. However, the proliferation of benchmark suites and environments, adversarial attacks, and other complications has diluted the basic evaluation model by overwhelming researchers with choices. Deliberate or accidental cherry picking is increasingly likely, and designing well-balanced evaluation suites requires increasing effort. In this paper we take a step back and propose Nash averaging. The approach builds on a detailed analysis of the algebraic structure of evaluation in two basic scenarios: agent-vs-agent and agent-vs-task. The key strength of Nash averaging is that it automatically adapts to redundancies in evaluation data, so that results are not biased by the incorporation of easy tasks or weak agents. Nash averaging thus encourages maximally inclusive evaluation - since there is no harm (computational cost aside) from including all available tasks and agents. © 2018 Curran Associates Inc.All rights reserved.",,"Learning systems; Algebraic structures; Benchmark suites; Common interests; Computational costs; Evaluation modeling; Exposed to; Heisenberg; Well balanced; Petroleum reservoir evaluation",,,,,"Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., ImageNet: A large-scale hierarchical image database (2009) CVPR; Bellemare, M.G., Naddaf, Y., Veness, J., Bowling, M., The arcade learning environment: An evaluation platform for general agents (2013) J. Artif. Intell. Res., 47, pp. 253-279; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems (NIPS); Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.A., Veness, J., Bellemare, M.G., Graves, A., Hassabis, D., Human-level control through deep reinforcement learning (2015) Nature, 518, pp. 529-533. , 02; Donoho, D., 50 years of Data Science (2015) Based on a Presentation at the Tukey Centennial Workshop; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks; Tramèr, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2018) ICLR; Kurakin, A., Goodfellow, I., Bengio, S., Dong, Y., Liao, F., Liang, M., Pang, T., Abe, M., (2018) Adversarial Attacks and Defences Competition; Uesato, J., O'Donoghue, B., Van Den Oord, A., Kohli, P., Adversarial risk and the dangers of evaluating against weak attacks (2018) ICML; Silver, D., Schrittwieser, J., Simonyan, K., Antonoglou, I., Huang, A., Guez, A., Hubert, T., Hassabis, D., Mastering the game of Go without human knowledge (2017) Nature, 550, pp. 354-359; Silver, D., Hubert, T., Schrittwieser, J., Antonoglou, I., Lai, M., Guez, A., Lanctot, M., Hassabis, D., (2017) Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm; Todorov, E., Erez, T., Tassa, Y., MujoCo: A physics engine for model-based control (2012) IROS; Beattie, C., Leibo, J.Z., Teplyashin, D., Ward, T., Wainwright, M., Küttler, H., Lefrancq, A., Petersen, S., (2016) DeepMind Lab; Brockman, G., Cheung, V., Pettersson, L., Schneider, J., Schulman, J., Tang, J., Zaremba, W., (2016) OpenAI Gym; Leibo, J.Z., De Masson D'Autume, C., Zoran, D., Amos, D., Beattie, C., Anderson, K., Castañeda, A.G., Botvinick, M.M., (2018) Psychlab: A Psychology Laboratory for Deep Reinforcement Learning Agents; Elo, A.E., (1978) The Rating of Chess Players, Past and Present, , Ishi Press International; Herbrich, R., Minka, T., Graepel, T., TrueSkill: A Bayesian skill rating system (2007) NIPS; Frean, M., Abraham, E.R., Rock-scissors-paper and the survival of the weakest (2001) Proc. R. Soc. Lond. B, (268), pp. 1323-1327; Kerr, B., Riley, M.A., Feldman, M.W., Bohannan, B.J.M., Local dispersal promotes biodiversity in a real-life game of rock-paper-scissors (2002) Nature, (418), pp. 171-174; Laird, R.A., Schamp, B.S., Competitive intransitivity promotes species coexistence (2006) The American Naturalist, 168 (2); Szolnoki, A., Mobilia, M., Jiang, L.-L., Szczesny, B., Rucklidge, A.M., Perc, M., Cyclic dominance in evolutionary games: A review (2014) J R Soc Interface, 11 (100); Jaderberg, M., Dalibard, V., Osindero, S., Czarnecki, W.M., Donahue, J., Razavi, A., Vinyals, O., Kavukcuoglu, K., (2017) Population Based Training of Neural Networks, , CoRR, abs/1711.09846; Balduzzi, D., Racanière, S., Martens, J., Foerster, J., Tuyls, K., Graepel, T., The mechanics of n-player differentiable games (2018) ICML; Silver, D., Huang, A., Maddison, C.J., Guez, A., Sifre, L., Van Den Driessche, G., Schrittwieser, J., Hassabis, D., Mastering the game of Go with deep neural networks and tree search (2016) Nature, 529 (7587), pp. 484-489; Lanctot, M., Zambaldi, V., Gruslys, A., Lazaridou, A., Tuyls, K., Perolat, J., Silver, D., Graepel, T., A unified game-theoretic approach to multiagent reinforcement learning (2017) NIPS; Legg, S., Hutter, M., A universal measure of intelligence for artificial agents (2005) IJCAI; Legg, S., Veness, J., An approximation of the universal intelligence measure (2013) Algorithmic Probability and Friends. Bayesian Prediction and Artificial Intelligence; Solomonoff, R.J., A formal theory of inductive inference I, II (1964) Inform. Control, 7 (1-22), pp. 224-254; Kolmogorov, A.N., Three approaches to the quantitative definition of information (1965) Problems Inform. Transmission, 1 (1), pp. 1-7; Chaitin, G.J., On the length of computer programs for computing finite binary sequences (1966) J Assoc. Comput. Mach., 13, pp. 547-569; Ferri, C., Hernández-Orallo, J., Modroiu, R., An experimental comparison of performance measures for classification (2009) Pattern Recognition Letters, (30), pp. 27-38; Hernández-Orallo, J., Flach, P., Ferri, C., A unified view of performance metrics: Translating threshold choice into expected classification loss (2012) JMLR, (13), pp. 2813-2869; Hernández-Orallo, J., (2017) The Measure of All Minds: Evaluating Natural and Artificial Intelligence, , Cambridge University Press; Hernández-Orallo, J., Evaluation in artificial intelligence: From task-oriented to ability-oriented measurement (2017) Artificial Intelligence Review, 48 (3), pp. 397-447; Olson, R.S., La Cava, W., Orzechowski, P., Urbanowicz, R.J., Moore, J.H., PMLB: A large benchmark suite for machine learning evaluation and comparison (2017) BioData Mining, 10, p. 36. , Dec; Spearman, C., General Intelligence,' objectively determined and measured (1904) Am. J. Psychol., 15 (201); Woolley, A., Fabris, C., Pentland, A., Hashmi, N., Malone, T., Evidence for a collective intelligence factor in the performance of human groups (2010) Science, (330), pp. 686-688; Bringsjord, S., Psychometric artificial intelligence (2011) Journal of Experimental & Theoretical Artificial Intelligence, 23 (3), pp. 271-277; Hunter, D.R., MM algorithms for generalized Bradley-Terry models (2004) Annals of Statistics, 32 (1), pp. 384-406; Machado, M.C., Bellemare, M.G., Talvitie, E., Veness, J., Hausknecht, M., Bowling, M., Revisiting the arcade learning environment: Evaluation protocols and open problems for general agents (2018) Journal of Artificial Intelligence Research (JAIR), 61, pp. 523-562; Liapis, A., Yannakakis, G.N., Togelius, J., Towards a generic method of evaluating game levels (2013) Artificial Intelligence in Digital Interactive Entertainment (AIIDE); Horn, B., Dahlskog, S., Shaker, N., Smith, G., Togelius, J., A comparative evaluation of procedural level generators in the Mario AI framework (2014) Foundations of Digital Games; Nielsen, T.S., Barros, G., Togelius, J., Nelson, M.J., General video game evaluation using relative algorithm performance profiles (2015) EvoApplications; De Mesentier Silva, F., Lee, S., Togelius, J., Nealen, A., AI-based Playtesting of Contemporary Board Games (2017) Foundations of Digital Games (FDG); Volz, V., Schrum, J., Liu, J., Lucas, S.M., Smith, A.M., Risi, S., Evolving Mario levels in the latent space of a deep convolutional generative adversarial network (2018) GECCO; Hambleton, R.K., Swaminathan, H., Rogers, H.J., (1991) Fundamentals of Item Response Theory, , Sage Publications; Martínez-Plumed, F., Hernández-Orallo, J., AI results for the Atari 2600 games: Difficulty and discrimination using IRT (2017) Workshop on Evaluating General-Purpose AI (EGPAI at IJCAI); Jiang, X., Lim, L.-H., Yao, Y., Ye, Y., Statistical ranking and combinatorial Hodge theory (2011) Math. Program., Ser. B, 127, pp. 203-244; Candogan, O., Menache, I., Ozdaglar, A., Parrilo, P.A., Flows and decompositions of games: Harmonic and potential games (2011) Mathematics of Operations Research, 36 (3), pp. 474-503; Candogan, O., Ozdaglar, A., Parrilo, P.A., Near-potential games: Geometry and dynamics (2013) ACM Trans Econ Comp, 1 (2); Candogan, O., Ozdaglar, A., Parrilo, P.A., Dynamics in near-potential games (2013) Games and Economic Behavior, 82, pp. 66-90; Walsh, W.E., Parkes, D.C., Das, R., Choosing samples to compute heuristic-strategy nash equilibrium (2003) Proceedings of the Fifth Workshop on Agent-Mediated Electronic Commerce; Wellman, M.P., Methods for empirical game-theoretic analysis (2006) Proceedings, the Twenty-First National Conference on Artificial Intelligence and the Eighteenth Innovative Applications of Artificial Intelligence Conference, pp. 1552-1556; Phelps, S., Parsons, S., McBurney, P., An evolutionary game-theoretic comparison of two double-auction market designs (2004) Agent-Mediated Electronic Commerce VI, Theories for and Engineering of Distributed Mechanisms and Systems, AAMAS Workshop, pp. 101-114; Phelps, S., Cai, K., McBurney, P., Niu, J., Parsons, S., Sklar, E., Auctions, Evolution, and Multi-agent Learning (2007) AAMAS and 7th European Symposium on Adaptive and Learning Agents and Multi-Agent Systems (ALAMAS), pp. 188-210; Ponsen, M., Tuyls, K., Kaisers, M., Ramon, J., An evolutionary game-theoretic analysis of poker strategies (2009) Entertainment Computing, 1 (1), pp. 39-45; Bloembergen, D., Tuyls, K., Hennes, D., Kaisers, M., Evolutionary dynamics of multi-agent learning: A survey (2015) J. Artif. Intell. Res. (JAIR), 53, pp. 659-697; Tuyls, K., Perolat, J., Lanctot, M., Leibo, J.Z., Graepel, T., A generalised method for empirical game theoretic analysis (2018) AAMAS; Dudik, M., Hofmann, K., Schapire, R.E., Slivkins, A., Zoghi, M., Contextual dueling bandits (2015) COLT; Balsubramani, A., Karnin, Z., Schapire, R.E., Zoghi, M., Instance-dependent Regret Bounds for Dueling Bandits (2016) COLT; Jordan, P.R., Kiekintveld, C., Wellman, M.P., Empirical game-theoretic analysis of the TAC supply chain game (2007) 6th International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS 2007), p. 193. , Honolulu, Hawaii, USA, May 14-18, 2007; Jordan, P.R., (2010) Practical Strategic Reasoning with Applications in Market Games, , PhD thesis; Von Neumann, J., Morgenstern, O., (1944) Theory of Games and Economic Behavior, , Princeton University Press, Princeton NJ; Nash, J.F., Equilibrium points in n-person games (1950) Proc Natl Acad Sci U S A, 36 (1), pp. 48-49; Hofbauer, J., Sandholm, W.H., On the global convergence of stochastic fictitious play (2002) Econometrica, 70 (6), pp. 2265-2294; Sandholm, W.H., (2010) Population Games and Evolutionary Dynamics, , MIT Press; Wang, Z., Schaul, T., Hessel, M., Van Hasselt, H., Lanctot, M., De Freitas, N., Dueling network architectures for deep reinforcement learning (2016) ICML; Van Hasselt, H., Guez, A., Hessel, M., Mnih, V., Silver, D., Learning values across many orders of magnitude (2016) NIPS; Ostrovski, G., Bellemare, M.G., Van Den Oord, A., Munos, R., Count-based exploration with neural density models (2017) ICML; Hessel, M., Modayil, J., Van Hasselt, H., Schaul, T., Ostrovski, G., Dabney, W., Horgan, D., Silver, D., Rainbow: Combining improvements in deep reinforcement learning (2018) AAAI; Ortiz, L.E., Schapire, R.E., Kakade, S.M., (2006) Maximum Entropy Correlated Equilibrium, , Technical Report CSAIL MIT; Ortiz, L.E., Schapire, R.E., Kakade, S.M., Maximum entropy correlated equilibria (2007) AISTATS; Diaconis, P., (1988) Group Representations in Probability and Statistics, , Institute of Mathematical Statistics; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324; Kondor, R., Jebara, T., A kernel between sets of vectors (2003) ICML; Kondor, R., (2008) Group Theoretical Methods in Machine Learning, , PhD dissertation; Zaheer, M., Kottur, S., Ravanbakhsh, S., Poczos, B., Salakhutdinov, R.R., Smola, A.J., Deep sets (2017) NIPS; Hartford, J., Graham, D.R., Leyton-Brown, K., Ravanbakhsh, S., Deep models of interactions across sets (2018) ICML; Kondor, R., Lin, Z., Trivedi, S., Clebsch-Gordan nets: A fully Fourier space spherical convolutional neural network (2018) NIPS; Sukhbaatar, S., Lin, Z., Kostrikov, I., Synnaeve, G., Szlam, A., Fergus, R., Intrinsic motivation and automatic curricula via asymmetric self-play (2017) ICLR; Freund, Y., Schapire, R.E., A decision-theoretic generalization of on-line learning and an application to boosting (1996) Journal of Computer and System Sciences; Schapire, R., Freund, Y., (2012) Boosting: Foundations and Algorithms, , MIT Press; Vandenberg, R.J., Lance, C.E., A review and synthesis of the measurement invariance literature: Suggestions, practices, and recommendations for organizational research (2000) Organizational Research Methods, 3 (1), pp. 4-70",,"Bengio S.Grauman K.Wallach H.Garnett R.Cesa-Bianchi N.Larochelle H.Grauman K.",,"Neural information processing systems foundation","32nd Conference on Neural Information Processing Systems, NeurIPS 2018","2 December 2018 through 8 December 2018",,147412,10495258,,,,"English","Adv. neural inf. proces. syst.",Conference Paper,"Final","",Scopus,2-s2.0-85064810117
"Zheng Z., Hong P.","57208443396;14630423200;","Robust detection of adversarial attacks by modeling the intrinsic properties of deep neural networks",2018,"Advances in Neural Information Processing Systems","2018-December",,,"7913","7922",,25,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064804649&partnerID=40&md5=f390fb99b96103d6e7bd08953a0ad071","Department of Computer Science, Brandeis University, Waltham, MA  02453, United States","Zheng, Z., Department of Computer Science, Brandeis University, Waltham, MA  02453, United States; Hong, P., Department of Computer Science, Brandeis University, Waltham, MA  02453, United States","It has been shown that deep neural network (DNN) based classifiers are vulnerable to human-imperceptive adversarial perturbations which can cause DNN classifiers to output wrong predictions with high confidence. We propose an unsupervised learning approach to detect adversarial inputs without any knowledge of attackers. Our approach tries to capture the intrinsic properties of a DNN classifier and uses them to detect adversarial inputs. The intrinsic properties used in this study are the output distributions of the hidden neurons in a DNN classifier presented with natural images. Our approach can be easily applied to any DNN classifiers or combined with other defense strategies to improve robustness. Experimental results show that our approach demonstrates state-of-the-art robustness in defending black-box and gray-box attacks. © 2018 Curran Associates Inc.All rights reserved.",,"Defense strategy; Hidden neurons; High confidence; Intrinsic property; Natural images; Output distribution; Robust detection; State of the art; Deep neural networks",,,,,"Ackerman, E., How drive. Ai is mastering autonomous driving with deep learning (2017) IEEE Spectrum, , March; Bojarski, M., Del Testa, D., Dworakowski, D., Firner, B., Flepp, B., Goyal, P., Jackel, L.D., Zhang, J., (2016) End to End Learning for Self-Driving Cars, , arXiv preprint; Carlini, N., Wagner, D., (2016) Defensive Distillation Is Not Robust to Adversarial Examples, , arXiv preprint; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium on, pp. 39-57. , IEEE; Cortes, C., Vapnik, V., Support-vector networks (1995) Machine Learning, 20 (3), pp. 273-297; Esteva, A., Kuprel, B., Novoa, R.A., Ko, J., Swetter, S.M., Blau, H.M., Thrun, S., Dermatologist-level classification of skin cancer with deep neural networks (2017) Nature, 542 (7639), p. 115; Giusti, A., Guzzi, J., Cireşan, D.C., He, F.-L., Rodríguez, J.P., Fontana, F., Faessler, M., Di Caro, G., A machine learning approach to visual perception of forest trails for mobile robots (2016) IEEE Robotics and Automation Letters, 1 (2), pp. 661-667; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, pp. 2672-2680; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Machine Learning at Scale, , arXiv preprint; LeCun, Y., (1998) The Mnist Database of Handwritten Digits, , http://yann.lecun.com/exdb/mnist/; Lu, J., Issaranon, T., Forsyth, D., SafeTyNet: Detecting and rejecting adversarial examples robustly (2017) CoRR, , abs/1704.00103; McLachlan, G., Krishnan, T., (2007) The EM Algorithm and Extensions, 382. , John Wiley & Sons; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., (2017) On Detecting Adversarial Perturbations, , arXiv preprint; Miyato, T., Maeda, S., Koyama, M., Nakae, K., Ishii, S., (2015) Distributional Smoothing with Virtual Adversarial Training, , arXiv preprint; Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D., Riedmiller, M., (2013) Playing Atari with Deep Reinforcement Learning, , arXiv preprint; Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.A., Veness, J., Bellemare, M.G., Graves, A., Ostrovski, G., Human-level control through deep reinforcement learning (2015) Nature, 518 (7540), p. 529; Moosavi Dezfooli, S.M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , number EPFL-CONF-218057; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., (2017) Universal Adversarial Perturbations, , arXiv preprint; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., (2016) Practical Black-Box Attacks Against Deep Learning Systems Using Adversarial Examples, , arXiv preprint; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387. , IEEE; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Security and Privacy (SP), 2016 IEEE Symposium on, pp. 582-597. , IEEE; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Bernstein, M., Imagenet large scale visual recognition challenge (2015) International Journal of Computer Vision, 115 (3), pp. 211-252; Samangouei, P., Kabkab, M., Chellappa, R., Defense-Gan: Protecting classifiers against adversarial attacks using generative models (2018) International Conference on Learning Representations, 9; Shen, D., Wu, G., Suk, H.-I., Deep learning in medical image analysis (2017) Annual Review of Biomedical Engineering, 19, pp. 221-248; Silver, D., Huang, A., Maddison, C.J., Guez, A., Sifre, L., Van Den Driessche, G., Schrittwieser, J., Lanctot, M., Mastering the game of go with deep neural networks and tree search (2016) Nature, 529 (7587), pp. 484-489; Silver, D., Schrittwieser, J., Simonyan, K., Antonoglou, I., Huang, A., Guez, A., Hubert, T., Bolton, A., Mastering the game of go without human knowledge (2017) Nature, 550 (7676), p. 354; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-Scale Image Recognition, , arXiv preprint; Su, J., Vargas, D.V., Kouichi, S., (2017) One Pixel Attack for Fooling Deep Neural Networks, , arXiv preprint; Sun, Y., Liang, D., Wang, X., Tang, X., (2015) Deepid3: Face Recognition with Very Deep Neural Networks, , arXiv preprint; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint; Xiao, H., Rasul, K., Vollgraf, R., (2017) Fashion-Mnist: A Novel Image Dataset for Benchmarking Machine Learning Algorithms; Zagoruyko, S., Komodakis, N., (2016) Wide Residual Networks, , arXiv preprint",,"Garnett R.Grauman K.Wallach H.Grauman K.Bengio S.Larochelle H.Cesa-Bianchi N.",,"Neural information processing systems foundation","32nd Conference on Neural Information Processing Systems, NeurIPS 2018","2 December 2018 through 8 December 2018",,147412,10495258,,,,"English","Adv. neural inf. proces. syst.",Conference Paper,"Final","",Scopus,2-s2.0-85064804649
[No author name available],[No author id available],"20th International Conference on Information Security and Cryptology, ICISC 2017",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","10779 LNCS",,,"","",367,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063924572&partnerID=40&md5=103962cf9c6dc53a8cbe4a20173d13a4",,"","The proceedings contain 20 papers. The special focus in this conference is on . The topics include: Recipient revocable broadcast encryption schemes without random oracles; recipient revocable broadcast encryption with dealership; Solving 114-bit ECDLP for barreto-naehrig curve; On the computational complexity of ECDLP for elliptic curves in various forms using index calculus; Two mutual authentication protocols based on zero-knowledge proofs for RFID systems; on new zero-knowledge arguments for attribute-based group signatures from lattices; Security analysis of improved cubic UOV signature schemes; evaluating the impact of juice filming charging attack in practical environments; reading network packets as a natural language for intrusion detection; improved meet-in-the-middle attacks on reduced round Kuznyechik; friend-safe adversarial examples in an evasion attack on a deep neural network; security of stateful order-preserving encryption; cryptanalysis of tran-pang-deng verifiable homomorphic encryption; multi-party (leveled) homomorphic encryption on identity-based and attribute-based settings; improved key generation algorithm for gentry’s fully homomorphic encryption scheme; subring homomorphic encryption; Novel leakage against realistic masking and shuffling countermeasures: Case study on PRINCE and SEED; detecting similar code segments through side channel leakage in microcontrollers.",,,,,,,,,"Kim D.Kim H.",,"Springer Verlag","20th International Conference on Information Security and Cryptology, ICISC 2017","29 November 2017 through 1 December 2017",,212119,03029743,9783319785554,,,"English","Lect. Notes Comput. Sci.",Conference Review,"Final","",Scopus,2-s2.0-85063924572
"Alshamrani A., Chowdhary A., Mjihil O., Myneni S., Huang D.","38560912200;57190399852;57190380330;36930877800;9733190700;","Combining Dynamic and Static Attack Information for Attack Tracing and Event Correlation",2018,"2018 IEEE Global Communications Conference, GLOBECOM 2018 - Proceedings",,,"8647326","","",,2,"10.1109/GLOCOM.2018.8647326","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063452879&doi=10.1109%2fGLOCOM.2018.8647326&partnerID=40&md5=a22a2e77e651c13c48e202edcab14bc6","Arizona State University, Tempe, United States; FST, Hassan 1st University, Settat, Morocco","Alshamrani, A., Arizona State University, Tempe, United States; Chowdhary, A., Arizona State University, Tempe, United States; Mjihil, O., Arizona State University, Tempe, United States, FST, Hassan 1st University, Settat, Morocco; Myneni, S., Arizona State University, Tempe, United States; Huang, D., Arizona State University, Tempe, United States","Many sophisticated attacks, e.g. Advanced Persistent Threats (APTs), have emerged with a variety of different attack forms. APT employs a wide range of sophisticated reconnaissance and information-gathering tools, as well as attack tools and methods. The diversity and stealthiness of APT make it a challenging threat to current networking systems. The attackers are very skilled and try to hide in a system undetected for a long period of time with the incentive to steal and collect invaluable Current commonly used solutions (firewalls, Intrusion Detection Systems, proxies, etc.) show the limited efficiency of detecting APT. Thus, in this paper, we design a solution that is based on multi-source data combination to learn the adversarial behavior of suspicious users as well as to optimally select a proper countermeasure. © 2018 IEEE.","Advanced Persistent Threats; Attack Graph; Intrusion Detection Systems","Computer crime; Computer system firewalls; Advanced Persistent Threats; Attack graph; Different attacks; Event correlation; Information gathering; Intrusion Detection Systems; Networking systems; Tools and methods; Intrusion detection",,,,,"Tankard, C., Advanced persistent threats and how to monitor and deter them (2011) Network Security, 2011 (8), pp. 16-19; Rockefeller, S.J., A kill chain analysis of the 2013 target data breach (2014) Technical Report, Tech Rep., Committee on Commerce, Science and Transportation; Ussath, M., Cheng, F., Meinel, C., Event attribute tainting: A new approach for attack tracing and event correlation (2016) Network Operations and Management Symposium (NOMS), 2016 IEEE/IFIP, pp. 509-515. , IEEE; Chen, T.M., Abu-Nimeh, S., Lessons from stuxnet (2011) Computer, 44 (4), pp. 91-93; Bencsáth, B., Pék, G., Buttyán, L., Félegyházi, M., Duqu: Analysis, detection, and lessons learned (2012) ACM European Workshop on System Security (EuroSec), 2012; Bencsáth, B., Pék, G., Buttyán, L., Felegyhazi, M., The cousins of stuxnet: Duqu, flame, and gauss (2012) Future Internet, 4 (4), pp. 971-1003; Marchetti, M., Pierazzi, F., Colajanni, M., Guido, A., Analysis of high volumes of network traffic for advanced persistent threat detection (2016) Computer Networks, 109, pp. 127-141; Singh, S., Kumar Sharma, P., Yeon Moon, S., Moon, D., Hyuk Park, J., A comprehensive study on apt attacks and countermeasures for future networks and communications: Challenges and solutions (2016) The Journal of Supercomputing, pp. 1-32; Ning, P., Cui, Y., Reeves, D.S., Constructing attack scenarios through correlation of intrusion alerts (2002) Proceedings of the 9th ACM Conference on Computer and Communications Security, pp. 245-254. , ACM; Brogi, G., Viet Triem Tong, V., Terminaptor: Highlighting advanced persistent threats through information flow tracking (2016) New Technologies, Mobility and Security (NTMS), 2016 8th IFIP International Conference on, pp. 1-5. , IEEE; Suh-Lee, C., Jo, J., Quantifying security risk by measuring network risk conditions (2015) Computer and Information Science (ICIS), 2015 IEEE/ACIS 14th International Conference on, pp. 9-14. , IEEE; Liu, Y., Goto, N., Kanaoka, A., Okamoto, E., Privacy preserved rule-based risk analysis through secure multi-party computation (2015) Information Security (AsiaJCIS), 2015 10th Asia Joint Conference on, pp. 77-84. , IEEE; Fall, D., Okuda, T., Kadobayashi, Y., Yamaguchi, S., Security risk quantification mechanism for infrastructure as a service cloud computing platforms (2015) Journal of Information Processing, 23 (4), pp. 465-475; Zhang, S., Zhang, X., Ou, X., After we knew it: Empirical study and modeling of cost-effectiveness of exploiting prevalent known vulnerabilities across iaas cloud (2014) Proceedings of the 9th ACM Symposium on Information, Computer and Communications Security, pp. 317-328. , ACM; Ou, X., Govindavajhala, S., Appel, A.W., Mulval: A logic-based network security analyzer (2005) USENIX Security; (2017) Common Vulnerability Scoring System Version 3. 0, , https://www.first.org/cvss/user-guide/; Rao, P., Sagonas, K., Swift, T., Warren, D.S., Freire, J., Xsb: A system for efficiently computing well-founded semantics (1997) International Conference on Logic Programming and Nonmonotonic Reasoning, pp. 430-440. , Springer; Singhal, A., Ou, X., Security risk analysis of enterprise networks using probabilistic attack graphs (2011) Citeseer",,,,"Institute of Electrical and Electronics Engineers Inc.","2018 IEEE Global Communications Conference, GLOBECOM 2018","9 December 2018 through 13 December 2018",,145422,,9781538647271,,,"English","IEEE Glob. Commun. Conf., GLOBECOM - Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85063452879
"Liu B., Ding M., Zhu T., Xiang Y., Zhou W.","55574235154;7202280996;9737124100;7201978796;7404511655;","Using Adversarial Noises to Protect Privacy in Deep Learning Era",2018,"2018 IEEE Global Communications Conference, GLOBECOM 2018 - Proceedings",,,"8647189","","",,7,"10.1109/GLOCOM.2018.8647189","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063422125&doi=10.1109%2fGLOCOM.2018.8647189&partnerID=40&md5=e7812f66873bd589bafe55b89b8f9c79","Department of Engineering, La Trobe University, Melbourne, Australia; Data61, CSIRO, Australia; University of Technology Sydney, School of Software, Sydney, Australia; Deakin University, School of IT, Melbourne, Australia","Liu, B., Department of Engineering, La Trobe University, Melbourne, Australia; Ding, M., Data61, CSIRO, Australia; Zhu, T., University of Technology Sydney, School of Software, Sydney, Australia; Xiang, Y., Deakin University, School of IT, Melbourne, Australia; Zhou, W., University of Technology Sydney, School of Software, Sydney, Australia","The unprecedented accuracy of deep learning methods has earned themselves as the foundation of new AI-based services on the Internet. At the same time, it presents obvious privacy issues. The deep learning aided privacy attack can dig out sensitive personal information not only from the text but also from unstructured data such as images and videos. In this paper, we proposed a framework to protect image privacy against the deep learning tools. We also propose two new metrics to measure the image privacy. Moreover, we propose two different image privacy protection schemes based on the two metrics, utilizing the adversarial example idea. The performance of our schemes is validated by simulation on a large-scale dataset. Our study shows that we can protect the image privacy by adding a small amount of noise, while the added noise has a humanly imperceptible impact on the image quality. © 2018 IEEE.","adversarial example; deep learning; privacy","Data privacy; Large dataset; adversarial example; Large-scale dataset; Learning methods; Personal information; Privacy Attacks; Privacy issue; Privacy protection; Unstructured data; Deep learning",,,,,"Facebook Privacy Breach [Online], , https://www.ft.com/content/87184c40-2cfe-11e8-9b4b-bc4b9f08f381, accessed: 2018-04-13; Weyand, T., Kostrikov, I., Philbin, J., Planet-photo geolocation with convolutional neural networks (2016) European Conference on Computer Vision, pp. 37-55. , Springer; Fredrikson, M., Jha, S., Ristenpart, T., Model inversion attacks that exploit con-dence information and basic countermeasures (2015) Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security. ACM, pp. 1322-1333; Abadi, M., Chu, A., Goodfellow, I., McMahan, H.B., Mironov, I., Talwar, K., Zhang, L., Deep learning with differential privacy (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security. ACM, pp. 308-318; Phan, N., Wang, Y., Wu, X., Dou, D., Differential privacy preservation for deep auto-encoders: An application of human behavior prediction (2016) AAAI, 16, pp. 1309-1316; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint arXiv:1412. 6572; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proceedings of the IEEE, 86 (11), pp. 2278-2324; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classi-cation with deep convolutional neural networks (2012) Advances in Neural Infor-mation Processing Systems, pp. 1097-1105; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) Cvpr; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., Inception-v4, inception-resnet and the impact of residual connections on learning (2017) AAAI, 4, p. 12; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition, , CoRR abs/1409. 1556; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Liu, B., Zhou, W., Zhu, T., Gao, L., Xiang, Y., Location privacy and its applications: A systematic study (2018) IEEE Access; Shokri, R., Shmatikov, V., Privacy-preserving deep learning (2015) Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security. ACM, pp. 1310-1321; Yu, J., Zhang, B., Kuang, Z., Lin, D., Fan, J., IPrivacy: Image privacy protection by identifying sensitive objects via deep multi-task learning (2017) IEEE Transactions on Information Forensics and Security, 12 (5), pp. 1005-1016; Liu, Y., Zhang, W., Yu, N., Protecting privacy in shared photos via adversarial examples based stealth (2017) Security and Communication Networks, 2017; Wagner, I., Eckhoff, D., (2015) Technical Privacy Metrics: A Systematic Survey, , arXiv preprint arXiv:1512. 00327; Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G.S., Zheng, X., (2015) TensorFlow: Large-scale Machine Learning on Heterogeneous Systems,., , https://www.tensor_ow.org/, software available from tensor-ow. org; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Bernstein, M., Imagenet large scale visual recognition challenge (2015) International Journal of Computer Vision, 115 (3), pp. 211-252",,,,"Institute of Electrical and Electronics Engineers Inc.","2018 IEEE Global Communications Conference, GLOBECOM 2018","9 December 2018 through 13 December 2018",,145422,,9781538647271,,,"English","IEEE Glob. Commun. Conf., GLOBECOM - Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85063422125
"Mudrakarta P.K., Taly A., Sundararajan M., Dhamdhere K.","56137067500;57208046968;55845419897;8593470600;","Did the model understand the question?",2018,"ACL 2018 - 56th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference (Long Papers)","1",,,"1896","1906",,49,"10.18653/v1/p18-1176","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062906615&doi=10.18653%2fv1%2fp18-1176&partnerID=40&md5=cf1e693cad0a0e5abfe20286eb28e4c1","University of Chicago, United States; Google Brain, United States; Google, United States","Mudrakarta, P.K., University of Chicago, United States; Taly, A., Google Brain, United States; Sundararajan, M., Google, United States; Dhamdhere, K., Google, United States","We analyze state-of-the-art deep learning models for three tasks: question answering on (1) images, (2) tables, and (3) passages of text. Using the notion of attribution (word importance), we find that these deep networks often ignore important question terms. Leveraging such behavior, we perturb questions to craft a variety of adversarial examples. Our strongest attacks drop the accuracy of a visual question answering model from 61.1% to 19%, and that of a tabular question answering model from 33.5% to 3.3%. Additionally, we show how attributions can strengthen attacks proposed by Jia and Liang (2017) on paragraph comprehension models. Our results demonstrate that attributions can augment standard measures of accuracy and empower investigation of model performance. When a model is accurate but for the wrong reasons, attributions can surface erroneous logic in the model that indicates inadequacies in the test data. © 2018 Association for Computational Linguistics",,"Computational linguistics; Comprehension models; Learning models; Model performance; Question Answering; State of the art; Test data; Deep learning",,,,,"Agrawal, A., Batra, D., Parikh, D., (2016) Analyzing the Behavior of Visual Question Answering Models, , arXiv preprint; Agrawal, A., Lu, J., Antol, S., Mitchell, M., Lawrence Zitnick, C., Batra, D., Parikh, D., (2015) Vqa: Visual Question Answering, , arXiv preprint; Baehrens, D., Schroeter, T., Harmel-Ing, S., Kawanabe, M., Hansen, K., Müller, K.-R., How to explain individual classification decisions (2010) Journal of Machine Learning Research, pp. 1803-1831; Ben-Younes, H., Cadene, R., Cord, M., Thome, N., (2017) Mutan: Multimodal Tucker Fusion for Visual Question Answering, , arXiv preprint; Binder, A., Montavon, G., Bach, S., Müller, K.-R., Samek, W., Layer-wise relevance propagation for neural networks with local renormalization layers (2016) CoRR; Fong, R.C., Vedaldi, A., Interpretable explanations of black boxes by meaningful perturbation (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3429-3437; Fukui, A., Park, D.H., Yang, D., Rohrbach, A., Darrell, T., Rohrbach, M., (2016) Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding, , arXiv preprint; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations; Goyal, Y., Khot, T., Summers-Stay, D., Batra, D., Parikh, D., (2016) Making the V in Vqa Matter: Elevating the Role of Image Understanding in Visual Question Answering, , arXiv preprint; Huang, J.-H., Dao, C.D., Alfadly, M., Ghanem, B., (2017) A Novel Framework for Robustness Analysis of Visual Qa Models, , arXiv preprint; Jia, R., Liang, P., Adversarial examples for evaluating reading comprehension systems (2017) Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, EMNLP 2017, , Copenhagen, Denmark, September 9-11, 2017; Kafle, K., Kanan, C., An analysis of visual question answering algorithms (2017) 2017 IEEE International Conference on Computer Vision (ICCV), pp. 1983-1991. , IEEE; Kazemi, V., Elqursh, A., (2017) Show, Ask, Attend, and Answer: A Strong Baseline for Visual Question Answering, , arXiv preprint; Krishnamurthy, J., Dasigi, P., Gardner, M., Neural semantic parsing with type constraints for semi-structured tables (2017) Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pp. 1516-1526; Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Dollár, P., Lawrence Zitnick, C., Microsoft coco: Common objects in context (2014) European Conference on Computer Vision, pp. 740-755. , Springer; Mudrakarta, P.K., Taly, A., Sundararajan, M., Dhamdhere, K., (2018) It Was the Training Data Pruning Too!, , arXiv preprint; Neelakantan, A., Le, Q.V., Abadi, M., McCallum, A., Amodei, D., (2017) Learning a Natural Language Interface with Neural Programmer; Neelakantan, A., Le, Q.V., Sutskever, I., Neural programmer: Inducing latent programs with gradient descent (2016) International Conference on Learning Representations ICLR; Pasupat, P., Liang, P., Compositional semantic parsing on semi-structured tables (2015) Proceedings of the Annual Meeting of the Association for Computational Linguistics, , In; Pasupat, P., Liang, P., (2016) Inferring Logical Forms from Denotations, , arXiv preprint; Pennington, J., Socher, R., Manning, C.D., Glove: Global vectors for word representation (2014) Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014, pp. 1532-1543. , October 25-29, 2014, Doha, Qatar, A meeting of SIGDAT, a Special Interest Group of the ACL; Rajpurkar, P., Zhang, J., Lopyrev, K., Liang, P., Squad: 100, 000+ questions for machine comprehension of text (2016) Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, EMNLP 2016, pp. 2383-2392. , Austin, Texas, USA, November 1-4, 2016; Ribeiro, M.T., Singh, S., Guestrin, C., (2016) Nothing Else Matters: Model-Agnostic Explanations by Identifying Prediction Invariance, , arXiv preprint; Ribeiro, M.T., Singh, S., Guestrin, C., Why should i trust you?: Explaining the predictions of any classifier (2016) Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 1135-1144. , ACM; Shrikumar, A., Greenside, P., Shcherbina, A., Kundaje, A., Not just a black box: Learning important features through propagating activation differences (2016) CoRR; Simonyan, K., Vedaldi, A., Zisser-Man, A., Deep inside convolutional networks: Visualising image classification models and saliency maps (2013) CoRR; Springenberg, J.T., Dosovitskiy, A., Brox, T., Riedmiller, M.A., (2014) Striving for Simplicity: The All Convolutional Net, , CoRR; Sundararajan, M., Taly, A., Yan, Q., Axiomatic attribution for deep networks (2017) Proceedings of the 34th International Conference on Machine Learning, ICML 2017, pp. 3319-3328. , Sydney, NSW, Australia, 6-11 August 2017; Teney, D., Anderson, P., He, X., Van Den Hengel, A., (2017) Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge, , arXiv preprint; Yu, A.W., Dohan, D., Le, Q., Luong, T., Zhao, R., Chen, K., Fast and accurate reading comprehension by combining self-attention and convolution (2018) International Conference on Learning Representations; Zhang, P., Goyal, Y., Summers-Stay, D., Batra, D., Parikh, D., Yin and yang: Balancing and answering binary visual questions (2016) Computer Vision and Pattern Recognition (CVPR), 2016 IEEE Conference on, pp. 5014-5022. , IEEE; Zhu, Y., Groth, O., Bernstein, M., Fei-Fei, L., Visual7W: Grounded question answering in images (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4995-5004",,,"Apple;ByteDance;et al.;Facebook;Google;Samsung Research","Association for Computational Linguistics (ACL)","56th Annual Meeting of the Association for Computational Linguistics, ACL 2018","15 July 2018 through 20 July 2018",,145927,,9781948087322,,,"English","ACL - Annu. Meet. Assoc. Comput. Linguist., Proc. Conf. (Long Pap.)",Conference Paper,"Final","All Open Access, Hybrid Gold, Green",Scopus,2-s2.0-85062906615
"Tao G., Ma S., Liu Y., Zhang X.","57209545399;57145548500;57192571891;35489738100;","Attacks meet interpretability: Attribute-steered detection of adversarial samples",2018,"Advances in Neural Information Processing Systems","2018-December",,,"7717","7728",,47,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062871720&partnerID=40&md5=5649bd5fbba60c1b8fa5a88b2fd3a73f","Department of Computer Science, Purdue University, United States","Tao, G., Department of Computer Science, Purdue University, United States; Ma, S., Department of Computer Science, Purdue University, United States; Liu, Y., Department of Computer Science, Purdue University, United States; Zhang, X., Department of Computer Science, Purdue University, United States","Adversarial sample attacks perturb benign inputs to induce DNN misbehaviors. Recent research has demonstrated the widespread presence and the devastating consequences of such attacks. Existing defense techniques either assume prior knowledge of specific attacks or may not work well on complex models due to their underlying assumptions. We argue that adversarial sample attacks are deeply entangled with interpretability of DNN models: while classification results on benign inputs can be reasoned based on the human perceptible features/attributes, results on adversarial samples can hardly be explained. Therefore, we propose a novel adversarial sample detection technique for face recognition models, based on interpretability. It features a novel bi-directional correspondence inference between attributes and internal neurons to identify neurons critical for individual attributes. The activation values of critical neurons are enhanced to amplify the reasoning part of the computation and the values of other neurons are weakened to suppress the uninterpretable part. The classification results after such transformation are compared with those of the original model to detect adversaries. Results show that our technique can achieve 94% detection accuracy for 7 different kinds of attacks with 9.91% false positives on benign inputs. In contrast, a state-of-the-art feature squeezing technique can only achieve 55% accuracy with 23.3% false positives. © 2018 Curran Associates Inc.All rights reserved.",,"Neurons; Activation value; Classification results; Critical neurons; Defense techniques; Detection accuracy; Recent researches; Recognition models; State of the art; Face recognition",,,,,"Kalchbrenner, N., Grefenstette, E., Blunsom, P., (2014) A Convolutional Neural Network for Modelling Sentences, , arXiv preprint; Zhou, B., Lapedriza, A., Xiao, J., Torralba, A., Oliva, A., Learning deep features for scene recognition using places database (2014) Advances in Neural Information Processing Systems (NIPS), pp. 487-495; Ren, S., He, K., Girshick, R., Sun, J., Faster R-CNN: Towards real-time object detection with region proposal networks (2015) Advances in Neural Information Processing Systems (NIPS), pp. 91-99; Du, M., Li, F., Zheng, G., Srikumar, V., Deeplog: Anomaly detection and diagnosis from system logs through deep learning (2017) Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security (CCS), pp. 1285-1298; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations (ICLR); Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy (S&P), pp. 39-57; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security (AISec), pp. 3-14; Liu, Y., Ma, S., Aafer, Y., Lee, W.-C., Zhai, J., Wang, W., Zhang, X., Trojaning attack on neural networks (2018) Proceedings of the 25nd Annual Network and Distributed System Security Symposium (NDSS); Pei, K., Cao, Y., Yang, J., Jana, S., Deepxplore: Automated whitebox testing of deep learning systems (2017) Proceedings of the 26th Symposium on Operating Systems Principles (SOSP), pp. 1-18; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , arXiv preprint; Gu, S., Rigazio, L., (2014) Towards Deep Neural Network Architectures Robust to Adversarial Examples, , arXiv preprint; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) IEEE Symposium on Security and Privacy (S&P), pp. 582-597; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts, , arXiv preprint; Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., (2017) On the (Statistical) Detection of Adversarial Examples, , arXiv preprint; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., (2017) On Detecting Adversarial Perturbations, , arXiv preprint; Xu, W., Evans, D., Qi, Y., Feature squeezing: Detecting adversarial examples in deep neural networks (2018) Proceedings of the 25nd Annual Network and Distributed System Security Symposium (NDSS); Parkhi, O.M., Vedaldi, A., Zisserman, A., Deep face recognition (2015) Proceedings of the British Machine Vision Conference (BMVC), pp. 1-12; Erhan, D., Bengio, Y., Courville, A., Vincent, P., Visualizing higher-layer features of a deep network (2009) University of Montreal, 1341 (3), p. 1; Simonyan, K., Vedaldi, A., Zisserman, A., (2013) Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps, , arXiv preprint; Mahendran, A., Vedaldi, A., Visualizing deep convolutional neural networks using natural pre-images (2016) International Journal of Computer Vision, 120 (3), pp. 233-255; Yosinski, J., Clune, J., Nguyen, A., Fuchs, T., Lipson, H., (2015) Understanding Neural Networks Through Deep Visualization, , arXiv preprint; Nguyen, A., Yosinski, J., Clune, J., (2016) Multifaceted Feature Visualization: Uncovering the Different Types of Features Learned By Each Neuron in Deep Neural Networks, , arXiv preprint; (2018) AmIAttribute/AmI, , https://github.com/AmIAttribute/AmI; Bau, D., Zhou, B., Khosla, A., Oliva, A., Torralba, A., Network dissection: Quantifying interpretability of deep visual representations (2017) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 3319-3327; Brown, T.B., Mané, D., Roy, A., Abadi, M., Gilmer, J., (2017) Adversarial Patch, , arXiv preprint cs.CV/1712.09665; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security (CCS), pp. 1528-1540; King, D.E., Dlib-mL: A machine learning toolkit (2009) Journal of Machine Learning Research (JMLR), 10, pp. 1755-1758; Takeda, H., Farsiu, S., Milanfar, P., Kernel regression for image processing and reconstruction (2007) IEEE Transactions on Image Processing, 16 (2), pp. 349-366; Buades, A., Coll, B., Morel, J.-M., A non-local algorithm for image denoising (2005) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2, pp. 60-65; Nasrabadi, N.M., Pattern recognition and machine learning (2007) Journal of Electronic Imaging, 16 (4), p. 049901; Huang, G.B., Ramesh, M., Berg, T., Learned-Miller, E., (2007) Labeled Faces in the Wild: A Database for Studying Face Recognition in Unconstrained Environments, , Technical report, Technical Report 07-49, University of Massachusetts, Amherst; Liu, Z., Luo, P., Wang, X., Tang, X., Deep learning face attributes in the wild (2015) IEEE International Conference on Computer Vision (ICCV), pp. 3730-3738; Kumar, N., Berg, A.C., Belhumeur, P.N., Nayar, S.K., Attribute and simile classifiers for face verification (2009) IEEE International Conference on Computer Vision (ICCV), pp. 365-372; Papernot, N., Carlini, N., Goodfellow, I., Feinman, R., Faghri, F., Matyasko, A., Hambardzumyan, K., Sheatsley, R., (2016) CleverHans V2.0.0: An Adversarial Machine Learning Library, , arXiv preprint; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proceedings of the IEEE, 86 (11), pp. 2278-2324; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images",,"Bengio S.Grauman K.Garnett R.Wallach H.Larochelle H.Grauman K.Cesa-Bianchi N.",,"Neural information processing systems foundation","32nd Conference on Neural Information Processing Systems, NeurIPS 2018","2 December 2018 through 8 December 2018",,147412,10495258,,,,"English","Adv. neural inf. proces. syst.",Conference Paper,"Final","",Scopus,2-s2.0-85062871720
"Burns J.P., Green C.D., Nolan J.","57201579362;56219995500;57207117472;","New genealogies and the courage of truth: Toward an ethics of adversarial public educational scholarship and policy activism [Novas genealogias e a coragem da verdade: Uma ética do conhecimento educacional adversarial e do ativismo político] [Nuevas genealogías y el valor de la verdad: Una ética de la erudición educativa pública contradictoria y el activismo político]",2018,"Education Policy Analysis Archives","26",,"151","","",,1,"10.14507/epaa.26.3397","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062236301&doi=10.14507%2fepaa.26.3397&partnerID=40&md5=92695a7c5127fcb12a0a45a79ac69f8c","Florida International University, United States; The George Washington University, United States; Washington State University, United States","Burns, J.P., Florida International University, United States; Green, C.D., The George Washington University, United States; Nolan, J., Washington State University, United States","Science denial in the post-truth era is driven by both the rejection of empirical science and the fraudulent use of scientific language. Education policy based on junk science produced by philanthrocapitalists depoliticizes political questions by relocating complex legislative and policy issues from the realm of political and philosophical discourse to that of scientific rationality using metrics and methods that are themselves fatally flawed. Dominant configurations of institutional power also attack scholarship that both debunks spurious causal claims and establishes causal links to existential crises, which in both cases inconveniences the neoliberal capitalist project. We discuss the methodological implications of education research as the counter-conduct of policy advocacy against power claims based on both the rejection of empirical science and the production of junk science. We both discuss and model Foucault’s tactic of genealogy and his analysis of parrhēsia, or truth telling, through creating an imperfect, preliminary genealogy of the “new” post-truth era, which contextualizes contemporary technologies of alternative facts in the history of public relations and propaganda that extend to the early 20th century. The methodological and political tactic of genealogy could be a move toward a new ethics of adversarial public scholarship that seeks to reconfigure what counts as scholarship in academia, itself a rationalizing disciplinary institution. Considering the moment, the study of power, the academy’s roles both in subverting and perpetuating it, and the necessity of epistemological and methodological counter-conduct have perhaps never been more important. © 2018, Arizona State University. All rights reserved.","Foucault; Genealogy; Neoliberalism; Post-truth; Propaganda; Public relations; Qualitative research methods; Truth-telling",,,,,,"Amrein-Beardsley, A., (2014) Rethinking Value-Added Models in Education: Critical Perspectives on Tests and Assessment-Based Accountability, , New York, NY: Routledge; Baldwin, J., The white man’s guilt (1998) Baldwin: Collected Essays, pp. 722-727. , T. Morrison, New York, NY: The Library of America. (Original work published 1965); Berliner, D., Exogenous variables and value-added assessments: A fatal flaw (2014) Teachers College Record, 116 (1), pp. 1-31; Bernays, E., (1923) Crystalizing Public Opinion, , New York, NY: Ig Publishing; Bernays, E., Molding public opinion (1935) Annals of the American Academy of Political and Social Science, 179 (1), pp. 82-87. , https://doi.org/10.1177/000271623517900111; Bernays, E., The engineering of consent (1947) Annals of the American Academy of Political and Social Science, 250 (1), pp. 113-120. , https://doi.org/10.1177/000271624725000116; Bernays, E., (2005) Propaganda, p. 1928. , New York, NY: Ig Publishing. (Original work published; Connell, R., Masculinity research and global change (2012) Masculinity and Social Change, 1 (10), pp. 4-18; Connell, R., Using southern theory: Decolonizing social thought in theory, research, and application (2014) Planning Theory, 13 (2), pp. 210-223. , https://doi.org/10.1177/1473095213499216; Crozier, M., Huntington, S., Watanuki, J., (1975) The Crisis of Democracy: Report on the Governability of Democracies to the Trilateral Commission, , New York, NY: New York University Press; Davenport, C., How much has ‘climate change’ been scrubbed from federal websites? (2018) A Lot. the New York Times, , https://www.nytimes.com/2018/01/10/climate/climate-change-trump.html, January 10; Ewen, S., (1996) PR!: A Social History of Spin, , New York, NY: Basic Books; Foucault, M., (1994) The Order of Things: An Archaeology of the Human Sciences, , New York, NY: Vintage Books. (Original work published 1970); Foucault, M., (1995) Discipline & Punish: The Birth of The Prison (A. Sheridan, Trans.), , New York, NY: Vintage. (Original work published 1977); Foucault, M., (2003) Society Must Be Defended: Lectures at the Collège De France 1975-1976, , (D. Macey, Trans.). M. Bertani & A. Fontana (Eds.). New York, NY: Picador; Foucault, M., (2007) Security, Territory, Population: Lectures at the Collège De France, pp. 1977-1978. , G. Burchell, Trans.). M. Senellart (Ed.). New York, NY: Picador; Foucault, M., (2008) The Birth of Biopolitics: Lectures at the Collège De France 1977-1978, , G. Burchell, Trans.). M. Senellart (Ed.). New York, NY: Picador; Foucault, M., (2011) The Courage of Truth: Lectures at the Collège De France 1983-1984, , G. Burchell, Trans.). F. Gros (Ed.). New York, NY: Picador; Friedman, M., The role of government in education (1955) Economics and the Public Interest, , http://la.utexas.edu/users/hcleaver/330T/350kPEEFriedmanRoleOfGovttable.pdf, R. A. Solo, New Brunswick, NJ: Rutgers University Press; Giroux, H., (2012) Education and the Crisis of Public Values: Challenging the Assault on Teachers, Students, & Public Education, , New York, NY: Peter Lang; Goodall, H., (2010) Counter-Narrative: How Progressive Academics Can Challenge Extremists and Promote Social Justice, , Walnut Creek, CA: Left Coast Press; Harvey, D., (2005) A Brief History of Neoliberalism, , New York, NY: Oxford University Press; Hofstadter, R., (1962) Anti-Intellectualism in American Life, , New York, NY: Vintage Books; Jay, M., (1988) Fin De siècle Socialism and Other Essays, , New York, NY: Routledge; Klein, N., (2007) The Shock Doctrine: The Rise of Disaster Capitalism, , New York, NY: Picador; Kumashiro, K., Toward a theory of anti-oppressive education (2000) Review of Educational Research, 70 (1), pp. 25-53. , https://doi.org/10.3102/00346543070001025; Kumashiro, K., (2008) The Seduction of Common Sense: How the Right has Framed the Debate on America’s Schools, , New York, NY: Teachers College Press; Kumashiro, K., (2012) Bad Teacher! How Blaming Teachers Distorts the Bigger Picture, , New York, NY: Teachers College Press; Kuntz, A., (2015) The Responsible Methodologist: Inquiry, Truth-Telling, and Social Justice, , Walnut Creek, CA: Left Coast Press; Lafer, G., (2017) The One Percent Solution: How Corporations are Remaking America One State at a Time, , https://doi.org/10.7591/cornell/9781501703065.001.0001, Ithaca, NY: ILR/Cornell University Press; Lasch, C., (1996) The Revolt of the Elites and the Betrayal of Democracy, , New York, NY: Norton; Le Bon, G., (2002) The Crowd: A Study of the Popular Mind. Mineola, NY: Dover Publications, , (Original work published 1896); Lippmann, W., (1993) The Phantom Public. New Brunswick, NJ: Transaction Publishers, , (Original work published 1927); Lippmann, W., (1997) Public Opinion, , New York, NY: The Free Press. (Original work published 1922); Lorde, A., (1984) Sister Outsider: Essays & Speeches by Audre Lorde, , Berkeley, CA: Crossing Press; Maclean, N., (2017) Democracy in Chains: The Deep History of The Radical right’s Stealth Plan for America, , New York, NY: Viking; Meier, B., Origins of an epidemic: Purdue Pharma knew its opioids were widely abused (2018) The New York Times, , https://www.nytimes.com/2018/05/29/health/purdue-opioids-oxycontin.html, May 29; Monbiot, G., Why are the crucial questions about Hurricane Harvey not being asked? (2017) The Guardian, , https://www.theguardian.com/commentisfree/2017/aug/29/hurricane-harvey-manmade-climate-disaster-world-catastrophe, August 29; Nietzsche, F., On the uses and abuses of history for life (R. J. Hollingdale, Trans.) (1997) Untimely Meditations, pp. 59-123. , https://doi.org/10.1017/CBO9780511812101.007, D. Breazeale, Cambridge, UK: Cambridge University Press., (Original work published 1874); Pinar, W., (2006) The Synoptic Text Today and Other Essays: Curriculum Development after the Reconceptualization, , New York, NY: Peter Lang; Pinar, W., (2011) The Character of Curriculum Studies: Bildung, Currere, and the Recurring Question of the Subject, , New York, NY: Palgrave Macmillan; Pinar, W., (2012) What is Curriculum Theory?, , 2nd ed.). New York, NY: Routledge; Oxford English Living Dictionaries, , https://en.oxforddictionaries.com/word-of-the-year/word-of-the-year-2016; Powell, L., (1971) Confidential Memorandum: Attack on American Free Enterprise System, , https://law2.wlu.edu/deptimages/Powell%20Archives/PowellMemorandumTypescript.pdf, August 23; Ravitch, D., (2010) The Death and Life of the Great American School System: How Testing and Choice are Undermining Education, , New York, NY: Basic Books; Shore, C., Wright, S., Audit culture and anthropology: Neo-liberalism in British higher education (1999) The Journal of the Royal Anthropological Institute, 5 (4), pp. 557-575. , https://doi.org/10.2307/2661148; Shore, C., Wright, S., Coercive accountability: The rise of audit culture in higher education (2000) Audit Cultures: Anthropological Studies in Accountability, Ethics, and the Academy, pp. 57-89. , M. Strathern, New York, NY: Routledge; Taubman, P., (2009) Teaching by Numbers: Deconstructing the Discourse of Standards and Accountability in Education, , New York, NY: Routledge; Tesich, S., A government of lies (1992) The Nation, pp. 12-14. , January 6-13; Tuck, E., Suspending damage: A letter to communities (2009) Harvard Educational Review, 79 (3), pp. 409-427. , https://doi.org/10.17763/haer.79.3.n0016675661t3n15",,,,"Arizona State University",,,,,10682341,,,,"English","Educ. Policy Anal. Arch.",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85062236301
"Ma Y., He Y., Tian Y.","57202033694;57202028465;9272686000;","Online Robust Lagrangian Support Vector Machine against Adversarial Attack",2018,"Procedia Computer Science","139",,,"173","181",,1,"10.1016/j.procs.2018.10.239","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062002352&doi=10.1016%2fj.procs.2018.10.239&partnerID=40&md5=e0c0e11fce9dd850390cd12fd7efce9d","School of Mathematical Sciences, University of Chinese Academy of Sciences, Beijing, 100049, China; Research Center on Fictitious Economy and Data Science, Chinese Academy of Sciences, Beijing, 100190, China; School of Computer and Control Engineering, University of Chinese Academy of Sciences, Beijing, 100049, China; Key Laboratory of Big Data Mining and Knowledge Management, Beijing, 100190, China; School of Economics and Management, University of Chinese Academy of Sciences, Beijing, 100190, China","Ma, Y., School of Mathematical Sciences, University of Chinese Academy of Sciences, Beijing, 100049, China, Research Center on Fictitious Economy and Data Science, Chinese Academy of Sciences, Beijing, 100190, China; He, Y., School of Computer and Control Engineering, University of Chinese Academy of Sciences, Beijing, 100049, China; Tian, Y., Research Center on Fictitious Economy and Data Science, Chinese Academy of Sciences, Beijing, 100190, China, Key Laboratory of Big Data Mining and Knowledge Management, Beijing, 100190, China, School of Economics and Management, University of Chinese Academy of Sciences, Beijing, 100190, China","In adversarial environment such as intrusion detection and spam filtering, the adversary-intruder or spam advertiser may attempt to produce contaminate training instance and manipulate the learning of classifier. In order to keep good classification performance, many robuster learning methods have been proposed to deal with the adversarial attack. Support Vector Machines(SVMs) is a kind of successful approach in the adversarial classification tasks and the investigation of robust SVMs is very popular. However, in many real application, the data including stain instance is coming dynamically. Batch learning which needs retraining when encountering new samples, will consume more computing resources. In this paper, we propose a robust Lagrangian support vector machine (RLSVM) with modified kernel matrix and explore the online learning algorithm on it. The experimental results show the robustness of RLSVM against label noise produced by adversaries under the online adversarial environment. © 2018 The Authors. Published by Elsevier B.V.","adversarial attack; label noise; Lagrangian SVM; online learning; poison attack","E-learning; Intrusion detection; Lagrange multipliers; Learning algorithms; adversarial attack; Adversarial classifications; Lagrangian; Lagrangian support vector machines; Online learning; Online learning algorithms; poison attack; Support vector machine (SVMs); Support vector machines",,,,,"Lowd, D., Meek, C., Good word attacks on statistical spam filters (2005) CEAS, 2005; Sculley, D., Wachman, G.M., Relaxed online svms for spam filtering (2007) Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pp. 415-422. , ACM; Mukkamala, S., Janoski, G., Sung, A., Intrusion detection using neural networks and support vector machines (2002) Neural Networks, 2002. IJCNN'02. Proceedings of the 2002 International Joint Conference on, 2, pp. 1702-1707. , IEEE 2002; Newsome, J., Karp, B., Song, D., Paragraph: Thwarting signature learning by training maliciously (2006) International Workshop on Recent Advances in Intrusion Detection, pp. 81-105. , Springer; Laishram, R., Phoha, V.V., Curie: A Method for Protecting Svm Classifier from Poisoning Attack, , arXiv preprint arXiv; Tian, Y., Qi, Z., Ju, X., Shi, Y., Liu, X., Nonparallel support vector machines for pattern classification (2014) IEEE Transactions on Cybernetics, 44 (7), pp. 1067-1079; Tian, Y., Ju, X., Qi, Z., Shi, Y., Improved twin support vector machine (2014) Science China Mathematics, 57 (2), pp. 417-432; Tang, J., Tian, Y., Zhang, P., Liu, X., Multiview privileged support vector machines IEEE Transactions on Neural Networks and Learning Systems; Lin, X., Chan, P.P., Causative attack to incremental support vector machine (2014) Machine Learning and Cybernetics (ICMLC), 2014 International Conference on, 1, pp. 137-142. , IEEE; Xiao, H., Biggio, B., Nelson, B., Xiao, H., Eckert, C., Roli, F., Support vector machines under adversarial label contamination (2015) Neurocomputing, 160, pp. 53-62; Biggio, B., Nelson, B., Laskov, P., Poisoning Attacks Against Support Vector Machines, , arXiv preprint arXiv; Stempfel, G., Ralaivola, L., Learning svms from sloppily labeled data (2009) International Conference on Artificial Neural Networks, pp. 884-893. , Springer; Natarajan, N., Dhillon, I.S., Ravikumar, P.K., Tewari, A., Learning with noisy labels (2013) Advances in Neural Information Processing Systems, pp. 1196-1204; Biggio, B., Nelson, B., Laskov, P., Support vector machines under adversarial label noise (2011) Asian Conference on Machine Learning, pp. 97-112; Syed, N.A., Huan, S., Kah, L., Sung, K., Incremental Learning with Support Vector Machines; Ruping, S., Incremental learning with support vector machines (2001) Data Mining, 2001. ICDM 2001, Proceedings IEEE International Conference on, pp. 641-642. , IEEE; Kivinen, J., Smola, A.J., Williamson, R.C., Online learning with kernels (2004) IEEE Transactions on Signal Processing, 52 (8), pp. 2165-2176; Cauwenberghs, G., Poggio, T., Incremental and decremental support vector machine learning (2001) Advances in Neural Information Processing Systems, pp. 409-415; Duan, H., Shao, X., Hou, W., He, G., Zeng, Q., An incremental learning algorithm for lagrangian support vector machines (2009) Pattern Recognition Letters, 30 (15), pp. 1384-1391; Mangasarian, O.L., Musicant, D.R., Lagrangian support vector machines (2001) Journal of Machine Learning Research, 1 (MAR), pp. 161-177; Mangasarian, O.L., Musicant, D.R., Successive overrelaxation for support vector machines (1999) IEEE Transactions on Neural Networks, 10 (5), pp. 1032-1037; Lee, Y.-J., Mangasarian, O.L., Ssvm: A smooth support vector machine for classification (2001) Computational Optimization and Applications, 20 (1), pp. 5-22; Yuan, Y.X., Sun, W., (1997) Optimization Theories and Methods, , Science Press; Lichman, M., (2013) UCI Machine Learning Repository, , http://archive.ics.uci.edu/ml","Tian, Y.; Research Center on Fictitious Economy and Data Science, China; email: tyj@ucas.ac.cn",,,"Elsevier B.V.","6th International Conference on Information Technology and Quantitative Management, ITQM 2018","20 October 2018 through 21 October 2018",,140788,18770509,,,,"English","Procedia Comput. Sci.",Conference Paper,"Final","All Open Access, Gold",Scopus,2-s2.0-85062002352
"Ozdag M.","57206787743;","Adversarial attacks and defenses against deep neural networks: A survey",2018,"Procedia Computer Science","140",,,"152","161",,22,"10.1016/j.procs.2018.10.315","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061991844&doi=10.1016%2fj.procs.2018.10.315&partnerID=40&md5=589f96feb8ee7203b7b8b57635c5a0d4","University of Central Florida, 4000 Central Florida Blvd, Orlando, FL  32816, United States","Ozdag, M., University of Central Florida, 4000 Central Florida Blvd, Orlando, FL  32816, United States","Deep learning has achieved great successes in various types of applications over recent years. On the other hand, it has been found that deep neural networks (DNNs) can be easily fooled by adversarial input samples. This vulnerability raises major concerns in security-sensitive environments. Therefore, research in attacking and defending DNNs with adversarial examples has drawn great attention. The goal of this paper is to review the types of adversarial attacks and defenses, describe the state-of-the-art methods for each group, and compare their results. In addition, we present some of the top-scored competition submissions for Neural Information Processing Systems (NIPS) in 2017, their solution models, and demonstrate their results. This adversary competition was organized by Google Brain for research scientists to come up with novel solutions that generate adversarial examples and also defend against them. Its contribution is significant on this era of machine learning and DNNs. © 2018 The Authors. Published by Elsevier B.V.","Adversarial examples; Deep learning; Deep neural network; Security","Adaptive systems; Complex networks; Deep learning; Embedded systems; Adversarial examples; Input sample; Neural information processing systems; Novel solutions; Security; Solution model; State-of-the-art methods; Deep neural networks",,,,,"Middlehurst, C., (2015) China Unveils World'S First Facial Recognition Atm, , http://www.telegraph.co.uk/news/worldnews/asia/china/11643314/China-unveils-worlds-first-facial-recognition-ATM.html; Harvey, A., Dazzle, C.V., (2010) Camouflage from Face Detection, , http://cvdazzle.com, Master's thesis, New York University; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proceedings of The 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540. , ACM, 2016; Face Recognition, , http://www.nec.com/en/global/solutions/biometrics/technologies/facerecognition.html; SentiVeillance SDK, , http://www.neurotechnology.com/sentiveillance.html; Amodei, D., Anubhai, R., Battenberg, E., Case, C., Casper, J., Catanzaro, B., Chen, J., Diamos, G., Deep speech 2: End-to-end speech recognition in english and Mandarin (2016) International Conference on Machine Learning, pp. 173-182; iOS - Siri - Apple, , https://www.apple.com/ios/siri/; https://developer.amazon.com/alexa; Cortana - Your Intelligent Virtual and Personal Assistant - Microsoft, , https://www.microsoft.com/en-us/windows/cortana; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in The Physical World, , arXiv preprint; Evtimov, I., Eykholt, K., Fernandes, E., Kohno, T., Li, B., Prakash, A., Rahmati, A., Song, D., (2017) Robust Physical-World Attacks on Deep Learning Models, 1. , arXiv preprint; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., Adversarial examples for semantic segmentation and object detection (2017) International Conference on Computer Vision, , IEEE; Carlini, N., Wagner, D., (2016) Towards Evaluating The Robustness of Neural Networks, , arXiv preprint; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , https://github.com/MadryLab/mnist\_challengeand, arXiv preprint The complete code, along with the description of the challenge, is https://github.com/MadryLab/cifar10\_challenge; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2014) CoRR, , http://arxiv.org/abs/1412.6572, abs/1412.6572. URL; Dong, Y., Liao, F., Pang, T., Su, H., Hu, X., Li, J., Zhu, J., (2017) Boosting Adversarial Attacks with Momentum, , arXiv preprint; Kurakin, A., Goodfellow, I.J., Bengio, S., (2016) Adversarial Machine Learning at Scale, , arXiv preprint; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) IEEE Symposium on Security and Privacy; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Proceedings of The 1st IEEE European Symposium on Security and Privacy, pp. 372-387. , 2016b; https://www.kaggle.com/google-brain/nips17-adversarial-learning-final-results; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) CVPR; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., Inception-v4, inception-resnet and the impact of residual connections on learning (2017) AAAI; He, K., Zhang, X., Ren, S., Sun, J., Identity mappings in deep residual networks (2016) ECCV; Tram'r, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P.D., (2017) Ensemble Adversarial Training: Attacks and Defenses, , arXiv preprint; Liao, F., Liang, M., Dong, Y., Pang, T., Zhu, J., Hu, X., (2017) Defense Against Adversarial Attacks Using High-Level Representation Guided Denoiser, , arXiv preprint","Ozdag, M.; University of Central Florida, 4000 Central Florida Blvd, United States",,,"Elsevier B.V.","Complex Adaptive Systems Conference with Theme: Cyber Physical Systems and Deep Learning, CAS 2018","5 November 2018 through 7 November 2018",,140798,18770509,,,,"English","Procedia Comput. Sci.",Conference Paper,"Final","All Open Access, Gold",Scopus,2-s2.0-85061991844
"Goswami G., Ratha N., Agarwal A., Singh R., Vatsa M.","56653684100;6603955463;57188752637;15061841400;55908650100;","Unravelling robustness of deep learning based face recognition against adversarial attacks",2018,"32nd AAAI Conference on Artificial Intelligence, AAAI 2018",,,,"6829","6836",,66,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060489154&partnerID=40&md5=c0cf357c48a40e23a9041f1c372f95eb","IIIT, Delhi, India; IBM IRL, Bangalore, India; IBM TJ Watson Research Center, United States","Goswami, G., IIIT, Delhi, India, IBM IRL, Bangalore, India; Ratha, N., IBM TJ Watson Research Center, United States; Agarwal, A., IIIT, Delhi, India; Singh, R., IIIT, Delhi, India; Vatsa, M., IIIT, Delhi, India","Deep neural network (DNN) architecture based models have high expressive power and learning capacity. However, they are essentially a black box method since it is not easy to mathematically formulate the functions that are learned within its many layers of representation. Realizing this, many researchers have started to design methods to exploit the drawbacks of deep learning based algorithms questioning their robustness and exposing their singularities. In this paper, we attempt to unravel three aspects related to the robustness of DNNs for face recognition: (i) assessing the impact of deep architectures for face recognition in terms of vulnerabilities to attacks inspired by commonly observed distortions in the real world that are well handled by shallow learning methods along with learning based adversaries; (ii) detecting the singularities by characterizing abnormal filter response behavior in the hidden layers of deep networks; and (iii) making corrections to the processing pipeline to alleviate the problem. Our experimental evaluation using multiple open-source DNN-based face recognition networks, including OpenFace and VGG-Face, and two publicly available databases (MEDS and PaSC) demonstrates that the performance of deep learning based face recognition algorithms can suffer greatly in the presence of such distortions. The proposed method is also compared with existing detection algorithms and the results show that it is able to detect the attacks with very high accuracy by suitably designing a classifier using the response of the hidden layers in the network. Finally, we present several effective countermeasures to mitigate the impact of adversarial attacks and improve the overall robustness of DNN-based face recognition. Copyright © 2018, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,"Artificial intelligence; Deep neural networks; Learning algorithms; Network architecture; Network layers; Architecture-based; Deep architectures; Detection algorithm; Experimental evaluation; Expressive power; Face recognition algorithms; Learning capacity; Learning-based algorithms; Face recognition",,,,,"Amos, B., Ludwiczuk, B., Harkes, J., Pillai, P., Elgazzar, K., Satyanarayanan, M., OpenFace: Face Recognition with Deep Neural Networks, , http://github.com/cmusatyalab/openface, Accessed: 2017-10-10; Beveridge, J., Phillips, P., Bolme, D., Draper, B., Given, G., Lui, Y.M., Teli, M., Cheng, S., The challenge of face recognition from digital point-and-shoot cameras (2013) IEEE Conference on Biometrics: Theory, Applications and Systems, pp. 1-8; Bhagoji, A.N., Cullina, D., Mittal, P., (2017) Dimensionality Reduction as a Defense Against Evasion Attacks on Machine Learning Classifiers, , arXiv preprint; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy, pp. 39-57; Das, N., Shanbhogue, M., Chen, S.-T., Hohman, F., Chen, L., Kounavis, M.E., Chau, D.H., (2017) Keeping the Bad Guys Out: Protecting and Vaccinating Deep Learning with Jpeg Compression, , arXiv preprint; Dhamecha, T.I., Singh, R., Vatsa, M., Kumar, A., Recognizing disguised faces: Human and machine evaluation (2014) PLOS ONE, 9 (7), pp. 1-16; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts, , arXiv preprint; Founds, A.P., Orlans, N., Genevieve, W., Watson, C.I., (2011) NIST Special Databse 32-Multiple Encounter Dataset II, , NIST Interagency/Internal Report 7807; Gong, Z., Wang, W., Ku, W.-S., (2017) Adversarial and Clean Data Are Not Twins, , arXiv preprint; Goodfellow, I.J., Shlens, J., Szegedy, C., (2015) Explaining and Harnessing Adversarial Examples, , ICLR arXiv preprint; Gross, R., Matthews, I., Cohn, J., Kanade, T., Baker, S., Multi-PIE (2010) Image and Vision Computing, 28 (5), pp. 807-813; Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., (2017) On the (Statistical) Detection of Adversarial Examples, , arXiv preprint; King, D.E., Dlib-mL: A machine learning toolkit (2009) Journal of Machine Learning Research, 10, pp. 1755-1758; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint; Liang, B., Li, H., Su, M., Li, X., Shi, W., Wang, X., Detecting adversarial examples in deep networks with adaptive noise reduction (2017) CoRR, , abs/1705.08378; Liu, J., Deng, Y., Bai, T., Huang, C., Targeting ultimate accuracy: Face recognition via deep embedding (2015) CoRR, , abs/1506.07310; Lu, J., Issaranon, T., Forsyth, D., (2017) Safetynet: Detecting and Rejecting Adversarial Examples Robustly, , arXiv preprint; Majumdar, A., Singh, R., Vatsa, M., Face verification via class sparsity based supervised encoding (2017) IEEE Transactions on Pattern Analysis and Machine Intelligence, 39 (6), pp. 1273-1280; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., (2017) On Detecting Adversarial Perturbations, , arXiv preprint; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) IEEE Conference on Computer Vision and Pattern Recognition; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) IEEE Conference on Computer Vision and Pattern Recognition, pp. 427-436; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) IEEE European Symposium on Security and Privacy, pp. 372-387; Parkhi, O.M., Vedaldi, A., Zisserman, A., Deep face recognition (2015) British Machine Vision Conference, 1, p. 6; Rauber, J., Brendel, W., Bethge, M., Foolbox v0.8.0: A python toolbox to benchmark the robustness of machine learning models (2017) CoRR, , abs/1707.04131; Schroff, F., Kalenichenko, D., Philbin, J., FaceNet: A unified embedding for face recognition and clustering (2015) IEEE Conference on Computer Vision and Pattern Recognition, pp. 815-823; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540; Sun, Y., Wang, X., Tang, X., Deeply learned face representations are sparse, selective, and robust (2015) IEEE Conference on Computer Vision and Pattern Recognition, pp. 2892-2900; Suykens, J.A., Vandewalle, J., Least squares support vector machine classifiers (1999) Neural Processing Letters, 9 (3), pp. 293-300; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint; Taigman, Y., Yang, M., Ranzato, M., Wolf, L., DeepFace: Closing the gap to human-level performance in face verification (2014) IEEE Conference on Computer Vision and Pattern Recognition, pp. 1701-1708; Viola, P., Jones, M.J., Robust real-time face detection (2004) International Journal of Computer Vision, 57 (2), pp. 137-154; Wu, X., He, R., Sun, Z., Tan, T., (2015) A Light Cnn for Deep Face Representation with Noisy Labels, , arXiv preprint",,,"Association for the Advancement of Artificial Intelligence","AAAI press","32nd AAAI Conference on Artificial Intelligence, AAAI 2018","2 February 2018 through 7 February 2018",,143510,,9781577358008,,,"English","AAAI Conf. Artif. Intell., AAAI",Conference Paper,"Final","",Scopus,2-s2.0-85060489154
"Luo B., Liu Y., Wei L., Xu Q.","57201127196;55787598200;55787378400;56583074400;","Towards imperceptible and robust adversarial example attacks against neural networks",2018,"32nd AAAI Conference on Artificial Intelligence, AAAI 2018",,,,"1652","1659",,34,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060486196&partnerID=40&md5=f256a5cef4f4b8053db383f0ed314c46","Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong","Luo, B., Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong; Liu, Y., Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong; Wei, L., Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong; Xu, Q., Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong","Machine learning systems based on deep neural networks, being able to produce state-of-the-art results on various perception tasks, have gained mainstream adoption in many applications. However, they are shown to be vulnerable to adversarial example attack, which generates malicious output by adding slight perturbations to the input. Previous adversarial example crafting methods, however, use simple metrics to evaluate the distances between the original examples and the adversarial ones, which could be easily detected by human eyes. In addition, these attacks are often not robust due to the inevitable noises and deviation in the physical world. In this work, we present a new adversarial example attack crafting method, which takes the human perceptual system into consideration and maximizes the noise tolerance of the crafted adversarial example. Experimental results demonstrate the efficacy of the proposed technique. Copyright © 2018, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,"Artificial intelligence; Human eye; Human perceptual system; Noise tolerance; Physical world; Simple metrics; State of the art; Deep neural networks",,,,,"Amato, F., López, A., Peña-Méndez, E.M., Vaňhara, P., Hampl, A., Havel, J., (2013) Artificial Neural Networks in Medical Diagnosis; Bojarski, M., Del Testa, D., Dworakowski, D., Firner, B., Flepp, B., Goyal, P., Jackel, L.D., Zhang, J., (2016) End to End Learning for Self-Driving Cars, , arXiv preprint; Carlini, N., Mishra, P., Vaidya, T., Zhang, Y., Sherr, M., Shields, C., Wagner, D., Zhou, W., Hidden voice commands (2016) USENIX Security Symposium, pp. 513-530; Clark, J., Koprinska, I., Poon, J., A neural network based approach to automated e-mail classification (2003) Web Intelligence, 2003. WI 2003. Proceedings. IEEE/WIC International Conference on, pp. 702-705. , IEEE; Evtimov, I., Eykholt, K., Fernandes, E., Kohno, T., Li, B., Prakash, A., Rahmati, A., Song, D., (2017) Robust Physical-World Attacks on Machine Learning Models, , arXiv preprint; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint; Graves, A., Mohamed, A.R., Hinton, G., Speech recognition with deep recurrent neural networks (2013) Acoustics, Speech and Signal Processing (Icassp), 2013 Ieee International Conference on, pp. 6645-6649. , IEEE; Grosse, K., Papernot, N., Manoharan, P., Backes, M., McDaniel, P., (2016) Adversarial Perturbations Against Deep Neural Networks for Malware Classification, , arXiv preprint; Krizhevsky, A., Nair, V., Hinton, G., (2014) The Cifar-10 Dataset, , http://www.cs.toronto.edu/kriz/cifar.html, online; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint; LeCun, Y., Cortes, C., Burges, C.J., Mnist handwritten digit database (2010) AT&T Labs, , http://yann.lecun.com/exdb/mnist2, Online; Legge, G.E., Foley, J.M., Contrast masking in human vision (1980) Josa, 70 (12), pp. 1458-1471; Lin, W., Dong, L., Xue, P., Visual distortion gauge based on discrimination of noticeable contrast changes (2005) IEEE Transactions on Circuits and Systems for Video Technology, 15 (7), pp. 900-909; Liu, A., Lin, W., Paul, M., Deng, C., Zhang, F., Just noticeable difference for images with decomposition model for separating edge and textured regions (2010) IEEE Transactions on Circuits and Systems for Video Technology, 20 (11), pp. 1648-1652; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387. , IEEE; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540. , ACM; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint",,,"Association for the Advancement of Artificial Intelligence","AAAI press","32nd AAAI Conference on Artificial Intelligence, AAAI 2018","2 February 2018 through 7 February 2018",,143510,,9781577358008,,,"English","AAAI Conf. Artif. Intell., AAAI",Conference Paper,"Final","",Scopus,2-s2.0-85060486196
"Tian S., Yang G., Cai Y.","57191032734;57193604947;7401750577;","Detecting adversarial examples through image transformation",2018,"32nd AAAI Conference on Artificial Intelligence, AAAI 2018",,,,"4139","4146",,20,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060469146&partnerID=40&md5=c2e4bb5e3e5c0fa76cda42baed6b0cdc","Department of Computer Science, Iowa State University, United States","Tian, S., Department of Computer Science, Iowa State University, United States; Yang, G., Department of Computer Science, Iowa State University, United States; Cai, Y., Department of Computer Science, Iowa State University, United States","Deep Neural Networks (DNNs) have demonstrated remarkable performance in a diverse range of applications. Along with the prevalence of deep learning, it has been revealed that DNNs are vulnerable to attacks. By deliberately crafting adversarial examples, an adversary can manipulate a DNN to generate incorrect outputs, which may lead catastrophic consequences in applications such as disease diagnosis and self-driving cars. In this paper, we propose an effective method to detect adversarial examples in image classification. Our key insight is that adversarial examples are usually sensitive to certain image transformation operations such as rotation and shifting. In contrast, a normal image is generally immune to such operations. We implement this idea of image transformation and evaluate its performance in oblivious attacks. Our experiments with two datasets show that our technique can detect nearly 99% of adversarial examples generated by the state-of-the-art algorithm. In addition to oblivious attacks, we consider the case of white-box attacks. We propose to introduce randomness in the process of image transformation, which can achieve a detection ratio of around 70%. Copyright © 2018, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,"Artificial intelligence; Diagnosis; Catastrophic consequences; Disease diagnosis; Diverse range; Image transformations; Self-driving cars; State-of-the-art algorithms; White box; Deep neural networks",,,,,"Athalye, A., Sutskever, I., (2017) Synthesizing Robust Adversarial Examples, , arXiv preprint; Baluja, S., Fischer, I., (2017) Adversarial Transformation Networks: Learning to Generate Adversarial Examples, , arXiv preprint; Bojarski, M., Del Testa, D., Dworakowski, D., Firner, B., Flepp, B., Goyal, P., Jackel, L.D., Zhang, J., (2016) End to End Learning for Self-Driving Cars, , arXiv preprint; Cao, X., Gong, N.Z., Mitigating evasion attacks to deep neural networks via region-based classification (2017) Annual Computer Security Applications Conference (ACSAC); Carlini, N., Wagner, D., (2017) Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods, , arXiv preprint; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium on, pp. 39-57. , IEEE; Esteva, A., Kuprel, B., Novoa, R.A., Ko, J., Swetter, S.M., Blau, H.M., Thrun, S., Dermatologist-level classification of skin cancer with deep neural networks (2017) Nature, 542 (7639), pp. 115-118; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts, , arXiv preprint; Gong, Z., Wang, W., Ku, W.-S., (2017) Adversarial and Clean Data Are Not Twins, , arXiv preprint; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations(ICLR); Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., (2017) On the (Statistical) Detection of Adversarial Examples, , arXiv preprint; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images, , Technical report, University of Toronto; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint; LeCun, Y., (1998) The Mnist Database of Handwritten Digits, , http://yann.lecun.com/exdb/mnist/; Lu, J., Sibai, H., Fabry, E., Forsyth, D., (2017) No Need to Worry About Adversarial Examples in Object Detection in Autonomous Vehicles, , arXiv preprint; Meng, D., Chen, H., Magnet: A two-pronged defense against adversarial examples (2017) ACM Conference on Computer and Communications Security; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., (2017) On Detecting Adversarial Perturbations, , arXiv preprint; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387. , IEEE; Petrov, S., Announcing syntaxnet: The worlds most accurate parser goes open source (2016) Google Research Blog; Silver, D., Huang, A., Maddison, C.J., Guez, A., Sifre, L., Van Den Driessche, G., Schrittwieser, J., Lanctot, M., Mastering the game of go with deep neural networks and tree search (2016) Nature, 529 (7587), pp. 484-489; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses, , arXiv preprint; Xu, W., Evans, D., Qi, Y., (2017) Feature Squeezing Mitigates and Detects Carlini/Wagner Adversarial Examples, , arXiv preprint",,,"Association for the Advancement of Artificial Intelligence","AAAI press","32nd AAAI Conference on Artificial Intelligence, AAAI 2018","2 February 2018 through 7 February 2018",,143510,,9781577358008,,,"English","AAAI Conf. Artif. Intell., AAAI",Conference Paper,"Final","",Scopus,2-s2.0-85060469146
"Cohen A., Holmgren J., Nishimaki R., Vaikuntanathan V., Wichs D.","56542247600;42661630900;35113652000;13405865500;24336779600;","Watermarking cryptographic capabilities",2018,"SIAM Journal on Computing","47","6",,"2157","2202",,12,"10.1137/18M1164834","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060050890&doi=10.1137%2f18M1164834&partnerID=40&md5=1150e7c1608d41821ecbce93f04adbf9","MIT, Cambridge, MA  02139, United States; NTT Secure Platform Laboratories, 3-9-11, Midori-cho Musashino-shi, Tokyo, 180-8585, Japan; MIT CSAIL, Cambridge, MA  02139, United States; Northeastern University, Boston, MA  02115, United States","Cohen, A., MIT, Cambridge, MA  02139, United States; Holmgren, J., MIT, Cambridge, MA  02139, United States; Nishimaki, R., NTT Secure Platform Laboratories, 3-9-11, Midori-cho Musashino-shi, Tokyo, 180-8585, Japan; Vaikuntanathan, V., MIT CSAIL, Cambridge, MA  02139, United States; Wichs, D., Northeastern University, Boston, MA  02115, United States","A watermarking scheme for programs embeds some information called a mark into a program while preserving its functionality. No adversary can remove the mark without damaging the functionality of the program. In this work, we study the problem of watermarking various cryptographic programs such as pseudorandom function (PRF) evaluation, decryption, and signing. For example, given a PRF F, we create a marked program C that evaluates F(·). An adversary that gets C cannot come up with any program C ∗ in which the mark is removed but which still evaluates the PRF correctly on even a small fraction of the inputs. The work of Barak et al. [CRYPTO 2001, Springer, Berlin, 2001, pp. 1-18; J. ACM, 59 (2012), 6] shows that, assuming indistinguishability obfuscation (iO), such watermarking is impossible if the marked program C evaluates the original program with perfect correctness. In this work we show that, assuming iO, such watermarking is possible if the marked program C is allowed to err with even a negligible probability, which would be undetectable to the user. We also significantly extend the impossibility results to our relaxed setting. Our watermarking schemes are public key, meaning that we use a secret marking key to embed marks in programs, and a public detection key that allows anyone to detect marks in programs. Our schemes are secure against chosen program attacks where the adversary is given oracle access to the marking functionality. We emphasize that our security notion of watermark nonremovability considers arbitrary adversarial strategies to modify the marked program, in contrast to the prior works. © 2018 Society for Industrial and Applied Mathematics","Indistinguishability obfuscation; Pseudorandom functions; Watermarking","Cryptography; Digital watermarking; Watermarking; Impossibility results; Indistinguishability; Oracle access; Program attacks; Pseudo-random functions; Public detection; Security notion; Watermarking schemes; C (programming language)",,,,,"Adelsbach, A., Katzenbeisser, S., Veith, H., Watermarking schemes provably secure against copy and ambiguity attacks (2003) Proceedings of the 2003 ACM Workshop on Digital Rights Management 2003, pp. 111-119. , https://doi.org/10.1145/947380.947395, Washington, DC, M. Yung, ed., ACM, New York; Baldimtsi, F., Kiayias, A., Samari, K., Watermarking public-key cryptographic functionalities and implementations (2017) Proceedings of the Information Security - 20th International Conference, ISC 2017, pp. 173-191. , Ho Chi Minh City, Vietnam, Springer, Cham, Switzerland; Banerjee, A., Fuchsbauer, G., Peikert, C., Pietrzak, K., Stevens, S., Key-homomorphic constrained pseudorandom functions (2015) Theory of Cryptography, , https://doi.org/10.1007/978-3-662-46497-72, Y. Dodis and J. B. Nielsen, eds., Lecture Notes in Comput. Sci. 9015, Springer, Heidelberg; Banerjee, A., Peikert, C., Rosen, A., Pseudorandom functions and lattices (2012) Proceedings of the Advances in Cryptology - EUROCRYPT 2012 - 31st Annual International Conference on the Theory and Applications of Cryptographic Techniques, pp. 719-737. , Cambridge, UK, Springer, Berlin; Barak, B., Goldreich, O., Impagliazzo, R., Rudich, S., Sahai, A., Vadhan, S.P., Yang, K., On the (im)possibility of obfuscating programs (2001) Proceedings of the Advances in Cryptology - CRYPTO 2001, 21st Annual International Cryptology Conference, pp. 1-18. , Santa Barbara, CA, Springer, Berlin; Barak, B., Goldreich, O., Impagliazzo, R., Rudich, S., Sahai, A., Vadhan, S.P., Yang, K., On the (im)possibility of obfuscating programs (2012) J. ACM, 59, p. 6; Bitansky, N., Paneth, O., On the impossibility of approximate obfuscation and applications to resettable cryptography (2013) Proceedings of Symposium on Theory of Computing Conference, STOC'13, pp. 241-250. , Palo Alto, CA, ACM, New York; Boneh, D., Lewi, K., Montgomery, H.W., Raghunathan, A., Key homomorphic PRFs and their applications (2013) Proceedings of the Advances in Cryptology - CRYPTO 2013, 33rd Annual Cryptology Conference, 8042, pp. 410-428. , https://doi.org/10.1007/978-3-642-40041-423, Santa Barbara, CA, Part I, R. Canetti and J. A. Garay, eds., Lecture Notes in Comput. Sci. Springer, Berlin; Boneh, D., Lewi, K., Wu, D.J., Constraining pseudorandom functions privately (2017) Proceedings of the Public-Key Cryptography - PKC 2017 - 20th IACR International Conference on Practice and Theory in Public-Key Cryptography, pp. 494-524. , Amsterdam, The Netherlands, Part II, Springer, Berlin; Boneh, D., Waters, B., Constrained pseudorandom functions and their applications (2013) Proceedings of the Advances in Cryptology - ASIACRYPT 2013 - 19th International Conference on the Theory and Application of Cryptology and Information Security, pp. 280-300. , Bengaluru, India, Part II, Springer, Heidelberg; Boyle, E., Goldwasser, S., Ivan, I., Functional signatures and pseudorandom functions (2014) Proceedings of the Public-Key Cryptography - PKC 2014 - 17th International Conference on Practice and Theory in Public-Key Cryptography, pp. 501-519. , Buenos Aires, Argentina, Springer, Berlin; Brakerski, Z., Vaikuntanathan, V., Constrained key-homomorphic PRFs from standard lattice assumptions or: How to secretly embed a circuit in your PRF, Theory of Cryptography (2015) Lecture Notes in Comput. Sci., 9015, pp. 1-30. , https://doi.org/10.1007/978-3-662-46497-71, Y. Dodis and J. B. Nielsen, eds, Springer, Heidelberg; Cohen, A., Holmgren, J., Nishimaki, R., Vaikuntanathan, V., Wichs, D., Watermarking cryptographic capabilities (2016) Proceedings of the 48th Annual ACM SIGACT Symposium on Theory of Computing, STOC 2016, pp. 1115-1127. , https://doi.org/10.1145/2897518.2897651, Cambridge, MA, ACM, New York; Cohen, A., Holmgren, J., Vaikuntanathan, V., (2015) Publicly Verifiable Software Watermarking, , http://eprint.iacr.org/2015/373, preprint, IACR Cryptology ePrint Archive, 2015/373; Cramer, R., Shoup, V., Design and analysis of practical public-key encryption schemes secure against adaptive chosen ciphertext attack (2003) SIAM J. Comput., 33, pp. 167-226; Garg, S., Gentry, C., Halevi, S., Raykova, M., Sahai, A., Waters, B., Candidate indistinguishability obfuscation and functional encryption for all circuits (2013) Proceedings of the 54th Annual IEEE Symposium on Foundations of Computer Science, FOCS 2013, pp. 40-49. , Berkeley, CA, IEEE, Piscataway, NJ; Goldreich, O., Goldwasser, S., Micali, S., How to construct random functions (1986) J. ACM, 33, pp. 792-807; Hopper, N., Molnar, D., Wagner, D., From weak to strong watermarking (2007) Theory of Cryptography, Proceedings of the 4th Theory of Cryptography Conference, TCC 2007, pp. 362-382. , Amsterdam, The Netherlands, Springer, Berlin; Kearns, M., Li, M., Learning in the presence of malicious errors (1993) SIAM J. Comput., 22, pp. 807-837; Keightley, T., The Fairy Mythology: Illustrative of the Romance and Superstition of Various Countries, , http://www.sacred-texts.com/neu/celt/tfm/, 1870; Kiayias, A., Papadopoulos, S., Triandopoulos, N., Zacharias, T., Delegatable pseudorandom functions and applications (2013) Proceedings of the 2013 ACM SIGSAC Conference on Computer and Communications Security, CCS'13, pp. 669-684. , Berlin, Germany, ACM, New York; Kim, S., Wu, D.J., Watermarking cryptographic functionalities from standard lattice assumptions (2017) Proceedings of the Advances in Cryptology - CRYPTO 2017 - 37th Annual International Cryptology Conference, pp. 503-536. , Santa Barbara, CA, Part I, Springer, Cham, Switzerland; Kutter, M., Voloshynovskiy, S., Herrigel, A., The watermark copy attack, in Security and Watermarking of Multimedia Contents II (2000) Proc. SPIE, 3971, pp. 371-379. , SPIE, Bellingham, WA; Naccache, D., Shamir, A., Stern, J.P., How to copyright a function? (1999) Public Key Cryptography, Proceedings of the Second International Workshop on Practice and Theory in Public Key Cryptography, PKC'99, pp. 188-196. , Kamakura, Japan, Springer, Berlin; Nishimaki, R., How to watermark cryptographic functions (2013) Advances in Cryptology - EUROCRYPT 2013, Proceedings of the 32nd Annual International Conference on the Theory and Applications of Cryptographic Techniques, pp. 111-125. , Athens, Greece, Springer, Berlin; Nishimaki, R., Wichs, D., Watermarking cryptographic programs against arbitrary removal strategies (2015), http://eprint.iacr.org/2015/344, preprint, IACR Cryptology ePrint Archive, 2015/344; Peikert, C., Shiehian, S., Privately constraining and programming PRFs, the LWE way, in Public-Key Cryptology-PKC 2018 (2018) Lecture Notes in Comput. Sci., 10770, pp. 675-701. , Springer, Cham, Switzerland; Rompel, J., One-way functions are necessary and sufficient for secure signatures (1990) STOC, pp. 387-394. , ACM, New York; Sahai, A., Waters, B., How to use indistinguishability obfuscation: Deniable encryption, and more (2014) Proceedings of the Symposium on Theory of Computing, STOC 2014, pp. 475-484. , New York, ACM, New York; Valiant, L.G., A theory of the learnable (1984) Commun. ACM, 27, pp. 1134-1142; Waters, B., A punctured programming approach to adaptively secure functional encryption (2015) Proceedings of the Advances in Cryptology - CRYPTO 2015 - 35th Annual Cryptology Conference, pp. 678-697. , Santa Barbara, CA, Part II, Springer, Berlin; Yoshida, M., Fujiwara, T., Toward digital watermarking for cryptographic data (2011) IEICE Transactions, 94-A, pp. 270-272",,,,"Society for Industrial and Applied Mathematics Publications",,,,,00975397,,SMJCA,,"English","SIAM J Comput",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85060050890
"Chau S.Y., Chowdhury O., Gonsalves V., Ge H., Yang W., Fahmy S., Li N.","57194972438;36166405500;57205353873;57191955049;55488624200;7005320939;16401839500;","Adaptive deterrence of DNS cache poisoning",2018,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST","255",,,"171","191",,2,"10.1007/978-3-030-01704-0_10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059667236&doi=10.1007%2f978-3-030-01704-0_10&partnerID=40&md5=2270fead21d5e5685639454d63ad7c32","Purdue University, West Lafayette, IN, United States; The University of Iowa, Iowa City, IA, United States; Google Inc., Mountain View, CA, United States","Chau, S.Y., Purdue University, West Lafayette, IN, United States; Chowdhury, O., The University of Iowa, Iowa City, IA, United States; Gonsalves, V., Purdue University, West Lafayette, IN, United States; Ge, H., Purdue University, West Lafayette, IN, United States; Yang, W., Google Inc., Mountain View, CA, United States; Fahmy, S., Purdue University, West Lafayette, IN, United States; Li, N., Purdue University, West Lafayette, IN, United States","Many long-lived network protocols were not designed with adversarial environments in mind; security is often an afterthought. Developing security mechanisms for protecting such systems is often very challenging as they are required to maintain compatibility with existing implementations, minimize deployment cost and performance overhead. The Domain Name System (DNS) is one such noteworthy example; the lack of source authentication has made DNS susceptible to cache poisoning. Existing countermeasures often suffer from at least one of the following limitations: insufficient protection; modest deployment; complex configuration; dependent on domain owners’ participation. We propose CGuard which is an adaptive defense framework for caching DNS resolvers: CGuard actively tries to detect cache poisoning attempts and protect the cache entries under attack by only updating them through available high confidence channels. CGuard’s effective defense is immediately deployable by the caching resolvers without having to rely on domain owners’ assistance and is compatible with existing and future solutions. We have empirically demonstrated the efficacy of CGuard. We envision that by taking away the attacker’s incentive to launch DNS cache poisoning attacks, CGuard essentially turns the existence of high confidence channels into a deterrence. Deterrence-based defense mechanisms can be applicable to other systems beyond DNS. © ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering 2018.",,"Internet protocols; Network protocols; Adversarial environments; Complex configuration; Defense mechanism; Deployment costs; DNS cache poisoning attacks; Domain name system; Security mechanism; Source authentication; Network security",,,,,"https://www.thatwhitepaperguy.com/downloads/5-CDN-Myths.pdf, 5 Myths about Content Delivery Networks and the truths you should know; (2008) Vulnerability Note VU 800113: Multiple DNS Implementations Vulnerable to Cache Poisoning, , Technical report, US CERT Vulnerability Notes Database; (2013) DNS Census 2013, , https://dnscensus2013.neocities.org; (2013), http://www.circleid.com/posts/20130717dnsdnssecandgooglespublicdnsservice/; (2013) Google’s Malaysian Domains Hit with DNS Cache Poisoning Attack, , http://www.tripwire.com/state-of-security/latest-security-news/googles-malaysian-domains-hit-dns-cache-poisoning-attack/; (2014) DNS Poisoning Slams Web Traffic from Millions in China into the Wrong Hole, , http://www.theregister.co.uk/2014/01/21/chinadnspoisoningattack/; (2014) Google Public Dns-Security Benefits, , https://developers.google.com/speed/public-dns/docs/security; (2015) Cloudflare Enables Universal DNSSEC for Its Millions of Customers for Free, , http://www.marketwired.com/press-release/cloudflare-enables-universal-dnssec-for-its-millions-of-customers-for-free-2072174.htm; (2015) DNSSEC Name and Shame!, , https://dnssec-name-and-shame.com/; Ager, B., Dreger, H., Feldmann, A., Predicting the DNSSEC overhead using DNS traces (2006) 40Th IEEE CISS; Antonakakis, M., Dagon, D., Luo, X., Perdisci, R., Lee, W., Bellmor, J., A centralized monitoring infrastructure for improving DNS security (2010) RAID 2010. LNCS, 6307, pp. 18-37. , https://doi.org/10.1007/978-3-642-15512-32, Jha, S., Sommer, R., Kreibich, C. (eds.), Springer, Heidelberg; (2015) APNIC Labs: Use of DNSSEC Validation for World, , http://stats.labs.apnic.net/dnssec/XA; Assolini, F., (2014) Attacks against Boletos, , https://securelist.com/attacks-against-boletos/66591/; Bernstein, D.J., (2009) Dnscurve: Usable Security for DNS, , http://dnscurve.org/; Bernstein, D.J., (2002) DNS Forgery, , http://cr.yp.to/djbdns/forgery.html; Calder, M., Flavel, A., Katz-Bassett, E., Mahajan, R., Padhye, J., Analyzing the performance of an anycast CDN (2015) Proceedings of ACM IMC, pp. 531-537; (2013), https://www.youtube.com/watch?v=eOGezLjlzFU, CCCen: An overview of secure name resolution [29c3]; (2016) Catalin Cimpanu: Around Four in Five DNSSEC Servers Can Be Hijacked for Ddos Attacks, , http://news.softpedia.com/news/around-four-in-five-dnssec-servers-can-be-used-in-ddos-attacks-507503.shtml; (2010) Communitydns: Performance Testing of BIND, NSD and CDNS Platforms on Identical Hardware, , http://communitydns.net/DNSSEC-Performance.pdf; Constantin, L., (2011) DNS Cache Poisoning Used in Brazilian Phishing Attack, , http://news.softpedia.com/news/DNS-Cache-Poisoning-Used-in-Brazilian-Phishing-Attack-212328.shtml; Czarny, M., (2013) How Anycast IP Routing is Used at Maxcdn, , https://www.maxcdn.com/blog/anycast-ip-routing-used-maxcdn/; Dagon, D., Antonakakis, M., Vixie, P., Jinmei, T., Lee, W., Increased DNS forgery resistance through 0x20-bit encoding: Security via LeET queries (2008) Proceedings of the 15Th ACM CCS, pp. 211-222; Duan, H., Hold-on: Protecting against on-path DNS poisoning (2012) Securing and Trusting Internet Names (SATIN); Flavel, A., FastRoute: A scalable load-aware anycast routing architecture for modern CDNs (2015) 12Th USENIX NSDI, pp. 381-394; Godard, S., (2015) Sysstat-System Performance Tools for the Linux Operating System, , https://github.com/sysstat/sysstat; Guðmundsson, Ó., Crocker, S.D., Observing DNSSEC validation in the wild (2011) Securing and Trusting Internet Names (SATIN); Herzberg, A., Shulman, H., Retrofitting security into network protocols: The case of DNSSEC (2014) IEEE Internet Comput, 18 (1), pp. 66-71; Herzberg, A., Shulman, H., Security of patched DNS (2012) ESORICS 2012. LNCS, 7459, pp. 271-288. , https://doi.org/10.1007/978-3-642-33167-116, Foresti, S., Yung, M., Martinelli, F. (eds.), Springer, Heidelberg; Hubert, A., van Mook, R., (2009) Measures for Making DNS More Resilient against Forged Answers, , https://www.rfc-editor.org/rfc/rfc5452.txt, January; Hussain, I., (2016) Google.Com.Bd Down, , http://www.dhakatribune.com/feature/2016/12/20/google-com-bd/; Huston, G., (2013) Measuring DNSSEC Use, , https://labs.apnic.net/presentations/store/2013-08-27-dnssec-apnic.pdf; Huston, G., Michaelson, G., (2013) Measuring DNSSEC Performance, , http://impossible.rand.apnic.net/ispcol/2013-05/dnssec-performance.pdf; (2015), https://www.infoblox.com/sites/infobloxcom/files/resources/infoblox-white-paper-dns-threat-index-q2-2015-report.pdf, Infoblox: Infoblox DNS Threat Index; (2016) JUNIPER Techlibrary: Network Address Translation Feature Guide for Security Devices-Disabling Port Randomization for Source NAT (CLI Proce-Dure), , https://www.juniper.net/documentation/enUS/junos/topics/task/configuration/nat-security-source-port-randomization-disabiling-cli.html; Kaminsky, D., (2008), Black Ops 2008: It’s The End Of The Cache As We Know It; Kaminsky, D., (2011), http://dankaminsky.com/2011/01/05/djb-ccc/, DNSSEC Interlude 2: DJB@CCC — Dan Kaminsky’s Blog; Levine, M., (2014) Measuring Throughput Performance: DNS Vs, , http://www.cachefly.com/2014/07/11/measuring-throughput-performance-dns-vs-tcp-anycast-routing/, TCP anycast routing; Lian, W., Rescorla, E., Shacham, H., Savage, S., Measuring the practical impact of DNSSEC deployment (2013) USENIX Security, pp. 573-588; Lindstrom, A., (2012), https://www.antonlindstrom.com/2012/01/02/dnssec-implementation-in-sweden.html, DNSSEC implementation in Sweden; Lowe, G., Winters, P., Marcus, M.L., (2007) The Great DNS Wall of China, , December; Nice, B.V., (2012) High Performance DNS Needs High Performance Security, , http://nominum.com/high-performance-dns-needs-high-performance-security/; (2002), http://web.nvd.nist.gov/view/vuln/detail?vulnId=CVE-2002-2211, NIST National Vulnerability Database: CVE-2002-2211; Park, K., Pai, V.S., Peterson, L.L., Wang, Z., CoDNS: Improving DNS performance and reliability via cooperative lookups (2004) OSDI, 4, p. 14; Perdisci, R., Antonakakis, M., Luo, X., Lee, W., WSEC DNS: Protecting recursive DNS resolvers from poisoning attacks (2009) IEEE/IFIP International Conference on Dependable Systems & Networks, DSN 2009, pp. 3-12. , IEEE; Poole, L., Pai, V.S., (2006) Confidns: Leveraging Scale and History to Improve DNS Security, , WORLDS; Prince, M., (2011) A Brief Primer on Anycast, , https://blog.cloudflare.com/a-brief-anycast-primer/; Rashid, F.Y., (2016) Poorly Configured DNSSEC Servers at Root of Ddos Attacks, , http://www.infoworld.com/article/3109581/security/poorly-configured-dnssec-servers-at-root-of-ddos-attacks.html; Raywood, D., (2009) Irish ISP Eircom Hit by Multiple Attacks that Restrict Service for Users, , http://www.scmagazineuk.com/irish-isp-eircom-hit-by-multiple-attacks-that-restrict-service-for-users/article/140243/; Schuba, C., (1993) Addressing Weaknesses in the Domain Name System Protocol, , Ph.D. thesis, Purdue University; Seltzer, L., (2009) Report Claims DNS Cache Poisoning Attack against Brazilian Bank and ISP, , http://www.eweek.com/c/a/Security/Report-Claims-DNS-Cache-Poisoning-Attack-Against-Brazilian-Bank-and-ISP-761709; Shulman, H., Waidner, M., One key to sign them all considered vulnerable: Evaluation of DNSSEC in the Internet (2017) NSDI, pp. 131-144; Son, S., Shmatikov, V., The Hitchhiker’s guide to DNS cache poisoning (2010) Security and Privacy in Communication Networks, pp. 466-483; Spring, J., (2014) Probable Cache Poisoning of Mail Handling Domains, , https://insights.sei.cmu.edu/cert/2014/09/-probable-cache-poisoning-of-mail-handling-domains.html; (2016) Statdns: TLD Zone File Statistics, , http://www.statdns.com/; (2016), https://www.keycdn.com/support/anycast/, KeyCDN Support: Anycast; Tatuya, J., (2014), https://github.com/jinmei/queryperfpp, queryperf++; http://scoreboard.verisignlabs.com/, Verisign Labs: DNSSEC Scoreboard; (2014), https://www.virusbtn.com/blog/2014/0912.xml, Virus Bulletin: DNS cache poisoning used to steal emails; https://en.wikipedia.org/w/index.php?title=Deterrencetheory, Wikipedia: Deterrence theory – Wikipedia, The Free Encyclopedia; Yao, Y., He, L., Xiong, G., Security and cost analyses of DNSSEC protocol (2013) ISCTCS 2012. CCIS, 320, pp. 429-435. , https://doi.org/10.1007/978-3-642-35795-454, Yuan, Y., Wu, X., Lu, Y. (eds.), Springer, Heidelberg; Yuan, L., Kant, K., Mohapatra, P., Chuah, C.N., DoX: A peer-to-peer antidote for DNS cache poisoning attacks (2006) IEEE ICC, 5 (2006); Zhu, L., Hu, Z., Heidemann, J., Wessels, D., Mankin, A., Somaiya, N., Connection-Oriented DNS to Improve Privacy and Security (Extended), , http://www.isi.edu/∼johnh/PAPERS/Zhu15c.html, Technical Report ISI-TR-2015-695, Febuary 2015","Chau, S.Y.; Purdue UniversityUnited States; email: schau@cs.purdue.edu","Chang B.Li Y.Beyah R.Zhu S.",,"Springer Verlag","14th International EAI Conference on Security and Privacy in Communication Networks, SecureComm 2018","8 August 2018 through 10 August 2018",,222459,18678211,9783030017033,,,"English","Lect. Notes Inst. Comput. Sci. Soc. Informatics Telecommun. Eng.",Conference Paper,"Final","",Scopus,2-s2.0-85059667236
"Lacey G., Taylor G.W., Areibi S.","56888576500;55377841000;6701709271;","Stochastic layer-wise precision in deep neural networks",2018,"34th Conference on Uncertainty in Artificial Intelligence 2018, UAI 2018","2",,,"663","672",,1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059390525&partnerID=40&md5=e12357ba9efc864c0a083fa283ea14c8","NVIDIA, United States; University of Guelph, Vector Institute for Artificial Intelligence, Canadian Institute for Advanced Research, Canada; University of Guelph, Canada","Lacey, G., NVIDIA, United States; Taylor, G.W., University of Guelph, Vector Institute for Artificial Intelligence, Canadian Institute for Advanced Research, Canada; Areibi, S., University of Guelph, Canada","Low precision weights, activations, and gradients have been proposed as a way to improve the computational efficiency and memory footprint of deep neural networks. Recently, low precision networks have even shown to be more robust to adversarial attacks. However, typical implementations of low precision DNNs use uniform precision across all layers of the network. In this work, we explore whether a heterogeneous allocation of precision across a network leads to improved performance, and introduce a learning scheme where a DNN stochastically explores multiple precision configurations through learning. This permits a network to learn an optimal precision configuration. We show on convolutional neural networks trained on MNIST and ILSVRC12 that even though these nets learn a uniform or near-uniform allocation strategy respectively, stochastic precision leads to a favourable regularization effect improving generalization. © 34th Conference on Uncertainty in Artificial Intelligence 2018. All rights reserved.",,"Computational efficiency; Network layers; Neural networks; Stochastic systems; Allocation strategy; Convolutional neural network; Learning schemes; Memory footprint; Optimal precision; Stochastic layers; Stochastic precision; Deep neural networks",,,,,"Agustsson, E., Mentzer, F., Tschannen, M., Cavigelli, L., Timofte, R., Benini, L., Van Gool, L., (2017) Soft-to-hard Vector Quantization for End-to-end Learned Compression of Images and Neural Networks, , arXiv preprint; Anwar, S., Hwang, K., Sung, W., Structured pruning of deep convolutional neural networks (2017) ACM Journal on Emerging Technologies in Computing Systems (JETC), 13 (3), p. 32; Bahdanau, D., Cho, K., Bengio, Y., (2014) Neural Machine Translation by Jointly Learning to Align and Translate, , arXiv preprint; Cai, Z., He, X., Sun, J., Vasconcelos, N., (2017) Deep Learning With Low Precision by Half-wave Gaussian Quantization, , arXiv preprint; Canziani, A., Paszke, A., Culurciello, E., (2016) An Analysis of Deep Neural Network Models for Practical Applications, , arXiv preprint; Choi, Y., El-Khamy, M., Lee, J., (2016) Towards the Limit of Network Quantization, , arXiv preprint; Courbariaux, M., Bengio, Y., (2016) Binarynet: Training Deep Neural Networks With Weights and Activations Constrained to +1 or -1, , arXiv preprint; Courbariaux, M., Bengio, Y., David, J., (2015) Binaryconnect: Training Deep Neural Networks With Binary Weights During Propagations, , arXiv preprint; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., Imagenet: A large-scale hierarchical image database (2009) IEEE Conference on Computer Vision and Pattern Recognition, , IEEE; Galloway, A., Taylor, G.W., Moussa, M., Attacking binarized neural networks (2018) International Conference on Learning Representations (ICLR); Goyal, P., Dollár, P., Girshick, R., Noordhuis, P., Wesolowski, L., Kyrola, A., Tulloch, A., He, K., (2017) Accurate, Large Minibatch Sgd: Training Imagenet in 1 Hour, , arXiv preprint; Han, S., Mao, H., Dally, W.J., (2015) Deep Compression: Compressing Deep Neural Networks With Pruning, Trained Quantization and Huffman Coding, , arXiv preprint; Han, S., Pool, J., Tran, J., Dally, W., Learning both weights and connections for efficient neural network (2015) Advances in Neural Information Processing Systems, pp. 1135-1143; Hinton, G., Deng, L., Yu, D., Dahl, G.E., Mohamed, A.-R., Jaitly, N., Senior, A., Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups (2012) IEEE Signal Processing Magazine, 29 (6), pp. 82-97; Jang, E., Gu, S., Poole, B., (2016) Categorical Reparameterization With Gumbel-Softmax, , arXiv preprint; Jin, X., Yuan, X., Feng, J., Yan, S., (2016) Training Skinny Deep Neural Networks With Iterative Hard Thresholding Methods, , arXiv preprint; Kim, M., Smaragdis, P., (2016) Bitwise Neural Networks, , arXiv preprint; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, 25, pp. 1097-1105; Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324; Li, F., Zhang, B., Liu, B., (2016) Ternary Weight Networks, , arXiv preprint; Li, H., Kadav, A., Durdanovic, I., Samet, H., Graf, H.P., (2016) Pruning Filters for Efficient Convnets, , arXiv preprint; Maddison, C.J., Mnih, A., Teh, Y.W., (2016) The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables, , arXiv preprint; Merolla, P., Appuswamy, R., Arthur, J., Esser, S.K., Modha, D., (2016) Deep Neural Networks are Robust to Weight Binarization and Other Non-linear Distortions, , arXiv preprint; Molchanov, P., Tyree, S., Karras, T., Aila, T., Kautz, J., (2016) Pruning Convolutional Neural Networks for Resource Efficient Transfer Learning, , arXiv preprint; Raghavan, A., Amer, M., Chai, S., Taylor, G.W., (2017) BitNet: Bit-regularized Deep Neural Networks, , arXiv preprint; Rastegari, M., Ordonez, V., Redmon, J., Farhadi, A., (2016) Xnor-net: Imagenet Classification Using Binary Convolutional Neural Networks, , arXiv preprint; Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., Dropout: A simple way to prevent neural networks from overfitting (2014) J. Mach. Learn. Res., 15 (1), pp. 1929-1958; Tung, F., Muralidharan, S., Mori, G., Fine-pruning: Joint fine-tuning and compression of a convolutional network with Bayesian optimization (2017) British Machine Vision Conference (BMVC); Wan, L., Zeiler, M., Zhang, S., Cun, Y.L., Fergus, R., Regularization of neural networks using dropconnect (2013) International Conference on Learning Representations (ICLR), pp. 1058-1066; Wang, X., Liang, J., Scalable compression of deep neural networks (2016) Proceedings of the ACM on Multimedia Conference, pp. 511-515; Yin, P., Zhang, S., Qi, Y., Xin, J., (2016) Quantization and Training of Low Bit-Width Convolutional Neural Networks for Object Detection, , arXiv preprint; Zhou, S., Wu, Y., Ni, Z., Zhou, X., Wen, H., Zou, Y., (2016) DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks With Low Bitwidth Gradients, , arXiv preprint; Zhu, C., Han, S., Mao, H., Dally, W.J., (2016) Trained Ternary Quantization, , arXiv preprint",,"Silva R.Globerson A.Globerson A.","Berg Health;Disney Research;et al.;Google Inc.;Microsoft Research;Uber","Association For Uncertainty in Artificial Intelligence (AUAI)","34th Conference on Uncertainty in Artificial Intelligence 2018, UAI 2018","6 August 2018 through 10 August 2018",,142872,,9781510871601,,,"English","Conf. Uncertain. Artif. Intell., UAI",Conference Paper,"Final","",Scopus,2-s2.0-85059390525
"Komiyama R., Hattori M.","57205206908;7401882705;","Adversarial minimax training for robustness against adversarial examples",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11302 LNCS",,,"690","699",,,"10.1007/978-3-030-04179-3_61","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059091090&doi=10.1007%2f978-3-030-04179-3_61&partnerID=40&md5=f9cbc95c4a58bcd998bd8d006c59149d","Interdisciplinary Graduate School of Medicine, Engineering and Agriculture, University of Yamanashi, Kofu, Yamanashi, Japan","Komiyama, R., Interdisciplinary Graduate School of Medicine, Engineering and Agriculture, University of Yamanashi, Kofu, Yamanashi, Japan; Hattori, M., Interdisciplinary Graduate School of Medicine, Engineering and Agriculture, University of Yamanashi, Kofu, Yamanashi, Japan","In this paper, we propose a novel method to improve robustness against adversarial examples. In conventional methods, in order to take measures against adversarial examples, a classifier is learned with adversarial examples generated in a specific way. However, this method can defend against only limited types of adversarial examples. In the proposed method, in order to deal with a wide range of adversarial examples, two networks are used: a generator network and a classifier network. The generator network generates noise to make an adversarial example and the classifier network acquires robustness by learning the adversarial example. Computer simulation results show that the proposed method is more robust against adversarial examples generated by some different methods in black box attacks than the conventional adversarial training methods. © 2018, Springer Nature Switzerland AG.","Adversarial examples; Adversarial training; Black box attack","Computer science; Computers; Adversarial examples; Black boxes; Conventional methods; Minimax; Training methods; Artificial intelligence",,,,,"Szegedy, C., (2014) Intriguing Properties of Neural Networks, , arXiv; Goodfellow, I., Shlens, J., Szegedy, C., (2015) Explaining and Harnessing Adversarial Examples; Carrara, F., Falchi, F., Caldelli, R., Amato, G., Fumarola, R., Becarelli, R., Detecting adversarial example attacks to deep neural networks (2017) 15Th International Workshop on Content-Based Multimedia Indexing, (38), pp. 1-7. , ACM; Meng, D., Chen, H., MagNet: A two-pronged defense against adversarial examples (2017) 2017 ACM SIGSAC Conference on Computer and Communications Security, pp. 135-147. , ACM; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) 37Th IEEE Symposium on Security and Privacy, pp. 582-597. , IEEE Press; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, B.Z., Swami, A., The limitations of deep learning in adversarial settings (2016) 1St IEEE European Symposium on Security and Privacy, pp. 372-387. , IEEE Press; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy, pp. 39-57. , IEEE Press; Kurakin, A., (2018) Adversarial Attacks and Defences Competition, , arXiv; Xiao, C., Li, B., Zhu, J., He, W., Liu, M., Song, D., (2018) Generating Adversarial Examples with Adversarial Networks, , arXiv; Baluja, S., Fischer, I., (2017) Adversarial Transformation Networks: Learning to Generate Adversarial Examples, , arXiv; Goodfellow, I., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, 27, pp. 2672-2680. , NIPS; Papernot, N., (2017) Cleverhans V2.0.0: An Adversarial Machine Learning Library","Komiyama, R.; Interdisciplinary Graduate School of Medicine, Japan; email: g18tk006@yamanashi.ac.jp","Leung A.C.S.Ozawa S.Cheng L.",,"Springer Verlag","25th International Conference on Neural Information Processing, ICONIP 2018","13 December 2018 through 16 December 2018",,221699,03029743,9783030041786,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","",Scopus,2-s2.0-85059091090
"Hang J., Han K., Li Y.","57203340214;57205203289;56036047900;","Delving into diversity in substitute ensembles and transferability of adversarial examples",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11303 LNCS",,,"175","187",,2,"10.1007/978-3-030-04182-3_16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058988667&doi=10.1007%2f978-3-030-04182-3_16&partnerID=40&md5=d90b0f089e32c9c945253a231ce5db13","School of Computer Science and Technology, Nanjing University of Posts and Telecommunications, Nanjing, China","Hang, J., School of Computer Science and Technology, Nanjing University of Posts and Telecommunications, Nanjing, China; Han, K., School of Computer Science and Technology, Nanjing University of Posts and Telecommunications, Nanjing, China; Li, Y., School of Computer Science and Technology, Nanjing University of Posts and Telecommunications, Nanjing, China","Deep learning (DL) models, e.g., state-of-the-art convolutional neural networks (CNNs), have been widely applied into security-sensitivity tasks, such as facial recognition, automated driving, etc. Then their vulnerability analysis is an emergent topic, especially for black-box attacks, where adversaries do not know the model internal architectures or training parameters. In this paper, two types of ensemble-based black-box attack strategies, iterative cascade ensemble strategy and stack parallel ensemble strategy, are proposed to explore the vulnerability of DL system and potential factors that contribute to the high-efficiency attacks are examined. Moreover, two pairwise and non-pairwise diversity measures are adopted to explore the relationship between the diversity in substitutes ensembles and transferability of crafted adversarial examples. Experimental results show that proposed ensemble adversarial attack strategies can successfully attack the DL system with ensemble adversarial training defense mechanism and the greater the diversity in substitute ensembles enables stronger transferability. © Springer Nature Switzerland AG 2018.","Black-box attack; Diversity; Ensemble adversarial attack; Transferability; Vulnerability","Deep learning; Neural networks; Black boxes; Diversity; Ensemble adversarial attack; Transferability; Vulnerability; Face recognition",,,,,"Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) 3Rd International Conference on Learning Representations; Kurakin, K., Goodfellow, J., Bengio, S., Adversarial examples in the physical world (2017) 5Th International Conference on Learning Representations; Biggio, B., Evasion attacks against machine learning at test time (2013) ECML PKDD 2013. LNCS (LNAI), 8190, pp. 387-402. , https://doi.org/10.1007/978-3-642-40994-3_25, Blockeel, H., Kersting, K., Nijssen, S., Železný, F. (eds.), Springer, Heidelberg; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2016) 1St IEEE European Symposium on Security and Privacy (EuroS&P), Pp, pp. 372-387. , IEEE Press, New York; Szegedy, C., Intriguing properties of neural networks (2014) 2Nd International Conference on Learning Representations; Papernot, N., McDaniel, P., (2016) Transferability in Machine Learning: From Phenomena to Black-Box Attacks Using Adversarial Samples, , arXiv preprint arXiv; Tramèr, F., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2017) The Space of Transferable Adversarial Examples; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) 5Th International Conference on Learning Representations; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) ASIACCS, pp. 506-519. , ACM, New York; Papernot, N., McDaniel, P., Sinha, A., Wellman, M., (2016) Towards the Science of Security and Privacy in Machine Learning, , arXiv preprint arXiv; Meng, D.Y., Chen, H., MagNet: A two-pronged defense against adversarial examples (2017) ACM SIGSAC Conference on Computer and Communications Security, pp. 135-147. , ACM, New York; Wang, Q.L., Guo, W.B., Zhang, K.X., Ororbia Ii, A.G., Xing, X., Liu, X., Adversary resistant deep neural networks with an application to malware detection (2017) 23Rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 1145-1153. , ACM, New York; Bhagoji, A., Cullina, D., Mittal, P., (2017) Dimensionality Reduction as a Defense against Evasion Attacks on Machine Learning Classifiers; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2018) 6Th International Conference on Learning Representations; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2017) 5Th International Conference on Learning Representations; Papernot, N., McDaniel, P., Wu, X., Distillation as a defense to adversarial perturbations against deep neural networks (2016) 2016 IEEE Symposium on Security and Privacy (SP), pp. 582-597. , IEEE, USA; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 38Th IEEE Symposium on Security and Privacy, pp. 39-57. , IEEE, USA; Boer, P.T.D., Kroese, D.P., Mannor, S., Rubinstein, R.Y., A tutorial on the cross-entropy method (2005) Ann. Oper. Res., 134 (1), pp. 19-67; Grosse, K., Papernot, N., Manoharan, P., Backes, M., McDaniel, P., (2016) Adversarial Perturbations against Deep Neural Networks for Malware Classification, , arXiv preprint arXiv; Ludmila, I.K., Whiker, C.J., Measures of diversity in classifier ensembles and their relationship with the ensemble accuracy (2003) Mach. Learn., 2 (51), pp. 181-207","Li, Y.; School of Computer Science and Technology, China; email: liyun@njupt.edu.cn","Cheng L.Ozawa S.Leung A.C.S.",,"Springer Verlag","25th International Conference on Neural Information Processing, ICONIP 2018","13 December 2018 through 16 December 2018",,221699,03029743,9783030041816,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","",Scopus,2-s2.0-85058988667
"Yin D., Yang Q.","57195234998;57201006967;","GANs Based Density Distribution Privacy-Preservation on Mobility Data",2018,"Security and Communication Networks","2018",,"9203076","","",,7,"10.1155/2018/9203076","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058896766&doi=10.1155%2f2018%2f9203076&partnerID=40&md5=eef6d85d853e284f8f40b876281e9fde","Department of Computer Science and Technology, Harbin Engineering University, Harbin, China","Yin, D., Department of Computer Science and Technology, Harbin Engineering University, Harbin, China; Yang, Q., Department of Computer Science and Technology, Harbin Engineering University, Harbin, China","With the development of mobile devices and GPS, plenty of Location-based Services (LBSs) have emerged in these years. LBSs can be applied in a variety of contexts, such as health, entertainment, and personal life. The location based data that contains significant personal information is released for analysing and mining. The privacy information of users can be attacked from the published data. In this paper, we investigate the problem of privacy-preservation of density distribution on mobility data. Different from adding noises into the original data for privacy protection, we devise the Generative Adversarial Networks (GANs) to train the generator and discriminator for generating the privacy-preserved data. We conduct extensive experiments on two real world mobile datasets. It is demonstrated that our method outperforms the differential privacy approach in both data utility and attack error. © 2018 Dan Yin and Qing Yang.",,"Electric equipment protection; Location based services; Telecommunication services; Adversarial networks; Density distributions; Differential privacies; Personal information; Privacy information; Privacy preservation; Privacy protection; Problem of privacy; Data privacy",,,,,"Andrés, M.E., Bordenabe, N.E., Chatzikokolakis, K., Palamidessi, C., Geo-indistinguishability: Differential privacy for location-based systems (2013) Proceedings of the ACM SIGSAC Conference on Computer and Communications Security (CCS '13), pp. 901-914. , ACM,Berlin, Germany, November; Xu, F., Tu, Z., Li, Y., Zhang, P., Fu, X., Jin, D., Trajectory recovery from ash (2017) Proceedings of the 26th International Conference, pp. 1241-1250. , Perth, Australia, April; Dwork, C., Differential privacy: A survey of results (2008) Theory and Applications of Models of Computation: 5th International Conference, TAMC 2008, Xi'an, China, April 25-29, 2008. Proceedings, Vol. 4978 of Lecture Notes in Computer Science, pp. 1-19. , Springer, Berlin, Germany; Goodfellow, I.J., Pouget-Abadie, J., Mirza, M., Generative adversarial nets (2014) Proceedings of the 28th Annual Conference on Neural Information Processing Systems 2014, NIPS 2014, pp. 2672-2680. , Canada, December; Liang, Y., Cai, Z., Yu, J., Han, Q., Li, Y., Deep learning based inference of private information using embedded sensors in smart devices (2018) IEEE Network, 32 (4), pp. 8-14; Acs, G., Castelluccia, C., A case study: Privacy preserving release of spatio-temporal density in Paris (2014) Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD 2014, pp. 1679-1688. , ACM, August; Linear programming and extensions (1964) StudentsQuarterly Journal, 34 (136), p. 242; Kuhn, H.W., The Hungarian method for the assignment problem (1955) Naval Research Logistics Quarterly, 2, pp. 83-97; Vallender, S., Calculation of the wasserstein distance between probability distributions on the line (1974) Theory of Probability & Its Applications, 18 (4), pp. 784-786; Chen, T., Kaafar, M.A., Boreli, R., The where and when of finding new friends: Analysis of a location-based social discovery network (2013) Proceedings of the 7th International AAAI Conference on Weblogs and Social Media, ICWSM 2013, pp. 61-70. , USA, July; Piorkowski, M., Sarafijanovic-Djukic, N., Grossglauser, M., (2009) CRAWDAD Dataset Epfl/mobility (V. 2009-02-24), , https://crawdad.org/epfl/mobility/20090224, Downloaded from; Liang, X., Zheng, X., Lv, W., Zhu, T., Xu, K., The scaling of human mobility by taxis is exponential (2012) Physica A: Statistical Mechanics and Its Applications, 391 (5), pp. 2135-2144; Rozenfeld, H.D., Rybski, D., Andrade, J.S., Jr., Batty, M., Stanley, H.E., Makse, H.A., Laws of population growth (2008) Proceedings of the National Acadamy of Sciences of the United States of America, 105 (48), pp. 18702-18707; Xu, W., Shen, Y., Bergmann, N., Hu, W., Sensor-assisted multi-view face recognition system on smart glass (2018) IEEE Transactions on Mobile Computing, 17 (1), pp. 197-210; Shen, Y., Luo, C., Yin, D., Wen, H., Daniela, R., Hu, W., Privacy-preserving sparse representation classification in cloud-enabled mobile applications (2018) Computer Networks, 133, pp. 59-72; Jiang, B., Yin, J., Zhao, S., Characterizing the humanmobility pattern in a large street network (2009) Physical Review E: Statistical, Nonlinear, and Soft Matter Physics, 80 (2); Agliari, E., Burioni, R., Cassi, D., Neri, F.M., Word-of-mouth and dynamical inhomogeneous markets: An efficiencymeasure and optimal sampling policies for the pre-launch stage (2010) IMA Journal of Management Mathematics, 21 (1), pp. 67-83; Hufnagel, L., Brockmann, D., Geisel, T., Forecast andcontrol of epidemics in a globalized world (2004) Proceedings of the National Acadamy of Sciences of the United States of America, 101 (42), pp. 15124-15129; He, Z., Cai, Z., Wang, X., Modeling propagation dynamics and developing optimized countermeasures for rumor spreading in online social networks (2015) Proceedings of the 35th IEEE International Conference on Distributed Computing Systems (ICDCS '15), pp. 205-214. , July; He, Z., Cai, Z., Yu, J., Latent-data privacy preserving with customized data utility for social network data (2017) IEEE Transactions on Vehicular Technology, PP (99), p. 1; Lee, K., Hong, S., Kim, S.J., Rhee, I., Chong, S., Slaw: A new mobility model for human walks (2009) Proceedings of the INFOCOM 2009, IEEE, pp. 855-863. , 855-863. IEEE; Zheng, X., Cai, Z., Li, J., Gao, H., Location-privacy-aware review publication mechanism for local business service systems (2017) Proceedings of the IEEE INFOCOM 2017 - IEEE Conference on Computer Communications, pp. 1-9. , Atlanta,GA, USA, May; González, M.C., Hidalgo, C.A., Barabási, A.-L., Understanding individual humanmobility patterns (2008) Nature, 453 (7196), pp. 779-782; Zheng, X., Cai, Z., Luo, G., Tian, L., Bai, X., Privacypreserved community discovery in online social networks (2018) Future Generation Computer Systems; LaMarca, A., Langheinrich, M., Truong, K.N., (2007) Pervasive Computing, , Springer Berlin Heidelberg, Berlin, Heidelberg; Gambs, S., Killijian, M.-O., Del Prado Cortez, M.N., Deanonymization attack on geolocated data (2014) Journal of Computer and System Sciences, 80 (8), pp. 1597-1614; Arjovsky, M., Chintala, S., Bottou, L., Wassersteingenerative adversarial networks (2017) Proceedings of the International Conference on Machine Learning, pp. 214-223; Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., Courville, A.C., Improved training of wasserstein gans (2017) Advances in Neural Information Processing Systems, pp. 5767-5777; Radford, A., Metz, L., Chintala, S., (2015) Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks; Ledig, C., Theis, L., Huszár, F., Photo-realistic single image super-resolution using a generative adversarial network (2017) Proceedings of the 30th IEEE Conference on ComputerVision and Pattern Recognition, CVPR 2017, pp. 105-114. , USA, July; Wang, T.-C., Liu, M.-Y., Zhu, J.-Y., Tao, A., Kautz, J., Catanzaro, B., High-resolution image synthesis and semantic manipulation with conditional gans (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 1, p. 5; Karras, T., Aila, T., Laine, S., Lehtinen, J., (2017) Progressive Growing of Gans for Improved Quality, Stability, and Variation; Reed, S., Akata, Z., Mohan, S., Tenka, S., Schiele, B., Lee, H., Learning what and where to draw (2016) Proceedings of the 30th Annual Conference on Neural Information Processing Systems, NIPS 2016, pp. 217-225. , Spain, December; Cai, Z., Zheng, X., Aprivate and efficientmechanismfor data uploading in smart cyber-physical systems (2018) EEE Transactions on Network Science & Engineering; Shen, Y., Wen, H., Luo, C., GaitLock: Protect virtual and augmented reality headsets using gait (2018) IEEE Transactions on Dependable and Secure Computing; Cai, Z., He, Z., Guan, X., Li, Y., Collective data-sanitization for preventing sensitive information inference attacks in social networks (2018) IEEE Transactions on Dependable Secure Computing, 15 (4), p. 1; Wu, R., Luo, G., Shao, J., Tian, L., Peng, C., Location prediction on trajectory data: A review (2018) Big Data Mining and Analytics, 1 (2), pp. 108-127; Shi, L., Wu, Y., Liu, L., Sun, X., Jiang, L., Event detection and identification of influential spreaders in social media data streams (2018) Big DataMining and Analytics, 1 (1), pp. 34-46; Zheng, X., Cai, Z., Li, Y., Data Linkage in Smart Internet of Things Systems: A Consideration from a Privacy Perspective (2018) IEEE CommunicationsMagazine, 56 (9), pp. 55-61; Wernke, M., Skvortsov, P., Dürr, F., Rothermel, K., Aclassification of location privacy attacks and approaches (2014) Personal and Ubiquitous Computing, 18 (1), pp. 163-175; Kido, H., Yanagisawa, Y., Satoh, T., An anonymous communication technique using dummies for location-based services (2005) Proceedings of the 2nd International Conference on Pervasive Services (ICPS '05), pp. 88-97. , IEEE Press, July; He, Z., Cai, Z., Yu, J., Wang, X., Sun, Y., Li, Y., Cost-efficient strategies for restraining rumor spreading in mobile social networks (2017) IEEE Transactions on Vehicular Technology, 66 (3), pp. 2789-2800; Huo, Y., Yong, C., Lu, Y., Re-adp: Real-time data aggregation with adaptive w-event differential privacy for fog computing (2018) Wireless Communications AndMobile Computing, pp. 1-13; Reynold, C., Zhang, Y., Bertino, E., Prabhakar, S., Preserving user location privacy in mobile data management infrastructures (2006) Privacy Enhancing Technologies, G. Danezis and P. Golle, Eds., Vol. 4258 of Lecture Notes in Computer Science, pp. 393-412. , Springer, Berlin, Germany; Yiu, M.L., Jensen, C.S., Møller, J., Lu, H., Designandanalysis of a ranking approach to private location-based services (2011) ACM Transactions on Database Systems (TODS), 36 (2), p. 10; Dürr, F., Skvortsov, P., Rothermel, K., Position sharing for location privacy in non-trusted systems (2011) Proceedings of the 9th IEEE International Conference on Pervasive Computing and Communications, PerCom 2011, pp. 189-196. , IEEE, Seattle, Wash, USA, March","Yang, Q.; Department of Computer Science and Technology, China; email: yangqing@hrbeu.edu.cn",,,"Hindawi Limited",,,,,19390114,,,,"English","Secur. Commun. Networks",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85058896766
"Cybenko G., Stocco G.F.","7003352275;36553158400;","Asymptotic behavior of attack graph games",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11170 LNCS",,,"104","112",,,"10.1007/978-3-030-04834-1_5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058685939&doi=10.1007%2f978-3-030-04834-1_5&partnerID=40&md5=c612043d5604e164fb79d8a130284175","Dartmouth College, Hanover, NH  03755, United States; Microsoft Corporation, Redmond, WA, United States","Cybenko, G., Dartmouth College, Hanover, NH  03755, United States; Stocco, G.F., Microsoft Corporation, Redmond, WA, United States","This paper presents and analyzes an attack graph optimization problem that arises in modeling certain adversarial cyber attack and defend scenarios. The problem formulation is based on representing attacks againt a system as a finite, weighted, directed graph in which the directed edges represent transitions between states in an attack and edge weights represent the estimated cost to an attacker for traversing the edge. An attacker strives to traverse the graph from a specified start node to a specified end node using the least weight cost directed path between those nodes. On the other hand, the defender seeks to allocate defensive measures in such a way as to maximize the attacker’s minimal cost attack path. We study the role that minimal cut sets play in hardening the attack graph and prove that under this simple model minimal cut sets are optimal defensive investments in the limit even though minimal cut sets may not play a role in hardening a system initially. Viewing attackers and defenders as players in a two person, non-zero sum game, the results in this paper describe the asyptotic behavior of optimal solutions to the game under certain conditions. © Springer Nature Switzerland AG 2018.","Attach graphs; Network interdiction; Optimal defenses","Hardening; Asymptotic behaviors; Attach graphs; Defensive measures; Minimal cut sets; Network interdiction; Optimal defenses; Optimal solutions; Problem formulation; Directed graphs",,,,,"Carin, L., Cybenko, G., Hughes, J., Cybersecurity strategies: The QuERIES methodology (2008) Computer, 41 (8), pp. 20-26; Fulkerson, D.R., Harding, G.C., Maximizing the minimum source-sink path subject to a budget constraint (1977) Math. Program., 13, pp. 116-118. , https://doi.org/10.1007/BF01584329; Golden, B., A problem in network interdiction (1978) Naval Res. Logist. Quarter., 25 (4), pp. 711-713; Israeli, E., Wood, R.K., Shortest-path network interdiction (2002) Networks, 40 (2), pp. 97-111. , https://doi.org/10.1002/net.10039; Menger, K., Zur allgemeinen kurventheorie (1927) Fundam. Math., 10 (1), pp. 96-115; Noel, S., Jajodia, S., O’Berry, B., Jacobs, M., Efficient minimum-cost network hardening via exploit dependency graphs (2003) Proceedings of 19Th Annual Computer Security Applications Conference, pp. 86-95. , pp., IEEE; Noel, S.E., Jajodia, S., O’Berry, B.C., Jacobs, M.A., Minimum-cost network hardening US Patent 7,555,778, , 30 June 2009; Schneier, B., Attack trees (1999) Dr. Dobb’s J, 24 (12), pp. 21-29; Schudel, G., Wood, B., Adversary work factor as a metric for information assurance (2001) Proceedings of the 2000 Workshop on New Security Paradigms, pp. 23-30. , pp., ACM; Sheyner, O., Haines, J., Jha, S., Lippmann, R., Wing, J.M., Automated generation and analysis of attack graphs (2002) Proceedings of the 2002 IEEE Symposium on Security and Privacy, pp. 273-284. , pp., IEEE; Wang, L., Noel, S., Jajodia, S., Minimum-cost network hardening using attack graphs (2006) Comput. Commun., 29 (18), pp. 3812-3824; West, D., (1996) Introduction to Graph Theory, , Prentice Hall, Upper Saddle River","Cybenko, G.; Dartmouth CollegeUnited States; email: gvc@dartmouth.edu",,,"Springer Verlag",,,,,03029743,,,,"English","Lect. Notes Comput. Sci.",Book Chapter,"Final","",Scopus,2-s2.0-85058685939
"Madsen D., Li W., Meng W., Wang Y.","57205121096;57189107700;56062319900;57217363842;","Evaluating the impact of intrusion sensitivity on securing collaborative intrusion detection networks against SOOA",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11337 LNCS",,,"481","494",,4,"10.1007/978-3-030-05063-4_36","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058653349&doi=10.1007%2f978-3-030-05063-4_36&partnerID=40&md5=5f96958e3a6eb273b50e4379110339dd","Department of Applied Mathematics and Computer Science, Technical University of Denmark, Kongens Lyngby, Denmark; Department of Computer Science, City University of Hong Kong, Kowloon Tong, Hong Kong; School of Computer Science, Guangzhou University, Guangzhou, China","Madsen, D., Department of Applied Mathematics and Computer Science, Technical University of Denmark, Kongens Lyngby, Denmark; Li, W., Department of Applied Mathematics and Computer Science, Technical University of Denmark, Kongens Lyngby, Denmark, Department of Computer Science, City University of Hong Kong, Kowloon Tong, Hong Kong; Meng, W., Department of Applied Mathematics and Computer Science, Technical University of Denmark, Kongens Lyngby, Denmark; Wang, Y., School of Computer Science, Guangzhou University, Guangzhou, China","Cyber attacks are greatly expanding in both size and complexity. To handle this issue, research has been focused on collaborative intrusion detection networks (CIDNs), which can improve the detection accuracy of a single IDS by allowing various nodes to communicate with each other. While such collaborative system or network is vulnerable to insider attacks, which can significantly reduce the advantages of a detector. To protect CIDNs against insider attacks, one potential way is to enhance the trust evaluation among IDS nodes, i.e., by emphasizing the impact of expert nodes. In this work, we adopt the notion of intrusion sensitivity that assigns different values of detection capability relating to particular attacks, and evaluate its impact on defending against a special On-Off attack (SOOA). In the evaluation, we investigate the impact of intrusion sensitivity in a simulated CIDN environment, and experimental results demonstrate that the use of intrusion sensitivity can help enhance the security of CIDNs under adversarial scenarios, like SOOA. © Springer Nature Switzerland AG 2018.","Challenge-based trust mechanism; Collaborative network; Insider attack; Intrusion detection; Intrusion sensitivity","Computer crime; Network architecture; Network security; Parallel architectures; Collaborative network; Collaborative systems; Detection accuracy; Detection capability; Insider attack; Intrusion sensitivity; Trust evaluation; Trust mechanism; Intrusion detection",,,,,"Chun, B., Lee, J., Weatherspoon, H., Chun, B.N., Netbait: A distributed worm detection service (2003) Technical Report IRB-TR-03-033, , Intel Research Berkeley; Douceur, J.R., The sybil attack (2002) IPTPS 2002. LNCS, 2429, pp. 251-260. , https://doi.org/10.1007/3-540-45748-824, Druschel, P., Kaashoek, F., Rowstron, A. (eds.), Springer, Heidelberg; Duma, C., Karresand, M., Shahmehri, N., Caronni, G., A trust-aware, P2P-based overlay for intrusion detection (2006) DEXA Workshop, pp. 692-697; Fadlullah, Z.M., Taleb, T., Vasilakos, A.V., Guizani, M., Kato, N., DTRAB: Combating against attacks on encrypted protocols through traffic-feature analysis (2010) IEEE/ACM Trans. Netw., 18 (4), pp. 1234-1247; Friedberg, I., Skopik, F., Settanni, G., Fiedler, R., Combating advanced persistent threats: From network event correlation to incident detection (2015) Comput. Secur., 48, pp. 35-47; Fung, C.J., Baysal, O., Zhang, J., Aib, I., Boutaba, R., Trust management for host-based collaborative intrusion detection (2008) DSOM 2008. LNCS, 5273, pp. 109-122. , https://doi.org/10.1007/978-3-540-87353-29, Turck, F., Kellerer, W., Kormentzas, G. (eds.), Springer, Heidelberg; Fung, C.J., Zhang, J., Aib, I., Boutaba, R., Robust and scalable trust management for collaborative intrusion detection (2009) Proceedings of the 11Th IFIP/IEEE International Conference on Symposium on Integrated Network Management (IM), pp. 33-40; Ghosh, A.K., Wanken, J., Charron, F., Detecting anomalous and unknown intrusions against programs (1998) Proceedings of Annual Computer Security Applications Conference (ACSAC), pp. 259-267; Gong, F., (2003) Next Generation Intrusion Detection Systems (IDS), , McAfee Network Security Technologies Group; Gou, Z., Ahmadon, M.A.B., Yamaguchi, S., Gupta, B.B., A Petri net-based framework of intrusion detection systems (2015) Proceedings of the 4Th IEEE Global Conference on Consumer Electronics, pp. 579-583; Huebsch, R., The architecture of PIER: An internet-scale query processor (2005) Proceedings of the 2005 Conference on Innovative Data Systems Research (CIDR), pp. 28-43; Li, Z., Chen, Y., Beach, A., Towards scalable and robust distributed intrusion alert fusion with good load balancing (2006) Proceedings of the 2006 SIGCOMM Workshop on Large-Scale Attack Defense (LSAD), pp. 115-122; Li, W., Meng, Y., Kwok, L.-F., Enhancing trust evaluation using intrusion sensitivity in collaborative intrusion detection networks: Feasibility and challenges (2013) Proceedings of the 9Th International Conference on Computational Intelligence and Security (CIS), pp. 518-522. , IEEE; Li, W., Meng, W., Kwok, L.-F., Design of intrusion sensitivity-based trust management model for collaborative intrusion detection networks (2014) IFIPTM 2014. IAICT, 430, pp. 61-76. , https://doi.org/10.1007/978-3-662-43813-85, Zhou, J., Gal-Oz, N., Zhang, J., Gudes, E. (eds.), Springer, Heidelberg; Li, W., Meng, W., Enhancing collaborative intrusion detection networks using intrusion sensitivity in detecting pollution attacks (2016) Inf. Comput. Secur., 24 (3), pp. 265-276; Li, W., Meng, W., Kwok, L.-F., Ip, H.H.S., Enhancing collaborative intrusion detection networks against insider attacks using supervised intrusion sensitivity-based trust management model (2017) J. Netw. Comput. Appl., 77, pp. 135-145; Li, W., Meng, W., Kwok, L.-F., Ip, H.H.S., PMFA: Toward passive message fingerprint attacks on challenge-based collaborative intrusion detection networks (2016) NSS 2016. LNCS, 9955, pp. 433-449. , https://doi.org/10.1007/978-3-319-46298-1_28, Chen, J., Piuri, V., Su, C., Yung, M. (eds.), Springer, Cham; Li, W., Meng, W., Kwok, L.-F., SOOA: Exploring special on-off attacks on challenge-based collaborative intrusion detection networks (2017) GPC 2017. LNCS, 10232, pp. 402-415. , https://doi.org/10.1007/978-3-319-57186-730, Au, M.H.A., Castiglione, A., Choo, K.-K.R., Palmieri, F., Li, K.-C. (eds.), Springer, Cham; Meng, Y., Kwok, L.F., Enhancing false alarm reduction using voted ensemble selection in intrusion detection (2013) Int. J. Comput. Intell. Syst., 6 (4), pp. 626-638; Meng, Y., Li, W., Kwok, L.F., Towards adaptive character frequency-based exclusive signature matching scheme and its applications in distributed intrusion detection (2013) Comput. Netw., 57 (17), pp. 3630-3640; Meng, W., Li, W., Kwok, L.-F., An evaluation of single character frequency-based exclusive signature matching in distinct IDS environments (2014) ISC 2014. LNCS, 8783, pp. 465-476. , https://doi.org/10.1007/978-3-319-13257-029, Chow, S.S.M., Camenisch, J., Hui, L.C.K., Yiu, S.M. (eds.), Springer, Cham; Meng, W., Li, W., Kwok, L.-F., EFM: Enhancing the performance of signature-based network intrusion detection systems using enhanced filter mechanism (2014) Comput. Secur., 43, pp. 189-204; Meng, W., Li, W., Kwok, L.-F., Design of intelligent KNN-based alarm filter using knowledge-based alert verification in intrusion detection (2015) Secur. Commun. Netw., 8 (18), pp. 3883-3895; Meng, W., Au, M.H., Towards statistical trust computation for medical smartphone networks based on behavioral profiling (2017) IFIPTM 2017. IAICT, 505, pp. 152-159. , https://doi.org/10.1007/978-3-319-59171-112, Steghöfer, J.-P., Esfandiari, B. (eds.), Springer, Cham; Meng, W., Li, W., Xiang, Y., Choo, K.K.R., A Bayesian inference-based detection mechanism to defend medical smartphone networks against insider attacks (2017) J. Netw. Comput. Appl., 78, pp. 162-169; Meng, W., Li, W., Kwok, L.-F., Towards effective trust-based packet filtering in collaborative network environments (2017) IEEE Trans. Netw. Serv. Manag., 14 (1), pp. 233-245; Meng, W., Wang, Y., Li, W., Liu, Z., Li, J., Probst, C.W., Enhancing intelligent alarm reduction for distributed intrusion detection systems via edge computing (2018) ACISP 2018. LNCS, 10946, pp. 759-767. , https://doi.org/10.1007/978-3-319-93638-344, Susilo, W., Yang, G. (eds.), Springer, Cham; Meng, W., Li, W., Wang, Y., Au, M.H., Detecting insider attacks in medical cyber-physical networks based on behavioral profiling (2018) Future Gener. Comput. Syst, , in pressElsevier; Mishra, A., Gupta, B.B., Joshi, R.C., A comparative study of distributed denial of service attacks, intrusion tolerance and mitigation techniques (2011) Proceedings of the 2011 European Intelligence and Security Informatics Conference, pp. 286-289; Papadopoulos, C., Lindell, R., Mehringer, J., Hussain, A., Govindan, R., COS-SACK: Coordinated suppression of simultaneous attacks (2003) Proceedings of the 2003 DARPA Information Survivability Conference and Exposition (DISCEX), pp. 94-96; Paxson, V., Bro: A system for detecting network intruders in real-time (1999) Comput. Netw, 31 (23-24), pp. 2435-2463; Porras, P.A., Neumann, P.G., Emerald: Event monitoring enabling responses to anomalous live disturbances (1997) Proceedings of the 20Th National Information Systems Security Conference, pp. 353-365; Roesch, M., Snort: Lightweight intrusion detection for networks (1999) Proceedings of USENIX Lisa Conference, pp. 229-238; Scarfone, K., Mell, P., Guide to Intrusion Detection and Prevention Systems (IDPS) (2007) NIST Special Publication, pp. 800-894; Snapp, S.R., DIDS (Distributed Intrusion Detection System)-motivation, architecture, and an early prototype (1991) Proceedings of the 14Th National Computer Security Conference, pp. 167-176; Snort: An Open Source Network Intrusion Prevention and Detection System (IDS/IPS), , http://www.snort.org/; Tuan, T.A., A game-theoretic analysis of trust management in P2P systems (2006) Proceedings of ICCE, pp. 130-134; Valdes, A., Anderson, D., Statistical methods for computer usage anomaly detection using NIDES (1995) Technical Report, SRI International, January; Vigna, G., Kemmerer, R.A., NetSTAT: A network-based intrusion detection approach (1998) Proceedings of Annual Computer Security Applications Conference (ACSAC), pp. 25-34; Wu, Y.-S., Foo, B., Mei, Y., Bagchi, S., Collaborative intrusion detection system (CIDS): A framework for accurate and efficient IDS (2003) Proceedings of the 2003 Annual Computer Security Applications Conference (ACSAC), pp. 234-244; Yegneswaran, V., Barford, P., Jha, S., Global intrusion detection in the DOMINO overlay system (2004) Proceedings of the 2004 Network and Distributed System Security Symposium (NDSS), pp. 1-17","Wang, Y.; School of Computer Science, China; email: yuwang@gzhu.edu.cn","Vaidya J.Li J.",,"Springer Verlag","18th International Conference on Algorithms and Architectures for Parallel Processing, ICA3PP 2018","15 November 2018 through 17 November 2018",,221839,03029743,9783030050627,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85058653349
"Ebrahimi J., Rao A., Lowd D., Dou D.","55390988100;57224651151;12140683600;22733517600;","Hotflip: White-box adversarial examples for text classification",2018,"ACL 2018 - 56th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference (Long Papers)","2",,,"31","36",,151,"10.18653/v1/p18-2006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058651747&doi=10.18653%2fv1%2fp18-2006&partnerID=40&md5=c8a55159eb17fe71bcc9954afd8dc60b","Computer and Information Science Department, University of Oregon, United States; School of Electronic Science and Engineering, Nanjing University, China","Ebrahimi, J., Computer and Information Science Department, University of Oregon, United States; Rao, A., School of Electronic Science and Engineering, Nanjing University, China; Lowd, D., Computer and Information Science Department, University of Oregon, United States; Dou, D., Computer and Information Science Department, University of Oregon, United States","We propose an efficient method to generate white-box adversarial examples to trick a character-level neural classifier. We find that only a few manipulations are needed to greatly decrease the accuracy. Our method relies on an atomic flip operation, which swaps one token for another, based on the gradients of the one-hot input vectors. Due to efficiency of our method, we can perform adversarial training which makes the model more robust to attacks at test time. With the use of a few semantics-preserving constraints, we demonstrate that HotFlip can be adapted to attack a word-level classifier as well. © 2018 Association for Computational Linguistics",,"Computational linguistics; Semantics; Text processing; Character level; Input vector; Neural classifiers; Test time; Text classification; White box; Word level; Classification (of information)",,,,,"Belinkov, Y., Bisk, Y., Synthetic and natural noise both break neural machine translation (2018) Proceedings of ICLR; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium on, pp. 39-57. , IEEE; Conneau, A., Schwenk, H., Barrault, L., Lecun, Y., Very deep convolutional networks for text classification (2017) Proceedings of EACL, 1, pp. 1107-1116; Dalvi, N., Domingos, P., Sanghai, S., Verma, D., Adversarial classification (2004) Proceedings of KDD, pp. 99-108; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) Proceedings of ICLR; Hosseini, H., Kannan, S., Zhang, B., Poovendran, R., (2017) Deceiving Google’S Perspective Api Built for Detecting Toxic Comments, , arXiv preprint; Iyyer, M., Wieting, J., Gimpel, K., Zettlemoyer, L., (2018) Adversarial Example Generation with Syntactically Controlled Paraphrase Networks, , arXiv preprint; Jia, R., Liang, P., Adversarial examples for evaluating reading comprehension systems (2017) Proceedings of EMNLP; Kim, Y., Convolutional neural networks for sentence classification (2014) Proceedings of EMNLP; Kim, Y., Jernite, Y., Sontag, D., Rush, A.M., Character-aware neural language models (2016) Proceedings of AAAI; Lowd, D., Meek, C., Adversarial learning (2005) Proceedings of KDD, pp. 641-647; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) Proceedings of ICLR; Miyato, T., Dai, A.M., Goodfellow, I., Adversarial training methods for semi-supervised text classification (2017) Proceedings of ICLR; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387. , IEEE; Rawlinson, G.E., (1976) The Significance of Letter Position in Word Recognition, , Ph.D. thesis, University of Nottingham; Socher, R., Perelygin, A., Wu, J., Chuang, J., Manning, C.D., Ng, A., Potts, C., Recursive deep models for semantic compositionality over a sentiment tree-bank (2013) Proceedings of EMNLP, pp. 1631-1642; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) Proceedings of ICLR; Zhao, Z., Dua, D., Singh, S., Generating natural adversarial examples (2018) Proceedings of ICLR",,,"Apple;ByteDance;et al.;Facebook;Google;Samsung Research","Association for Computational Linguistics (ACL)","56th Annual Meeting of the Association for Computational Linguistics, ACL 2018","15 July 2018 through 20 July 2018",,145927,,9781948087346,,,"English","ACL - Annu. Meet. Assoc. Comput. Linguist., Proc. Conf. (Long Pap.)",Conference Paper,"Final","All Open Access, Hybrid Gold, Green",Scopus,2-s2.0-85058651747
"Fleshman W., Raff E., Zak R., McLean M., Nicholas C.","57205117245;57191162116;57191154823;56027859700;7005623880;","Static malware detection & subterfuge: Quantifying the robustness of machine learning and current anti-virus",2018,"CEUR Workshop Proceedings","2269",,,"3","10",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058645708&partnerID=40&md5=cd58e1dc4493ddefa69ddd6a873f15da","Laboratory for Physical Sciences, United States; Booz Allen Hamilton, United States; University of Maryland, Baltimore County, United States","Fleshman, W., Laboratory for Physical Sciences, United States; Raff, E., Laboratory for Physical Sciences, United States, Booz Allen Hamilton, United States, University of Maryland, Baltimore County, United States; Zak, R., Laboratory for Physical Sciences, United States, Booz Allen Hamilton, United States; McLean, M., Laboratory for Physical Sciences, United States; Nicholas, C., University of Maryland, Baltimore County, United States","As machine-learning (ML) based systems for malware detection become more prevalent, it becomes necessary to quantify the benefits compared to the more traditional anti-virus (AV) systems widely used today. It is not practical to build an agreed upon test set to benchmark malware detection systems on pure classification performance. Instead we tackle the problem by creating a new testing methodology, where we evaluate the change in performance on a set of known benign & malicious files as adversarial modifications are performed. The change in performance combined with the evasion techniques then quantifies a system’s robustness against that approach. Through these experiments we are able to show in a quantifiable way how purely ML based systems can be more robust than AV products at detecting malware that attempts evasion through modification, but may be slower to adapt in the face of significantly novel attacks. © 2018 CEUR-WS. All Rights Reserved.",,"Artificial intelligence; Benchmarking; Classification (of information); Computer crime; Learning algorithms; Learning systems; Viruses; Anti virus; Classification performance; Malware detection; Static malware detections; Test sets; Testing methodology; Malware",,,,,"Anderson, R., Barton, C., Böhme, R., Clayton, R., Van Eeten, M.J.G., Levi, M., Moore, T., Savage, S., (2013) Measuring The Cost of Cybercrime, pp. 265-300. , 2013 Berlin, Heidelberg: Springer Berlin Heidelberg; Anderson, H.S., Filar, B., Roth, P., (2017) Evading Machine Learning Malware Detection, , 2017 Black Hat USA; Barreno, M., Nelson, B., Joseph, A.D., Tygar, J.D., The security of machine learning (2010) Machine Learning, 81 (2), pp. 121-148. , 2010; Biggio, B., Fumera, G., Roli, F., Security evaluation of pattern classifiers under attack (2014) IEEE Transactions on Knowledge and Data Engineering, 26 (4), pp. 984-996. , 2014; Deo, A., Dash, S.K., Suarez-Tangil, G., Vovk, V., Cavallaro, L., Prescience: Probabilistic guidance on the retraining conundrum for malware detection (2016) Proceedings of The 2016 ACM Workshop on Artificial Intelligence and Security, AISec’16, pp. 71-82. , 2016 New York, NY, USA: ACM; Egele, M., Scholte, T., Kirda, E., Barbara, S., A survey on automated dynamic malware analysis evasion and counter-evasion (2017) Proceedings of Reversing and Offensive-Oriented Trends Symposium, , 2017; Grosse, K., Papernot, N., Manoharan, P., Backes, M., McDaniel, P.D., Adversarial perturbations against deep neural networks for malware classification (2016) CoRR, , 2016; Hyman, P., Cybercrime (2013) Communications of The ACM, 56 (3), p. 18. , 2013; Jordaney, R., Wang, Z., Papini, D., Nouretdinov, I., Cavallaro, L., (2016) Misleading Metrics: On Evaluating Machine Learning for Malware with Confidence, , 2016 Technical report, University of London; Jordaney, R., Sharad, K., Dash, S.K., Wang, Z., Papini, D., Nouretdinov, I., Cavallaro, L., TranscEnd: Detecting concept drift in malware classification models (2017) 26th USENIX Security Symposium (USENIX Security 17), pp. 625-642. , 2017 Vancouver, BC: (USENIX) Association; Kantchelian, A., Afroz, S., Huang, L., Islam, A.C., Miller, B., Tschantz, M.C., Greenstadt, R., Tygar, J.D., Approaches to adversarial drift (2013) Proceedings of The 2013 ACM Workshop on Artificial Intelligence and Security, AISec’13, pp. 99-110. , 2013 New York, NY, USA: ACM; Kolosnjaji, B., Demontis, A., Biggio, B., Maiorca, D., Giacinto, G., Eckert, C., Roli, F., (2018) Adversarial Malware Binaries: Evading Deep Learning for Malware Detection in Executables, , 2018; Kolter, J.Z., Maloof, M.A., Learning to detect and classify malicious executables in the wild (2006) Journal of Machine Learning Research, 7, pp. 2721-2744. , 2006; Kreuk, F., Barak, A., Aviv-Reuven, S., Baruch, M., Pinkas, B., Keshet, J., (2018) Adversarial Examples on Discrete Sequences for Beating Whole-Binary Malware Detection, , 2018; Li, B., Roundy, K., Gates, C., Vorobeychik, Y., Large-scale identification of malicious singleton files (2017) Proceedings of The Seventh ACM on Conference on Data and Application Security and Privacy - CODASPY’, 17, pp. 227-238. , 2017; Miller, B., Kantchelian, A., Tschantz, M.C., Afroz, S., Bachwani, R., Faizullabhoy, R., Huang, L., Tygar, J.D., Reviewer integration and performance measurement for malware detection (2016) Proceedings of The 13th International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment - Volume, 9721, pp. 122-141. , 2016 DIMVA 2016, New York, NY, USA: Springer-Verlag New York, Inc; Moskovitch, R., Feher, C., Tzachar, N., Berger, E., Gitelman, M., Dolev, S., Elovici, Y., Unknown malcode detection using opcode representation (2008) Proceedings of The 1st European Conference on Intelligence and Security Informatics, EuroISI’08, pp. 204-215. , 2008 Berlin, Heidelberg: Springer-Verlag; Papernot, N., McDaniel, P.D., Goodfellow, I.J., Transferability in machine learning: From phenomena to black-box attacks using adversarial samples (2016) CoRR, , 2016; Poulios, G., Ntantogian, C., Xenakis, C., Ropinjector: Using return- Oriented programming for polymorphism and AV evasion (2015) Black Hat USA, , 2015; Raff, E., Nicholas, C., Malware classification and class imbalance via stochastic hashed Lzjd (2017) Proceedings of The 10th ACM Workshop on Artificial Intelligence and Security, AISec’17, pp. 111-120. , 2017 New York, NY, USA: ACM; Raff, E., Zak, R., Cox, R., Sylvester, J., Yacci, P., Ward, R., Tracy, A., Nicholas, C., An investigation of byte n-gram features for malware classification (2016) Journal of Computer Virology and Hacking Techniques, , 2016; Raff, E., Barker, J., Sylvester, J., Brandon, R., Catan-Zaro, B., Nicholas, C., (2017) Malware Detection by Eating A Whole EXE, , 2017 arXiv preprint; Rossow, C., Dietrich, C.J., Grier, C., Kreibich, C., Paxson, V., Pohlmann, N., Bos, H., Van Steen, M., Prudent practices for designing malware experiments: Status quo and outlook (2012) 2012 IEEE Symposium on Security and Privacy, pp. 65-79. , 2012 IEEE; Russu, P., Demontis, A., Biggio, B., Fumera, G., Roli, F., Secure kernel machines against evasion attacks (2016) Proceedings of The 2016 ACM Workshop on Artificial Intelligence and Security, AISec’16, pp. 59-69. , 2016 New York, NY, USA: ACM; Schultz, M., Eskin, E., Zadok, F., Stolfo, S., Data mining methods for detection of new malicious executables (2001) Proceedings 2001 IEEE Symposium on Security and Privacy. S&P, 2001, pp. 38-49. , 2001 IEEE Comput. Soc; Shafiq, M.Z., Tabish, S.M., Mirza, F., Farooq, M., Pe-Miner: Mining structural information to detect malicious executables in realtime (2009) Recent Advances in Intrusion Detection, pp. 121-141. , 2009; Singh, A., Walenstein, A., Lakhotia, A., Tracking concept drift in malware families (2012) Proceedings of The 5th ACM Workshop on Security and Artificial Intelligence, AISec’12, pp. 81-92. , 2012 New York, NY, USA: ACM; Sommer, R., Paxson, V., Outside the closed world: On using machine learning for network intrusion detection (2010) Proceedings of The 2010 IEEE Symposium on Security and Privacy, SP’, 10, pp. 305-316. , 2010 Washington, DC, USA: IEEE Computer Society; Spafford, E.C., Is anti-virus really dead? (2014) Computers & Security, 44, p. iv. , 2014; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) ICLR, , 2014; Wressnegger, C., Freeman, K., Yamaguchi, F., Rieck, K., (2016) From Malware Signatures to Anti-Virus Assisted Attacks, , 2016; Zeiler, M.D., Fergus, R., Visualizing and understanding convolutional networks (2014) Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 8689, pp. 818-833. , 2014 LNCS",,"Collins J.B.Dasgupta P.Mittu R.",,"CEUR-WS","2018 AAAI Symposium on Adversary-Aware Learning Techniques and Trends in Cybersecurity, ALEC 2018","18 October 2018 through 20 October 2018",,142950,16130073,,,,"English","CEUR Workshop Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85058645708
"Nichols N., Jasper R.","57193708056;36851843300;","Projecting trouble: Light based adversarial attacks on deep learning classifiers",2018,"CEUR Workshop Proceedings","2269",,,"44","49",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058642380&partnerID=40&md5=5de96f983aa93ac51ddda8ee6b2f7af8","Pacific Northwest National Laboratory, Seattle, WA, United States; Western Washington University, Bellingham, WA, United States","Nichols, N., Pacific Northwest National Laboratory, Seattle, WA, United States, Western Washington University, Bellingham, WA, United States; Jasper, R., Pacific Northwest National Laboratory, Seattle, WA, United States","This work demonstrates a physical attack on a deep learning image classification system using projected light onto a physical scene. Prior work is dominated by techniques for creating adversarial examples which directly manipulate the digital input of the classifier. Such an attack is limited to scenarios where the adversary can directly update the inputs to the classifier. This could happen by intercepting and modifying the inputs to an online API such as Clarifai or Cloud Vision. Such limitations have led to a vein of research around physical attacks where objects are constructed to be inherently adversarial or adversarial modifications are added to cause misclassification. Our work differs from other physical attacks in that we can cause misclassification dynamically without altering physical objects in a permanent way. We construct an experimental setup which includes a light projection source, an object for classification, and a camera to capture the scene. Experiments are conducted against 2D and 3D objects from CIFAR-10. Initial tests show projected light patterns selected via differential evolution could degrade classification from 98% to 22% and 89% to 43% probability for 2D and 3D targets respectively. Subsequent experiments explore sensitivity to physical setup and compare two additional baseline conditions for all 10 CIFAR classes. Some physical targets are more susceptible to perturbation. Simple attacks show near equivalent success, and 6 of the 10 classes were disrupted by light. © 2018 CEUR-WS. All Rights Reserved.",,"Equivalence classes; Evolutionary algorithms; Learning algorithms; Optimization; Base-line conditions; Differential Evolution; Image classification systems; Learning classifiers; Light projection; Misclassifications; Physical attacks; Physical objects; Deep learning",,,,,"Athalye, A., Sutskever, I., (2017) Synthesizing Robust Adversarial Examples, , arXiv preprint; Athalye, A., Carlini, N., Wagner, D., (2018) Obfuscated Gradients Give A False Sense of Security: Circumventing Defenses to Adversarial Examples, , arXiv preprint; Brown, T.B., Mané, D., Roy, A., Abadi, M., Gilmer, J., (2017) Adversarial Patch, , arXiv preprint; Chen, S.-T., Cornelius, C., Martin, J., Chau, D.H., (2018) Robust Physical Adversarial Attack on Faster R-Cnn Object Detector, , arXiv preprint; Cohen, T.S., Welling, M., (2014) Transformation Properties of Learned Visual Representations, , arXiv preprint; Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Xiao, C., Prakash, A., Song, D., (2017) Robust Physical-World Attacks on Deep Learning Models; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts, , arXiv preprint; Jaderberg, M., Simonyan, K., Zisserman, A., Spatial transformer networks (2015) Advances in Neural Information Processing Systems, pp. 2017-2025; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2016) Arxiv, pp. 1-15. , c; LeCun, Y., Huang, F.J., Bottou, L., Learning methods for generic object recognition with invariance to pose and lighting (2004) Computer Vision and Pattern Recognition, 2004. CVPR 2004. Proceedings of The 2004 IEEE Computer Society Conference on, 2, pp. II–104. , IEEE; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: from Phenomena to Black-Box Attacks Using Adversarial Samples; Qi, C.R., Su, H., Mo, K., Guibas, L.J., PointNet: Deep learning on point sets for 3d classification and segmentation (2017) Proc. Computer Vision and Pattern Recognition (CVPR), IEEE, 1 (2), p. 4; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proceedings of The 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540. , ACM; Su, J., Vargas, D.V., Kouichi, S., (2017) One Pixel Attack for Fooling Deep Neural Networks, , arXiv preprint; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint; Yamada, T., Gohshi, S., Echizen, I., Privacy visor: Method for preventing face image detection by using differences in human and device sensitivity (2013) IFIP International Conference on Communications and Multimedia Security, pp. 152-161. , Springer; Zheng, S., Song, Y., Leung, T., Goodfellow, I., (2016) Improving The Robustness of Deep Neural Networks Via Stability Training",,"Collins J.B.Dasgupta P.Mittu R.",,"CEUR-WS","2018 AAAI Symposium on Adversary-Aware Learning Techniques and Trends in Cybersecurity, ALEC 2018","18 October 2018 through 20 October 2018",,142950,16130073,,,,"English","CEUR Workshop Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85058642380
"Suciu O., Coull S.E., Joh J.","57204828060;23566653400;55626874900;","Exploring adversarial examples in malware detection",2018,"CEUR Workshop Proceedings","2269",,,"11","16",,2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058641789&partnerID=40&md5=c8319ad0424c703d3f5c9772cedd4ecc","University of Maryland, College Park, United States; FireEye, Inc., United States","Suciu, O., University of Maryland, College Park, United States; Coull, S.E., FireEye, Inc., United States; Joh, J., FireEye, Inc., United States","The Convolutional Neural Network (CNN) architecture is increasingly being applied to new domains, such as malware detection, where it is able to learn malicious behavior from raw bytes extracted from executables. These architectures reach impressive performance with no feature engineering effort involved, but their robustness against active attackers is yet to be understood. Such malware detectors could face a new attack vector in the form of adversarial interference with the classification model. Existing evasion attacks intended to cause misclassification on test-time instances, which have been extensively studied for image classifiers, are not applicable because of the input semantics that prevents arbitrary changes to the binaries. This paper explores the area of adversarial examples for malware detection. By training an existing model on a production-scale dataset, we show that some previous attacks are less effective than initially reported, while simultaneously highlighting architectural weaknesses that facilitate new attack strategies for malware classification. Finally, we explore more generalizable attack strategies that increase the potential effectiveness of evasion attacks. © 2018 CEUR-WS. All Rights Reserved.",,"Classification (of information); Computer crime; Learning algorithms; Learning systems; Network architecture; Neural networks; Semantics; Architectural weakness; Classification models; Convolutional Neural Networks (CNN); Feature engineerings; Malicious behavior; Malware classifications; Malware detection; Misclassifications; Malware",,,,,"Anderson, H.S., Kharkar, A., Filar, B., Evans, D., Roth, P., (2018) Learning to Evade Static Pe Machine Learning Malware Models Via Reinforcement Learning, , arXiv preprint; Barreno, M., Nelson, B., Joseph, A.D., Tygar, J.D., The security of machine learning (2010) Machine Learning, 81 (2), pp. 121-148; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndić, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 387-402. , Springer; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP), pp. 39-57. , IEEE; Goodfellow, I., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint; Grosse, K., Papernot, N., Manoharan, P., Backes, M., McDaniel, P., Adversarial examples for malware detection (2017) European Symposium on Research in Computer Security, pp. 62-79. , Springer; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of The IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Hu, W., Tan, Y., Black-box attacks against RNN based malware detection algorithms (2018) The Workshops of The The Thirty-Second AAAI Conference on Artificial Intelligence, , New Orleans, Louisiana, USA, February 2-7, 2018; Kolosnjaji, B., Demontis, A., Biggio, B., Maiorca, D., Giacinto, G., Eckert, C., Roli, F., Adversarial malware binaries: Evading deep learning for malware detection in executables (2018) 26th European Signal Processing Conference (EUSIPCO’18); Krčál, M., Švec, O., Bálek, M., Jašek, O., Deep convolutional malware classifiers can learn from raw executables and labels only (2018) International Conference on Learning Representations; (2018) Pe Format, , https://docs.microsoft.com/en-us/windows/desktop/debug/pe-format; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of The 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519. , ACM; Raff, E., Barker, J., Sylvester, J., Brandon, R., Catanzaro, B., Nicholas, C., (2017) Malware Detection by Eating A Whole Exe, , arXiv preprint; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint; Ugarte-Pedrero, X., Balzarotti, D., Santos, I., Bringas, P.G., Sok: Deep packer inspection: A longitudinal study of the complexity of run-time packers (2015) 2015 IEEE Symposium on Security and Privacy (SP), pp. 659-673. , IEEE; Xu, W., Qi, Y., Evans, D., Automatically evading classifiers (2016) Proceedings of The 2016 Network and Distributed Systems Symposium; Zhang, X., Zhao, J., LeCun, Y., Character-level convolutional networks for text classification (2015) Advances in Neural Information Processing Systems, pp. 649-657",,"Collins J.B.Dasgupta P.Mittu R.",,"CEUR-WS","2018 AAAI Symposium on Adversary-Aware Learning Techniques and Trends in Cybersecurity, ALEC 2018","18 October 2018 through 20 October 2018",,142950,16130073,,,,"English","CEUR Workshop Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85058641789
[No author name available],[No author id available],"CEUR Workshop Proceedings",2018,"CEUR Workshop Proceedings","2269",,,"63","",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058614978&partnerID=40&md5=d44329b811898ee6588be1a850306d40",,"","The proceedings contain 10 papers. The topics discussed include: inefficiencies in cyber-security exercises life-cycle; exploring adversarial examples in malware detection; gray-box techniques for adversarial text generation; adversarial training on word-char embedding; integrating collaborative cognitive assistants into cybersecurity operations centers; data and deep models applied to cyber security data analysis; projecting trouble: light based adversarial attacks on deep learning classifiers; an artificial coevolutionary framework for adversarial AI; and coordination-driven learning in multi-agent problem spaces.",,,,,,,,,"Collins J.B.Dasgupta P.Mittu R.",,"CEUR-WS","2018 AAAI Symposium on Adversary-Aware Learning Techniques and Trends in Cybersecurity, ALEC 2018","18 October 2018 through 20 October 2018",,142950,16130073,,,,"English","CEUR Workshop Proc.",Conference Review,"Final","",Scopus,2-s2.0-85058614978
"Tang Z., Kuijper M., Chong M., Mareels I., Leckie C.","57220907881;7003535680;54912439800;7004369521;7003524629;","Sensor attack correction for linear systems with known inputs",2018,"IFAC-PapersOnLine","51","23",,"206","211",,2,"10.1016/j.ifacol.2018.12.036","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058467946&doi=10.1016%2fj.ifacol.2018.12.036&partnerID=40&md5=7aa0259fb602c0f4c813fd1002d12a09","School of Electrical and Electronic Engineering, University of Melbourne, Australia; Department of Automatic Control, KTH Royal Institute of Technology, Sweden; IBM Research Australia, Australia; School of Computing and Information Systems, University of Melbourne, Australia","Tang, Z., School of Electrical and Electronic Engineering, University of Melbourne, Australia; Kuijper, M., School of Electrical and Electronic Engineering, University of Melbourne, Australia; Chong, M., Department of Automatic Control, KTH Royal Institute of Technology, Sweden; Mareels, I., IBM Research Australia, Australia; Leckie, C., School of Computing and Information Systems, University of Melbourne, Australia","We address the problem of attack detection and attack correction for multi-input multi-output discrete-time linear time-invariant systems under sensor attacks. More specifically, we consider the situation that a system with known input is corrupted by additive adversarial attack signals on some of the system's outputs. In this paper, we use system representation in a behavioural approach, which allows for natural and compact statements regarding linear system security. We extend our earlier results for systems with zero inputs to systems with non-zero inputs. We assume that these non-zero inputs are known. © 2018","error correction; Linear systems; system security","Error correction; Invariance; MIMO systems; Time varying control systems; Attack detection; Behavioural approach; Discrete-time linear time-invariant systems; Multi input multi output; System representation; System security; Linear systems",,,,,"Chen, Y., Kar, S., Moura, J., (2015), Cyber-physical systems: dynamic sensor attacks and strong observability. In Proc. of the 40th International Conference on Acoustics, Speech and Signal Processing (ICASSP), 1752–1756. Brisbane, Australia; Chong, M., Kuijper, M., Characterising the vulnerability of linear control systems under sensor attacks using a system’ s security index (2016) In Proc. of the 55th Conference on Decision and Control (CDC) December, 2016, pp. 5906-5911. , Las Vegas, USA; Chong, M., Kuijper, M., (2016), Vulnerability of linear systems against sensor attacks–a system's security index. In Proc. of 22nd International Symposium on Mathematical Theory of Networks and Systems(MTNS), 373–376. Minneapolis, USA; Chong, M., Wakaiki, M., Hespanha, J., (2015), Observability of linear systems under adversarial attacks. In Proc. of the 2015 American Control Conference (ACC), 2439–2444. Chicago, USA; Chow, E.Y., Willsky, A.S., Analytical redundancy and the design of robust failure detection systems (1984) IEEE Trans. Automat. Contr., 27, pp. 603-614; Fawzi, H., Tabuada, P., Diggavi, S., Secure estimation and control for cyber-physical systems under adversarial attacks (2014) IEEE Transactions of Automatic Control, 59 (6), pp. 1454-1467; Frisk, E., Nyberg, M., (1999), Using minimal polynomial bases for fault diagnosis. In Proc. of European Control Conference, 4161–4166. Karlsruhe, Germany; Hajshirmohamadi, S., Davoodi, M., Meskin, N., Sheik-holeslam, F., Event-triggered fault detection and isolation for discrete-time linear systems (2016) IET Control Theory and Applications, 10, pp. 526-533; Manandhar, K., Cao, X., Detection of faults and attacks including false data injection attack in smart grid using Kalman filter (2014) IEEE Transactions on Control of Network Systems, 1, pp. 370-379; Pajic, M., Tabuada, P., Lee, I., Pappas, G., (2015), Attack-resilient state estimation in the presence of noise. In Proc. of the 54th Conference on Decision and Control (CDC), 5827–5832. Osaka, Japan; Pasqualetti, F., Dörfler, F., Bullo, F., Attack detection and identification in cyber-physical systems (2013) IEEE Transactions on Automatic Control, 58 (99), pp. 2715-2729; Polderman, J., Willems, J., (1997) Introduction to mathematical systems theory: a behavioral approach, volume 26 of Texts in Applied Mathematics, , Springer New York NY, USA; Proakis, J., Salehi, M., (2008) Digital Communications 5th edition, , McGraw Hill New York, USA; Sandberg, H., Teixeira, A., (2016), From control system security indices to attack identifiability. In Proc. of 2016 Science of Security for Cyber-Physical Systems Workshop (SOSCYPS), 1–6. Vienna, Austria; Sandberg, H., Teixeira, A., Johansson, K., (2010), On security indices for state estimators in power networks. In Proc. of First Workshop on Secure Control Systems, CPSWEEK, 1–6. Stockholm, Sweden; Shoukry, Y., Chong, M., Wakaiki, M., Nuzzo, P., Sangiovanni-Vincentelli, A., Seshia, S., Hespanha, J., Tabuada, P., (2016), SMT-based observer design for cyber-physical systems under sensor attacks. In 7th ACM/IEEE International Conference on Cyber-Physical Systems, ICCPS, 29:1–29:10. Vienna, Austria; Shoukry, Y., Tabuada, P., Event-triggered state observers for sparse sensor noise/attacks (2016) IEEE Transactions of Automatic Control, 61 (8), pp. 2079-2091; Tang, Z., Kuijper, M., Chong, M., Mareels, I., Leckie, C., (2017), Linear system security–detection and correction of adversarial attacks in the noise-free case. Available at submitted to Automatica; Tang, Z., Kuijper, M., Chong, M., Mareels, I., Leckie, C., Attack correction for noise-free linear systems subject to sensor attacks (2018) In Proc. of the 23rd International Symposium on Mathematical Theory of Networks and Systems, MTNS, Hong Kong, China, pp. 18-21; Teixeira, A., Shames, I., Sandberg, H., Johansson, K., A secure control framework for resource-limited adversaries (2015) Automatica, 51, pp. 135-148; Teixeira, A., Sou, K.C., Sandberg, H., K.H.J., Secure control systems: A quantitave risk management approach (2015) IEEE Control System, 35, pp. 24-45; Warner, J.S., Johnstib, R.G., A simple demonstration that the global positioning system is vulnerable to spoofing (2002) In Journal of Security Administration, pp. 19-27; Yang, T., Murguia, C., Kuijper, M., Nešić, D., (2018), A robust circle-criterion observer-based estimator for discrete-time nonlinear systems in the presence of sensor attacks and measurement noise. Available at, accepted 57th IEEE Conference on Decision and Control (CDC); Zhang, Y., Qiu, Q., Yang, F., Han, Q.L., Vlacic, L., Liul, J., (2015), Set-membership filtering approach for fault detection of systems with unknown-but-bounded noises. In Proc. of the 5th Australian Control Conference (AUCC), 170–175. Gold Coast, Australia",,,,"Elsevier B.V.",,,,,24058963,,,,"English","IFAC-PapersOnLine",Conference Paper,"Final","All Open Access, Bronze",Scopus,2-s2.0-85058467946
"Dumitraş T., Kaya Y., Mărginean R., Suciu O.","13609104900;57204824575;57204822940;57204828060;","Too Big to FAIL: What You Need to Know Before Attacking a Machine Learning System",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11286 LNCS",,,"150","162",,,"10.1007/978-3-030-03251-7_17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057415576&doi=10.1007%2f978-3-030-03251-7_17&partnerID=40&md5=5b40417e40f9746c26c158ea5e5fdaba","University of Maryland, College Park, United States","Dumitraş, T., University of Maryland, College Park, United States; Kaya, Y., University of Maryland, College Park, United States; Mărginean, R., University of Maryland, College Park, United States; Suciu, O., University of Maryland, College Park, United States","There is an emerging arms race in the field of adversarial machine learning (AML). Recent results suggest that machine learning (ML) systems are vulnerable to a wide range of attacks; meanwhile, there are no systematic defenses. In this position paper we argue that to make progress toward such defenses, the specifications for machine learning systems must include precise adversary definitions—a key requirement in other fields, such as cryptography or network security. Without common adversary definitions, new AML attacks risk making strong and unrealistic assumptions about the adversary’s capabilities. Furthermore, new AML defenses are evaluated based on their robustness against adversarial samples generated by a specific attack algorithm, rather than by a general class of adversaries. We propose the FAIL adversary model, which describes the adversary’s knowledge and control along four dimensions: data Features, learning Algorithms, training Instances and crafting Leverage. We analyze several common assumptions, often implicit, from the AML literature, and we argue that the FAIL model can represent and generalize the adversaries considered in these references. The FAIL model allows us to consider a range of adversarial capabilities and enables systematic comparisons of attacks against ML systems, providing a clearer picture of the security threats that these attacks raise. By evaluating how much a new AML attack’s success depends on the strength of the adversary along each of the FAIL dimensions, researchers will be able to reason about the real effectiveness of the attack. Additionally, such evaluations may suggest promising directions for investigating defenses against the ML threats. © 2018, Springer Nature Switzerland AG.","Adversary model; Machine learning","Artificial intelligence; Knowledge management; Learning algorithms; Network security; Risk perception; Adversary modeling; Data feature; Four dimensions; General class; Ml systems; Position papers; Security threats; Learning systems",,,,,"Arp, D., Spreitzenbarth, M., Hubner, M., Gascon, H., Rieck, K., (2014), https://www.ndss-symposium.org/ndss2014/drebin-effective-and-explainable-detection-android-malware-your-pocket; Barreno, M., Nelson, B., Joseph, A.D., Tygar, J.D., The security of machine learning (2010) Mach. Learn., 81, pp. 121-148; Biggio, B., Corona, I., Fumera, G., Giacinto, G., Roli, F., Bagging classifiers for fighting poisoning attacks in adversarial classification tasks (2011) MCS 2011. LNCS, 6713, pp. 350-359. , https://doi.org/10.1007/978-3-642-21557-537, Sansone, C., Kit-tler, J., Roli, F. (eds.), pp., Springer, Heidelberg; Biggio, B., (2013) Evasion Attacks against Machine Learning at Test Time, , https://doi.org/10.1007/978-3-642-40994-325; Biggio, B., Nelson, B., Laskov, P., (2012) Poisoning Attacks against Support Vector Machines, , arXiv preprint arXiv; Carlini, N., Hidden voice commands (2016) USENIX Security Symposium, pp. 513-530. , pp; Carlini, N., Wagner, D.A., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy, SP 2017, San Jose, CA, USA, pp. 39-57. , https://doi.org/10.1109/SP.2017.49; Chau, D.H.P., Nachenberg, C., Wilhelm, J., Wright, A., Faloutsos, C., http://www.cs.cmu.edu/; Chung, J.S., Senior, A., Vinyals, O., Zisserman, A., Lip Reading Sentences in the Wild, (2016); Cretu, G.F., Stavrou, A., Locasto, M.E., Stolfo, S.J., Keromytis, A.D., Casting out demons: Sanitizing training data for anomaly sensors (2008) IEEE Symposium on Security and Privacy, SP 2008, pp. 81-95; Dalvi, N., Domingos, P., Sanghai, S., Verma, D., Adversarial classification (2004) Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 99-108. , pp., ACM; Fredrikson, M., Lantz, E., Jha, S., Lin, S., Page, D., Ristenpart, T., Privacy in pharmacogenetics: An end-to-end case study of personalized warfarin dosing (2014) 23Rd USENIX Security Symposium (USENIX Security 2014), pp. 17-32. , pp; Dowlin, N., Gilad-Bachrach, R., Laine, K., Lauter, K., Naehrig, M., Wernsing, J., Cryptonets: Applying neural networks to encrypted data with high throughput and accuracy (2016) International Conference on Machine Learning, pp. 201-210. , pp; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint arXiv; Gu, T., Dolan-Gavitt, B., Garg, S., (2017) Badnets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain, , arXiv preprint arXiv; Hearn, M., https://ripe64.ripe.net/archives/video/25/; Koh, P.W., Liang, P., (2017) Understanding Black-Box Predictions via Influence Functions, , arXiv preprint arXiv; Liu, Y., Chen, X., Liu, C., Song, D., (2016) Delving into Transferable Adversarial Examples and Black-Box Attacks, , arXiv preprint arXiv; Liu, Y., Trojaning attack on neural networks. Technical report 17-002 (2017) Purdue University; Lowd, D., Meek, C., Adversarial learning (2005) Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining, pp. 641-647. , pp., ACM; Muñoz-González, L., Towards poisoning of deep learning algorithms with back-gradient optimization (2017) Proceedings of the 10Th ACM Workshop on Artificial Intelligence and Security, pp. 27-38. , pp., ACM; Nelson, B., Exploiting machine learning to subvert your spam filter (2008) Proceedings of the 1St USENIX Workshop on Large-Scale Exploits and Emergent Threats, LEET 2008, , http://dl.acm.org/citation.cfm?id=1387709.1387716; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., (2016) Practical Black-Box Attacks against Deep Learning Systems Using Adversarial Examples, , arXiv preprint arXiv; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) 2016 IEEE European Symposium on Security and Privacy (EuroS&P), pp. 372-387; Papernot, N., McDaniel, P.D., Goodfellow, I.J., Transferability in machine learning: From phenomena to black-box attacks using adversarial samples (2016) Corr Abs/1605, p. 07277. , http://arxiv.org/abs/1605.07277; Papernot, N., McDaniel, P.D., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) IEEE Symposium on Security and Privacy, SP 2016, San Jose, CA, USA, pp. 582-597. , https://doi.org/10.1109/SP.2016.41; Papernot, N., McDaniel, P.D., Goodfellow, I.J., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against deep learning systems using adversarial examples (2017) ACM Asia Conference on Computer and Communications Security, Abu Dhabi, UAE, , http://arxiv.org/abs/1602.02697; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540. , pp., ACM; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-Scale Image Recognition, , http://arxiv.org/abs/1409.1556; Steinhardt, J., Koh, P.W.W., Liang, P.S., Certified defenses for data poisoning attacks (2017) Advances in Neural Information Processing Systems, pp. 3520-3532. , pp; Suciu, O., Marginean, R., Kaya, Y., Daume, I.I.I., H., Dumitras, T.: When does machine learning FAIL? Generalized transferability for evasion and poisoning attacks (2018) 27Th USENIX Security Symposium (USENIX Security 2018), pp. 1299-1316. , https://www.usenix.org/conference/usenixsecurity18/presentation/suciu, pp., USENIX Association, Baltimore; Szegedy, C., (2013) Intriguing Properties of Neural Networks, , arXiv preprint arXiv; Tamersoy, A., Roundy, K., Chau, D.H., Guilt by association: Large scale malware detection by mining file-relation graphs (2014) KDD; Tramèr, F., Zhang, F., Juels, A., Reiter, M., Ristenpart, T., Stealing machine learning models via prediction APIs (2016) 25Th USENIX Security Symposium (USENIX Security 2016). USENIX Association, , https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/tramer, Austin, August; Xu, W., Evans, D., Qi, Y., (2017) Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks, , arXiv preprint arXiv; Xu, W., Qi, Y., Evans, D., Automatically evading classifiers (2016) Proceedings of the 2016 Network and Distributed Systems Symposium; Yang, C., Wu, Q., Li, H., Chen, Y., (2017) Generative Poisoning Attack Method against Neural Networks, , arXiv preprint arXiv","Dumitraş, T.; University of MarylandUnited States; email: tdumitra@umd.edu","Matyas V.Svenda P.Anderson J.Christianson B.Stajano F.",,"Springer Verlag","26th International Workshop on Security Protocols, 2018","19 March 2018 through 21 March 2018",,221439,03029743,9783030032500,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","",Scopus,2-s2.0-85057415576
"Biondo A., Conti M., Davi L., Frassetto T., Sadeghi A.-R.","57212252589;15019127200;35302017400;57195335362;25925364500;","The Guard's Dilemma: Efficient code-reuse attacks against intel SGX",2018,"Proceedings of the 27th USENIX Security Symposium",,,,"1213","1227",,42,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057350742&partnerID=40&md5=98105c61d519939a05a56b189aeecfe5","University of Padua, Italy; University of Duisburg-Essen, Germany; TU Darmstadt, Germany","Biondo, A., University of Padua, Italy; Conti, M., University of Padua, Italy; Davi, L., University of Duisburg-Essen, Germany; Frassetto, T., TU Darmstadt, Germany; Sadeghi, A.-R., TU Darmstadt, Germany","Intel Software Guard Extensions (SGX) isolate security-critical code inside a protected memory area called enclave. Previous research on SGX has demonstrated that memory corruption vulnerabilities within enclave code can be exploited to extract secret keys and bypass remote attestation. However, these attacks require kernel privileges, and rely on frequently probing enclave code which results in many enclave crashes. Further, they assume a constant, not randomized memory layout. In this paper, we present novel exploitation techniques against SGX that do not require any enclave crashes and work in the presence of existing SGX randomization approaches such as SGX-Shield. A key contribution of our attacks is that they work under weak adversarial assumptions, e.g., not requiring kernel privileges. In fact, they can be applied to any enclave that is developed with the standard Intel SGX SDK on either Linux or Windows. © 2018 Proceedings of the 27th USENIX Security Symposium. All rights reserved.",,"Code reuse; Exploitation techniques; Memory corruption; Memory layout; Remote attestation; Secret key; Security-critical codes; Linux",,,,,"Baumann, A., Peinado, M., Hunt, G., Shielding applications from an untrusted cloud with haven (2014) Proceedings of the 11th USENIX Conference on Operating Systems Design and Implementation, pp. 267-283. , USENIX Association; Baumann, A., Peinado, M., Hunt, G., Shielding applications Froman untrusted cloud with haven (2015) ACM Transactions on Computer Systems (TOCS), 33 (3), p. 8; Bittau, A., Belay, A., Mashtizadeh, A., Mazières, D., Boneh, D., Hacking blind (2014) Proceedings of the 35th IEEE Symposium on Security and Privacy, , SP'14; Bosman, E., Bos, H., Framing signals-areturntoportable shellcode (2014) Security and Privacy (SP), 2014 IEEE Symposium on, pp. 243-258; Brasser, F., Capkun, S., Dmitrienko, A., Frassetto, T., Kostiainen, K., Müller, U., Sadeghi, A., DR.SGX: Hardening SGX enclaves against cache attacks with data location randomization (2017) CoRR Abs/1709.09917; Brasser, F., Müller, U., Dmitrienko, A., Kostiainen, K., Capkun, S., Sadeghi, A.-R., Software grand exposure: SGX cache attacks are practical (2017) USENIX Workshop on Offensive Technologies; Chen, S., Zhang, X., Reiter, M.K., Zhang, Y., Detecting privileged side-channel attacks in shielded execution with Déjá vu (2017) Proceedings of the 2017ACM on Asia Conference on Computer and Communications Security, pp. 7-18; Costan, V., Devadas, S., Intel SGX explained (2016) IACR Cryptology EPrint Archive 2016, p. 86; Davi, L., Lehmann, D., Sadeghi, A.-R., Monrose, F., Stitching the gadgets: On the ineffectiveness of coarse-grained control-flow integrity protection (2014) Proceedings of the 23rd USENIX Security Symposium; Evans, I., Long, F., Otgonbaatar, U., Shrobe, H., Rinard, M., Okhravi, H., Sidiroglou-Douskos, S., Control jujutsu: On the weaknesses of fine-grained control flow integrity (2015) ACM CCS; Goktas, E., Athanasopoulos, E., Bos, H., Portokalidis, G., Out of control: Overcoming control-flow integrity (2014) Proceedings of the 35th IEEE Symposium on Security and Privacy, , SP'14; Gruss, D., Lettner, J., Schuster, F., Ohrimenko, O., Haller, I., Costa, M., Strong and efficient cache side-channel protection using hardware transactional memory (2017) 26th USENIX Security Symposium; Gruss, D., Maurice, C., Wagner, K., Mangard, S., Flush+Flush: A fast and stealthy cache attack (2016) International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment, pp. 279-299. , Springer; Intel® Software Guard Extensions SDK, , https://software.intel.com/en-us/sgx-sdk; Intel® Software Guard Extensions SDK for Linux, , https://01.org/intel-software-guard-extensions; (2017) Intel® 64 and IA-32 Architectures Software Developer's Manual, Volume 3D: System Programming Guide, Part 4, , December Order Number 332831-065US; Irazoqui, G., Eisenbarth, T., Sunar, B., S$A: A shared cache attack that works across cores and defies vm sandboxing-and its application to aes (2015) Security and Privacy (SP), 2015 IEEE Symposium on, pp. 591-604; Kuvaiskii, D., Oleksenko, O., Arnautov, S., Trach, B., Bhatotia, P., Felber, P., Fetzer, C., SGXBOUNDS: Memory safety for shielded execution (2017) Proceedings of the Twelfth European Conference on Computer Systems, pp. 205-221; Lee, J., Jang, J., Jang, Y., Kwak, N., Choi, Y., Choi, C., Kim, T., Kang, B.B., Hacking in darkness: Return-oriented programming against secure enclaves (2017) USENIX Security, pp. 523-539; Lee, S., Shih, M.-W., Gera, P., Kim, T., Kim, H., Peinado, M., Inferring fine-grained control flow inside SGX enclaves with branch shadowing (2017) 26th USENIX Security Symposium, USENIX Security, pp. 16-18; Liu, F., Yarom, Y., Ge, Q., Heiser, G., Lee, R.B., Last-level cache side-channel attacks are practical (2015) Security and Privacy (SP), 2015 IEEE Symposium on, pp. 605-622; Mckeen, F., Alexandrovich, I., Anati, I., Caspi, D., Johnson, S., Leslie-Hurd, R., Rozas, C., Intel®Software guard extensions (Intel® SGX) support for dynamic memory management inside an enclave (2016) Proceedings of the Hardware and Architectural Support for Security and Privacy 2016, pp. 101-109. , New York, NY, USA HASP 2016, ACM; Moghimi, A., Irazoqui, G., Eisenbarth, T., CacheZoom: How SGX amplifies the power of cache attacks (2017) International Conference on Cryptographic Hardware and Embedded Systems, pp. 69-90. , Springer; Schuster, F., Costa, M., Fournet, C., Gkantsidis, C., Peinado, M., Mainar-Ruiz, G., Russinovich, M., VC3: Trustworthy data analytics in the cloud using SGX (2015) Security and Privacy (SP), 2015 IEEE Symposium on, pp. 38-54; Seo, J., SGX-Shield Open Source Repository, , https://github.com/jaebaek/SGX-Shield.Commit04b09dd, 2017-09-27; Seo, J., Lee, B., Kim, S., Shih, M.-W., Shin, I., Han, D., Kim, T., SGX-shield: Enabling address space layout randomization for SGX programs (2017) Proceedings of the 2017 Annual Network and Distributed System Security Symposium (NDSS), , San Diego, CA; Shacham, H., The geometry of innocent flesh on the bone: Return-into-libc without function calls (on the x86) (2007) Proceedings of the 14th ACM Conference on Computer and Communications Security, pp. 552-561; Shih, M.-W., Lee, S., Kim, T., Peinado, M., T-SGX: Eradicating controlled-channel attacks against enclave programs (2017) Network and Distributed System Security Symposium; Van Bulck, J., Weichbrodt, N., Kapitza, R., Piessens, F., Strackx, R., Telling your secrets without page faults: Stealthy page table-based attacks on enclaved execution (2017) 26th USENIX Security Symposium (USENIX Security); Weichbrodt, N., Kurmus, A., Pietzuch, P., Kapitza, R., AsyncShock: Exploiting synchronisation bugs in intel SGX enclaves (2016) European Symposium on Research in Computer Security, pp. 440-457. , Springer; Xu, Y., Cui, W., Peinado, M., Controlled-channel attacks: Deterministic side channels for untrusted operating systems (2015) IEEE Symposium on Security and Privacy; Yarom, Y., Falkner, K., FLUSH+RELOAD: A high resolution, low noise, L3 cache side-channel attack (2014) USENIX Security Symposium, pp. 719-732",,,"Baidu;Dropbox;Facebook;Google;NSF;The USENIX Association","USENIX Association","27th USENIX Security Symposium","15 August 2018 through 17 August 2018",,155142,,9781939133045,,,"English","Proc. USENIX Secur. Symp.",Conference Paper,"Final","",Scopus,2-s2.0-85057350742
"Ros A.S., Doshi-Velez F.","57196121909;34874672900;","Improving the adversarial robustness and interpretability of deep neural networks by regularizing their input gradients",2018,"32nd AAAI Conference on Artificial Intelligence, AAAI 2018",,,,"1660","1669",,150,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057345011&partnerID=40&md5=eb82fab92d99b8e2bc2b2ad755e5d01a","Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA  02138, United States","Ros, A.S., Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA  02138, United States; Doshi-Velez, F., Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA  02138, United States","Deep neural networks have proven remarkably effective at solving many classification problems, but have been criticized recently for two major weaknesses: the reasons behind their predictions are uninterpretable, and the predictions themselves can often be fooled by small adversarial perturbations. These problems pose major obstacles for the adoption of neural networks in domains that require security or transparency. In this work, we evaluate the effectiveness of defenses that differentiably penalize the degree to which small changes in inputs can alter model predictions. Across multiple attacks, architectures, defenses, and datasets, we find that neural networks trained with this input gradient regularization exhibit robustness to transferred adversarial examples generated to fool all of the other models. We also find that adversarial examples generated to fool gradient-regularized models fool all other models equally well, and actually lead to more “legitimate,” interpretable misclassifications as rated by people (which we confirm in a human subject experiment). Finally, we demonstrate that regularizing input gradients makes them more naturally interpretable as rationales for model predictions. We conclude by discussing this relationship between interpretability and robustness in deep neural networks. Copyright © 2018, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,"Artificial intelligence; Forecasting; Human subject experiments; Interpretability; Misclassifications; Model prediction; Deep neural networks",,,,,"Adler, P., Falk, C., Friedler, S.A., Rybeck, G., Scheidegger, C., Smith, B., Venkatasubramanian, S., Auditing black-box models for indirect influence (2016) Data Mining (ICDM), 2016 IEEE 16th International Conference on, pp. 1-10. , IEEE; Angwin, J., Larson, J., Mattu, S., Kirchner, L., (2016) How We Analyzed the Compas Recidivism Algorithm, , ProP-ublica; Athalye, A., Sutskever, I., (2017) Synthesizing Robust Adversarial Examples, , arXiv preprint; Ba, J., Caruana, R., Do deep nets really need to be deep? (2014) Advances in Neural Information Processing Systems, pp. 2654-2662; Baehrens, D., Schroeter, T., Harmeling, S., Kawanabe, M., Hansen, K., Müller, K.-R., How to explain individual classification decisions (2010) Journal of Machine Learning Research, 11, pp. 1803-1831. , Jun; Butalov, Y., (2011) The notMNIST Dataset, , http://yaroslavvb.com/upload/notMNIST/; Carlini, N., Wagner, D., (2016) Defensive Distillation Is Not Robust to Adversarial Examples, , arXiv preprint; Caruana, R., Lou, Y., Gehrke, J., Koch, P., Sturm, M., Elhadad, N., Intelligible models for healthcare: Predicting pneumonia risk and hospital 30-day readmission (2015) Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 1721-1730. , ACM; Drucker, H., Le Cun, Y., Improving generalization performance using double backpropagation (1992) IEEE Transactions on Neural Networks, 3 (6), pp. 991-997; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint; Grundland, M., Dodgson, N.A., Decolorize: Fast, contrast enhancing, color to grayscale conversion (2007) Pattern Recognition, 40 (11), pp. 2891-2896; Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., Courville, A., (2017) Improved Training of Wasserstein Gans, , arXiv preprint; Kang, H.-W., Kang, H.-B., Prediction of crime occurrence from multi-modal data using deep learning (2017) PloS One, 12 (4); Kingma, D., Ba, J., (2014) Adam: A Method for Stochastic Optimization, , arXiv preprint; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Machine Learning at Scale, , arXiv preprint; LeCun, Y., Cortes, C., Burges, C.J., (2010) The MNIST Database of Handwritten Digits, , http://yann.lecun.com/exdb/mnist/; Nayebi, A., Ganguli, S., (2017) Biologically Inspired Protection of Deep Networks from Adversarial Attacks, , arXiv preprint; Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., Ng, A.Y., Reading digits in natural images with unsupervised feature learning (2011) NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011; Papernot, N., Goodfellow, I., Sheatsley, R., Feinman, R., McDaniel, P., (2016) Cleverhans V1.0.0: An Adversarial Machine Learning Library, , arXiv preprint; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387. , IEEE; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Security and Privacy (SP), 2016 IEEE Symposium on, pp. 582-597. , IEEE; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519. , ACM; Ribeiro, M.T., Singh, S., Guestrin, C., Why should I trust you?: Explaining the predictions of any classifier (2016) Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 1135-1144. , ACM; Ross, A.S., Hughes, M.C., Doshi-Velez, F., Right for the right reasons: Training differentiable models by constraining their explanations (2017) Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, pp. 2662-2670; Sermanet, P., Chintala, S., LeCun, Y., Convolu-tional neural networks applied to house numbers digit classification (2012) Pattern Recognition (ICPR), 2012 21st International Conference on, pp. 3288-3291. , IEEE; Smilkov, D., Thorat, N., Kim, B., Viégas, F., Watten-Berg, M., (2017) Smoothgrad: Removing Noise by Adding Noise, , arXiv preprint; Sturm, B.L., A simple method to determine if a music information retrieval system is a horse (2014) IEEE Transactions on Multimedia, 16 (6), pp. 1636-1644; Sundararajan, M., Taly, A., Yan, Q., (2016) Gradients of Counterfactuals, , arXiv preprint; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses, , arXiv preprint; Tramèr, F., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2017) The Space of Transferable Adversarial Examples, , arXiv preprint; Xu, W., Evans, D., Qi, Y., (2017) Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks, , arXiv preprint",,,"Association for the Advancement of Artificial Intelligence","AAAI press","32nd AAAI Conference on Artificial Intelligence, AAAI 2018","2 February 2018 through 7 February 2018",,143510,,9781577358008,,,"English","AAAI Conf. Artif. Intell., AAAI",Conference Paper,"Final","",Scopus,2-s2.0-85057345011
"Wang Y., Jha S., Chaudhuri K.","57194610617;7202728236;8935564900;","Analyzing the robustness of nearest neighbors to adversarial examples",2018,"35th International Conference on Machine Learning, ICML 2018","11",,,"8132","8147",,15,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057321166&partnerID=40&md5=8b9115a7359e72ce02ccc27b57f9c154","University of California, San Diego, United States; University of Wisconsin-Madison, United States","Wang, Y., University of California, San Diego, United States; Jha, S., University of Wisconsin-Madison, United States; Chaudhuri, K., University of California, San Diego, United States","Motivated by safety-critical applications, test-time attacks on classifiers via adversarial examples has recently received a great deal of attention. However, there is a general lack of understanding on why adversarial examples arise; whether they originate due to inherent properties of data or due to lack of training samples remains ill-understood. In this work, we introduce a theoretical framework analogous to bias-variance theory for understanding these effects. We use our framework to analyze the robustness of a canonical non-parametric classifier - the k-nearest neighbors. Our analysis shows that its robustness properties depend critically on the value of k - the classifier may be inherently non-robust for small k, but its robustness approaches that of the Bayes Optimal classifier for fast-growing k. We propose a novel modified 1-nearest neighbor classifier, and guarantee its robustness in the large sample limit. Our experiments suggest that this classifier may have good robustness properties even for reasonable data set sizes. Copyright 2018 by the author(s). © 2018 by the Authors All rights reserved.",,"Artificial intelligence; Learning systems; Nearest neighbor search; Safety engineering; 1-nearest neighbor; K-nearest neighbors; Nearest neighbors; Non-parametric classifiers; Robustness properties; Safety critical applications; Theoretical framework; Training sample; Classification (of information)",,,,,"Sinha, A., Hongseok Namkoong, J.D., (2018) Certifiable Distributional Robustness with Principled Adversarial Training, , International Conference on Learning Representations; Amsaleg, L., Bailey, J., Erfani, S., Furon, T., Houle, M.E., Radovanovic, M., Vinh, N.X., (2016) The Vulnerability of Learning to Adversarial Perturbation Increases with Intrinsic Dimensionality; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Srndic, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 387-402. , Springer; Chaudhuri, K., Dasgupta, S., Rates of convergence for the cluster tree (2010) Advances in Neural Information Processing Systems, 23, pp. 343-351. , In J. D. Lafferty, C. K. I. Williams, J. Shawe-Taylor, R. S. Zemel, and A. Culotta, editors, Curran Associates, Inc; Chaudhuri, K., Dasgupta, S., Rates of convergence for nearest neighbor classification (2014) Advances in Neural Information Processing Systems, pp. 3437-3445; Cover, T., Hart, P., Nearest neighbor pattern classification (1967) IEEE Transactions on Information Theory, 13, pp. 21-27; Devroye, L., Gyorfi, L., Krzyzak, A., Lugosi, G., On the strong universal consistency of nearest neighbor regression function estimates (1994) The Annals of Statistics, pp. 1371-1385; Devroye, L.P., Wagner, T.J., The strong uniform consistency of nearest neighbor density estimates (1977) The Annals of Statistics, pp. 536-540; Fawzi, A., Moosavi-Dezfooli, S.-M., Frossard, P., Robustness of classifiers: From adversarial to random noise (2016) Advances in Neural Information Processing Systems, 29, pp. 1632-1640. , In D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett, editors, Curran Associates, Inc; Friedman, J., Hastie, T., Tibshirani, R., Additive logistic regression: A statistical view of boosting (with discussion and a rejoinder by the authors) (2000) The Annals of Statistics, 28 (2), pp. 337-407; Gilmer, J., Metz, L., Faghri, F., Schoenholz, S.S., Raghu, M., Wattenberg, M., Goodfellow, I., (2018) Adversarial Spheres, , arXivpreprint arXiv; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint arXiv; Hein, M., Andriushchenko, M., Formal guarantees on the robustness of a classifier against adversarial manipulation (2017) Advances in Neural Information Processing Systems, pp. 2263-2273; Katz, G., Barrett, C., Dill, D.L., Julian, K., Kochen-Derfer, M.J., (2017) Towards Proving the Adversarial Robustness of Deep Neural Networks, , arXiv preprint arXiv; Kolter, J.Z., Wong, E., (2017) Provable Defenses Against Adversarial Examples Via the Convex Outer Adversarial Polytope, , arXiv preprint arXiv; Kontorovich, A., Weiss, R., A bayes consistent 1-nn classifier (2015) Artificial Intelligence and Statistics Conference; Kulkarni, S., Posner, S., Rates of convergence of nearest neighbor estimation under arbitrary sampling (1995) IEEE Transactions on Information Theory, 41 (4), pp. 1028-1039; Lichman, M., (2013) UCI Machine Learning Repository; Lowd, D., Meek, C., Adversarial learning (2005) Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining, pp. 641-647. , ACM; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, Stat, 1050, p. 9; Mitzenmacher, M., Upfal, E., (2005) Probability and Computing: Randomized Algorithms and Probabilistic Analysis, , Cambridge university press; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Proceedings of the 1st IEEE European Symposium on Security and Privacy, , arXiv preprint arXiv; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples, , arXiv preprint arXiv; Papernot, N., Carlini, N., Goodfellow, I., Feinman, R., Faghri, F., Matyasko, A., Hambardzumyan, K., Lin, Y.-C., (2017) Cleverhans v2.0.0: An Adversarial Machine Learning Library, , arXiv preprint arXiv; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, B., Swami, A., Practical black-box attacks against deep learning systems using adversarial examples (2017) Proceedings of the 2017 ACM Asia Conference on Computer and Communications Security; Stone, C., Consistent nonparametric regression (1977) Annals of Statistics, 5, pp. 595-645; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Er-Han, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint arXiv","Chaudhuri, K.; University of CaliforniaUnited States; email: kamalika@cs.ucsd.edu","Krause A.Dy J.",,"International Machine Learning Society (IMLS)","35th International Conference on Machine Learning, ICML 2018","10 July 2018 through 15 July 2018",,141700,,9781510867963,,,"English","Int. Conf. Mach. Learn., ICML",Conference Paper,"Final","",Scopus,2-s2.0-85057321166
"Uesato J., O'Donoghue B., Van Den Oord A., Kohli P.","57202451204;54407366600;55329476300;14035707300;","Adversarial risk and the dangers of evaluating against weak attacks",2018,"35th International Conference on Machine Learning, ICML 2018","11",,,"7995","8007",,46,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057301673&partnerID=40&md5=53ebff6be03140645e37b4d3a505d486","DeepMind, United States","Uesato, J., DeepMind, United States; O'Donoghue, B., DeepMind, United States; Van Den Oord, A., DeepMind, United States; Kohli, P., DeepMind, United States","This paper investigates recently proposed approaches for defending against adversarial examples and evaluating adversarial robustness. We motivate adversarial risk as an objective for achieving models robust to worst-case inputs. We then frame commonly used attacks and evaluation metrics as defining a tractable surrogate objective to the true adversarial risk. This suggests that models may optimize this surrogate rather than the true adversarial risk. We formalize this notion as obscurity to an adversary, and develop tools and heuristics for identifying obscured models and designing transparent models. We demonstrate that this is a significant problem in practice by repurposing gradient-free optimization techniques into adversarial attacks, which we use to decrease the accuracy of several recently proposed defenses to near zero. Our hope is that our formulations and results will help researchers to develop more powerful defenses. Copyright 2018 by the author(s). © 2018 by the Authors All rights reserved.",,"Artificial intelligence; Optimization; Evaluation metrics; Gradient-free optimizations; Repurposing; Worst case inputs; Learning systems",,,,,"Athalye, A., Carlini, N., Wagner, D., (2018) Obfuscated Gradients Give A False Sense of Security: Circumventing Defenses to Adversarial Examples, , https://arxiv.org/abs/1802.00420, Accessed: 2018-02-03; Athalye, A., Engstrom, L., Ilyas, A., Kwok, K., (2018) Synthesizing Robust Adversarial Examples, , https://openreview.net/forum?id=BJDH5M-AW; Audibert, J., Catoni, O., Robust linear least squares regression (2011) The Annals of Statistics, 39 (5), pp. 2766-2794; Brown, T.B., Mane, D., Roy, A., Abadi, M., Gilmer, J., (2017) Adversarial Patch, , arXiv preprint arXiv; Brownlees, C., Joly, E., Lugosi, G., Empirical risk minimization for heavy-tailed losses (2015) The Annals of Statistics, 43 (6), pp. 2507-2536; Bunel, R., Turkaslan, I., Torr, P.H.S., Kohli, P., Pawan Kumar, M., (2017) Piecewise Linear Neural Network Verification: A Comparative Study, , arXiv preprint arXiv; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 3-14. , ACM; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium on, pp. 39-57. , IEEE; Carlini, N., Katz, G., Barrett, C., Dill, D.L., (2017) Ground-truth Adversarial Examples, , arXiv preprint arXiv; Chen, P., Zhang, H., Sharma, Y., Yi, J., Hsieh, C., Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 15-26. , ACM; Paul Christiano, 2016. , https://ai-alignment.com/red-teams-b5b6de33dc76, Accessed: 2018-01-20; Deng, J., Dong, W., Socher, R., Li, L., Li, K., Fei-Fei, L., Imagenet: A large-scale hierarchical image database (2009) Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pp. 248-255. , IEEE; Goodfellow, I., Papernot, N., (2017), http://www.cleverhans.io/security/privacy/ml/2017/02/15/why-attacking-machine-learning-is-easier-than-defending-it.html, Accessed: 2018-01-20; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint arXiv; Graves, A., Mohamed, A., Hinton, G., Speech recognition with deep recurrent neural networks (2013) Acoustics, Speech and Signal Processing (Icassp), 2013 Ieee International Conference on, pp. 6645-6649. , IEEE; Grosse, K., Papernot, N., Manoharan, P., Backes, M., McDaniel, P., (2016) Adversarial Perturbations Against Deep Neural Networks for Malware Classification, , arXiv preprint arXiv; Gu, S., Rigazio, L., Towards Deep Neural Network Architectures Robust to Adversarial Examples, , arXiv preprint arXiv:, 20U; Guo, C., Rana, M., Cisse, M., Van Der Maaten, L., (2017) Countering Adversarial Images Using Input Transformations, , arXiv preprint arXiv; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Huang, S., Papernot, N., Goodfellow, I., Duan, Y., Abbeel, P., (2017) Adversarial Attacks on Neural Network Policies, , arXiv preprint arXiv; Ilyas, A., Engstrom, L., Athalye, A., Lin, J., (2017) Query-efficient Black-box Adversarial Examples, , arXiv preprint arXiv; Jia, R., Liang, P., (2011) Adversarial Examples for Evaluating Reading Comprehension Systems, , arXiv preprint arXiv; Katz, G., Barrett, C., Dill, D., Julian, K., Kochenderfer, M., (2017) Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks, , arXiv preprint arXiv; Kim, B., (2015) Interactive and Interpretable Machine Learning Models for Human Machine Collaboration, , PhD thesis, Massachusetts Institute of Technology; Kingma, D.P., Ba, J., (2014) Adam: A Method for Stochastic Optimization, , arXiv preprint arXiv; Zico Kolter, J., Wong, E., (2017) Provable Defenses Against Adversarial Examples Via the Convex Outer Adversarial Polytope, , arXiv preprint arXiv; Krakovna, V., Doshi-Velez, F., (2016) Increasing the Inter-pretability of Recurrent Neural Networks Using Hidden Markov Models, , arXiv preprint arXiv; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images; Kurakin, A., Goodfellow, I., (2017) Nips 2017: Defense Against Adversarial Attack, , https://www.kaggle.com/c/nips-2017-defense-against-adversarial-attack, Accessed: 2018-01-20; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Machine Learning at Scale, , arXiv preprint arXiv; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint arXiv; Liao, F., Liang, M., Dong, Y., Pang, T., Zhu, J., Hu, X., (2017) Defense Against Adversarial Attacks Using High-level Representation Guided Denoiser, , arXiv preprint arXiv; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2011) Towards Deep Learning Models Resistant to Adversarial Attacks, , arXiv preprint arXiv; Maryak, J.L., Chin, D.C., Global random optimization by simultaneous perturbation stochastic approximation (2001) American Control Conference, 2001. Proceedings of the 2001, 2, pp. 756-762. , IEEE; Meng, D., Chen, H., Magnet: A two-pronged defense against adversarial examples (2017) Proceedings of the 2017 ACM S1GSAC Conference on Computer and Communications Security, pp. 135-147. , ACM; Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.A., Veness, J., Bellemare, M.G., Graves, A., Ostrovski, G., Human-level control through deep reinforcement learning (2015) Na-fwe, 518 (7540), p. 529; Olah, C., Mordvintsev, A., Schubert, L., Feature visualization (2017) Distill; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Trans-ferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples, , arXiv preprint arXiv; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519. , ACM; Papernot, N., Faghri, F., Carlini, N., Goodfellow, I., Feinman, R., Kurakin, A., Xie, C., Long, R., (2018) Clevcrhans v2.1.0: An Adversarial Machine Learning Library, , arXiv preprint arXiv; Pinto, L., Davidson, J., Sukthankar, R., Gupta, A., (2017) Robust Adversarial Reinforcement Learning, , arXiv preprint arXiv; Raghunathan, A., Steinhardt, J., Liang, P., Certified defenses against adversarial examples (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=Bys4ob-Rb; Slavin Ross, A., Doshi-Velez, F., Improving the adversarial robustness and interpretability of deep neural networks by regularizing their input gradients (2018) AAAI Conference on Artificial Intelligence; Salimans, T., Ho, J., Chen, X., Sutskever, I., (2017) Evolution Strategies As A Scalable Alternative to Reinforcement Learning, , arXiv preprint arXiv; Salimans, T., Karpathy, A., Chen, X., Kingma, D.P., (2017) Pixelcnn++: Improving the Pixelcnn with Discretized Logistic Mixture Likelihood and Other Modifications, , arXiv preprint arXiv; Sinha, A., Namkoong, H., Duchi, J., (2017) Certifiable Distributional Robustness with Principled Adversarial Training, , arXiv preprint arXiv; Song, Y., Kim, T., Nowozin, S., Ermon, S., Kushman, N., (2017) Pixeldefend: Leveraging Generative Models to Understand and Defend Against Adversarial Examples, , arXiv preprint arXiv; Spall, J.C., Multivariate stochastic approximation using a simultaneous perturbation gradient approximation (1992) IEEE Transactions on Automatic Control, 37 (3), pp. 332-341; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint arXiv; Tramer, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses, , arXiv preprint arXiv; Valiant, L.G., A theory of the learnable (1984) Communications of the ACM, 27 (11), pp. 1134-1142; Van Den Oord, A., Kalchbrenner, N., Kavukcuoglu, K., (2016) Pixel Recurrent Neural Networks, , arXiv preprint arXiv; Warde-Farley, D., Goodfellow, I., Adversarial perturbations of deep neural networks (2016) Perturbations Optimization and Statistics, p. 311; Wierstra, D., Schaul, T., Peters, J., Schmidhu-Ber, J., Natural evolution strategies (2008) Evolutionary Computation, 2008. CEC 2008.(IEEE World Congress on Computational Intelligence). IEEE Congress on, pp. 3381-3387. , IEEE; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuillc, A., (2017) Mitigating Adversarial Effects Through Randomization, , arXiv preprint arXiv; Yuan, X., He, P., Zhu, Q., Rana Bhat, R., Li, X., (2017) Adversarial Examples: Attacks and Defenses for Deep Learning, , arXiv preprint arXiv","Uesato, J.; DeepMindUnited States; email: juesato@google.com","Krause A.Dy J.",,"International Machine Learning Society (IMLS)","35th International Conference on Machine Learning, ICML 2018","10 July 2018 through 15 July 2018",,141700,,9781510867963,,,"English","Int. Conf. Mach. Learn., ICML",Conference Paper,"Final","",Scopus,2-s2.0-85057301673
"Wang K.-C., Vicol P., Lucas J., Gu L., Grosse R., Zemel R.","57202054741;56657961500;57204820834;57204817680;34875103900;7004912699;","Adversarial distillation of Bayesian neural network posteriors",2018,"35th International Conference on Machine Learning, ICML 2018","12",,,"8239","8248",,2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057295083&partnerID=40&md5=58b9031cfb6519489d3324ea3c32f9ef","University of Toronto, Toronto, ON, Canada; Vector Institute, Toronto, ON, Canada","Wang, K.-C., University of Toronto, Toronto, ON, Canada, Vector Institute, Toronto, ON, Canada; Vicol, P., University of Toronto, Toronto, ON, Canada, Vector Institute, Toronto, ON, Canada; Lucas, J., University of Toronto, Toronto, ON, Canada, Vector Institute, Toronto, ON, Canada; Gu, L., University of Toronto, Toronto, ON, Canada; Grosse, R., University of Toronto, Toronto, ON, Canada, Vector Institute, Toronto, ON, Canada; Zemel, R., University of Toronto, Toronto, ON, Canada, Vector Institute, Toronto, ON, Canada","Bayesian neural networks (BNNs) allow us to reason about uncertainty in a more principled way. Stochastic Gradient Langevin Dynamics (SGLD) enables efficient BNN learning by drawing samples from the BNN posterior using minibatches. However, SGLD and its extensions require storage of many copies of the model parameters, a potentially prohibitive cost, especially for large neural networks. We propose a framework, Adversarial Posterior Distillation, to distill the SGLD samples using a Generative Adversarial Network (GAN). At test-time, samples are generated by the GAN. We show that this distillation framework incurs no loss in performance on recent BNN applications including anomaly detection, active learning, and defense against adversarial attacks. By construction, our framework not only distills the Bayesian predictive distribution, but the posterior itself. This allows one to compute quantities such as the approximate model variance, which is useful in downstream tasks. To our knowledge, these are the first results applying MCMC-based BNNs to the aforementioned downstream applications. © 35th International Conference on Machine Learning, ICML 2018.All Rights Reserved.",,"Distillation; Learning systems; Neural networks; Stochastic systems; Adversarial networks; Anomaly detection; Approximate model; Bayesian neural networks; Downstream applications; Langevin dynamics; Predictive distributions; Stochastic gradient; Bayesian networks",,,,,"Ahn, S., Korattikara, A., Welling, M., (2012) Bayesian Posterior Sampling Via Stochastic Gradient Fisher Scoring; Ahn, S., Shahbaba, B., Welling, M., Distributed stochastic gradient MCMC (2014) International Conference on Machine Learning, pp. 1044-1052; Arjovsky, M., Chintala, S., Bottou, L., (2017) Wasserstein GAN; Balan, A.K., Rathod, V., Murphy, K.P., Welling, M., Bayesian dark knowledge (2015) Advances in Neural Information Processing Systems, pp. 3438-3446; Blundell, C., Cornebise, J., Kavukcuoglu, K., Wierstra, D., (2015) Weight Uncertainty in Neural Networks; Carlini, N., Wagner, D., (2017) Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods; Chen, T., Fox, E., Guestrin, C., Stochastic gradient Hamiltonian Monte Carlo (2014) International Conference on Machine Learning, pp. 1683-1691; Dempster, A.P., Laird, N.M., Rubin, D.B., Maximum likelihood from incomplete data via the EM algorithm (1977) Journal of the Royal Statistical Society. Series B, pp. 1-38; Ding, N., Fang, Y., Babbush, R., Chen, C., Skeel, R.D., Neven, H., Bayesian sampling using stochastic gradient thermostats (2014) Advances in Neural Information Processing Systems, pp. 3203-3211; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts; Gal, Y., Ghahramani, Z., Dropout as a Bayesian approximation: Representing model uncertainty in deep learning (2016) International Conference on Machine Learning, pp. 1050-1059; Gal, Y., Islam, R., Ghahramani, Z., (2017) Deep Bayesian Active Learning with Image Data; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, pp. 2672-2680; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Graves, A., Practical variational inference for neural networks (2011) Advances in Neural Information Processing Systems, pp. 2348-2356; Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., Courville, A., (2017) Improved Training of Wasserstein GANs; Guo, C., Pleiss, G., Sun, Y., Weinberger, K.Q., (2017) On Calibration of Modern Neural Networks; Hendrycks, D., Gimpel, K., (2016) A Baseline for Detecting Misclassified and Out-of-distribution Examples in Neural Networks; Hernandez-Lobato, J.M., Adams, R., Probabilistic backpropagation for scalable learning of Bayesian neural networks (2015) International Conference on Machine Learning, pp. 1861-1869; Hinton, G.E., Van Camp, D., Keeping the neural networks simple by minimizing the description length of the weights (1993) Proceedings of the Sixth Annual Conference on Computational Learning Theory, pp. 5-13. , ACM; Houlsby, N., Huszar, F., Ghahramani, Z., Lengyel, M., (2011) Bayesian Active Learning for Classification and Preference Learning; Kingma, D.P., Welling, M., Stochastic gradient VB and the variational auto-encoder (2014) Second International Conference on Learning Representations; Krizhevsky, A., Hinton, G., Learning multiple layers of features from tiny images (2009) Technical Report, , University of Toronto; Krueger, D., Huang, C.-W., Islam, R., Turner, R., Lacoste, A., Courville, A., (2017) Bayesian Hypernetworks; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradientbased learning applied to document recognition (1998) Proceedings of the IEEE, 86 (11), pp. 2278-2324; Li, Y., Turner, R.E., Liu, Q., (2017) Approximate Inference with Amortised MCMC; Louizos, C., Welling, M., (2017) Multiplicative Normalizing Flows for Variational Bayesian Neural Networks; MacKay, D.J., A practical Bayesian framework for backpropagation networks (1992) Neural Computation, 4 (3), pp. 448-472; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks; Minka, T.P., Expectation propagation for approximate Bayesian inference (2001) Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence, pp. 362-369. , Morgan Kaufmann Publishers Inc; Neal, R.M., (1996) Bayesian Learning for Neural Networks, , PhD thesis, University of Toronto; Rauber, J., Brendel, W., Bethge, M., (2017) Foolbox V0.8.0: A Python Toolbox to Benchmark the Robustness of Machine Learning Models; Rawat, A., Wistuba, M., Nicolae, M.-I., (2017) Adversarial Phenomenon in the Eyes of Bayesian Deep Learning; Rezende, D.J., Mohamed, S., Wierstra, D., (2014) Stochastic Backpropagation and Approximate Inference in Deep Generative Models; Rosea, M., Lakshminarayanan, B., Warde-Farley, D., Mohamed, S., (2017) Variational Approaches for Autoencoding Generative Adversarial Networks; Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., Chen, X., Improved techniques for training GANs (2016) Advances in Neural Information Processing Systems, pp. 2234-2242; Salimans, T., Zhang, H., Radford, A., Metaxas, D., Improving GANs using optimal transport (2018) International Conference on Learning Representations; Springenberg, J.T., Dosovitskiy, A., Brox, T., Riedmiller, M., (2014) Striving for Simplicity: The All Convolutional Net; Srivastava, N., Hinton, G.E., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., Dropout: A simple way to prevent neural networks from overfitting (2014) Journal of Machine Learning Research, 15 (1), pp. 1929-1958; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks; Vollmer, S.I., Zygalakis, K.C., Teh, Y.W., Exploration of the (non-) asymptotic bias and variance of stochastic gradient langevin dynamics (2016) Journal of Machine Learning Research, 17 (159), pp. 1-48; Wei, X., Liu, Z., Wang, L., Gong, B., Improving the improved training of Wasserstein GANs (2018) International Conference on Learning Representations; Welling, M., Teh, Y.W., Bayesian learning via stochastic gradient Langevin dynamics (2011) Proceedings of the 28th International Conference on Machine Learning, pp. 681-688","Wang, K.-C.; University of TorontoCanada; email: wangkual@cs.toronto.edu","Dy J.Krause A.",,"International Machine Learning Society (IMLS)","35th International Conference on Machine Learning, ICML 2018","10 July 2018 through 15 July 2018",,141700,,9781510867963,,,"English","Int. Conf. Mach. Learn., ICML",Conference Paper,"Final","",Scopus,2-s2.0-85057295083
"Dai H., Li H., Tian T., Xin H., Wang L., Jun Z., Le S.","57189099007;57204804669;57203906456;57204805136;57204812400;57204798252;57204799311;","Adversarial attack on graph structured data",2018,"35th International Conference on Machine Learning, ICML 2018","3",,,"1799","1808",,56,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057260187&partnerID=40&md5=f27682ae15830c7b87e1ffcf27e737aa","Georgia Institute of Technology, Georgia; Ant Financial, China; Tsinghua University, China","Dai, H., Georgia Institute of Technology, Georgia; Li, H., Ant Financial, China; Tian, T., Tsinghua University, China; Xin, H., Ant Financial, China; Wang, L., Ant Financial, China; Jun, Z., Tsinghua University, China; Le, S., Georgia Institute of Technology, Georgia, Ant Financial, China","Deep learning on graph structures has shown exciting results in various applications. However, few attentions have been paid to the robustness of such models, in contrast to numerous research work for image or text adversarial attack and defense. In this paper, we focus on the adversarial attacks that fool deep learning models by modifying the combinatorial structure of data. We first propose a reinforcement learning based attack method that learns the generalizable attack policy, while only requiring prediction labels from the target classifier. We further propose attack methods based on genetic algorithms and gradient descent in the scenario where additional prediction confidence or gradients are available. We use both synthetic and real-world data to show that, a family of Graph Neural Network models are vulnerable to these attacks, in both graph-level and node-level classification tasks. We also show such attacks can be used to diagnose the learned classifiers. © 2018 35th International Conference on Machine Learning, ICML 2018. All rights reserved.",,"Artificial intelligence; Genetic algorithms; Graphic methods; Reinforcement learning; Classification tasks; Combinatorial structures; Gradient descent; Graph neural networks; Graph structured data; Graph structures; Learning models; Prediction confidence; Deep learning",,,,,"Akoglu, L., Tong, H., Koutra, D., Graph based anomaly detection and description: A survey (2015) Data Mining and Knowledge Discovery, 29 (3), pp. 626-688; Bello, I., Pham, H., Le, Q.V., Norouzi, M., Bengio, S., (2016) Neural Combinatorial Optimization with Reinforcement Learning; Buckman, J., Roy, A., Raffel, C., Goodfellow, I., Thermometer encoding: One hot way to resist adversarial examples (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=S18Su-CW; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 15-26. , ACM; Dai, H., Dai, B., Song, L., Discriminative embeddings of latent variable models for structured data (2016) ICML; Dai, H., Khalil, E.B., Zhang, Y., Dilkina, B., Song, L., (2017) Learning Combinatorial Optimization Algorithms over Graphs; Duvenaud, D.K., Maclaurin, D., Iparraguirre, J., Bombarell, R., Hirzel, T., Aspuru-Guzik, A., Adams, R.P., Convolutional networks on graphs for learning molecular fingerprints (2015) Advances in Neural Information Processing Systems, pp. 2215-2223; Gilmer, J., Schoenholz, S.S., Riley, P.F., Vinyals, O., Dahl, G.E., (2011) Neural Message Passing for Quantum Chemistry; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Hamilton, W.L., Ying, R., Leskovec, J., (2017) Inductive Representation Learning on Large Graphs; Jia, R., Liang, P., (2017) Adversarial Examples for Evaluating Reading Comprehension Systems; Kipf, T.N., Welling, M., (2016) Semi-supervised Classification with Graph Convolutional Networks; Lei, T., Jin, W., Barzilay, R., Jaakkola, T., (2017) Deriving Neural Architectures from Sequence and Graph Kernels; Li, Y., Tarlow, D., Brockschmidt, M., Zemel, R., (2015) Gated Graph Sequence Neural Networks; Miikkulainen, R., Liang, J., Meyerson, E., Rawal, A., Fink, D., Francon, O., Raju, B., Hodjat, B., (2017) Evolving Deep Neural Networks; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519. , ACM; Real, E., Moore, S., Selle, A., Saxena, S., Suematsu, Y., Le, Q., Kurakin, A., (2017) Large-scale Evolution of Image Classifiers; Scarselli, F., Gori, M., Tsoi, A.C., Hagenbuchner, M., Monfardini, G., The graph neural network model (2009) Neural Networks, IEEE Transactions on, 20 (1), pp. 61-80; Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., Dropout: A simple way to prevent neural networks from overfitting (2014) The Journal of Machine Learning Research, 15 (1), pp. 1929-1958; Su, J., Vargas, D.V., Kouichi, S., (2017) One Pixel Attack for Fooling Deep Neural Networks; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks; Trivedi, R., Dai, H., Wang, Y., Song, L., Know-evolve: Deep temporal reasoning for dynamic knowledge graphs (2017) ICML; Ziigner, D., Akbarnejad, A., Gunnemann, S., Adversarial attacks on neural networks for graph data (2018) KDD","Dai, H.; Georgia Institute of TechnologyGeorgia; email: hanjundai@gatcch.edu","Krause A.Dy J.",,"International Machine Learning Society (IMLS)","35th International Conference on Machine Learning, ICML 2018","10 July 2018 through 15 July 2018",,141700,,9781510867963,,,"English","Int. Conf. Mach. Learn., ICML",Conference Paper,"Final","",Scopus,2-s2.0-85057260187
"El Mhamdi E.M., Guerraoui R., Rouault S.","57195391207;7006237459;57199500150;","The hidden vulnerability of distributed learning in byzantium",2018,"35th International Conference on Machine Learning, ICML 2018","8",,,"5674","5686",,21,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057247992&partnerID=40&md5=70c3e7e72c2fb40230eb337ab8347371","EPFL, Lausanne, Switzerland","El Mhamdi, E.M., EPFL, Lausanne, Switzerland; Guerraoui, R., EPFL, Lausanne, Switzerland; Rouault, S., EPFL, Lausanne, Switzerland","While machine learning is going through an era of celebrated success, concerns have been raised about the vulnerability of its backbone: Stochastic gradient descent (SGD). Recent approaches have been proposed to ensure the robustness, of distributed SGD against adversarial (Byzantine) workers sending poisoned gradients during the training phase. Some of these approaches have been proven Byzantine-resilient: They ensure the convergence of SGD despite the presence of a minority of adversarial workers. We show in this paper that convergence is not enough. In high dimension d 1, an adversary can build on the loss function's non-convexity to make SGD converge to ineffective models. More precisely, we bring to light that existing Byzantine-resilient schemes leave a margin of poisoning of Cl(f(d)), where f(d) increases at least like Vd. Based on this leeway, we build a simple attack, and experimentally show its strong to utmost effectivity on CIFAR-10 and MNIST. We introduce Bulyan, and prove it significantly reduces the attacker's leeway to a narrow C(1/V5"") bound. We empirically show that Bulyan does not suffer the fragility of existing aggregation rules and, at a reasonable cost in terms of required batch size, achieves convergence as if only non-Byzantine gradients had been used to update the model. © The Author(s) 2018.",,"Artificial intelligence; Stochastic systems; Aggregation rules; Batch sizes; Distributed learning; High dimensions; Loss functions; Nonconvexity; Stochastic gradient descent; Training phase; Learning systems",,,,,"Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Isard, M., Tensorflow: A system for large-scale machine learning (2016) Proceedings of the 12th USENIX Symposium on Operating Systems Design and Implementation (OSDI), , Savannah, Georgia, USA; Biggio, B., Laskov, P., Poisoning attacks against support vector machines (2012) International Conference on Machine Learning (ICML. Citeseer; Biggio, B., Roli, F., Wild patterns: Ten years after the rise of adversarial machine learning (2017) ArXiv Preprint ArXiv:1712.03141; Blanchard, P., El Mhamdi, E.M., Guerraoui, R., Stainer, J., Machine learning with adversaries: Byzantine tolerant gradient descent (2017) Advances in Neural Information Processing Systems 30, pp. 118-128. , Curran Associates, Inc; Bojarski, M., Del Testa, D., Dworakowski, D., Firner, B., Flepp, B., Goyal, P., Jackel, L.D., Zhang, J., End to end learning for self-driving cars (2016) ArXiv Preprint ArXiv:1604.07316; Bottou, L., Online learning and stochastic approximations (1998) Online Learning in Neural Networks, 17 (9), p. 142; Bottou, L., (2012) Stochastic Gradient Descent Tricks, pp. 421-436. , https://doi.org/10.1007/978-3-642-35289-8_25, Springer Berlin Heidelberg, Berlin, Heidelberg, ISBN 978-3-642-35289-8; Chen, Y., Su, L., Xu, J., Distributed statistical machine learning in adversarial settings: Byzantine gradient descent (2017) ArXiv Preprint ArXiv:1705.05491; Choromanska, A., Henaff, M., Mathieu, M., Ben Arous, G., LeCun, Y., The loss surfaces of multilayer networks (2015) Artificial Intelligence and Statistics, pp. 192-204; Choromanska, A., LeCun, Y., Ben Arous, G., Open problem: The landscape of the loss surfaces of multilayer networks (2015) Conference on Learning Theory, pp. 1756-1760; Cohen, M.B., Lee, Y.T., Miller, G., Pachocki, J., Sidford, A., Geometric median in nearly linear time (2016) Proceedings of the Forty-eighth Annual ACM Symposium on Theory of Computing, pp. 9-21. , ACM; Dean, J., Corrado, G., Monga, R., Chen, K., Devin, M., Mao, M., Tucker, P., Le, Q.V., Large scale distributed deep networks (2012) Advances in neural information processing systems, pp. 1223-1231; Gilmer, J., Metz, L., Faghri, F., Schoenholz, S.S., Raghu, M., Wattenberg, M., Goodfellow, I., Adversarial spheres (2018) ArXiv Preprint ArXiv:1801.02774; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2014) ArXiv Preprint ArXiv:1412.6572; Holzinger, A., Interactive machine learning for health informatics: When do we need the human-in-the- loop (2016) Brain Informatics, 3 (2), pp. 119-131; Koh, P.W., Liang, P., Understanding black- box predictions via influence functions (2017) International Conference on Machine Learning, pp. 1689-1698; Kumar, A., Mehta, S., Vijaykeerthy, D., An introduction to adversarial machine learning (2017) International Conference on Big Data Analytics, pp. 293-299. , Springer; Lamport, L., Shostak, R., Pease, M., The byzantine generals problem (1982) ACM Transactions on Programming Languages and Systems (TOPLAS), 4 (3), pp. 382-401; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), pp. 436-444; Li, M., Andersen, D.G., Park, J.W., Smola, A.J., Ahmed, A., Josifovski, V., Long, J., Su, B.-Y., Scaling distributed machine learning with the parameter server (2014) OSDI, 1, p. 3; Li, M., Andersen, D.G., Smola, A.J., Yu, K., Communication efficient distributed machine learning with the parameter server (2014) Advances in Neural Information Processing Systems, pp. 19-27; Reddi, S.J., Zaheer, M., Sra, S., Poczos, B., Bach, F., Salakhutdinov, R., Smola, A.J., A generic approach for escaping saddle points (2017) ArXiv Preprint ArXiv:1709.01434; Rousseeuw, P.J., Multivariate estimation with high breakdown point (1985) Mathematical Statistics and Applications, 8, pp. 283-297; Su, L., Defending distributed systems against adversarial attacks: Consensus, consensus-based learning, and statistical learning (2017) PhD Thesis, , University of Illinois at Urbana-Champaign; Zhang, S., Choromanska, A.E., LeCun, Y., Deep learning with elastic averaging sgd (2015) Advances in Neural Information Processing Systems, pp. 685-693","El Mhamdi, E.M.; EPFLSwitzerland; email: elmahdi.elmhamdi@epfl.ch","Dy J.Krause A.",,"International Machine Learning Society (IMLS)","35th International Conference on Machine Learning, ICML 2018","10 July 2018 through 15 July 2018",,141700,,9781510867963,,,"English","Int. Conf. Mach. Learn., ICML",Conference Paper,"Final","",Scopus,2-s2.0-85057247992
"Jiang J., Li B., Yu M., Liu C., Sun J., Huang W., Lv Z.","55731810500;56129960300;56438359400;56938528500;56683220200;56419055500;56438815200;","Advrefactor: A resampling-based defense against adversarial attacks",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11165 LNCS",,,"815","825",,1,"10.1007/978-3-030-00767-6_75","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057219348&doi=10.1007%2f978-3-030-00767-6_75&partnerID=40&md5=f651f1843106f7814f2eeaa448eba3e9","Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; School of Computer Science and Technology, Harbin Engineering University, Harbin, China","Jiang, J., Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Li, B., Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China, School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; Yu, M., Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China, School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; Liu, C., Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Sun, J., School of Computer Science and Technology, Harbin Engineering University, Harbin, China; Huang, W., Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Lv, Z., Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China","Deep neural networks have achieved great success in many domains. However, they are vulnerable to adversarial attacks, which generate adversarial examples by adding tiny perturbations to legitimate images. Previous studies providing defense mostly focus on modifying DNN models to mitigate adversarial attacks. We propose a resampling-based defense, AdvRefactor, which aims at transforming the inputs of models, and thereby eliminates the adversarial perturbations. We explore two resampling algorithms, proximal interpolation and bilinear interpolation, which cost less, suit more models and are combinable with other defenses. Our evaluation results demonstrate that AdvRefactor can significantly mitigate the adversarial attacks. © Springer Nature Switzerland AG 2018.","Adversarial examples; Deep neural networks; Defense against adversarial attacks; Image recognition; Resampling","Image recognition; Interpolation; Network security; Adversarial examples; Bilinear interpolation; Defense against adversarial attacks; Evaluation results; Resampling; Resampling algorithms; Deep neural networks",,,,,"Akhtar, N., Mian, A., (2018) Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey, , arXiv preprint arXiv; Carlini, N., Wagner, D., (2016) Defensive Distillation is Not Robust to Adversarial Examples, , arXiv preprint arXiv; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP), pp. 39-57. , pp., IEEE; Evtimov, I., (2017) Robust Physical-World Attacks on Deep Learning Models, , arXiv preprint arXiv; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations (ICLR; Gu, S., Rigazio, L., (2014) Towards Deep Neural Network Architectures Robust to Adversarial Examples, , arXiv preprint arXiv; He, K., Zhang, X., Ren, S., Sun, J., Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification (2015) Proceedings of the IEEE International Conference on Computer Vision, pp. 1026-1034. , pp; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778. , pp; Jain, A.K., (1989) Fundamentals of Digital Image Processing, , Prentice Hall, Englewood Cliffs; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2015) International Conference on Learning Representations (ICLR) Workshop; Moosavi Dezfooli, S.M., Fawzi, A., Frossard, P., DeepFool: A simple and accurate method to fool deep neural networks (2016) Proceedings of 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Osadchy, M., Hernandez-Castro, J., Gibson, S., Dunkelman, O., Pérez-Cabo, D., No bot expects the deepcaptcha! (2017) IEEE Trans. Inf. Forensics Secur., 12 (11), pp. 2640-2653; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) 2016 IEEE European Symposium on Security and Privacy (EuroS&P), Pp. 372–387. IEEE; Papernot, N., McDaniel, P., Sinha, A., Wellman, M., (2016) Towards the Science of Security and Privacy in Machine Learning, , arXiv preprint arXiv; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) 2016 IEEE Symposium on Security and Privacy (SP), pp. 582-597. , pp., IEEE; Rauber, J., Brendel, W., Bethge, M., (2017) Foolbox: A Python Toolbox to Benchmark the Robustness of Machine Learning Models, , arXiv preprint arXiv; Russakovsky, O., ImageNet large scale visual recognition challenge (2015) Int. J. Comput. Vis. (IJCV), 115 (3), pp. 211-252. , https://doi.org/10.1007/s11263-015-0816-y; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540. , pp., ACM; Su, J., Vargas, D.V., Kouichi, S., (2017) One Pixel Attack for Fooling Deep Neural Networks, , arXiv preprint arXiv; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations (ICLR","Yu, M.; Institute of Information Engineering, China; email: yumin@iie.ac.cn","Cheng W.-H.Yamasaki T.Ngo C.-W.Hong R.Wang M.",,"Springer Verlag","19th Pacific-Rim Conference on Multimedia, PCM 2018","21 September 2018 through 22 September 2018",,218709,03029743,9783030007669,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","",Scopus,2-s2.0-85057219348
"Tessaro S., Thiruvengadam A.","13405791300;55599163600;","Provable time-memory trade-offs: Symmetric cryptography against memory-bounded adversaries",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11239 LNCS",,,"3","32",,8,"10.1007/978-3-030-03807-6_1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057110677&doi=10.1007%2f978-3-030-03807-6_1&partnerID=40&md5=6b3ca8f8ba5dd62d265655c762baeb8d","University of California, Santa Barbara, United States","Tessaro, S., University of California, Santa Barbara, United States; Thiruvengadam, A., University of California, Santa Barbara, United States","We initiate the study of symmetric encryption in a regime where the memory of the adversary is bounded. For a block cipher with n-bit blocks, we present modes of operation for encryption and authentication that guarantee security beyond 2n encrypted/authenticated messages, as long as (1) the adversary’s memory is restricted to be less than 2n bits, and (2) the key of the block cipher is long enough to mitigate memory-less key-search attacks. This is the first proposal of a setting which allows to bypass the 2n barrier under a reasonable assumption on the adversarial resources. Motivated by the above, we also discuss the problem of stretching the key of a block cipher in the setting where the memory of the adversary is bounded. We show a tight equivalence between the security of double encryption in the ideal-cipher model and the hardness of a special case of the element distinctness problem, which we call the list-disjointness problem. Our result in particular implies a conditional lower bound on time-memory trade-offs to break PRP security of double encryption, assuming optimality of the worst-case complexity of existing algorithms for list disjointness. © International Association for Cryptologic Research 2018.","Foundations; Randomness extraction; Symmetric cryptography","Authentication; Commerce; Computational complexity; Foundations; Public key cryptography; Disjointness problems; Ideal-cipher model; Modes of operation; Randomness extractions; Symmetric cryptography; Symmetric encryption; Time-memory trade-offs; Worst-case complexity; Economic and social effects",,,,,"Aiello, W., Bellare, M., Di Crescenzo, G., Venkatesan, R., Security amplification by composition: The case of doubly-iterated, ideal ciphers (1998) CRYPTO 1998. LNCS, 1462, pp. 390-407. , https://doi.org/10.1007/BFb0055743, Krawczyk, H. (ed.), Springer, Heidelberg; Ajtai, M., A non-linear time lower bound for boolean branching programs (2005) Theory Comput, 1 (8), pp. 149-176; Alwen, J., Blocki, J., Pietrzak, K., (2017) Depth-Robust Graphs and Their Cumulative Memory Complexity, pp. 3-32. , Coron and Nielsen [18]; Alwen, J., Chen, B., Pietrzak, K., Reyzin, L., Tessaro, S., Scrypt is maximally memory-hard (2017) Coron and Nielsen, (18), pp. 33-62; Alwen, J., Dodis, Y., Wichs, D., Leakage-resilient public-key cryptography in the bounded-retrieval model (2009) CRYPTO 2009. LNCS, 5677, pp. 36-54. , https://doi.org/10.1007/978-3-642-03356-83, Halevi, S. (ed.), Springer, Heidelberg; Alwen, J., Serbinenko, V., High parallel complexity graphs and memory-hard functions (2015) 47Th ACM STOC, pp. 595-603. , Servedio, R.A., Rubinfeld, R. (eds.), Portland, OR, USA, 14–17 June 2015, ACM Press; Auerbach, B., Cash, D., Fersch, M., Kiltz, E., Memory-tight reductions (2017) CRYPTO 2017. LNCS, 10401, pp. 101-132. , https://doi.org/10.1007/978-3-319-63688-74, Katz, J., Shacham, H. (eds.), Springer, Cham; Beame, P., Clifford, R., Machmouchi, W., Element distinctness, frequency moments, and sliding windows (2013) 54Th FOCS, pp. 290-299. , Berkeley, CA, USA, 26–29 October 2013, IEEE Computer Society Press; Beame, P., Saks, M., Sun, X., Vee, E., Time-space trade-off lower bounds for randomized computation of decision problems (2003) J. ACM, 50 (2), pp. 154-195; Beame, P., Saks, M.E., Sun, X., Vee, E., Time-space trade-off lower bounds for randomized computation of decision problems (2003) J. ACM, 50 (2), pp. 154-195; Bellare, M., Dai, W., (2017) Defending against Key Exfiltration: Efficiency Improvements for Big-Key Cryptography via Large-Alphabet Subkey Prediction, pp. 923-940. , Thuraisingham, B.M., Evans, D., Malkin, T., Xu, D. (eds.)ACM CCS 17, Dallas, TX, USA, 31 October-2 November 2017, ACM Press; Bellare, M., Desai, A., Jokipii, E., Rogaway, P., (1997) A Concrete Security Treatment of Symmetric Encryption, pp. 394-403. , 38th FOCS, Miami Beach, Florida, 19–22 October 1997, IEEE Computer Society Press; Bellare, M., Goldreich, O., Krawczyk, H., Stateless evaluation of pseudorandom functions: Security beyond the birthday barrier (1999) CRYPTO 1999. LNCS, 1666, pp. 270-287. , https://doi.org/10.1007/3-540-48405-117, Wiener, M. (ed.), Springer, Heidelberg; Bellare, M., Kane, D., Rogaway, P., Big-key symmetric encryption: Resisting key exfiltration (2016) CRYPTO 2016. LNCS, 9814, pp. 373-402. , https://doi.org/10.1007/978-3-662-53018-414, Robshaw, M., Katz, J. (eds.), Springer, Heidelberg; Bellare, M., Rogaway, P., The security of triple encryption and a framework for code-based game-playing proofs (2006) EUROCRYPT 2006. LNCS, 4004, pp. 409-426. , https://doi.org/10.1007/1176167925, Vaudenay, S. (ed.); Bogdanov, A., Papakonstantinou, P.A., Wan, A., Pseudorandomness for linear length branching programs and stack machines (2012) APPROX/RANDOM-2012. LNCS, 7408, pp. 447-458. , https://doi.org/10.1007/978-3-642-32512-038, Gupta, A., Jansen, K., Rolim, J., Servedio, R. (eds.), Springer, Heidelberg; Borodin, A., Fischer, M.J., Kirkpatrick, D.G., Lynch, N.A., Tompa, M., A time-space tradeoff for sorting on non-oblivious machines (1981) J. Comput. Syst. Sci., 22 (3), pp. 351-364; Coron, J.-S., Nielsen, J.B., (2017) EUROCRYPT 2017. LNCS, 10211. , (eds.), Springer, Heidelberg; Dodis, Y., Ostrovsky, R., Reyzin, L., Smith, A.D., Fuzzy extractors: How to generate strong keys from biometrics and other noisy data (2008) SIAM J. Comput., 38 (1), pp. 97-139; Garg, S., Raz, R., Tal, A., Extractor-based time-space lower bounds for learning (2017) Corr, , abs/1708.02639; Gaži, P., Plain versus randomized cascading-based key-length extension for block ciphers (2013) CRYPTO 2013. LNCS, 8042, pp. 551-570. , https://doi.org/10.1007/978-3-642-40041-430, Canetti, R., Garay, J.A. (eds.), Springer, Heidelberg; Gaži, P., Lee, J., Seurin, Y., Steinberger, J., Tessaro, S., Relaxing full-codebook security: A refined analysis of key-length extension schemes FSE 2015. LNCS, 9054, pp. 319-341. , https://doi.org/10.1007/978-3-662-48116-516, Leander, G. (ed.), Springer, Heidelberg (2015); Gaži, P., Maurer, U., Cascade encryption revisited (2009) ASI-ACRYPT 2009. LNCS, 5912, pp. 37-51. , https://doi.org/10.1007/978-3-642-10366-73, Matsui, M. (ed.), Springer, Heidelberg; Gaži, P., Tessaro, S., Efficient and optimally secure key-length extension for block ciphers via randomized cascading (2012) EURO-CRYPT 2012. LNCS, 7237, pp. 63-80. , https://doi.org/10.1007/978-3-642-29011-46, Pointcheval, D., Johansson, T. (eds.), Springer, Heidelberg; Håstad, J., Impagliazzo, R., Levin, L.A., Luby, M., A pseudorandom generator from any one-way function (1999) SIAM J. Comput., 28 (4), pp. 1364-1396; Hoang, V.T., Tessaro, S., Key-alternating ciphers and key-length extension: Exact bounds and multi-user security (2016) Robshaw and Katz, 34, pp. 3-32; Impagliazzo, R., Meka, R., Zuckerman, D., (2012) Pseudorandomness from Shrinkage, pp. 111-119. , 53rd FOCS, New Brunswick, NJ, USA, 20–23 October 2012, IEEE Computer Society Press; Lee, J., Towards key-length extension with optimal security: Cascade encryption and Xor-cascade encryption (2013) EUROCRYPT 2013. LNCS, 7881, pp. 405-425. , https://doi.org/10.1007/978-3-642-38348-925, Johansson, T., Nguyen, P.Q. (eds.), Springer, Heidelberg; Nisan, N., Pseudorandom generators for space-bounded computation (1992) Combina-Torica, 12 (4), pp. 449-461; Nisan, N., Zuckerman, D., Randomness is linear in space (1996) J. Comput. Syst. Sci., 52 (1), pp. 43-52; Pollard, J.M., A monte carlo method for factorization (1975) BIT Numer. Math., 15 (3), pp. 331-334; Raz, R., Fast learning requires good memory: A time-space lower bound for parity learning (2016) <ref-sourcetitle type=""edbook""></ref-sourcetitle>, pp. 266-275. , Dinur, I. (ed.)57th FOCS, New Brunswick, NJ, USA, 9–11 October 2016, IEEE Computer Society Press; Raz, R., A time-space lower bound for a large class of learning problems (2017) 58Th FOCS, pp. 732-742. , IEEE Computer Society Press; Robshaw, M., Katz, J., Advances in Cryptology – CRYPTO 2016, Part I (2016) LNCS, 9814. , https://doi.org/10.1007/978-3-662-53018-4, (eds.), Springer, Heidelberg; Savage, J.E., (1997) Models of Computation: Exploring the Power of Computing, , 1st edn. Addison-Wesley Longman Publishing Co. Inc., Boston; Vadhan, S.P., Constructing locally computable extractors and cryptosystems in the bounded-storage model (2004) J. Cryptol., 17 (1), pp. 43-77; Vadhan, S.P., Pseudorandomness (2012) Found. Trends Theoret. Comput. Sci., 7 (1-3), pp. 1-336; van Oorschot, P.C., Wiener, M.J., Parallel collision search with cryptanalytic applications (1999) J. Cryptol., 12 (1), pp. 1-28; Yao, A.C., Near-optimal time-space tradeoff for element distinctness (1988) 29Th FOCS, pp. 91-97. , White Plains, New York, 24–26 October 1988, IEEE Computer Society Press; Yao, A.C., Near-optimal time-space tradeoff for element distinctness (1994) SIAM J. Comput., 23 (5), pp. 966-975","Tessaro, S.; University of CaliforniaUnited States; email: tessaro@cs.ucsb.edu","Beimel A.Dziembowski S.",,"Springer Verlag","16th Theory of Cryptography Conference, TCC 2018","11 November 2018 through 14 November 2018",,220799,03029743,9783030038069,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","",Scopus,2-s2.0-85057110677
"Yuan X., Chen Y., Zhao Y., Long Y., Liu X., Chen K., Zhang S., Huang H., Wang X.F., Gunter C.A.","57207999560;57203863043;57190429329;57213443811;57195527096;57051675000;34972484500;55865339600;56417470400;26643555100;","CommanderSong: A systematic approach for practical adversarial voice recognition",2018,"Proceedings of the 27th USENIX Security Symposium",,,,"49","64",,116,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056767269&partnerID=40&md5=532142e76885fb1aaeed9b91388b0d04","SKLOIS, Institute of Information Engineering, Chinese Academy of Sciences, China; School of Cyber Security, University of Chinese Academy of Sciences, China; Department of Computer Science, Florida Institute of Technology, United States; Department of Computer Science, University of Illinois, Urbana-Champaign, United States; Department of Computer Science, Metropolitan College, Boston University, United States; School of Informatics and Computing, Indiana University, Bloomington, United States","Yuan, X., SKLOIS, Institute of Information Engineering, Chinese Academy of Sciences, China, School of Cyber Security, University of Chinese Academy of Sciences, China; Chen, Y., Department of Computer Science, Florida Institute of Technology, United States; Zhao, Y., SKLOIS, Institute of Information Engineering, Chinese Academy of Sciences, China, School of Cyber Security, University of Chinese Academy of Sciences, China; Long, Y., Department of Computer Science, University of Illinois, Urbana-Champaign, United States; Liu, X., SKLOIS, Institute of Information Engineering, Chinese Academy of Sciences, China, School of Cyber Security, University of Chinese Academy of Sciences, China; Chen, K., SKLOIS, Institute of Information Engineering, Chinese Academy of Sciences, China, School of Cyber Security, University of Chinese Academy of Sciences, China; Zhang, S., Department of Computer Science, Florida Institute of Technology, United States, Department of Computer Science, Metropolitan College, Boston University, United States; Huang, H., SKLOIS, Institute of Information Engineering, Chinese Academy of Sciences, China; Wang, X.F., School of Informatics and Computing, Indiana University, Bloomington, United States; Gunter, C.A., Department of Computer Science, University of Illinois, Urbana-Champaign, United States","The popularity of automatic speech recognition (ASR) systems, like Google Assistant, Cortana, brings in security concerns, as demonstrated by recent attacks. The impacts of such threats, however, are less clear, since they are either less stealthy (producing noise-like voice commands) or requiring the physical presence of an attack device (using ultrasound speakers or transducers). In this paper, we demonstrate that not only are more practical and surreptitious attacks feasible but they can even be automatically constructed. Specifically, we find that the voice commands can be stealthily embedded into songs, which, when played, can effectively control the target system through ASR without being noticed. For this purpose, we developed novel techniques that address a key technical challenge: integrating the commands into a song in a way that can be effectively recognized by ASR through the air, in the presence of background noise, while not being detected by a human listener. Our research shows that this can be done automatically against real world ASR applications1. We also demonstrate that such CommanderSongs can be spread through Internet (e.g., YouTube) and radio, potentially affecting millions of ASR users. Finally we present mitigation techniques that defend existing ASR systems against such threat. © 2018 Proceedings of the 27th USENIX Security Symposium. All rights reserved.",,"Automatic speech recognition system; Background noise; Human listeners; Mitigation techniques; Novel techniques; Target systems; Technical challenges; Voice command; Speech recognition",,,,,"Amazon Alexa, , https://developer.amazon.com/alexa; Amazon Mechanical Turk, , https://www.mturk.com; Apple Siri, , https://www.apple.com/ios/siri; Aspire, , https://github.com/kaldi-asr/kaldi/tree/master/egs/aspire; CMUSphinx, , https://cmusphinx.github.io/; Google Assistant, , https://assistant.google.com; Google Text-to-speech, , https://play.google.com/store/apps; HackRF One, , https://greatscottgadgets.com/hackrf/; http://htk.eng.cam.ac.uk/; https://www.iflyrec.com/; http://www.iflytek.com/en/index.html; IFLYTEK Input, , http://www.iflytek.com/en/mobile/iflyime.html; http://kaldi-asr.org; https://www.microsoft.com/en-us/cortana; Number of Monthly Active WeChat Users from 2nd Quarter 2010 to 2nd Quarter 2017 (in Millions), , https://www.statista.com/statistics/255778/number-of-active-wechat-messenger-accounts/; SENMATE Broadcast, , http://www.114pifa.com/p106/34376.html; Amodei, D., Ananthanarayanan, S., Anubhai, R., Bai, J., Battenberg, E., Case, C., Casper, J., Chen, G., Deep speech 2: End-to-end speech recognition in English and Mandarin (2016) International Conference on Machine Learning, pp. 173-182; Audhkhasi, K., Kingsbury, B., Ramabhadran, B., Saon, G., Picheny, M., Building competitive direct acoustics-to-word models for English conversational speech recognition (2018) IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP); Bao, W., Li, H., Li, N., Jiang, W., A liveness detection method for face recognition based on optical flow field (2009) Image Analysis and Signal Processing, 2009, pp. 233-236. , IASP 2009. International Conference on IEEE; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndić, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 387-402. , Springer; Brown, T.B., Mané, D., Roy, A., Abadi, M., Gilmer, J., Adversarial patch (2017) 31st Conference on Neural Information Processing Systems (NIPS); Carlini, N., Mishra, P., Vaidya, T., Zhang, Y., Sherr, M., Shields, C., Wagner, D., Zhou, W., Hidden voice commands (2016) USENIX Security Symposium, pp. 513-530; Carlini, N., Wagner, D., Audio adversarial examples: Targeted attacks on speech-to-text (2018) Deep Learning and Security Workshop; Collobert, R., Puhrsch, C., Synnaeve, G., (2016) Wav2letter: An End-to-end Convnet-based Speech Recognition System; Dalvi, N., Domingos, P., Sanghai, S., Verma, D., Adversarial classification (2004) Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 99-108; Diao, W., Liu, X., Zhou, Z., Zhang, K., Your voice assistant is mine: How to abuse speakers to steal information and control your phone (2014) Proceedings of the 4th ACM Workshop on Security and Privacy in Smartphones & Mobile Devices, pp. 63-74; Evtimov, I., Eykholt, K., Fernandes, E., Kohno, T., Li, B., Prakash, A., Rahmati, A., Song, D., Robust physical-world attacks on deep learning models (2018) Computer Vision and Pattern Recognition; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations; He, W., Wei, J., Chen, X., Carlini, N., Song, D., Adversarial example defenses: Ensembles of weak defenses are not strong (2017) USENIX Workshop on Offensive Technologies; Hermansky, H., Perceptual linear predictive (plp) analysis of speech (1990) The Journal of the Acoustical Society of America, 87 (4), pp. 1738-1752; Hinton, G., Deng, L., Yu, D., Dahl, G.E., Mohamed, A.-R., Jaitly, N., Senior, A., Sainath, T.N., Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups (2012) IEEE Signal Processing Magazine, 29 (6), pp. 82-97; Hinton, G., Deng, L., Yu, D., Dahl, G.E., Mohamed, A.-R., Jaitly, N., Senior, A., Sainath, T.N., Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups (2012) IEEE Signal Processing Magazine, 29 (6), pp. 82-97; Hinton, G., Vinyals, O., Dean, J., Distilling the knowledge in a neural network (2014) NIPS Deep Learning Workshop; Itakura, F., Line spectrum representation of linear predictor coefficients of speech signals (1975) The Journal of the Acoustical Society of America, 57 (S1), p. S35; Kasmi, C., Esteves, J.L., Iemi threats for information security: Remote command injection on modern smartphones (2015) IEEE Transactions on Electromagnetic Compatibility, 57 (6), pp. 1752-1755; Kune, D.F., Backes, J., Clark, S.S., Kramer, D., Reynolds, M., Fu, K., Kim, Y., Xu, W., Ghost talk: Mitigating EMI signal injection attacks against analog sensors (2013) Security and Privacy (SP), 2013 IEEE Symposium on, pp. 145-159; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint; Li, P., Liu, Q., Zhao, W., Wang, D., Wang, S., (2018) BEBP: An Poisoning Method against Machine Learning Based Idss, , arXiv preprint; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) International Conference on Learning Representations; Muda, L., Begam, M., Elamvazuthi, I., Voice recognition algorithms using mel frequency cepstral coefficient (mfcc) and dynamic time warping (dtw) techniques (2010) Journal of Computing, 2 (3); Mukhopadhyay, D., Shirvanian, M., Saxena, N., All your voices are belong to us: Stealing voices to fool humans and machines (2015) European Symposium on Research in Computer Security, pp. 599-621. , Springer; O'Shaughnessy, D., Automatic speech recognition: History, methods and challenges (2008) Pattern Recognition, 41 (10), pp. 2965-2979; Papernot, N., Carlini, N., Goodfellow, I., Feinman, R., Faghri, F., Matyasko, A., Hambardzumyan, K., Sheatsley, R., (2016) Cleverhans V2. 0.0: An Adversarial Machine Learning Library; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples, , arXiv preprint; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519; Pirie, W., Spearman rank correlation coefficient (1988) Encyclopedia of Statistical Sciences; Rao, K., Sak, H., Prabhavalkar, R., Exploring architectures, data and units for streaming end-to-end speech recognition with rnn-transducer (2017) Automatic Speech Recognition and Understanding Workshop (ASRU), 2017 IEEE, pp. 193-199; Schuckers, S.A.C., Spoofing and anti-spoofing measures (2002) Information Security Technical Report, 7 (4), pp. 56-62; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint; Tronci, R., Muntoni, D., Fadda, G., Pili, M., Sirena, N., Murgia, G., Ristori, M., Roli, F., Fusion of multiple clues for photo-attack detection in face recognition systems (2011) Biometrics (IJCB), 2011 International Joint Conference on, pp. 1-6; Vaidya, T., Zhang, Y., Sherr, M., Shields, C., Cocaine noodles: Exploiting the gap between human and machine speech recognition (2015) WOOT, 15, pp. 10-11; Xiong, W., Droppo, J., Huang, X., Seide, F., Seltzer, M., Stolcke, A., Yu, D., Zweig, G., The microsoft 2016 conversational speech recognition system (2017) Acoustics, Speech and Signal Processing (ICASSP), 2017 IEEE International Conference on, pp. 5255-5259; Zhang, G., Yan, C., Ji, X., Zhang, T., Zhang, T., Xu, W., Dolphinattack: Inaudible voice commands (2017) Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pp. 103-117","Chen, K.; SKLOIS, China; email: chenkai@iie.ac.cn",,"Baidu;Dropbox;Facebook;Google;NSF;The USENIX Association","USENIX Association","27th USENIX Security Symposium","15 August 2018 through 17 August 2018",,155142,,9781939133045,,,"English","Proc. USENIX Secur. Symp.",Conference Paper,"Final","",Scopus,2-s2.0-85056767269
"Ke Y., Liu J., Zhang M.-Q., Su T.-T., Yang X.-Y.","57196775031;57193393252;10439335900;35276203000;35194813400;","Steganography Security: Principle and Practice",2018,"IEEE Access","6",,"8537887","73009","73022",,15,"10.1109/ACCESS.2018.2881680","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056735102&doi=10.1109%2fACCESS.2018.2881680&partnerID=40&md5=851f22fc5624782e3348ad55587ecb15","Key Laboratory of Network and Information Security under the Chinese People Armed Police Force (PAP), College of Cryptography Engineering in Engineering University of PAP, Xi'an, 710086, China","Ke, Y., Key Laboratory of Network and Information Security under the Chinese People Armed Police Force (PAP), College of Cryptography Engineering in Engineering University of PAP, Xi'an, 710086, China; Liu, J., Key Laboratory of Network and Information Security under the Chinese People Armed Police Force (PAP), College of Cryptography Engineering in Engineering University of PAP, Xi'an, 710086, China; Zhang, M.-Q., Key Laboratory of Network and Information Security under the Chinese People Armed Police Force (PAP), College of Cryptography Engineering in Engineering University of PAP, Xi'an, 710086, China; Su, T.-T., Key Laboratory of Network and Information Security under the Chinese People Armed Police Force (PAP), College of Cryptography Engineering in Engineering University of PAP, Xi'an, 710086, China; Yang, X.-Y., Key Laboratory of Network and Information Security under the Chinese People Armed Police Force (PAP), College of Cryptography Engineering in Engineering University of PAP, Xi'an, 710086, China","This paper focuses on several theoretical issues and principles in steganography security, and defines four security levels by analyzing the corresponding algorithm instances. In the theoretical analysis, we discuss the differences between steganography security and watermarking security. The two necessary conditions for the steganography security are obtained. Under the current technology situation, we then analyze the indistinguishability of the cover and stego-cover, and consider that the steganography security should rely on the key secrecy with algorithms open. By specifying the role of key in steganography, the necessary conditions for a secure steganography algorithm in theory are formally presented. When analyzing the security instances, we have classified the steganalysis attacks according to their variable access to the steganography system, and then defined the four security levels. The higher level security one has, the higher level attacks one can resist. We have also presented algorithm instances based on current technical conditions, and analyzed their data hiding process, security level, and practice requirements. © 2013 IEEE.","generative adversarial networks; Kerckhoofs' principle; reversible data hiding in encrypted domain; steganalysis attacks; Steganography security","Computational complexity; Cryptography; Data structures; Digital watermarking; Steganography; Adversarial networks; Classification algorithm; Complexity theory; Computational model; Reversible data hiding; Steganalysis attacks; Network security",,,,,"Simmons, G.J., The prisoners' problem and the subliminal channel (1984) Proc. Adv. Cryptol. (Crypto), pp. 51-67. , New York, NY, USA: Plenum; Kalker, T., Considerations on watermarking security (2001) Proc. IEEE 4th Workshop Multimedia Signal Process., pp. 201-206. , Cannes, France, Oct; Fridrich, J., (2013) Steganography in Digital Media: Principles, Algorithms, and Applications, , Cambridge, U.K.: Cambridge Univ. Press; Cachin, C., An information-theoretic model for steganography (1998) Information Hiding (Lecture Notes in Computer Science), 1525, pp. 306-318. , D. Ancsmith, Ed. New York, NY, USA: Springer-Verlag; Pevný, T., Fridrich, J., Benchmarking for steganography (2008) Proc. Int. Workshop Inf. Hiding, , Berlin, Germany: Springer; Cayre, F., Basm, P., Kerckhoffs-based embedding security classes for WOA data hiding (2008) IEEE Trans. Inf. Forensics Security, 3 (1), pp. 1-15. , Mar; Bahi, J.M., Guyeux, C., Heam, P.-C., (2017) A Cryptographic Approach for Steganography., , https://arxiv.org/abs/1706.08752, Jun; Huynh-Thu, Q., Garcia, M.-N., Speranza, F., Corriveau, P., Raake, A., Study of rating scales for subjective quality assessment of high-definition video (2011) IEEE Trans. Broadcast., 57 (1), pp. 1-14. , Mar; Goodfellow, I., Generative adversarial nets (2014) Proc. Adv. Neural Inf. Process. Syst., pp. 2672-2680; Hopper, N.J., Langford, J., Von Ahn, L., Provably secure steganography (2002) Advances in Cryptology-CRYPTO (Lecture Notes in Computer Science), 2442, pp. 77-92. , M. Yung, Ed. Santa Barbare, CA, USA: Springer-Verlag; Katzenbeisser, S., Petitcolas, F.A.P., Defining security in steganographic systems (2002) Proc. SPIE, 4675, pp. 50-55. , Apr; Moulin, P., O'Sullivan, J.A., Information-theoretic analysis of information hiding (2003) IEEE Trans. Inf. Theory, 49 (3), pp. 563-593. , Mar; Filler, T., Judas, J., Fridrich, J., Minimizing additive distortion in steganography using syndrome-trellis codes (2011) IEEE Trans. Inf. Forensics Security, 6 (3), pp. 920-935. , Sep; Pevný, T., Filler, T., Bas, P., Using high-dimensional image models to perform highly undetectable steganography (2010) Information Hiding, pp. 161-177. , Berlin, Germany: Springer; Holub, V., Fridrich, J., Designing steganographic distortion using directional filters (2012) Proc. IEEE Int. Workshop Inf. Forensics Secur. (WIFS), pp. 234-239. , Dec; Fridrich, J., Kodovský, J., Multivariate Gaussian model for designing additive distortion for steganography (2013) Proc. ICASSP, pp. 2949-2953. , May; Guo, L., Ni, J., Shi, Y.Q., Uniform embedding for Effecient JPEG steganography (2014) IEEE Trans. Inf. Forensics Security, 9 (5), pp. 814-825. , May; Qian, Y., Dong, J., Wang, W., Tan, T., Learning and transferring representations for image steganalysis using convolutional neural network (2016) Proc. IEEE Int. Conf. Image Process., pp. 2752-2756. , Sep; Xu, G., Wu, H.-Z., Shi, Y.-Q., Structural design of convolutional neural networks for steganalysis (2016) IEEE Signal Process. Lett., 23 (5), pp. 708-712. , May; Wang, S., Sang, J., Song, X., Niua, X., Least significant qubit (LSQb) information hiding algorithm for quantum image (2015) Measurement, 73, pp. 352-359. , Sep; Jiang, N., Zhao, N., Wang, L., LSB based quantum image steganography algorithm (2016) Int. J. Theor. Phys., 55 (1), pp. 107-123; Luo, X., Steganalysis of HUGO steganography based on parameter recognition of syndrome-trellis-codes (2016) Multimedia Tools Appl., 75 (21), pp. 13557-13583; Kerckhoffs, A., La cryptographie militaire (1883) J. Sci. Militaires, 9, pp. 5-191. , Jan./Feb; Furon, T., (2002) Security Analysis, European Project IST-1999-10987 CERTIMARK, , Deliverable D.5.5; Cayre, F., Fontaine, C., Furon, T., Watermarking security: Theory and practice (2005) IEEE Trans. Signal Process., 53 (10), pp. 3976-3987. , Oct; Filler, T., Ker, A.D., Fridrich, J., The square root law of steganographic capacity for Markov covers (2009) Proc. SPIE, 7254, p. 725408. , Feb; Backes, M., Cachin, C., Public-key steganography with active attacks (2005) Theory of Cryptography (Lecture Notes in Computer Science), 3378, pp. 210-226. , J. Kilian, Ed. Cambridge, MA, USA: Springer-Verlag; Comesaña, P., Pérez-Freire, L., Pérez-González, F., Fundamentals of data hiding security and their application to spread-spectrum analysis (2005) Information Hiding (Lecture Notes in Computer Science), 3727, pp. 146-160. , Berlin, Germany: Springer-Verlag; Wang, Y.-G., Zhu, G., Kwong, S., Shi, Y.-Q., A study on the security levels of spread-spectrum embedding schemes in the WOA framework (2018) IEEE Trans. Cybern., 48 (8), pp. 2307-2320. , Aug; Ker, A.D., Batch steganography and pooled steganalysis (2006) Informa-tion Hiding (Lecture Notes in Computer Science), pp. 265-281. , New York, NY, USA: Springer-Verlag; Nash, J., Non-cooperative games (1951) Ann. Math., 54 (2), pp. 286-295; Schöettle, P., Laszka, A., Johnson, B., Grossklags, J., Böhme, R., A game-theoretic analysis of content-adaptive steganography with independent embedding (2013) Proc. 21st Eur. Signal Process. Conf., pp. 1-5. , Sep; Zheng, S., Wang, L., Ling, B., Hu, D., Coverless information hiding based on robust image hashing (2017) Proc. Int. Conf. Intell. Comput. (ICIC), pp. 536-547. , Liverpool, U.K., Aug; Ke, Y., Zhang, M., Liu, J., Su, T., Yang, X., (2018) Generative Steganography with Kerckhoffs' Principle Based on Generative Adversarial Networks., , https://arxiv.org/abs/1711.04916; Yeh, R.A., Chen, C., Lim, T.Y., Schwing, A.G., Hasegawa-Johnson, M., Do, M.N., (2017) Semantic Image Inpainting with Deep Generative Models., , https://arxiv.org/abs/1607.07539; Radford, A., Metz, L., Chintala, S., (2016) Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks., , https://arxiv.org/abs/1511.06434; Gatys, L.A., Ecker, A.S., Bethge, M., (2015) Texture Synthesis Using Convolutional Neural Networks., , https://arxiv.org/abs/1505.07376; Pevný, T., Bas, P., Fridrich, J., Steganalysis by subtractive pixel adjacency matrix (2010) IEEE Trans. Inf. Forensics Security, 5 (2), pp. 215-224. , Jun; Denemark, T., Fridrich, J., Holub, V., Further study on the security of S-UNIWARD (2014) Proc. SPIE, 9028, pp. 902805-902813. , Feb; Kodovsky, J., Fridrich, J., Holub, V., Ensemble classifiers for steganalysis of digital media (2012) IEEE Trans. Inf. Forensics Security, 7 (2), pp. 432-444. , Apr; Ke, Y., Zhang, M.-Q., Liu, J., Su, T.-T., Yang, X.-Y., A multilevel reversible data hiding scheme in encrypted domain based on LWE (2018) J. Vis. Commun. Image Represent., 54, pp. 133-144. , Jul; Wu, H.-T., Cheung, Y.-M., Huang, J., Reversible data hiding in Paillier cryptosystem (2016) J. Vis. Commun. Image Represent., 40, pp. 765-771. , Oct; Paillier, P., Pointcheval, D., Effecient public-key cryptosystems provably secure against active adversaries (1999) Advances in Cryptology-ASIACRYPT (Lecture Notes in Computer Science), 1716, pp. 165-179. , K. Y. Lam, E. Okamoto, and C. Xing, Eds. Berlin, Germany: Springer","Ke, Y.; Key Laboratory of Network and Information Security under the Chinese People Armed Police Force (PAP), China; email: 15114873390@163.com",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85056735102
"Zoto E., Kowalski S., Frantz C., Katt B., Lopez-Rojas E.","57202435903;24756026500;54903301000;25824984500;55913449600;","Cyberaims: A tool for teaching adversarial and systems thinking",2018,"8th International Defense and Homeland Security Simulation Workshop, DHSS 2018",,,,"20","28",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056570249&partnerID=40&md5=4cefc1ea4ea2a8eda375c2adf93dd482","Norwegian University for Science and Technology, NTNU Gjøvik, Norway","Zoto, E., Norwegian University for Science and Technology, NTNU Gjøvik, Norway; Kowalski, S., Norwegian University for Science and Technology, NTNU Gjøvik, Norway; Frantz, C., Norwegian University for Science and Technology, NTNU Gjøvik, Norway; Katt, B., Norwegian University for Science and Technology, NTNU Gjøvik, Norway; Lopez-Rojas, E., Norwegian University for Science and Technology, NTNU Gjøvik, Norway","CyberAIMs stands for Cyber Agents' Interactive Modeling and Simulation. We designed this tool in order to use it as an educational tool to teach Master students in a Cyber security course. This paper aims to describe the model and explain the design choices behind CyberAIMs in terms of associating them with the emerging concepts within cyber security curriculum, namely adversarial and systems thinking. The preliminary results indicate that the current distribution of values and entities allows most of the defense agents to avoid losing all their resources to their attack counterparts. We intend to use this tool as part of a lab with students in Information Security and further extend our target users, by including others who need training in adversarial and systems thinking. We conclude by providing rough results from running simulations with the tool and giving further directions of our future research, in order to improve the usability and level of detail for this tool. © 2018 2018 Dime università di Genova, dimeg university of calabria.","Adversarial Thinking; Agent-Based Simulation; Cyber Security; Systems Thinking; Teaching; Training","National security; Network security; Personnel training; Security systems; Teaching; Adversarial Thinking; Agent based simulation; Current distribution; Cyber security; Educational tools; Interactive modeling; Running simulations; Systems thinking; System theory",,,,,"Ablon, L., Libicki, M.C., Go-Lay, A.A., (2014) Markets for Cybercrime Tools and Stolen Data: Hackers' Bazaar, , Rand Corporation; AlSabbagh, B., Kowalski, S., Socio-technical siem (st-siem): Towards bridging the gap in security incident response (2017) International Journal of Systems and Society (IJSS), 4 (2), pp. 8-21; Anne Bardoel, E., Haslett, T., Success to the successful: The use of systems thinking tools in teaching ob (2004) Organization Management Journal, 1 (2), pp. 112-124; Ben-Asher, N., Gonzalez, C., Cyberwar game: A paradigm for understanding new challenges of cyber war (2015) Cyber Warfare, pp. 207-220. , Springer; Bologna, J., Momm's (motivations, opportunities, methods, means)-A taxonomy for computer related employee theft (1981) Assets Protection, 6 (3), pp. 33-36; Brahima, S., Global cybersecurity index 2017 (2017) International Telecommunication Union (ITU), pp. 1-77; Filkins, B., Hardy, G.M., (2016) It Security Spending Trends. A SANS Survey, , SANS Institute; Goodwin, J.S., Franklin, S.G., The beer distribution game: Using simulation to teach systems thinking (1994) Journal of Management Development, 13 (8), pp. 7-15; Hamman, S.T., Hopkinson, K.M., Markham, R.L., Chaplik, A.M., Metzler, G.E., Teaching game theory to improve adversarial thinking in cybersecurity students (2017) IEEE Transactions on Education, 60 (3), pp. 205-211; (2017) Cybersecurity Curricula 2017 - Curriculum Guidelines for Post-Secondary Degree Programs in Cybersecurity - Csec2017 V. 0.95 Draft, , Cybersecurity Education. Technical report, November; Norman, M.D., Koehler, M.T.K., (2017) Cyber Defense as A Complex Adaptive System: A Model-Based Approach to Strategic Policy Design, , e-prints, June; Pastor, V., Díaz, G., Castro, M., State-of-the-art simulation systems for information security education, training and awareness (2010) Education Engineering (EDUCON), 2010 IEEE, pp. 1907-1916. , IEEE; (2016) Flipping The Economics of Attacks, , Ponemon Institute. Technical report, January; Rogers, M., (2000) A New Hacker Taxonomy, , University of Manitoba; Rogers, R.W., A protection motivation theory of fear appeals and attitude change1 (1975) The Journal of Psychology, 91 (1), pp. 93-114; Rowe, B.R., Pokryshevskiy, I.D., Link, A.N., Reeves, D.S., Economic analysis of an inadequate cyber security technical infrastructure (2013) National Institute of Standards and Technology Planning Report, pp. 13-21; Schneider, F.B., Cybersecurity education in universities (2013) IEEE Security & Privacy, 11 (4), pp. 3-4; Vaishnavi, V., Kuechler, W., (2004) Design Research in Information Systems; Wilensky, U., (1999) Netlogo. Evanston, , il: Center for connected learning and computer-based modeling, northwestern university",,"Bruzzone A.G.Sottilare R.",,"Dime University of Genoa","8th International Defense and Homeland Security Simulation Workshop, DHSS 2018","17 September 2018 through 19 September 2018",,140340,,9788885741133,,,"English","Int. Def. Homel. Secur. Simul. Workshop, DHSS",Conference Paper,"Final","",Scopus,2-s2.0-85056570249
"Worzyk N., Kramer O.","57144662600;34875208500;","Properties of adv-1 - Adversarials of adversarials",2018,"ESANN 2018 - Proceedings, European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning",,,,"19","24",,1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056520931&partnerID=40&md5=59877b6cb61d6bd864430c3abc4f5a23","University of Oldenburg, Dept. of Computing Science, Oldenburg, Germany","Worzyk, N., University of Oldenburg, Dept. of Computing Science, Oldenburg, Germany; Kramer, O., University of Oldenburg, Dept. of Computing Science, Oldenburg, Germany","Neural networks are very successful in the domain of image processing, but they are still vulnerable against adversarial images -carefully crafted images to fool the neural network during image classification. There are already some attacks to create those adversarial images, therefore the transition from original images to adversarial images is well understood. In this paper we apply adversarial attacks on adversarial images. These new images are called adv-1. The goal is to investigate the transition from adversarial images to adv-1 images. This knowledge can be used to 1.) identify adversarial images and 2.) to find the original class of adversarial images. © ESANN 2018 - Proceedings, European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning.",,"Machine learning; Neural networks; Original images; Image processing",,,,,"Szegedy, C., Rethinking the inception architecture for computer vision (2016) IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826; Szegedy, C., (2013) Intriguing Properties of Neural Networks; Evtimov, I., (2017) Robust Physical-world Attacks on Machine Learning Models; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Machine Learning at Scale; Gong, Z., Wang, W., Ku, W.-S., (2017) Adversarial and Clean Data Are Not Twins; Papernot, N., Distillation as a defense to adversarial perturbations against deep neural networks (2016) IEEE Symposium on Security and Privacy (SP), pp. 582-597. , IEEE; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy (SP), pp. 39-57. , IEEE; Tabacof, P., Valle, E., Exploring the space of adversarial images (2016) International Joint Conference on Neural Networks (IJCNN), pp. 426-433. , IEEE; Papernot, N., (2016) Cleverhans v1.0.0: An Adversarial Machine Learning Library; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World; Papernot, N., The limitations of deep learning in adversarial settings (2016) IEEE European Symposium on Security and Privacy (EuroS&P), pp. 372-387. , IEEE; Miyato, T., (2015) Distributional Smoothing with Virtual Adversarial Training; Le-Cun, Y., The mnist database of handwritten digits (1998) Http://yann. Lecun. Com/exdb/mnist/; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images; Deng, J., Imagenet: A large-scale hierarchical image database (2009) IEEE Conference on Computer Vision and Pattern Recognition, pp. 248-255. , IEEE; Zagoruyko, S., Komodakis, N., (2016) Wide Residual Networks",,,,"i6doc.com publication","26th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2018","25 April 2018 through 27 April 2018",,149253,,9782875870476,,,"English","ESANN - Proc., Euro. Symp. Artif. Neural Networks, Comput. Intell. Mach. Learn.",Conference Paper,"Final","",Scopus,2-s2.0-85056520931
[No author name available],[No author id available],"21st International Conference on Principles and Practice of Multi-Agent Systems, PRIMA 2018",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11224 LNAI",,,"","",679,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056486503&partnerID=40&md5=c0e5169a098a0957e809203f986f4019",,"","The proceedings contain 55 papers. The special focus in this conference is on Principles and Practice of Multi-Agent Systems. The topics include: Cost sharing security information with minimal release delay; fast algorithms for computing interim allocations in single-parameter environments; on existence, mixtures, computation and efficiency in multi-objective games; student-project-resource allocation: Complexity of the symmetric case; repeated triangular trade: Sustaining circular cooperation with observation errors; accountability and responsibility in agent organizations; runtime norm revision using bayesian networks; a deep reinforcement learning approach for large-scale service composition; narrowing reinforcement learning: Overcoming the cold start problem for personalized health interventions; discovering emergent agent behaviour with evolutionary finite state machines; abstract argumentation / persuasion / dynamics; on generating explainable plans with assumption-based argumentation; a temporal planning example with assumption-based argumentation; progressive inference algorithms for probabilistic argumentation; computing preferences in abstract argumentation; notions of instrumentality in agency logic; augmented reality for multi-agent simulation of air operations; abstracting reinforcement learning agents with prior knowledge; a multi-modal urban traffic agent-based framework to study individual response to catastrophic events; dialogue games for enforcement of argument acceptance and rejection via attack removal; realization of two types of compact city - Street activeness and tramway; Learning strategic group formation for coordinated behavior in adversarial multi-agent with double DQN; personalization of health interventions using cluster-based reinforcement learning; using generative adversarial networks to develop a realistic human behavior simulator; a deontic argumentation framework based on deontic defeasible logic; simulations vs. human playing in repeated prisoner’s dilemma; qualitative-based possibilistic εL ontology.",,,,,,,,,"Oren N.Sakurai Y.Noda I.Cao Son T.Miller T.Savarimuthu B.T.",,"Springer Verlag","21st International Conference on Principles and Practice of Multi-Agent Systems, PRIMA 2018","29 October 2018 through 2 November 2018",,220189,03029743,9783030030971,,,"English","Lect. Notes Comput. Sci.",Conference Review,"Final","",Scopus,2-s2.0-85056486503
"Asgari Taghanaki S., Das A., Hamarneh G.","55511019100;57204630599;6603568967;","Vulnerability analysis of chest x-ray image classification against adversarial attacks",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11038 LNCS",,,"87","94",,15,"10.1007/978-3-030-02628-8_10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056481045&doi=10.1007%2f978-3-030-02628-8_10&partnerID=40&md5=4e28ffa549244b48da886feb90426806","School of Computing Science, Simon Fraser University, Burnaby, Canada; Department of Mathematics, Indian Institute of Technology, Guwahati, India","Asgari Taghanaki, S., School of Computing Science, Simon Fraser University, Burnaby, Canada; Das, A., School of Computing Science, Simon Fraser University, Burnaby, Canada, Department of Mathematics, Indian Institute of Technology, Guwahati, India; Hamarneh, G., School of Computing Science, Simon Fraser University, Burnaby, Canada","Recently, there have been several successful deep learning approaches for automatically classifying chest X-ray images into different disease categories. However, there is not yet a comprehensive vulnerability analysis of these models against the so-called adversarial perturbations/attacks, which makes deep models more trustful in clinical practices. In this paper, we extensively analyzed the performance of two state-of-the-art classification deep networks on chest X-ray images. These two networks were attacked by three different categories (ten methods in total) of adversarial methods (both white- and black-box), namely gradient-based, score-based, and decision-based attacks. Furthermore, we modified the pooling operations in the two classification networks to measure their sensitivities against different attacks, on the specific task of chest X-ray classification. © Springer Nature Switzerland AG 2018.","Adversarial perturbation; Chest X-ray classification; Deep learning","Artificial intelligence; Computer aided instruction; Deep learning; Image analysis; Medical computing; Neuroimaging; Adversarial perturbation; Chest X-ray image; Chest x-rays; Classification networks; Clinical practices; Different attacks; Learning approach; Vulnerability analysis; Image classification",,,,,"Baltruschat, I.M., Nickisch, H., Grass, M., Knopp, T., Saalbach, A., (2018) Comparison of Deep Learning Approaches for Multi-Label Chest X-Ray Classification; Brendel, W., Rauber, J., Bethge, M., (2017) Decision-Based Adversarial Attacks: Reliable Attacks against Black-Box Machine Learning Models, , arXiv preprint arXiv; Finlayson, S.G., Kohane, I.S., Beam, A.L., (2018) Adversarial Attacks against Medical Deep Learning Systems, , arXiv preprint arXiv; Guendel, S., (2018) Learning to Recognize Abnormalities in Chest X-Rays with Location-Aware Dense Networks, , arXiv preprint arXiv; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Kannan, H., Kurakin, A., Goodfellow, I., (2018) Adversarial Logit Pairing; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint arXiv; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , arXiv preprint arXiv; Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P., DeepFool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Narodytska, N., Kasiviswanathan, S.P., (2016) Simple Black-Box Adversarial Perturbations for Deep Networks, , arXiv preprint arXiv; Rajpurkar, P., (2017) Chexnet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning; Rauber, J., Brendel, W., Bethge, M., (2017) Foolbox V0. 8.0: A Python Toolbox to Benchmark the Robustness of Machine Learning Models; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-Scale Image Recognition; Su, J., Vargas, D.V., Kouichi, S., (2017) One Pixel Attack for Fooling Deep Neural Networks, , arXiv preprint arXiv; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., Inception-v4, inception-ResNet and the impact of residual connections on learning (2017) AAAI, 4, p. 12; Szegedy, C., Going deeper with convolutions (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9; Szegedy, C., (2013) Intriguing Properties of Neural Networks, , arXiv preprint arXiv; Toshev, A., Szegedy, C., DeepPose: Human pose estimation via deep neural networks (2014) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1653-1660; Wang, X., Peng, Y., Lu, L., Lu, Z., Bagheri, M., Summers, R.M., ChestX-ray8: Hospital-scale chest X-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases (2017) 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 3462-3471. , IEEE; Yao, L., Poblenz, E., Dagunts, D., Covington, B., Bernard, D., Lyman, K., (2017) Learning to Diagnose from Scratch by Exploiting Dependencies among Labels, , arXiv preprint arXiv; Yuan, X., He, P., Zhu, Q., Bhat, R.R., Li, X., (2017) Adversarial Examples: Attacks and Defenses for Deep Learning, , arXiv preprint arXiv; Zantedeschi, V., Nicolae, M.I., Rawat, A., Efficient defenses against adversarial attacks (2017) Proceedings of the 10Th ACM Workshop on Artificial Intelligence and Security, pp. 39-49. , ACM; Zoph, B., Vasudevan, V., Shlens, J., Le, Q.V., (2017) Learning Transferable Architectures for Scalable Image Recognition, 2 (6)","Asgari Taghanaki, S.; School of Computing Science, Canada; email: sasgarit@sfu.ca","Taylor Z.Reyes M.Cardoso M.J.Silva C.A.Stoyanov D.Maier-Hein L.Pereira S.Kia S.M.Oguz I.Landman B.Martel A.Duchesnay E.Lofstedt T.Marquand A.F.Meier R.",,"Springer Verlag","1st International Workshop on Machine Learning in Clinical Neuroimaging, MLCN 2018, 1st International Workshop on Deep Learning Fails, DLF 2018, and 1st International Workshop on Interpretability of Machine Intelligence in Medical Image Computing, iMIMIC 2018, held in conjunction with the 21st International Conference on Medical Imaging and Computer-Assisted Intervention, MICCAI 2018","16 September 2018 through 20 September 2018",,220139,03029743,9783030026271,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85056481045
"Kügler D., Distergoft A., Kuijper A., Mukhopadhyay A.","57214378100;57204631794;56131137100;56241021800;","Exploring adversarial examples: Patterns of one-pixel attacks",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11038 LNCS",,,"70","78",,1,"10.1007/978-3-030-02628-8_8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056461036&doi=10.1007%2f978-3-030-02628-8_8&partnerID=40&md5=2c3cdc94c9f7c67e594e66aba56b7470","Interactive Graphics Systems Group, Technische Universität Darmstadt, Darmstadt, Germany; Fraunhofer IGD, Darmstadt, Germany","Kügler, D., Interactive Graphics Systems Group, Technische Universität Darmstadt, Darmstadt, Germany; Distergoft, A., Interactive Graphics Systems Group, Technische Universität Darmstadt, Darmstadt, Germany; Kuijper, A., Fraunhofer IGD, Darmstadt, Germany; Mukhopadhyay, A., Interactive Graphics Systems Group, Technische Universität Darmstadt, Darmstadt, Germany","Failure cases of black-box deep learning, e.g. adversarial examples, might have severe consequences in healthcare. Yet such failures are mostly studied in the context of real-world images with calibrated attacks. To demystify the adversarial examples, rigorous studies need to be designed. Unfortunately, complexity of the medical images hinders such study design directly from the medical images. We hypothesize that adversarial examples might result from the incorrect mapping of image space to the low dimensional generation manifold by deep networks. To test the hypothesis, we simplify a complex medical problem namely pose estimation of surgical tools into its barest form. An analytical decision boundary and exhaustive search of the one-pixel attack across multiple image dimensions let us localize the regions of frequent successful one-pixel attacks at the image space. © Springer Nature Switzerland AG 2018.","Adversarial examples; CNN; Deep Learning Fails; One-pixel attack","Artificial intelligence; Complex networks; Computer aided instruction; Medical computing; Neuroimaging; Pixels; Surgical equipment; Adversarial examples; Analytical decisions; Low dimensional; Multiple image; One-pixel attack; Pose estimation; Real-world image; Surgical tools; Deep learning",,,,,"Berkrot, B., U.S. FDA Approves AI Device to Detect Diabetic Eye Disease, , https://www.reuters.com/article/us-fda-ai-approval/u-s-fda-approves-ai-device-to-detect-diabetic-eye-disease-idUSKBN1HI2LC, 11 April 2018; Eykholt, K., (2017) Robust Physical-World Attacks on Deep Learning Models, , http://arxiv.org/pdf/1707.08945; Finlayson, S.G., Chung, H.W., Kohane, I.S., Beam, A.L., (2018) Adversarial Attacks against Medical Deep Learning Systems, , http://arxiv.org/pdf/1804.05296; Gilmer, J., (2018) Adversarial Spheres, , http://arxiv.org/pdf/1801.02774; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , http://arxiv.org/pdf/1412.6572; Kügler, D., Stefanov, A., Mukhopadhyay, A., (2018) I3posnet: Instrument Pose Estimation from X-Ray, , http://arxiv.org/pdf/1802.09575; Walter, M., FDA Reclassification Proposal Could Ease Approval Process for CAD Software, , https://www.healthimaging.com/topics/healthcare-economics/fda-reclassification-proposal-could-ease-approval-process-cad-software, 01 June 2018; Nguyen, A., Yosinski, J., Clune, J., (2014) Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images, , http://arxiv.org/pdf/1412.1897; Rauber, J., Brendel, W., Bethge, M., (2017) Foolbox: A Python Toolbox to Benchmark the Robustness of Machine Learning Models, , http://arxiv.org/pdf/1707.04131; Su, J., Vargas, D.V., Kouichi, S., (2017) One Pixel Attack for Fooling Deep Neural Networks, , http://arxiv.org/pdf/1710.08864; Szegedy, C., (2013) Intriguing Properties of Neural Networks, , http://arxiv.org/pdf/1312.6199","Kügler, D.; Interactive Graphics Systems Group, Germany; email: david.kuegler@gris.tu-darmstadt.de","Taylor Z.Reyes M.Cardoso M.J.Silva C.A.Stoyanov D.Maier-Hein L.Pereira S.Kia S.M.Oguz I.Landman B.Martel A.Duchesnay E.Lofstedt T.Marquand A.F.Meier R.",,"Springer Verlag","1st International Workshop on Machine Learning in Clinical Neuroimaging, MLCN 2018, 1st International Workshop on Deep Learning Fails, DLF 2018, and 1st International Workshop on Interpretability of Machine Intelligence in Medical Image Computing, iMIMIC 2018, held in conjunction with the 21st International Conference on Medical Imaging and Computer-Assisted Intervention, MICCAI 2018","16 September 2018 through 20 September 2018",,220139,03029743,9783030026271,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85056461036
[No author name available],[No author id available],"1st International Workshop on Machine Learning in Clinical Neuroimaging, MLCN 2018, 1st International Workshop on Deep Learning Fails, DLF 2018, and 1st International Workshop on Interpretability of Machine Intelligence in Medical Image Computing, iMIMIC 2018, held in conjunction with the 21st International Conference on Medical Imaging and Computer-Assisted Intervention, MICCAI 2018",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11038 LNCS",,,"","",148,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056447258&partnerID=40&md5=88d8e08da8ede12d32a4b3b17f5882b3",,"","The proceedings contain 16 papers. The special focus in this conference is on Machine Learning in Clinical Neuroimaging. The topics include: Alzheimer’s disease modelling and staging through independent gaussian process analysis of spatio-temporal brain changes; vulnerability analysis of chest x-ray image classification against adversarial attacks; Collaborative human-AI (CHAI): Evidence-based interpretable melanoma classification in dermoscopic images; Automatic brain tumor grading from MRI data using convolutional neural networks and quality assessment; visualizing convolutional neural networks to improve decision support for skin lesion classification; regression concept vectors for bidirectional explanations in histopathology; towards complementary explanations using deep neural networks; how users perceive content-based image retrieval for identifying skin images; multi-channel stochastic variational inference for the joint analysis of heterogeneous biomedical data in alzheimer’s disease; Visualizing convolutional networks for MRI-based diagnosis of alzheimer’s disease; Finding effective ways to (machine) learn fMRI-based classifiers from multi-site data; Towards robust CT-ultrasound registration using deep learning methods; to learn or not to learn features for deformable registration?; Evaluation of strategies for PET motion correction - Manifold learning vs. Deep learning; exploring adversarial examples: Patterns of one-pixel attacks; shortcomings of ventricle segmentation using deep convolutional networks.",,,,,,,,,"Taylor Z.Reyes M.Cardoso M.J.Silva C.A.Stoyanov D.Maier-Hein L.Pereira S.Kia S.M.Oguz I.Landman B.Martel A.Duchesnay E.Lofstedt T.Marquand A.F.Meier R.",,"Springer Verlag","1st International Workshop on Machine Learning in Clinical Neuroimaging, MLCN 2018, 1st International Workshop on Deep Learning Fails, DLF 2018, and 1st International Workshop on Interpretability of Machine Intelligence in Medical Image Computing, iMIMIC 2018, held in conjunction with the 21st International Conference on Medical Imaging and Computer-Assisted Intervention, MICCAI 2018","16 September 2018 through 20 September 2018",,220139,03029743,9783030026271,,,"English","Lect. Notes Comput. Sci.",Conference Review,"Final","",Scopus,2-s2.0-85056447258
"Diallo E.A.O., Sugawara T.","57202470553;7201751518;","Learning strategic group formation for coordinated behavior in adversarial multi-agent with double DQN",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11224 LNAI",,,"458","466",,7,"10.1007/978-3-030-03098-8_30","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056447233&doi=10.1007%2f978-3-030-03098-8_30&partnerID=40&md5=816af3d9cfb08c2fd3cb9add49f5c333","Department of Computer Science and Communications Engineering, Waseda University, 3-4-1 Okubo, Shinjuku-ku, Tokyo, 169-8555, Japan","Diallo, E.A.O., Department of Computer Science and Communications Engineering, Waseda University, 3-4-1 Okubo, Shinjuku-ku, Tokyo, 169-8555, Japan; Sugawara, T., Department of Computer Science and Communications Engineering, Waseda University, 3-4-1 Okubo, Shinjuku-ku, Tokyo, 169-8555, Japan","We examine whether a team of agents can learn geometric and strategic group formations by using deep reinforcement learning in adversarial multi-agent systems. This is a significant point underlying the control and coordination of multiple autonomous and intelligent agents. While there are many possible approaches to solve this problem, we are interested in fully end-to-end learning method where agents do not have any prior knowledge of the environment and its dynamics. In this paper, we propose a scalable and distributed double DQN framework to train adversarial multi-agent systems. We show that a large number of agents can learn to cooperatively move, attack and defend themselves in various geometric formations and battle tactics like encirclement, guerrilla warfare, frontal attack, flanking maneuver, and so on. We finally show that agents create an emergent and collective flocking behaviors by using local views from the environment only. © Springer Nature Switzerland AG 2018.","Collective intelligence; Cooperation; Coordination; Deep reinforcement learning; Multi-agent systems","Autonomous agents; Data privacy; Deep learning; Intelligent agents; Network security; Reinforcement learning; Collective intelligences; Cooperation; Coordinated behavior; Coordination; Learning methods; Prior knowledge; Significant points; Strategic groups; Multi agent systems",,,,,"Balch, T., Arkin, R.C., Behavior-based formation control for multirobot teams (1998) IEEE Trans. Robot. Autom., 14 (6), pp. 926-939; Barfoot, T.D., Clark, C.M., Motion planning for formations of mobile robots (2004) Robot. Autonom. Syst., 46 (2), pp. 65-78; Buşoniu, L., Babuška, R., Schutter, B., Multi-agent reinforcement learning: An overview (2010) Innovations in Multi-Agent Systems and Applications-1, Studies in Computational Intelligence, 310. , https://doi.org/10.1007/978-3-642-14435-67, Srinivasan, D., Jain L.C., Springer, Heidelberg; Desai, J.P., Ostrowski, J., Kumar, V., Controlling formations of multiple mobile robots (1998) Proceedings 1998 IEEE International Conference on Robotics and Automation (Cat. No.98Ch36146), 4, pp. 2864-2869. , May; Diallo, E.A.O., Sugiyama, A., Sugawara, T., Learning to coordinate with deep reinforcement learning in doubles pong game (2017) 16Th IEEE International Conference on Machine Learning and Applications (ICMLA), pp. 14-19. , Dec; Mnih, V., Human-level control through deep reinforcement learning (2015) Nature, 518 (7540), p. 529; Nathan, A., Barbosa, V.C., (2006) V-Like Formations in Flocks of Artificial Birds, , http://arxiv.org/abs/cs/0611032; Rana, O.F., Stout, K., What is scalability in multi-agent systems? (2000) Proceedings of the Fourth International Conference on Autonomous Agents, pp. 56-63. , AGENTS 2000, ACM, New York; Reynolds, C.W., Flocks, herds and schools: A distributed behavioral model (1987) ACM SIGGRAPH Computer Graphics, 21, pp. 25-34. , ACM; Sukhbaatar, S., Szlam, A., Fergus, R., Learning multiagent communication with backpropagation (2016) NIPS; van Hasselt, H., Guez, A., Silver, D., Deep reinforcement learning with double Q-learning (2016) AAAI, 16, pp. 2094-2100; Wooldridge, M., (2009) An Introduction to Multiagent Systems, , John Wiley & Sons, Hoboken","Diallo, E.A.O.; Department of Computer Science and Communications Engineering, 3-4-1 Okubo, Shinjuku-ku, Japan; email: diallo.oury@fuji.waseda.jp","Oren N.Sakurai Y.Noda I.Cao Son T.Miller T.Savarimuthu B.T.",,"Springer Verlag","21st International Conference on Principles and Practice of Multi-Agent Systems, PRIMA 2018","29 October 2018 through 2 November 2018",,220189,03029743,9783030030971,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","",Scopus,2-s2.0-85056447233
"Zawistowski P., Twardowski B.","36624638100;55438080100;","Exploiting random perturbations to defend against adversarial attacks",2018,"Proceedings of SPIE - The International Society for Optical Engineering","10808",,"108082N","","",,,"10.1117/12.2501606","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056285447&doi=10.1117%2f12.2501606&partnerID=40&md5=e2abaf7c7d9904525688a5991f9e8a0d","Institute of Computer Science, Faculty of Electronics and Information Technology, Warsaw University of Technology, Nowowiejska 15/19, Warsaw, 00-665, Poland","Zawistowski, P., Institute of Computer Science, Faculty of Electronics and Information Technology, Warsaw University of Technology, Nowowiejska 15/19, Warsaw, 00-665, Poland; Twardowski, B., Institute of Computer Science, Faculty of Electronics and Information Technology, Warsaw University of Technology, Nowowiejska 15/19, Warsaw, 00-665, Poland","Adversarial examples are deliberately crafted data points which aim to induce errors in machine learning models. This phenomenon has gained much attention recently, especially in the field of image classification, where many methods have been proposed to generate such malicious examples. In this paper we focus on defending a trained model against such attacks by introducing randomness to its inputs. © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.","Adversarial examples; Machine learning security; Neural networks","Artificial intelligence; Learning systems; Neural networks; Random processes; Adversarial examples; Data points; Machine learning models; Random perturbations; High energy physics",,,,,"LeCun, Y., (1998) The Mnist Database of Handwritten Digits, , http://yann.lecun.com/exdb/mnist; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., Imagenet: A large-scale hierarchical image database (2009) Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pp. 248-255. , IEEE; Huang, G.B., Ramesh, M., Berg, T., Learned-Miller, E., (2007) Labeled Faces in the Wild: A Database for Studying Face Recognition in Unconstrained Environments, , tech. rep., Technical Report 07-49, University of Massachusetts, Amherst; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint arXiv:1312.6199; Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P., (2015) DeepFool: A Simple and Accurate Method to Fool Deep Neural Networks; Athalye, A., Engstrom, L., Ilyas, A., Kwok, K., (2017) Synthesizing Robust Adversarial Examples; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, pp. 1-11; Brown, T.B., Mane, D., Roy, A., Abadi, M., Gilmer, J., Adversarial Patch; Papernot, N., McDaniel, P., Sinha, A., Wellman, M., (2016) Towards the Science of Security and Privacy in Machine Learning, , arXiv preprint arXiv:1611.03814; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Security and Privacy (SP), 2016 IEEE Symposium on, pp. 582-597. , IEEE; Gong, Z., Wang, W., Ku, W.-S., (2017) Adversarial and Clean Data Are Not Twins, , arXiv preprint arXiv:1704.04960; Metzen, J.H., Genewein, T., Fischer, V., Bischo, B., (2017) On Detecting Adversarial Perturbations, , arXiv preprint arXiv:1702.04267; Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., (2017) On the (Statistical) Detection of Adversarial Examples, , arXiv preprint arXiv:1702.06280; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts, , arXiv preprint arXiv:1703.00410; Hendrycks, D., Gimpel, K., (2017) Early Methods for Detecting Adversarial Images; Bhagoji, A.N., Cullina, D., Mittal, P., (2017) Dimensionality Reduction As A Defense Against Evasion Attacks on Machine Learning Classiers, , arXiv preprint arXiv:1704.02654; Li, X., Li, F., Adversarial examples detection in deep networks with convolutional lter statistics (2016) CoRR, , abs/1612.07767 7; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) Proceedings of the 10th ACM Workshop on Articial Intelligence and Security, pp. 3-14. , ACM; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Dong, Y., Liao, F., Pang, T., Su, H., Hu, X., Li, J., Zhu, J., (2017) Boosting Adversarial Attacks with Momentum. Arxiv Preprint, , arXiv preprint arXiv:1710.06081","Zawistowski, P.; Institute of Computer Science, Nowowiejska 15/19, Poland; email: pawel.zawistowski@pw.edu.pl","Romaniuk R.S.Linczuk M.","ARIES - Accelerator Research and Innovation for European Science and Society (CERN, EU H2020);Committee of Electronics and Telecommunications, Polish Academy of Sciences;EuroFusion Collaboration;EuroFusion Poland;PKOpto - Polish Committee of Optoelectronics of SEP-The Association of Polish Electrical Engineers;PSP - Photonics Society of Poland","SPIE","Photonics Applications in Astronomy, Communications, Industry, and High-Energy Physics Experiments 2018","3 June 2018 through 10 June 2018",,140492,0277786X,9781510622036,PSISD,,"English","Proc SPIE Int Soc Opt Eng",Conference Paper,"Final","",Scopus,2-s2.0-85056285447
"Oleszkiewicz W.","57191745215;","Comparison of deep neural network fooling methods on the accuracy of classification",2018,"Proceedings of SPIE - The International Society for Optical Engineering","10808",,"108082I","","",,,"10.1117/12.2501586","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056283486&doi=10.1117%2f12.2501586&partnerID=40&md5=791cc02a6dfa66d597811a778f07f85a","Artificial Intelligence Division, Institute of Informatics, Warsaw University of Technology, Warsaw, Poland","Oleszkiewicz, W., Artificial Intelligence Division, Institute of Informatics, Warsaw University of Technology, Warsaw, Poland","The ability to train neural networks depends on access to data. In some areas, for example in medicine, it is difficult to obtain large datasets since medical data can contain very sensitive information. It is desirable to anonymize the dataset in such a way that the utility of machine learning prediction models is preserved. In this paper, we compare different methods of fooling deep neural networks. We investigate how different algorithms affects the accuracy of one classification task while fooling classifier in the other classification task. © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.","Adversarial attacks; Artificial intelligence; Artificial neural networks; Computer vision; Generative adversarial network; Machine learning","Artificial intelligence; Computer vision; High energy physics; Learning systems; Neural networks; Accuracy of classifications; Adversarial attacks; Adversarial networks; Classification tasks; Large datasets; Medical data; Prediction model; Sensitive informations; Deep neural networks",,,,,"Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Fei-Fei, L., Imagenet large scale visual recognition challenge (2015) International Journal of Computer Vision; Raval, N., Srivastava, A., Lebeck, K., Cox, L., Machanavajjhala, A., Markit: Privacy markers for pro-tecting visual secrets (2014) Proceedings of the 2014 Acm International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct Publication, pp. 1289-1295; Abadi, M., Erlingsson, U., Goodfellow, I., McMahan, H.B., Mironov, I., Papernot, N., Zhang, L., On the protection of private information in machine learning systems: Two recent approaches (2017) CoRR, , ArXiv preprint: abs/1708.08022; Raval, N., Machanavajjhala, A., Cox, L.P., Protecting visual secrets using adversarial nets (2017) Cvpr Workshop Proceedings; Narayanan, A., Shmatikov, V., Robust de-anonymization of large sparse datasets (2008) Security and Privacy, Ieee Symposium, pp. 111-125; Sweeney, L., Abu, A., Winn, J., (2013) Identifying Participants in the Personal Genome Project by Name (A Re-identication Experiment), , ArXiv preprint: abs/1304.7605; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2015) CoRR, , abs/1512.03385; Goodfellow, I.J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., (2014) Generative Adversarial Networks, , arXiv preprint: 1406.2661; Cheung, V., Chen, X., Goodfellow, I., Radford, A., Salimans, T., Zaremba, W., Improved techniques for training gans (2016) NIPS; Li, M., Zuo, W., Zhang, D., (2016) Deep Identity-aware Transfer of Facial Attributes, , arXiv preprint: 1610.05586; Mirza, M., Osindero, S., (2014) Conditional Generative Adversarial Nets, , arXiv preprint: 1411.1784; Hu, Y., Gibson, E., Lee, L., Xie, W., Barratt, D.C., Vercauteren, T., Noble, J.A., Free-hand ultrasound image simulation with spatially-conditioned generative adversarial networks CoRR, , abs/1707.05392; Esteban, C., Hyland, S.L., Ratsch, G., (2017) Real-valued (Medical) Time Series Generation with Recurrent Conditional Gans, , arXiv preprint: 1706.02633; Moosavi-Dezfooli, S., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2015) CoRR, , abs/1511.04599; Athalye, A., Engstrom, L., Ilyas, A., Kwok, K., Synthesizing robust adversarial examples (2017) CoRR, , abs/1707.07397; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint:1412.6572; Nist 8-bit Gray Scale Images of Ngerprint Image Groups(gs), Standard Reference Data Program, National Institute of Standards and Technology; Oleszkiewicz, W., Wodarczyk, T., Piczak, K., Trzcinski, T., Kairouz, P., Rajagopal, R., (2018) Siamese Generative Adversarial Privatizer for Biometric Data, , ArXiv preprint: 1804.08757, Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), Challenges and Opportunities for Privacy and Security (CV-COPS) The Bright and Dark Sides of Computer Vision; Bromley, J., Guyon, I., LeCun, Y., Sackinger, E., Shah, R., Signature verication using a siamese time delay neural network (1994) NIPS","Oleszkiewicz, W.; Artificial Intelligence Division, Poland; email: witold.oleszkiewicz@gmail.com","Romaniuk R.S.Linczuk M.","ARIES - Accelerator Research and Innovation for European Science and Society (CERN, EU H2020);Committee of Electronics and Telecommunications, Polish Academy of Sciences;EuroFusion Collaboration;EuroFusion Poland;PKOpto - Polish Committee of Optoelectronics of SEP-The Association of Polish Electrical Engineers;PSP - Photonics Society of Poland","SPIE","Photonics Applications in Astronomy, Communications, Industry, and High-Energy Physics Experiments 2018","3 June 2018 through 10 June 2018",,140492,0277786X,9781510622036,PSISD,,"English","Proc SPIE Int Soc Opt Eng",Conference Paper,"Final","",Scopus,2-s2.0-85056283486
"Li Y., Abdel-Khalik H.S., Bertino E.","57196442761;8575537300;7102307605;","Online adversarial learning of reactor state",2018,"International Conference on Nuclear Engineering, Proceedings, ICONE","4",,,"","",,1,"10.1115/ICONE2682372","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056159576&doi=10.1115%2fICONE2682372&partnerID=40&md5=893ada8cf7ab1bb84e944aed4a388c05","School of Nuclear Engineering, Purdue University, West Lafayette, IN  47907, United States; Computer Science Department, Purdue University, West Lafayette, IN  47907, United States","Li, Y., School of Nuclear Engineering, Purdue University, West Lafayette, IN  47907, United States; Abdel-Khalik, H.S., School of Nuclear Engineering, Purdue University, West Lafayette, IN  47907, United States; Bertino, E., Computer Science Department, Purdue University, West Lafayette, IN  47907, United States","This paper is in support of our recent efforts to designing intelligent defenses against false data injection attacks, where false data are injected in the raw data used to control the reactor. Adopting a game-model between the attacker and the defender, we focus here on how the attacker may estimate reactor state in order to inject an attack that can bypass normal reactor anomaly and outlier detection checks. This approach is essential to designing defensive strategies that can anticipate the attackers moves. More importantly, it is to alert the community that defensive methods based on approximate physics models could be bypassed by the attacker who can approximate the models in an online mode during a lie-in-wait period. For illustration, we employ a simplified point kinetics model and show how an attacker, once gaining access to the reactor raw data, i.e., instrumentation readings, can inject small perturbations to learn the reactor dynamic behavior. In our context, this equates to estimating the reactivity feedback coefficients, e.g., Doppler, Xenon poisoning, etc. We employ a non-parametric learning approach that employs alternating conditional estimation in conjunction with discrete Fourier transform and curve fitting techniques to estimate reactivity coefficients. An Iranian model of the Bushehr reactor is employed for demonstration. Results indicate that very accurate estimation of reactor state could be achieved using the proposed learning method. Copyright © 2018 ASME",,"Curve fitting; Discrete Fourier transforms; E-learning; Network security; Nuclear engineering; Adversarial learning; Curve fitting technique; Defensive strategies; False data injection attacks; Point-kinetics models; Reactivity coefficients; Reactivity feedback; Small perturbations; Learning systems",,,,,"Urbina, D., Limiting the Impact of Stealthy Attacks on Industrial Control Systems (2016) Proceedings of The 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1092-1105. , 24 October; Bunn, M., Sagan, S.D., A Worst Practices Guide to Insider Threats: Lessons from Past Mistakes (2014) American ACADEMY OF ARTS & SCIENCES; Liu, Y., Ning, P., Reiter, M.K., (2011) False Data Injection Attacks Against State Estimation in Electric Power Grids, 14 (1); Hashemian, H.M., (2006) Maintenance of Process Instrumentation in Nuclear Power Plants, , Springer; Fantoni, P., Mazzola, A., (1990) Applications Of Autoassociative Neural Networksfor Signal Validation In Accident Management, 37 (2), pp. 1040-1047; Breiman, L., Friedman, J.H., Estimating Optimal Transformations Multiple Regression and Correlation (1985) Journal of The American Statistical Association September, 80 (391). , Theory and Method; Zarei, M., Ghaderi, R., Minuchehr, A., Progress in Nuclear Energy Space independent xenon oscillations control in VVER reactor: A bifurcation analysis approach (2016) Progress in Nuclear Energy, 88, pp. 19-27; Li, Y., Bertino, E., Abdel-Khalik, H., Non-Parametric Based Inverse Approach Of Nuclear Reactor Dynamic Behavior Proceedings of The PHYSOR 2018, , Cancun, Mexico; Touran, N.W., (2012), https://github.com/partofthething/ace",,,"Nuclear Engineering Division","American Society of Mechanical Engineers (ASME)","2018 26th International Conference on Nuclear Engineering, ICONE 2018","22 July 2018 through 26 July 2018",,141167,,9780791851463,,,"English",,Conference Paper,"Final","",Scopus,2-s2.0-85056159576
"Ali T., Jan S., Musa S.N., Rahman A.","55204929000;56825229400;52963995100;7402940471;","Malware analysis and detection approaches: Drive to deep learning",2018,"Journal of Engineering and Applied Sciences","13","15",,"6281","6292",,,"10.3923/jeasci.2018.6281.6292","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055930187&doi=10.3923%2fjeasci.2018.6281.6292&partnerID=40&md5=d3ad4c5c4db1f4c6fd260694ef29c97d","Islamic University of Madinah, Medina, Saudi Arabia; MalaysianIn stitute of Information Technology, Universiti Kuala Lumpur, Malaysia; University of Peshawar, Peshawar, Khyber Pakhtunkhwa, Pakistan","Ali, T., Islamic University of Madinah, Medina, Saudi Arabia; Jan, S., MalaysianIn stitute of Information Technology, Universiti Kuala Lumpur, Malaysia, University of Peshawar, Peshawar, Khyber Pakhtunkhwa, Pakistan; Musa, S.N., MalaysianIn stitute of Information Technology, Universiti Kuala Lumpur, Malaysia; Rahman, A., Islamic University of Madinah, Medina, Saudi Arabia","The growing number of malware attacks poses serious threats to private data and to the expensive computing resources. To detect malware and their associated families, anti-malware companies rely on signatures which indeed include regular expressions and strings. The recent malware attacks in the last few years including the resurgence of ransomware have proven that signature-based methods are error-prone and can be easily evaded by intelligent malware programs. This study reviews traditional and state-of-the-art models developed for malware analysis and detection. According to our observation the classification of malware and their behavior facilitates in provision of basic insights for the researchers working in the domain of malware analysis. At the end we present the conception of using Deep Convolutional Generated Adversarial Networks (DCGAN) in the area of malware detection as the DCGANs are the latest approach in deep learning that effectively deals adversarial examples. © Medwell Journals, 2018.","CNN; DCGAN; ESN; GAN; GPU; Neural networks; RNN; Trusted computing",,,,,,"Agrawal, S., Agrawal, J., Survey on anomaly detection using data mining techniques (2015) Procedia Comput. Sci, 60, pp. 708-713; Alam, M., Ali, T., Khan, S., Khan, S., Ali, M., Analysis of existing remote attestation techniques (2012) Secur. Commun. Netw, 5, pp. 1062-1082; Alam, M., Zhang, X., Nauman, M., Ali, T., Seifert, J.P., Model-based behavioral attestation (2008) Proceedings of the 13th ACM Symposium on Access Control Models and Technologies, pp. 175-184. , June 11-13, 2008, ACM, Colorado, USA; Ali, T., Nauman, M., Zhang, X., On leveraging stochastic models for remote attestation (2010) Proceedings of the 2nd International Conference on Trusted Systems (INTRUST'10), pp. 290-301. , December 13-15, 2010, Springer, Beijing, China; (2010) Computer immune systems, , University of New Mexico, Albuquerque, New Mexico; (2017) File statistics, , https://www.virustotal.com/en/statistics/, VirusTotal, Dublin, Ireland; (2017) PE infor service, , GitHub Inc., San Francisco, California, USA; Asmitha, K.A., Vinod, P., A machine learning approach for linux malware detection (2014) Proceedings of the 2014 International Conference on Issues and Challenges in Intelligent Computing Techniques (ICICT), pp. 825-830. , February 7-8, 2014, IEEE, Ghaziabad, India; Avdiienko, V., Kuznetsov, K., Gorla, A., Zeller, A., Arzt, S., Mining apps for abnormal usage of sensitive data (2015) Proceedings of the 37th International Conference on Software Engineering, 1, pp. 426-436. , May 16-24, 2015, IEEE, Florence, Italy; Bayer, U., Comparetti, P.M., Hlauschek, C., Kruegel, C., Kirda, E., Scalable, behavior-based malware clustering (2009) NDSS, 9, pp. 8-11; Bodke, A., (2013) Systems and methods for identifying polymorphic malware, , https://patents.google.com/patent/US8479291B1/en, US Patent No. US8479291B1, Symantec, California, USA; Burns, J., Exploratory androidTM surgery (2009) Proceedings of the Black Hat Conference on Technical Security, pp. 1-47. , July 25-30, 2009, iSEC Partners, Inc., San Francisco, California, USA; Cesare, S., Xiang, Y., Zhou, W., Malwise: An effective and efficient classification system for packed and polymorphic malware (2013) IEEE Trans. Comput, 62, pp. 1193-1206; Chen, Y., Venkatesan, R., Cary, M., Pang, R., Sinha, S., Oblivious hashing: A stealthy software integrity verification primitive (2002) Proceedings of the 5th International Workshop on Information Hiding (IH'02), pp. 400-414. , October 7-9, 2002, Springer, Noordwijkerhout, The Netherlands; Cohen, I.G., Hoffman, S., Adashi, E.Y., Your money or your patient's life? Ransomware and electronic health records (2017) Ann. Internal Med, 167, pp. 587-588; Cusumano, M., Cloud computing and SaaS as new computing platforms (2010) Communi. ACM, 53, pp. 27-29; Day, C.W., (2007) Intrusion detection system, , https://patents.google.com/patent/US7260846B2/en, US Patent No. US7260846B2, SteelCloud Inc., Virginia, USA; Farid, D.M., Zhang, L., Rahman, C.M., Hossain, M.A., Strachan, R., Hybrid decision tree and naïve Bayes classifiers for multi-class classification tasks (2014) Expert Syst. Appl, 41, pp. 1937-1946; Farid, D.M., Harbi, N., Rahman, M.Z., Combining naive bayes and decision tree for adaptive intrusion detection (2010) Int. J. Network Secur. Appl, 2, pp. 12-25; Fu, S., Liu, J., Pannu, H., A hybrid anomaly detection framework in cloud computing using one-class and two-class support vector machines (2012) Proceedings of the 8th International Conference on International Conference on Advanced Data Mining and Applications (ADMA'12), pp. 726-738. , December 15-18, 2012, Springer, Nanjing, China; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Generative adversarial nets (2014) Proceedings of the 27th International Conference on Neural Information Processing Systems, pp. 2672-2680. , December 08-13, 2014, ACM, Montreal, Canada; Hasselbring, W., Reussner, R., Toward trustworthy software systems (2006) Comput, 39, pp. 91-92; Idika, N., Mathur, A.P., (2007) A survey of malware detection techniques, , http://www.serc.net/system/files/SERC-TR-286.pdf, Purdue University, Arxan Technologies/21STC.R&T Fund, February 2, 2007; Islam, R., Tian, R., Batten, L.M., Versteeg, S., Classification of malware based on integrated static and dynamic features (2013) J. Netw. Comput. Appl, 36, pp. 646-656; Ismail, R., Syed, T.A., Musa, S., Design and implementation of an efficient framework for behaviour attestation using n-call slides (2014) Proceedings of the 8th International Conference on Ubiquitous Information Management and Communication, pp. 361-368. , January 09-11, 2014, ACM, Siem Reap, Cambodia; Kim, D., Majlesi-Kupaei, A., Roy, J., Anand, K., ElWazeer, K., DynODet: Detecting dynamic obfuscation in malware (2017) Proceedings of the 14th International Conference on Detection of Intrusions and Malware and Vulnerability Assessment (DIMVA'17), pp. 97-118. , July 6-7, 2017, Springer, Bonn, Germany; Kolosnjaji, B., Zarras, A., Webster, G., Eckert, C., Deep learning for classification of malware system call sequences (2016) Proceedings of the 29th Australasian Joint Conference on Artificial Intelligence, pp. 137-149. , December 5-8, 2016, Springer, Hobart, Australia; Kolosnjaji, B., Eraisha, G., Webster, G., Zarras, A., Eckert, C., Empowering convolutional networks for malware classification and analysis (2017) Proceedings of the 2017 International Joint Conference on Neural Networks (IJCNN'17), pp. 3838-3845. , May 14-19, 2017, IEEE, Anchorage, Alaska; Kolter, J.Z., Maloof, M.A., Learning to detect malicious executables in the wild (2004) Proceedings of the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 470-478. , ACM, Seattle, Washington, August 22-25, 2004; Kolter, J.Z., Maloof, M.A., Learning to detect and classify malicious executables in the wild (2006) J. Mach. Learn. Res, 7, pp. 2712-2744; Kong, D., Yan, G., Discriminant malware distance learning on structural information for automated malware classification (2013) Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 1357-1365. , August 11-14, 2013, ACM, Chicago, Illinois, USA; Liao, H.J., Lin, C.H.R., Lin, Y.C., Tung, K.Y., Intrusion detection system: A comprehensive review (2013) J. Network Comput. Applic, 36, pp. 16-24; Linn, C., Debray, S., Obfuscation of executable code to improve resistance to static disassembly (2003) Proceedings of the 10th ACM Conference on Computer and Communications Security, pp. 290-299. , October 27-30, 2003, ACM, Washington D.C., USA; Lipton, Z.C., (2017) Deep convolutional generative adversarial networks, , GitHub Inc., San Francisco, California, USA; Luo, X., Liao, Q., Awareness education as the key to ransomware prevention (2007) Inf. Syst. Secur, 16, pp. 195-202; Mehdi, B., Ahmed, F., Khayyam, S.A., Farooq, M., Towards a theory of generalizing system call representation for in-execution malware detection (2010) Proceedings of the 2010 IEEE International Conference on Communications (ICC'10), pp. 1-5. , May 23-27, 2010, IEEE, Cape Town, South Africa; Moein, S., Gebali, F., Traore, I., Analysis of covert hardware attacks (2014) J. Convergence, 5, pp. 26-30; Mohaisen, A., Alrawi, O., Mohaisen, M., Amal: High-fidelity, behavior-based automated malware analysis and classification (2015) Comput. Secur, 52, pp. 251-266; Moser, A., Kruegel, C., Kirda, E., Exploring multiple execution paths for malware analysis (2007) Proceeding of the IEEE Symposium on Securit and Privacy, pp. 231-245. , May 20-23, Berkeley, CA; Moser, A., Kruegel, C., Kirda, E., Limits of static analysis for malware detection (2007) Proceedings of the 23rd Annual Conference on Computer Security Applications (ACSAC'07), pp. 421-430. , December 10-14, 2007, IEEE, Miami Beach, Florida; Nataraj, L., Karthikeyan, S., Jacob, G., Manjunath, B.S., Malware images: Visualization and automatic classification (2011) Proceedings of the 8th International Symposium on Visualization for Cyber Security, pp. 1-7. , July 20, 2011, ACM, Pittsburgh, Pennsylvania, USA; Nauman, M., Azam, N., Yao, J., A three-way decision making approach to malware analysis using probabilistic rough sets (2016) Inf. Sci, 374, pp. 193-209; Pascanu, R., Stokes, J.W., Sanossian, H., Marinescu, M., Thomas, A., Malware classification with recurrent networks (2015) Proceedings of the 2015 IEEE International Conference on Acoustics, pp. 1916-1920. , Speech and Signal Processing (ICASSP'15), April 19-24, 2015, IEEE, Brisbane, Australia; Rowett, K., Sikdar, S., (2005) Intrusion detection system, , https://patents.google.com/patent/US20050216770A1/en, US Patent No. US20050216770A1, Gigafin Networks Inc., Cupertino, California, USA; Santos, I., Brezo, F., Ugarte-Pedrero, X., Bringas, P.G., Opcode sequences as representation of executables for data-mining-based unknown malware detection (2013) Inf. Sci, 231, pp. 64-82; Scheidell, M., (2009) Intrusion detection system, , https://patents.google.com/patent/US7603711B2/en, US Patent No. US7603711B2, SECNAP Network Security, Boca Raton, Florida, USA; Schmidt, A.D., Bye, R., Schmidt, H.G., Clausen, J., Kiraz, O., Static analysis of executables for collaborative malware detection on android (2009) Proceedings of the 2009 IEEE International Conference on Communications (ICC'09), pp. 1-5. , June 14-18, 2009, IEEE, Dresden, Germany; Schultz, M., Eskin, E., Zadok, E., Stolfo, S.J., Data mining methods for detection of new malicious executables (2001) Proceedings of the IEEE Symposium on Security and Privacy, pp. 38-49. , May 14-16, IEEE Computer Society Washington, DC, USA; Shafiq, M.Z., Momina, T.S., Mirza, F., Farooq, M., PE-Miner: Mining structural information to detect malicious executables in real time (2009) Proceedings of the Recent Advances in Intrusion Detection, pp. 121-141. , September 23-25, 2009, France, Springer; Sharif, M., Yegneswaran, V., Saidi, H., Porras, P., Lee, W., Eureka: A framework for enabling static malware analysis (2008) Proceedings of the 13th European Symposium on Research in Computer Security, pp. 481-500. , October 6-8, 2008, Springer, Malaga, Spain; Tian, R., Batten, L., Islam, R., Versteeg, S., An automated classification system based on the strings of Trojan and virus families (2009) Proceedings of the 4th International Conference on Malicious and Unwanted Software (MALWARE'09), pp. 23-30. , October 13-14, 2009, IEEE, Montreal, Canada; Tian, R., Islam, R., Batten, L., Versteeg, S., Differentiating malware from cleanware using behavioural analysis (2010) Proceedings of the 5th International Conference on Malicious and Unwanted Software (MALWARE), pp. 23-30. , October 19-20, 2010, IEEE, Nancy, France; Willems, C., Holz, T., Freiling, F., Toward automated dynamic malware analysis using cwsandbox (2007) IEEE. Secur. Privacy, 5, pp. 32-39; Ye, Y., Wang, D., Li, T., Ye, D., IMDS: Intelligent malware detection system (2007) Proceedings of the 13th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 1043-1047. , August 12-15, 2007, ACM, San Jose, California, USA; You, I., Yim, K., Malware obfuscation techniques: A brief survey (2010) Proceedings of the 2010 International Conference on Broadband, pp. 297-300. , Wireless Computing, Communication and Applications (BWCCA'10), November 4-6, 2010, IEEE, Fukuoka, Japan","Ali, T.; Islamic University of MadinahSaudi Arabia",,,"Medwell Journals",,,,,1816949X,,,,"English","J. Eng. Appl. Sci.",Article,"Final","",Scopus,2-s2.0-85055930187
"Sutanto R.E., Lee S.","57194786751;55716387600;","Ensemble of degraded artificial intelligence modules against adversarial attacks on neural networks",2018,"Journal of Information and Communication Convergence Engineering","16","3",,"148","152",,1,"10.6109/jicce.2018.16.3.148","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055899719&doi=10.6109%2fjicce.2018.16.3.148&partnerID=40&md5=a7285cc93b218b83f9fb47d929cb1bac","Department of Computer Engineering, Dongseo University, Busan, 47011, South Korea","Sutanto, R.E., Department of Computer Engineering, Dongseo University, Busan, 47011, South Korea; Lee, S., Department of Computer Engineering, Dongseo University, Busan, 47011, South Korea","Adversarial attacks on artificial intelligence (AI) systems use adversarial examples to achieve the attack objective. Adversarial examples consist of slightly changed test data, causing AI systems to make false decisions on these examples. When used as a tool for attacking AI systems, this can lead to disastrous results. In this paper, we propose an ensemble of degraded convolutional neural network (CNN) modules, which is more robust to adversarial attacks than conventional CNNs. Each module is trained on degraded images. During testing, images are degraded using various degradation methods, and a final decision is made utilizing a one-hot encoding vector that is obtained by summing up all the output vectors of the modules. Experimental results show that the proposed ensemble network is more resilient to adversarial attacks than conventional networks, while the accuracies for normal images are similar. © The Korea Institute of Information and Communication Engineering.","Adversarial attack; Artificial Intelligence; Image classification",,,,,,"Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) ""Explaining and harnessing adversarial examples,"", , https://arxiv.org/abs/1412.6572; Carlini, N., Wagner, D., 'Towards evaluating the robustness of neural networks,' (2017) Proceedings of IEEE Symposium on Security and Privacy, pp. 39-57. , San Jose, CA; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., 'The limitations of deep learning in adversarial settings,' (2016) Proceedings of IEEE European Symposium on Security and Privacy, pp. 372-387. , Saarbrucken, Germany; Lu, J., Sibai, H., Fabry, E., Forsyth, D., (2017) ""No need to worry about adversarial examples in object detection in autonomous vehicles,"", , https://arxiv.org/abs/1707.03501; Athalye, A., Engstrom, L., Ilyas, A., Kwok, K., (2018) ""Synthesizing robust adversarial examples,"", , https://arxiv.org/abs/1707.07397; Su, J., Vargas, D.V., Kouichi, S., (2018) ""One pixel attack for fooling deep neural networks,"", , https://arxiv.org/abs/1710.08864; Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P., (2016) ""DeepFool: a simple and accurate method to fool deep neural networks,"", , https://arxiv.org/abs/1511.04599; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) ""Detecting adversarial samples from artifacts,"", , https://arxiv.org/abs/1703.00410; Li, X., Li, F., (2017) ""Adversarial examples detection in deep networks with convolutional filter statistics,"", , https://arxiv.org/abs/1612.07767; Sabour, S., Frosst, N., Hinton, G.E., (2017) ""Dynamic routing between capsules,"", , https://arxiv.org/abs/1710.09829; Strauss, T., Hanselmann, M., Junginger, A., Ulmer, H., (2018) ""Ensemble methods as a defense to adversarial perturbations against deep neural networks,"", , https://arxiv.org/abs/1709.03423; He, W., Wei, J., Chen, X., Carlini, N., Song, D., (2017) ""Adversarial example defenses: ensembles of weak defenses are not strong,"", , https://arxiv.org/abs/1706.04701","Lee, S.; Department of Computer Engineering, 47, Jurye-ro, South Korea; email: petrasuk@gmail.com",,,"Korea Institute of Information and Communication Engineering",,,,,22348255,,,,"English","J. Inf. Commun. Converg. Eng.",Article,"Final","",Scopus,2-s2.0-85055899719
"Weerasinghe S., Alpcan T., Erfani S.M., Leckie C., Pourbeik P., Riddle J.","57204512695;56250520000;54791054200;7003524629;24462383600;57204510404;","Deep learning based game-theoretical approach to evade jamming attacks",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11199 LNCS",,,"386","397",,4,"10.1007/978-3-030-01554-1_22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055892318&doi=10.1007%2f978-3-030-01554-1_22&partnerID=40&md5=0d1963ede0a1acf1a01398a76dd92548","Melbourne School of Engineering, The University of Melbourne, Melbourne, Australia; Defence Science and Technology Group, Canberra, Australia; Northrop Grumman Corporation, Falls Church, United States","Weerasinghe, S., Melbourne School of Engineering, The University of Melbourne, Melbourne, Australia; Alpcan, T., Melbourne School of Engineering, The University of Melbourne, Melbourne, Australia; Erfani, S.M., Melbourne School of Engineering, The University of Melbourne, Melbourne, Australia; Leckie, C., Melbourne School of Engineering, The University of Melbourne, Melbourne, Australia; Pourbeik, P., Defence Science and Technology Group, Canberra, Australia; Riddle, J., Northrop Grumman Corporation, Falls Church, United States","Software-defined radios (SDRs) with substantial cognitive (computing) and networking capabilities provide an opportunity for malicious individuals to jam the communications of other legitimate users. Channel hopping is a well known anti-jamming tactic used in order to evade jamming attacks. We model the interaction between a transmitter, who uses chaotic pseudo-random patterns for channel hopping, and a sophisticated jammer, who uses advanced machine learning algorithms to predict the transmitter’s frequency hopping patterns as a non-cooperative security game. We investigate the effectiveness of adversarial distortions in such a scenario to support the anti-jamming efforts by deceiving the jammer’s learning algorithms. The optimal strategies in the formulated game indicate how adversarial distortions should be used by the players at every step of the game in order improve their outcomes. The studied jamming/anti-jamming scenario combines chaotic time series generators, game theory, and online deep learning. © 2018, Springer Nature Switzerland AG.","Adversarial learning; Game theory; Jamming","Cognitive radio; Computation theory; Decision theory; Deep learning; Jamming; Learning algorithms; Security systems; Software radio; Transmitters; Adversarial learning; Chaotic time series; Frequency hopping pattern; Legitimate users; Optimal strategies; Pseudo random pattern; Software-defined radios; Theoretical approach; Game theory",,,,,"Boeing, G., Visual analysis of nonlinear dynamical systems: Chaos, fractals, self-similarity and the limits of prediction (2016) Systems, 4 (4), p. 37; Cong, L., Songgeng, S., Chaotic frequency hopping sequences (1998) IEEE Trans. Commun., 46 (11), pp. 1433-1437; Dabcevic, K., Betancourt, A., Marcenaro, L., Regazzoni, C.S., Intelligent cognitive radio jamming-a game-theoretical approach (2014) EURASIP J. Adv. Sig. Process., 2014 (1), p. 171; Han, M., Xi, J., Xu, S., Yin, F.L., Prediction of chaotic time series based on the recurrent predictor neural network (2004) IEEE Trans. Sig. Process., 52 (12), pp. 3409-3416; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput, 9 (8), pp. 1735-1780; Hu, H., Liu, L., Ding, N., Pseudorandom sequence generator based on the chen chaotic system (2013) Comput. Phys. Commun., 184 (3), pp. 765-768; Kawahara, Y., Sugiyama, M., Change-point detection in time-series data by direct density-ratio estimation (2009) Proceedings of the 2009 SIAM International Conference on Data Mining, pp. 389-400. , SIAM; Laufer, C., (2015) The Hobbyist’s Guide to the RTL-SDR: Really Cheap Software Defined Radio, , CreateSpace Independent Publishing Platform; Liu, S., Yamada, M., Collier, N., Sugiyama, M., Change-point detection in time-series data by relative density-ratio estimation (2013) Neural Netw, 43, pp. 72-83; Nash, J., Non-cooperative games (1951) Ann. Math., 54, pp. 286-295; Pathak, J., Hybrid forecasting of chaotic processes: Using machine learning in conjunction with a knowledge-based model (2018) Corr Abs/1803, 4779; Pual, O., Akta, I., Schnelke, C.J., Abidin, G., Wehrle, K., Gross, J., Machine learning-based jamming detection for IEEE 802.11: Design and experimental evaluation (2014) In: Proceeding of IEEE International Symposium on a World of Wireless, Mobile and Multimedia Networks, p. 110. , (June 2014); Xu, W., Wood, T., Trappe, W., Zhang, Y., Channel surfing and spatial retreats: Defenses against wireless denial of service (2004) Proceedings of the 3Rd ACM Workshop on Wireless Security, pp. 80-89. , Wise 2004; Zhu, Q., Saad, W., Han, Z., Poor, H.V., Başar, T., Eavesdropping and jamming in next-generation wireless networks: A game-theoretic approach (2011) Military Communications Conference, 2011-MILCOM 2011, pp. 119-124. , IEEE","Weerasinghe, S.; Melbourne School of Engineering, Australia; email: pweerasinghe@student.unimelb.edu.au","Bushnell L.Poovendran R.Basar T.",,"Springer Verlag","9th International Conference on Decision and Game Theory for Security, GameSec 2018","29 October 2018 through 31 October 2018",,220039,03029743,9783030015534,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","",Scopus,2-s2.0-85055892318
"Rahmattalabi A., Vayanos P., Tambe M.","57189899513;23478550500;7006395526;","A robust optimization approach to designing near-optimal strategies for constant-sum monitoring games",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11199 LNCS",,,"603","622",,4,"10.1007/978-3-030-01554-1_35","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055889845&doi=10.1007%2f978-3-030-01554-1_35&partnerID=40&md5=b063c57aed0ac87b9d3f0608965ca0b8","University of Southern California, Los Angeles, United States","Rahmattalabi, A., University of Southern California, Los Angeles, United States; Vayanos, P., University of Southern California, Los Angeles, United States; Tambe, M., University of Southern California, Los Angeles, United States","We consider the problem of monitoring a set of targets, using scarce monitoring resources (e.g., sensors) that are subject to adversarial attacks. In particular, we propose a constant-sum Stackelberg game in which a defender (leader) chooses among possible monitoring locations, each covering a subset of targets, while taking into account the monitor failures induced by a resource-constrained attacker (follower). In contrast to the previous Stackelberg security models in which the defender uses mixed strategies, here, the defender must commit to pure strategies. This problem is highly intractable as both players’ strategy sets are exponentially large. Thus, we propose a solution methodology that automatically partitions the set of adversary’s strategies and maps each subset to a coverage policy. These policies are such that they do not overestimate the defender’s payoff. We show that the partitioning problem can be reformulated exactly as a mixed-integer linear program (MILP) of moderate size which can be solved with off-the-shelf solvers. We demonstrate the effectiveness of our proposed approach in various settings. In particular, we illustrate that even with few policies, we are able to closely approximate the optimal solution and outperform the heuristic solutions. © 2018, Springer Nature Switzerland AG.",,"Decision theory; Integer programming; Optimal systems; Patient monitoring; Heuristic solutions; Mixed integer linear program; Monitoring locations; Optimal solutions; Partitioning problem; Robust optimization; Solution methodology; Stackelberg Games; Game theory",,,,,"Bard, N., Nicholas, D., Szepesvaári, C., Bowling, M., Decision-theoretic clustering of strategies (2015) Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems, pp. 17-25. , International Foundation for Autonomous Agents and Multiagent Systems; Basak, A., Abstraction using analysis of subgames (2016) Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, pp. 4196-4197. , AAAI Press; Ben-Tal, A., El Ghaoui, L., Nemirovski, A., (2009) Robust Optimization, , Princeton University Press, Princeton; Ben-Tal, A., Goryashko, A., Guslitzer, E., Nemirovski, A., Adjustable robust solutions of uncertain linear programs (2004) Math. Program., 99 (2), pp. 351-376; Bertsimas, D., Brown, D.B., Caramanis, C., Theory and applications of robust optimization (2011) SIAM Rev, 53 (3), pp. 464-501; Bertsimas, D., Caramanis, C., Finite adaptability in multistage linear optimization (2010) IEEE Trans. Autom. Control, 55 (12), pp. 2751-2766; Bogunovic, I., Mitrović, S., Scarlett, J., Cevher, V., (2017) Robust Submodular Maximization: A Non-Uniform Partitioning Approach, , arXiv preprint arXiv; Bošanskỳ, B., Jiang, A.X., Tambe, M., Kiekintveld, C., Combining compact representation and incremental generation in large games with sequential strategies (2015) Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence, pp. 812-818. , AAAI Press; Brown, G., Carlyle, M., Salmerón, J., Wood, K., Defending critical infrastructure (2006) Interfaces, 36 (6), pp. 530-544; Dahan, M., Sela, L., Amin, S., (2017) Network Monitoring under Strategic Disruptions, , arXiv preprint arXiv; Hanasusanto, G.A., Kuhn, D., Wiesemann, W., K-adaptability in two-stage robust binary programming (2015) Oper. Res., 63 (4), pp. 877-891; Jain, M., Korzhyk, D., Vaněk, O., Conitzer, V., Pěchouček, M., Tambe, M., A double oracle algorithm for zero-sum security games on graphs (2011) 10Th International Conference on Autonomous Agents and Multiagent Systems, 1, pp. 327-334; Krause, A., McMahan, H.B., Guestrin, C., Gupta, A., Robust submodular observation selection (2008) J. Mach. Learn. Res, 9 (Dec), pp. 2761-2801; Orlin, J.B., Schulz, A.S., Udwani, R., Robust monotone submodular function maximization (2016) IPCO 2016. LNCS, 9682, pp. 312-324. , Louveaux, Q., Skutella, M. (eds.), Springer, Cham, https://doi.org/10.1007/978-3-319-33461-5 26; Pita, J., Tambe, M., Kiekintveld, C., Cullen, S., Steigerwald, E., GUARDS: Game theoretic security allocation on a national scale (2011) 10Th International Conference on Autonomous Agents and Multiagent Systems, 1, pp. 37-44. , International Foundation for Autonomous Agents and Multiagent Systems; Tsai, J., Kiekintveld, C., Ordonez, F., Tambe, M., Rathi, S., (2009) Iris-A Tool for Strategic Security Allocation in Transportation Networks; Tzoumas, V., Gatsis, K., Jadbabaie, A., Pappas, G.J., (2017) Resilient Monotone Submodular Function Maximization, , arXiv preprint arXiv; Vayanos, P., Kuhn, D., Rustem, B., Decision rules for information discovery in multi-stage stochastic programming (2011) 2011 50Th IEEE Conference on Decision and Control and European Control Conference (CDC-ECC), pp. 7368-7373. , IEEE","Rahmattalabi, A.; University of Southern CaliforniaUnited States; email: rahmatta@usc.edu","Bushnell L.Poovendran R.Basar T.",,"Springer Verlag","9th International Conference on Decision and Game Theory for Security, GameSec 2018","29 October 2018 through 31 October 2018",,220039,03029743,9783030015534,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","",Scopus,2-s2.0-85055889845
"Ma Y., Jun K.-S., Li L., Zhu X.","57204513838;36470289800;55730767800;55696704600;","Data poisoning attacks in contextual bandits",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11199 LNCS",,,"186","204",,12,"10.1007/978-3-030-01554-1_11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055885113&doi=10.1007%2f978-3-030-01554-1_11&partnerID=40&md5=ec27e72b8b1aa2467ac32191258e38ba","University of Wisconsin-Madison, Madison, United States; Google Brain, Kirkland, WA, United States","Ma, Y., University of Wisconsin-Madison, Madison, United States; Jun, K.-S., University of Wisconsin-Madison, Madison, United States; Li, L., Google Brain, Kirkland, WA, United States; Zhu, X., University of Wisconsin-Madison, Madison, United States","We study offline data poisoning attacks in contextual bandits, a class of reinforcement learning problems with important applications in online recommendation and adaptive medical treatment, among others. We provide a general attack framework based on convex optimization and show that by slightly manipulating rewards in the data, an attacker can force the bandit algorithm to pull a target arm for a target contextual vector. The target arm and target contextual vector are both chosen by the attacker. That is, the attacker can hijack the behavior of a contextual bandit. We also investigate the feasibility and the side effects of such attacks, and identify future directions for defense. Experiments on both synthetic and real-world data demonstrate the efficiency of the attack algorithm. © 2018, Springer Nature Switzerland AG.","Adversarial attack; Contextual bandit; Data poisoning","Convex optimization; Decision theory; Medical problems; Reinforcement learning; Adversarial attack; Contextual bandits; Medical treatment; Offline data; Poisoning attacks; Real-world; Side effect; Game theory",,,,,"Abbasi-Yadkori, Y., Pál, D., Szepesvári, C., Improved algorithms for linear stochastic bandits (2011) Advances in Neural Information Processing Systems (NIPS), pp. 2312-2320; Agarwal, A., (2016) Making Contextual Decisions with Low Technical Debt, , coRR abs/1606.03966; Alfeld, S., Zhu, X., Barford, P., Data poisoning attacks against autoregressive models (2016) The 30Th AAAI Conference on Artificial Intelligence; Auer, P., Cesa-Bianchi, N., Fischer, P., Finite-time analysis of the multiarmed bandit problem (2002) Mach. Learn., 47 (2-3), pp. 235-256; Biggio, B., Nelson, B., Laskov, P., Poisoning attacks against support vector machines (2012) Proceedings of the 29Th International Coference on International Conference on Machine Learning (ICML), pp. 1467-1474; Chapelle, O., Manavoglu, E., Rosales, R., Simple and scalable response prediction for display advertising (2014) ACM Trans. Intell. Syst. Technol., 5 (4), pp. 1-61; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations; Greenewald, K., Tewari, A., Murphy, S.A., Klasnja, P.V., Action centered contextual bandits (2017) Advances in Neural Information Processing Systems 30 (NIPS), pp. 5979-5987; Jagielski, M., Oprea, A., Biggio, B., Liu, C., Nita-Rotaru, C., Li, B., (2018) Manipulating Machine Learning: Poisoning Attacks and Countermeasures for Regression Learning, , arXiv preprint arXiv; Joseph, A.D., Nelson, B., Rubinstein, B.I.P., Tygar, J., (2018) Adversarial Machine Learning, , Cambridge University Press, Cambridge; Kuleshov, V., Precup, D., (2014) Algorithms for Multi-Armed Bandit Problems, , coRR abs/1402.6028; Li, B., Wang, Y., Singh, A., Vorobeychik, Y., Data poisoning attacks on factorization-based collaborative filtering (2016) Advances in Neural Information Processing Systems, pp. 1885-1893; Li, L., Chu, W., Langford, J., Schapire, R.E., A contextual-bandit approach to personalized news article recommendation (2010) Proceedings of the 19Th International Conference on World Wide Web (WWW), pp. 661-670; Mei, S., Zhu, X., The security of latent Dirichlet allocation (2015) The 18Th International Conference on Artificial Intelligence and Statistics, , AISTATS; Mei, S., Zhu, X., Using machine teaching to identify optimal training-set attacks on machine learners (2015) The 29Th AAAI Conference on Artificial Intelligence; Ng, A.Y., Harada, D., Russell, S.J., Policy invariance under reward transformations: Theory and application to reward shaping (1999) Proceedings of the 16Th International Conference on Machine Learning (ICML), pp. 278-287; Zhao, M., An, B., Yu, Y., Liu, S., Pan, S.J., Data poisoning attacks on multi-task relationship learning (2018) Proceedings of the 32Nd AAAI Conference on Artificial Intelligence, pp. 2628-2635; Zhu, X., Machine teaching: An inverse problem to machine learning and an approach toward optimal education (2015) The 29Th AAAI Conference on Artificial Intelligence (AAAI “Blue Sky” Senior Member Presentation Track; Zhu, X., Singla, A., Zilles, S., Rafferty, A.N., (2018) An Overview of Machine Teaching. Arxiv E-Prints, , https://arxiv.org/abs/1801.05927, January","Ma, Y.; University of Wisconsin-MadisonUnited States; email: ma234@wisc.edu","Bushnell L.Poovendran R.Basar T.",,"Springer Verlag","9th International Conference on Decision and Game Theory for Security, GameSec 2018","29 October 2018 through 31 October 2018",,220039,03029743,9783030015534,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85055885113
"Kiumarsi B., Başar T.","54897906900;7102588845;","Distributed aggregative games on graphs in adversarial environments",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11199 LNCS",,,"296","313",,,"10.1007/978-3-030-01554-1_17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055878120&doi=10.1007%2f978-3-030-01554-1_17&partnerID=40&md5=f8de2e2ac8e2ab974b25cf9c2613b3ad","Coordinated Science Laboratory, University of Illinois at Urbana-Champaign, 1308 West Main Street, Urbana, IL  61801, United States","Kiumarsi, B., Coordinated Science Laboratory, University of Illinois at Urbana-Champaign, 1308 West Main Street, Urbana, IL  61801, United States; Başar, T., Coordinated Science Laboratory, University of Illinois at Urbana-Champaign, 1308 West Main Street, Urbana, IL  61801, United States","Existing solutions to aggregative games assume that all players are fully trustworthy for cooperative tasks or, in a worst-case scenario, are selfish players with no intent to intentionally harm the network. Nevertheless, the need to believe that players will behave consistently exposes the network to vulnerabilities associated with cyber-physical attacks. This paper investigates the effects of cyber-physical attacks on the outcome of distributed aggregative games (DAGs). More specifically, we are seeking to answer two main questions: (1) how a stealthy attack can deviate the game outcome from a cooperative Nash equilibrium, and by doing so, (2) by how much efficiency of a DAG degrades. To this end, we first show that adversaries can stealthily manipulate the outcome of a DAG by compromising the Nash equilibrium solution and consequently lead to an emergent misbehavior or no emergent behavior. This study will intensify the urgency of designing novel resilient solutions to DAGs so that the overall network sustains some notion of acceptable global behavior in the presence of malicious agents. Finally, we corroborate and illustrate our results by providing simulation examples. Simulations reveal that the adverse effect of a compromised agent is considerably worse than that of a selfish agent. © 2018, Springer Nature Switzerland AG.","Adversarial environment; Distributed aggregative games","Computation theory; Computer crime; Cyber Physical System; Decision theory; Adversarial environments; Cooperative tasks; Distributed aggregative games; Emergent behaviors; Global behaviors; Overall networks; Simulation example; Worst case scenario; Game theory",,,,,"Cornes, R., Hartley, R., Fully aggregative games (2012) Econ. Lett., 116 (3), pp. 631-633; Huang, M., Caines, P.E., Malhame, R.P., Large-population cost-coupled LQG problems with nonuniform agents: Individual-mass behavior and decentralized Nash equilibria (2007) IEEE Trans. Autom. Control, 52, pp. 1560-1571; Lasry, J.-M., Lions, P.-L., Mean field games (2007) Jpn. J. Math., 2, pp. 229-260; Bauso, D., Pesenti, R., Mean field linear quadratic games with set up costs (2013) Dyn. Games Appl., 3, pp. 89-104; Grammatico, S., Parise, F., Colombino, M., Lygeros, J., Decentralized convergence to Nash equilibria in constrained deterministic mean field control (2016) IEEE Trans. Autom. Control, 61, pp. 3315-3329; Bauso, D., Tembine, H., Başar, T., Robust mean field games (2016) Dyn. Games Appl., 6, pp. 277-303; Moon, J., Başar, T., Linear quadratic risk-sensitive and robust mean field games (2017) IEEE Trans. Autom. Control, 62, pp. 1062-1077; Mohsenian-Rad, A.H., Wong, V.W.S., Jatskevich, J., Schober, R., Leon-Garcia, A., Autonomous demand-side management based on game-theoretic energy consumption scheduling for the future smart grid (2010) IEEE Trans. Smart Grid, 1, pp. 320-331; Bagagiolo, F., Bauso, D., Mean-field games and dynamic demand management in power grids (2014) Dyn. Games Appl., 4, pp. 155-176; Chen, H., Li, Y., Louie, R.H.Y., Vucetic, B., Autonomous demand side management based on energy consumption scheduling and instantaneous load billing: An aggregative game approach (2014) IEEE Trans. Smart Grid, 5, pp. 1744-1754; Ma, Z., Callaway, D.S., Hiskens, I.A., Decentralized charging control of large populations of plug-in electric vehicles (2013) IEEE Trans. Control Syst. Technol., 21, pp. 67-78; Parise, F., Colombino, M., Grammatico, S., Lygeros, J., Mean field constrained charging policy for large populations of plug-in electric vehicles (2014) 53Rd IEEE Conference on Decision and Control, pp. 5101-5106. , December; Alpcan, T., Başar, T., (2005) Distributed Algorithms for Nash Equilibria of Flow Control Games, pp. 473-498. , Birkhäuser, Boston; Başar, T., Control and game-theoretic tools for communication networks (2007) Appl. Comput. Math., 6 (2), pp. 104-125; Barrera, J., Garcia, A., Dynamic incentives for congestion control (2015) IEEE Trans. Autom. Control, 60, pp. 299-310; Kizilkale, A.C., Mannor, S., Caines, P.E., Large scale real-time bidding in the smart grid: A mean field framework (2012) 2012 IEEE 51St IEEE Conference on Decision and Control, CDC, pp. 3680-3687. , December; Koshal, J., Nedi, A., Shanbhag, U.V., A gossip algorithm for aggregative games on graphs (2012) 2012 IEEE 51St IEEE Conference on Decision and Control, CDC, pp. 4840-4845. , December; Swenson, B., Kar, S., Xavier, J., Distributed learning in large-scale multi-agent games: A modified fictitious play approach (2012) 2012 Conference Record of the Forty Sixth Asilomar Conference on Signals, Systems and Computers, ASILOMAR, pp. 1490-1495. , November; Koshal, J., Nedić, A., Shanbhag, U.V., Distributed algorithms for aggregative games on graphs (2016) Oper. Res., 64 (3), pp. 680-704; Parise, F., Gentile, B., Grammatico, S., Lygeros, J., Network aggregative games: Distributed convergence to Nash equilibria (2015) 2015 54Th IEEE Conference on Decision and Control, CDC, pp. 2295-2300. , December; Başar, T., Olsder, G.J., (1999) Dynamic Noncooperative Game Theory. SIAM, , Philadelphia; Ye, M., Hu, G., Game design and analysis for price-based demand response: An aggregate game approach (2017) IEEE Trans. Cybern., 47, pp. 720-730; Teixeira, A., Sandberg, H., Johansson, K.H., Networked control systems under cyber attacks with applications to power networks (2010) Proceedings of the 2010 American Control Conference, pp. 3690-3696. , June; Sundaram, S., Hadjicostis, C.N., Distributed function calculation via linear iterative strategies in the presence of malicious agents (2011) IEEE Trans. Autom. Control, 56, pp. 1495-1508; Pasqualetti, F., Bicchi, A., Bullo, F., Consensus computation in unreliable networks: A system theoretic approach (2012) IEEE Trans. Autom. Control, 57, pp. 90-104; Pasqualetti, F., Drfler, F., Bullo, F., Attack detection and identification in cyberphysical systems (2013) IEEE Trans. Autom. Control, 58, pp. 2715-2729; Zhu, M., Martnez, S., On the performance analysis of resilient networked control systems under replay attacks (2014) IEEE Trans. Autom. Control, 59, pp. 804-808; Zhu, Q., Başar, T., Game-theoretic methods for robustness, security, and resilience of cyberphysical control systems: Games-in-games principle for optimal cross-layer resilient control systems (2015) IEEE Control Syst, 35, pp. 46-65; Mo, Y., Sinopoli, B., Secure estimation in the presence of integrity attacks (2015) IEEE Trans. Autom. Control, 60, pp. 1145-1151; Khanafer, A., Baar, T., Robust distributed averaging: When are potential-theoretic strategies optimal? (2016) IEEE Trans. Autom. Control, 61, pp. 1767-1779; Moghadam, R., Modares, H., An internal model principle for the attacker in distributed control systems (2017) 2017 IEEE 56Th Annual Conference on Decision and Control, CDC, pp. 6604-6609. , December; Kamdem, G., Kamhoua, C., Lu, Y., Shetty, S., Njilla, L., A Markov game theoritic approach for power grid security (2017) 2017 IEEE 37Th International Conference on Distributed Computing Systems Workshops, ICDCSW, pp. 139-144. , June; Freeman, R.A., Yang, P., Lynch, K.M., Stability and convergence properties of dynamic average consensus estimators (2006) Proceedings of the 45Th IEEE Conference on Decision and Control, pp. 338-343. , December; Haghshenas, H., Badamchizadeh, M.A., Baradarannia, M., Containment control of heterogeneous linear multi-agent systems (2015) Automatica, 54, pp. 210-216","Kiumarsi, B.; Coordinated Science Laboratory, 1308 West Main Street, United States; email: kiumarsi@illinois.edu","Bushnell L.Poovendran R.Basar T.",,"Springer Verlag","9th International Conference on Decision and Game Theory for Security, GameSec 2018","29 October 2018 through 31 October 2018",,220039,03029743,9783030015534,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","",Scopus,2-s2.0-85055878120
"Nguyen L., Wang S., Sinha A.","57212419521;57204512130;52063804200;","A learning and masking approach to secure learning",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11199 LNCS",,,"453","464",,14,"10.1007/978-3-030-01554-1_26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055876928&doi=10.1007%2f978-3-030-01554-1_26&partnerID=40&md5=d8caa81bd4e07da762ed31d34a0c160f","University of Michigan, Ann Arbor, United States","Nguyen, L., University of Michigan, Ann Arbor, United States; Wang, S., University of Michigan, Ann Arbor, United States; Sinha, A., University of Michigan, Ann Arbor, United States","Deep Neural Networks (DNNs) have been shown to be vulnerable against adversarial examples, which are data points cleverly constructed to fool the classifier. In this paper, we introduce a new perspective on the problem. We do so by first defining robustness of a classifier to adversarial exploitation. Further, we categorize attacks in literature into high and low perturbation attacks. Next, we show that the defense problem can be posed as a learning problem itself and find that this approach effective against high perturbation attacks. For low perturbation attacks, we present a classifier boundary masking method that uses noise to randomly shift the classifier boundary at runtime. We also show that both our learning and masking based defense can work simultaneously to protect against multiple attacks. We demonstrate the efficacy of our techniques by experimenting with the MNIST and CIFAR-10 datasets. © 2018, Springer Nature Switzerland AG.",,"Decision theory; Deep neural networks; Network security; Data points; Learning problem; Runtimes; Game theory",,,,,"Anthony, M., Bartlett, P.L., (2009) Neural Network Learning: Theoretical Foundations, , 1st edn. Cambridge University Press, New York; Baluja, S., Fischer, I., (2017) Adversarial Transformation Networks: Learning to Generate Adversarial Examples, , http://arxiv.org/abs/1703.09387, CoRR abs/1703.09387; Biggio, B., Roli, F., (2017) Wild Patterns: Ten Years after the Rise of Adversarial Machine Learning, , arXiv preprint arXiv; Carlini, N., Wagner, D., (2017) Magnet and “efficient Defenses against Adversarial attacks” are Not Robust to Adversarial Examples, , arXiv preprint arXiv; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP), pp. 39-57. , IEEE; Chen, X., Li, B., Vorobeychik, Y., (2016) Evaluation of Defensive Methods for Dnns against Multiple Adversarial Evasion Models, , https://openreview.net/forum? id=ByToKu9ll&noteId=ByToKu9ll; Cisse, M., Bojanowski, P., Grave, E., Dauphin, Y., Usunier, N., (2017) Parseval Networks: Improving Robustness to Adversarial Examples, , arXiv preprint arXiv; Fawzi, A., Fawzi, O., Frossard, P., Fundamental limits on adversarial robustness (2015) Proceedings of ICML, Workshop on Deep Learning; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2014) Corr Abs/1412, p. 6572. , http://arxiv.org/abs/1412.6572; Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., (2017) On the (Sta-Tistical) Detection of Adversarial Examples, , arXiv preprint arXiv; Huang, R., Xu, B., Schuurmans, D., Szepesvári, C., (2015) Learning with a Strong Adversary, , arXiv preprint arXiv; Kolter, J.Z., Wong, E., (2017) Provable Defenses against Adversarial Examples via the Convex Outer Adversarial Polytope, , arXiv preprint arXiv; Li, B., Vorobeychik, Y., Feature cross-substitution in adversarial classification (2014) Advances in Neural Information Processing Systems, pp. 2087-2095; Li, B., Vorobeychik, Y., Chen, X., (2016) A General Retraining Framework for Scalable Adversarial Classification, , arXiv preprint arXiv; Li, X., Li, F., (2016) Adversarial Examples Detection in Deep Networks with Convolutional Filter Statistics, , arXiv preprint arXiv; Lowd, D., Meek, C., Adversarial learning (2005) ACM SIGKDD. ACM; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , arXiv preprint arXiv; Meng, D., Chen, H., Magnet: A two-pronged defense against adversarial examples (2017) ACM Conference on Computer and Communications Security; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., (2016) Practical Black-Box Attacks against Deep Learning Systems Using Adversarial Examples, , arXiv preprint arXiv; Papernot, N., McDaniel, P., Sinha, A., Wellman, M., (2016) Towards the Science of Security and Privacy in Machine Learning, , arXiv preprint arXiv; Sinha, A., Kar, D., Tambe, M., Learning adversary behavior in security games: A PAC model perspective (2016) Conference on Autonomous Agents & Multiagent Systems; Tramèr, F., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2017) The Space of Transferable Adversarial Examples, , arXiv preprint arXiv; Tygar, J., Adversarial machine learning (2011) IEEE Internet Comput, 15 (5), pp. 4-6; Wang, B., Gao, J., Qi, Y., (2016) A Theoretical Framework for Robustness of (Deep) Classifiers under Adversarial Noise, , arXiv preprint arXiv; Xu, W., Evans, D., Qi, Y., (2017) Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks, , arXiv preprint arXiv","Sinha, A.; University of MichiganUnited States; email: arunesh@umich.edu","Bushnell L.Poovendran R.Basar T.",,"Springer Verlag","9th International Conference on Decision and Game Theory for Security, GameSec 2018","29 October 2018 through 31 October 2018",,220039,03029743,9783030015534,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85055876928
[No author name available],[No author id available],"9th International Conference on Decision and Game Theory for Security, GameSec 2018",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11199 LNCS",,,"","",636,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055875653&partnerID=40&md5=d7d56e0c69a95f35b5d30f51ff7fb51c",,"","The proceedings contain 36 papers. The special focus in this conference is on Decision and Game Theory for Security. The topics include: Data poisoning attacks in contextual bandits; analysis and computation of adaptive defense strategies against advanced persistent threats for cyber-physical systems; multi-sided advertising markets: Dynamic mechanisms and incremental user compensations; a game-theoretic analysis of the adversarial boyd-kuramoto model; a game theoretic analysis of the twitter follow-unfollow mechanism; game theoretic analysis of a byzantine attacker in vehicular mix-zones; distributed aggregative games on graphs in adversarial environments; disappointment-aversion in security games; moving target defense for the placement of intrusion detection systems in the cloud; cyber-warranties as a quality signal for information security products; approximating power indices to assess cybersecurity criticality; a differentially private and truthful incentive mechanism for traffic offload to public transportation; deep learning based game-theoretical approach to evade jamming attacks; towards scientific incident response; rational trust modeling; scaling-Up stackelberg security games applications using approximations; a learning and masking approach to secure learning; towards true decentralization: A blockchain consensus protocol based on game theory and randomness; a game theoretical framework for inter-process adversarial intervention detection; cyber-insurance as a signaling game: Self-reporting and external security audits; game theoretic security framework for quantum key distribution; a bayesian multi-armed bandit approach for identifying human vulnerabilities; hypothesis testing game for cyber deception; algorithms for subgame abstraction with applications to cyber defense; a two-stage deception game for network defense; imbalanced collusive security games; a robust optimization approach to designing near-optimal strategies for constant-sum monitoring games.",,,,,,,,,"Bushnell L.Poovendran R.Basar T.",,"Springer Verlag","9th International Conference on Decision and Game Theory for Security, GameSec 2018","29 October 2018 through 31 October 2018",,220039,03029743,9783030015534,,,"English","Lect. Notes Comput. Sci.",Conference Review,"Final","",Scopus,2-s2.0-85055875653
"Han Y., Rubinstein B.I.P., Abraham T., Alpcan T., De Vel O., Erfani S., Hubczenko D., Leckie C., Montague P.","57190989480;7005303997;8750008900;56250520000;56429241700;54791054200;57204509774;7003524629;7004572755;","Reinforcement learning for autonomous defence in software-defined networking",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11199 LNCS",,,"145","165",,20,"10.1007/978-3-030-01554-1_9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055868724&doi=10.1007%2f978-3-030-01554-1_9&partnerID=40&md5=70fb1f55557c827ba5449a1f5ecf2ec0","School of Computing and Information Systems, The University of Melbourne, Parkville, Australia; Defence Science and Technology Group, Edinburgh, Australia","Han, Y., School of Computing and Information Systems, The University of Melbourne, Parkville, Australia; Rubinstein, B.I.P., School of Computing and Information Systems, The University of Melbourne, Parkville, Australia; Abraham, T., Defence Science and Technology Group, Edinburgh, Australia; Alpcan, T., School of Computing and Information Systems, The University of Melbourne, Parkville, Australia; De Vel, O., Defence Science and Technology Group, Edinburgh, Australia; Erfani, S., School of Computing and Information Systems, The University of Melbourne, Parkville, Australia; Hubczenko, D., Defence Science and Technology Group, Edinburgh, Australia; Leckie, C., School of Computing and Information Systems, The University of Melbourne, Parkville, Australia; Montague, P., Defence Science and Technology Group, Edinburgh, Australia","Despite the successful application of machine learning (ML) in a wide range of domains, adaptability—the very property that makes machine learning desirable—can be exploited by adversaries to contaminate training and evade classification. In this paper, we investigate the feasibility of applying a specific class of machine learning algorithms, namely, reinforcement learning (RL) algorithms, for autonomous cyber defence in software-defined networking (SDN). In particular, we focus on how an RL agent reacts towards different forms of causative attacks that poison its training process, including indiscriminate and targeted, white-box and black-box attacks. In addition, we also study the impact of the attack timing, and explore potential countermeasures such as adversarial training. © 2018, Springer Nature Switzerland AG.","Adversarial reinforcement learning; Adversarial training; Cyber security; Software-defined networking","Artificial intelligence; Decision theory; Game theory; Learning algorithms; Software defined networking; Black boxes; Cyber defences; Cyber security; Software defined networking (SDN); Specific class; Training process; White box; Reinforcement learning",,,,,"Amazon EC2 Instance Types – Amazon Web Services (AWS), , https://aws.amazon.com/ec2/instance-types/; https://www.opennetworking.org/wp-content/uploads/2013/02/TRSDNARCH1.006062014.pdf, Technical report, June 2014; (2017) An Instant Virtual Network on Your Laptop, , http://mininet.org/; (2017), https://www.opendaylight.org/; Athalye, A., Carlini, N., Wagner, D., (2018) Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples, , arXiv, [cs], February; Barreno, M., Nelson, B., Joseph, A.D., Tygar, J.D., The security of machine learning (2010) Mach. Learn., 81 (2), pp. 121-148; Beaudoin, L., (2009) Autonomic Computer Network Defence Using Risk States and Reinforcement Learning, , Ph.D. thesis, University of Ottawa (Canada); Behzadan, V., Munir, A., (2017) Vulnerability of Deep Reinforcement Learning to Policy Induction Attacks, , eprint arXiv; Bhagoji, A.N., Cullina, D., Mittal, P., (2017) Dimensionality Reduction as a Defense against Evasion Attacks on Machine Learning Classifiers, , arXiv; Biggio, B., Security evaluation of support vector machines in adversarial environments (2014) Support Vector Machines Applications, pp. 105-153. , https://doi.org/10.1007/978-3-319-02300-74, Ma, Y., Guo, G. (eds.) , Springer, Cham; Biggio, B., Nelson, B., Laskov, P., Poisoning attacks against support vector machines (2012) Proceedings of the 29Th International Conference on International Conference on Machine Learning, pp. 1467-1474. , Omnipress, Edinburgh; Burkard, C., Lagesse, B., Analysis of causative attacks against SVMs learning from data streams (2017) Proceedings of the 3Rd ACM on International Workshop on Security and Privacy Analytics, pp. 31-36. , ACM, New York; Carlini, N., Wagner, D., (2016) Defensive Distillation is Not Robust to Adversarial Examples, , arXiv; Carlini, N., Wagner, D., (2016) Towards Evaluating the Robustness of Neural Networks, , eprint arXiv; Carlini, N., Wagner, D., (2017) Adversarial Examples are Not Easily Detected: Bypassing Ten Detection Methods, , eprint arXiv; Chung, S.P., Mok, A.K., Advanced allergy attacks: Does a corpus really help? (2007) RAID 2007. LNCS, 4637, pp. 236-255. , Kruegel, C., Lippmann, R., Clark, A. (eds.) , Springer, Heidelberg, https://doi.org/10.1007/978-3-540-74320-0 13; Das, N., (2017) Keeping the Bad Guys Out: Protecting and Vaccinating Deep Learning with JPEG Compression, , eprint arXiv, May; Diakonikolas, I., Kamath, G., Kane, D.M., Li, J., Moitra, A., Stewart, A., Robust estimators in high dimensions without the computational intractability (2016) Proceedings of the 2016 IEEE 57Th Annual Symposium on Foundations of Computer Science (FOCS), pp. 655-664. , October; Everitt, T., Krakovna, V., Orseau, L., Hutter, M., Legg, S., (2017) Reinforcement Learning with a Corrupted Reward Channel, , eprint arXiv; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts, , eprint arXiv; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , eprint arXiv; Han, Y., Rubinstein, B.I.P., (2017) Adequacy of the Gradient-Descent Method for Classifier Evasion Attacks, , arXiv:, April; Hasselt, H.V., Double Q-learning (2010) Advances in Neural Information Processing Systems, 23, pp. 2613-2621. , Lafferty, J.D., Williams, C.K.I., Shawe-Taylor, J., Zemel, R.S., Culotta, A. (eds.), Curran Associates, Inc; Hasselt, H.V., Guez, A., Silver, D., (2015) Deep Reinforcement Learning with Double Q-Learning, , eprint arXiv:, September; He, W., Wei, J., Chen, X., Carlini, N., Song, D., (2017) Adversarial Example Defenses: Ensembles of Weak Defenses are Not Strong, , eprint arXiv; Hosseini, H., Chen, Y., Kannan, S., Zhang, B., Poovendran, R., (2017) Blocking Transferability of Adversarial Examples in Black-Box Learning Systems, , eprint arXiv; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I., Tygar, J., Adversarial machine learning (2011) Proceedings of the 4Th ACM Workshop on Security and Artificial Intelligence, pp. 43-58. , ACM; Huang, S., Papernot, N., Goodfellow, I., Duan, Y., Abbeel, P., (2017) Adversarial Attacks on Neural Network Policies, , eprint arXiv; Koh, P.W., Liang, P., (2017) Understanding Black-Box Predictions via Influence Functions., , arXiv:, [cs, stat], March; Laishram, R., Phoha, V.V., (2016) Curie: A Method for Protecting SVM Classifier from Poisoning Attack., , arXiv:, [cs], June; Li, B., Vorobeychik, Y., Feature cross-substitution in adversarial classification (2014) Proceedings of the 2014 NIPS, NIPS 2014, pp. 2087-2095. , MIT Press, Cambridge; Li, B., Wang, Y., Singh, A., Vorobeychik, Y., (2016) Data Poisoning Attacks on Factorization-Based Collaborative Filtering, , eprint arXiv; Li, X., Li, F., (2016) Adversarial Examples Detection in Deep Networks with Convolutional Filter Statistics., , arXiv:, [cs], December; Lin, Y.C., Hong, Z.W., Liao, Y.H., Shih, M.L., Liu, M.Y., Sun, M., (2017) Tactics of Adversarial Attack on Deep Reinforcement Learning Agents, , eprint arXiv:, March; Medved, J., Varga, R., Tkacik, A., Gray, K., OpenDaylight: Towards a model-driven SDN controller architecture (2014) Proceedings of IEEE International Symposium on a World of Wireless, Mobile and Multimedia Networks, pp. 1-6; Mei, S., Zhu, X., Using machine teaching to identify optimal training-set attacks on machine learners (2015) Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence, pp. 2871-2877. , AAAI Press, Austin; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., (2017) On Detecting Adversarial Perturbations, , eprint arXiv; Mnih, V., Asynchronous methods for deep reinforcement learning (2016) Proceedings of the 33Rd International Conference on International Conference on Machine Learning, ICML 2016, 48, pp. 1928-1937. , JMLR.org, New York; Mnih, V., (2013) Playing Atari with Deep Reinforcement Learning, , CoRR abs/1312.5602; Moore, D., Shannon, C., Brown, D.J., Voelker, G.M., Savage, S., Inferring internet denial-of-service activity (2006) ACM Trans. Comput. Syst., 24 (2), pp. 115-139; Moosavi-Dezfooli, S.M., Fawzi, A., Fawzi, O., Frossard, P., (2016) Universal Adversarial Perturbations, , eprint arXiv; Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P., DeepFool: A simple and accurate method to fool deep neural networks (2016) CVPR, pp. 2574-2582; Nelson, B., Exploiting machine learning to subvert your spam filter (2008) Proceedings of the First USENIX Workshop on Large-Scale Exploits and Emergent Threats (LEET 2008); Nelson, B., Query strategies for evading convex-inducing classifiers (2012) J. Mach. Learn. Res, 13 (May), pp. 1293-1332; Newsome, J., Karp, B., Song, D., Paragraph: Thwarting signature learning by training maliciously (2006) RAID 2006. LNCS, 4219, pp. 81-105. , Zamboni, D., Kruegel, C. (eds.), Springer, Heidelberg, https://doi.org/10.1007/11856214 5; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) CVPR, pp. 427-436; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-Box Attacks Using Adversarial Samples, , eprint arXiv; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., (2016) Practical Black-Box Attacks against Deep Learning Systems Using Adversarial Examples, , eprint arXiv; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Proceedings of the European Symposium on Security & Privacy, pp. 372-387; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., (2015) Distillation as a Defense to Adversarial Perturbations against Deep Neural Networks, , eprint arXiv; Pinto, L., Davidson, J., Sukthankar, R., Gupta, A., (2017) Robust Adversarial Reinforcement Learning, , eprint arXiv; Rubinstein, B.I., ANTIDOTE: Understanding and defending against poisoning of anomaly detectors (2009) Proceedings of the 9Th ACM SIGCOMM Conference on Internet Measurement, pp. 1-14. , ACM; Schaul, T., Quan, J., Antonoglou, I., Silver, D., (2015) : Prioritized Experience Replay, , CoRR abs/1511.05952; Sengupta, S., Chakraborti, T., Kambhampati, S., (2017) Securing Deep Neural Nets against Adversarial Attacks with Moving Target Defense., , eprint arXiv:, May; Steinhardt, J., Koh, P.W., Liang, P., (2017) Certified Defenses for Data Poisoning Attacks., , eprint arXiv:, June; Sutton, R.S., Barto, A.G., (1998) Introduction to Reinforcement Learning, 1St Edn, , MIT Press, Cambridge; Szegedy, C., (2013) Intriguing Properties of Neural Networks, , eprint arXiv; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses, , eprint arXiv:, May; Wang, B., Gao, J., Qi, Y., (2016) A Theoretical Framework for Robustness of (Deep) Classifiers against Adversarial Examples, , eprint arXiv; Xiao, H., Xiao, H., Eckert, C., Adversarial label flips attack on support vector machines (2012) Proceedings of the 20Th European Conference on Artificial Intelligence. ECAI 2012, pp. 870-875. , IOS Press, Amsterdam; Zhang, F., Chan, P.P.K., Biggio, B., Yeung, D.S., Roli, F., Adversarial feature selection against evasion attacks (2016) IEEE Trans. Cybern., 46 (3), pp. 766-777; Zheng, S., Song, Y., Leung, T., Goodfellow, I., (2016) Improving the Robustness of Deep Neural Networks via Stability Training, , eprint arXiv","Han, Y.; School of Computing and Information Systems, Australia; email: yi.han@unimelb.edu.au","Bushnell L.Poovendran R.Basar T.",,"Springer Verlag","9th International Conference on Decision and Game Theory for Security, GameSec 2018","29 October 2018 through 31 October 2018",,220039,03029743,9783030015534,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85055868724
"Sayin M.O., Hosseini H., Poovendran R., Başar T.","55832164500;8130972800;6603592481;7102588845;","A game theoretical framework for inter-process adversarial intervention detection",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11199 LNCS",,,"486","507",,4,"10.1007/978-3-030-01554-1_28","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055864591&doi=10.1007%2f978-3-030-01554-1_28&partnerID=40&md5=b48b397749c48199bec9a9c53d60d1ce","Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana, IL  61801, United States; Department of Electrical Engineering, University of Washington, Seattle, WA  98195, United States","Sayin, M.O., Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana, IL  61801, United States; Hosseini, H., Department of Electrical Engineering, University of Washington, Seattle, WA  98195, United States; Poovendran, R., Department of Electrical Engineering, University of Washington, Seattle, WA  98195, United States; Başar, T., Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana, IL  61801, United States","In this paper, we propose and analyze a two-level game theoretical framework to detect advanced and persistent threats across processes. The two-level framework adapted facilitates abstraction of the complexity of process level interactions between defense mechanisms and adversaries from easier to interpret and more flexible system-level interaction. At the process-level, program anomaly detection algorithms have already been proposed to detect anomalous program behavior by comparing monitored activities with the predetermined expected behavior. This had led to significant detection performance initially until advanced adversaries modified the attacks to remain undetected. Therefore, we propose defense mechanisms that anticipate the reaction of advanced evaders and seek to maximize the complexity of undetectable attacks at the expense of additional false alarm rate. Furthermore, in the system-level, we propose defense mechanisms to detect adversarial intervention across processes through the assessment of all process activities together in a cohesive way so that the advanced adversaries need to craft their attacks further to remain undetected also at the system-level. This further increases the cost of complexity for the attacker, and correspondingly degrades the motivation to attack. We provide a game theoretical incentive analysis for both defenders and adversaries, and characterize pure and mixed strategy equilibria. We also analyze the coupling between the two levels of the game. © 2018, Springer Nature Switzerland AG.","Advanced persistent threats; Anomaly detection; Games-in-games; Host-based intrusion detection; Mimicry attacks; Process monitoring; Stackelberg games","Decision theory; Intrusion detection; Network security; Process monitoring; Advanced persistent threats; Anomaly detection; Games-in-games; Host-based intrusion detection; Mimicry attacks; Stackelberg Games; Game theory",,,,,"Başar, T., Olsder, G., (1999) Dynamic Noncooperative Game Theory; Barabosch, T., Gerhards-Padilla, E., Host-based code injection attacks: A popular technique used by malware (2014) The 9Th International Conference on Malicious and Unwanted Software: The Americas (MALWARE); Brangetto, P., Aubyn, M.K.-S., (2015) Economic Aspects of National Cyber Security Strategies, , Technical report, NATO Cooperative Cyber Defense Centre of Excellence Tallinn, Estonia; Dritsoula, L., Loiseau, P., Musacchio, J., A game-theoretic analysis of adversarial classification (2017) IEEE Trans. Inf. Forensics Secur., 12 (12), pp. 3094-3109; Du, M., Li, F., Zheng, G., Srikumar, V., DeepLog: Anomaly detection and diagnosis from system logs through deep learning (2017) Proceedings of the 24Th ACM Conference on Computer and Communications Security; Elisan, C.C., (2013) Malware, Rootkits and Botnets: A Beginner’s Guide, , McGraw-Hill, New York; Feng, H.H., Kolesnikov, O.M., Fogla, P., Lee, W., Gong, W., Anomaly detection using call stack information (2003) Proceedings of the IEEE Security and Privacy; Forrest, S., Hofmeyr, S.A., Somayaji, A., Longstaff, T.A., A sense of self for Unix processes (1996) Proceedings of IEEE Symposium on Security and Privacy; Gao, D., Reiter, M.K., Song, D., On gray-box program tracking for anomaly detection (2004) Proceedings of the 13Th Conference on USENIX Security Symposium; Ghafouri, A., Abbas, W., Laszka, A., Vorobeychik, Y., Koutsoukos, X., Optimal thresholds for anomaly-based intrusion detection in dynamical environments (2016) Gamesec 2016. LNCS, 9996, pp. 415-434. , Zhu, Q., Alpcan, T., Panaousis, E., Tambe, M., Casey, W. (eds.), Springer, Cham, https://doi.org/10.1007/978-3-319-47413-7 24; Ji, Y., RAIN: Refinable attack investigation with on-demand inter-process information flow tracking (2017) Proceedings of the 24Th ACM Conference on Computer and Communications Security; Kruegel, C., Kirda, E., Mutz, D., Robertson, W., Vigna, G., Automating mimicry attacks using static binary analysis (2005) Proceedings of the 14Th USENIX Security Symposium; Manzoor, E., Milajerdi, S.M., Akoglu, L., Fast memory-efficient anomaly detection in streaming heterogeneous graphs (2016) Proceedings of the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining; Parampalli, C., Sekar, R., Johanson, R., A practical mimicry attack against powerful system-call monitors (2008) Proceedings of the 2008 ACM Symposium on Information, Computer and Communications Security; Shu, X., Yao, D.D., Ryder, B.G., A formal framework for program anomaly detection (2015) RAID 2015. LNCS, 9404, pp. 270-292. , Bos, H., Monrose, F., Blanc, G. (eds.), Springer, Cham, https://doi.org/10.1007/978-3-319-26362-5 13; Silberschatz, A., Galvin, P.B., Gagne, G., (2013), Operating System Concepts. Wiley, Hoboken; Somayaji, A., Forest, S., Automated response using system-call delays (2000) Proceedings of the 9Th USENIX Security Symposium; Wagner, D., Dean, D., Intrusion detection via static analysis (2001) Proceedings of the Symposium on Security and Privacy; Wagner, D., Soto, P., Mimicry attacks on host-based intrusion detection systems (2002) Proceedings of the 9Th ACM Conference on Computer and Communications Security; Yao, D., Shu, X., Cheng, L., Stolfo, S.J., (2017) Anomaly Detection as a Service: Challenges, Advances, and Opportunities. Synthesis Lectures on Information Security, Privacy, and Thrust #22, , Morgan & Claypool Publishers; Zhu, Q., Başar, T., Game-theoretic methods for robustness, security, and resiliency of cyberphysical control systems: Games-in-games principle for cross-layer resilient control systems (2015) IEEE Control Syst. Mag., 35 (1), pp. 46-65","Sayin, M.O.; Department of Electrical and Computer Engineering, United States; email: sayin2@illinois.edu","Bushnell L.Poovendran R.Basar T.",,"Springer Verlag","9th International Conference on Decision and Game Theory for Security, GameSec 2018","29 October 2018 through 31 October 2018",,220039,03029743,9783030015534,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","",Scopus,2-s2.0-85055864591
"Zhang F., Wang Y., Wang H.","37100510600;57204780329;7501735520;","Gradient Correlation: Are Ensemble Classifiers More Robust Against Evasion Attacks in Practical Settings?",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11233 LNCS",,,"96","110",,4,"10.1007/978-3-030-02922-7_7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055819395&doi=10.1007%2f978-3-030-02922-7_7&partnerID=40&md5=15bd4578a39ca945041ee82d6fdc95ed","Dongguang University of Technology, Dongguan, Guangdong, China; Institute for Sustainable Industries and Liveable Cities, VU Research, Victoria University, Melbourne, Australia","Zhang, F., Dongguang University of Technology, Dongguan, Guangdong, China; Wang, Y., Dongguang University of Technology, Dongguan, Guangdong, China; Wang, H., Institute for Sustainable Industries and Liveable Cities, VU Research, Victoria University, Melbourne, Australia","Pattern recognition is an essential part of modern security systems for malware detection, intrusion detection, and spam filtering. Conventional classifiers widely used in these applications are found vulnerable themselves to adversarial machine learning attacks. Existing studies argued that ensemble classifiers are more robust than a single classifier under evasion attacks due to more uniform weights produced on the basis of training data. In this paper, we investigate the problem in a more practical setting where attackers do not know the classifier details. Instead, attackers may acquire only a portion of the labeled data or a replacement dataset for learning the target decision boundary. In this case, we show that ensemble classifiers are not necessarily more robust under a least effort attack based on gradient descent. Our experiments are conducted with both linear and kernel SVMs on real datasets for spam filtering and malware detection. © 2018, Springer Nature Switzerland AG.","Adversarial machine learning; Ensemble classifiers; Evasion attacks","Artificial intelligence; Computer crime; Information systems; Information use; Intrusion detection; Learning systems; Malware; Pattern recognition systems; Systems engineering; Conventional classifier; Decision boundary; Ensemble classifiers; Evasion attacks; Gradient correlation; Gradient descent; Malware detection; Real data sets; Classification (of information)",,,,,"Androutsopoulos, I., Paliouras, G., Michelakis, E., (2004) Learning to Filter Unsolicited Commercial E-Mail; Biggio, B., Evasion attacks against machine learning at test time ECML PKDD 2013. LNCS (LNAI), 8190, pp. 387-402. , https://doi.org/10.1007/978-3-642-40994-325, Blockeel, H., Kersting, K., Nijssen, S., Železný, F. (eds.), Springer, Heidelberg; Biggio, B., Security evaluation of support vector machines in adversarial environments (2014) Support Vector Machines Applications, pp. 105-153. , https://doi.org/10.1007/978-3-319-02300-74, Ma, Y., Guo, G. (eds.), Springer, Cham; Biggio, B., Fumera, G., Roli, F., Evade hard multiple classifier systems (2009) Applications of Supervised and Unsupervised Ensemble Methods, pp. 15-38. , https://doi.org/10.1007/978-3-642-03999-72, Okun, O., Valentini, G. (eds.), Springer, Heidelberg; Biggio, B., Fumera, G., Roli, F., Multiple classifier systems for robust classifier design in adversarial environments (2010) Int. J. Mach. Learn. Cybern., 1 (1-4), pp. 27-41; Biggio, B., Roli, F., (2017) Wild Patterns: Ten Years after the Rise of Adversarial Machine Learning, , http://arxiv.org/abs/1712.03141, arXiv Preprint; Cheng, K., Secure k-NN query on encrypted cloud data with multiple keys (2015) IEEE Trans. Big Data, 1, p. 1; Demontis, A., Yes, machine learning can be more secure! A case study on android malware detection (2017) IEEE Trans. Dependable Secur. Comput., , https://ieeexplore.ieee.org/document/7917369; Dong, Y.S., Han, K.S., Boosting SVM classifiers by ensemble (2005) The 14Th International Conference on World Wide Web, Pp. 1072–1073, WWW 2005. ACM; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) The International Conference on Learning Representations, ICLR 2015; Hastie, T., Tibshirani, R., Friedman, J., (2009) The Elements of Statistical Learning, , 2nd edn. Springer, New York; Ho, T.K., The random subspace method for constructing decision forests (1998) IEEE Trans. Pattern Anal. Mach. Intell., 20 (8), pp. 832-844; Kabir, E., Mahmood, A., Wang, H., Mustafa, A., Microaggregation sorting framework for k-anonymity statistical disclosure control in cloud computing (2015) IEEE Trans. Cloud Comput., , https://ieeexplore.ieee.org/document/7208829; Kabir, M.E., Wang, H., Bertino, E., A role-involved purpose-based access control model (2012) Inf. Syst. Front., 14 (3), pp. 809-822; Kantchelian, A., Tygar, J., Joseph, A., Evasion and hardening of tree ensemble classifiers (2016) International Conference on Machine Learning, pp. 2387-2396; Khalil, F., Li, J., Wang, H., An integrated model for next page access prediction (2009) Int. J. Knowl. Web Intell., 1 (1-2), pp. 48-80; Kim, H.C., Pang, S., Je, H.M., Kim, D., Bang, S.Y., Constructing support vector machine ensemble (2003) Pattern Recogn, 36 (12), pp. 2757-2767; Ko̷lcz, Eo, H.:., Eature weighting for improved classifier robustness (2009) Ixth Conference on Email and Anti-Spam, CEAS 2009; Kolter, J.Z., Maloof, M.A., Learning to detect malicious executables in the wild (2004) Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 470-478. , ACM; Laskov, P., Practical evasion of a learning-based classifier: A case study (2014) 2014 IEEE Symposium on Security and Privacy (SP), pp. 197-211. , IEEE; Mujtaba, G., Shuib, L., Raj, R.G., Majeed, N., Al-Garadi, M.A., Email classification research trends: Review and open issues (2017) IEEE Access, 5, pp. 9044-9064; Papernot, N., McDaniel, P., Sinha, A., Wellman, M., (2016) Sok: Towards the Science of Security and Privacy in Machine Learning, pp. 1-19. , http://arxiv.org/abs/1611.03814, arXiv Preprint; Peng, M., Zeng, G., Sun, Z., Huang, J., Wang, H., Tian, G., Personalized app recommendation based on app permissions (2018) World Wide Web, 21 (1), pp. 89-104; Shah, Z., Mahmood, A.N., Barlow, M., Tari, Z., Yi, X., Zomaya, A.Y., Computing hierarchical summary from two-dimensional big data streams (2018) IEEE Trans. Parallel Distrib. Syst., 29 (4), pp. 803-818; Shen, Y., Zhang, T., Wang, Y., Wang, H., Jiang, X., Microthings: A generic iot architecture for flexible data aggregation and scalable service cooperation (2017) IEEE Commun. Mag., 55 (9), pp. 86-93; Shu, J., Jia, X., Yang, K., Wang, H., Privacy-preserving task recommendation services for crowdsourcing (2018) IEEE Trans. Serv. Comput., , https://ieeexplore.ieee.org/document/8253516; Smutz, C., Stavrou, A., When a tree falls: Using diversity in ensemble classifiers to identify evasion in malware detectors (2016) NDSS; Sun, X., Li, M., Wang, H., Plank, A., An efficient hash-based algorithm for minimal k-anonymity (2008) Proceedings of the Thirty-First Australasian Conference on Computer Science, 74, pp. 101-107. , Australian Computer Society, Inc; Sun, X., Wang, H., Li, J., Zhang, Y., Injecting purpose and trust into data anonymisation (2011) Comput. Secur., 30 (5), pp. 332-345; Vapnik, V., (1999) The Nature of Statistical Learning, , 1st edn. Springer, New York; Wang, G., Wang, T., Zheng, H., Zhao, B.Y., Man vs. Machine: Practical adversarial detection of malicious crowdsourcing workers (2014) USENIX Security Symposium, pp. 239-254; Wang, H., Cao, J., Zhang, Y., Ticket-based service access scheme for mobile users (2002) Australian Computer Science Communications, 24, pp. 285-292; Xu, W., Qi, Y., Evans, D., Automatically evading classifiers (2016) Proceedings of the 2016 Network and Distributed Systems Symposium; Yi, X., Sun, H., Jafar, S.A., Gesbert, D., Tdma is optimal for all-unicast dof region of tim if and only if topology is chordal bipartite (2018) IEEE Trans. Inf. Theory, 64 (3), pp. 2065-2076; Zhang, F., Chan, P.P., Biggio, B., Yeung, D.S., Roli, F., Adversarial feature selection against evasion attacks (2016) IEEE Trans. Cybern., 46 (3), pp. 766-777; Zhang, Y., Shen, Y., Wang, H., Zhang, Y., Jiang, X., On secure wireless communications for service oriented computing (2018) IEEE Trans. Serv. Comput., 11 (2), pp. 318-328","Wang, Y.; Dongguang University of TechnologyChina; email: wangyi@dgut.edu.cn","Paik H.Wang H.Zhou R.Hacid H.Cellary W.",,"Springer Verlag","19th International Conference on Web Information Systems Engineering, WISE 2018","12 November 2018 through 15 November 2018",,219849,03029743,9783030029210,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","",Scopus,2-s2.0-85055819395
"Primiero G., Tuci E., Tagliabue J., Ferrante E.","24721838900;6603207541;6603305536;36602262300;","Swarm attack: A self-organized model to recover from malicious communication manipulation in a swarm of simple simulated agents",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11172 LNCS",,,"213","224",,7,"10.1007/978-3-030-00533-7_17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055775146&doi=10.1007%2f978-3-030-00533-7_17&partnerID=40&md5=40e0c884798a1f3a95abe560a2a18452","The Department of Computer Science, Middlesex University London, London, United Kingdom; Tooso Inc., San Francisco, United States; Laboratory of Socioecology and Social Evolution, KU Leuven, Leuven, Belgium; School of Computer Science, University of Birmingham, Dubai, United Kingdom","Primiero, G., The Department of Computer Science, Middlesex University London, London, United Kingdom; Tuci, E., The Department of Computer Science, Middlesex University London, London, United Kingdom; Tagliabue, J., Tooso Inc., San Francisco, United States; Ferrante, E., Laboratory of Socioecology and Social Evolution, KU Leuven, Leuven, Belgium, School of Computer Science, University of Birmingham, Dubai, United Kingdom","Non-centralised behaviour such as those that characterise swarm robotics systems are vulnerable to intentional disruptions from internal or external adversarial sources. Threats in the context of swarm robotics can be executed through goal, behaviour, environment or communication manipulation. Experimental studies in this area are still sparse. We study an attack scenario performed by actively modifying the data between authorised participants. We formulate a robust probabilistic adaptive defence mechanism which does not aim at identifying malicious agents, but to provide the swarm with the means to minimise the consequences of the attack. The mechanism relies on a dynamic modification of the probability of agents to change their current information in view of new contradictory or corroborating incoming data. We investigate several experimental conditions in simulation. The results show that the presence of adversaries in the swarm hinders reaching consensus to the majority opinion when using a baseline method, but that there are several conditions in which our adaptive defence mechanism is highly efficient. © 2018, Springer Nature Switzerland AG.",,"Robotics; Attack scenarios; Baseline methods; Defence mechanisms; Dynamic modifications; Experimental conditions; Malicious agent; Self-organized models; Simulated agents; Swarm intelligence",,,,,"Akdemir, K.D., Karakoyunlu, D., Padir, T., Sunar, B., An emerging threat: Eve meets a robot (2011) INTRUST 2010. LNCS, 6802, pp. 271-289. , Chen, L., Yung, M. (eds.) , Springer, Heidelberg, https://doi.org/10.1007/978-3-642-25283-9 18; Aura, T., (1997) Strategies against Replay Attacks, pp. 59-69. , https://doi.org/10.1109/CSFW.1997.596787, 10th Computer Security Foundations Workshop (CSFW 1997), Rockport, Massachusetts, USA, 10-12 June 1997; Brambilla, M., Ferrante, E., Birattari, M., Dorigo, M., Swarm robotics: A review from the swarm engineering perspective (2013) Swarm Intell, 7 (1), pp. 1-41; Chamoso, P., de la Prieta, F., de Paz, F., Corchado, J.M., Swarm agent-based architecture suitable for internet of things and smartcities (2015) Distributed Computing and Artificial Intelligence, 12Th International Conference, 373, pp. 21-29. , Omatu, S., et al. (eds.), AISC, Springer, Cham, https://doi.org/; Ducatelle, F., Cooperative navigation in robotic swarms (2014) Swarm Intell, 8 (1), pp. 1-33; Gong, L., (1993) A Variation on the Themes of Message Freshness and Replay Or, the Difficulty in Devising Formal Methods to Analyze Cryptographic Protocols, pp. 131-136. , Proceedings of the 6th IEEE Computer Security Foundations Workshop-CSFW 1993, Franconia, New Hampshire, USA, 15-17 June 1993, https://doi.org/; Higgins, F., Tomlinson, A., Martin, K., Survey on security challenges for swarm robotics (2009) Fifth International Conference on Autonomic and Autonomous Systems (ICAS), pp. 307-312; Laan, A., Madirolas, G., de Polavieja, G., Rescuing collective wisdom when the average group opinion is wrong (2017) Front. Robot. AI, 4, pp. 1-21; Montes de Oca, M., Ferrante, E., Scheidler, A., Pinciroli, C., Birattari, M., Dorigo, M., Majority-rule opinion dynamics with differential latency: A mechanism for self-organized collective decision-making (2011) Swarm Intell, 5, pp. 305-327; Primiero, G., Martorana, A., Tagliabue, J., (2018) Simulation of a Trust and Reputation Based Mitigation Protocol for a Black Hole Style Attack on Vanets, pp. 127-135. , https://doi.org/10.1109/EuroSPW.2018.00025, 2018 IEEE European Symposium on Security and Privacy Workshops, EuroS&P Workshops 2018, London, United Kingdom, 23-27 April 2018; Reina, A., Marshall, J.A.R., Trianni, V., Bose, T., Model of the best-of-N nest-site selection process in honeybees (2017) Phys. Rev. E, 95 (5). , https://doi.org/; Reina, A., Valentini, G., Fernández-Oto, C., Dorigo, M., Trianni, V., A design pattern for decentralised decision making (2015) Plos ONE, 10 (10). , https://doi.org/10.1371/journal.pone.0140950; Roosta, T., Shieh, S., Sastry, S., Taxonomy of security attacks in sensor networks and countermeasures (2006) IEEE International Conference on System Integration and Reliability Improvements, pp. 13-15; Saljooghinejad, H., Bhukya, W.N., Layered security architecture for masquerade attack detection (2012) Dbsec 2012. LNCS, 7371, pp. 255-262. , Cuppens-Boulahia, N., Cuppens, F., Garcia-Alfaro, J. (eds.) , Springer, Heidelberg, https://doi.org/10.1007/978-3-642-31540-4 19; Sargeant, I., Tomlinson, A., Review of potential attacks on robotic swarms (2018) Intellisys 2016. LNNS, 16, pp. 628-646. , https://doi.org/10.1007/978-3-319-56991-8 46, Bi, Y., Kapoor, S., Bhatia, R. (eds.) , Springer, Cham; Sargeant, I., Tomlinson, A., Maliciously manipulating a robotic swarm (2016) Proceedings of the International Conference Embedded Systems, Cyber-Physical Systems and Applications (ESCS), pp. 122-128; Scharre, P., Robotics on the battlefield part II: The coming swarm. Technical report (2014) Centre for a New American Security; Strobel, V., Castello, F., Dorigo, M., Managing byzantine robots via blockchain technology in a swarm robotics collective decision making scenario. Technical report TR/IRIDIA/2017-013, IRIDIA, Université Libre de Bruxelles, Brussels (2017) Belgium; Syverson, P.F., (1994), pp. 187-191. , A taxonomy of replay attacks. In: Proceedings of the Seventh IEEE Computer Security Foundations Workshop-CSFW 1994, Franconia, New Hampshire, USA, 14-16 June 1994, https://doi.org/; Valentini, G., Ferrante, E., Dorigo, M., The best-of-n problem in robot swarms: Formalization, state of the art, and novel perspectives (2017) Front. Robot. AI 4, 9, , https://www.frontiersin.org/article/10.3389/frobt.2017.00009, https://doi.org/10.3389/frobt.2017.00009; Valentini, G., Ferrante, E., Hamann, H., Dorigo, M., Collective decision with 100 Kilobots: Speed versus accuracy in binary discrimination problems (2016) Auton. Agents Multi-Agent Syst., 30 (3), pp. 553-580; (2011) Encyclopedia of Cryptography and Security, , van Tilborg, H., Jajodia, S. (eds.), Springer, Heidelberg","Primiero, G.; The Department of Computer Science, United Kingdom; email: G.Primiero@mdx.ac.uk","Reina A.Christensen A.L.Trianni V.Blum C.Dorigo M.Birattari M.",,"Springer Verlag","11th International Conference on Swarm Intelligence, ANTS 2018","29 October 2018 through 31 October 2018",,219989,03029743,9783030005320,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","",Scopus,2-s2.0-85055775146
"Zhou W., Hou X., Chen Y., Tang M., Huang X., Gan X., Yang Y.","57303422100;56026918900;57203387347;57204471584;57204472671;57204466148;57206629478;","Transferable adversarial perturbations",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11218 LNCS",,,"471","486",,8,"10.1007/978-3-030-01264-9_28","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055725664&doi=10.1007%2f978-3-030-01264-9_28&partnerID=40&md5=68b3a4f3e5552d51d336980ffc7b4c93","Basic Research Group, Security Platform Department, Tencent, Beijing, China","Zhou, W., Basic Research Group, Security Platform Department, Tencent, Beijing, China; Hou, X., Basic Research Group, Security Platform Department, Tencent, Beijing, China; Chen, Y., Basic Research Group, Security Platform Department, Tencent, Beijing, China; Tang, M., Basic Research Group, Security Platform Department, Tencent, Beijing, China; Huang, X., Basic Research Group, Security Platform Department, Tencent, Beijing, China; Gan, X., Basic Research Group, Security Platform Department, Tencent, Beijing, China; Yang, Y., Basic Research Group, Security Platform Department, Tencent, Beijing, China","State-of-the-art deep neural network classifiers are highly vulnerable to adversarial examples which are designed to mislead classifiers with a very small perturbation. However, the performance of black-box attacks (without knowledge of the model parameters) against deployed models always degrades significantly. In this paper, We propose a novel way of perturbations for adversarial examples to enable black-box transfer. We first show that maximizing distance between natural images and their adversarial examples in the intermediate feature maps can improve both white-box attacks (with knowledge of the model parameters) and black-box attacks. We also show that smooth regularization on adversarial perturbations enables transferring across models. Extensive experimental results show that our approach outperforms state-of-the-art methods both in white-box and black-box attacks. © 2018, Springer Nature Switzerland AG.","Adversarial perturbations; Black-box attacks; Transferability","Deep neural networks; Image enhancement; Adversarial perturbations; Black boxes; Model parameters; Neural network classifier; Small perturbations; State of the art; State-of-the-art methods; Transferability; Computer vision",,,,,"Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Hinton, G., Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups (2012) IEEE Sig. Process. Mag., 29 (6), pp. 82-97; Sutskever, I., Vinyals, O., Le, Q.V., Sequence to sequence learning with neural networks (2014) Advances in Neural Information Processing Systems, pp. 3104-3112; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 427-436; Moosavi-Dezfooli, S.M., Fawzi, A., Fawzi, O., Frossard, P., (2016) Universal Adversarial Perturbations, , arXiv preprint arXiv; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations; Kurakin, A., Goodfellow, I.J., Bengio, S., (2016) Adversarial Machine Learning at Scale. Arxiv: Computer Vision and Pattern Recognition; Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P., DeepFool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., (2017) Inception-V4, Inception-Resnet and the Impact of Residual Connections on Learning, pp. 4278-4284. , AAA; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses, , arXiv preprint arXiv; Szegedy, C., (2013) Intriguing Properties of Neural Networks, , arXiv preprint arXiv; Kurakin, A., Goodfellow, I.J., Bengio, S., (2016) Adversarial Examples in the Physical World. Arxiv: Computer Vision and Pattern Recognition; Perronnin, F., Sánchez, J., Mensink, T., Improving the fisher kernel for large-scale image classification (2010) ECCV 2010. LNCS, 6314, pp. 143-156. , Daniilidis, K., Maragos, P., Paragios, N. (eds.) , Springer, Heidelberg, https://doi.org/10.1007/978-3-642-15561-111; Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L., ImageNet: A large-scale hierarchical image database (2009) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 248-255. , IEEE; Russakovsky, O., ImageNet large scale visual recognition challenge (2015) Int. J. Comput. Vis. (IJCV), 115 (3), pp. 211-252; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-Scale Image Recognition, , arXiv preprint arXiv; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826; He, K., Zhang, X., Ren, S., Sun, J., Identity mappings in deep residual networks (2016) ECCV 2016. LNCS, 9908, pp. 630-645. , Leibe, B., Matas, J., Sebe, N., Welling, M. (eds.) , Springer, Cham, https://doi.org/10.1007/978-3-319-46493-0 38; Nicolas, P., (2017) Cleverhans V2.0.0: An Adversarial Machine Learning Library, , arXiv preprint arXiv; Abadi, M., (2016) Tensorflow: Large-Scale Machine Learning on Heterogeneous Distributed Systems, , arXiv preprint arXiv; Dong, Y., Boosting adversarial attacks with momentum (2018) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , June; Carlini, N., Wagner, D., (2016) Towards Evaluating the Robustness of Neural Networks, , arXiv preprint arXiv","Zhou, W.; Basic Research Group, China; email: wen8.zhou@gmail.com","Ferrari V.Sminchisescu C.Weiss Y.Hebert M.",,"Springer Verlag","15th European Conference on Computer Vision, ECCV 2018","8 September 2018 through 14 September 2018",,219419,03029743,9783030012632,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","",Scopus,2-s2.0-85055725664
"Cai Q.-Z., Liu C., Song D.","57220980170;55873082700;7402443870;","Curriculum adversarial training",2018,"IJCAI International Joint Conference on Artificial Intelligence","2018-July",,,"3740","3747",,16,"10.24963/ijcai.2018/520","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055725417&doi=10.24963%2fijcai.2018%2f520&partnerID=40&md5=6e4c521821d0013a13c101c9ab52c95c","Nanjing University, China; UC Berkeley, China","Cai, Q.-Z., Nanjing University, China, UC Berkeley, China; Liu, C., UC Berkeley, China; Song, D., UC Berkeley, China","Recently, deep learning has been applied to many security-sensitive applications, such as facial authentication. The existence of adversarial examples hinders such applications. The state-of-theart result on defense shows that adversarial training can be applied to train a robust model on MNIST against adversarial examples; but it fails to achieve a high empirical worst-case accuracy on a more complex task, such as CIFAR-10 and SVHN. In our work, we propose curriculum adversarial training (CAT) to resolve this issue. The basic idea is to develop a curriculum of adversarial examples generated by attacks with a wide range of strengths. With two techniques to mitigate the catastrophic forgetting and the generalization issues, we demonstrate that CAT can improve the prior art's empirical worst-case accuracy by a large margin of 25% on CIFAR-10 and 35% on SVHN. At the same, the model's performance on non-adversarial inputs is comparable to the state-of-the-art models. © 2018 International Joint Conferences on Artificial Intelligence. All right reserved.",,"Artificial intelligence; Deep learning; Catastrophic forgetting; Complex task; Large margins; Prior arts; Robust modeling; Sensitive application; State of the art; Curricula",,,,,"Liang, P., Raghunathan, A., Steinhardt, J., Certified defenses against adversarial examples (2018) Proc. of ICLR; Duchi, J., Sinha, A., Namkoong, H., Certifiable distributional robustness with principled adversarial training (2018) Proc. of ICLR; Wagner, D., Athalye, A., Carlini, N., Obfuscated gradients give a false sense of security (2018) Proc. of ICML; Buckman, J., Roy, A., Raffel, C., Goodfellow, I., Thermometer encoding: One hot way to resist adversarial examples (2018) Submissions to International Conference on Learning Representations; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) Proc. of ACM Workshop on Artificial Intelligence and Security, pp. 3-14; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Proc. of Euro S & P, pp. 39-57; Chen, C., Seff, A., Kornhauser, A., Xiao, J., Deepdriving: Learning affordance for direct perception in autonomous driving (2015) Proc. of ICCV, pp. 2722-2730; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) Proc. of ICLR; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. of CVPR, pp. 770-778; He, W., Wei, J., Chen, X., Carlini, N., Song, D., Adversarial example defense: Ensembles of weak defenses are not strong (2017) Proc. of WOOT; Hinton, G., Deng, L., Yu, D., Dahl, G.E., Mohamed, A.-R., Jaitly, N., Senior, A., Sainath, T.N., Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups (2012) IEEE Signal Processing Magazine, pp. 82-97; Huang, G., Liu, Z., Van Der Maaten, L., Weinberger, K.Q., Densely connected convolutional networks (2017) Proc. of CVPR, pp. 2261-2269; Kolter, J., Wong, E., (2017) Provable Defenses Against Adversarial Examples Via the Convex Outer Adversarial Polytope; Krizhevsky, A., (2009) Learning Multiple Layers of Features from Tiny Images; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2017) Proc. of ICLR; LeCun, Y., (1998) The Mnist Database of Handwritten Digits; Li, B., Vorobeychik, Y., Chen, X., (2016) A General Retraining Framework for Scalable Adversarial Classification; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) Proc. of ICLR; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) Proc. of ICLR; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) Proc. of CVPR, pp. 86-94; Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., Ng, A.Y., (2011) Reading Digits in Natural Images With Unsupervised Feature Learning; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z., Swami, A., (2016) Practical Black-box Attacks Against Deep Learning Systems Using Adversarial Examples; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Proc. of Euro S & P, 2016 IEEE Symposium on, pp. 582-597; Sharma, Y., Chen, P.-Y., Attacking the madry defense model with l 1-based adversarial examples (2018) Proc. of AAAI; Silver, D., Huang, A., Maddison, C.J., Guez, A., Sifre, L., Van Den, G.D., Schrittwieser, J., Lanctot, M., Mastering the game of go with deep neural networks and tree search (2016) Nature, pp. 484-489; Sun, Y., Wang, X., Tang, X., Deep learning face representation from predicting 10, 000 classes (2014) Proc. of CVPR, pp. 1891-1898; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks; Xu, W., Evans, D., Qi, Y., Feature squeezing: Detecting adversarial examples in deep neural networks (2018) Proc. of NDSS",,"Lang J.","International Joint Conferences on Artifical Intelligence (IJCAI)","International Joint Conferences on Artificial Intelligence","27th International Joint Conference on Artificial Intelligence, IJCAI 2018","13 July 2018 through 19 July 2018",,140653,10450823,9780999241127,,,"English","IJCAI Int. Joint Conf. Artif. Intell.",Conference Paper,"Final","All Open Access, Bronze, Green",Scopus,2-s2.0-85055725417
"Liang B., Li H., Su M., Bian P., Li X., Shi W.","57200218592;57191247209;57200218741;35995253600;23035594000;8727119200;","Deep text classification can be fooled",2018,"IJCAI International Joint Conference on Artificial Intelligence","2018-July",,,"4208","4215",,75,"10.24963/ijcai.2018/585","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055723882&doi=10.24963%2fijcai.2018%2f585&partnerID=40&md5=4f2111b303c4c1abe86a2340b308b9f3","School of Information, Renmin University of China, Beijing, China; Key Laboratory of Data Engineering and Knowledge Engineering, MOE, Beijing, China","Liang, B., School of Information, Renmin University of China, Beijing, China, Key Laboratory of Data Engineering and Knowledge Engineering, MOE, Beijing, China; Li, H., School of Information, Renmin University of China, Beijing, China, Key Laboratory of Data Engineering and Knowledge Engineering, MOE, Beijing, China; Su, M., School of Information, Renmin University of China, Beijing, China, Key Laboratory of Data Engineering and Knowledge Engineering, MOE, Beijing, China; Bian, P., School of Information, Renmin University of China, Beijing, China, Key Laboratory of Data Engineering and Knowledge Engineering, MOE, Beijing, China; Li, X., School of Information, Renmin University of China, Beijing, China, Key Laboratory of Data Engineering and Knowledge Engineering, MOE, Beijing, China; Shi, W., School of Information, Renmin University of China, Beijing, China, Key Laboratory of Data Engineering and Knowledge Engineering, MOE, Beijing, China","In this paper, we present an effective method to craft text adversarial samples, revealing one important yet underestimated fact that DNN-based text classifiers are also prone to adversarial sample attack. Specifically, confronted with different adversarial scenarios, the text items that are important for classification are identified by computing the cost gradients of the input (white-box attack) or generating a series of occluded test samples (blackbox attack). Based on these items, we design three perturbation strategies, namely insertion, modification, and removal, to generate adversarial samples. The experiment results show that the adversarial samples generated by our method can successfully fool both state-of-the-art character-level and wordlevel DNN-based text classifiers. The adversarial samples can be perturbed to any desirable classes without compromising their utilities. At the same time, the introduced perturbation is difficult to be perceived. © 2018 International Joint Conferences on Artificial Intelligence. All right reserved.",,"Artificial intelligence; Classification (of information); Black boxes; Character level; Deep text; State of the art; Test samples; Text classifiers; White box; Text processing",,,,,"Arras, L., Horn, F., Montavon, G., Müller, K.-R., Samek, W., (2016) Explaining Predictions of Non-linear Classifiers in Nlp; Atallah, M., Raskin, V., Crogan, M., Hempelmann, C., Kerschbaum, F., Mohamed, D., Naik, S., Natural language watermarking: Design, analysis, and a proof-ofconcept implementation (2001) Information Hiding, pp. 185-200. , Springer; Barzilay, R., McKeown, K.R., Extracting paraphrases from a parallel corpus (2001) Proceedings of the 39th Annual Meeting on Association for Computational Linguistics, pp. 50-57. , Association for Computational Linguistics; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium on, pp. 39-57. , IEEE; Gao, J., Lanchantin, J., Soffa, M.L., Qi, Y., (2018) Black-box Generation of Adversarial Text Sequences to Evade Deep Learning Classifiers; Gong, Z., Wang, W., Li, B., Song, D., Ku, W.-S., (2018) Adversarial Texts With Gradient Methods; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) Proceedings of the 2015 International Conference on Learning Representations. Computational and Biological Learning Society; Jia, R., Liang, P., (2017) Adversarial Examples for Evaluating Reading Comprehension Systems; Kereliuk, C., Sturm, B.L., Larsen, J., Deep learning and music adversaries (2015) IEEE Transactions on Multimedia, 17 (11), pp. 2059-2071; Kim, Y., Convolutional neural networks for sentence classification (2014) Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 1746-1751. , Association for Computational Linguistics; Liang, B., Li, H., Su, M., Li, X., Shi, W., Wang, X., (2017) Detecting Adversarial Examples in Deep Networks With Adaptive Noise Reduction; Mikolov, T., Sutskever, I., Chen, K., Corrado, G.S., Dean, J., Distributed representations of words and phrases and their compositionality (2013) Advances in Neural Information Processing Systems, pp. 3111-3119; Mitton, R., (1985) Corpora of Misspellings for Download, , http://www.dcs.bbk.ac.uk/ROGER/corpora.html; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 427-436; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Security and Privacy (SP), 2016 IEEE Symposium on, pp. 582-597. , IEEE; Slawski, B., (2014) Google Turns to Deep Learning Classification to Fight Web Spam, , http://www.seobythesea.com/2014/09/google-turnsdeep-learning-classification-fight-web-spam, sep; Suchanek, F.M., Kasneci, G., Weikum, G., Yago: A core of semantic knowledge unifying wordnet and wikipedia (2007) Proceedings of the 16th International Conference on World Wide Web, pp. 697-706. , ACM; Sutton, M., Greene, A., Amini, P., Fuzzing: Brute force vulnerability discovery (2007) Pearson Education; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2014) Intriguing Properties of Neural Networks; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9; Topkara, U., Topkara, M., Atallah, M.J., The hiding virtues of ambiguity: Quantifiably resilient watermarking of natural language text through synonym substitutions (2006) Proceedings of the 8th Workshop on Multimedia and Security, pp. 164-174. , ACM; Topkara, M., Topkara, U., Atallah, M.J., Information hiding through errors: A confusing approach (2007) Security, Steganography, and Watermarking of Multimedia Contents, p. 65050V; Vybornova, O., Macq, B., Natural language watermarking and robust hashing based on presuppositional analysis (2007) Information Reuse and Integration, 2007. IRI 2007. IEEE International Conference on, pp. 177-182. , IEEE; Whittaker, C., Ryner, B., Nazif, M., Large-scale automatic classification of phishing pages (2010) NDSS, 10, p. 2010; Zhang, X., Zhao, J., LeCun, Y., Character-level convolutional networks for text classification (2015) Advances in Neural Information Processing Systems, pp. 649-657",,"Lang J.","International Joint Conferences on Artifical Intelligence (IJCAI)","International Joint Conferences on Artificial Intelligence","27th International Joint Conference on Artificial Intelligence, IJCAI 2018","13 July 2018 through 19 July 2018",,140653,10450823,9780999241127,,,"English","IJCAI Int. Joint Conf. Artif. Intell.",Conference Paper,"Final","All Open Access, Bronze, Green",Scopus,2-s2.0-85055723882
"Pang T., Du C., Zhu J.","57204799576;57194774618;56734692500;","Max-mahalanobis linear discriminant analysis networks",2018,"35th International Conference on Machine Learning, ICML 2018","9",,,"6409","6421",,9,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055721820&partnerID=40&md5=ffe29d0621739202e393234d4a14eb24","Dept. of Comp. Sci. and Tech., BNRist Center, State Key Lab for Intell. Tech. and Sys., THBI Lab, Tsinghua University, Beijing, 100084, China","Pang, T., Dept. of Comp. Sci. and Tech., BNRist Center, State Key Lab for Intell. Tech. and Sys., THBI Lab, Tsinghua University, Beijing, 100084, China; Du, C., Dept. of Comp. Sci. and Tech., BNRist Center, State Key Lab for Intell. Tech. and Sys., THBI Lab, Tsinghua University, Beijing, 100084, China; Zhu, J., Dept. of Comp. Sci. and Tech., BNRist Center, State Key Lab for Intell. Tech. and Sys., THBI Lab, Tsinghua University, Beijing, 100084, China","A deep neural network (DNN) consists of a nonlinear transformation from an input to a feature representation, followed by a common softmax linear classifier. Though many efforts have been devoted to designing a proper architecture for nonlinear transformation, little investigation has been done on the classifier part. In this paper, we show that a properly designed classifier can improve robustness to adversarial attacks and lead to better prediction results. Specifically, we define a Max-Mahalanobis distribution (MMD) and theoretically show that if the input distributes as a MMD, the linear discriminant analysis (LDA) classifier will have the best robustness to adversarial examples. We further propose a novel Max-Mahalanobis linear discriminant analysis (MM-LDA) network, which explicitly maps a complicated data distribution in the input space to a MMD in the latent feature space and then applies LDA to make predictions. Our results demonstrate that the MM-LDA networks are significantly more robust to adversarial attacks, and have belter performance in class-biased classification. ©35th International Conference on Machine Learning, ICML 2018.All Rights Reserved.",,"Artificial intelligence; Deep neural networks; Discriminant analysis; Linear transformations; Data distribution; Feature representation; Feature space; Input space; Linear classifiers; Linear discriminant analyses (LDA); Linear discriminant analysis; Non-linear transformations; Mathematical transformations",,,,,"Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) ACM Workshop on Artificial Intelligence and Security; Coates, A., Ng, A., Lee, H., An analysis of single-layer networks in unsupervised feature learning (2011) Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics, pp. 215-223; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., Imagenet: A large-scale hierarchical image database (2009) Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pp. 248-255. , IEEE; Efron, B., The efficiency of logistic regression compared to normal discriminant analysis (1975) Journal of the American Statistical Association, 70 (352), pp. 892-898; Fallah, F., Tsanev, D.M., Yang, B., Walter, S., Bamberg, F., A novel objective function based on a generalized kelly criterion for deep learning (2017) Signal Processing: Algorithms, Architectures, Arrangements, and Applications (SPA), 2017, pp. 84-89. , IEEE; Fei-Fei, L., Fergus, R., Perona, P., Learning generative visual models from few training examples: An incremental Bayesian approach tested on 101 object categories (2007) Computer Vision and Image Understanding, 106 (1), pp. 59-70; Friedman, J., Hastie, T., Tibshirani, R., (2001) The Elements of Statistical Learning, 1. , Springer series in statistics New York; Geiger, A., Lenz, P., Urtasun, R., Are we ready for autonomous driving? The kitti vision benchmark suite (2012) Conference on Computer Vision and Pattern Recognition (CVPR); Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, pp. 2672-2680; Goodfellow, I., Bengio, Y., Courville, A., (2016) Deep Learning, , MIT Press; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) The International Conference on Learning Representations (ICLR); He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 770-778; He, K., Zhang, X., Ren, S., Sun, J., Identity mappings in deep residual networks (2016) European Conference on Computer Vision (ECCV), pp. 630-645. , Springer; Hornik, K., Stinchcombe, M., White, H., Multilayer feedforward networks are universal approximators (1989) Neural Networks, 2 (5), pp. 359-366; Huang, C., Loy, C.C., Tang, X., Discriminative sparse neighbor approximation for imbalanced learning (2017) IEEE Transactions on Neural Networks and Learning Systems; Huang, F.J., LeCun, Y., Large-scale learning with SVM and convolutional for generic object categorization (2006) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 1, pp. 284-291. , IEEE; Kingma, D., Ba, J., Adam: A method for stochastic optimization (2015) The International Conference on Learning Representations (ICLR); Kingma, D.P., Welling, M., (2013) Auto-encoding Variational Bayes; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images, , Technical report; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2017) The International Conference on Learning Representations (ICLR) Workshops; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2017) The International Conference on Learning Representations (ICLR); LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proceedings of the IEEE, 86 (11), pp. 2278-2324; Liu, W., Wen, Y., Yu, Z., Yang, M., Large-margin softmax loss for convolutional neural networks (2016) ICML, pp. 507-516; Van Der Maaten, L., Hinton, G., Visualizing data using t-sne (2008) Journal of Machine Learning Research (JMLR), 9, pp. 2579-2605. , Nov; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2574-2582; Ngiam, J., Chen, Z., Chia, D., Koh, P.W., Le, Q.V., Ng, A.Y., Tiled convolutional neural networks (2010) Advances in Neural Information Processing Systems, pp. 1279-1287; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 427-436; Pang, T., Du, C., Dong, Y., Zhu, J., (2017) Towards Robust Detection of Adversarial Examples, , v; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387. , IEEE; Rothe, R., Timofte, R., Van Gool, L., Dex: Deep expectation of apparent age from a single image (2015) Proceedings of the IEEE International Conference on Computer Vision Workshops, pp. 10-15; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) The International Conference on Learning Representations (ICLR); Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2818-2826; Tang, Y., Deep learning using linear support vector machines (2013) International Conference on Machine Learning (ICML) Workshops; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses","Zhu, J.; Dept. of Comp. Sci. and Tech., China; email: dcszj@mail.tsinghua.edu.cn","Krause A.Dy J.",,"International Machine Learning Society (IMLS)","35th International Conference on Machine Learning, ICML 2018","10 July 2018 through 15 July 2018",,141700,,9781510867963,,,"English","Int. Conf. Mach. Learn., ICML",Conference Paper,"Final","",Scopus,2-s2.0-85055721820
"Ghafouri A., Vorobeychik Y., Koutsoukos X.","55364390100;8913948800;6603632868;","Adversarial regression for detecting attacks in cyber-physical systems",2018,"IJCAI International Joint Conference on Artificial Intelligence","2018-July",,,"3769","3775",,6,"10.24963/ijcai.2018/524","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055716325&doi=10.24963%2fijcai.2018%2f524&partnerID=40&md5=f5a63788735052f349f5415fd4b900ba","Cruise Automation, San Francisco, CA, United States; Electrical Engineering and Computer Science, Vanderbilt University, Nashville, TN, United States","Ghafouri, A., Cruise Automation, San Francisco, CA, United States; Vorobeychik, Y., Electrical Engineering and Computer Science, Vanderbilt University, Nashville, TN, United States; Koutsoukos, X., Electrical Engineering and Computer Science, Vanderbilt University, Nashville, TN, United States","Attacks in cyber-physical systems (CPS) which manipulate sensor readings can cause enormous physical damage if undetected. Detection of attacks on sensors is crucial to mitigate this issue. We study supervised regression as a means to detect anomalous sensor readings, where each sensor's measurement is predicted as a function of other sensors. We show that several common learning approaches in this context are still vulnerable to stealthy attacks, which carefully modify readings of compromised sensors to cause desired damage while remaining undetected. Next, we model the interaction between the CPS defender and attacker as a Stackelberg game in which the defender chooses detection thresholds, while the attacker deploys a stealthy attack in response. We present a heuristic algorithm for finding an approximately optimal threshold for the defender in this game, and show that it increases system resilience to attacks without significantly increasing the false alarm rate. © 2018 International Joint Conferences on Artificial Intelligence. All right reserved.",,"Artificial intelligence; Cyber Physical System; Embedded systems; Heuristic algorithms; Cyber-physical systems (CPS); Detecting attacks; Detection of attacks; Detection threshold; Learning approach; Optimal threshold; Stackelberg Games; System resiliences; Computer crime",,,,,"Bathelt, A., Ricker, N., Jelali, M., Revision of the Tennessee eastman process model (2015) IFAC-papersOnLine, 48 (8), pp. 309-314; Biggio, B., Fumera, G., Roli, F., Multiple classifier systems for robust classifier design in adversarial environments (2010) International Journal of Machine Learning and Cybernetics, 1 (1-4), pp. 27-41; Biggio, B., Fumera, G., Roli, F., Security evaluation of pattern classifiers under attack (2014) IEEE Transactions on Knowledge and Data Engineering, 26 (4), pp. 984-996; Cárdenas, A.A., Amin, S., Lin, Z.-S., Huang, Y.-L., Huang, C.-Y., Sastry, S., Attacks against process control systems: Risk assessment, detection, and response (2011) Proceedings of the 6th ACM Symposium on Information, Computer and Communications Security, pp. 355-366. , ACM; Dalvi, N., Domingos, P., Sanghai, S., Verma, D., Adversarial classification (2004) Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 99-108. , ACM; Downs, J.J., Vogel, E.F., A plant-wide industrial process control problem (1993) Computers & Chemical Engineering, 17 (3), pp. 245-255; Ghafouri, A., Abbas, W., Laszka, A., Vorobeychik, Y., Koutsoukos, X., Optimal thresholds for anomaly-based intrusion detection in dynamical environments (2016) International Conference on Decision and Game Theory for Security, pp. 415-434. , Springer; Ghafouri, A., Laszka, A., Dubey, A., Koutsoukos, X., Optimal detection of faulty traffic sensors used in route planning (2017) International Workshop on Science of Smart City Operations and Platforms Engineering (SCOPE), pp. 1-6; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations; Grosshans, M., Sawade, C., Brückner, M., Scheffer, T., Bayesian games for adversarial regression problems (2013) International Conference on International Conference on Machine Learning, pp. 55-63; Junejo, K.N., Goh, J., Behaviour-based attack detection and classification in cyber physical systems using machine learning (2016) Proceedings of the 2nd ACM International Workshop on Cyber-physical System Security, pp. 34-43. , ACM; Li, B., Vorobeychik, Y., Feature cross-substitution in adversarial classification (2014) Neural Information Processing Systems, pp. 2087-2095; Li, B., Vorobeychik, Y., Evasion-robust classification on binary domains (2018) ACM Transactions on Knowledge Discovery from Data, , to appear; Lowd, D., Meek, C., Adversarial learning (2005) Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining, pp. 641-647. , ACM; Nader, P., Honeine, P., Beauseroy, P., [lp]-norms in one-class classification for intrusion detection in scada systems (2014) IEEE Transactions on Industrial Informatics, 10 (4), pp. 2308-2317; Ricker, N., Decentralized control of the Tennessee eastman challenge process (1996) Journal of Process Control, 6 (4), pp. 205-221; Urbina, D.I., Giraldo, J.A., Cardenas, A.A., Tippenhauer, N.O., Valente, J., Faisal, M., Ruths, J., Sandberg, H., Limiting the impact of stealthy attacks on industrial control systems (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1092-1105. , ACM; Vorobeychik, Y., Li, B., Optimal randomized classification in adversarial settings (2014) International Conference on Autonomous Agents and Multiagent Systems, pp. 485-492",,"Lang J.","International Joint Conferences on Artifical Intelligence (IJCAI)","International Joint Conferences on Artificial Intelligence","27th International Joint Conference on Artificial Intelligence, IJCAI 2018","13 July 2018 through 19 July 2018",,140653,10450823,9780999241127,,,"English","IJCAI Int. Joint Conf. Artif. Intell.",Conference Paper,"Final","All Open Access, Bronze, Green",Scopus,2-s2.0-85055716325
"Hou M., Chaibdraa B., Li C., Zhao Q.","56939876400;56654421000;57171160100;21735304000;","Generative adversarial positive-unlabeled learning",2018,"IJCAI International Joint Conference on Artificial Intelligence","2018-July",,,"2255","2261",,22,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055716146&partnerID=40&md5=dd6b6d124e630930e06681e781691880","Tensor Learning Unit, Center for Advanced Intelligence Project, Riken, Japan; Department of Computer Science and Software Engineering, Laval University, Canada; Causal Inference Team, Center for Advanced Intelligence Project, Riken, Japan; School of Automation, Guangdong University of Technology, China","Hou, M., Tensor Learning Unit, Center for Advanced Intelligence Project, Riken, Japan; Chaibdraa, B., Department of Computer Science and Software Engineering, Laval University, Canada; Li, C., Causal Inference Team, Center for Advanced Intelligence Project, Riken, Japan; Zhao, Q., Tensor Learning Unit, Center for Advanced Intelligence Project, Riken, Japan, School of Automation, Guangdong University of Technology, China","In this work, we consider the task of classifying binary positive-unlabeled (PU) data. Existing discriminative learning based PU models attempt to seek an optimal reweighting strategy for unlabeled (U) data, so that a decent decision boundary can be found. However, given limited positive (P) data, the conventional PU models tend to suffer from overfitting when adapted to very flexible deep neural networks. In contrast, we are the first to innovate a totally new paradigm to attack the binary PU task, from the perspective of generative learning by leveraging the powerful generative adversarial networks (GAN). Our generative positive-unlabeled (GenPU) framework incorporates an array of discriminators and generators that are endowed with different roles in simultaneously producing positive and negative realistic samples. We also provide theoretical analysis to justify that, at equilibrium, GenPU is capable of recovering both positive and negative data distributions. Moreover, we show GenPU is generalizable and closely related to the semi-supervised classification. Given rather limited P data, experiments on both synthetic and real-world dataset demonstrate the effectiveness of our proposed framework. With infinite realistic and diverse samples generated from GenPU, a very flexible classifier can then be trained using deep neural networks. © 2018 International Joint Conferences on Artificial Intelligence. All right reserved.",,"Artificial intelligence; Supervised learning; Adversarial networks; Data distribution; Decision boundary; Discriminative learning; Overfitting; Re-weighting; Real-world; Semi-supervised classification; Deep neural networks",,,,,"Arjovsky, M., Chintala, S., Bottou, L., Wasserstein generative adversarial networks (2017) International Conference on Machine Learning, pp. 214-223; Denis, F., Gilleron, R., Letouzey, F.-B., Learning from positive and unlabeled examples (2005) Theoretical Computer Science, 348 (1), pp. 70-83; Du Plessis, M.C., Niu, G., Sugiyama, M., Analysis of learning from positive and unlabeled data (2014) Advances in Neural Information Processing Systems, pp. 703-711; Plessis, M.D., Niu, G., Sugiyama, M., Convex formulation for learning from positive and unlabeled data (2015) International Conference on Machine Learning, pp. 1386-1394; Elkan, C., Noto, K., Learning classifiers from only positive and unlabeled data (2008) SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 213-220. , ACM; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, pp. 2672-2680; Goodfellow, I., Bengio, Y., Courville, A., Bengio, Y., (2016) Deep Learning, , MIT press Cambridge; Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., Courville, A.C., Improved training of wasserstein GANs (2017) Advances in Neural Information Processing Systems, pp. 5769-5779; Hido, S., Tsuboi, Y., Kashima, H., Sugiyama, M., Kanamori, T., Inlier-based outlier detection via direct density ratio estimation (2008) International Conference on Data Mining, pp. 223-232. , IEEE; Jain, S., White, M., Radivojac, P., Estimating the class prior and posterior from noisy positives and unlabeled data (2016) Advances in Neural Information Processing Systems, pp. 2693-2701; Kiryo, R., Niu, G., Du Plessis, M.C., Sugiyama, M., Positive-unlabeled learning with non-negative risk estimator (2017) Advances in Neural Information Processing Systems, pp. 1674-1684; LeCun, Y., Boser, B.E., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W.E., Jackel, L.D., Handwritten digit recognition with a back-propagation network (1990) Advances in Neural Information Processing Systems, pp. 396-404; LeCun, Y., Cortes, C., Burges, C.J.C., (1998) The MNIST Database of Handwritten Digits, , http://yann.lecun.com/exdb/mnist/; Lee, W.S., Liu, B., Learning with positive and unlabeled examples using weighted logistic regression (2003) International Conference on Machine Learning, pp. 448-455; Li, X., Liu, B., Learning to classify texts using positive and unlabeled data (2003) International Joint Conference on Artifical Intelligence, pp. 587-592; Li, W., Guo, Q., Elkan, C., A positive and unlabeled learning algorithm for one-class classification of remote-sensing data (2011) IEEE Transactions on Geoscience and Remote Sensing, 49 (2), pp. 717-725; Liu, B., Lee, W.S., Yu, P.S., Li, X., Partially supervised classification of text documents (2002) International Conference on Machine Learning, pp. 387-394; Liu, B., Dai, Y., Li, X., Lee, W.S., Yu, P.S., Building text classifiers using positive and unlabeled examples (2003) International Conference on Data Mining, pp. 179-186. , IEEE; Liu, Z., Luo, P., Wang, X., Tang, X., Deep learning face attributes in the wild (2015) International Conference on Computer Vision, pp. 3730-3738; Patrini, G., Nielsen, F., Nock, R., Carioni, M., Loss factorization, weakly supervised learning and label noise robustness (2016) International Conference on Machine Learning, pp. 708-717; Salimans, T., Goodfellow, I., Zaremba, W.-C., Cheung, V., Radford, A., Chen, X., Improved techniques for training GANs (2016) Advances in Neural Information Processing Systems, pp. 2234-2242; Ward, G., Hastie, T., Barry, S., Elith, J., Leathwick, J.R., Presence-only data and the EM algorithm (2009) Biometrics, 65 (2), pp. 554-563","Zhao, Q.; Tensor Learning Unit, Japan; email: qibin.zhao@riken.jp","Lang J.","International Joint Conferences on Artifical Intelligence (IJCAI)","International Joint Conferences on Artificial Intelligence","27th International Joint Conference on Artificial Intelligence, IJCAI 2018","13 July 2018 through 19 July 2018",,140653,10450823,9780999241127,,,"English","IJCAI Int. Joint Conf. Artif. Intell.",Conference Paper,"Final","",Scopus,2-s2.0-85055716146
"Li X., Wu A., Zheng W.-S.","55959890900;56875087200;25928152800;","Adversarial Open-World Person Re-Identification",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11206 LNCS",,,"287","303",,6,"10.1007/978-3-030-01216-8_18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055456768&doi=10.1007%2f978-3-030-01216-8_18&partnerID=40&md5=f01e17055f36a865b665ac46c0d7ab5a","Sun Yat-sen University, Guangzhou, China; Inception Institute of Artificial Intelligence, Abu Dhabi, United Arab Emirates; Key Laboratory of Machine Intelligence and Advanced Computing, MOE, Guangzhou, China","Li, X., Sun Yat-sen University, Guangzhou, China; Wu, A., Sun Yat-sen University, Guangzhou, China; Zheng, W.-S., Sun Yat-sen University, Guangzhou, China, Inception Institute of Artificial Intelligence, Abu Dhabi, United Arab Emirates, Key Laboratory of Machine Intelligence and Advanced Computing, MOE, Guangzhou, China","In a typical real-world application of re-id, a watch-list (gallery set) of a handful of target people (e.g. suspects) to track around a large volume of non-target people are demanded across camera views, and this is called the open-world person re-id. Different from conventional (closed-world) person re-id, a large portion of probe samples are not from target people in the open-world setting. And, it always happens that a non-target person would look similar to a target one and therefore would seriously challenge a re-id system. In this work, we introduce a deep open-world group-based person re-id model based on adversarial learning to alleviate the attack problem caused by similar non-target people. The main idea is learning to attack feature extractor on the target people by using GAN to generate very target-like images (imposters), and in the meantime the model will make the feature extractor learn to tolerate the attack by discriminative learning so as to realize group-based verification. The framework we proposed is called the adversarial open-world person re-identification, and this is realized by our Adversarial PersonNet (APN) that jointly learns a generator, a person discriminator, a target discriminator and a feature extractor, where the feature extractor and target discriminator share the same weights so as to makes the feature extractor learn to tolerate the attack by imposters for better group-based verification. While open-world person re-id is challenging, we show for the first time that the adversarial-based approach helps stabilize person re-id system under imposter attack more effectively. © 2018, Springer Nature Switzerland AG.",,"Artificial intelligence; Computer science; Computers; Adversarial learning; Camera view; Discriminative learning; Feature extractor; Group-based; Large volumes; Model-based OPC; Person re identifications; Computer vision",,,,,"Ahmed, E., Jones, M.J., Marks, T.K., An improved deep learning architecture for person re-identification (2015) CVPR. IEEE Computer Society; Baltieri, D., Vezzani, R., Cucchiara, R., 3DPeS: 3D people dataset for surveillance and forensics (2011) Proceedings of the 1St International ACM Workshop on Multimedia Access to 3D Human Objects, Scottsdale, Arizona, USA, pp. 59-64. , November; Bedagkar-Gala, A., Shah, S.K., A survey of approaches and trends in person re-identification (2014) Image Vis. Comput., 32 (4), pp. 270-286; Cancela, B., Hospedales, T.M., Gong, S., (2014) Open-World Person Re-Identification by Multi-Label Assignment Inference, , In: Valstar, M.F., French, A.P., Pridmore, T.P. (eds.) BMVC. BMVA Press; Chen, Y.C., Zheng, W.S., Lai, J.H., Yuen, P.C., An asymmetric distance model for cross-view feature mapping in person reidentification (2017) IEEE Trans. Circuits Syst. Video Technol., 27 (8), pp. 1661-1675; Chen, Y.C., Zhu, X., Zheng, W.S., Lai, J.H., Person re-identification by camera correlation aware feature augmentation (2017) Corr Abs/1703, 8837; Cheng, D., Gong, Y., Zhou, S., Wang, J., Zheng, N., Person re-identification by multi-channel parts-based CNN with improved triplet loss function (2016) CVPR. IEEE Computer Society; Deng, W., Zheng, L., Ye, Q., Kang, G., Yang, Y., Jiao, J., Image-image domain adaptation with preserved self-similarity and domain-dissimilarity for person reidentification (2018) CVPR, p. 6. , IEEE Computer Society; Ding, S., Lin, L., Wang, G., Chao, H., (2015) Deep Feature Learning with Relative Distance Comparison for Person Re-Identification; Farenzena, M., Bazzani, L., Perina, A., Murino, V., Cristani, M., Person re-identification by symmetry-driven accumulation of local features (2010) CVPR. IEEE Computer Society; Gong, S., Cristani, M., Yan, S., Loy, C.C., (2014) Person Re-Identification, , https://doi.org/10.1007/978-1-4471-6296-4; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) CVPR. IEEE Computer Society; Hirzer, M., Beleznai, C., Roth, P.M., Bischof, H., Person re-identification by descriptive and discriminative classification (2011) SCIA 2011, 6688, pp. 91-102. , https://doi.org/10.1007/978-3-642-21227-79; Hirzer, M., Roth, P.M., Köstinger, M., Bischof, H., Relaxed pairwise learned metric for person re-identification (2012) ECCV 2012, 7577, pp. 780-793. , https://doi.org/10.1007/978-3-642-33783-356; Kawanishi, Y., Wu, Y., Mukunoki, M., Minoh, M., (2014) Shinpuhkan 2014: A Multicamera Pedestrian Dataset for Tracking People across Multiple Cameras; Kingma, D.P., Ba, J., (2014) Adam: A Method for Stochastic Optimization; Kviatkovsky, I., Adam, A., Rivlin, E., Color invariants for person reidentification (2013) IEEE Trans. Pattern Anal. Mach. Intell., 35 (7), pp. 1622-1634; Köstinger, M., Hirzer, M., Wohlhart, P., Roth, P.M., Bischof, H., Large scale metric learning from equivalence constraints (2012) CVPR. IEEE Computer Society; Li, W., Zhao, R., Wang, X., (2012) Human Reidentification with Transferred Metric Learning, , ACCV; Li, W., Zhao, R., Xiao, T., Wang, X., DeepReID: Deep filter pairing neural network for person re-identification (2014) CVPR. IEEE Computer Society; Liao, S., Hu, Y., Zhu, X., Li, S.Z., Person re-identification by local maximal occurrence representation and metric learning (2015) CVPR, pp. 2197-2206. , IEEE Computer Society; Liu, C., Gong, S., Loy, C.C., On-the-fly feature importance mining for person re-identification (2014) Pattern Recognit, 47 (4), pp. 1602-1615; Lu, J., Issaranon, T., Forsyth, D.A., (2017) Safetynet: Detecting and Rejecting Adversarial Examples Robustly; Ma, B., Su, Y., Jurie, F., BiCov: A novel image representation for person re-identification and face verification (2012) BMVC; Ma, B., Su, Y., Jurie, F., Covariance descriptor based on bio-inspired features for person re-identification and face verification (2014) Image Vis. Comput., 32 (6-7), pp. 379-390. , https://doi.org/10.1016/j.imavis.2014.04.002; Mignon, A., Jurie, F., PCCA: A new approach for distance learning from sparse pairwise constraints (2012) CVPR. IEEE Computer Society; Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P., DeepFool: A simple and accurate method to fool deep neural networks (2016) CVPR. IEEE Computer Society; Papernot, N., McDaniel, P.D., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., (2015) The Limitations of Deep Learning in Adversarial Settings; Radford, A., Metz, L., Chintala, S., (2015) Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks; Subramaniam, A., Chatterjee, M., Mittal, A., Deep neural networks with inexact matching for person re-identification (2016) NIPS; Szegedy, C., (2013) Intriguing Properties of Neural Networks; Tao, D., Jin, L., Wang, Y., Yuan, Y., Li, X., Person re-identification by regularized smoothing KISS metric learning (2013) IEEE Trans. Circuits Syst. Video Technol., 23 (10), pp. 1675-1685; Wang, H., Zhu, X., Xiang, T., Gong, S., Towards unsupervised open-set person re-identification (2016) ICIP. IEEE; Wang, T., Gong, S., Zhu, X., Wang, S., Person re-identification by discriminative selection in video ranking (2016) IEEE Trans. Pattern Anal. Mach. Intell., 38 (12), pp. 2501-2514; Wu, L., Shen, C., van den Hengel, A., (2016) Personnet: Person Re-Identification with Deep Convolutional Neural Networks; Wu, S., Chen, Y.C., Li, X., Wu, A., You, J., Zheng, W.S., (2016) An Enhanced Deep Feature Representation for Person Re-Identification; Xiao, T., Li, H., Ouyang, W., Wang, X., Learning deep feature representations with domain guided dropout for person re-identification (2016) CVPR. IEEE Computer Society; Zheng, L., Shen, L., Tian, L., Wang, S., Wang, J., Tian, Q., Scalable person re-identification: A Benchmark (2015) ICCV; Zheng, W.S., Gong, S., Xiang, T., Person re-identification by probabilistic relative distance comparison (2011) CVPR. IEEE Computer Society; Zheng, W.S., Gong, S., Xiang, T., Transfer re-identification: From person to set-based verification (2012) CVPR. IEEE Computer Society; Zheng, W.S., Gong, S., Xiang, T., Towards open-world person re-identification by one-shot group-based verification (2016) IEEE Trans. Pattern Anal. Mach. Intell., 38 (3), pp. 591-606; Zheng, Z., Zheng, L., Yang, Y., (2017) Unlabeled Samples Generated by GAN Improve the Person Re-Identification Baseline in Vitro; Zhong, Z., Zheng, L., Zheng, Z., Li, S., Yang, Y., Camera style adaptation for person re-identification (2018) CVPR, pp. 5157-5166. , IEEE Computer Society; Zhu, J., Zeng, H., Liao, S., Lei, Z., Cai, C., Zheng, L., (2017) Deep Hybrid Similarity Learning for Person Re-Identification; Zhu, X., Wu, B., Huang, D., Zheng, W.S., Fast open-world person re-identification (2017) IEEE Trans. Image Process., (99), p. 1. , https://doi.org/10.1109/TIP.2017.2740564","Zheng, W.-S.; Sun Yat-sen UniversityChina; email: wszheng@ieee.org","Hebert M.Weiss Y.Ferrari V.Sminchisescu C.",,"Springer Verlag","15th European Conference on Computer Vision, ECCV 2018","8 September 2018 through 14 September 2018",,219419,03029743,9783030012151,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85055456768
"Vivek B.S., Mopuri K.R., Babu R.V.","57203207864;57024033600;57202410887;","Gray-box adversarial training",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11219 LNCS",,,"213","228",,3,"10.1007/978-3-030-01267-0_13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055438686&doi=10.1007%2f978-3-030-01267-0_13&partnerID=40&md5=e7a92b9cac84761bd58ae819624a68fd","Indian Institute of Science, Bangalore, India","Vivek, B.S., Indian Institute of Science, Bangalore, India; Mopuri, K.R., Indian Institute of Science, Bangalore, India; Babu, R.V., Indian Institute of Science, Bangalore, India","Adversarial samples are perturbed inputs crafted to mislead the machine learning systems. A training mechanism, called adversarial training, which presents adversarial samples along with clean samples has been introduced to learn robust models. In order to scale adversarial training for large datasets, these perturbations can only be crafted using fast and simple methods (e.g., gradient ascent). However, it is shown that adversarial training converges to a degenerate minimum, where the model appears to be robust by generating weaker adversaries. As a result, the models are vulnerable to simple black-box attacks. In this paper we, (i) demonstrate the shortcomings of existing evaluation policy, (ii) introduce novel variants of white-box and black-box attacks, dubbed “gray-box adversarial attacks” based on which we propose novel evaluation method to assess the robustness of the learned models, and (iii) propose a novel variant of adversarial training, named “Gray-box Adversarial Training” that uses intermediate versions of the models to seed the adversaries. Experimental evaluation demonstrates that the models trained using our method exhibit better robustness compared to both undefended and adversarially trained models. © Springer Nature Switzerland AG 2018.","Adversarial perturbations; Adversarial training; Attacks on machine learning models; Robust machine learning models","Artificial intelligence; Learning systems; Adversarial perturbations; Evaluation policy; Experimental evaluation; Gradient ascent; Large datasets; Machine learning models; On-machines; Robust models; Computer vision",,,,,"Biggio, B., Evasion attacks against machine learning at test time (2013) Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 387-402; Biggio, B., Fumera, G., Roli, F., Pattern recognition systems under attack: Design issues and research challenges (2014) Int. J. Pattern Recogn. Artif. Intell., 28 (7); Carlini, N., Wagner, D.A., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy, SP, pp. 39-57. , San Jose, CA, USA, pp; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations (ICLR; Guo, C., Rana, M., Cisse, M., van der Maaten, L., Countering adversarial images using input transformations (2018) International Conference on Learning Representations (ICLR; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Computer Vision and Pattern Recognition (CVPR), pp. 770-778; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I., Tygar, J.D., Adversarial machinelearning.In:Proceedingsofthe4thACMWorkshoponSecurityand Artificial Intelligence (2011) Aisec 2011; Krizhevsky, A., Learning Multiple Layers of Features from Tiny Images, , Technical report, University of Toronto (2009); Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial machine learning at scale (2017) International Conference on Learning Representations (ICLR; Lecun, Y., The Mnist Database of Handwritten Digits, , http://yann.lecun.com/exdb/mnist/; Lecun, Y., Lenet-5, Convolutional Neural Networks, , http://yann.lecun.com/exdb/lenet/; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) International Conference on Learning Representations (ICLR; Madry, A., Makelov, A., Schmidt, L., Dimitris, T., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) International Conference on Learning Representations (ICLR; Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2574-2582; Mopuri, K.R., Garg, U., Babu, R.V., Fast feature fool: A data independent approach to universal adversarial perturbations (2017) Proceedings of the British Machine Vision Conference (BMVC; Mopuri, K.R., Ojha, U., Garg, U., Babu, R.V., NAG: Network for adversary generation (2018) Proceedings of the IEEE Computer Vision and Pattern Recognition (CVPR); Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) 2016 IEEE European Symposium on Security and Privacy (EuroS&P), pp. 372-387. , IEEE; Papernot, N., McDaniel, P.D., Goodfellow, I.J., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against deep learning systems using adversarial examples (2017) Asia Conference on Computer and Communications Security (ASIACCS); Samangouei, P., Kabkab, M., Chellappa, R., Defense-GAN: Protecting classifiers against adversarial attacks using generative models (2018) International Conference on Learning Representations (ICLR; Szegedy, C., Intriguing properties of neural networks (2014) International Conference on Learning Representations (ICLR); Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2018) International Conference on Learning Representations (ICLR); Zagoruyko, S., Komodakis, N., Wide residual networks Proceedings of the British Machine Vision Conference (BMVC), , Richard C., Wilson, E.R.H., Smith, W.A.P. (eds.), 87.1–87.12. BMVA Press (Sept 2016)","Vivek, B.S.; Indian Institute of ScienceIndia; email: svivek@iisc.ac.in","Weiss Y.Ferrari V.Sminchisescu C.Hebert M.",,"Springer Verlag","15th European Conference on Computer Vision, ECCV 2018","8 September 2018 through 14 September 2018",,219419,03029743,9783030012663,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85055438686
"Yang S., Wiliem A., Chen S., Lovell B.C.","57193111947;26423358900;7410259481;7003583184;","Using LIP to gloss over faces in single-stage face detection networks",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11219 LNCS",,,"664","681",,,"10.1007/978-3-030-01267-0_39","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055417985&doi=10.1007%2f978-3-030-01267-0_39&partnerID=40&md5=e9a0f656dfebde6dc79b0f22cde986e4","The University of Queensland, Brisbane, Australia","Yang, S., The University of Queensland, Brisbane, Australia; Wiliem, A., The University of Queensland, Brisbane, Australia; Chen, S., The University of Queensland, Brisbane, Australia; Lovell, B.C., The University of Queensland, Brisbane, Australia","This work shows that it is possible to fool/attack recent state-of-the-art face detectors which are based on the single-stage networks. Successfully attacking face detectors could be a serious malware vulnerability when deploying a smart surveillance system utilizing face detectors. In addition, for the privacy concern, it helps prevent faces being harvested and stored in the server. We show that existing adversarial perturbation methods are not effective to perform such an attack, especially when there are multiple faces in the inut image. This is because the adversarial perturbation specifically generated for one face may disrupt the adversarial perturbation for another face. In this paper, we call this problem the Instance Perturbation Interference (IPI) problem. This IPI problem is addressed by studying the relationship between the deep neural network receptive field and the adversarial perturbation. Besides the single-stage face detector, we find that the IPI problem also exists on the first stage of the Faster-RCNN, the commonly used two-stage object detector. As such, we propose the Localized Instance Perturbation (LIP) that confines the adversarial perturbation inside the Effective Receptive Field (ERF) of a target to perform the attack. Experimental results show the LIP method massively outperforms existing adversarial perturbation generation methods – often by a factor of 2 to 10. © Springer Nature Switzerland AG 2018.","Adversarial; Detection; Effective Receptive Field; Interference; Single-stage network","Computer vision; Deep neural networks; Error detection; Malware; Object detection; Perturbation techniques; Wave interference; Adversarial; Detection networks; Generation method; Object detectors; Perturbation method; Receptive fields; Single stage; Smart surveillance systems; Face recognition",,,,,"Chen, D., Hua, G., Wen, F., Sun, J., Supervised transformer network for efficient face detection (2016) ECCV 2016. LNCS, 9909, pp. 122-138. , https://doi.org/10.1007/978-3-319-46454-1_8, Leibe, B., Matas, J., Sebe, N., Welling, M. (eds.), Springer, Cham; Cisse, M., Adi, Y., Neverova, N., Keshet, J., Houdini: Fooling deep structured prediction models (2017) Advances in Neural Information Processing Systems (NIPS; Fischer, V., Kumar, M.C., Metzen, J.H., Brox, T., Adversarial examples for semantic image segmentation (2017) International Conference on Learning Representations (ICLR) Workshop; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations (ICLR; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Computer Vision and Pattern Recognition (CVPR). IEEE; Hu, P., Ramanan, D., Finding tiny faces (2017) Computer Vision and Pattern Recognition (CVPR). IEEE; Huang, J., Speed/accuracy trade-offs for modern convolutional object detectors (2017) Computer Vision and Pattern Recognition (CVPR). IEEE; Jain, V., Learned-Miller, E.G., Fddb: A benchmark for face detection in unconstrained settings (2010) Umass Amherst Technical Report; Jiang, H., Learned-Miller, E., Face detection with the faster r-cnn (2017) IEEE International Conference on Automatic Face & Gesture Recognition (FG). IEEE; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems (NIPS); Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2017) International Conference on Learning Representations (ICLR) Workshop; Li, H., Lin, Z., Shen, X., Brandt, J., Hua, G., A convolutional neural network cascade for face detection (2015) Computer Vision and Pattern Recognition (CVPR). IEEE; Li, Y., Sun, B., Wu, T., Wang, Y., Face detection with end-to-end integration of a convnet and a 3D model (2016) ECCV 2016. LNCS, 9907, pp. 420-436. , https://doi.org/10.1007/978-3-319-46487-9_26, Leibe, B., Matas, J., Sebe, N., Welling, M. (eds.), Springer, Cham; Lin, T.-Y., Microsoft COCO: Common objects in context ECCV 2014. LNCS, 8693, pp. 740-755. , https://doi.org/10.1007/978-3-319-10602-1_48, Fleet, D., Pajdla, T., Schiele, B., Tuytelaars, T. (eds.), Springer, Cham (2014); Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., Fu, C.-Y., Berg, A.C., SSD: Single shot MultiBox detector (2016) ECCV 2016. LNCS, 9905, pp. 21-37. , https://doi.org/10.1007/978-3-319-46448-0_2, Leibe, B., Matas, J., Sebe, N., Welling, M. (eds.), Springer, Cham; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) International Conference on Learning Representations (ICLR; Long, J., Shelhamer, E., Darrell, T., Fully convolutional networks for semantic segmentation (2015) Computer Vision and Pattern Recognition (CVPR). IEEE; Luo, W., Li, Y., Urtasun, R., Zemel, R., Understanding the effective receptive field in deep convolutional neural networks (2016) Advances in Neural Information Processing Systems (NIPS); Metzen, J.H., Kumar, M.C., Brox, T., Fischer, V., Universal adversarial perturbations against semantic image segmentation (2017) International Conference on Computer Vision (ICCV). IEEE; Mirjalili, V., Raschka, S., Namboodiri, A., Ross, A., Semi-adversarial networks: Convolutional autoencoders for imparting privacy to face images (2018) International Conference on Biometrics (ICB); Mirjalili, V., Ross, A., Soft biometric privacy: Retaining biometric utility of face images while perturbing gender (2017) International Joint Conference on Biometrics (IJCB); Moosavi-Dezfooli, S.M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) Computer Vision and Pattern Recognition (CVPR). IEEE; Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Computer Vision and Pattern Recognition (CVPR). IEEE; Najibi, M., Samangouei, P., Chellappa, R., Davis, L., Ssh: Single stage headless face detector (2017) International Conference on Computer Vision (ICCV). IEEE; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Computer Vision and Pattern Recognition (CVPR). IEEE; Qin, H., Yan, J., Li, X., Hu, X., Joint training of cascaded cnn for face detection (2016) Computer Vision and Pattern Recognition (CVPR). IEEE; Redmon, J., Divvala, S., Girshick, R., Farhadi, A., You only look once: Unified, real-time object detection (2016) Computer Vision and Pattern Recognition (CVPR). IEEE; Ren, S., He, K., Girshick, R., Sun, J., Faster r-cnn: Towards real-time object detection with region proposal networks (2015) Advances in Neural Information Processing Systems (NIPS); Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, , ACM; Shrivastava, A., Gupta, A., Girshick, R., Training region-based object detectors with online hard example mining (2016) Computer Vision and Pattern Recognition (CVPR). IEEE; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) International Conference on Learning Representations (ICLR; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations (ICLR; Viola, P., Jones, M., Rapid object detection using a boosted cascade of simple features (2001) Computer Vision and Pattern Recognition (CVPR). IEEE; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., Mitigating adversarial effects through randomization (2018) International Conference on Learning Representations (ICLR; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., Adversarial examples for semantic segmentation and object detection (2017) International Conference on Computer Vision (ICCV). IEEE; Yamada, T., Gohshi, S., Echizen, I., Privacy Visor: Method for preventing face image detection by using differences in human and device sensitivity (2013) CMS 2013. LNCS, 8099, pp. 152-161. , https://doi.org/10.1007/978-3-642-40779-6_13, Decker, B., Dittmann, J., Kraetzer, C., Vielhauer, C. (eds.), Springer, Heidelberg; Yang, S., Luo, P., Loy, C.C., Tang, X., From facial parts responses to face detection: A deep learning approach (2015) International Conference on Computer Vision (ICCV); Yang, S., Luo, P., Loy, C.C., Tang, X., Wider face: a face detection benchmark (2015) Computer Vision and Pattern Recognition (CVPR), , IEEE; Zhang, K., Zhang, Z., Li, Z., Qiao, Y., Joint face detection and alignment using multitask cascaded convolutional networks (2016) IEEE Signal Process. Lett., 23 (10), pp. 1499-1503; Zhang, S., Zhu, X., Lei, Z., Shi, H., Wang, X., Li, S.Z., S3 fd: Single shot scale-invariant face detector (2017) International Conference on Computer Vision (ICCV), , IEEE","Yang, S.; The University of QueenslandAustralia; email: siqi.yang@uq.net.au","Weiss Y.Ferrari V.Sminchisescu C.Hebert M.",,"Springer Verlag","15th European Conference on Computer Vision, ECCV 2018","8 September 2018 through 14 September 2018",,219419,03029743,9783030012663,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85055417985
"Balcan M.-F., Blum A., Chen S.-T.","8954993900;7402674963;55377234300;","Diversified strategies for mitigating adversarial attacks in multiagent systems",2018,"Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS","1",,,"407","415",,3,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055340167&partnerID=40&md5=9c6687aa618ecb6035d9d3cf0bd945ea","Carnegie Mellon University, United States; TTI, Chicago, United States; Georgia Institute of Technology, United States","Balcan, M.-F., Carnegie Mellon University, United States; Blum, A., TTI, Chicago, United States; Chen, S.-T., Georgia Institute of Technology, United States","In this work we consider online decision-making in settings where players want to guard against possible adversarial attacks or other catastrophic failures. To address this, we propose a solution concept in which players have an additional constraint that at each time step they must play a diversified mixed strategy: one that does not put too much weight on any one action. This constraint is motivated by applications such as finance, routing, and resource allocation, where one would like to limit one's exposure to adversarial or catastrophic events while still perfonning well in typical cases. We explore prope rties of diversified strategies in both zero-sum and general-sum games, and provide algorithms for minimizing regret within the family of diversified strategies as well as methods for using taxes or fees to guide standard regret-minimizing players towards divers ified strategies. We also analyze equilibria produced by diversified strategies in general-sum games. We show that surprisingly, requiri ng diversification can actually lead to higher-welfare equilibria, and give strong guarantees on both price of anarchy and the social welfare produced by regret-minimizing diversified agents. We addit ionally give algorithms for finding optimal diversified strategies in distributed settings where one must limit communication overhead. © 2018 International Foundation for Autonomous Agents and Multiagent Systems.","Adversarial multiagent systems; Diversified strategies; Game theory; General-sum games; Regret minimization; Risk mitigation","Decision making; Game theory; Multi agent systems; Catastrophic event; Catastrophic failures; Communication overheads; Diversified strategies; General sum games; On-line decision makings; Regret minimization; Risk mitigation; Autonomous agents",,,,,"Axon, S., Harass, E., Kale, S., Fast algorithms for appxoxl mate semldefinite programming using the multiplicative weights update method (2005) IEEE Symposium on Foundations of Computer Science (FOCS05 IEEE, pp. 339-344; Axons, S., Harass, E., Kale, S., The multiplicative weights update method. A mets-algorithm and applications (2012) Theory of Computing, 8 (1), pp. 121-164. , 2012; Babaioff, M., Kleinberg, R., Papadlmitsiou, C.H., Coisgesl ion gamea with malicious players (2007) Proceedings of the 8th ACM Conference on Elentc osmmeree, pp. 103-112. , ACM; Balcan, M.F., Blunt, A., Fine, S., Mansour, Y., DIstributed learning communication complexity and privacy (2012) Journal of Machine Learning ResearchP i'oceedlngs Track, 23, pp. 261-2622. , 2012; Balcan, M.-F., Blues, A., Mansour, Y., The price of uncertaint (2008) Proceedings of the 10th ACM conference on Ekcrronic commerce. ACM, pp. 285-294; Balcan, M.-F., Constantln, F., Ehrhck, S., The snowball effect of uncertainty In potential games (2011) Internet and Network Economics, pp. 1-12. , In Ineernazlo,tal Workshop osiSpflnger; Blues, A., Mansour, Y., (2007) Leaning Regret MiMmixattos. and Equilibria, pp. 79-102. , https:/ldoLocgIlO.1017/CO9780511800481.006, Cambridge University Press; Casagiannis, L., Kurokawa, D., Procaccia, A.D., (2014) Biased Games. Lit MAL, pp. 609-615; Ceu-Biandsl, N., Lugost, G., (2006) Pivdicttor, Leaning and Games, , Cambridge university press; Balcan, S.C., Chau, D., Communication efficient distributed agnostic boosting (2011) Proceedings of the 19th InternatIonal Conference on Artificial lnselhgeitce aid Siatlstics. AJSTATS, pp. 1299-1307. , 2016. Cadiz Spain. May 9-11,2016; Clien, S.T., Lisa, H.T., Lu, C.-I., An online boosting algorithm with theoreticaljustiflcations (2012) Proceedings of RML, pp. 1007-1014; Hal, D., Phillips, J.M., Avishek, S.M., Venkatssubrmn, S., Efficient protocols (or distributed classsflcation and optimization (2012) Proceedings of the 23rd lnieniatlonal Conference on Algorithmic Learning Theory (ALT'12, pp. 154-168; Freund, Y., Schaplre, R.E., A decision-Theoretic generalization of on line learning and an application to boosting j (1997) CompuL System Sd., 55 (1), pp. 119-139. , 1997; Freund, Y., Schapire, R., Adaptive game playing using multip licstive weights (1999) Games and Economic BehavIor, 29 (1), pp. 79-103. , 1999; Gavlky, D., Optimally-smooth Adaptive Boosting and Application toAgssosttcLeainlng (2003) J. Mack Leant. Res, 4, pp. 101-117. , 2003; Heist, M., Astdrtushdsenkcs, M., Formal guarantees on the robusmess of classifier against adversarial manipulation (2017) Advances in Neural Information Processing Systems, pp. 223-2273; Herbster, M., Wazmuth, M.K., TrackIng the best linear predictol (2001) J Mack. Learn. Res., 1, pp. 281-309. , 2001); Impagliazzo, R., Hard-core distributions for somewhat hard problems. In Foundations of Computer Science. 1995 (1995) ProceedIngs.. 36th Annual Symposium on, pp. 538-545. , IEEE; Littlestone, N., Warmuth, M.K., The weighted maortty algorithm (1959) Foundations of Computer Science. 1919.. 30th Annual Symposium, pp. 256-261; Panagopoulou, P.N., Spirakls, P.G., Random blesatnix games me asymptotically easy to solve (A simple proof (2014) Theory of Co.niputuig Systems, 54 (3), pp. 479-490. , 2014; Rosentha, R.W., A class of games possessing pure-strategy Nash equilibria (1911) Lissernational Journal of Game Theory, 2 (1), pp. 65-67. , 1973; Roughgarden, T., Routing games (2007) Algorithmic Game Theory, 18, p. 459. , 2007; Roughgarden, T., Intrinsic robustness of the price of anarchy (2015) J. ACM, 62 (5), pp. 321-3242. , httpsIldol.orgIlO.l14512806883, 2015; Sion, M., On general missimax theorems (1958) Pacific J Math, S., 1, pp. 171-176. , 1958); Szegedy, C., Zaremba, W., Sutskever, I., Bnuna, J., Intslgulng properties of neural networks (2014) ZCL",,,"Artificial Intelligence;Elsevier;et al.;International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS);Nissan;NSF","International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS)","17th International Conference on Autonomous Agents and Multiagent Systems, AAMAS 2018","10 July 2018 through 15 July 2018",,139890,15488403,9781510868083,,,"English","Proc. Int. Joint Conf. Auton. Agents Multiagent Syst., AAMAS",Conference Paper,"Final","",Scopus,2-s2.0-85055340167
"Yu S., Vorobeychik Y., Alfeld S.","57193240885;8913948800;55232344500;","Adversarial classification on social networks",2018,"Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS","1",,,"211","219",,9,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055330337&partnerID=40&md5=09b8d0eb27da6a86a1fa09366ba46e8c","Electrical Engineering and Computer Science, Vanderbilt University, Nashville, TN, United States; Computer Science, Amherst College, Amherst, MA, United States","Yu, S., Electrical Engineering and Computer Science, Vanderbilt University, Nashville, TN, United States; Vorobeychik, Y., Electrical Engineering and Computer Science, Vanderbilt University, Nashville, TN, United States; Alfeld, S., Computer Science, Amherst College, Amherst, MA, United States","The spread of unwanted or malicious content through social med ia has become a major challenge. Traditional examples of this include social network spain, but an important new concern is the propagation of fake news through social media. A common app roach for mitigating this problem is by using standard statistical classification to distinguish malicious (e.g., fake news) instances from benign (e.g.. actual news stories). However, such an approach ignores the fact that malicious instances propagate through the network, which is consequential both in quantifying consequences (e.g.. fake news diffusing through the network), and capturing det ection redundancy (bad content can be detected at different nodes). An additional concern is evasion attacks, whereby the generators of malicious instances modify the nature of these to escape detection. We model this problem as a Stackelberg game between the defender who is choosing parameters of the detection model, and an attacker, who is choosing both the node at which to initiate malicious spread, and the nature of malicious entities. We develop a novel bi-level programming approach for this problem, as well as a novel solution approach based on implicit function gradients, and experimentally demonstrate the advantage of our approach over alternatives which ignore network structure. © 2018 International Foundation for Autonomous Agents and Multiagent Systems.",,"Multi agent systems; Adversarial classifications; Bi-level programming; Implicit function; Malicious entity; Network structures; Solution approach; Stackelberg Games; Statistical classification; Autonomous agents",,,,,"Ailcolt, H., Oentzkow, M., (2017) Social Media and Fake News In the 2016 Election, , Technical report. National Bureau oFEconondc Research; Barabdsl, A.-L., Albert, R., Emergence of scaling In random networks (1999) Science., 286, pp. 509-512; Barabssl, A.L., Nlda, Z., Ravaszk, E., Vicsek, T., Evolution of the social network o(scientiflc collaborations (2002) Physlca A Statistical Mechanics and Its Applications., 31 (3), pp. 590-614; Baxreno, I., Nelson, B., Sears, P., Joseph, A., Typr, J., Can machine learning be secure? (2006) ProceedIngs of the 20176 ACM Symposium on Information. Computer and Communications Security, pp. 16-25. , ACM; Boyd, S., Vandenberghe, L., (2004), Cnvix optlmLzarloIL Cambridge university press; Bruckner, M., Scheffer, I., Stackelberg games for adversarial prediction probl ems (2011) Proceedings of rAe 17th ACM SIGKDD, pp. 541-555. , ACM; Budaic, C., El Abbadi, A., Limiting the spread of misinformation in social networks (2011) Proceedings of the 20th Internallone Conference on Woeld wide web, pp. 665-674. , ACM; Surges, C.J., A tutorial on support vector machines for pattern recognition (1998) Data mining and knowf edge discovery., 2 (2), pp. 121-167; Cheng, J., Dassescu-Nlculescis-Mlzil, C., Leskovec, J., Antisocial behavior In online discussion communities (2015) Interiiojlonal Conference on Weblogs and Social Media, pp. 61-70; Colson, B., Marcotte, P., Savud, O., An overview of blievel optimization (2007) Mnssls of operations research, 153 (1), pp. 235-256; Cormack, O.V., Email span filtering: A systematic review. Foiusdations and Trends Is (2008) Information Retrttval, 1 (4), pp. 335-455; Dalvi, N., Domlngos, P., Sangbal, S., Verma, D., Adversarial classification (2004) Proceedings of the Tenth ACM SIGKDD, pp. 99-108. , ACM; Song, N.O.L., Scalable Influence estimation In continuous time diffusion networks Advances Inseurdl Information processing systems, pp. 3147-3155; Song, N.D.I., Woo, H., Tha, H., Uncover topic-sensitive Infornialion diffusion networks (2013) Arriflctal IntellIgence and Statistics, pp. 229-237; Du, N., Song, L., Yuan, M., Smota, A.J., Learning networks of heterogeneous Influence (2012) Advances in Neural Information Processing Systems, pp. 2780-2788; Gomez-Rodriguez, M., Schoflcopl, B., Issiluence 4ni,tion In continuous time ddfutlon networks Proceedings of the 29th InternatIonal Coference on Inteniational Conference on Machine Learning, pp. 579-586. , Osnnlpress. 2012; Gottfried, J., Mitchell, A., News use across social media platforms (2013) Pew Research JournalIsm PtuJecs; Lcleinberg, J., Maximizing the spreid o(influence through a social network (2003) Proceedings of the ninth ACM SJGKDD, pp. 137-146. , ACM; Vorobeychik, Y., Feature cross-substitution In adversarial classification (2014) Advances in neural Information processing systems, pp. 2081-2095; Li, B., Vorobeychik, Y., Chess, X., (2016) A General Retraining Framework for Scalable Adversarial Classification, , arXlvpreprtnt arXWl6D4.O26O; Lichmaa, M., (2013) UCI Machine Learning Repository; Lowd, O., Meek, C., Adversarial learning (2008) Proceedings of the eleventh ACM SIGKDD, pp. 641-647. , ACM; Mel, S., Thu, X., Using machine teaching to identify optimal tralnlng.ael attacks on machine leirners (2015) AAAI Conference on Artificial IntellIgence, pp. 2871-2877; Thi, J., Tainbe, N., Security games for controlling contagion (2012) AAAJ Conference on Artificial Intelligence; Ugandes, J., Icarrer, B., Backatrom, L., Maclow, C., (2011) The Anatoesy of the Facebook Social Graph, , arXivprrpilntarXivllli.4S03; Vorobeychik, R., Letchford, J., Securing interdependent assets (2015) Autonomous Agents and Mtsltl-Ageid Systems., 29 (2), pp. 305-333; Walllssga, J., Tennis, P., Differeut epidemic cwves for severe acute respiratory syndrome reveal similar Impacts of control measures. American (2004) Journal of EpIdemiology., 160 (6), pp. 509-516; With, D.J., Strogaz, S.H., Collective dynamics of smaUworld networks (1998) Nature., 393, pp. 440-442. , 6684); Zorich, V.A., Cookt, P., (2004) Mathematical Analysis I",,,"Artificial Intelligence;Elsevier;et al.;International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS);Nissan;NSF","International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS)","17th International Conference on Autonomous Agents and Multiagent Systems, AAMAS 2018","10 July 2018 through 15 July 2018",,139890,15488403,9781510868083,,,"English","Proc. Int. Joint Conf. Auton. Agents Multiagent Syst., AAMAS",Conference Paper,"Final","",Scopus,2-s2.0-85055330337
"Mopuri K.R., Uppala P.K., Babu R.V.","57024033600;57204288344;57202410887;","Ask, acquire, and attack: data-free UAP generation using class impressions",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11213 LNCS",,,"20","35",,4,"10.1007/978-3-030-01240-3_2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055135956&doi=10.1007%2f978-3-030-01240-3_2&partnerID=40&md5=1b70d58cbcc70be0071c80995903ed5a","Video Analytics Lab, Indian Institute of Science, Bangalore, India","Mopuri, K.R., Video Analytics Lab, Indian Institute of Science, Bangalore, India; Uppala, P.K., Video Analytics Lab, Indian Institute of Science, Bangalore, India; Babu, R.V., Video Analytics Lab, Indian Institute of Science, Bangalore, India","Deep learning models are susceptible to input specific noise, called adversarial perturbations. Moreover, there exist input-agnostic noise, called Universal Adversarial Perturbations (UAP) that can affect inference of the models over most input samples. Given a model, there exist broadly two approaches to craft UAPs: (i) data-driven: that require data, and (ii) data-free: that do not require data samples. Data-driven approaches require actual samples from the underlying data distribution and craft UAPs with high success (fooling) rate. However, data-free approaches craft UAPs without utilizing any data samples and therefore result in lesser success rates. In this paper, for data-free scenarios, we propose a novel approach that emulates the effect of data samples with class impressions in order to craft UAPs using data-driven objectives. Class impression for a given pair of category and model is a generic representation (in the input space) of the samples belonging to that category. Further, we present a neural network based generative model that utilizes the acquired class impressions to learn crafting UAPs. Experimental evaluation demonstrates that the learned generative model, (i) readily crafts UAPs via simple feed-forwarding through neural network layers, and (ii) achieves state-of-the-art success rates for data-free scenario and closer to that for data-driven setting without actually utilizing any data samples. © Springer Nature Switzerland AG 2018.","Adversarial attacks; Attacks on ML systems; Class impressions; Data-free attacks; Image-agnostic perturbations","Computer vision; Deep learning; Adversarial attacks; Class impressions; Data-free attacks; Image-agnostic perturbations; Ml systems; Network layers",,,,,"Abadi, M., TensorFlow: Large-scale machine learning on heterogeneous systems (2015) Tensorflow.Org, , http://tensorflow.org/; Baluja, S., Fischer, I., Learning to attack: Adversarial transformation networks (2018) Proceedings of AAAI; Biggio, B., Evasion attacks against machine learning at test time (2013) ECML PKDD 2013 Part III. LNCS (LNAI), 8190, pp. 387-402. , https://doi.org/10.1007/978-3-642-40994-325, Bloc-keel, H., Kersting, K., Nijssen, S., Železný, F. (eds.), Springer, Heidelberg; Biggio, B., Fumera, G., Roli, F., Pattern recognition systems under attack: Design issues and research challenges (2014) Int. J. Pattern Recogn. Artif. Intell., 28 (7); Chatfield, K., Simonyan, K., Vedaldi, A., Zisserman, A., Return of the devil in the details: Delving deep into convolutional nets (2014) Proceedings of the British Machine Vision Conference (BMVC); Goodfellow, I.J., Generative adversarial nets (2014) Advances in Neural Information Processing Systems (NIPS); Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations (ICLR; He, K., Zhang, X., Ren, S., Sun, J., (2015) Deep Residual Learning for Image Recognition, , arXiv preprint arXiv; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I., Tygar, J.D., Adversarial machine learning (2011) Proceedings of the 4Th ACM Workshop on Security and Artificial Intelligence, Aisec 2011; Kingma, D., Ba, J., (2014) Adam: A Method for Stochastic Optimization, , arXiv preprint arXiv; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2017) International Conference on Learning Representations (ICLR; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) International Conference on Learning Representations (ICLR; Moosavi-Dezfooli, S., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Moosavi-Dezfooli, S., Fawzi, A., Frossard, P., DeepFool: A simple and accurate method to fool deep neural networks (2016) IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Mopuri, K.R., Ganeshan, A., Babu, R.V., Generalizable data-free objective for crafting universal adversarial perturbations (2018) IEEE Trans. Pattern Anal. Mach. Intell.; Mopuri, K.R., Garg, U., Babu, R.V., (2017) CNN Fixations: An Unraveling Approach to Visualize the Discriminative Image Regions, , arXiv preprint arXiv; Mopuri, K.R., Garg, U., Babu, R.V., Fast feature fool: A data independent approach to universal adversarial perturbations (2017) Proceedings of the British Machine Vision Conference (BMVC; Mopuri, K.R., Ojha, U., Garg, U., Babu, R.V., NAG: Network for adversary generation (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Mordvintsev, A., Tyka, M., Olah, C., (2015) Google Deep Dream, , https://research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html; Olah, C., Mordvintsev, A., Schubert, L., Feature visualization (2017) Distill, , https://distill.pub/2017/feature-visualization; Papernot, N., McDaniel, P.D., Goodfellow, I.J., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against deep learning systems using adversarial examples (2017) Asia Conference on Computer and Communications Security, , ASIACCS; Radford, A., Metz, L., Chintala, S., (2015) Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks, , arXiv preprint arXiv; Russakovsky, O., ImageNet large scale visual recognition challenge (2015) Int. J. Comput. Vis. (IJCV), 115 (3), pp. 211-252; Salimans, T., Goodfellow, I.J., Zaremba, W., Cheung, V., Radford, A., Chen, X., Improved techniques for training GANs (2016) Advances in Neural Information Processing Systems (NIPS); Selvaraju, R.R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., Batra, D., Grad-CAM: Visual explanations from deep networks via gradient-based localization (2017) The IEEE International Conference on Computer Vision (ICCV); Simonyan, K., Vedaldi, A., Zisserman, A., Deep inside convolutional networks: Visu-alising image classification models and saliency maps (2014) International Conference on Learning Representations ICLR Workshops; Springenberg, J., Dosovitskiy, A., Brox, T., Riedmiller, M., Striving for simplicity: The all convolutional net (2015) International Conference on Learning Representations (ICLR) (Workshop Track; Szegedy, C., Intriguing properties of neural networks (2013) International Conference on Learning Representations (ICLR; Zeiler, M.D., Fergus, R., Visualizing and understanding convolutional networks (2014) European Conference on Computer Vision (ECCV), pp. 818-833; Zhang, J., Lin, Z., Brandt, J., Shen, X., Sclaroff, S., Top-down neural attention by excitation backprop (2016) European Conference on Computer Vision (ECCV); Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., Torralba, A., Learning deep features for discriminative localization (2016) Proceedings of Computer Vision and Pattern Recognition (CVPR)","Mopuri, K.R.; Video Analytics Lab, India; email: kondamopuri@iisc.ac.in","Hebert M.Ferrari V.Sminchisescu C.Weiss Y.",,"Springer Verlag","15th European Conference on Computer Vision, ECCV 2018","8 September 2018 through 14 September 2018",,219419,03029743,9783030012397,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85055135956
"Liu X., Cheng M., Zhang H., Hsieh C.-J.","57210642015;57201213233;57192486575;24502954900;","Towards robust neural networks via random self-ensemble",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11211 LNCS",,,"381","397",,14,"10.1007/978-3-030-01234-2_23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055128669&doi=10.1007%2f978-3-030-01234-2_23&partnerID=40&md5=799292c24822979627e3342a2f705313","Electrical and Computer Science, UC Davis, Davis, CA  95616, United States; Department of Statistics, UC Davis, Davis, CA  95616, United States","Liu, X., Electrical and Computer Science, UC Davis, Davis, CA  95616, United States; Cheng, M., Electrical and Computer Science, UC Davis, Davis, CA  95616, United States; Zhang, H., Electrical and Computer Science, UC Davis, Davis, CA  95616, United States; Hsieh, C.-J., Electrical and Computer Science, UC Davis, Davis, CA  95616, United States, Department of Statistics, UC Davis, Davis, CA  95616, United States","Recent studies have revealed the vulnerability of deep neural networks: A small adversarial perturbation that is imperceptible to human can easily make a well-trained deep neural network misclassify. This makes it unsafe to apply neural networks in security-critical applications. In this paper, we propose a new defense algorithm called Random Self-Ensemble (RSE) by combining two important concepts: randomness and ensemble. To protect a targeted model, RSE adds random noise layers to the neural network to prevent the strong gradient-based attacks, and ensembles the prediction over random noises to stabilize the performance. We show that our algorithm is equivalent to ensemble an infinite number of noisy models fϵ without any additional memory overhead, and the proposed training procedure based on noisy stochastic gradient descent can ensure the ensemble model has a good predictive capability. Our algorithm significantly outperforms previous defense techniques on real data sets. For instance, on CIFAR-10 with VGG network (which has 92% accuracy without any attack), under the strong C&amp;W attack within a certain distortion tolerance, the accuracy of unprotected model drops to less than 10%, the best previous defense technique has 48 % accuracy, while our method still has 86 % prediction accuracy under the same level of attack. Finally, our method is simple and easy to integrate into any neural network. © Springer Nature Switzerland AG 2018.",,"Computer vision; Network security; Stochastic models; Stochastic systems; Defense techniques; Distortion tolerance; Ensemble modeling; Prediction accuracy; Predictive capabilities; Security critical applications; Stochastic gradient descent; Training procedures; Deep neural networks",,,,,"Athalye, A., Carlini, N., (2018) On the Robustness of the CVPR 2018 White-Box Adversarial Example Defenses, , arXiv preprint arXiv; Athalye, A., Carlini, N., Wagner, D., Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples (2018) 35Th International Conference on Machine Learning (ICML); Buckman, J., Roy, A., Raffel, C., Goodfellow, I., Thermometer encoding: One hot way to resist adversarial examples (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=S18Su-CW; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) Proceedings of the 10Th ACM Workshop on Artificial Intelligence and Security, Aisec 2017, pp. 3-14. , https://doi.org/10.1145/3128572.3140444, ACM, New York, http://doi.acm.org/10.1145/3128572.3140444; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy (SP), pp. 39-57. , IEEE; Chen, P.Y., Sharma, Y., Zhang, H., Yi, J., Hsieh, C.J., EAD: Elastic-net attacks to deep neural networks via adversarial examples (2018) Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence; Dean, J., Large scale distributed deep networks (2012) Advances in Neural Information Processing Systems, pp. 1223-1231; Dhillon, G.S., Stochastic activation pruning for robust adversarial defense (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=H1uR4GZRZ; Eykholt, K., Robust physical-world attacks on deep learning visual classification (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1625-1634; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts, , arXiv preprint arXiv; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations, , http://arxiv.org/abs/1412.6572; Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., (2017) On the (Sta-Tistical) Detection of Adversarial Examples, , arXiv preprint arXiv; Guo, C., Rana, M., Cisse, M., van der Maaten, L., Countering adversarial images using input transformations (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=SyJ7ClWCb; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Hein, M., Andriushchenko, M., Formal guarantees on the robustness of a classifier against adversarial manipulation (2017) Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, pp. 2263-2273. , 4–9 December 2017, Long Beach, CA, USA; Huang, R., Xu, B., Schuurmans, D., Szepesvári, C., (2015) Learning with a Strong Adversary, , arXiv preprint arXiv; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2017) International Conference on Learning Representations (ICLR; Lecuyer, M., Atlidakis, V., Geambasu, R., Hsu, D., Jana, S., (2018) Certified Robustness to Adversarial Examples with Differential Privacy, , ArXiv e-prints, February; Ma, X., Characterizing adversarial subspaces using local intrinsic dimensionality (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=B1gJ1L2aW; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) 6-Th International Conference on Learning Representations (ICLR; Meng, D., Chen, H., MagNet: A two-pronged defense against adversarial examples (2017) Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pp. 135-147. , https://doi.org/10.1145/3133956.3134057, CCS 2017, ACM, New York; Noh, H., You, T., Mun, J., Han, B., Regularizing deep neural networks by noise: Its interpretation and optimization (2017) Advances in Neural Information Processing Systems, pp. 5115-5124; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., (2016) Practical Black-Box Attacks against Deep Learning Systems Using Adversarial Examples, , arXiv preprint arXiv; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) 2016 IEEE Symposium on Security and Privacy (SP), pp. 582-597. , IEEE; Samangouei, P., Kabkab, M., Chellappa, R., Defense-GAN: Protecting classifiers against adversarial attacks using generative models (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=BkJ3ibb0-; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) International Conference on Learning Representation; Song, Y., Kim, T., Nowozin, S., Ermon, S., Kushman, N., PixelDefend: Leveraging generative models to understand and defend against adversarial examples (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=rJUYGxbCW; Steinhardt, J., Koh, P.W.W., Liang, P.S., Certified defenses for data poisoning attacks (2017) Advances in Neural Information Processing Systems, pp. 3520-3532; Strauss, T., Hanselmann, M., Junginger, A., Ulmer, H., (2017) Ensemble Methods as a Defense to Adversarial Perturbations against Deep Neural Networks, , arXiv; Szegedy, C., Going deeper with convolutions (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9; Szegedy, C., Intriguing properties of neural networks (2014) International Conference on Learning Representation; Tramér, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses, , arXiv preprint arXiv; Weng, T.W., Evaluating the robustness of neural networks: An extreme value theory approach (2018) 6-Th International Conference on Learning Representations (ICLR; Xiao, C., Li, B., Zhu, J.Y., He, W., Liu, M., Song, D., Generating Adversarial Examples with Adversarial Networks. In: Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI-2018, pp. 3905-3911. , https://doi.org/10.24963/ijcai.2018/543, International Joint Conferences on Artificial Intelligence Organization, July 2018; Xiao, C., Zhu, J.Y., Li, B., He, W., Liu, M., Song, D., (2018) Spatially Transformed Adversarial Examples, , arXiv preprint arXiv; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., Mitigating adversarial effects through randomization (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=Sk9yuql0Z; Xie, S., Girshick, R., Dollár, P., Tu, Z., He, K., Aggregated residual transformations for deep neural networks (2017) 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 5987-5995. , IEEE; Xu, K., Show, attend and tell: Neural image caption generation with visual attention (2015) International Conference on Machine Learning, pp. 2048-2057; Xu, W., Evans, D., Qi, Y., Feature squeezing: Detecting adversarial examples in deep neural networks (2018) Network and Distributed System Security Symposium; Zantedeschi, V., Nicolae, M.I., Rawat, A., Efficient defenses against adversarial attacks (2017) Proceedings of the 10Th ACM Workshop on Artificial Intelligence and Security, pp. 39-49. , ACM","Liu, X.; Electrical and Computer Science, United States; email: xqliu@ucdavis.edu","Ferrari V.Sminchisescu C.Hebert M.Weiss Y.",,"Springer Verlag","15th European Conference on Computer Vision, ECCV 2018","8 September 2018 through 14 September 2018",,219419,03029743,9783030012335,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85055128669
"Eyas A., Engstrom L., Athalye A., Lin J.","57204809114;57204801909;57204807086;57204798460;","Black-box adversarial attacks with limited queries and information",2018,"35th International Conference on Machine Learning, ICML 2018","5",,,"3392","3401",,98,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055122654&partnerID=40&md5=d545b57a0d5af74d7ecf91c57218924e","Massachusetts Institute of Technology, United States; LabSix, Australia","Eyas, A., Massachusetts Institute of Technology, United States, LabSix, Australia; Engstrom, L., Massachusetts Institute of Technology, United States, LabSix, Australia; Athalye, A., Massachusetts Institute of Technology, United States, LabSix, Australia; Lin, J., Massachusetts Institute of Technology, United States, LabSix, Australia","Current neural network-based classifiers are susceptible to adversarial examples even in the black-box setting, where the attacker only has query access to the model. In practice, the threat model for real-world systems is often more restrictive than the typical black-box model where the adversary can observe the full output of the network on arbitrarily many chosen inputs. We define three realistic threat models that more accurately characterize many real-world classifiers: the query-limited setting, the partialinformation setting, and the label-only setting. We develop new attacks that fool classifiers under these more restrictive threat models, where previous methods would be impractical or ineffective. We demonstrate that our methods are effective against an ImageNet classifier under our proposed threat models. We also demonstrate a targeted black-box attack against a commercial classifier, overcoming the challenges of limited query access, partial information, and other practical issues to break the Google Cloud Vision API. © 2018 by authors.All right reserved.",,"Artificial intelligence; Classification (of information); Learning systems; Black boxes; Black-box model; Partial information; Practical issues; Real-world; Real-world system; Threat modeling; Threat models; Search engines",,,,,"Athalye, A., Engstrom, L., Ilyas, A., Kwok, K., (2017) Synthesizing Robust Adversarial Examples, , https://arxiv.org/abs/1707.07397; Biggio, B., Nelson, B., Laskov, P., Poisoning attacks against support vector machines (2012) Proceedings of the 29th International Coference on International Conference on Machine Learning, ICML' 12, pp. 1467-1474. , http://dl.acm.org/citation.cfm?id=3042573.3042761; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Srndic, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 387-402. , Springer; Brendel, W., Rauber, J., Bethge, M., Decision-based adversarial attacks: Reliable attacks against black-box machine learning models (2018) Proceedings of the International Conference on Learning Representations (ICLR), , https://arxiv.org/abs/1712.04248; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security & Privacy; Carlini, N., Mishra, P., Vaidya, T., Zhang, Y., Sherr, M., Shields, C., Wagner, D., Zhou, W., Hidden voice commands (2016) 25th USENIX Security Symposium (USENIX Security 16), , Austin, TX; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, AlSec'17, pp. 15-26. , http://doi.acm.org/10.1145/3128572.3140448, New York, NY, USA, ACM; Dasgupta, S., Hsu, D., Verma, N., A concentration theorem for projections (2006) Conference on Uncertainty in Artificial Intelligence; Evtimov, I., Eykholt, K., Fernandes, E., Kohno, T., Li, B., Prakash, A., Rahmati, A., Song, D., (2017) Robust Physical-world Attacks on Machine Learning Models, , CoRR, abs/1707.08945; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) Proceedings of the International Conference on Learning Representations (ICLR); Gorban, A.N., Tyukin, I.Y., Prokhorov, D.V., Sofeikov, K.I., Approximation with random bases (2016) Inf. Sci., 364 (C), pp. 129-145. , http://dx.doi.org/10.1016/j.ins.2015.09.021, October; Hayes, J., Danezis, G., (2017) Machine Learning as an Adversarial Service: Learning Black-box Adversarial Examples, , CoRR, abs/1708.05207; Hosseini, H., Xiao, B., Jaiswal, M., Poovendran, R., On the limitation of convolutional neural networks in recognizing negative images (2017) 2017 16th IEEE International Conference on Machine Learning and Applications (ICMLA), pp. 352-358; Hu, W., Tan, Y., (2017) Black-box Attacks Against RNN Based Malware Detection Algorithms, , CoRR, abs/1705.08131; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , https://arxiv.org/abs/1607.02533; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) Proceedings of the International Conference on Learning Representations (ICLR); Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , https://arxiv.org/abs/1706.06083; Moosavi-Dezfooli, S., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) CVPR, pp. 86-94. , IEEE Computer Society; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Narodytska, N., Kasiviswanathan, S.P., Simple black-box adversarial perturbations for deep networks (2017) IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Nesterov, Y., Spokoiny, V., Random gradient-free minimization of convex functions (2017) Found. Comput. Math., 17 (2), pp. 527-566. , https://doi.org/10.1007/sl0208-015-9296-2, April; Nguyen, A.M., Yosinski, J., Clune, J., (2014) Deep Neural Networks Are Easily Fooled: High Confidence Predictions for Unrecognizable Images, , CoRR, abs/1412.1897; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) IEEE European Symposium on Security & Privacy; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, ASIA CCS'17, pp. 506-519. , http://doi.acm.org/10.1145/3052973.3053009, New York, NY, USA, ACM; Salimans, T., Ho, J., Chen, X., Sutskever, I., (2017) Evolution Strategies as a Scalable Alternative to Reinforcement Learning, , http://arxiv.org/abs/1703.03864, CoRR, abs/1703.03864; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., (2017) Adversarial Generative Nets: Neural Network Attacks on State-of-theart Face Recognition; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , https://arxiv.org/abs/1312.6199; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., (2015) Rethinking the Inception Architecture for Computer Vision, , https://arxiv.org/abs/1512.00567; Wierstra, D., Schaul, T., Glasmachers, T., Sun, Y., Peters, J., Schmidhuber, J., Natural evolution strategies (2014) J. Mach. Learn. Res., 15 (1), pp. 949-980. , http://dl.acm.org/citation.cfm?id=2627435.2638566, January; Xu, W., Yi, Y., Evans, D., Automatically evading classifiers: A case study on pdf malware classifiers (2016) Network and Distributed System Security Symposium (NDSS)",,"Dy J.Krause A.",,"International Machine Learning Society (IMLS)","35th International Conference on Machine Learning, ICML 2018","10 July 2018 through 15 July 2018",,141700,,9781510867963,,,"English","Int. Conf. Mach. Learn., ICML",Conference Paper,"Final","",Scopus,2-s2.0-85055122654
"Chen P.-Y., Sharma Y., Zhang H., Yi J., Hsieh C.-J.","36930105800;57198896649;57192486575;36095116600;24502954900;","EAD: Elastic-net attacks to deep neural networks via adversarial examples",2018,"32nd AAAI Conference on Artificial Intelligence, AAAI 2018",,,,"10","17",,149,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055121088&partnerID=40&md5=36b920fef5727015c021094263890ed0","AI Foundations Lab, IBM T. J. Watson Research Center, Yorktown Heights, NY  10598, United States; Cooper Union, New York, NY  10003, United States; University of California, Davis, Davis, CA  95616, United States; Tencent AI Lab, Bellevue, WA  98004, United States","Chen, P.-Y., AI Foundations Lab, IBM T. J. Watson Research Center, Yorktown Heights, NY  10598, United States; Sharma, Y., Cooper Union, New York, NY  10003, United States; Zhang, H., University of California, Davis, Davis, CA  95616, United States; Yi, J., Tencent AI Lab, Bellevue, WA  98004, United States; Hsieh, C.-J., University of California, Davis, Davis, CA  95616, United States","Recent studies have highlighted the vulnerability of deep neural networks (DNNs) to adversarial examples - a visually indistinguishable adversarial image can easily be crafted to cause a well-trained model to misclassify. Existing methods for crafting adversarial examples are based on L2 and L∞ distortion metrics. However, despite the fact that L1 distortion accounts for the total variation and encourages sparsity in the perturbation, little has been developed for crafting L1-based adversarial examples. In this paper, we formulate the process of attacking DNNs via adversarial examples as an elastic-net regularized optimization problem. Our elastic-net attacks to DNNs (EAD) feature L1-oriented adversarial examples and include the state-of-the-art L2 attack as a special case. Experimental results on MNIST, CIFAR10 and ImageNet show that EAD can yield a distinct set of adversarial examples with small L1 distortion and attains similar attack performance to the state-of-the-art methods in different attack scenarios. More importantly, EAD leads to improved attack transferability and complements adversarial training for DNNs, suggesting novel insights on leveraging L1 distortion in adversarial machine learning and security implications of DNNs. Copyright © 2018, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,"Artificial intelligence; Different attacks; Distortion metrics; Elastic net; Regularized optimization problems; Security implications; State of the art; State-of-the-art methods; Total variation; Deep neural networks",,,,,"Beck, A., Teboulle, M., A fast iterative shrinkage-thresholding algorithm for linear inverse problems (2009) SIAM Journal on Imaging Sciences, 2 (1), pp. 183-202; Candès, E.J., Wakin, M.B., An introduction to compressive sampling (2008) IEEE Signal Processing Magazine, 25 (2), pp. 21-30; Carlini, N., Wagner, D., (2017) Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy (SP), pp. 39-57; Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.-J., Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) ACM Workshop on Artificial Intelligence and Security, pp. 15-26; Dong, Y., Su, H., Zhu, J., Bao, F., (2017) Towards Interpretable Deep Neural Networks by Leveraging Adversarial Examples; Duchi, J., Singer, Y., Efficient online and batch learning using forward backward splitting (2009) Journal of Machine Learning Research, 10, pp. 2899-2934. , Dec; Evtimov, I., Eykholt, K., Fernandes, E., Kohno, T., Li, B., Prakash, A., Rahmati, A., Song, D., (2017) Robust Physical-World Attacks on Machine Learning Models; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts; Fu, H., Ng, M.K., Nikolova, M., Barlow, J.L., Efficient minimization methods of mixed l2-l1 and l1-l1 norms for image restoration (2006) SIAM Journal on Scientific Computing, 27 (6), pp. 1881-1902; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR'15; Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., (2017) On the (Statistical) Detection of Adversarial Examples; Hinton, G., Vinyals, O., Dean, J., (2015) Distilling the Knowledge in a Neural Network; Kingma, D., Ba, J., (2014) Adam: A Method for Stochastic Optimization; Koh, P.W., Liang, P., Understanding black-box predictions via influence functions (2017) ICML; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial machine learning at scale (2016) ICLR'17; Liu, Y., Chen, X., Liu, C., Song, D., (2016) Delving into Transferable Adversarial Examples and Black-Box Attacks; Lu, J., Issaranon, T., Forsyth, D., (2017) Safetynet: Detecting and Rejecting Adversarial Examples Robustly; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., (2016) Universal Adversarial Perturbations; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) IEEE European Symposium on Security and Privacy (EuroS&P), pp. 372-387; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) IEEE Symposium on Security and Privacy (SP), pp. 582-597; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) ACM Asia Conference on Computer and Communications Security, pp. 506-519; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses; Xu, W., Evans, D., Qi, Y., (2017) Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks; Zantedeschi, V., Nicolae, M.-I., Rawat, A., (2017) Efficient Defenses Against Adversarial Attacks; Zheng, S., Song, Y., Leung, T., Goodfellow, I., Improving the robustness of deep neural networks via stability training (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4480-4488; Zou, H., Hastie, T., Regularization and variable selection via the elastic net (2005) Journal of the Royal Statistical Society: Series B (Statistical Methodology), 67 (2), pp. 301-320",,,"Association for the Advancement of Artificial Intelligence","AAAI press","32nd AAAI Conference on Artificial Intelligence, AAAI 2018","2 February 2018 through 7 February 2018",,143510,,9781577358008,,,"English","AAAI Conf. Artif. Intell., AAAI",Conference Paper,"Final","",Scopus,2-s2.0-85055121088
"Xiao C., Deng R., Li B., Yu F., Liu M., Song D.","56379538100;57204286868;57188689924;57141404100;9733562100;7402443870;","Characterizing adversarial examples based on spatial consistency information for semantic segmentation",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11214 LNCS",,,"220","237",,5,"10.1007/978-3-030-01249-6_14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055114623&doi=10.1007%2f978-3-030-01249-6_14&partnerID=40&md5=4736459ce6c1dd9978a0f79e2bc1fede","University of Michigan, Ann Arbor, United States; Simon Fraser University, Burnaby, Canada; UIUC, Champaign, United States; UC Berkeley, Berkeley, United States","Xiao, C., University of Michigan, Ann Arbor, United States; Deng, R., Simon Fraser University, Burnaby, Canada; Li, B., UIUC, Champaign, United States, UC Berkeley, Berkeley, United States; Yu, F., UC Berkeley, Berkeley, United States; Liu, M., University of Michigan, Ann Arbor, United States; Song, D., UC Berkeley, Berkeley, United States","Deep Neural Networks (DNNs) have been widely applied in various recognition tasks. However, recently DNNs have been shown to be vulnerable against adversarial examples, which can mislead DNNs to make arbitrary incorrect predictions. While adversarial examples are well studied in classification tasks, other learning problems may have different properties. For instance, semantic segmentation requires additional components such as dilated convolutions and multiscale processing. In this paper, we aim to characterize adversarial examples based on spatial context information in semantic segmentation. We observe that spatial consistency information can be potentially leveraged to detect adversarial examples robustly even when a strong adaptive attacker has access to the model and detection strategies. We also show that adversarial examples based on attacks considered within the paper barely transfer among models, even though transferability is common in classification. Our observations shed new light on developing adversarial attacks and defenses to better understand the vulnerabilities of DNNs. © Springer Nature Switzerland AG 2018.","Adversarial example; Semantic segmentation; Spatial consistency","Computer vision; Semantics; Adversarial example; Classification tasks; Learning problem; Multiscale processing; Semantic segmentation; Spatial consistency; Spatial context; Deep neural networks",,,,,"Badrinarayanan, V., Kendall, A., Cipolla, R., SegNet: A deep convolutional encoder-decoder architecture for image segmentation (2017) IEEE Trans. Pattern Anal. Mach. Intell., 39 (12), pp. 2481-2495; Bhagoji, A.N., He, W., Li, B., Song, D., (2017) Exploring the Space of Black-Box Attacks on Deep Neural Networks; Brostow, G.J., Shotton, J., Fauqueur, J., Cipolla, R., Segmentation and recognition using structure from motion point clouds (2008) ECCV 2008. LNCS, 5302, pp. 44-57. , https://doi.org/10.1007/978-3-540-88682-2_5, Forsyth, D., Torr, P., Zisserman, A. (eds.), Springer, Heidelberg; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) Proceedings of the 10Th ACM Workshop on Artificial Intelligence and Security, pp. 3-14. , ACM; Carlini, N., Wagner, D.A., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy, pp. 39-57. , https://doi.org/10.1109/SP.2017.49, SP 2017, San Jose, CA, USA, 22-26 May 2017; Chan, T.F., Wong, C.K., Total variation blind deconvolution (1998) IEEE Trans. Image Process., 7 (3), pp. 370-375; Chen, H., Zhang, H., Chen, P.Y., Yi, J., Hsieh, C.J., Attacking visual language grounding with adversarial examples: A case study on neural image captioning (2018) Proceedings of the 56Th Annual Meeting of the Association for Computational Linguistics, Long Papers, 1, pp. 2587-2597; Chen, P.Y., Sharma, Y., Zhang, H., Yi, J., Hsieh, C.J., (2017) EAD: Elastic-Net Attacks to Deep Neural Networks via Adversarial Examples; Chen, P.Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.J., ZOO: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) Proceedings of the 10Th ACM Workshop on Artificial Intelligence and Security, pp. 15-26. , ACM; Cisse, M., Adi, Y., Neverova, N., Keshet, J., (2017) Houdini: Fooling Deep Structured Prediction Models; Cordts, M., The cityscapes dataset for semantic urban scene understanding (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3213-3223; Cui, W., Wang, Y., Fan, Y., Feng, Y., Lei, T., Localized FCM clustering with spatial information for medical image segmentation and bias field estimation (2013) J. Biomed. Imaging, 2013, p. 13; Das, N., (2017) Keeping the Bad Guys Out: Protecting and Vaccinating Deep Learning with JPEG Compression; Dziugaite, G.K., Ghahramani, Z., Roy, D.M., (2016) A Study of the Effect of JPG Compression on Adversarial Images; Everingham, M., Eslami, S.M.A., van Gool, L., Williams, C.K.I., Winn, J., Zisserman, A., The pascal visual object classes challenge: A retrospective (2015) Int. J. Comput. Vis., 111 (1), pp. 98-136; Evtimov, I., (2017) Robust Physical-World Attacks on Machine Learning Models; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; He, W., Wei, J., Chen, X., Carlini, N., Song, D., Adversarial example defense: Ensembles of weak defenses are not strong (2017) 11Th USENIX Workshop on Offensive Technologies (WOOT 2017), , https://www.usenix.org/conference/woot17/workshop-program/presentation/he, USENIX Association, Vancouver; Hinton, G., Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups (2012) IEEE Signal Process. Mag., 29 (6), pp. 82-97; Hosseini, H., Chen, Y., Kannan, S., Zhang, B., Poovendran, R., (2017) Blocking Transferability of Adversarial Examples in Black-Box Learning Systems; Johnson, B., Xie, Z., Unsupervised image segmentation evaluation and refinement using a multi-scale approach (2011) ISPRS J. Photogramm. Remote. Sens., 66 (4), pp. 473-483; Krähenbühl, P., Koltun, V., Efficient inference in fully connected CRFs with Gaussian edge potentials (2011) Advances in Neural Information Processing Systems, pp. 109-117; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Leung, T., Malik, J., Representing and recognizing the visual appearance of materials using three-dimensional textons (2001) Int. J. Comput. Vis., 43 (1), pp. 29-44; Lin, G., Shen, C., van Den Hengel, A., Reid, I., Efficient piecewise training of deep structured models for semantic segmentation (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3194-3203; Liu, Y., Chen, X., Liu, C., Song, D., (2016) Delving into Transferable Adversarial Examples and Black-Box Attacks; Long, J., Shelhamer, E., Darrell, T., Fully convolutional networks for semantic segmentation (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3431-3440; Ma, X., (2018) Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 427-436. , IEEE; Noda, K., Arie, H., Suga, Y., Ogata, T., Multimodal integration learning of robot behavior using deep neural networks (2014) Robot. Auton. Syst., 62 (6), pp. 721-736; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-Box Attacks Using Adversarial Samples; Ronneberger, O., Fischer, P., Brox, T., U-Net: Convolutional networks for biomedical image segmentation (2015) MICCAI 2015. LNCS, 9351, pp. 234-241. , https://doi.org/10.1007/978-3-319-24574-4_28, Navab, N., Hornegger, J., Wells, W.M., Frangi, A.F. (eds.), Springer, Cham; Saha, P.K., Udupa, J.K., Odhner, D., Scale-based fuzzy connected image segmentation: Theory, algorithms, and validation (2000) Comput. Vis. Image Underst., 77 (2), pp. 145-174; Shannon, C.E., Communication theory of secrecy systems (1949) Bell Labs Tech. J., 28 (4), pp. 656-715; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540. , ACM; Szegedy, C., (2013) Intriguing Properties of Neural Networks; Tabacof, P., Valle, E., Exploring the space of adversarial images (2016) 2016 International Joint Conference on Neural Networks (IJCNN), pp. 426-433. , IEEE; Tong, L., Li, B., Hajaj, C., Xiao, C., Vorobeychik, Y., Hardening classifiers against evasion: The good, the bad, and the ugly (2017) Corr; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses; Weng, T.W., (2018) Towards Fast Computation of Certified Robustness for Relu Networks; Weng, T.W., Evaluating the robustness of neural networks: An extreme value theory approach (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=BkUHlMZ0b; Wu, Z., Shen, C., van den Hengel, A., (2016) Wider Or Deeper: Revisiting the Resnet Model for Visual Recognition; Xiao, C., Li, B., Zhu, J.Y., He, W., Liu, M., Song, D., Generating adversarial examples with adversarial networks (2018) Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI 2018, pp. 3905-3911. , https://doi.org/10.24963/ijcai.2018/543, International Joint Conferences on Artificial Intelligence Organization, July; Xiao, C., Sarabi, A., Liu, Y., Li, B., Liu, M., Dumitras, T., From patching delays to infection symptoms: Using risk profiles for an early discovery of vulnerabilities exploited in the wild (2018) 27Th USENIX Security Symposium (USENIX Security 2018). USENIX Association, , https://www.usenix.org/conference/usenixsecurity18/presentation/xiao, Baltimore; Xiao, C., Zhu, J.Y., Li, B., He, W., Liu, M., Song, D., Spatially transformed adversarial examples (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=HyydRMZC-; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., Mitigating adversarial effects through randomization (2018) International Conference on Learning Representations; Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., Adversarial examples for semantic segmentation and object detection (2017) International Conference on Computer Vision. IEEE; Yu, F., Koltun, V., Multi-scale context aggregation by dilated convolutions (2016) International Conference on Learning Representations (ICLR; Yu, F., Koltun, V., Funkhouser, T., Dilated residual networks (2017) Computer Vision and Pattern Recognition (CVPR); Yu, F., Wang, D., Darrell, T., (2017) Deep Layer Aggregation; Yu, F., (2018) BDD100K: A Diverse Driving Video Database with Scalable Annotation Tooling; Zeng, D., Liu, K., Lai, S., Zhou, G., Zhao, J., Relation classification via convolutional deep neural network (2014) Proceedings of COLING 2014, the 25Th International Conference on Computational Linguistics: Technical Papers, pp. 2335-2344; Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J., Pyramid scene parsing network (2017) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2881-2890","Xiao, C.; University of MichiganUnited States; email: xiaocw@umich.edu","Hebert M.Ferrari V.Sminchisescu C.Weiss Y.",,"Springer Verlag","15th European Conference on Computer Vision, ECCV 2018","8 September 2018 through 14 September 2018",,219419,03029743,9783030012489,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85055114623
"Baluja S., Fischer I.","7004033798;54899111300;","Learning to attack: Adversarial transformation networks",2018,"32nd AAAI Conference on Artificial Intelligence, AAAI 2018",,,,"2687","2695",,54,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055113457&partnerID=40&md5=ea03d561deed56219a12d397c5a0e7f9","Google Research, Google, Inc, United States","Baluja, S., Google Research, Google, Inc, United States; Fischer, I., Google Research, Google, Inc, United States","With the rapidly increasing popularity of deep neural networks for image recognition tasks, a parallel interest in generating adversarial examples to attack the trained models has arisen. To date, these approaches have involved either directly computing gradients with respect to the image pixels or directly solving an optimization on the image pixels. We generalize this pursuit in a novel direction: can a separate network be trained to efficiently attack another fully trained network? We demonstrate that it is possible, and that the generated attacks yield startling insights into the weaknesses of the target network. We call such a network an Adversarial Transformation Network (ATN). ATNs transform any input into an adversarial attack on the target network, while being minimally perturbing to the original inputs and the target network's outputs. Further, we show that ATNs are capable of not only causing the target network to make an error, but can be constructed to explicitly control the type of misclassification made. We demonstrate ATNs on both simple MNIST-digit classifiers and state-of-the-art ImageNet classifiers deployed by Google, Inc.: Inception ResNet-v2. Copyright © 2018, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,"Artificial intelligence; Image recognition; Pixels; Digit classifier; Image pixels; Misclassifications; State of the art; Deep neural networks",,,,,"Alemi, A., (2016) Improving Inception and Image Classification in Tensorflow, , https://research.googleblog.com/2016/08/improvinginception-and-image.html; Baluja, S., Covell, M., Sukthankar, R., The virtues of peer pressure: A simple method for discovering high-value mistakes (2015) Int. Conf. on Computer Analysis of Images and Patterns, pp. 96-108. , Springer; Carlini, N., Wagner, D., (2016) Towards Evaluating the Robustness of Neural Networks, , arXiv preprint; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., Imagenet: A large-scale hierarchical image database (2009) Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pp. 248-255. , IEEE; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint; He, K., Zhang, X., Ren, S., Sun, J., (2015) Deep Residual Learning for Image Recognition, , CoRR abs/1512.03385; Hendrik Metzen, J., Genewein, T., Fischer, V., Bischoff, B., (2017) On Detecting Adversarial Perturbations, , ArXiv e-prints; Johnson, J., Alahi, A., Fei-Fei, L., Perceptual losses for real-time style transfer and super-resolution (2016) European Conference on Computer Vision; Kingma, D., Ba, J., Adam: A method for stochastic optimization (2015) Iclr; Kurakin, A., Goodfellow, I.J., Bengio, S., (2016) Adversarial Examples in the Physical World, , CoRR abs/1607.02533; LeCun, Y., Cortes, C., Burges, C.J., (1998) The Mnist Database of Handwritten Digits; Liu, Y., Chen, X., Liu, C., Song, D., (2016) Delving into Transferable Adversarial Examples and Black-Box Attacks, , CoRR abs/1611.02770; Moosavi-Dezfooli, S., Fawzi, A., Fawzi, O., Frossard, P., (2016) Universal Adversarial Perturbations, , CoRR abs/1610.08401; Moosavi-Dezfooli, S., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE CVPR, pp. 2574-2582; Mordvintsev, A., Olah, C., Tyka, M., (2015) Inceptionism: Going Deeper into Neural Networks, , http://googleresearch.blogspot.com/2015/06/inceptionismgoing-deeper-into-neural.html; Nguyen, A.M., Yosinski, J., Clune, J., (2014) Deep Neural Networks Are Easily Fooled: High Confidence Predictions for Unrecognizable Images, , CoRR abs/1412.1897; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2015) Proceedings of the 1st IEEE European Symposium on Security and Privacy; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., (2016) Practical Black-Box Attacks Against Deep Learning Systems Using Adversarial Examples, , arXiv preprint; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A., (2016) Inception-V4, Inception-Resnet and the Impact of Residual Connections on Learning, , arXiv preprint; Tramèr, F., Zhang, F., Juels, A., Reiter, M.K., Risten-Part, T., Stealing machine learning models via prediction apis (2016) USENIX Security; Williams, R.J., Simple statistical gradient-following algorithms for connectionist reinforcement learning (1992) Machine Learning, 8 (3-4), pp. 229-256",,,"Association for the Advancement of Artificial Intelligence","AAAI press","32nd AAAI Conference on Artificial Intelligence, AAAI 2018","2 February 2018 through 7 February 2018",,143510,,9781577358008,,,"English","AAAI Conf. Artif. Intell., AAAI",Conference Paper,"Final","",Scopus,2-s2.0-85055113457
"Bhagoji A.N., He W., Li B., Song D.","57189365305;57207135651;57188689924;7402443870;","Practical black-box attacks on deep neural networks using efficient query mechanisms",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11216 LNCS",,,"158","174",,44,"10.1007/978-3-030-01258-8_10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055098585&doi=10.1007%2f978-3-030-01258-8_10&partnerID=40&md5=3a733ff1374cb61554364c2914b00a67","Princeton University, Princeton, United States; University of California, Berkeley, Berkeley, United States; University of Illinois at Urbana-Champaign, Champaign, United States","Bhagoji, A.N., Princeton University, Princeton, United States; He, W., University of California, Berkeley, Berkeley, United States; Li, B., University of Illinois at Urbana-Champaign, Champaign, United States; Song, D., University of California, Berkeley, Berkeley, United States","Existing black-box attacks on deep neural networks (DNNs) have largely focused on transferability, where an adversarial instance generated for a locally trained model can “transfer” to attack other learning models. In this paper, we propose novel Gradient Estimation black-box attacks for adversaries with query access to the target model’s class probabilities, which do not rely on transferability. We also propose strategies to decouple the number of queries required to generate each adversarial sample from the dimensionality of the input. An iterative variant of our attack achieves close to 100% attack success rates for both targeted and untargeted attacks on DNNs. We carry out a thorough comparative evaluation of black-box attacks and show that Gradient Estimation attacks achieve attack success rates similar to state-of-the-art white-box attacks on the MNIST and CIFAR-10 datasets. We also apply the Gradient Estimation attacks successfully against real-world classifiers hosted by Clarifai. Further, we evaluate black-box attacks against state-of-the-art defenses based on adversarial training and show that the Gradient Estimation attacks are very effective even against these defenses. © Springer Nature Switzerland AG 2018.","Adversarial examples; Black-box attacks; Deep neural networks; Image classification","Computer vision; Image classification; Adversarial examples; Black boxes; Class probabilities; Comparative evaluations; Gradient estimation; Learning models; Query mechanisms; State of the art; Deep neural networks",,,,,"Athalye, A., Carlini, N., Wagner, D., Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples (2018) Proceedings of the 35Th International Conference on Machine Learning; Brendel, W., Rauber, J., Bethge, M., Decision-based adversarial attacks: Reliable attacks against black-box machine learning models (2018) International Conference on Learning Representations; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy; Chen, P.Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.J., Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) 11Th ACM Workshop on Artificial Intelligence and Security; (2017) Clarifai — Image & Video Recognition API, , https://clarifai.com.Accessed22, Aug; Dang, H., Yue, H., Chang, E.C., Evading classifiers by morphing in the dark (2017) 24Th ACM Conference on Computer and Communications Security; Goodfellow, I., Bengio, Y., Courville, A., (2016) Deep Learning, , MIT Press, Cambridge; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations; (2017) Vision Api-Image Content analysis—Google Cloud Platform, , https://cloud.google.com/vision/.Accessed22, Aug; Gu, S., Rigazio, L., (2014) Towards Deep Neural Network Architectures Robust to Adversarial Examples, , arXiv preprint arXiv; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Hildebrand, F.B., (1962) Advanced Calculus for Applications, 63. , Prentice-Hall Engle-wood Cliffs, NJ; Ilyas, A., Engstrom, L., Athalye, A., Lin, J., Black-box adversarial attacks with limited queries and information (2018) Proceedings of the 35Th International Conference on Machine Learning; Kennedy, J., Particle swarm optimization (2011) Encyclopedia of Machine Learning, pp. 760-766. , https://doi.org/10.1007/978-0-387-30164-8, Sammut, C., Webb, G.I. (eds.), Springer, Heidelberg; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint arXiv; Lecun, Y., Cortes, C., (1998) The MNIST Database of Handwritten Digits; Liu, A., (2016) Clarifai Featured Hack: Block Unwanted Nudity in Blog Comments with Disqus, , https://goo.gl/TCCVrR, Accessed 22 Aug 2017; Moosavi-Dezfooli, S.M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2016) IEEE Conference on Computer Vision and Pattern Recognition; Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) IEEE Conference on Computer Vision and Pattern Recognition; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) International Conference on Learning Representations; Narodytska, N., Kasiviswanathan, S.P., (2016) Simple Black-Box Adversarial Perturbations for Deep Networks; Nelson, B., Query strategies for evading convex-inducing classifiers (2012) J. Mach. Learn. Res., 13 (1), pp. 1293-1332; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-Box Attacks Using Adversarial Samples, , arXiv preprint arXiv; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against deep learning systems using adversarial examples (2017) ACM Asia Conference on Computer and Communications Security; Salimans, T., Ho, J., Chen, X., Sutskever, I., (2017) Evolution Strategies as a Scalable Alternative to Reinforcement Learning, , arXiv preprint arXiv; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) ACM Conference on Computer and Communications Security; Shlens, J., (2014) A Tutorial on Principal Component Analysis.; Spall, J.C., Multivariate stochastic approximation using a simultaneous perturbation gradient approximation (1992) IEEE Trans. Autom. Control, 37 (3), pp. 332-341; Spall, J.C., (2005) Introduction to Stochastic Search and Optimization: Estimation, Simulation, and Control, 65. , Wiley, Hoboken; Szegedy, C., Intriguing properties of neural networks (2014) International Conference on Learning Representations; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2018) International Conference on Learning Representations; https://www.ibm.com/watson/services/visual-recognition/, Accessed 27 Aug 2017; Wright, S.J., Nocedal, J., Numerical optimization (1999) Springer Sci., 35 (67-68), p. 7; Xu, W., Qi, Y., Evans, D., Automatically evading classifiers (2016) Proceedings of the 2016 Network and Distributed Systems Symposium; Zagoruyko, S., Komodakis, N., (2016) Wide Residual Networks","Bhagoji, A.N.; Princeton UniversityUnited States; email: abhagoji@princeton.edu","Hebert M.Ferrari V.Sminchisescu C.Weiss Y.",,"Springer Verlag","15th European Conference on Computer Vision, ECCV 2018","8 September 2018 through 14 September 2018",,219419,03029743,9783030012571,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","",Scopus,2-s2.0-85055098585
"Su D., Zhang H., Chen H., Yi J., Chen P.-Y., Gao Y.","35727155500;57192486575;57201132566;36095116600;36930105800;57204286267;","Is robustness the cost of accuracy? – A comprehensive study on the robustness of 18 deep image classification models",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11216 LNCS",,,"644","661",,22,"10.1007/978-3-030-01258-8_39","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055098385&doi=10.1007%2f978-3-030-01258-8_39&partnerID=40&md5=5a8bef60c9b9947f318c919f7dbed7d9","IBM Research, New York, United States; University of California, Davis, Davis, United States; Massachusetts Institute of Technology, Cambridge, United States; JD AI Research, Beijing, China","Su, D., IBM Research, New York, United States; Zhang, H., University of California, Davis, Davis, United States; Chen, H., Massachusetts Institute of Technology, Cambridge, United States; Yi, J., JD AI Research, Beijing, China; Chen, P.-Y., IBM Research, New York, United States; Gao, Y., IBM Research, New York, United States","The prediction accuracy has been the long-lasting and sole standard for comparing the performance of different image classification models, including the ImageNet competition. However, recent studies have highlighted the lack of robustness in well-trained deep neural networks to adversarial examples. Visually imperceptible perturbations to natural images can easily be crafted and mislead the image classifiers towards misclassification. To demystify the trade-offs between robustness and accuracy, in this paper we thoroughly benchmark 18 ImageNet models using multiple robustness metrics, including the distortion, success rate and transferability of adversarial examples between 306 pairs of models. Our extensive experimental results reveal several new insights: (1) linear scaling law - the empirical ℓ2 and ℓ∞ distortion metrics scale linearly with the logarithm of classification error; (2) model architecture is a more critical factor to robustness than model size, and the disclosed accuracy-robustness Pareto frontier can be used as an evaluation criterion for ImageNet model designers; (3) for a similar network architecture, increasing network depth slightly improves robustness in ℓ∞ distortion; (4) there exist models (in VGG family) that exhibit high adversarial transferability, while most adversarial examples crafted from one model can only be transferred within the same family. Experiment code is publicly available at https://github.com/huanzhang12/Adversarial_Survey. © Springer Nature Switzerland AG 2018.","Adversarial attacks; Deep neural networks; Robustness","Computer vision; Deep neural networks; Economic and social effects; Image enhancement; Network architecture; Robustness (control systems); Adversarial attacks; Classification errors; Classification models; Distortion metrics; Evaluation criteria; Misclassifications; Model architecture; Prediction accuracy; Image classification",,,,,"Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems (NIPS), pp. 1097-1105; Russakovsky, O., Imagenet large scale visual recognition challenge (2015) Int. J. Comput. Vis., 115 (3), pp. 211-252; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations (ICLR; Xu, X., Chen, X., Liu, C., Rohrbach, A., Darell, T., Song, D., Fooling vision and language models despite localization and attention mechanism (2018) Proceedings of the Thirtieth IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR); Chen, H., Zhang, H., Chen, P.Y., Yi, J., Hsieh, C.J., Attacking visual language grounding with adversarial examples: A case study on neural image captioning (2018) Proceedings of the 56Th Annual Meeting of the Association for Computational Linguistics, 1, pp. 2587-2597. , Long Papers; Metzen, J.H., Kumar, M.C., Brox, T., Fischer, V., Universal adversarial perturbations against semantic image segmentation (2017) Statistics, 1050, p. 19; Cheng, M., Yi, J., Zhang, H., Chen, P.Y., Hsieh, C.J., (2018) Seq2sick: Evaluating the Robustness of Sequence-To-Sequence Models with Adversarial Examples, , arXiv preprint arXiv; Carlini, N., Wagner, D., Audio adversarial examples: Targeted attacks on speech-to-text (2018) Deep Learning and Security Workshop; Sun, M., Tang, F., Yi, J., Wang, F., Zhou, J., Identify susceptible locations in medical records via adversarial attacks on deep predictive models (2018) Proceedings of the 24Th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD), pp. 793-801; Xiao, C., Li, B., Zhu, J.Y., He, W., Liu, M., Song, D., Generating adversarial examples with adversarial networks (2018) Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI 2018, International Joint Conferences on Artificial Intelligence Organization, pp. 3905-3911. , July; Xiao, C., Zhu, J.Y., Li, B., He, W., Liu, M., Song, D., Spatially transformed adversarial examples (2018) International Conference on Learning Representations (ICLR; Eykholt, K., Robust physical-world attacks on deep learning visual classification (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1625-1634; Szegedy, C., Intriguing properties of neural networks (2014) International Conference on Learning Representations (ICLR; Hein, M., Andriushchenko, M., Formal guarantees on the robustness of a classifier against adversarial manipulation (2017) Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems (NIPS), pp. 2263-2273; Weng, T.W., Evaluating the robustness of neural networks: An extreme value theory approach (2018) International Conference on Learning Representations (ICLR; Weng, T.W., Towards fast computation of certified robustness for ReLU networks (2018) Proceedings of the 35Th International Conference on Machine Learning (ICML); Stock, P., Cisse, M., (2017) Convnets and Imagenet beyond Accuracy: Explanations, Bias Detection, Adversarial Examples and Model Criticism, , arXiv preprint arXiv; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) International Conference on Learning Representations (ICLR; Szegedy, C., Going deeper with convolutions (2015) IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9. , CVPR 2015, Boston, MA, USA, 7–12 June 2015; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) 2016 IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778. , CVPR 2016, Las Vegas, NV, USA, 27–30 June 2016; Huang, G., Liu, Z., van der Maaten, L., Weinberger, K.Q., Densely connected convolutional networks (2017) 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR; Howard, A.G., MobileNets: Efficient convolutional neural networks for mobile vision applications (2017) Corr Abs/1704.04861; Zoph, B., Vasudevan, V., Shlens, J., Le, Q.V., Learning transferable architectures for scalable image recognition (2018) 2018 IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Lin, M., Chen, Q., Yan, S., Network in network. In: International Conference on Learning Representations (2014) ICLR (ICLR); Ioffe, S., Szegedy, C., Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015) Proceedings of the 32Nd International Conference on Machine Learning, pp. 448-456. , ICML 2015, Lille, France, 6–11 July 2015; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) 2016 IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826. , CVPR 2016, Las Vegas, NV, USA, 27–30 June 2016; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., Inception-v4, inception-resnet and the impact of residual connections on learning (2017) Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence, pp. 4278-4284. , San Francisco, California, USA, 4–9 February 2017; Zoph, B., Le, Q.V., Neural architecture search with reinforcement learning (2017) International Conference on Learning Representations (ICLR; Wu, N., Sivakumar, S., Guadarrama, S., Andersen, D., TensorFlow-Slim Image Classification Model Library (2017) Github, , https://github.com/tensorflow/models/tree/master/research/slim; He, K., Zhang, X., Ren, S., Sun, J., Identity mappings in deep residual networks (2016) ECCV 2016. LNCS, 9908, pp. 630-645. , https://doi.org/10.1007/978-3-319-46493-038, Leibe, B., Matas, J., Sebe, N., Welling, M. (eds.), Springer, Cham; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) International Conference on Learning Representations (ICLR; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-Box Attacks Using Adversarial Samples, , arXiv preprint arXiv; Chen, P.Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.J., ZOO: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) Proceedings of the 10Th ACM Workshop on Artificial Intelligence and Security, pp. 15-26. , ACM; Tu, C., AutoZOOM: Autoencoder-based zeroth order optimization method for attacking black-box neural networks (2018) Corr Abs/1805.11770; Cheng, M., Le, T., Chen, P.Y., Yi, J., Zhang, H., Hsieh, C.J., (2018) Query-Efficient Hard-Label Black-Box Attack: An Optimization-Based Approach, , arXiv preprint arXiv; Tu, C.C., (2018) Autozoom: Autoencoder-Based Zeroth Order Optimization Method for Attacking Black-Box Neural Networks, , arXiv preprint arXiv; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial machine learning at scale (2017) International Conference on Learning Representations (ICLR; Cisse, M., Bojanowski, P., Grave, E., Dauphin, Y., Usunier, N., Parseval networks: Improving robustness to adversarial examples (2017) International Conference on Machine Learning (ICML), pp. 854-863; Carlini, N., Wagner, D.A., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy, pp. 39-57. , (Oakland) 2017, San Jose, CA, USA, 22–26 May 2017; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) Proceedings of the 10Th ACM Workshop on Artificial Intelligence and Security, Aisec 2017, pp. 3-14. , ACM, New York; Chen, P.Y., Sharma, Y., Zhang, H., Yi, J., Hsieh, C.J., EAD: Elastic-net attacks to deep neural networks via adversarial examples (2018) AAAI; Sharma, Y., Chen, P.Y., (2017) Attacking the Madry Defense Model with L1-Based Adversarial Examples, , arXiv preprint arXiv; Lu, P.H., Chen, P.Y., Chen, K.C., Yu, C.M., On the limitation of magnet defense against L1-based adversarial examples (2018) IEEE/IFIP DSN Workshop; Lu, P.H., Chen, P.Y., Yu, C.M., On the limitation of local intrinsic dimensionality for characterizing the subspaces of adversarial examples (2018) ICLR Workshop; Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L., ImageNet: A large-scale hierarchical image database (2009) IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2009, pp. 248-255. , IEEE; Krizhevsky, A., (2009) Learning Multiple Layers of Features from Tiny Images; Stallkamp, J., Schlipsing, M., Salmen, J., Igel, C., Man vs. Computer: Benchmarking machine learning algorithms for traffic sign recognition (2012) Neural Netw, 32, pp. 323-332; Moosavi-Dezfooli, S., Fawzi, A., Frossard, P., DeepFool: A simple and accurate method to fool deep neural networks (2016) 2016 IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582. , CVPR 2016, Las Vegas, NV, USA, 27–30 June 2016; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) International Conference on Learning Representations (ICLR; Athalye, A., Engstrom, L., Ilyas, A., Kwok, K., Synthesizing robust adversarial examples (2018) 35Th International Conference on Machine Learning (ICML); Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A., Adversarial examples for semantic segmentation and object detection (2017) International Conference on Computer Vision (ICCV). IEEE","Su, D.; IBM ResearchUnited States; email: sudong.tom@gmail.com","Hebert M.Ferrari V.Sminchisescu C.Weiss Y.",,"Springer Verlag","15th European Conference on Computer Vision, ECCV 2018","8 September 2018 through 14 September 2018",,219419,03029743,9783030012571,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85055098385
"Xiao C., Li B., Zhu J.-Y., He W., Liu M., Song D.","56379538100;57188689924;56316642900;57207135651;9733562100;7402443870;","Generating adversarial examples with adversarial networks",2018,"IJCAI International Joint Conference on Artificial Intelligence","2018-July",,,"3905","3911",,100,"10.24963/ijcai.2018/543","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055082314&doi=10.24963%2fijcai.2018%2f543&partnerID=40&md5=24fe208bd6d82013877e0bcdeda30f23","University of Michigan, Ann Arbor, United States; University of California, Berkeley, United States; Massachusetts Institute of Technology, China","Xiao, C., University of Michigan, Ann Arbor, United States; Li, B., University of California, Berkeley, United States; Zhu, J.-Y., University of California, Berkeley, United States, Massachusetts Institute of Technology, China; He, W., University of California, Berkeley, United States; Liu, M., University of Michigan, Ann Arbor, United States; Song, D., University of California, Berkeley, United States","Deep neural networks (DNNs) have been found to be vulnerable to adversarial examples resulting from adding small-magnitude perturbations to inputs. Such adversarial examples can mislead DNNs to produce adversary-selected results. Different attack strategies have been proposed to generate adversarial examples, but how to produce them with high perceptual quality and more efficiently requires more research efforts. In this paper, we propose AdvGAN to generate adversarial examples with generative adversarial networks (GANs), which can learn and approximate the distribution of original instances. For AdvGAN, once the generator is trained, it can generate perturbations efficiently for any instance, so as to potentially accelerate adversarial training as defenses. We apply Adv-GAN in both semi-whitebox and black-box attack settings. In semi-whitebox attacks, there is no need to access the original target model after the generator is trained, in contrast to traditional white-box attacks. In black-box attacks, we dynamically train a distilled model for the black-box model and optimize the generator accordingly. Adversarial examples generated by AdvGAN on different target models have high attack success rate under stateof-the-art defenses compared to other attacks. Our attack has placed the first with 92.76% accuracy on a public MNIST black-box attack challenge.1. © 2018 International Joint Conferences on Artificial Intelligence. All right reserved.",,"Artificial intelligence; Adversarial networks; Black boxes; Black-box model; Different attacks; Perceptual quality; Research efforts; State of the art; Target model; Deep neural networks",,,,,"Baluja, S., Fischer, I., (2017) Adversarial Transformation Networks: Learning to Generate Adversarial Examples; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 3-14. , ACM; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium on, pp. 39-57. , IEEE; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., Imagenet: A large-scale hierarchical image database (2009) CVPR, pp. 248-255. , IEEE; Evtimov, I., Eykholt, K., Fernandes, E., Kohno, T., Li, B., Prakash, A., Rahmati, A., Song, D., (2017) Robust Physical-world Attacks on Machine Learning Models; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) NIPS, pp. 2672-2680; Goodfellow, I., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) CVPR, pp. 770-778; He, W., Wei, J., Chen, X., Carlini, N., Song, D., (2017) Adversarial Example Defenses: Ensembles of Weak Defenses Are Not Strong; Hinton, G., Vinyals, O., Dean, J., (2015) Distilling the Knowledge in a Neural Network; Isola, P., Zhu, J.-Y., Zhou, T., Efros, A.A., Image-to-image translation with conditional adversarial networks (2017) CVPR; Kinga, D., Ba Adam, J., Amethod for stochastic optimization (2015) International Conference on Learning Representations (ICLR); Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images; Kurakin, A., Goodfellow, I., Bengio, S., Dong, Y., Liao, F., Liang, M., Pang, T., Xie, C., (2018) Adversarial Attacks and Defences Competition; LeCun, Y., Cortes, C., (1998) The Mnist Database of Handwritten Digits; Liu, Y., Chen, X., Liu, C., Song, D., Delving into transferable adversarial examples and black-box attacks (2017) ICLR; Mao, X., Li, Q., Xie, H., Lau, R.Y.K., Wang, Z., Smolley, S.P., Least squares generative adversarial networks (2017) 2017 IEEE International Conference on Computer Vision (ICCV), pp. 2813-2821. , IEEE; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, , cs, stat, June; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z., Swami, A., (2016) Practical Black-box Attacks Against Deep Learning Systems Using Adversarial Examples, , arXiv preprint; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) ICLR; Tramèr, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P., (2017) Ensemble Adversarial Training: Attacks and Defenses; Xiao, C., Zhu, J.-Y., Li, B., He, W., Liu, M., Song, D., (2018) Spatially Transformed Adversarial Examples; Zagoruyko, S., Komodakis, N., (2016) Wide Residual Networks; Zhu, J.-Y., Krähenbühl, P., Shechtman, E., Efros, A.A., Generative visual manipulation on the natural image manifold (2016) ECCV, pp. 597-613. , Springer; Zhu, J.-Y., Park, T., Isola, P., Efros, A.A., Unpaired image-to-image translation using cycle-consistent adversarial networks (2017) ICCV, pp. 2242-2251",,"Lang J.","International Joint Conferences on Artifical Intelligence (IJCAI)","International Joint Conferences on Artificial Intelligence","27th International Joint Conference on Artificial Intelligence, IJCAI 2018","13 July 2018 through 19 July 2018",,140653,10450823,9780999241127,,,"English","IJCAI Int. Joint Conf. Artif. Intell.",Conference Paper,"Final","All Open Access, Bronze, Green",Scopus,2-s2.0-85055082314
"Jakubovitz D., Giryes R.","57204286184;33767616100;","Improving DNN robustness to adversarial attacks using jacobian regularization",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11216 LNCS",,,"525","541",,10,"10.1007/978-3-030-01258-8_32","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055081553&doi=10.1007%2f978-3-030-01258-8_32&partnerID=40&md5=7334d3c7ebf7c7361495aa057cfbc573","School of Electrical Engineering, Tel Aviv University, Tel Aviv, Israel","Jakubovitz, D., School of Electrical Engineering, Tel Aviv University, Tel Aviv, Israel; Giryes, R., School of Electrical Engineering, Tel Aviv University, Tel Aviv, Israel","Deep neural networks have lately shown tremendous performance in various applications including vision and speech processing tasks. However, alongside their ability to perform these tasks with such high accuracy, it has been shown that they are highly susceptible to adversarial attacks: a small change in the input would cause the network to err with high confidence. This phenomenon exposes an inherent fault in these networks and their ability to generalize well. For this reason, providing robustness to adversarial attacks is an important challenge in networks training, which has led to extensive research. In this work, we suggest a theoretically inspired novel approach to improve the networks’ robustness. Our method applies regularization using the Frobenius norm of the Jacobian of the network, which is applied as post-processing, after regular training has finished. We demonstrate empirically that it leads to enhanced robustness results with a minimal change in the original network’s accuracy. © Springer Nature Switzerland AG 2018.","Adversarial examples; Classification robustness; Data perturbation; Deep learning; Jacobian regularization; Neural networks","Computer vision; Deep learning; Neural networks; Speech processing; Adversarial examples; Data perturbation; Frobenius norm; High confidence; High-accuracy; In networks; Jacobians; Post processing; Deep neural networks",,,,,"Abadi, M., (2015) Tensorflow: Large-Scale Machine Learning on Heterogeneous Systems, 1. , tensorflow.org; Baluja, S., Fischer, I., Learning to attack: Adversarial transformation networks (2018) AAAI; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy; Cisse, M., Bojanowski, P., Grave, E., Dauphin, Y., Usunier, N., Parseval networks: Improving robustness to adversarial examples (2017) ICML; Fawzi, A., Moosavi-Dezfooli, S., Frossard, P., Soatto, S., (2017) Classification Regions of Deep Neural Networks; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts, , https://arxiv.org/pdf/1703.00410.pdf; Goodfellow, I., Bengio, Y., Courville, A., (2016) Deep Learning, , MIT Press, Cambridge; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) ICLR; Hein, M., Andriushchenko, M., Formal guarantees on the robustness of a classifier against adversarial manipulation (2017) Advances in Neural Information Processing Systems, 30, pp. 2266-2276. , http://papers.nips.cc/paper/6821-formal-guarantees-on-the-robustness-of-a-classifier-against-adversarial-manipulation.pdf, Guyon, I., et al. (eds.), Curran Associates, Inc; Hinton, G., (2012) Networks for Machine Learning-Lecture 6A-Overview of Mini-Batch Gradient Descent; Kingma, D.P., Ba, J., Adam: A method for stochastic optimization (2015) ICLR, , http://arxiv.org/abs/1412.6980; Li, X., Li, F., Adversarial examples detection in deep networks with convolutional filter statistics (2017) ICCV; Lu, J., Issaranon, T., Forsyth, D., SafetyNet: Detecting and rejecting adversarial examples robustly (2017) ICCV; Madryi, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2017) Towards Deep Learning Models Resistant to Adversarial Attacks, p. 3. , https://arxiv.org/pdf/1706.06083.pdf; Martens, J., Sutskever, I., Swersky, K., Estimating the hessian by back-propagating curvature (2012) Proceedings of the 29Th International Conference on Machine Learning, ICML 2012, , Edinburgh, Scotland, UK, 26 June 2012–1 July 2012; Meng, D., Chen, H., MagNet: A two-pronged defense against adversarial examples (2017) ACM SIGSAC Conference on Computer and Communications Security, pp. 135-147; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., On detecting adversarial perturbations (2017) ICLR; Miyato, T., Maeda, S., Koyama, M., Nakae, K., Ishii, S., Distributional smoothing with virtual adversarial training (2016) ICLR, , https://arxiv.org/pdf/1507.00677.pdf; Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2574-2582. , June; Moosavi-Dezfooli, S.M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) CVPR; Moosavi-Dezfooli, S.M., Fawzi, A., Fawzi, O., Frossard, P., Soatto, S., (2017) Analysis of Universal Adversarial Perturbations; Oh, S.J., Fritz, M., Schiele, B., Adversarial image perturbation for privacy protection a game theory perspective (2017) ICCV; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) 1St IEEE European Symposium on Security and Privacy; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) 37Th IEEE Symposium on Security and Privacy; Ross, A.S., Doshi-Velez, F., Improving the adversarial robustness and interpretability of deep neural networks by regularizing their input gradients (2017) Corr Abs/1711.09404, , http://arxiv.org/abs/1711.09404; Rozsa, A., Gunther, M., Boult, E., T.: Towards robust deep neural networks with BANG (2018) WACV; Shaham, U., Yamada, Y., Negahban, S., (2016) Understanding Adversarial Training: Increasing Local Stability of Neural Nets through Robust Optimization, , https://arxiv.org/pdf/1511.05432.pdf; Simon-Gabriel, C.J., Ollivier, Y., Bottou, L., Schlkopf, B., Lopez-Paz, D., (2018) Adversarial Vulnerability of Neural Networks Increases with Input Dimension, , https://arxiv.org/pdf/1802.01421.pdf; Sinha, A., Namkoong, H., Duchi, J., Certifying some distributional robustness with principled adversarial training (2018) ICLR; Sokolic, J., Giryes, R., Sapiro, G., Rodrigues, M.R.D., Robust large margin deep neural networks (2017) IEEE Trans. Signal Process., 65 (16), pp. 4265-4280; Strauss, T., Hanselmann, M., Junginger, A., Ulmer, H., (2018) Ensemble Methods as a Defense to Adversarial Perturbations against Deep Neural Networks, , https://arxiv.org/pdf/1709.03423.pdf; Szegedy, C., Intriguing properties of neural networks (2014) International Conference on Learning Representations, , http://arxiv.org/abs/1312.6199; Tramer, F., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., (2017) The Space of Transferable Adversarial Examples, , https://arxiv.org/pdf/1704.03453.pdf; Varga, D., Csiszarik, A., Zombori, Z., (2018) Gradient Regularization Improves Accuracy of Discriminative Models, , https://arxiv.org/pdf/1712.09936.pdf; Xu, W., Evans, D., Qi, Y., Feature squeezing: Detecting adversarial examples in deep neural networks (2018) Network and Distributed Systems Security Symposium (NDSS), , to appear","Jakubovitz, D.; School of Electrical Engineering, Israel; email: danielshaij@mail.tau.ac.il","Hebert M.Ferrari V.Sminchisescu C.Weiss Y.",,"Springer Verlag","15th European Conference on Computer Vision, ECCV 2018","8 September 2018 through 14 September 2018",,219419,03029743,9783030012571,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85055081553
"Sharma R.K., Kalita H.K., Issac B.","56125672900;56231992800;16021747000;","Are machine learning based intrusion detection system always secure? An insight into tampered learning",2018,"Journal of Intelligent and Fuzzy Systems","35","3",,"3635","3651",,2,"10.3233/JIFS-18202","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054829185&doi=10.3233%2fJIFS-18202&partnerID=40&md5=75be72feb05dbed912fadb4dc2ef3cc2","Department of Information Techcnology, NEHU, Shillong, Meghalaya, India; School of Computing, Media and Arts, Teesside University, United Kingdom","Sharma, R.K., Department of Information Techcnology, NEHU, Shillong, Meghalaya, India; Kalita, H.K., Department of Information Techcnology, NEHU, Shillong, Meghalaya, India; Issac, B., School of Computing, Media and Arts, Teesside University, United Kingdom","Machine Learning is successful in many applications including securing a network from unseen attack. The application of learning algorithm for detecting anomaly in a Network has been fundamental since few years. With increasing use of machine learning techniques it has become important to study to what extent it is good to be dependent on them. Altogether a different discipline called 'Adversarial Learning' have come up as a separate dimension of study. The work in this paper is to test the robustness of online machine learning based IDS to carefully crafted packets by attacker called poison packets. The objective is to observe how a remote attacker can deviate the normal behavior of machine learning based classifier in the IDS by injecting the network with carefully crafted packets externally, that may seem normal by the classification algorithm and the instance made part of its future training set. This behavior eventually can lead to a poison learning by the classification algorithm in the long run, resulting in misclassification of true attack instances. This work explores one such approach with SOM and SVM as the online learning based classification algorithms. © 2018-IOS Press and the authors. All rights reserved.","Adversarial learning; artificial intelligence; intrusion detection system; machine learning; NSL-KDD dataset; poison learning; support vectors; SVM","Artificial intelligence; Classification (of information); Computer crime; E-learning; Intrusion detection; Learning systems; Network security; Adversarial learning; Intrusion Detection Systems; NSL-KDD dataset; poison learning; Support vector; Learning algorithms",,,,,"Lee, S., Gisung, K., Kim, S., Self-adaptive and dynamic clustering for online anomaly detection (2011) Expert Systems with Applications, 38 (12), pp. 14891-14898; Tavallaee, M., (2012) Nsl-kdd Dataset, , http://www.iscx.ca/NSL-KDD; Haykin, S., Multilayer perceptrons (1999) Neural Networks: A Comprehensive Foundation, 2, pp. 156-255; Hawang, S.-C., Artificial neural network (2003) Interdisciplinary Computing in Java Programming, pp. 81-100. , Springer US; Mukkamala, S., Janoski, G., Sung, A., Intrusion detection using neural networks and support vector machines (2002) Neural Networks, 2002 IJCNN'02 Proceedings of the 2002 International Joint Conference on, 2. , IEEE; Meyer, D., Wien, F.H.T., Support vector machines (2015) The Interface to Libsvm in Package, p. e1071; Mammone, A., Turchi, M., Cristianini, N., Support vector machines (2009) Wiley Interdisciplinary Reviews: Computational Statistics, 1 (3), pp. 283-289; Yin, H., The self-organizing maps: Background theories extensions and applications (2008) Computational Intelligence: A Compendium, pp. 715-762. , Springer Berlin Heidelberg; Mitchell, T.M., Learning from labeled and unlabeled data (2006) Machine Learning, 10, p. 701; Murphy, K.P., (2006) Naive Bayes Classifiers, , University of British Columbia; Zamani, M., Mahnush, M., (2013) Machine Learning Techniques for Intrusion Detection, , arxiv 1312.2177; Orr, M.J.L., (1996) Introduction to Radial Basis Function Networks; Teknomo, K., K-means clustering tutorial (2006) Medicine, 100 (4), p. 3; Wang, G., A new approach to intrusion detection using artificial neural networks and fuzzy clustering (2010) Expert Systems with Applications, 37 (9), pp. 6225-6232; Ahmad, I., Abdullah, A.B., Alghamdi, A.S., Application of artificial neural network in detection ofDOSattacks (2009) Proceedings of the 2nd International Conference on Security of Information and Networks ACM; Norouzian, M.R., Merati, S., Classifying attacks in a network intrusion detection system based on artificial neural networks (2011) Advanced Communication Technology (ICACT), 2011 13th International Conference on IEEE; Horng, S.-J., A novel intrusion detection system based on hierarchical clustering and support vector machines (2011) Expert Systems with Applications, 38 (1), pp. 306-313; Li, Y., An efficient intrusion detection system based on support vector machines and gradually feature removal method (2012) Expert Systems with Applications, 39 (1), pp. 424-430; Chen, R.-C., Using rough set and support vector machine for network intrusion detection system (2009) Intelligent Information and Database Systems, 2009, ACIIDS 2009 First Asian Conference on IEEE; Huang, S.-Y., Huang, Y.-N., Network traffic anomaly detection based on growing hierarchical SOM (2013) 2013 43rd Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN) IEEE; Ippoliti, D., Zhou, X., A-GHSOM: An adaptive growing hierarchical self organizing map for network anomaly detection (2012) Journal of Parallel and Distributed Computing, 72 (12), pp. 1576-1590; Sheikhan, M., Jadidi, Z., Farrokhi, A., Intrusion detection using reduced-size RNN based on feature grouping (2012) Neural Computing and Applications, 21 (6), pp. 1185-1190; Sindhu, S.S.S., Geetha, S., Kannan, A., Decision tree based light weight intrusion detection using a wrapper approach (2012) Expert Systems with Applications, 39 (1), pp. 129-141; Lin, S.-W., An intelligent algorithm with feature selection and decision rules applied to anomaly intrusion detection (2012) Applied Soft Computing, 12 (10), pp. 3285-3290; Muniyandi, A.P., Rajeswari, R., Rajaram, R., Network anomaly detection by cascading k-Means clustering and C4. 5 decision tree algorithm (2012) Procedia Engineering, 30, pp. 174-182; Koc, L., Mazzuchi, T.A., Sarkani, S., A network intrusion detection system based on a Hidden Nave Bayes multiclass classifier (2012) Expert Systems with Applications, 39 (18), pp. 13492-13500; Altwaijry, H., Algarny, S., Bayesian based intrusion detection system (2012) Journal of King Saud University-Computer and Information Sciences, 24 (1), pp. 1-6; Mukherjee, S., Sharma, N., Intrusion detection using naive Bayes classifier with feature reduction (2012) Procedia Technology, 4, pp. 119-128; Alsubhi, K., Aib, I., Boutaba, R., FuzMet: A fuzzy-logic based alert prioritization engine for intrusion detection systems (2012) International Journal of Network Management, 22 (4), pp. 263-284; Kavitha, B., Karthikeyan, S., Sheeba Maybell, P., An ensemble design of intrusion detection system for handling uncertainty using Neutrosophic Logic Classifier (2012) Knowledge-Based Systems, 28, pp. 88-96; Liu, S., A fuzzy logic based reputation model against unfair ratings (2013) Proceedings of the 2013 International Conference on Autonomous Agents and Multi-Agent Systems, International Foundation for Autonomous Agents and Multiagent Systems; Govindarajan, M., Chandrasekaran, R.M., Intrusion detection using an ensemble of classification methods (2012) World Congress on Engineering and Computer Science, 1; Cheng, C., Tay, W.P., Huang, G.-B., Extreme learning machines for intrusion detection (2012) The 2012 International Joint Conference on Neural Networks (IJCNN) IEEE; Hongqiang, J., Limin, J., Yanhua, J., A new network intrusion detection algorithm based on radial basis function neural networks classifier (2012) Advances in Information Sciences & Service Sciences, 4 (1); Li, Y., An efficient intrusion detection system based on support vector machines and gradually feature removal method (2012) Expert Systems with Applications, 39 (1), pp. 424-430; Lin, W.-C., Ke, S.-W., Tsai, C.-F., CANN: An intrusion detection system based on combining cluster centers and nearest neighbors (2015) Knowledge-Based Systems, 78, pp. 13-21; Sharma, S.K., An improved network intrusion detection technique based on k-means clustering via Naïve bayes classification (2012) Advances in Engineering, Science and Management (ICAESM), 2012 International Conference on, , IEEE; Hettich, S., Bay, S.D., (1999) The UCI KDD Archive, , http://kdd.ics.uci.edu, Irvine, CA: University of California, Department of Information and Computer Science; Tavallaee, M., Bagheri, E., Lu, W., Ghorbani, A., A detailed analysis of the kdd cup 99 data set (2009) Submitted to Second IEEE Symposium on Computational Intelligence for Security and Defense Applications (CISDA); Huang, L., Adversarial machine learning (2011) Proceedings of the 4th ACM Workshop on Security and Artificial Intelligence, , ACM; Barreno, M., Can machine learning be secure? (2006) Proceedings of the 2006 ACM Symposium on Information, Computer and Communications Security, , ACM; Damopoulos, D., Evaluation of anomaly-based IDS for mobile devices using machine learning classifiers (2012) Security and Communication Networks, 5 (1), pp. 3-14; Ranjan, S., Chen, F., (2013) Machine Learning Based Botnet Detection with Dynamic Adaptation, , U.S. Patent No. 8,402,543; Lin, W.-C., Ke, S.-W., Tsai, C.-F., CANN: An intrusion detection system based on combining cluster centers and nearest neighbors (2015) Knowledge-Based Systems, 78, pp. 13-21; Xiao, L., Chen, Y., Chang, C.K., Bayesian model averaging of Bayesian network classifiers for intrusion detection (2014) Computer Software and Applications Conference Workshops (COMPSACW), 2014 IEEE 38th International IEEE; Lee, S., Kim, G., Kim, S., Self-adaptive and dynamic clustering for online anomaly detection (2011) Expert Systems with Applications, 38 (12), pp. 14891-14898; Sharma, R.K., Kalita, H.K., Borah, P., Analysis of machine learning techniques based intrusion detection systems (2016) Proceedings of 3rd International Conference on Advanced Computing, Networking and Informatics, , Springer India; Sharma, R.K., Kalita, H.K., Issac, B., Plant based biologically inspired intrusion response mechanism: An insight into the proposed model PIRIDS (2016) Journal of Information Assurance and Security; Sharma, R.K., Kalita, H.K., Issac, B., Different firewall techniques: A survey (2014) Computing, Communication and Networking Technologies (ICCCNT), 2014 International Conference on IEEE; Sharma, R.K., Generation of biometric key for use in des (2012) International Journal of Computer Science Isseues, 9 (6); Kubat, M., Matwin, S., Addressing the curse of imbalanced training sets: One-sided selection (1997) ICML, 97; Witten, I.H., (2016) Data Mining: Practical Machine Learning Tools and Techniques, , Morgan Kaufmann; Dua, S., Xian, D., (2016) Data Mining and Machine Learning in Cybersecurity, , CRC Press; Huang, R., (2015) Learning with A Strong Adversary, , arxiv 1511.03034; Shokri, R., Membership inference attacks against machine learning models (2017) Security and Privacy (SP), 2017 IEEE Symposium on, , IEEE; Lemâtre, G., Nogueira, F., Aridas, C.K., Imbalancedlearn: A python toolbox to tackle the curse of imbalanced datasets in machine learning (2017) Journal of Machine Learning Research, 18 (17), pp. 1-5; Zhai, J., Zhang, S., Chenxi, W., The classification of imbalanced large data sets based on map reduce and ensemble of ELM classifiers (2017) Journal of Machine Learning and Cybernetics, 8 (3), pp. 1009-1017; Zhai, J., Zhang, S., Zhang, M., Fuzzy integral-based ELM ensemble for imbalanced big data classification (2018) Soft Computing; Papernot, N., (2017) Adversarial Examples in Machine Learning; Zheng, J., He, Z., Lin, Z., Hybrid adversarial sample crafting for black-box evasion attack (2017) Wavelet Analysis and Pattern Recognition (ICWAPR), 2017 International Conference on IEEE","Sharma, R.K.; Department of Information Techcnology, India; email: rupam.sharma@dbuniversity.ac.in",,,"IOS Press",,,,,10641246,,,,"English","J. Intelligent Fuzzy Syst.",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85054829185
"Pattanaik A., Tang Z., Liu S., Bommannan G., Chowdhary G.","57189684586;57204156540;57204156477;57204158104;8724723800;","Robust Deep Reinforcement Learning with adversarial attacks",2018,"Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS","3",,,"2040","2042",,47,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054762037&partnerID=40&md5=30fcb05b34d27197cdd5dafbddd136ad","University of Illinois at Urbana-Champaign, United States","Pattanaik, A., University of Illinois at Urbana-Champaign, United States; Tang, Z., University of Illinois at Urbana-Champaign, United States; Liu, S., University of Illinois at Urbana-Champaign, United States; Bommannan, G., University of Illinois at Urbana-Champaign, United States; Chowdhary, G., University of Illinois at Urbana-Champaign, United States","This paper proposes adversarial attacks for Reinforcement Learning (RL). These attacks are then leveraged during training to improve the robustness of RL within robust control framework. We show that this adversarial training of DRL algorithms like Deep Double Q learning and Deep Deterministic Policy Gradients leads to significant increase in robustness to parameter variations for RL benchmarks such as Mountain Car and Hopper environment. Full paper is available at (https://arxiv.org/abs/1712.03632) [7]. © 2018 International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org). All rights reserved.","Adversarial machine learning; Deep learning; Reinforcement Learning","Autonomous agents; Learning algorithms; Multi agent systems; Reinforcement learning; Robust control; Control framework; Policy gradient; Q-learning; Deep learning",,,,,"Brockman, G., Cheung, V., Pettersson, L., Schneider, J., Schulman, J., Tang, J., Zaremba, W., (2016) OpenAI Gym, , 2016; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , 2014; Huang, S., Papernot, N., Goodfellow, I., Duan, Y., AbbeeL, P., (2017) Adversarial Attacks on Neural Network Policies, , 2017; Levine, S., Finn, C., Darreil, T., Abbeel, P., End-to-end training of Deep visuomotor policies (2016) Journal of Machine Learning Research, 17 (39), pp. 1-40. , 2016; Lillicrap, T.P., Hunt, J.J., Pritzel, A., Heess, N., Erez, T., Tassa, Y., Silver, D., Wierstra, D., (2015) Continuous Control with Deep Reinforcement Learning, , 2015; Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.A., Veness, J., Bellemare, M.G., Graves, A., Hassabis, D., Human-level control through deep reinforcement learning (2015) Nature, 518 (7540), pp. 529-533. , 2015; Pattanaik, A., Tang, Z., Liu, S., Bommannan, G., Chowdhary, G., (2017) Robust Deep Reinforcement Learning with Adversarial Attacks, , 2017; Schulman, J., Levine, S., Abbeel, P., Jordan, M.I., Moritz, P., Trust region policy optirnization (2015) ICML, pp. 1889-1897; Silver, D., Huang, A., Maddison, C.J., Guez, A., Sifre, L., Van Den Driessche, G., Schrittwieser, J., Hassabis, D., Mastering the game of Go with deep neural networks and tree search (2016) Nature, 529 (7587), pp. 484-489. , 2016; Todorov, E., Erez, T., Tassa, Y., MuJoCo: A physics engine for model-based control (2012) IROS",,,"Artificial Intelligence;Elsevier;et al.;International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS);Nissan;NSF","International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS)","17th International Conference on Autonomous Agents and Multiagent Systems, AAMAS 2018","10 July 2018 through 15 July 2018",,139890,15488403,9781510868083,,,"English","Proc. Int. Joint Conf. Auton. Agents Multiagent Syst., AAMAS",Conference Paper,"Final","",Scopus,2-s2.0-85054762037
"Gholami S., McCarthy S., Dilkina B., Plumptre A., Tambe M., Driciru M., Wanyama F., Rwetsiba A., Nsubaga M., Mabonga J., Okello T., Enyel E.","57191169254;57196120192;23008031500;6603665150;7006395526;15126824100;56042040800;36509376200;57196402400;57196402227;57204143703;57204143272;","Adversary models account for imperfect crime data: Forecasting and planning against real-world poachers",2018,"Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS","2",,,"823","831",,13,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054612520&partnerID=40&md5=8054ce5092ab09c8f3b2901609e6303a","University of Southern California, United States; Wildlife Conservation Society, United States; Uganda Wildlife Authority, United States","Gholami, S., University of Southern California, United States; McCarthy, S., University of Southern California, United States; Dilkina, B., University of Southern California, United States; Plumptre, A., Wildlife Conservation Society, United States; Tambe, M., University of Southern California, United States; Driciru, M., Uganda Wildlife Authority, United States; Wanyama, F., Uganda Wildlife Authority, United States; Rwetsiba, A., Uganda Wildlife Authority, United States; Nsubaga, M., Wildlife Conservation Society, United States; Mabonga, J., Wildlife Conservation Society, United States; Okello, T., Uganda Wildlife Authority, United States; Enyel, E., Uganda Wildlife Authority, United States","Poachers are engaged in extinction level wholesale slaughter, so it is critical to harness historical data for predicting poachers' behavior. However, in these domains, data collected about adversarial actions are remarkably imperfect, where reported negative instances of crime may be mislabeled or uncertain. Unfortunately, past attempts to develop predictive and prescriptive models to address this problem suffer from shortcomings from a modeling perspective as well as in the implementability of their techniques. Most notably these models i) neglect the uncertainty in crime data, leading to inaccurate and biased predictions of adversary behavior, ii) use coarse-grained crime analysis and iii) do not provide a convincing evaluation as they only look at a single protected area. Additionally, they iv) proposed time-consuming techniques which cannot be directly integrated into low resource outposts. In this innovative application paper, we (I) introduce iWare-E a novel imperfect-observation aWare Ensemble (iWare-E) technique1, which is designed to handle the uncertainty in crime information efficiently. This approach leads to superior accuracy for adversary behavior prediction (up to 34% increase in AUC) compared to the previous state-of-the-art. We also demonstrate the country-wide efficiency of the models and are the first to (II) evaluate our adversary behavioral model across different protected areas in Uganda, i.e., Murchison Fall and Queen Elizabeth National Park, (totaling about 7500 square km) as well as (ID) on fine-grained temporal resolutions. Lastly, (IV) we provide a scalable planning algorithm to design fine-grained patrol routes for the rangers, which achieves up to 150% improvement in number of predicted attacks detected. © 2018 International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org). All rights reserved.","Ensemble techniques; Field test evaluation; Patrol planning; Predictive models; Wildlife poaching; Wildlife protection","Animals; Conservation; Crime; Environmental protection; Forecasting; Multi agent systems; Uncertainty analysis; Ensemble techniques; Field test; Predictive models; Wildlife poaching; Wildlife protection; Autonomous agents",,,,,"Basilico, N., Gattl, N., Strategic guard placement for optimal response toaiarms in security games (2014) Proceedings of the 2014 International Conference on Autonomous Agents and Multi-agent Systems, pp. 1481-1482. , International Foundation for Autonomous Agents and Multiagent Systems; Basilico, N., Gatti, N., Amigoni, F., Leader-follower strategies for robotic patrolling in environments with arbitrary topologies (2009) AAMAS.; Chase, M.J., Schlossberg, S., Griffin, C.R., Bouche, P.J.C., Djene, S.W., Elkan, P.W., Ferreira, S., Landen, K., Continent-wide survey reveals massive decline in African savannah elephants (2016) PeerJ, 4, p. e2354. , 2016; Cooney, R., Roe, D., Dublin, H., Phelps, J., Wilkie, D., Keane, A., Travers, H., Allan, J.R., From poachers to protectors: Engaging local communities in solutions to illegal wildlife trade (2017) Conservation Letters, 10 (3), pp. 367-374. , 2017; Critchlow, R., Plumptre, A.J., Driciru, M., Rwetsiba, A., Tumwesigye, E.J., Stokes, C., Wanyama, F., Beale, C.M., Spatiotemporal trends of illegal activities from ranger-collected data in a ugandan national park (2015) Conservation Biology, 29 (5), pp. 1458-1470. , 2015; Fang, F., Nguyen, T.H., Pickles, R., Lam, W.Y., Clements, G.R., An, B., Singh, A., Lemieux, A., Deploying paws: Field optimization of the protection assistant for wildlife security (2016) IAAL; Fang, F., Stone, P., Tambe, M., When security games go green: Designing defender strategies to prevent poaching and illegal fishing (2015) 1JCAI.; Gholami, S., Ford, B., Fang, F., Plumptre, A., Tambe, M., Driciru, M., Wanyama, F., Mabonga, J., Taking it for a test drive: A hybrid spatio-temporal model for wildlife poaching prediction evaluated through a controlled field test (2017) Proceedings of the European Conference on Machine Learning & Principles and Practice of Knowledge Discovery in Databases, , ECML PKDD; Gholami, S., Wilder, B., Brown, M., Sinha, A., Sintov, N., Tambe, M., A game theoretic approach on addressing cooperation among human adversaries (2016) Proceedings of the 15th International Conference on Autonomous Agents and Multiagent Systems.; Gholami, S., Wilder, B., Brown, M., Thomas, D., Sintov, N., Tambe, M., Divide to defend: Collusive security games (2016) GameSec, pp. 272-293. , Springer; Kar, D., Fang, F., Fave, F.D., Sintov, N., Tambe, M., A game of thrones: When human behavior models compete in repeated stackelberg security games (2015) Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems, pp. 1381-1390. , International Foundation for Autonomous Agents and Multiagent Systems; Kar, D., Fang, F., Sintov, F.D., Fave, N., Tambe, M., A game ofthrones"": When human behavior models compete in repeated stackelberg security games (2015) AAMAS.; Kar, D., Ford, B., Gholami, S., Fang, F., Plumptre, A., Tambe, M., Driciru, M., Nsubaga, M., Cloudy with a chance of poaching: Adversary behavior modeling and forecasting with real-world poaching data (2017) Proceedings of the 16th Conference on Autonomous Agents and MultiAgent Systems, pp. 159-167. , International Foundation for Autonomous Agents and Multiagent Systems; Kiekintveld, C., Islam, T., Kreinovich, V., Security games with interval uncertainly (2013) Proceedings of the 2013 International Conference on Autonomous Agents and Multi-agent Systems, pp. 231-238. , International Foundation for Autonomous Agents and Multiagent Systems; Korzhyk, D., Conitzer, V., Parr, R., Solving stackelberg games with uncertain observability (2011) The 10th International Conference on Autonomous Agents and Multiagent Systems-Volume 3, pp. 1013-1020. , International Foundation for Autonomous Agents and Multiagent Systems; Lee, W.S., Liu, B., Learning with positive and unlabeled examples using weighted logistic regression (2003) ICML, 3; Lubbe, B.A., Preez, E.A.D., Douglas, A., Fairer-Wessels, F., The impact of rhino poaching on tourist experiences and future visitation to national parks in South Africa (2017) Current Issues in Tourism (2017), pp. 1-8; McCarthy, S., Tambe, M., Kiekintveld, C., Gore, M.L., Killion, A., Preventing illegal logging: Simultaneous optimization of resource teams and tactics for security (2016) Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence (AAAI'16), pp. 3880-3886. , http://dl.acm.org/citation.cfm?id=3016387.3016450, AAAI Press; McKelvey, R., Palfrey, T.R.D., Quantal response equilibria for normal form games (1995) Games and Economic Behavior; De Cote, E.M., Stranders, R., Basilico, N., Gatti, N., Jennings, N., Introducing alarms in adversarial patrolling games (2013) Proceedings of the 2013 International Conference on Autonomous Agents and Multiagent Systems, pp. 1275-1276. , International Foundation for Autonomous Agents and Multiagent Systems; Naidoo, R., Fisher, B., Manica, A., Balmford, A., Estimating economic losses to tourism in Africa from the illegal killing of elephants (2016) Nature Communications, p. 7. , 2016; Nguyen, T.H., Fave, F.M.D., Kar, D., Lakshminarayanan, A.S., Yadav, A., Tambe, M., Agmon, N., Wanyama, F., Making the most of our regrets: Regret-based solutions to handle payoff uncertainty and elicitation in green security games (2015) GameSec., pp. 170-191. , Springer; Nguyen, T.H., Sinha, A., Gholami, S., Plumptre, A., Joppa, L., Tambe, M., Driciru, M., Critchlow, R., Capture: A new predictive anti-poaching tool for wildlife protection (2016) AAMAS, pp. 767-775; Nguyen, T.H., Yang, R., Azaria, A., Kraus, S., Tambe, M., Analyzing the effectiveness of adversary modeling in security games (2013) AAAL; Okamoto, S., Hazon, N., Sycara, K., Solving non-zero sum multiagent network flow security games with attack costs (2012) AAMAS, pp. 879-888; Wittemyer, G., Northrup, J.M., Blanc, J., Douglas-Hamilton, I., Omondi, P., Burnham, K.P., Illegal killing for ivory drives global decline in african elephants (2014) Proceedings of the National Academy of Sciences, 111 (36), pp. 13117-13121. , 2014; Xu, H., Ford, B., Fang, F., Dilkina, B., Plumptre, A., Tambe, M., Driciru, M., Nsubaga, M., Optimal patrol planning for green security games with black-box attackers (2017) International Conference on Decision and Game Theory for Security, pp. 458-477. , Springer; Yang, R., Ford, B., Tambe, M., Lemieux, A., Adaptive resource allocation for wildlife protection against illegal poachers (2004) AAMAS.; Yang, R., Kiekintveld, C., Ordonez, F., Tambe, M., John, R., Improving resource allocation strategy against human adversaries in security games (2011) IJCAI Proceedings-International Joint Conference on Artificial Intelligence, 22, p. 458",,,"Artificial Intelligence;Elsevier;et al.;International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS);Nissan;NSF","International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS)","17th International Conference on Autonomous Agents and Multiagent Systems, AAMAS 2018","10 July 2018 through 15 July 2018",,139890,15488403,9781510868083,,,"English","Proc. Int. Joint Conf. Auton. Agents Multiagent Syst., AAMAS",Conference Paper,"Final","",Scopus,2-s2.0-85054612520
"Rodriguez N., Rojas-Galeano S.","57198003846;24401750500;","Fighting adversarial attacks on online abusive language moderation",2018,"Communications in Computer and Information Science","915",,,"480","493",,1,"10.1007/978-3-030-00350-0_40","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054063816&doi=10.1007%2f978-3-030-00350-0_40&partnerID=40&md5=2e06c155ff16547ef57f0d03e5031752","School of Engineering, Universidad Distrital Francisco José de Caldas, Bogotá, Colombia","Rodriguez, N., School of Engineering, Universidad Distrital Francisco José de Caldas, Bogotá, Colombia; Rojas-Galeano, S., School of Engineering, Universidad Distrital Francisco José de Caldas, Bogotá, Colombia","Lack of moderation in online conversations may result in personal aggression, harassment or cyberbullying. Such kind of hostility is usually expressed by using profanity or abusive language. On the basis of this assumption, recently Google has developed a machine-learning model to detect hostility within a comment. The model is able to assess to what extent abusive language is poisoning a conversation, obtaining a “toxicity” score for the comment. Unfortunately, it has been suggested that such a toxicity model can be deceived by adversarial attacks that manipulate the text sequence of the abusive language. In this paper we aim to fight this anomaly; firstly we characterise two types of adversarial attacks, one using obfuscation and the other using polarity transformations. Then, we propose a two–stage approach to disarm such attacks by coupling a text deobfuscation method and the toxicity scoring model. The approach was validated on a dataset of approximately 24000 distorted comments showing that it is feasible to restore the toxicity score of the adversarial variants. We anticipate that combining machine learning and text pattern recognition methods operating on different layers of linguistic features, will help to foster aggression–safe online conversations despite the adversary challenges inherent to the versatile nature of written language. © 2018, Springer Nature Switzerland AG.","Abusive language moderation; Adversarial attacks; Text pattern recognition","Artificial intelligence; Couplings; Learning systems; Linguistics; Social networking (online); Toxicity; Abusive language moderation; Adversarial attacks; Cyber bullying; Different layers; Linguistic features; Machine learning models; Pattern recognition method; Toxicity modeling; Character recognition",,,,,"Dale, R., NLP in a post-truth world (2017) Nat. Lang. Eng., 23 (2), pp. 319-324; Hosseinmardi, H., Survey of computational methods in cyberbullying research (2016) Proceedings of the First International Workshop on Computational Methods for Cybersafety, , ACM, New York; Burnap, P., Williams, M.L., Us and them: Identifying cyber hate on Twitter across multiple protected characteristics (2016) EPJ Data Sci, 5 (1), p. 11; Nobata, C., Tetreault, J., Thomas, A., Mehdad, Y., Chang, Y., Abusive language detection in online user content (2016) Proceedings of the 25Th International Conference on World Wide Web; Wulczyn, E., Thain, N., Dixon, L., Ex Machina: Personal Attacks Seen at Scale, , arXiv preprint arXiv:, February 2017; Hosseini, H., Kannan, S., Zhang, B., Poovendran, R., Deceiving google’s Perspective API Built for Detecting Toxic Comments, , arXiv preprint arXiv:, February 2017; Rojas-Galeano, S., On obstructing obscenity obfuscation (2017) ACM Trans. Web, 11 (2), pp. 1-12. , https://doi.org/10.1145/3032963; Laskov, P., Lippmann, R., Machine learning in adversarial environments (2010) Mach. Learn., 81 (2), pp. 115-119; Samanta, S., Mehta, S., (2017) Towards Crafting Text Adversarial Samples, , arXiv preprint arXiv; (2017), https://www.perspectiveapi.com, PerspectiveAPI: Jigsaw, Accessed 26 May 2018; (2017), https://api.textpatrol.tk, TextPatrolAPI: TPLabs, Accessed 26 May 2018; Stone, T.E., McMillan, M., Hazelton, M., Back to swear one: A review of English language literature on swearing and cursing in western health settings (2015) Aggress. Violent Behav., 25, pp. 65-74; Hosseinmardi, H., Mattson, S.A., Ibn Rafiq, R., Han, R., Lv, Q., Mishra, S., Analyzing labeled cyberbullying incidents on the instagram social network (2015) Social Informatics. LNCS, 9471, pp. 49-66. , Liu, T.Y., Scollon, C., Zhu, W. (eds.) , Springer, Cham, https://doi.org/10.1007/978-3-319-27433-14","Rojas-Galeano, S.; School of Engineering, Colombia; email: srojas@udistrital.edu.co","Lopez-Santana E.R.Figueroa-Garcia J.C.Rodriguez-Molano J.I.","","Springer Verlag","5th Workshop on Engineering Applications, WEA 2018","17 October 2018 through 19 October 2018",,218579,18650929,9783030003494,,,"English","Commun. Comput. Info. Sci.",Conference Paper,"Final","",Scopus,2-s2.0-85054063816
"Athalye A., Carlini N., Wagner D.","57204807086;57194977162;7401982903;","Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples",2018,"35th International Conference on Machine Learning, ICML 2018","1",,,"436","448",,324,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053904058&partnerID=40&md5=e223190d09dc143691105a8349160b57","Massachusetts Institute of Technology, United States; University of California, Berkeley, United States","Athalye, A., Massachusetts Institute of Technology, United States; Carlini, N., University of California, Berkeley, United States; Wagner, D., University of California, Berkeley, United States","We identify obfuscated gradients, a kind of gradient masking, as a phenomenon that leads to a false sense of security in defenses against adversarial examples. While defenses that causc obfuscated gradients appear to defeat iterative optimization- based attacks, wc find defenses relying on this effect can be circumvented. We describe characteristic behaviors of defenses exhibiting the effect, and for each of the three types Qf obfuscated gradients we discover, wc develop attack techniques to overcome it. In a case study, examining non- certified white-box-secure defenses at ICLR 2018. we find obfuscated gradients arc a common occurrence, with 7 of 9 defenses relying on obfuscated gradients. Our new attacks successfully circumvent 6 completely, and 1 partially, in the original threat model each paper considers. © Copyright 2018 by the Authors. All rights reserved.",,"Artificial intelligence; Iterative methods; Iterative Optimization; Sense of security; Threat modeling; White box; Learning systems",,,,,"Athalye, A., Engstrom, L., Ilyas, A., Kwok, K., (2017) Synthesizing Robust Adversarial Examples, , arXiv preprint arXiv:1707.07397; Bengio, Y., Leonard, N., Courville, A., (2013) Estimating or Propagating Gradients through Stochastic Neurons for Conditional Computation, , arXiv preprint arXiv:1308.3432; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Srndic, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 387-402. , Springer; Buckman, J., Roy, A., Raffel, C., Goodfellow, I., Thermometer encoding: One hot way to resist adversarial examples (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=S18Su-CW, accepted as poster; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) AlSec; Carlini, N., Wagner, D., (2017) Magnet and ""Efficient Defenses against Adversarial Attacks"" are Not Robust to Adversarial Examples, , arXiv preprint arXiv:1711.08478; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security & Privacy; Dhillon, G.S., Azizzadenesheli, K., Bernstein, J.D., Kos-Saifi, J., Khanna, A., Lipton, Z.C., Anandkumar, A., Stochastic activation pruning for robust adversarial defense (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=HluR4GZRZ, accepted as poster; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, pp. 2672-2680; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint arXiv:1412.6572; Guo, C., Rana, M., Cisse, M., Van Der Maaten, L., Countering adversarial images using input transformations (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=SyJ7ClWCb, accepted as poster; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; He, W., Wei, J., Chen, X., Carlini, N., Song, D., (2017) Adversarial Example Defenses: Ensembles of Weak Defenses are Not Strong, , arXiv preprint arXiv:1706.04701; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint arXiv-.1607.02533; Kurakin, A., Goodfellow, I.J., Bengio, S., (2016) Adversarial Machine Learning at Scale, , arXiv preprint arXiv:1611.01236; Ma, X., Li, B., Wang, Y., Erfani, S.M., Wijewickrema, S., Schoenebeck, G., Houle, M.E., Bailey, J., Characterizing adversarial subspaces using local intrinsic dimensionality (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=BlgJlL2aW, accepted as oral presentation; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=rJzIBfZAb; Na, T., Ko, J.H., Mukhopadhyay, S., Cascade adversarial machine learning regularized with a unified embedding (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=HyRVBzap-; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Ce-Lik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, Asia CCS '17, pp. 506-519. , http://doi.acm.org/10.1145/3052973.305300, New York, NY, USA, ACM; Raghunathan, A., Steinhardt, J., Liang, P., Certified defenses against adversarial examples (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=Bys4ob-Rb; Rumelhart, D.E., Hinton, G.E., Williams, R.J., Learning representations by back-propagating errors (1986) Nature, 323, pp. 533-536; Salimans, T., Karpathy, A., Chen, X., Kingma, D.P., Pixelcnn++: A pixelcnn implementation with discretized logistic mixture likelihood and other modifications (2017) ICLR; Samangouei, P., Kabkab, M., Chellappa, R., Defense-gan: Protecting classifiers against adversarial attacks using generative models (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=BkJ3ibbO-, accepted as poster; Sharma, Y., Chen, P.-Y., (2017) Attacking the Madry Defense Model with L\-based Adversarial Examples, , arXiv preprint arXiv:1710.10733; Sinha, A., Namkoong, H., Duchi, J., Certifiable distributional robustness with principled adversarial training (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=Hk6kPgZA-; Song, Y., Kim, T., Nowozin, S., Ermon, S., Kush-Man, N., Pixeldefend: Leveraging generative models to understand and defend against adversarial examples (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=rJUYGxbCW, accepted as poster; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2013) ICLR; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826; Tramer, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., McDaniel, P., Ensemble adversarial training: Attacks and defenses (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=rkZvSe-RZ, accepted as poster; Xie, C., Wang, J., Zhang, Z., Ren, Z., Yuille, A., Mitigating adversarial effects through randomization (2018) International Conference on Learning Representations, , https://openreview.net/forum?id=Sk9yuq!0Z, accepted as poster; Zagoruyko, S., Komodakis, N., (2016) Wide Residual Networks, , arXiv preprint arXiv:1605.07146","Carlini, N.; University of CaliforniaUnited States; email: npc@cs.bcrkeley.edu","Krause A.Dy J.",,"International Machine Learning Society (IMLS)","35th International Conference on Machine Learning, ICML 2018","10 July 2018 through 15 July 2018",,141700,,9781510867963,,,"English","Int. Conf. Mach. Learn., ICML",Conference Paper,"Final","",Scopus,2-s2.0-85053904058
"Li S., Ye D., Jiang S., Liu C., Niu X., Luo X.","57203981968;7102368943;57203980885;57203979596;24081452700;8976166200;","Attack on Deep Steganalysis Neural Networks",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11066 LNCS",,,"265","276",,4,"10.1007/978-3-030-00015-8_23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053883155&doi=10.1007%2f978-3-030-00015-8_23&partnerID=40&md5=8eff2bd6c464771e17327a88727c3e3d","School of Cyber Science and Engineering, Wuhan University, Wuhan, China; School of Computer Science, Wuhan University, Wuhan, China; State Key Laboratory of Mathematical Engineering and Advanced Computing, Zhengzhou, China","Li, S., School of Cyber Science and Engineering, Wuhan University, Wuhan, China; Ye, D., School of Cyber Science and Engineering, Wuhan University, Wuhan, China; Jiang, S., School of Cyber Science and Engineering, Wuhan University, Wuhan, China; Liu, C., School of Cyber Science and Engineering, Wuhan University, Wuhan, China; Niu, X., School of Computer Science, Wuhan University, Wuhan, China; Luo, X., State Key Laboratory of Mathematical Engineering and Advanced Computing, Zhengzhou, China","Deep neural networks (DNN) have achieved state-of-art performance on image classification and pattern recognition in recent years, and also show its power on steganalysis field. But research revealed that the DNN can be easily fooled by adversarial examples generated by adding perturbation to input. Deep steganalysis neural networks have the same potential threat as well. In this paper we discuss and analysis two different attack methods and apply the methods in attacking on deep steganalysis neural networks. We defined the model and propose the concrete attack steps, the result shows that the two methods have 96.02% and 90.25% success ratio separately on the target DNN. Thus, the adversarial example attack is valid for deep steganalysis neural networks. © 2018, Springer Nature Switzerland AG.","Adversarial example; DNN; Steganalysis","Cloud computing; Pattern recognition; Steganography; Adversarial example; Different attacks; Potential threats; State-of-art performance; Steganalysis; Success ratio; Deep neural networks",,,,,"Bas, P., Filler, T., Pevný, T., “Break our steganographic system”: The ins and outs of organizing BOSS (2011) IH 2011. LNCS, 6958, pp. 59-70. , https://doi.org/10.1007/978-3-642-24178-9, Filler, T., Pevný, T., Craver, S., Ker, A. (eds.), Springer, Heidelberg, 5; Das, S., Suganthan, P.N., Differential evolution: A survey of the state-of-the-art (2011) IEEE Trans. Evol. Comput., 15 (1), pp. 4-31; Fridrich, J., Kodovsky, J., Rich models for steganalysis of digital images (2012) IEEE Trans. Inf. Forensics Secur., 7 (3), pp. 868-882; Fridrich, J., Kodovský, J., Holub, V., Goljan, M., Breaking HUGO – the process discovery (2011) IH 2011. LNCS, 6958, pp. 85-101. , https://doi.org/10.1007/978-3-642-24178-97, Filler, T., Pevný, T., Craver, S., Ker, A. (eds.), Springer, Heidelberg; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint arXiv; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Kodovskỳ, J., Fridrich, J., On completeness of feature spaces in blind steganalysis (2008) Proceedings of the 10Th ACM Workshop on Multimedia and Security, pp. 123-132. , ACM; Kurak, C., McHugh, J., A cautionary note on image downgrading (1992) Eighth Annual Computer Security Applications Conference, Proceedings, pp. 153-159. , IEEE; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint arXiv; Lecun, Y., Cortes, C., (2010) MNIST Handwritten Digit Database, , http://yann.lecun.com/exdb/mnist/; Luo, X., Steganalysis of HUGO steganography based on parameter recognition of syndrome-trellis-codes (2016) Multimedia Tools Appl, 75 (21), pp. 13557-13583; Ma, Y., Luo, X., Li, X., Bao, Z., Zhang, Y., Selection of rich model steganalysis features based on decision rough set α-positive region reduction (2018) IEEE Trans. Circuits Syst. Video Technol.; Moosavi-Dezfooli, S.M., Fawzi, A., Fawzi, O., Frossard, P., (2017) Universal Adversarial Perturbations; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 427-436; Pibre, L., Pasquet, J., Ienco, D., Chaumont, M., Deep learning is a good steganalysis tool when embedding key is reused for different images, even if there is a cover sourcemismatch (2016) Electron. Imaging, 2016 (8), pp. 1-11; Qian, Y., Dong, J., Wang, W., Tan, T., (2015) Deep Learning for Steganalysis via Convolutional Neural Networks. In: Media Watermarking, Security, and Forensics, 9409. , p. 94090J. International Society for Optics and Photonics; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-Scale Image Recognition, , arXiv preprint arXiv; Storn, R., Price, K., Differential evolution-a simple and efficient heuristic for global optimization over continuous spaces (1997) J. Global Optim., 11 (4), pp. 341-359; Su, J., Vargas, D.V., Kouichi, S., (2017) One Pixel Attack for Fooling Deep Neural Networks, , arXiv preprint arXiv; Szegedy, C., (2013) Intriguing Properties of Neural Networks, , arXiv preprint arXiv; Upham, D., (1997) Jsteg. Software Available at Ftp. Funet.Fi; Wang, J., Li, T., Shi, Y.Q., Lian, S., Ye, J., Forensics feature analysis in quaternion wavelet domain for distinguishing photographic images and computer graphics (2017) Multimedia Tools Appl, 76 (22), pp. 23721-23737; Winkler, S., Mohandas, P., The evolution of video quality measurement: From psnr to hybrid metrics (2008) IEEE Trans. Broadcast., 54 (3), pp. 660-668; Wu, S., Zhong, S.H., Liu, Y., (2017) A Novel Convolutional Neural Network for Image Steganalysis with Shared Normalization, , arXiv preprint arXiv; Xu, G., Wu, H.Z., Shi, Y.Q., Structural design of convolutional neural networks for steganalysis (2016) IEEE Signal Process. Lett., 23 (5), pp. 708-712; Ye, J., Ni, J., Yi, Y., Deep learning hierarchical representations for image steganalysis (2017) IEEE Trans. Inf. Forensics Secur., 12 (11), pp. 2545-2557; Zhang, Y., Qin, C., Zhang, W., Liu, F., Luo, X., (2018) On the Fault-Tolerant Performance for a Class of Robust Image Steganography, , Signal Process","Ye, D.; School of Cyber Science and Engineering, China; email: yedp2001@163.com","Bertino E.Sun X.Pan Z.",,"Springer Verlag","4th International Conference on Cloud Computing and Security, ICCCS 2018","8 June 2018 through 10 June 2018",,218419,03029743,9783030000141,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","",Scopus,2-s2.0-85053883155
"Behzadan V., Munir A.","55189927600;24587067400;","Mitigation of policy manipulation attacks on deep Q-networks with parameter-space noise",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11094 LNCS",,,"406","417",,5,"10.1007/978-3-319-99229-7_34","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053879955&doi=10.1007%2f978-3-319-99229-7_34&partnerID=40&md5=1d22a9bd72d749d0fef53a154b89571a","Kansas State University, Manhattan, KS  66506, United States","Behzadan, V., Kansas State University, Manhattan, KS  66506, United States; Munir, A., Kansas State University, Manhattan, KS  66506, United States","Recent developments establish the vulnerability of deep reinforcement learning to policy manipulation attack. In this work, we propose a technique for mitigation of such attacks based on addition of noise to the parameter space of deep reinforcement learners during training. We experimentally verify the effect of parameter-space noise in reducing the transferability of adversarial examples, and demonstrate the promising performance of this technique in mitigating the impact of whitebox and blackbox attacks at both test and training times. © Springer Nature Switzerland AG 2018.","Adversarial attacks; Adversarial examples; Deep reinforcement learning; Mitigation; Parameter-space noise","Reinforcement learning; Adversarial attacks; Adversarial examples; Black boxes; Effect of parameters; Mitigation; Parameter spaces; Deep learning",,,,,"Atallah, R., (2017) The Next Generation Intelligent Transportation System: Connected, Safe and Green. Ph.D. Thesis, , Concordia University; Baird, L., Moore, A.W., Gradient descent for general reinforcement learning (1998) Proceedings of the Advances in Neural Information Processing Systems, pp. 968-974; Behzadan, V., (2017) Crafting Adversarial Example Attacks on Policy Learners, , https://github.com/behzadanksu/rl-attack; Behzadan, V., Munir, A., (2017) Vulnerability of Deep Reinforcement Learning to Policy Induction Attacks, , arXiv preprint arXiv; Behzadan, V., Munir, A., (2017) Whatever Does Not Kill Deep Reinforcement Learning, Makes It Stronger, , arXiv preprint arXiv; Brockman, G., Cheung, V., Pettersson, L., Schneider, J., Schulman, J., Tang, J., Zaremba, W., (2016) Openai Gym, , arXiv preprint arXiv; Deng, Y., Bao, F., Kong, Y., Ren, Z., Dai, Q., Deep direct reinforcement learning for financial signal representation and trading (2017) IEEE Trans. Neural Networks Learn. Syst., 28 (3), pp. 653-664; Dhariwal, P., Hesse, C., Plappert, M., Radford, A., Schulman, J., Sidor, S., Wu, Y., (2017) Openai Baselines, , https://github.com/openai/baselines; Fortunato, M., Azar, M.G., Piot, B., Menick, J., Osband, I., Graves, A., Mnih, V., Pietquin, O., (2017) Noisy Networks for Exploration, , arXiv preprint arXiv; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint arXiv; Gu, S., Holly, E., Lillicrap, T., Levine, S., Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates (2017) 2017 IEEE International Conference on Robotics and Automation (ICRA), pp. 3389-3396. , IEEE; Huang, S., Papernot, N., Goodfellow, I., Duan, Y., Abbeel, P., (2017) Adversarial Attacks on Neural Network Policies, , arXiv preprint arXiv; Kos, J., Song, D., (2017) Delving into Adversarial Attacks on Deep Policies, , arXiv preprint arXiv; Lin, Y.C., Liu, M.Y., Sun, M., Huang, J.B., (2017) Detecting Adversarial Attacks on Neural Network Policies with Visual Foresight, , arXiv preprint arXiv; Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.A., Veness, J., Bellemare, M.G., Graves, A., Ostrovski, G., Human-level control through deep reinforcement learning (2015) Nature, 518 (7540), pp. 529-533; Mohammadi, M., Al-Fuqaha, A., Guizani, M., Oh, J.S., Semisupervised deep reinforcement learning in support of IoT and smart city services (2018) IEEE Internet Things J, 5 (2), pp. 624-635; Papernot, N., Goodfellow, I., Sheatsley, R., Feinman, R., McDaniel, P., (2016) Cleverhans V1. 0.0: An Adversarial Machine Learning Library, , arXiv preprint arXiv; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., (2016) Practical Black-Box Attacks against Deep Learning Systems Using Adversarial Examples, , arXiv preprint arXiv; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) 2016 IEEE European Symposium on Security and Privacy (EuroS&P), pp. 372-387. , IEEE; Pattanaik, A., Tang, Z., Liu, S., Bommannan, G., Chowdhary, G., (2017) Robust Deep Reinforcement Learning with Adversarial Attacks, , arXiv preprint arXiv; Plappert, M., Houthooft, R., Dhariwal, P., Sidor, S., Chen, R.Y., Chen, X., Asfour, T., Andrychowicz, M., (2017) Parameter Space Noise for Exploration, , arXiv preprint arXiv; Silver, D., Hassabis, D., Alphago: Mastering the ancient game of go with machine learning (2016) Research Blog; Sutton, R.S., Barto, A.G., (1998) Reinforcement Learning: An Introduction, , MIT Press, Cambridge; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint arXiv; Zhang, T., Kahn, G., Levine, S., Abbeel, P., Learning deep control policies for autonomous aerial vehicles with mpc-guided policy search (2016) 2016 IEEE International Conference on Robotics and Automation (ICRA), pp. 528-535. , IEEE; Zhu, Y., Mottaghi, R., Kolve, E., Lim, J.J., Gupta, A., Fei-Fei, L., Farhadi, A., Target-driven visual navigation in indoor scenes using deep reinforcement learning (2017) 2017 IEEE International Conference on Robotics and Automation (ICRA), pp. 3357-3364. , IEEE","Behzadan, V.; Kansas State UniversityUnited States; email: behzadan@ksu.edu","Bitsch F.Skavhaug A.Gallina B.Schoitsch E.","","Springer Verlag","Workshops: ASSURE, DECSoS, SASSUR, STRIVE, and WAISE 2018  co-located with 37th International Conference on Computer Safety, Reliability and Security, SAFECOMP 2018","18 September 2018 through 21 September 2018",,218049,03029743,9783319992280,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85053879955
"Rosenberg I., Shabtai A., Rokach L., Elovici Y.","57191409772;17435550700;9276243500;6602317815;","Generic black-box end-to-end attack against state of the art API call based malware classifiers",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11050 LNCS",,,"490","510",,46,"10.1007/978-3-030-00470-5_23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053870606&doi=10.1007%2f978-3-030-00470-5_23&partnerID=40&md5=5edb4703c0bada3de6f59e5c535914f4","Software and Information Systems Engineering Department, Ben Gurion University, Beersheba, Israel","Rosenberg, I., Software and Information Systems Engineering Department, Ben Gurion University, Beersheba, Israel; Shabtai, A., Software and Information Systems Engineering Department, Ben Gurion University, Beersheba, Israel; Rokach, L., Software and Information Systems Engineering Department, Ben Gurion University, Beersheba, Israel; Elovici, Y., Software and Information Systems Engineering Department, Ben Gurion University, Beersheba, Israel","In this paper, we present a black-box attack against API call based machine learning malware classifiers, focusing on generating adversarial sequences combining API calls and static features (e.g., printable strings) that will be misclassified by the classifier without affecting the malware functionality. We show that this attack is effective against many classifiers due to the transferability principle between RNN variants, feed forward DNNs, and traditional machine learning classifiers such as SVM. We also implement GADGET, a software framework to convert any malware binary to a binary undetected by malware classifiers, using the proposed attack, without access to the malware source code. © Springer Nature Switzerland AG 2018.","Adversarial attacks; Deep neural networks; Dynamic analysis; Malware classification; Transferability","Artificial intelligence; Computer crime; Computer programming; Deep neural networks; Dynamic analysis; Adversarial attacks; Feed forward; Malware classifications; Software frameworks; Source codes; State of the art; Static features; Transferability; Malware",,,,,"Arjovsky, M., Bottou, L., (2017) Towards Principled Methods for Training Generative Adversarial Networks, , ICLR; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE S&P; Chen, P.Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.J., Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models (2017) ACM Workshop on Artificial Intelligence and Security; Goodfellow, I.J., Shlens, J., Szegedy, C., (2015) Explaining and Harnessing Adversarial Examples, , ICLR; Grosse, K., Papernot, N., Manoharan, P., Backes, M., McDaniel, P., Adversarial examples for malware detection (2017) ESORICS 2017. LNCS, 10493, pp. 62-79. , https://doi.org/10.1007/978-3-319-66399-9_4, Foley, S.N., Gollmann, D., Snekkenes, E, Springer, Cham; Hu, W., Tan, Y., (2017) Generating Adversarial Malware Examples for Black-Box Attacks Based on GAN; Hu, W., Tan, Y., (2017) Black-Box Attacks against RNN Based Malware Detection Algorithms; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I.P., Tygar, J.D., Adversarial machine learning (2011) ACM Workshop on Security and Artificial Intelligence; Huang, W., Stokes, J.W., MtNet: A multi-task neural network for dynamic malware classification (2016) DIMVA 2016. LNCS, 9721, pp. 399-418. , https://doi.org/10.1007/978-3-319-40667-1_20, Caballero, J., Zurutuza, U., Rodríguez, R.J. (eds.), Springer, Cham; Papernot, N., McDaniel, P., Jha, S.H., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) IEEE European Symposium on Security and Privacy; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) ASIA CCS; Papernot, N., McDaniel, P., Swami, A., Harang, R., Crafting adversarial input sequences for recurrent neural networks (2016) IEEE MILCOM; Pascanu, R., Stokes, J.W., Sanossian, H., Marinescu, M., Thomas, A., Malware classification with recurrent networks (2015) IEEE ICASSP; Rieck, K., Trinius, P., Willems, C., Holz, T., Automatic analysis of malware behavior using machine learning (2011) J. Comput. Secur., 19, pp. 639-668; Rosenberg, I., Gudes, E., Bypassing system calls-based intrusion detection systems (2016) Concurr. Comput.: Pract. Exp.; Rosenberg, I., Sicard, G., David, E.O., DeepAPT: Nation-state APT attribution using end-to-end deep neural networks (2017) ICANN 2017. LNCS, 10614, pp. 91-99. , https://doi.org/10.1007/978-3-319-68612-7_11, Lintas, A., Rovetta, S., Verschure, P.F.M.J., Villa, A.E.P. (eds.), Springer, Cham; Rosenberg, I., Shabtai, A., Rokach, L., Elovici, Y., (2018) Low Resource Black-Box End-To-End Attack against State of the Art API Call Based Malware Classifiers; Szegedy, C., (2014) Intriguing Properties of Neural Networks, , ICLR; Tandon, G., Chan, P.K., On the learning of system call attributes for host-based anomaly detection (2006) Int. J. Artif. Intell. Tools, 15, pp. 875-892; Trinius, P., Willems, C., Holz, T., Rieck, K., (2010) A Malware Instruction Set for Behavior-Based Analysis, , Sicherheit; Wagner, D., Soto, P., Mimicry attacks on host-based intrusion detection systems (2002) ACM CCS","Rosenberg, I.; Software and Information Systems Engineering Department, Israel; email: ishairos@post.bgu.ac.il","Bailey M.Ioannidis S.Stamatogiannakis M.Holz T.","","Springer Verlag","21st International Symposium on Research in Attacks, Intrusions and Defenses, RAID 2018","10 September 2018 through 12 September 2018",,218149,03029743,9783030004699,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85053870606
"Zoto E., Kowalski S., Frantz C., Lopez-Rojas E., Katt B.","57202435903;24756026500;54903301000;55913449600;25824984500;","A pilot study in cyber security education using cyberAIMs: A simulation-based experiment",2018,"IFIP Advances in Information and Communication Technology","531",,,"40","54",,1,"10.1007/978-3-319-99734-6_4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053867653&doi=10.1007%2f978-3-319-99734-6_4&partnerID=40&md5=22c939cd55e60ae8c771542e5d7adb93","Norwegian University of Science and Technology (NTNU), Gjøvik, Norway","Zoto, E., Norwegian University of Science and Technology (NTNU), Gjøvik, Norway; Kowalski, S., Norwegian University of Science and Technology (NTNU), Gjøvik, Norway; Frantz, C., Norwegian University of Science and Technology (NTNU), Gjøvik, Norway; Lopez-Rojas, E., Norwegian University of Science and Technology (NTNU), Gjøvik, Norway; Katt, B., Norwegian University of Science and Technology (NTNU), Gjøvik, Norway","We hardly pass any day without hearing of a new cyber attack. The recent ever-increasing occurrence of such attacks has given to researchers, practitioners and others an opportunity to raise awareness and train staff from the public and private institutions, as well as other people within the society, about the evolving nature of cyberspace threats. As a first step in this process, we aim to present main findings from a pilot study conducted with a target group of Master students with diverse backgrounds and knowledge about cyber security practices. The study was done using an agent-based simulation tool, CyberAIMs, as the core component of the experiment. Students were involved in a pre-test/post-test study in order to assess the probable change in their thinking process after using CyberAIMs. A scenario created from a real cyber case was additionally used to get the participants accustomed to the tool. The experiment is still in progress, while preliminary data indicate that there is a shift in students’ perspective on the most relevant attributes affecting defense agents’ performance, results that could be related to both adversarial and systems thinking processes. © IFIP International Federation for Information Processing 2018.","Adversarial thinking; Agent-based simulation; Cyber security; Systems thinking; Teaching; Training","Audition; Network security; Personnel training; System theory; Teaching; Adversarial thinking; Agent based simulation; Cyber security; Cyber-security educations; Private institutions; Systems thinking; Systems Thinking process; Thinking process; Students",,,,,"Ablon, L., Libicki, M.C., Golay, A.A., (2014) Markets for Cybercrime Tools and Stolen Data: hackers’ Bazaar, , Rand Corporation; (2013) ACM: Computer Science Curricula 2013 Curriculum Guidelines for Undergraduate Degree Programs in Computer Science, , New York, NY, USA; Anne Bardoel, E., Haslett, T., Success to the successful: The use of systems thinking tools in teaching OB (2004) Organ. Manag. J., 1 (2), pp. 112-124; Bologna, J., Momm’s (Motivations, opportunities, methods, means)-a taxonomy for computer related employee theft (1981) Assets Prot, 6 (3), pp. 33-36; Brahima, S., (2017) Global Cybersecurity Index 2017. International Telecommunication Union (ITU), pp. 1-77; Goodwin, J.S., Franklin, S.G., The beer distribution game: Using simulation to teach systems thinking (1994) J. Manag. Dev., 13 (8), pp. 7-15; Hamman, S.T., Hopkinson, K.M., Markham, R.L., Chaplik, A.M., Metzler, G.E., Teaching game theory to improve adversarial thinking in cybersecurity students (2017) IEEE Trans. Educ., 60 (3), pp. 205-211; (2017) Joint Task Force on Cybersecurity Education: Cybersecurity Curricula 2017-Curriculum Guidelines for Post-Secondary Degree Programs in Cybersecurity-Csec2017 V. 0.95 Draft, , Technical report, November; Pastor, V., Díaz, G., Castro, M., State-of-the-art simulation systems for information security education, training and awareness (2010) 2010 IEEE Education Engineering (EDUCON), pp. 1907-1916. , IEEE; (2016) Ponemon Institute: Flipping the Economics of Attacks, , Technical report, January; Rogers, R.W., A protection motivation theory of fear appeals and attitude change1 (1975) J. Psychol., 91 (1), pp. 93-114; Schneider, F.B., Cybersecurity education in universities (2013) IEEE Secur. Priv., 11 (4), pp. 3-4","Zoto, E.; Norwegian University of Science and Technology (NTNU)Norway; email: erjon.zoto@ntnu.no","Theocharidou M.Drevin L.",,"Springer New York LLC","11th World Conference on Information Security Education, WISE 2018 Held at the 24th IFIP World Computer Congress, WCC 2018","18 September 2018 through 20 September 2018",,218259,18684238,9783319997339,,,"English","IFIP Advances in Information and Communication Technology",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85053867653
[No author name available],[No author id available],"8th IAPR TC3 workshop on Artificial Neural Networks for Pattern Recognition, ANNPR 2018",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11081 LNAI",,,"","",406,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053626048&partnerID=40&md5=f3c37bdec11884c2dc8641746bc4c8ab",,"","The proceedings contain 31 papers. The special focus in this conference is on Artificial Neural Networks for Pattern Recognition. The topics include: A κ-nearest neighbor based algorithm for multi-instance multi-label active learning; manifold learning regression with non-stationary kernels; f-Measure Curves for Visualizing Classifier Performance with Imbalanced Data; maximum-likelihood estimation of neural mixture densities: model, algorithm, and preliminary experimental evaluation; generating Bounding Box Supervision for Semantic Segmentation with Deep Learning; inductive–transductive learning with graph neural networks; bounded rational decision-making with adaptive neural network priors; feature selection with rényi min-entropy; extracting gamma-ray information from images with convolutional neural network methods on simulated cherenkov telescope array data; deep learning in the wild; automatic hand sign recognition: Identify unusuality through latent cognizance; cascade of ordinal classification and local regression for audio-based affect estimation; combining classical and deep learning methods for twitter sentiment analysis; PHoG features and kullback-leibler divergence based ranking method for handwriting recognition; pattern recognition pipeline for neuroimaging data; anomaly pattern recognition with privileged information for sensor fault detection; Capturing suprasegmental features of a voice with RNNs for improved speaker clustering; Trace and detect adversarial attacks on CNNs using feature response maps; Video and audio data extraction for retrieval, ranking and recapitulation (VADER3); ATM protection using embedded deep learning solutions; effect of equality constraints to unconstrained large margin distribution machines; object detection in floor plan images; historical handwritten document segmentation by using a weighted loss; DLL: A fast deep neural network library; selecting features from foreign classes.",,,,,,,,,"Pancioni L.Trentin E.Schwenker F.","","Springer Verlag","8th IAPR TC3 workshop on Artificial Neural Networks for Pattern Recognition, ANNPR 2018","19 September 2018 through 21 September 2018",,217799,03029743,9783319999777,,,"English","Lect. Notes Comput. Sci.",Conference Review,"Final","",Scopus,2-s2.0-85053626048
"Amirian M., Schwenker F., Stadelmann T.","55957074500;6701325661;16069451700;","Trace and detect adversarial attacks on CNNs using feature response maps",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11081 LNAI",,,"346","358",,4,"10.1007/978-3-319-99978-4_27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053596493&doi=10.1007%2f978-3-319-99978-4_27&partnerID=40&md5=1e8df909c6c92289aa0d24cce4be19e0","ZHAW Datalab & School of Engineering, Winterthur, Switzerland; Institute of Neural Information Processing, Ulm University, Ulm, Germany","Amirian, M., ZHAW Datalab & School of Engineering, Winterthur, Switzerland, Institute of Neural Information Processing, Ulm University, Ulm, Germany; Schwenker, F., Institute of Neural Information Processing, Ulm University, Ulm, Germany; Stadelmann, T., ZHAW Datalab & School of Engineering, Winterthur, Switzerland","The existence of adversarial attacks on convolutional neural networks (CNN) questions the fitness of such models for serious applications. The attacks manipulate an input image such that misclassification is evoked while still looking normal to a human observer—they are thus not easily detectable. In a different context, backpropagated activations of CNN hidden layers—“feature responses” to a given input—have been helpful to visualize for a human “debugger” what the CNN “looks at” while computing its output. In this work, we propose a novel detection method for adversarial examples to prevent attacks. We do so by tracking adversarial perturbations in feature responses, allowing for automatic detection using average local spatial entropy. The method does not alter the original network architecture and is fully human-interpretable. Experiments confirm the validity of our approach for state-of-the-art attacks on large-scale models trained on ImageNet. © Springer Nature Switzerland AG 2018.","Diagnostic; Feature visualization; Model interpretability","Network architecture; Neural networks; Automatic Detection; Convolutional Neural Networks (CNN); Detection methods; Diagnostic; Interpretability; Large-scale models; Misclassifications; State of the art; Feature extraction",,,,,"Akhtar, N., Mian, A., (2018) Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey; Bojarski, M., (2016) End to End Learning for Self-Driving Cars; Brendel, W., Rauber, J., Bethge, M., (2017) Decision-Based Adversarial Attacks: Reliable Attacks against Black-Box Machine Learning Models; Chanwimaluang, T., Fan, G., An efficient blood vessel detection algorithm for retinal images using local entropy thresholding (2003) International Symposium on Circuits and Systems (ISCAS), 5; Cireşan, D., Meier, U., Masci, J., Schmidhuber, J., A committee of neural networks for traffic sign classification (2011) IJCNN, pp. 1918-1921. , IEEE; Cisse, M., Adi, Y., Neverova, N., Keshet, J., (2017) Houdini: Fooling Deep Structured Prediction Models; Dumoulin, V., Visin, F., (2016) A Guide to Convolution Arithmetic for Deep Learning; Erhan, D., Bengio, Y., Courville, A., Vincent, P., Visualizing higher-layer features of a deep network (2009) Univ. Montr., 1341 (3), p. 1; Feinman, R., Curtin, R.R., Shintre, S., Gardner, A.B., (2017) Detecting Adversarial Samples from Artifacts; Fletcher, R., (2013) Practical Methods of Optimization, , Wiley, Hoboken; Gal, Y., Ghahramani, Z., Dropout as a Bayesian approximation: Representing model uncertainty in deep learning (2016) ICML; Goodfellow, I.J., Shlens, J., Szegedy, C., (2015) Explaining and Harnessing Adversarial Examples, , ICLR; Goodman, B., Flaxman, S., EU regulations on algorithmic decision-making and a “right to explanation” (2016) In: ICML Workshop on Human Interpretability in Machine Learning (WHI); Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P., (2017) On the (Statistical) Detection of Adversarial Examples; Gunning, D., Explainable Artificial Intelligence (XAI) (2017) Defense Advanced Research Projects Agency (DARPA; Krause, J., Stark, M., Deng, J., Fei-Fei, L., 3D object representations for fine-grained categorization (2013) ICCV Workshops; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images; Kurakin, A., Goodfellow, I., Bengio, S., Adversarial examples in the physical world (2016) ICRL Workshop Track; Lecun, Y., Backpropagation applied to handwritten zip code recognition (1989) Neural Comput, 1 (4), pp. 541-551; Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324; Li, X., Li, F., (2016) Adversarial Examples Detection in Deep Networks with Convolutional Filter Statistics; Liang, B., Li, H., Su, M., Li, X., Shi, W., Wang, X., (2017) Detecting Adversarial Examples in Deep Networks with Adaptive Noise Reduction; Lu, J., Issaranon, T., Forsyth, D., (2017) Safetynet: Detecting and Rejecting Adversarial Examples Robustly; Meng, D., Chen, H., Magnet: A two-pronged defense against adversarial examples (2017) ACM SIGSAC Conference on Computer and Communications Security; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., On detecting adversarial perturbations (2017) ICLR; Metzen, J.H., Kumar, M.C., Brox, T., Fischer, V., (2017) Universal Adversarial Perturbations against Semantic Image Segmentation; Moosavi-Dezfooli, S.M., Fawzi, A., Fawzi, O., Frossard, P., (2017) Universal Adversarial Perturbations; Moosavi Dezfooli, S.M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) CVPR; Olah, C., Mordvintsev, A., Schubert, L., Feature visualization (2017) Distill, , https://doi.org/10.23915/distill.00007; Olah, C., (2018) The Building Blocks of Interpretability. Distill, , https://doi.org/10.23915/distill.00010; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-Box Attacks Using Adversarial Samples; Parkhi, O.M., Vedaldi, A., Zisserman, A., Jawahar, C., Cats and dogs (2012) CVPR; Rauber, J., Brendel, W., Bethge, M., (2017) Foolbox V0.8.0: A Python Toolbox to Benchmark the Robustness of Machine Learning Models; Russakovsky, O., Imagenet large scale visual recognition challenge (2015) Int. J. Comput. Vis. (IJCV), 115 (3), pp. 211-252. , https://doi.org/10.1007/s11263-015-0816-y; Schmidhuber, J., Deep learning in neural networks: An overview (2015) Neural Netw, 61, pp. 85-117; Simonyan, K., Zisserman, A., (2015) Very Deep Convolutional Networks for Large-Scale Image Recognition, , ICLR; Springenberg, J.T., Dosovitskiy, A., Brox, T., Riedmiller, M., (2014) Striving for Simplicity: The All Convolutional Net; Stadelmann, T., Tolkachev, V., Sick, B., Stampfli, J., Dürr, O., Beyond imagenet-deep learning in industrial practice (2018) Applied Data Science-Lessons Learned for the Data-Driven Business. Springer, , https://stdm.github.io/data-science-book/, Braschler, M., Stadelmann, T., Stockinger, K; Storn, R., Price, K., Differential evolution-a simple and efficient heuristic for global optimization over continuous spaces (1997) J. Glob. Optim., 11 (4), pp. 341-359; Su, J., Vargas, D.V., Kouichi, S., (2017) One Pixel Attack for Fooling Deep Neural Networks; Szegedy, C., (2014) Intriguing Properties of Neural Networks, , ICLR; Vellido, A., Martín-Guerrero, J.D., Lisboa, P.J., Making machine learning models interpretable (2012) ESANN, 12, pp. 163-172; Xu, W., Evans, D., Qi, Y., (2018) Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks; Xu, X., Chen, X., Liu, C., Rohrbach, A., Darell, T., Song, D., (2017) Can You Fool AI with Adversarial Examples on a Visual Turing Test?; Zeiler, M.D., Fergus, R., Visualizing and understanding convolutional networks (2014) ECCV 2014. LNCS, 8689, pp. 818-833. , https://doi.org/10.1007/978-3-319-10590-1_53, Fleet, D., Pajdla, T., Schiele, B., Tuytelaars, T. (eds.), Springer, Cham; Zhu, J., Liao, S., Yi, D., Lei, Z., Li, S.Z., Multi-label CNN based pedestrian attribute learning for soft biometrics (2015) International Conference on Biometrics (ICB). IEEE","Amirian, M.; ZHAW Datalab & School of EngineeringSwitzerland; email: amir@zhaw.ch","Pancioni L.Trentin E.Schwenker F.","","Springer Verlag","8th IAPR TC3 workshop on Artificial Neural Networks for Pattern Recognition, ANNPR 2018","19 September 2018 through 21 September 2018",,217799,03029743,9783319999777,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85053596493
"Oregi I., Del Ser J., Perez A., Lozano J.A.","57193268641;9737598300;14049225300;35473051700;","Adversarial sample crafting for time series classification with elastic similarity measures",2018,"Studies in Computational Intelligence","798",,,"26","39",,5,"10.1007/978-3-319-99626-4_3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053457377&doi=10.1007%2f978-3-319-99626-4_3&partnerID=40&md5=d05b4c982549ec8734a752680f2f7d66","TECNALIA, Derio, Bizkaia  48160, Spain; TECNALIA, University of the Basque Country (UPV/EHU), Leioa, Bizkaia, Spain; Basque Center for Applied Mathematics (BCAM), Bilbao, Bizkaia  48009, Spain; University of the Basque Country (UPV/EHU), Leioa, Spain","Oregi, I., TECNALIA, Derio, Bizkaia  48160, Spain; Del Ser, J., TECNALIA, University of the Basque Country (UPV/EHU), Leioa, Bizkaia, Spain, Basque Center for Applied Mathematics (BCAM), Bilbao, Bizkaia  48009, Spain; Perez, A., Basque Center for Applied Mathematics (BCAM), Bilbao, Bizkaia  48009, Spain; Lozano, J.A., Basque Center for Applied Mathematics (BCAM), Bilbao, Bizkaia  48009, Spain, University of the Basque Country (UPV/EHU), Leioa, Spain","Adversarial Machine Learning (AML) refers to the study of the robustness of classification models when processing data samples that have been intelligently manipulated to confuse them. Procedures aimed at furnishing such confusing samples exploit concrete vulnerabilities of the learning algorithm of the model at hand, by which perturbations can make a given data instance to be misclassified. In this context, the literature has so far gravitated on different AML strategies to modify data instances for diverse learning algorithms, in most cases for image classification. This work builds upon this background literature to address AML for distance based time series classifiers (e.g., nearest neighbors), in which attacks (i.e. modifications of the samples to be classified by the model) must be intelligently devised by taking into account the measure of similarity used to compare time series. In particular, we propose different attack strategies relying on guided perturbations of the input time series based on gradient information provided by a smoothed version of the distance based model to be attacked. Furthermore, we formulate the AML sample crafting process as an optimization problem driven by the Pareto trade-off between (1) a measure of distortion of the input sample with respect to its original version; and (2) the probability of the crafted sample to confuse the model. In this case, this formulated problem is efficiently tackled by using multi-objective heuristic solvers. Several experiments are discussed so as to assess whether the crafted adversarial time series succeed when confusing the distance based model under target. © 2018, Springer Nature Switzerland AG.","Adversarial machine learning; Elastic similarity measures; Time series classification",,,,,,"Akhtar, N., Mian, A., (2018) Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey; Berndt, D.J., Clifford, J., Using dynamic time warping to find patterns in time series (1994) Workshop on Knowledge Discovery in Databases, pp. 359-370. , Seattle, WA; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndić, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 387-402. , Springer; Chen, Y., Keogh, E., Hu, B., Begum, N., Bagnall, A., Mueen, A., Batista, G., (2015) The UCR Time Series Classification Archive, , www.cs.ucr.edu/; Deb, K., Pratap, A., Agarwal, S., Meyarivan, T., A fast and elitist multiobjective genetic algorithm: NSGA-II (2002) IEEE Trans. Evol. Comput., 6 (2), pp. 182-197; Ding, H., Trajcevski, G., Scheuermann, P., Wang, X., Keogh, E., Querying and mining of time series data: Experimental comparison of representations and distance measures (2008) Proc. VLDB Endow., 1 (2), pp. 1542-1552; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Ten Holt, G.A., Reinders, M.J., Hendriks, E., Multi-dimensional dynamic time warping for gesture recognition (2007) Conference of the Advanced School for Computing and Imaging, 300, p. 1; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I., Tygar, J., Adversarial machinelearning (2011) Proceedings of the 4th ACM Workshop on Security and Artificial Intelligence, pp. 43-58. , ACM; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I., Tygar, J., Adversarial machinelearning (2011) Proceedings of the 4th ACM Workshop on Security and Artificial Intelligence, pp. 43-58. , ACM; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World; Lana, I., Del Ser, J., Velez, M., Vlahogianni, E.I., Road traffic forecasting: Recent advances and new challenges (2018) Proc. VLDB Endow., 10 (2), pp. 93-109; Lines, J., Bagnall, A., Time series classification with ensembles of elastic distance measures (2015) Data Min. Knowl. Discov., 29 (3), pp. 565-592; Miyato, T., Maeda, S., Koyama, M., Ishii, S., (2017) Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning; Molina-Solana, M., Ros, M., Ruiz, M.D., Gómez-Romero, J., Martín-Bautista, M.J., Data science for building energy management: A review (2017) Renew. Sustain. Energy Rev., 70, pp. 598-609; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-Box Attacks Using Adversarial Samples; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) 2016 IEEE Symposium on Security and Privacy (SP), pp. 582-597. , IEEE; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, pp. 506-519. , ACM; Sakoe, H., Chiba, S., Dynamic programming algorithm optimization for spoken word recognition (1978) IEEE Trans. Acoust. Speech Signal Process., 26 (1), pp. 43-49; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks; Villar-Rodriguez, E., Del Ser, J., Oregi, I., Bilbao, M.N., Gil-Lopez, S., Detection of non-technical losses in smart meter data based on load curve profiling and time series analysis (2017) Energy, 137, pp. 118-128","Oregi, I.; TECNALIASpain; email: izaskun.oregui@tecnalia.com",,,"Springer Verlag",,,,,1860949X,,,,"English","Stud. Comput. Intell.",Book Chapter,"Final","",Scopus,2-s2.0-85053457377
"Pitropakis N., Panaousis E., Giannakoulias A., Kalpakis G., Rodriguez R.D., Sarigiannidis P.","55819807400;34877407700;57203764047;57188565581;57203760606;12445587500;","An enhanced cyber attack attribution framework",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11033 LNCS",,,"213","228",,8,"10.1007/978-3-319-98385-1_15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052902303&doi=10.1007%2f978-3-319-98385-1_15&partnerID=40&md5=d2bba636f21aab4472624565ccdfc2e6","Edinburgh Napier University, Edinburgh, United Kingdom; Surrey Centre for Cyber Security, University of Surrey, Guildford, United Kingdom; European Dynamics SA, Athens, Greece; Information Technologies Institute, Centre for Research and Technology Hellas, Thermi, Greece; Atos Spain SA, Madrid, Spain; University of Western Macedonia, Kozani, Greece","Pitropakis, N., Edinburgh Napier University, Edinburgh, United Kingdom; Panaousis, E., Surrey Centre for Cyber Security, University of Surrey, Guildford, United Kingdom; Giannakoulias, A., European Dynamics SA, Athens, Greece; Kalpakis, G., Information Technologies Institute, Centre for Research and Technology Hellas, Thermi, Greece; Rodriguez, R.D., Atos Spain SA, Madrid, Spain; Sarigiannidis, P., University of Western Macedonia, Kozani, Greece","Advanced Persistent Threats (APTs) are considered as the threats that are the most challenging to detect and defend against. As APTs use sophisticated attack methods, cyber situational awareness and especially cyber attack attribution are necessary for the preservation of security of cyber infrastructures. Recent challenges faced by organizations in the light of APT proliferation are related to the: collection of APT knowledge; monitoring of APT activities; detection and classification of APTs; and correlation of all these to result in the attribution of the malicious parties that orchestrated an attack. We propose the Enhanced Cyber Attack Attribution (NEON) Framework, which performs attribution of malicious parties behind APT campaigns. NEON is designed to increase societal resiliency to APTs. NEON combines the following functionalities: (i) data collection from APT campaigns; (ii) collection of publicly available data from social media; (iii) honeypots and virtual personas; (iv) network and system behavioural monitoring; (v) incident detection and classification; (vi) network forensics; (vii) dynamic response based on game theory; and (viii) adversarial machine learning; all designed with privacy considerations in mind. © Springer Nature Switzerland AG 2018.",,"Crime; Digital forensics; Game theory; Learning systems; Neon; Network security; Attack methods; Cyber infrastructures; Cyber-attacks; Data collection; Honeypots; Incident detection; Situational awareness; Social media; Computer crime",,,,,"Farinholt, B., To catch a ratter: Monitoring the behavior of amateur Dark-Comet RAT operators in the wild (2017) IEEE Symposium on Security and Privacy, pp. 770-787. , IEEE; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I., Tygar, J., Adversarial machine learning (2011) 4Th ACM Workshop on Security and Artificial Intelligence, pp. 43-58. , ACM; Pfleeger, S.L., Sasse, M.A., Furnham, A., From weakest link to security hero: Transforming staff security behavior (2014) J. Homel. Secur. Emerg. Manag., 11 (4), pp. 489-510; Langner, R., Stuxnet: Dissecting a cyberwarfare weapon (2011) IEEE Secur. Priv., 9 (3), pp. 49-51; (2018) Kaspersky: Targeted Cyber Attacks Logbook, , https://apt.securelist.com/, Accessed 09 Feb; Symantec: Advanced Persistent Threats: A Symantec Perspective, , https://www.symantec.com/content/en/us/enterprise/whitepapers/b-advancedpersistentthreatsWP21215957.en-us.pdf, Accessed 09 Feb 2018; https://www.itu.int/en/ITU-D/Cybersecurity/Documents/2H2013TargetedAttackCampaignReport.pdf, Accessed 09 Feb 2018; King, S., (2018) Apt (Advanced Persistent Threat)-What You Need to Know, , https://www.netswitch.net/apt-advanced-persistent-threat-what-you-need-to-know/, Feb; Cavelty, M.D., Cyber-security and Threat Politics: US Efforts to Secure the Information Age (2007) Routledge, Abingdon; Choo, K.K.R., The cyber threat landscape: Challenges and future research directions (2011) Comput. Secur., 30 (8), pp. 719-731; Giura, P., Wang, W., A context-based detection framework for advanced persistent threats (2012) International Conference on Cyber Security, pp. 69-74. , IEEE; Virvilis, N., Gritzalis, D., The big four-what we did wrong in advanced persistent threat detection? (2013) 8Th International Conference on Availability, Reliability and Security, pp. 248-254. , IEEE; Jasek, R., Kolarik, M., Vymola, T., APT detection system using honeypots (2013) 13Th International Conference on Applied Informatics and Communications, pp. 25-29; Chen, P., Desmet, L., Huygens, C., A study on advanced persistent threats (2014) CMS 2014. LNCS, 8735, pp. 63-72. , https://doi.org/10.1007/978-3-662-44885-4_5, Decker, B., Zúquete, A. (eds.), Springer, Heidelberg; Friedberg, I., Skopik, F., Settanni, G., Fiedler, R., Combating advanced persistent threats: From network event correlation to incident detection (2015) Comput. Secur., 48, pp. 35-57; Marchetti, M., Pierazzi, F., Colajanni, M., Guido, A., Analysis of high volumes of network traffic for advanced persistent threat detection (2016) Comput. Netw., 109, pp. 127-141; Hu, P., Li, H., Fu, H., Cansever, D., Mohapatra, P., Dynamic defense strategy against advanced persistent threat with insiders (2015) IEEE Conference on Computer Communications, pp. 747-755. , IEEE; Zhu, Q., Rass, S., On multi-phase and multi-stage game-theoretic modeling of advanced persistent threats (2018) IEEE Access, 6, pp. 13958-13971; Bhatt, P., Yano, E.T., Gustavsson, P., Towards a framework to detect multi-stage advanced persistent threats attacks (2014) 2014 IEEE 8Th International Symposium on Service Oriented System Engineering (SOSE), pp. 390-395. , IEEE; Giura, P., Wang, W., Using large scale distributed computing to unveil advanced persistent threats (2012) Sci. J., 1 (3), pp. 93-105; Wheeler, D.A., Larsen, G.N., (2003) Techniques for Cyber Attack Attribution, , Technical report, Institute for Defense Analyses, Alexandria, VA; Hunker, J., Hutchinson, B., Margulies, J., (2008) Role and Challenges for Sufficient Cyberattack Attribution. Institute for Information Infrastructure Protection, pp. 5-10; Bou-Harb, E., Lucia, W., Forti, N., Weerakkody, S., Ghani, N., Sinopoli, B., Cyber meets control: A novel federated approach for resilient CPS leveraging real cyber threat intelligence (2017) IEEE Commun. Mag., 55 (5), pp. 198-204; Qamar, S., Anwar, Z., Rahman, M.A., Al-Shaer, E., Chu, B.T., Data-driven analytics for cyber-threat intelligence and information sharing (2017) Comput. Secur., 67, pp. 35-58; (2018) DARPA: Enhanced Attribution Federal Project, , https://govtribe.com/project/enhanced-attribution, Feb; Kintis, P., Hiding in plain sight: A longitudinal study of combosquatting abuse (2017) ACM Conference on Computer and Communications Security, pp. 569-586. , ACM; Keromytis, A., Enhanced Attribution, , https://www.enisa.europa.eu/events/cti-eu-event/cti-eu-event-presentations/enhanced-attribution/, Accessed 09 Feb 2018; David Westcott, K.B., Aptnotes, , https://github.com/aptnotes/data, Accessed 09 Feb 2018; Meusel, R., Mika, P., Blanco, R., Focused crawling for structured data (2014) 23Rd ACM International Conference on Conference on Information and Knowledge Management, pp. 1039-1048. , ACM; Triguero, I., García, S., Herrera, F., Self-labeled techniques for semi-supervised learning: Taxonomy, software and empirical study (2015) Knowl. Inf. Syst., 42 (2), pp. 245-284; Olston, C., Najork, M., Web crawling (2010) Found. Trends Inf. Retr., 4 (3), pp. 175-246; Cimiano, P., Ontology learning from text (2006) Ontology Learning and Population from Text: Algorithms, Evaluation and Applications, pp. 19-34. , https://doi.org/10.1007/978-0-387-39252-3_3, Cimiano, P. (ed.), Springer, Boston; Gialampoukidis, I., Moumtzidou, A., Tsikrika, T., Vrochidis, S., Kompatsiaris, I., Retrieval of multimedia objects by fusing multiple modalities (2016) ACM on International Conference on Multimedia Retrieval, pp. 359-362. , ACM; Pitropakis, N., Pikrakis, A., Lambrinoudakis, C., Behaviour reflects personality: Detecting co-residence attacks on Xen-based cloud environments (2015) Int. J. Inf. Secur., 14 (4), pp. 299-305; Davidoff, S., Ham, J., (2012) Network Forensics: Tracking Hackers through Cyberspace, 2014. , Prentice Hall, Upper Saddle River; Fielder, A., Panaousis, E., Malacaria, P., Hankin, C., Smeraldi, F., Decision support approaches for cyber security investment (2016) Decis. Support Syst., 86, pp. 13-23; Fielder, A., Panaousis, E., Malacaria, P., Hankin, C., Smeraldi, F., Game theory meets information security management (2014) SEC 2014. IAICT, 428, pp. 15-29. , https://doi.org/10.1007/978-3-642-55415-5_2, Cuppens-Boulahia, N., Cuppens, F., Jajodia, S., Abou El Kalam, A., Sans, T. (eds.), Springer, Heidelberg; Fielder, A., Konig, S., Panaousis, E., Schauer, S., Rass, S., (2017) Uncertainty in Cyber Security Investments, , arXiv preprint arXiv; Widmer, G., Kubat, M., Learning in the presence of concept drift and hidden contexts (1996) Mach. Learn., 23 (1), pp. 69-101; Nikhi, B., Giannetsos, T., Panaousis, E., Took, C.C., Unsupervised learning for trustworthy IoT (2018) IEEE International Conference on Fuzzy Systems, , FUZZ-IEEE","Pitropakis, N.; Edinburgh Napier UniversityUnited Kingdom; email: n.pitropakis@napier.ac.uk","Mouratidis H.Furnell S.Pernul G.",,"Springer Verlag","15th International Conference on Trust, Privacy, and Security in Digital Business, TrustBus 2018","5 September 2018 through 6 September 2018",,217289,03029743,9783319983844,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","",Scopus,2-s2.0-85052902303
"Horváth A., Egervári C.","55515333800;57203684637;","Detection of sticker based adversarial attacks",2018,"Proceedings of SPIE - The International Society for Optical Engineering","10806",,"108066Y","","",,,"10.1117/12.2503219","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052625164&doi=10.1117%2f12.2503219&partnerID=40&md5=b82ad0f6042e10189db5ab638b5419ac","Peter Pázmány Catholic University, Faculty of Information Technology and Bionics, Hungary","Horváth, A., Peter Pázmány Catholic University, Faculty of Information Technology and Bionics, Hungary; Egervári, C., Peter Pázmány Catholic University, Faculty of Information Technology and Bionics, Hungary","Adversarial examples revealed and important aspect of convolutional neural networks and are getting more and more attention in machine learning. It was shown that not only small perturbations, covering the whole image can be applied but also sticker based attacks, concentrated on small regions of the image can cause misclassification. Meanwhile the first type of attack is theoretical the later can be applied in practice and lead tomisclassification in image processing pipelines. In this paper we show a method how sticker based adversarial samples can be detected by calculating the responses of the neurons in the last layers and estimating the measure of region based classification consistency. © 2018 SPIE.",,"Learning systems; Neural networks; Pipeline processing systems; Classification consistency; Convolutional neural network; Image processing pipeline; Misclassifications; Region-based; Small perturbations; Small region; Image processing",,,,,"Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , Adversarial examples and the application of adverserial noise was shown in arXiv preprint; Kingma, D.P., Ba, J., (2014) Adam: A Method for Stochastic Optimization, , arXiv preprint; Lu, J., Sibai, H., Fabry, E., Forsyth, D., (2017) No Need to Worry About Adversarial Examples in Object Detection in Autonomous Vehicles, , https://arxiv.org/abs/1707.03501.g; Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Song, D., Kohno, T., Tramer, F., (2017) Note on Attacking Object Detectors with Adversarial Stickers, , cite arXiv preprint; Evtimov, I., Eykholt, K., Fernandes, E., Kohno, T., Li, B., Prakash, A., Song, D., (2017) Robust Physical-World Attacks on Machine Learning Models, , arXiv preprint; Yuan, X., He, P., Zhu, Q., Bhat, R.R., Li, X., (2017) Adversarial Examples: Attacks and Defenses for Deep Learning, , arXiv preprint; Lecun, Y., Cortes, C., Christopher, B., (2016) The MNIST Database of Handwritten Digits, , yann.lecun.com/exdb/mnist, JC; Houben, S., Stallkamp, J., Salmen, J., Schlipsing, M., Ige, C., (2014) German Traffic Sign Benchmarks, , benchmark.ini.rub.de; Zeiler, M.D., Fergus, R., Visualizing and understanding convolutional networks (2014) European Conference on Computer Vision, pp. 818-833. , September. Springer, Cham",,"Hwang J.-N.Jiang X.","International Association of Computer Science and Information Technology;Shanghai Key Laboratory of Multidimensional Information Processing","SPIE","10th International Conference on Digital Image Processing, ICDIP 2018","11 May 2018 through 14 May 2018",,138746,0277786X,9781510621992,PSISD,,"English","Proc SPIE Int Soc Opt Eng",Conference Paper,"Final","",Scopus,2-s2.0-85052625164
"Marufu A.M.C., Kayem A.V.D.M., Wolthusen S.D.","57189311629;22734066800;55887434700;","The design and classification of cheating attacks on power marketing schemes in resource constrained smart micro-grids",2018,"Advances in Information Security","71",,,"103","144",,,"10.1007/978-3-319-91427-5_6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052612152&doi=10.1007%2f978-3-319-91427-5_6&partnerID=40&md5=64007245755a51ace73ff013c4273c47","Department of Computer Science, University of Cape Town, Cape Town, South Africa; Hasso-Plattner-Institute, Faculty of Digital Engineering, University of Potsdam, Potsdam, Germany; Department of Mathematics and Information Security, Royal Holloway, University of London, Egham Surrey, United Kingdom; Norwegian Information Security Laboratory, Gjovik University College, Norwegian University of Science and Technology, Trondheim, Norway","Marufu, A.M.C., Department of Computer Science, University of Cape Town, Cape Town, South Africa; Kayem, A.V.D.M., Hasso-Plattner-Institute, Faculty of Digital Engineering, University of Potsdam, Potsdam, Germany; Wolthusen, S.D., Department of Mathematics and Information Security, Royal Holloway, University of London, Egham Surrey, United Kingdom, Norwegian Information Security Laboratory, Gjovik University College, Norwegian University of Science and Technology, Trondheim, Norway","In this chapter, we provide a framework to specify how cheating attacks can be conducted successfully on power marketing schemes in resource constrained smart micro-grids. This is an important problem because such cheating attacks can destabilise and in the worst case result in a breakdown of the micro-grid. We consider three aspects, in relation to modelling cheating attacks on power auctioning schemes. First, we aim to specify exactly how in spite of the resource constrained character of the micro-grid, cheating can be conducted successfully. Second, we consider how mitigations can be modelled to prevent cheating, and third, we discuss methods of maintaining grid stability and reliability even in the presence of cheating attacks. We use an Automated-Cheating-Attack (ACA) conception to build a taxonomy of cheating attacks based on the idea of adversarial acquisition of surplus energy. Adversarial acquisitions of surplus energy allow malicious users to pay less for access to more power than the quota allowed for the price paid. The impact on honest users, is the lack of an adequate supply of energy to meet power demand requests. We conclude with a discussion of the performance overhead of provoking, detecting, and mitigating such attacks efficiently. © Springer International Publishing AG, part of Springer Nature 2018.","Cheating attacks; Power auctioning; Smart micro-grids",,,,,,"Kayem, A., Meinel, C., Wolthusen, S.D., A smart micro-grid architecture for resource constrained environments (2017) In Proceedings of the 2017 IEEE 31St International Conference on Advanced Information Networking and Applications, AINA, (Taipeh, Taiwan), pp. 857-864. , IEEE, Mar; Weldehawaryat, G.K., Ambassa, P.L., Marufu, A.M.C., Wolthusen, S.D., Kayem, A., Decentralised scheduling of power consumption in micro-grids: Optimisation and security (2016) Security of Industrial Control Systems and Cyber-Physical Systems - Second International Workshop, Cybericps 2016, pp. 69-86. , Heraklion, Crete, Greece, September 26-30, 2016, Revised Selected Papers, vol. 10166 of Lecture Notes in Computer Science, (Heraklion, Greece), Springer, Sept; Ambassa, P.L., Kayem, A., Wolthusen, S., Meinel, C., Secure and reliable power consumption monitoring in untrustworthy micro-grids (2015) Future Network Systems and Security (R. Doss, S. Piramuthu, and W. ZHOU, Eds.), Vol. 523 of Communications in Computer and Information Science, pp. 166-180. , Springer International Publishing; Ambassa, P.L., Kayem, A., Wolthusen, S.D., Meinel, C., Secure and reliable power consumption monitoring in untrustworthy micro-grids (2015) International Conference on Future Network Systems and Security, pp. 166-180. , Springer; Marufu, A.M.C., Kayem, A., Wolthusen, S.D., A distributed continuous double auction framework for resource constrained microgrids (2015) Ritical Information Infrastructures Security - 10Th International Conference, CRITIS 2015, pp. 183-198. , Berlin, Germany, October 5-7, 2015, Revised Selected Papers, vol. 9578 of Lecture Notes in Computer Science, Springer; Marufu, A.M.C., Kayem, A., Wolthusen, S.D., Fault-tolerant distributed continuous double auctioning on computationally constrained microgrids (2016) Proceedings of the 2nd International Conference on Information Systems Security and Privacy, pp. 448-456. , ICISSP 2016, Rome, Italy, February 19-21, 2016, SCITEPRESS; Marufu, A.M.C., Kayem, A., Wolthusen, S.D., Power auctioning in resource constrained micro-grids: Cases of cheating (2016) 11Th International Conference on Critical Information Infrastructures Security, , SPRINGER; Marufu, A.M.C., Kayem, A., Wolthusen, S.D., Circumventing cheating on power auctioning in resource constrained micro-grids (2016) 2016 IEEE 18Th International Conference on High Performance Computing and Communications, pp. 1380-1387. , IEEE 14th International Conference on Smart City; IEEE 2nd International Conference on Data Science and Systems (HPCC/SmartCity/DSS), IEEE, Dec; Pálka, P., Radziszewska, W., Nahorski, Z., Balancing electric power in a microgrid via programmable agents auctions (2012) Control and Cybernetics, 41; Stánczak, J., Radziszewska, W., Nahorski, Z., Dynamic pricing and balancing mechanism for a microgrid electricity market (2015) Intelligent Systems’2014 - Proceedings of the 7th IEEE International Conference Intelligent Systems IS’2014, pp. 793-806. , September 24-26, 2014, Warsaw, Poland, Volume 2: Tools, Architectures, Systems, Applications, Springer; Tan, Z., (2007) Market-Based Grid Resource Allocation Using a Stable Continuous Double Auction, , PhD thesis, The University of Manchester; Izakian, H., Abraham, A., Ladani, B.T., An auction method for resource allocation in computational grids (2010) Future Generation Computer Systems, 26 (2), pp. 228-235; Sobe, A., Elmenreich, W., Smart microgrids: Overview and outlook (2013) Corr, , vol. abs/1304.3944; Smith, V.L., An experimental study of competitive market behavior (1962) The Journal of Political Economy, pp. 111-137; Preist, C., Van Tol, M., Adaptive agents in a persistent shout double auction (1998) Proceedings of the First International Conference on Information and Computation Economies, pp. 11-18. , ACM; Clearwater, S.H., Costanza, R., Dixon, M., Schroeder, B., Saving energy using marketbased control (1996) Market-Based Control: A Paradigm for Distributed Resource Allocation, pp. 253-273; Guttman, R.H., Maes, P., Chavez, A., Dreilinger, D., Results from a multi-agent electronic marketplace experiment (1997) Poster Proceedings of the Eighth European Workshop on Modeling Autonomous Agents in a Multi-Agent World (MAAMAW’97), pp. 86-98. , Citeseer; Ma, H., Leung, H.-F., An adaptive attitude bidding strategy for agents in continuous double auctions (2008) Electronic Commerce Research and Applications, 6 (4), pp. 383-398; Vytelingum, P., (2006) The Structure and Behaviour of the Continuous Double Auction, , PhD thesis, University of Southampton, UK; Nunna, H.K., Doolla, S., Multiagent-based distributed-energy-resource management for intelligent microgrids (2013) IEEE Transactions on Industrial Electronics, 60 (4), pp. 1678-1687; Nunna, H.K., Doolla, S., Energy management in microgrids using demand response and distributed storage-a multiagent approach (2013) IEEE Transactions on Power Delivery, 28 (2), pp. 939-947; Nunna, H.K., Saklani, A.M., Sesetti, A., Battula, S., Doolla, S., Srinivasan, D., Multi-agent based demand response management system for combined operation of smart microgrids (2016) Sustainable Energy, Grids and Networks, 6, pp. 25-34; Rust, J., Miller, J., Palmer, R., (1993) Behavior of Trading Automata in a Computerized Double Auction Market, pp. 155-198. , The double auction market: Institutions, theories, and evidence; Gode, D.K., Sunder, S., Allocative efficiency of markets with zero-intelligence traders: Market as a partial substitute for individual rationality (1993) Journal of Political Economy, 101 (1), pp. 119-137; Cliff, D., (1997) Minimal-Intelligence Agents for Bargaining Behaviors in Market-Based Environments, , Hewlett-Packard Labs Technical Reports; Cliff, D., Evolutionary optimization of parameter sets for adaptive software-agent traders in continuous double auction markets (2001) HP LABORATORIES TECHNICAL REPORT HPL, (99); Gjerstad, S., Dickhaut, J., Price formation in double auctions (2001) E-Commerce Agents, Marketplace Solutions, Security Issues, and Supply and Demand, 22, pp. 106-134. , Elsevier; Tesauro, G., Das, R., High-performance bidding agents for the continuous double auction (2001) Proceedings 3Rd ACM Conference on Electronic Commerce (EC-2001), pp. 206-209. , Tampa, Florida, USA, October 14-17, 2001, ACM; Tesauro, G., Bredin, J.L., Strategic sequential bidding in auctions using dynamic programming (2002) The First International Joint Conference on Autonomous Agents & Multiagent Systems, pp. 591-598. , AAMAS 2002, July 15-19, 2002, Bologna, Italy, Proceedings, ACM, ACM; He, M., Leung, H.F., Jennings, N.R., A fuzzy-logic based bidding strategy for autonomous agents in continuous double auctions (2003) IEEE Transactions on Knowledge and Data Engineering, 15 (6), pp. 1345-1363; Vytelingum, P., Dash, R.K., David, E., Jennings, N.R., A risk-based bidding strategy for continuous double auctions (2004) Proceedings of the 16Th Eureopean Conference on Artificial Intelligence, ECAI’2004, including Prestigious Applicants of Intelligent Systems, PAIS 2004, 16, pp. 79-83. , Valencia, Spain, August 22-27, 2004, IOS Press; Cliff, D., Zip60: An enhanced variant of the zip trading algorithm (2006) The 3Rd IEEE International Conference on E-Commerce Technology. the 8Th IEEE International Conference on and Enterprise Computing, E-Commerce, and E-Services, p. 15. , IEEE; Vytelingum, P., Ramchurn, S.D., Voice, T.D., Rogers, A., Jennings, N.R., Trading agents for the smart electricity grid (2010) 9Th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2010), 1-3, pp. 897-904. , Toronto, Canada, May 10-14, 2010, International Foundation for Autonomous Agents and Multiagent Systems; Trevathan, J., Security, anonymity and trust in electronic auctions (2005) Crossroads, 11, p. 2; Trevathan, J., (2007) Privacy and Security in Online Auctions, , PhD thesis, James Cook University; Trevathan, J., Read, W., Undesirable and fraudulent behaviour in online auctions (2006) SECRYPT 2006, Proceedings of the International Conference on Security and Cryptography, 6, pp. 450-458. , Setúbal, Portugal, August 7-10, 2006, SECRYPT is part of ICETE - The International Joint Conference on e-Business and Telecommunications, INSTICC Press; Yokoo, M., Sakurai, Y., Matsubara, S., The effect of false-name bids in combinatorial auctions: New fraud in internet auctions (2004) Games and Economic Behavior, 46 (1), pp. 174-188; Chakraborty, I., Kosmopoulou, G., Auctions with shill bidding (2004) Economic Theory, 24 (2), pp. 271-287; Porter, R., Shoham, Y., On cheating in sealed-bid auctions (2005) Decision Support Systems, 39 (1), pp. 41-54; Wang, C., Leung, H.F., Anonymity and security in continuous double auctions for internet retails market (2004) System Sciences, 2004. Proceedings of the 37Th Annual Hawaii International Conference On, p. 10. , IEEE, Jan; Trevathan, J., Ghodosi, H., Read, W., An anonymous and secure continuous double auction scheme (2006) System Sciences, 2006. HICSS’06. Proceedings of the 39Th Annual Hawaii International Conference On, 6, p. 125. , IEEE; Adepu, S., Mathur, A., Generalized attacker and attack models for cyber physical systems (2016) 40Th IEEE Annual Computer Software and Applications Conference, COMPSAC 2016, 1, pp. 283-292. , Atlanta, GA, USA, June 10-14; Tan, Z., Gurd, J.R., Market-based grid resource allocation using a stable continuous double auction (2007) Proceedings of the 8Th IEEE/ACM International Conference on Grid Computing, GRID ’07, pp. 283-290. , (Washington, DC, USA), IEEE Computer Society; Haque, A., Alhashmi, S.M., Parthiban, R., Continuous double auction in grid computing: An agent based approach to maximize profit for providers (2010) Proceedings of the 2010 IEEE/WIC/ACM International Conference on Intelligent Agent Technology, IAT 2010, 2, pp. 347-351. , Toronto, Canada, August 31 - September 3, IEEE; Koutsopoulos, I., Iosifidis, G., Auction mechanisms for network resource allocation (2010) Modeling and Optimization in Mobile, Ad Hoc and Wireless Networks (Wiopt), 2010 Proceedings of the 8Th International Symposium On, pp. 554-563. , IEEE; Kant, U., Grosu, D., Double auction protocols for resource allocation in grids (2005) International Symposium on Information Technology: Coding and Computing (ITCC 2005), 1, pp. 366-371. , 4-6 April 2005, Las Vegas, Nevada, USA; Raymond, K., A tree-based algorithm for distributed mutual exclusion (1989) ACM Transactions on Computer Systems (TOCS), 7, pp. 61-77; Zhang, Z., Nait-Abdesselam, F., Ho, P.H., Boosting markov reward models for probabilistic security evaluation by characterizing behaviors of attacker and defender (2008) Availability, Reliability and Security, 2008. ARES 08. Third International Conference On, pp. 352-359. , IEEE; Gollmann, D., Gurikov, P., Isakov, A., Krotofil, M., Larsen, J., Winnicki, A., Cyber-physical systems security: Experimental analysis of a vinyl acetate monomer plant (2015) Proceedings of the 1St ACM Workshop on Cyber-Physical System Security, CPSS 2015, pp. 1-12. , Singapore, Republic of Singapore, April 14 - March 14, 2015, ACM; Liu, P., Zang, W., Yu, M., Incentive-based modeling and inference of attacker intent, objectives, and strategies (2005) ACM Transactions on Information and System Security (TISSEC), 8 (1), pp. 78-118; Teixeira, A., Pérez, D., Sandberg, H., Johansson, K.H., Attack models and scenarios for networked control systems (2012) Proceedings of the 1St International Conference on High Confidence Networked Systems, Hicons ’12, pp. 55-64. , ACM; Teixeira, A., Shames, I., Sandberg, H., Johansson, K.H., A secure control framework for resource-limited adversaries (2015) Automatica, 51, pp. 135-148; Sedaghatbaf, A., Abdollahi Azgomi, M., “Attack modelling and security evaluation based on stochastic activity networks (2014) Security and Communication Networks, 7 (4), pp. 714-737; Amenaza, T., (2005) Fundamentals of Capabilities-Based Attack Tree Analysis, , Calgary, Canada, November; Buldas, A., Laud, P., Priisalu, J., Saarepera, M., Willemson, J., Rational choice of security measures via multi-parameter attack trees (2006) Critical Information Infrastructures Security, pp. 235-248; Chen, T.M., Sanchez-Aarnoutse, J.C., Buford, J., Petri net modeling of cyber-physical attacks on smart grid (2011) IEEE Transactions on Smart Grid, 2 (4), pp. 741-749; Chen, B., Kalbarczyk, Z., Nicol, D.M., Sanders, W.H., Tan, R., Temple, W.G., Tippenhauer, N.O., Yau, D.K., Go with the flow: Toward workflow-oriented security assessment (2013) Proceedings of the 2013 Workshop on New Security Paradigms Workshop, pp. 65-76. , ACM; Jajodia, S., Noel, S., (2010) Advanced Cyber Attack Modeling Analysis and Visualization, , tech. rep., DTIC Document; Vytelingum, P., Cliff, D., Jennings, N.R., Strategic bidding in continuous double auctions (2008) Artificial Intelligence, 172 (14), pp. 1700-1729; De Luca, M., Cliff, D., Human-agent auction interactions: Adaptive-aggressive agents dominate (2011) IJCAI 2011, Proceedings of the 22Nd International Joint Conference on Artificial Intelligence, 22, p. 178. , Barcelona, Catalonia, Spain, July 16-22, Citeseer; Vach, D., Marsnales, M.A., (2015) Comparison of Double Auction Bidding Strategies for Automated Trading Agents, , Master’s thesis, Charles University in Prague; Chaudhuri, P., Edward, T., An algorithm for k-mutual exclusion in decentralized systems (2008) Computer Communications, 31 (14), pp. 3223-3235; Kyle, A.S., Continuous auctions and insider trading (1985) Econometrica: Journal of the Econometric Society, pp. 1315-1335; Sallhammar, K., Knapskog, S.J., Helvik, B.E., Using stochastic game theory to compute the expected behavior of attackers (2005) 2005 IEEE/IPSJ International Symposium on Applications and the Internet Workshops (SAINT 2005 Workshops), pp. 102-105. , 31 January - 4 February 2005, Trento, Italy, IEEE; Niitsoo, M., Optimal adversary behavior for the serial model of financial attack trees (2010) Advances in Information and Computer Security - 5Th International Workshop on Security, IWSEC 2010, pp. 354-370. , Kobe, Japan, November 22-24, 2010. Proceedings, Springer; Madan, B.B., Trivedi, K.S., Security modeling and quantification of intrusion tolerant systems using attack-response graph (2004) Journal of High Speed Networks, 13 (4), pp. 297-308; Dahl, O.M., Wolthusen, S.D., Modeling and execution of complex attack scenarios using interval timed colored petri nets (2006) Proceedings of the 4Th IEEE International Workshop on Information Assurance (IWIA 2006), p. 12. , 13-14 April 2006, Egham, Surrey, UK, IEEE; Kiviharju, M., Venäläinen, T., Kinnunen, S., Towards modelling information security with key-challenge petri nets (2009) Nordic Conference on Secure IT Systems, pp. 190-206. , Springer","Marufu, A.M.C.; Department of Computer Science, South Africa; email: amarufu@cs.uct.ac.za",,,"Springer New York LLC",,,,,15682633,,,,"English","Advances in Information Security",Book Chapter,"Final","",Scopus,2-s2.0-85052612152
"Chida K., Genkin D., Hamada K., Ikarashi D., Kikuchi R., Lindell Y., Nof A.","7101719136;36135431800;36895320900;36570523100;36628478800;6602568240;57053226400;","Fast large-scale honest-majority MPC for malicious adversaries",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","10993 LNCS",,,"34","64",,48,"10.1007/978-3-319-96878-0_2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052385389&doi=10.1007%2f978-3-319-96878-0_2&partnerID=40&md5=1f5347d2114e3b31ebacc1c78a20af78","NTT Secure Platform Laboratories, Tokyo, Japan; University of Michigan, Ann Arbor, United States; Bar-Ilan University, Ramat Gan, Israel","Chida, K., NTT Secure Platform Laboratories, Tokyo, Japan; Genkin, D., University of Michigan, Ann Arbor, United States; Hamada, K., NTT Secure Platform Laboratories, Tokyo, Japan; Ikarashi, D., NTT Secure Platform Laboratories, Tokyo, Japan; Kikuchi, R., NTT Secure Platform Laboratories, Tokyo, Japan; Lindell, Y., Bar-Ilan University, Ramat Gan, Israel; Nof, A., Bar-Ilan University, Ramat Gan, Israel","Protocols for secure multiparty computation enable a set of parties to compute a function of their inputs without revealing anything but the output. The security properties of the protocol must be preserved in the presence of adversarial behavior. The two classic adversary models considered are semi-honest (where the adversary follows the protocol specification but tries to learn more than allowed by examining the protocol transcript) and malicious (where the adversary may follow any arbitrary attack strategy). Protocols for semi-honest adversaries are often far more efficient, but in many cases the security guarantees are not strong enough. In this paper, we present new protocols for securely computing any functionality represented by an arithmetic circuit. We utilize a new method for verifying that the adversary does not cheat, that yields a cost of just twice that of semi-honest protocols in some settings. Our protocols are information-theoretically secure in the presence of a malicious adversaries, assuming an honest majority. We present protocol variants for small and large fields, and show how to efficiently instantiate them based on replicated secret sharing and Shamir sharing. As with previous works in this area aiming to achieve high efficiency, our protocol is secure with abort and does not achieve fairness, meaning that the adversary may receive output while the honest parties do not. We implemented our protocol and ran experiments for different numbers of parties, different network configurations and different circuit depths. Our protocol significantly outperforms the previous best for this setting (Lindell and Nof, CCS 2017); for a large number of parties, our implementation runs almost an order of magnitude faster than theirs. © International Association for Cryptologic Research 2018.",,"Information theory; Arithmetic circuit; Information-theoretically secure; Malicious adversaries; Network configuration; Protocol specifications; Secure multi-party computation; Security properties; Semi-honest adversaries; Cryptography",,,,,"Araki, T., Barak, A., Furukawa, J., Lichter, T., Lindell, Y., Nof, A., Ohara, K., Weinstein, O., Optimized honest-majority MPC for malicious adversaries-breaking the 1 billion-gate per second barrier (2017) The IEEE S&P; Araki, T., Furukawa, J., Lindell, Y., Nof, A., Ohara, K., High-throughput semi-honest secure three-party computation with an honest majority (2016) The 23Rd ACM CCS, pp. 805-817; Beaver, D., Foundations of secure interactive computing (1992) CRYPTO 1991. LNCS, 576, pp. 377-391. , https://doi.org/10.1007/3-540-46766-131, Feigenbaum, J. (ed.), Springer, Heidelberg; Beerliová-Trubíniová, Z., Hirt, M., Perfectly-secure MPC with linear communication complexity (2008) TCC 2008. LNCS, 4948, pp. 213-230. , https://doi.org/10.1007/978-3-540-78524-813, Canetti, R. (ed.), Springer, Heidelberg; Ben-Or, M., Goldwasser, S., Wigderson, A., Completeness theorems for non-cryptographic fault-tolerant distributed computation (1988) 20Th STOC; Burra, S.S., Larraia, E., Nielsen, J.B., Nordholt, P.S., Orlandi, C., Orsini, E., Scholl, P., Smart, N.P., High performance multi-party computation for binary circuits based on oblivious transfer (2015) Eprint Cryptology Archive, 2015 (472); Canetti, R., Security and composition of multiparty cryptographic protocols (2000) J. Cryptol., 13 (1), pp. 143-202; Chaum, D., Crépeau, C., Damgård, I., Multi-party unconditionally secure protocols (1988) 20Th STOC, pp. 11-19; Cleve, R., Limits on the security of coin flips when half the processors are faulty (1986) 18Th STOC, pp. 364-369; Cramer, R., Damgård, I., Ishai, Y., Share conversion, pseudorandom secret-sharing and applications to secure computation (2005) TCC 2005. LNCS, 3378, pp. 342-362. , https://doi.org/10.1007/978-3-540-30576-719, Kilian, J. (ed.), Springer, Heidelberg; Damgård, I., Keller, M., Larraia, E., Pastro, V., Scholl, P., Smart, N.P., Practical covertly secure MPC for dishonest majority – or: Breaking the SPDZ limits (2013) ESORICS 2013. LNCS, 8134, pp. 1-18. , https://doi.org/10.1007/978-3-642-40203-61, Crampton, J., Jajodia, S., Mayes, K. (eds.), Springer, Heidelberg; Damgård, I., Nielsen, J.B., Scalable and unconditionally secure multiparty computation (2007) CRYPTO 2007. LNCS, 4622, pp. 572-590. , https://doi.org/10.1007/978-3-540-74143-532, Menezes, A. (ed.), Springer, Heidelberg; Damgård, I., Pastro, V., Smart, N.P., Zakarias, S., Multiparty computation from somewhat homomorphic encryption (2012) CRYPTO 2012. LNCS, 7417, pp. 643-662. , https://doi.org/10.1007/978-3-642-32009-538, Safavi-Naini, R., Canetti, R. (eds.), Springer, Heidelberg; Genkin, D., Ishai, Y., Prabhakaran, M., Sahai, A., Tromer, E., Circuits resilient to additive attacks with applications to secure computation (2014) STOC 2014; Genkin, D., Ishai, Y., Polychroniadou, A., Efficient multi-party computation: From passive to active security via secure SIMD circuits (2015) CRYPTO 2015. LNCS, 9216, pp. 721-741. , https://doi.org/10.1007/978-3-662-48000-735, Gennaro, R., Robshaw, M. (eds.), Springer, Heidelberg; Goldreich, O., Micali, S., Wigderson, A., How to play any mental game (1987) 19Th STOC, pp. 218-229; Goldwasser, S., Levin, L., Fair computation of general functions in presence of immoral majority (1991) CRYPTO 1990. LNCS, 537, pp. 77-93. , https://doi.org/10.1007/3-540-38424-36, Menezes, A.J., Vanstone, S.A. (eds.), Springer, Heidelberg; Gennaro, R., Rabin, M., Rabin, T., Simplified VSS and fact-track multiparty computations with applications to threshold cryptography (1998) 17Th PODC; Goldreich, O., (2004) Foundations of Cryptography: Basic Applications, 2; Keller, M., Orsini, E., Scholl, P., MASCOT: Faster malicious arithmetic secure computation with oblivious transfer (2016) 23Rd ACM CCS, pp. 830-842; Keller, M., Pastro, V., Rotaru, D., Overdrive: Making SPDZ great again (2018) EUROCRYPT 2018. LNCS, 10822, pp. 158-189. , https://doi.org/10.1007/978-3-319-78372-76, Nielsen, J.B., Rijmen, V. (eds.), Springer, Cham; Lindell, Y., Nof, A., A framework for constructing fast MPC over arithmetic circuits with malicious adversaries and an honest-majority (2017) ACM CCS; Mohassel, P., Rosulek, M., Zhang, Y., Fast and secure three-party computation: The garbled circuit approach (2015) ACM CCS, pp. 591-602; Rabin, T., Ben-Or, M., Verifiable secret sharing and multi-party protocols with honest majority (1989) 21St STOC, pp. 73-85; Shamir, A., How to share a secret (1979) CACM, 22 (11), pp. 612-613; Yao, A., How to generate and exchange secrets (1986) 27Th FOCS, pp. 162-167","Lindell, Y.; Bar-Ilan UniversityIsrael; email: yehuda.lindell@biu.ac.il","Shacham H.Boldyreva A.",,"Springer Verlag","38th Annual International Cryptology Conference, CRYPTO 2018","19 August 2018 through 23 August 2018",,217039,03029743,9783319968773,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","",Scopus,2-s2.0-85052385389
"Somer T., Tiido A., Sample C., Mitchener-Nissen T.","57190340652;57203435847;55588309000;55332688700;","Application of journey mapping and crime scripting to the phenomenon of trolling",2018,"Proceedings of the 13th International Conference on Cyber Warfare and Security, ICCWS 2018","2018-March",,,"465","473",,2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051737104&partnerID=40&md5=7bed8e3a8250f0083f8c7702e27c6839","Tallinn University of Technology, Estonia; University of Warsaw, Poland; ICF International, United States; Trilateral Research Ltd., United Kingdom","Somer, T., Tallinn University of Technology, Estonia; Tiido, A., University of Warsaw, Poland; Sample, C., ICF International, United States; Mitchener-Nissen, T., Trilateral Research Ltd., United Kingdom","Cyber attacks and the terms “cyber warfare” and “information warfare” have entered everyday language, and as a result a new class of adversarial toolsets have emerged. Tactically speaking, cyber attack campaigns today follow techniques and patterns that are similar to those used by cyber criminals: DOS attacks (Ottis 2008), information gathering malicious software (Kaspersky 2015), sophisticated targeted weapons (De Falco 2012), and espionage and infiltration for data exfiltration (Lancaster University 2014). Having analysed writings on cyber warfare (Bernik, 2014, Clarke 2012, PC World 2012) and cyber crime (Goodman 2015, Olson 2013), we have concluded that, with the exception of the intent and end goals, the underlying attack cycle remains the same: attack preparation, attack execution and exit upon completion of goal. This paper discusses how methods from typically non-cyber disciplines can be applied to the cyber domain. By providing a visual representation in the form of criminal journeys this paper clarifies how such mappings can assist in building understanding of the steps adversaries undertake, in addition to supporting in the identification and development of effective and proportional countermeasures. Our work has deconstructed the lifecycle of cyber-attack events and translated these entries into a visualisation map, highlighting key steps an attacker takes during the lifecycle in the preparation and execution of trolling, where the authors have applied this methodology. We apply the definition of Jalonen et al. (2016): “Trolling is a phenomenon that is experienced in the interactions between internet users, with the aim of changing behaviour, altering reasoning and values, or simply gaining a strong response from as many users as possible by using offensive, emotionally-charged content”. Our work focuses on the motivation and activities of human trolls, with particular interest in the so-called hybrid-trolls. We examine trolling by mapping this as a crime script, with specific interest placed on the activities of hybrid trolls supporting pro-Russian political agenda within Estonia. © 2018 Academic Conferences and Publishing International Limited. All Rights Reserved.","Attack visualisation; Crime scripting; Cyber crime; Cyber warfare; Hybrid trolling; Information warfare; Journey mapping","Denial-of-service attack; Life cycle; Mapping; Network security; Visualization; Cyber warfare; Cyber-crimes; Data exfiltration; Hybrid trolling; Information gathering; Information warfare; Lancaster University; Visual representations; Crime",,,,,"Bernik, I., (2014) Cybercrime and Cyberwarfare, , John Wiley & Sons, Inc., Hoboken, USA; Borrion, H., Quality assurance in crime scripting (2013) Crime Science 2013, , http://www.crimesciencejournal.com/content/2/1/6, Available online at; Brayley, H., Cockbain, E., Laycock, G., The value of crime scripting: Deconstructing Internal Child Sex Trafficking (2011) Policing, 5 (2), pp. 132-143. , Number; Cheng, J., Bernstein, M., Danescu-Niculescu-Mizil, C., Leskovec, J., (2017) Anyone Can Become A Troll -Causes of Trolling Behavior in Online Discussions, , http://cs.stanford.edu/~jure/pubs/trolling-cscw17.pdf, Available online at; Clarke, R., (2012) Cyber War, , New York, HarperCollins Publishers, 2012; Cornish, D.B., The procedural analysis of offending and its releavnce for situational prevention (1994) Crime Prev. Stud., 3 (1994), pp. 151-196; De Falco, M., (2012) Stuxnet Facts Report. A Technical and Strategic Analysis, , https://ccdcoe.org/sites/default/files/multimedia/pdf/Falco2012_StuxnetFactsReport.pdf, NATO Cooperative Cyber Defence Center of Excellence, Tallinn, 2012. Available online at; (2015) FP7-SEC-2013.2.5-2. D2.3 “Detailed Appendixes on Cyber Crime Inventory and Networks in Non-ICT Sectors, , The Economic Impacts of Cyber Crime Sõmer, T., Ottis, R., Lepik, T., Lagazio, M., Hallaq, B., Simms, D., Mitchener-Nissen, T; Fiske, S., Linville, P., What does the Schema Concept Buy us? (1980) Personality and Social Psychology Bulletin, 6 (4). , http://journals.sagepub.com/doi/pdf/10.1177/014616728064006, vailable online at; Goodman, M., (2015) Future Crimes, , New York, Random House; Hillman, S., Procyk, J., Neustaedter, C., Tumblr fandoms, community and culture (2014) Proceedings of The Companion Publication of The 17th ACM Conference on Computer Supported Cooperative Work & Social Computing, pp. 285-288. , ACM, February 2014; Hutchins, E., Cloppert, M., Amin, R., (2014) Intelligence-Driven Computer Network Defence Informed by Analysis of Adversary Campaigns and Intrusion Kill Chains, , https://www.lockheedmartin.com/content/dam/lockheed/data/corporate/documents/LM-White-Paper-IntelDriven-Defense.pdf, Available online at; Jaitner, M., Mattsson, P.A., (2014) Russian Information Warfare 2015 7th International Conference on Cyber Conflict: Architectures in Cyberspace, , NATO CCD COE Publications, Tallinn; Jalonen, H., Paavola, J., Helo, T., Huhtinen, A.-M., Understanding the Trolling Phenomenon: The Automated Detection of Bots and Cyborgs in Social Media (2016) Journal of Information Warfare, 15 (4); (2015) The Duqu 2.0. Technical Details, , https://securelist.com/files/2015/06/The_Mystery_of_Duqu_2_0_a_sophisticated_cyberespionage_actor_returns.pdf, available online at; (2014) Detecting and Preventing Data Exfiltration, , https://www.cpni.gov.uk/Documents/Publications/2014/2014-04-11-de_lancaster_technical_report.pdf, Lancaster University Available online at; Levi, M., Organized fraud and organizing fraud. Unpacking research on networks and organizations (2008) Criminol. Crim. Justice, 8 (4), pp. 389-419; (2006) Webster'S Ninth New Collegiate Dictionary, , https://www.merriamwebster.com/dictionary/troll, Merriam-Webster; (2014) Analysis of Russia’S Information Campaign Against Ukraine, , http://www.stratcomcoe.org/analysis-russias-information-campaign-against-ukraine, NATO StratCom Center of Excellence; (2017) Robotrolling, , www.stratcomcoe.org/robotrolling-20171, NATO StratCom Center of Excellence; Olson, P., (2013) We Are Anonymous: Inside The Hacker World of Lulzsec, Anonymous, and The Global Cyber Insurgency, , Hachette Book Group; Ottis, R., Analysis of the 2007 cyber attacks against Estonia from the information warfare perspective (2008) Proceedings of The 7th European Conference on Information Warfare and Security, pp. 163-168. , Plymouth, 2008. Reading: Academic Publishing Limited; (2012) When Is A Cybercrime An Act of Cyberwar?, , http://www.pcworld.com/article/250308/when_is_a_cybercrime_an_act_of_cyberwar_.html, Available online at; Pomerantsev, P., Weiss, M., The menace of unreality: How the Kremlin weaponizes information, culture and money (2014) The Interpreter, 22; Ristolainen, M., Should 'RuNet2020' be taken seriously? Contradictory views about cybersecurity between Russia and the west (2017) Proceedings of The 16th European Conference on Cyber Warfare and Security, pp. 391-400. , ublin, Ireland; (2016) Incident Response Capabilities 2016, , https://www.sans.org/readingroom/whitepapers/analyst/incident-response-capabilities-2016-2016-incident-response-survey-37047, available online at; Schank, R.C., Abelson, R.P., (1977) Scripts, Plans, Goals, and Understanding, , illsdale, NJ: Lawrence Erlbaum Associates, 1977; Spruds, A., Rožukalne, A., Sedlenieks, K., Daugulis, M., Potjomkina, D., Tölgyesi, B., Bruge, I., Internet trolling as a hybrid warfare tool (2015) The Case of Latvia, , http://www.stratcomcoe.org/download/file/fid/3345; Volodymyr, H., (2016) The “Hybrid Warfare” Ontology, , Фахове видання з економічних, філософських, політичних наук Затверджено постановами Президії ВАК України від 26 січня 2011 р; Wall, D., (2007) Cybercrime The Transformation of Crime in The Information Age, 4. , Polity, Cambridge; Warren, S., Oxburgh, G., Briggs, P., Wall, D., How might crime-scripts be used to support the understanding and policing of cloud crime? (2017) Human Aspects of Information Security, Privacy and Trust. HAS 2017. Lecture Notes in Computer Science, , Tryfonas T. eds Springer, Cham",,"Hurley J.S.Chen J.Q.",,"Academic Conferences and Publishing International Limited","13th International Conference on Cyber Warfare and Security, ICCWS 2018","8 March 2018 through 9 March 2018",,135360,,9781911218746,,,"English","Proc. Int. Conf. Cyber Warf. Secur., ICCWS",Conference Paper,"Final","",Scopus,2-s2.0-85051737104
"Bramlette C., Reith M.","57203413848;57192255430;","Framework for assessing cyber risk/effects in context of air force operations",2018,"Proceedings of the 13th International Conference on Cyber Warfare and Security, ICCWS 2018","2018-March",,,"52","56",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051678730&partnerID=40&md5=2ccf980dced93a412d33f7b13d276fe0","Air Force Institute of Technology, Dayton, United States","Bramlette, C., Air Force Institute of Technology, Dayton, United States; Reith, M., Air Force Institute of Technology, Dayton, United States","The Air Force has a network centric view of risk assessment that fails to appreciate how the dynamic nature of cyber impacts missions. There is no clear way of predicting or quantifying effects of cyber-attack on networks. There is also a lack of a methodology for being able to quantify how, when, and why adversarial cyber force may realistically affect friendly platforms. As a result, it is difficult for commanders and cyberspace operators to have situational awareness of the security level of their mission. This paper is a foundational work exploring a basic process/framework for assessing the effects and impact of cyber power in the context of Air Force operations. Challenges to achieving quality risk assessments are explored. The goal is to develop a format that is simple enough to convey to leadership but sophisticated and holistic enough to make valid assessments. Several key design concepts are recommended and the basics of a framework incorporating them is presented. The focus of the assessment is from a defensive (network owner) standpoint, however much of the risk will be assessed from methods and effects of adversary methodologies and COAs. The intent of this framework is to assist future operational mission planning and improve cybersecurity practices in the Air Force. © 2018 Academic Conferences and Publishing International Limited. All Rights Reserved.","Air force; Assessment; Cyber; Effects; Framework; Mission impact; Risk; Rmf","Computer crime; Military aviation; Risks; Air force; Assessment; Cyber; Effects; Framework; Mission impacts; Risk assessment",,,,,,,"Hurley J.S.Chen J.Q.",,"Academic Conferences and Publishing International Limited","13th International Conference on Cyber Warfare and Security, ICCWS 2018","8 March 2018 through 9 March 2018",,135360,,9781911218746,,,"English","Proc. Int. Conf. Cyber Warf. Secur., ICCWS",Conference Paper,"Final","",Scopus,2-s2.0-85051678730
"Tong L., Yu S., Alfeld S., Vorobeychik Y.","57219525735;57193240885;55232344500;8913948800;","Adversarial regression with multiple learners",2018,"35th International Conference on Machine Learning, ICML 2018","11",,,"7899","7907",,4,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051566621&partnerID=40&md5=6e950d5c941434e44583064efddce064","Department of EECS, Vanderbilt University, Nashville, TN, United States; Computer Science Department, Amherst College, Amherst, MA, United States","Tong, L., Department of EECS, Vanderbilt University, Nashville, TN, United States; Yu, S., Department of EECS, Vanderbilt University, Nashville, TN, United States; Alfeld, S., Computer Science Department, Amherst College, Amherst, MA, United States; Vorobeychik, Y., Department of EECS, Vanderbilt University, Nashville, TN, United States","Despite the considerable success enjoyed by machine learning techniques in practice, numerous studies demonstrated that many approaches are vulnerable to attacks. An important class of such attacks involves adversaries changing features at test time to cause incorrect predictions. Previous investigations of this problem pit a single learner against an adversary. However, in many situations an adversary's decision is aimed at a collection of learners, rather than specifically targeted at each independently. We study the problem of adversarial linear regression with multiple learners. We approximate the resulting game by exhibiting an upper bound on learner loss functions, and show that the resulting game has a unique symmetric equilibrium. We present an algorithm for computing this equilibrium, and show through extensive experiments that equilibrium models are significantly more robust than conventional regularized linear regression. Copyright 2018 by the author(s). © 2018 by the Authors All rights reserved.",,"Artificial intelligence; Regression analysis; Equilibrium models; Loss functions; Machine learning techniques; Show through; Symmetric equilibrium; Test time; Upper Bound; Learning systems",,,,,"Alfeld, S., Zhu, X., Barford, P., Data poisoning attacks against autoregressive models (2016) AAAI Conference on Artificial Intelligence; Bruckner, M., Scheffer, T., Stackelberg games for adversarial prediction problems (2011) ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 547-555; Cheng, S.-R., Reeves, D.M., Vorobeychik, Y., Wellman, M.P., Notes on equilibria in symmetric games (2004) International Workshop on Game Theoretic and Decision Theoretic Agents, pp. 71-78; Cortez, P., Cerdeira, A., Almeida, F., Matos, T., Reis, J., Modeling wine preferences by data mining from physic-ochemical properties (2009) Decision Support Systems, 47 (4), pp. 547-553; Dalvi, N., Domingos, P., Mausam Sanghai, S., Verma, D., Adversarial classification (2004) SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 99-108; Grosshans, M., Sawade, C., Bruckner, M., Scheffer, T., Bayesian games for adversarial regression problems (2013) International Conference on International Conference on Machine Learning, pp. 55-63; Laszka, A., Lou, J., Vorobeychik, Y., Multi-defender strategic filtering against spear-phishing attacks (2016) AAAI Conference on Artificial Intelligence; Li, B., Vorobeychik, Y., Feature cross-substitution in adversarial classification (2014) Advances in Neural Information Processing Systems, pp. 2087-2095; Li, B., Vorobeychik, Y., Scalable optimization of randomized operational decisions in adversarial classification settings (2015) Conference on Artificial Intelligence and Statistics; Lowd, D., Meek, C., Adversarial learning (2005) ACM SIGKDD International Conference on Knowledge Discovery in Data Mining, pp. 641-647. , ACM; Rosen, J.B., Existence and uniqueness of equilibrium points for concave n-person games (1965) Econometrica, pp. 520-534; Russu, P., Demontis, A., Biggio, B., Fumera, G., Roli, F., Secure kernel machines against evasion attacks (2016) ACM Workshop on Artificial Intelligence and Security, pp. 59-69; Smith, A., Lou, J., Vorobeychik, Y., Multidefender security games (2017) IEEE Intelligent Systems, 32 (1), pp. 50-60; Srndic, N., Laskov, P., Practical evasion of a learning-based classifier: A case study (2014) 2014 IEEE Symposium on Security and Privacy, pp. 197-211; Stevens, D., Lowd, D., On the hardness of evading combinations of linear classifiers (2013) ACM Workshop on Artificial Intelligence and Security; Vorobeychik, Y., Mayo, J.R., Armstrong, R.C., Ruthruff, J., Noncooperatively optimized tolerance: Decentralized strategic optimization in complex systems (2011) Physical Review Letters, 107 (10), p. 108702; Xu, H., Caramanis, C., Mannor, S., Robust regression and lasso (2009) Advances in Neural Information Processing Systems, pp. 1801-1808; Zhou, Y., Kantarcioglu, M., Thuraisingham, B.M., Xi, B., Adversarial support vector machine learning (2012) ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 1059-1067","Vorobeychik, Y.; Department of EECS, United States; email: eug.vorobey@gmail.com","Krause A.Dy J.",,"International Machine Learning Society (IMLS)","35th International Conference on Machine Learning, ICML 2018","10 July 2018 through 15 July 2018",,141700,,9781510867963,,,"English","Int. Conf. Mach. Learn., ICML",Conference Paper,"Final","",Scopus,2-s2.0-85051566621
"Vorobeychik Y., Kantarcioglu M.","8913948800;57203214848;","Adversarial machine learning",2018,"Synthesis Lectures on Artificial Intelligence and Machine Learning","12","3",,"1","169",,64,"10.2200/S00861ED1V01Y201806AIM039","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051535921&doi=10.2200%2fS00861ED1V01Y201806AIM039&partnerID=40&md5=7b6be75583c6d7e876d9ecddb96b070f","Vanderbilt University, Department of Computer Science, Computer Engineering, and Biomedical Informatics, United States; UTD Data Security and Privacy Lab., University of Texas, Dallas, United States","Vorobeychik, Y., Vanderbilt University, Department of Computer Science, Computer Engineering, and Biomedical Informatics, United States; Kantarcioglu, M., UTD Data Security and Privacy Lab., University of Texas, Dallas, United States","The increasing abundance of large high-quality datasets, combined with significant technical advances over the last several decades have made machine learning into a major tool employed across a broad array of tasks including vision, language, finance, and security. However, success has been accompanied with important new challenges: many applications of machine learning are adversarial in nature. Some are adversarial because they are safety critical, such as autonomous driving. An adversary in these applications can be a malicious party aimed at causing congestion or accidents, or may even model unusual situations that expose vulnerabilities in the prediction engine. Other applications are adversarial because their task and/or the data they use are. For example, an important class of problems in security involves detection, such as malware, spam, and intrusion detection. The use of machine learning for detecting malicious entities creates an incentive among adversaries to evade detection by changing their behavior or the content of malicius objects they develop. The field of adversarial machine learning has emerged to study vulnerabilities of machine learning approaches in adversarial settings and to develop techniques to make learning robust to adversarial manipulation. This book provides a technical overview of this field. After reviewing machine learning concepts and approaches, as well as common use cases of these in adversarial settings, we present a general categorization of attacks on machine learning. We then address two major categories of attacks and associated defenses: decision-time attacks, in which an adversary changes the nature of instances seen by a learned model at the time of prediction in order to cause errors, and poisoning or training time attacks, in which the actual training dataset is maliciously modified. In our final chapter devoted to technical content, we discuss recent techniques for attacks on deep learning, as well as approaches for improving robustness of deep neural networks. We conclude with a discussion of several important issues in the area of adversarial learning that in our view warrant further research. Given the increasing interest in the area of adversarial machine learning, we hope this book provides readers with the tools necessary to successfully engage in research and practice of machine learning in adversarial settings. Copyright © 2018 by Morgan & Claypool.","Adversarial machine learning; Game theory; Machine learning","Decision making; Deep neural networks; Forecasting; Game theory; Intrusion detection; Learning systems; Malware; Safety engineering; Adversarial learning; Autonomous driving; Machine learning approaches; Malicious entity; Prediction engines; Technical advances; Technical content; Training dataset; Artificial intelligence",,,,,"Alfeld, S., Zhu, X., Barford, P., Data poisoning attacks against autoregressive models (2016) AAAI Conference on Artificial Intelligence; Alfeld, S., Zhu, X., Barford, P., Explicit defense actions against test-set attacks (2017) AAAI Conference on Artificial Intelligence; Anthony, M., Bartlett, P.L., (1999) Neural Network Learning: Theoretical Foundations, , Cambridge University Press; Anthony, M., Bartlett, P.L., (2009) Neural Network Learning: Theoretical Foundations, , Cambridge University Press; Barreno, M., Nelson, B., Sears, R., Joseph, A.D., Tygar, J.D., Can machine learning be secure? (2006) ACM Asia Conference on Computer and Communications Security, pp. 16-25; Barreno, M., Nelson, B., Joseph, A.D., Tygar, J.D., The security of machine learning (2010) Machine Learning, 81, pp. 121-148; Bertsekas, D.P., Tsitsiklis, J.N., (1996) Neuro-Dynamic Programming, , Optimization and Neural Computation, Athena Scientific; Bhagoji, A.N., He, W., Li, B., Song, D., (2017) Exploring the Space of Black-box Attacks on Deep Neural Networks, , Arxiv Preprint; Bhowmick, A., Hazarika, S.M., E-mail spam filtering: A review of techniques and trends (2018) Advances in Electronics, Communication and Computing; Biggio, B., Nelson, B., Laskov, P., Support vector machines under adversarial label noise (2011) Proc. of the Asian Conference on Machine Learning, pp. 97-112; Biggio, B., Roli, F., (2018) Wild Patterns: Ten Years After the Rise of Adversarial Machine Learning; Biggio, B., Nelson, B., Laskov, P., Poisoning attacks against support vector machines (2012) International Conference on Machine Learning; Biggio, B., Corona, I., Maiorca, D., Nelson, B., Srndic, N., Laskov, P., Giacinto, G., Roli, F., Evasion attacks against machine learning at test time (2013) European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 387-402; Biggio, B., Bulo, S.R., Pillai, I., Mura, M., Mequanint, E.Z., Pelillo, M., Roli, F., Poisoning complete-linkage hierarchical clustering (2014) Structural, Syntactic, and Statistical Pattern Recognition; Biggio, B., Fumera, G., Roli, F., Security evaluation of pattern classifiers under attack (2014) IEEE Transactions on Knowledge and Data Engineering, 26 (4), pp. 984-996; Bishop, C.M., (2011) Pattern Recognition and Machine Learning, , Information Science and Statistics, Springer; Bojarski, M., Del Testa, D., Dworakowski, D., Firner, B., Flepp, B., Goyal, P., Jackel, L.D., Zieba, K., (2016) End to end Learning for Self-driving Cars; Boutilier, C., Dean, T., Hanks, S., Decision-theoretic planning: Structural assumptions and computational leverage (1999) Journal of Artificial Intelligence Research, 11 (1), p. 94; Boutilier, C., Dearden, R., Goldszmidt, M., Stochastic dynamic programming with factored representations (2000) Artificial Intelligence, 121 (1), pp. 49-107; Brückner, M., Scheffer, T., Stackelberg games for adversarial prediction problems (2011) ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 547-555; Brückner, M., Scheffer, T., Static prediction games for adversarial learning problems (2012) Journal of Machine Learning Research, (13), pp. 2617-2654; Bshoutya, N.H., Eironb, N., Kushilevitz, E., PAC learning with nasty noise (2002) Theoretical Computer Science, 288, pp. 255-275; Cai, J.-F., Candès, E., Shen, Z., A singular value thresholding algorithm for matrix completion (2010) SIAM Journal on Optimization, 20 (4), pp. 1956-1982; Candès, E., Recht, B., Exact matrix completion via convex optimization (2007) Foundations of Computational Mathematics, 9 (6), pp. 717-772; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) IEEE Symposium on Security and Privacy, pp. 39-57; Cauwenberghs, G., Poggio, T., Incremental and decremental support vector machine learning (2001) Neural Information Processing Systems, pp. 409-415; Chau, D.H., Nachenberg, C., Wilhelm, J., Wright, A., Faloutsos, C., Polonium: Tera-scale graph mining and inference for malware detection (2011) SIAM International Conference on Data Mining; Chen, Z., Huang, X., End-to-end learning for lane keeping of self-driving cars (2017) IEEE Intelligent Vehicles Symposium; Conn, A.R., Gould, N.I.M., Toint, P.L., Trust-region methods (1987) Society for Industrial and Applied Mathematics; Cretu, G.F., Stavrou, A., Locasto, M.E., Stolfo, S.J., Keromytis, A.D., Casting out demons: Sanitizing training data for anomaly sensors (2008) IEEE Symposium on Security and Privacy, pp. 81-95; Dalvi, N., Domingos, P., Mausam, Sanghai, S., Verma, D., Adversarial classification (2004) SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 99-108; Danskin, J.M., (1967) The Theory of Max-Min and its Application to Weapons Allocation Problems, , Springer; De Wolf, R., A brief introduction to fourier analysis on the Boolean cube (2008) Theory of Computing, Graduate Surveys, 1, pp. 1-20; Demontis, A., Melis, M., Biggio, B., Maiorca, D., Arp, D., Rieck, K., Corona, I., Roli, F., Yes, machine learning can be more secure! A case study on android malware detection (2017) IEEE Transactions on Dependable and Secure Computing; Demontis, A., Biggio, B., Fumera, G., Giacinto, G., Roli, F., Infinitynorm support vector machines against adversarial label contamination (2017) Italian Conference on Cybersecurity, pp. 106-115; Eckart, C., Young, G., The approximation of one matrix by another of lower rank (1936) Psychometrika, 1 (3), pp. 211-218; Evtimov, I., Eykholt, K., Fernandes, E., Kohno, T., Li, B., Prakash, A., Rahmati, A., Song, D., Robust physical-world attacks on deep learning visual classification (2018) Conference on Computer Vision and Pattern Recognition; Feng, J., Xu, H., Mannor, S., Yan, S., Robust logistic regression and classification (2014) Neural Information Processing Systems, 1, pp. 253-261; Fogla, P., Lee, W., Evading network anomaly detection systems: Formal reasoning and practical techniques (2006) ACM Conference on Computer and Communications Security, pp. 59-68; Fogla, P., Sharif, M., Perdisci, R., Kolesnikov, O., Lee, W., Polymorphic blending attacks (2006) USENIX Security Symposium; Fudenberg, D., Levine, D.K., (1998) The Theory of Learning in Games, , Economic Learning and Social Evolution, MIT Press; Gemulla, R., Nijkamp, E., Haas, P.J., Sismanis, Y., Large-scale matrix factorization with distributed stochastic gradient descent (2011) SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 69-77; Gentle, J.E., (2007) Matrix Algebra: Theory, Computations, and Applications in Statistics, , Springer Texts in Statistics, Springer; Goodfellow, I., Bengio, Y., Courville, A., (2016) Deep Learning, , http://www.deeplearningbook.org/contents/autoencoders.html, chapter 14. MIT Press; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations; Grosse, K., Papernot, N., Manoharan, P., Backes, M., McDaniel, P., Adversarial perturbations against deep neural networks for malware classification (2017) European Symposium on Research in Computer Security; Grosshans, M., Sawade, C., Brückner, M., Scheffer, T., Bayesian games for adversarial regression problems (2013) International Conference on International Conference on Machine Learning, pp. 55-63; Guarnieri, C., Tanasi, A., Bremer, J., Schloesser, M., (2012) Cuckoo Sandbox: A Malware Analysis System, , http://www.cuckoosandbox.org/; Guestrin, C., Koller, D., Parr, R., Venkataraman, S., Efficient solution algorithms for factored MDPS (2003) Journal of Artificial Intelligence Research, 19, pp. 399-468; Hajaj, C., Vorobeychik, Y., Adversarial task assignment (2018) International Joint Conference on Artificial Intelligence, , to appear; Hanna, S., Huang, L., Wu, E., Li, S., Chen, C., Song, D., Juxtapp: A scalable system for detecting code reuse among android applications (2013) International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment, pp. 62-81; Hardt, M., Megiddo, N., Papadimitriou, C., Wootters, M., Strategic classification (2016) Proc. of the ACM Conference on Innovations in Theoretical Computer Science, pp. 111-122; Hastie, T., Tibshirani, R., Friedman, J., (2016) The Elements of Statistical Learning: Data Mining, Inference, and Prediction, , 2nd ed. Springer Series in Statistics, Springer; Hoffgen, K.-U., Simon, H.-U., Van Horn, K.S., Robust trainability of single neurons (1995) Journal of Computer and System Sciences, 50 (1), pp. 114-125; Hoos, H.H., Stützle, T., (2004) Stochastic Local Search: Foundations and Applications, , The Morgan Kaufmann Series in Artificial Intelligence, Morgan Kaufmann; Hotelling, H., Analysis of a complex of statistical variables into principal components (1933) Journal of Educational Psychology, 24 (6), p. 417; Jagielski, M., Oprea, A., Biggio, B., Liu, C., Nita-Rotaru, C., Li, B., Manipulating machine learning: Poisoning attacks and countermeasures for regression learning (2018) IEEE Symposium on Security and Privacy; Jain, P., Netrapalli, P., Sanghavi, S., Low-rank matrix completion using alternating minimization (2013) STOC; Jolliffe, I., (2002) Principal Component Analysis, , Wiley Online Library; Jolliffe, I.T., A note on the use of principal components in regression (1982) Applied Statistics, pp. 300-303; Kahn, J., Kalai, G., Linial, N., The influence of variables on Boolean functions (1988) Foundations of Computer Science, 29th Annual Symposium on, pp. 68-80. , IEEE; Kalai, A., Klivans, A.R., Mansour, Y., Servedio, R.A., Agnostically learning halfspaces (2008) SIAM Journal on Computing, 37 (6), pp. 1777-1805; Kantarcioglu, M., Xi, B., Clifton, C., Classifier evaluation and attribute selection against active adversaries (2011) Data Mining and Knowledge Discovery, 22 (1-2), pp. 291-335. , https://doi.org/10.1007/s10618-010-0197-3; Alex Kantchelian, J., Tygar, D., Joseph, A.D., Evasion and hardening of tree ensemble classifiers (2016) International Conference on Machine Learning; Kearns, M., Li, M., Learning in the presence of malicious errors (1993) SIAM Journal on Computing, 22 (4), pp. 807-837; Kellerer, H., Pferschy, U., Pisinger, D., (2004) Knapsack Problems, , Springer; Klivans, A.R., Long, P.M., Servedio, R.A., Learning halfspaces with malicious noise (2009) Journal of Machine Learning Research, 10, pp. 2715-2740; Kloft, M., Laskov, P., Security analysis of online centroid anomaly detection (2012) Journal of Machine Learning Research, 13, pp. 3681-3724; Koh, P.W., Liang, P., Understanding black-box predictions via influence functions (2017) International Conference on Machine Learning; Kurakin, A., Goodfellow, I.J., Bengio, S., Adversarial examples in the physical world (2016) CoRR, , http://arxiv.org/abs/1607.02533, 1607.02533; Lakhina, A., Crovella, M., Diot, C., Diagnosing network-wide traffic anomalies (2004) SIG-COMM Conference; Lebichot, B., Braun, F., Caelen, O., Saerens, M., A graph-based, semi-supervised, credit card fraud detection system (2016) International Workshop on Complex Networks and their Applications; Li, B., Vorobeychik, Y., Feature cross-substitution in adversarial classification (2014) Neural Information Processing Systems, pp. 2087-2095; Li, B., Vorobeychik, Y., Scalable optimization of randomized operational decisions in adversarial classification settings (2015) Conference on Artificial Intelligence and Statistics; Li, B., Vorobeychik, Y., Evasion-robust classification on binary domains (2018) ACM Transactions on Knowledge Discoveryfrom Data, 12 (4); Li, B., Wang, Y., Singh, A., Vorobeychik, Y., Data poisoning attacks on factorization-based collaborative filtering (2016) Neural Information Processing Systems, pp. 1885-1893; Liu, C., Li, B., Vorobeychik, Y., Oprea, A., Robust linear regression against training data poisoning (2017) Workshop on Artificial Intelligence and Security; Lowd, D., Meek, C., Adversarial learning (2005) ACM SIGKDD International Conference on Knowledge Discovery in Data Mining, pp. 641-647; Lowd, D., Meek, C., Good word attacks onstatistical spam filters (2005) Conference on Email and Anti-Spam; Lyu, C., Huang, K., Liang, H.-N., A unified gradient regularization family for adversarial examples (2015) IEEE International Conference on Data Mining, pp. 301-309; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards deep learning models resistant to adversarial attacks (2018) International Conference on Learning Representations; Martello, S., Toth, P., (1990) Knapsack Problems: Algorithms and Computer Implementations, , John Wiley & Sons; McCormick, G.P., Computability of global solutions to factorable nonconvex programs: Part I - Convex underestimating problems (1976) Mathematical Programming, 10 (1), pp. 147-175; Mei, S., Zhu, X., Using machine teaching to identify optimal training-set attacks on machine learners (2015) AAAI Conference on Artificial Intelligence, pp. 2871-2877; Mei, S., Zhu, X., The security of latent dirichlet allocation (2015) International Conference on Artificial Intelligence and Statistics, pp. 681-689; Melo-Acosta, G.E., Duitama-Munoz, F., Arias-Londono, J.D., Fraud detection in big data using supervised and semi-supervised learning techniques (2017) IEEE Colombian Conference on Communications and Computing; Montgomery, J.D., Spoofing, market manipulation, and the limit-order book (2016) Technical Report, Navigant Economics, , http://ssrn.com/abstract=2780579; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., DeepFool: A simple and accurate method to fool deep neural networks (2016) Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., Frossard, P., Universal adversarial perturbations (2017) IEEE Conference on Computer Vision and Pattern Recognition, pp. 1765-1773; Natarajan, N., Dhillon, I.S., Ravikumar, P., Tewari, A., Learning with noisy labels (2013) Proc. of the 26th International Conference on Neural Information Processing Systems, 1, pp. 1196-1204; Nelson, B., Rubinstein, B.I.P., Huang, L., Joseph, A.D., Tygar, J.D., Classifier evasion: Models and open problems (2010) Privacy and Security Issues in Data Mining and Machine Learning - International ECML/PKDD Workshop, pp. 92-98; Nelson, B., Rubinstein, B.I.P., Huang, L., Joseph, A.D., Lee, S.J., Rao, S., Tygar, J.D., Query strategies for evading convex-inducing classifiers (2012) Journal of Machine Learning Research, pp. 1293-1332; Nocedal, J., Wright, S., (2006) Numerical Optimization, , 2nd ed. Springer Series in Operations Research and Financial Engineering, Springer; O'Donnell, R., Some topics in analysis of Boolean functions (2008) ACM Symposium on Theory of Computing, pp. 569-578; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) IEEE Symposium on Security and Privacy, pp. 582-597; Papernot, N., McDaniel, P., (2018) Deep K-nearest Neighbors: Towards Confident, Interpretable and Robust Deep Learning, , Arxiv Preprint; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Berkay Celik, Z., Swami, A., The limitations of deep learning in adversarial settings (2016) IEEE European Symposium on Security and Privacy; Papernot, N., McDaniel, P.D., Goodfellow, I.J., (2016) Transferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples, , Arxiv, preprint; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A., Practical black-box attacks against machine learning (2017) ACM Asia Conference on Computer and Communications Security, pp. 506-519; Perdisci, R., Ariu, D., Giacinto, G., Scalable fine-grained behavioral clustering of http-based malware (2013) Computer Networks, 57 (2), pp. 487-500; Raghunathan, A., Steinhardt, J., Liang, P., Certified defenses against adversarial examples (2018) International Conference on Learning Representations; Rajaraman, A., Ullman, J.D., (2012) Mining of Massive Datasets, , Cambridge University Press; Rouhani, B.D., Samragh, M., Javidi, T., Koushanfar, F., (2017) Curtail: Characterizing and Thwarting Adversarial Deep Learning, , Arxiv Preprint; Benjamin, I., Rubinstein, P., Nelson, B., Huang, L., Joseph, A.D., Lau, S.H., Rao, S., Tygar, J.D., ANTIDOTE: Understanding and defending against poisoning of anomaly detectors (2009) Internet Measurement Conference; Russu, P., Demontis, A., Biggio, B., Fumera, G., Roli, F., Secure kernel machines against evasion attacks (2016) Proc. of the ACM Workshop on Artificial Intelligence and Security, pp. 59-69; Servedio, R.A., Smooth boosting and learning with malicious noise (2003) Journal of Machine Learning Research, 4, pp. 633-648; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540; Smith, A., Lou, J., Vorobeychik, Y., Multidefender security games (2017) IEEE Intelligent Systems, 32 (1), pp. 50-60; Smutz, C., Stavrou, A., Malicious PDF detection using metadata and structural features (2012) Annual Computer Security Applications Conference, pp. 239-248; Sra, S., Dhillon, I.S., Generalized nonnegative matrix approximations with bregman divergences (2006) Neural Information Processing Systems, pp. 283-290; Šrndic, N., Laskov, P., Practical evasion of a learning-based classifier: A case study (2014) IEEE Symposium on Security and Privacy, pp. 197-211; Šrndić, N., Laskov, P., Hidost: A static machine-learning-based detector of malicious files (2016) EURASIP Journal on Information Security, (1), p. 22; St. Aubin, R., Hoey, J., Boutilier, C., Apricodd: Approximate policy construction using decision diagrams (2000) NIPS, pp. 1089-1095; Steinhardt, J., Koh, P.W., Liang, P., Certified defenses for data poisoning attacks (2017) Neural Information Processing Systems; Stevens, D., Lowd, D., On the hardness of evading combinations of linear classifiers (2013) ACM Workshop on Artificial Intelligence and Security; Suciu, O., Marginean, R., Kaya, Y., Daume, H., III, Dumitras, T., When does machine learning FAIL? Generalized transferability for evasion and poisoning attacks (2018) USENIX Security Symposium; Sutton, R.S., Barto, A.G., (1998) Reinforcement Learning: An Introduction, , Adaptive Computation and Machine Learning, A Bradford Book; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R., Intriguing properties of neural networks (2013) International Conference on Learning Representations; Tambe, M., (2011) Security and Game Theory: Algorithms, Deployed Systems, Lessons Learned, , Cambridge University Press; Tamersoy, A., Roundy, K., Chau, D.H., Guilt by association: Large scale malware detection by mining file-relation graphs (2014) SIGKDD International Conference on Knowledge Discovery and Data Mining; Teo, C.H., Globerson, A., Roweis, S., Smola, A.J., Convex learning with invariances (2007) Neural Information Processing Systems; Tong, L., Li, B., Hajaj, C., Xiao, C., Vorobeychik, Y., (2018) A Framework for Validating Models of Evasion a Acks on Machine Learning, with Application to PDF Malware Detection, , Arxiv Preprint; Tong, L., Yu, S., Alfeld, S., Vorobeychik, Y., Adversarial regression with multiple learners (2018) International Conference on Machine Learning, , to appear; Valiant, L., Learning disjunctions of conjunctions (1985) International Joint Conference on Artificial Intelligence, pp. 560-566; Vapnik, V., (1999) The Nature of Statistical Learning Theory, , 2nd ed. Information Science and Statistics, Springer; Vorobeychik, Y., Li, B., Optimal randomized classification in adversarial settings (2014) International Conference on Autonomous Agents and Multiagent Systems, pp. 485-492; Vovk, V., Gammerman, A., Shafer, G., (2005) Algorithmic Learning in a Random World, , Springer Verlag; Wang, G., Wang, T., Zheng, H., Zhao, B.Y., Man vs. Machine: Practical adversarial detection of malicious crowdsourcing workers (2014) USENIX Security Symposium, pp. 239-254; Wang, K., Parekh, J.J., Stolfo, S.J., Anagram: A content anomaly detector resistant to mimicry attack (2006) Recent Advances in Intrusion Detection, pp. 226-248; Welling, M., Teh, Y.W., Bayesian learning via stochastic gradient langevin dynamics (2011) Proc. of the 28th International Conference on Machine Learning (ICML-11), pp. 681-688; Wong, E., Zico Kolter, J., Provable defenses against adversarial examples via the convex outer adversarial polytope (2018) International Conference on Machine Learning; Xiao, C., Zhu, J.-Y., Li, B., He, W., Liu, M., Song, D., Spatially transformed adversarial examples (2018) International Conference on Learning Representations; Xiao, H., Xiao, H., Eckert, C., Adversarial label flips attack on support vector machines (2012) European Conference on Artificial Intelligence; Xiao, H., Biggio, B., Nelson, B., Xiao, H., Eckert, C., Roli, F., Support vector machines under adversarial label contamination (2015) Neurocomputing, 160, pp. 53-62; Xu, H., Caramanis, C., Mannor, S., Robust regression and lasso (2009) Neural Information Processing Systems, 21, pp. 1801-1808; Xu, H., Caramanis, C., Mannor, S., Robustness and regularization of support vector machines (2009) Journal of Machine Learning Research, 10, pp. 1485-1510; Xu, H., Caramanis, C., Sanghavi, S., Robust PCA via outlier pursuit (2012) IEEE Transactions on Information Theory, 58 (5), pp. 3047-3064; Xu, H., Caramanis, C., Mannor, S., Outlier-robust PCA: The high-dimensional case (2013) IEEE Transactions on Information Theory, 59 (1), pp. 546-572; Xu, W., Qi, Y., Evans, D., Automatically evading classifiers: A case study on PDF malware classifiers (2016) Network and Distributed System Security Symposium; Ye, Y., Li, T., Adjeroh, D., Sitharama Iyengar, S., A survey on malware detection using data mining techniques (2017) ACM Computing Surveys, 50 (3); Zhang, F., Chan, P.P.K., Biggio, B., Yeung, D.S., Roli, F., Adversarial feature selection against evasion attacks (2015) IEEE Transactions on Cybernetics; Zhou, Y., Kantarcioglu, M., Modeling adversarial learning as nested stackelberg games (2016) Advances in Knowledge Discovery and Data Mining - 20th Pacific-Asia Conference, PAKDD, Proceedings, pp. 350-362. , https://doi.org/10.1007/978-3-319-31750-2-28, Auckland, New Zealand, April 19-22; Zhou, Y., Kantarcioglu, M., Thuraisingham, B.M., Xi, B., Adversarial support vector machine learning (2012) ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 1059-1067",,,,"Morgan and Claypool Publishers",,,,,19394608,,,,"English","Synth. Lect. Artif. Intell. Mach. Learn.",Article,"Final","",Scopus,2-s2.0-85051535921
"Wong E., Kolter J.Z.","57155743900;23110770000;","Provable defenses against adversarial examples via the convex outer adversarial polytope",2018,"35th International Conference on Machine Learning, ICML 2018","12",,,"8405","8423",,123,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051478879&partnerID=40&md5=55751aeabaa614c58ef1aa41918fd7d4","Machine Learning Department, Carnegie Mellon University, Pittsburgh, PA  15213, United States; Computer Science Department, Carnegie Mellon University, Pittsburgh, PA  15213, United States","Wong, E., Machine Learning Department, Carnegie Mellon University, Pittsburgh, PA  15213, United States; Kolter, J.Z., Computer Science Department, Carnegie Mellon University, Pittsburgh, PA  15213, United States","We propose a method to learn deep ReLU-based classifiers that are provably robust against normbounded adversarial perturbations on the training data. For previously unseen examples, the approach is guaranteed to detect all adversarial examples, though it may flag some non-adversarial examples as well. The basic idea is to consider a convex outer approximation of the set of activations reachable through a norm-bounded perturbation, and we develop a robust optimization procedure that minimizes the worst case loss over this outer region (via a linear program). Crucially, we show that the dual problem to this linear program can be represented itself as a deep network similar to the backpropagation network, leading to very efficient optimization approaches that produce guaranteed bounds on the robust loss. The end result is that by executing a few more forward and backward passes through a slightly modified version of the original network (though possibly with much larger batch sizes), we can learn a classifier that is provably robust to any norm-bounded adversarial attack. We illustrate the approach on a number of tasks to train classifiers with robust adversarial guarantees (e.g. for MNIST, we produce a convolutional classifier that provably has less than 5.8% test error for any adversarial attack with bounded ℓ∞ norm less than ϵ = 0.1), and code for all experiments is available at http://github.com/locuslab/convex-adversarial. © 35th International Conference on Machine Learning, ICML 2018.All Rights Reserved.",,"Artificial intelligence; Learning systems; Linear programming; Backpropagation network; Forward-and-backward; Guaranteed bounds; Linear programs; Norm-bounded perturbation; Optimization approach; Outer approximation; Robust optimization; Classification (of information)",,,,,"Anguita, D., Ghio, A., Oneto, L., Parra, X., Reyes-Ortiz, J.L., A public domain dataset for human activity recognition using smartphones (2013) ESANN; Athalye, A., Sutskever, I., (2017) Synthesizing Robust Adversarial Examples; Athalye, A., Carlini, N., Wagner, D., (2018) Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples, , https://arXiv.org/abs/1802.00420; Ben-Tal, A., El Ghaoui, L., Nemirovski, A., (2009) Robust Optimization, , Princeton University Press; Carlini, N., Wagner, D., Adversarial examples are not easily detected: Bypassing ten detection methods (2017) Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pp. 3-14. , ACM; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Security and Privacy (SP), 2017 IEEE Symposium on, pp. 39-57. , IEEE; Carlini, N., Katz, G., Barrett, C., Dill, D.L., (2017) Ground-truth Adversarial Examples; Cheng, C.-H., Nuhrenberg, G., Ruess, H., Maximum resilience of artificial neural networks (2017) International Symposium on Automated Technology for Verification and Analysis, pp. 251-268. , Springer; Cisse, M., Bojanowski, P., Grave, E., Dauphin, Y., Usunier, N., Parseval networks: Improving robustness to adversarial examples (2017) International Conference on Machine Learning, pp. 854-863; Ehlers, R., Formal verification of piece-wise linear feedforward neural networks (2017) International Symposium on Automated Technology for Verification and Analysis; Engstrom, L., Tsipras, D., Schmidt, L., Madry, A., (2017) A Rotation and a Translation Suffice: Fooling Cnns with Simple Transformations; Goodfellow, L., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) International Conference on Learning Representations, , http://arXiv.org/abs/1412.6572; Hein, M., Andriushchenko, M., Formal guarantees on the robustness of a classifier against adversarial manipulation (2017) Advances in Neural Information Processing Systems; Huang, X., Kwiatkowska, M., Wang, S., Wu, M., Safety verification of deep neural networks (2017) International Conference on Computer Aided Verification, pp. 3-29. , Springer; Katz, G., Barrett, C., Dill, D., Julian, K., Kochenderfer, M., (2017) Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks; Kingma, D., Ba, J., Adam: A method for stochastic optimization (2015) International Conference on Learning Representations; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World; Lomuscio, A., Maganti, L., (2017) An Approach to Reachability Analysis for Feed-forward Relu Neural Networks; Lu, J., Sibai, H., Fabry, E., Forsyth, D., (2017) No Need to Worry About Adversarial Examples in Object Detection in Autonomous Vehicles; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., Towards Deep Learning Models Resistant to Adversarial Attacks; Metzen, J.H., Genewein, T., Fischer, V., Bischoff, B., On detecting adversarial perturbations (2017) International Conference on Learning Representations; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Security and Privacy (SP), 2016 IEEE Symposium on, pp. 582-597. , IEEE; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against deep learning systems using adversarial examples (2017) Proceedings of the 2017 ACM Asia Conference on Computer and Communications Security; Peck, J., Roels, J., Goossens, B., Saeys, Y., Lower bounds on the robustness to adversarial perturbations (2017) Advances in Neural Information Processing Systems, pp. 804-813; Raghunathan, A., Steinhardt, J., Liang, P., Certified defenses against adversarial examples (2018) International Conference on Learning Representations; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on stateof-the-art face recognition (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540. , ACM; Sinha, A., Namkoong, H., Duchi, J., Certifiable distributional robustness with principled adversarial training (2018) International Conference on Learning Representations; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., Intriguing properties of neural networks (2014) International Conference on Learning Representations, , http://arXiv.org/abs/1312.6199; Tjeng, V., Tedrake, R., Verifying neural networks with mixed integer programming (2017) CoRR, , http://arXiv.org/abs/1711.07356; Xiao, H., Rasul, K., Vollgraf, R., (2017) Fashion-mnist: A Novel Image Dataset for Benchmarking Machine Learning Algorithms; Xu, H., Caramanis, C., Mannor, S., Robustness and regularization of support vector machines (2009) Journal of Machine Learning Research, 10, pp. 1485-1510. , Jul","Wong, E.; Machine Learning Department, United States; email: ericwong@cs.cmu.edu","Dy J.Krause A.",,"International Machine Learning Society (IMLS)","35th International Conference on Machine Learning, ICML 2018","10 July 2018 through 15 July 2018",,141700,,9781510867963,,,"English","Int. Conf. Mach. Learn., ICML",Conference Paper,"Final","",Scopus,2-s2.0-85051478879
"Cao N., Wang Y., Li G., Shen Y., Wang J., Zhang H.","15821756700;57197750479;55714080700;57197746713;36083505100;57008330000;","Improve the robustness of data mining algorithm against adversarial evasion attack",2018,"International Journal of Innovative Computing and Applications","9","3",,"142","149",,,"10.1504/IJICA.2018.093732","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051264865&doi=10.1504%2fIJICA.2018.093732&partnerID=40&md5=51dc6b6814b799f4147c59d3273a64f6","College of Information Engineering, Qingdao Binhai University, Qingdao, China; College of Communication and Art Design, University of Shanghai for Science and Technology, Shanghai, China; School of Information Science and Engineering, Hebei University of Science and Technology, Shijiazhuang, China","Cao, N., College of Information Engineering, Qingdao Binhai University, Qingdao, China; Wang, Y., College of Information Engineering, Qingdao Binhai University, Qingdao, China; Li, G., College of Communication and Art Design, University of Shanghai for Science and Technology, Shanghai, China; Shen, Y., College of Information Engineering, Qingdao Binhai University, Qingdao, China; Wang, J., School of Information Science and Engineering, Hebei University of Science and Technology, Shijiazhuang, China; Zhang, H., School of Information Science and Engineering, Hebei University of Science and Technology, Shijiazhuang, China","Conventional data mining theories developed for general-purpose applications commonly focus on the reducing the bias and variance on the ideal i.i.d. Datasets, but neglecting its potential failure on maliciously generated data points by observing the system's behaviours. Therefore, dealing with these adversarial samples is an essential part of a security system to handle the data that are intentionally made to deceive the system. Due to this concern, this paper proposes a novel approach that introduces uncertainty to the model behaviour, in order to obfuscate the decision process of the attacking strategy and improve the robustness of security system against attacks that try to evade the detection. Our approach addresses three problems. First, we build a pool of mining models to improve robustness of a variety of mining algorithms, similar to ensemble learning but focusing on the optimisation the trade-off between off-line accuracy and robustness. Second, we randomly select a subset of models at run time (when the model is used for detection) to further boost the robustness. Third, we propose a theoretical framework that bounds the minimal number of features an attacker needs to modify given a set of selected models. Copyright © 2018 Inderscience Enterprises Ltd.","Data mining; Robustness; Security","Economic and social effects; Robustness (control systems); Security systems; Attacking strategy; Conventional data mining; Data mining algorithm; Modeling behaviour; Models at run time; Potential failures; Security; Theoretical framework; Data mining",,,,,"Barreno, M., Can machine learning be secure?' (1995) Proceedings of the 2006 ACM Symposium on Information, Computer and Communications Security, pp. 16-25; (2006) Rocky Mountain Research Lab, , ACM C.J. KaufmanBoulder, CO, private communication; Dua, S., Du, X., (2016) Data Mining and Machine Learning in Cybersecurity, , CRC Press, Boca Raton; Fawzi, H., Secure estimation and control for cyber-physical systems under adversarial attacks (2014) IEEE Transactions on Automatic Control, 59 (6), pp. 1454-1467; Gupta, B.B., Analysis of various security issues and challenges in cloud computing environment: A survey' (2016) Handbook of Research on Modern Cryptographic Solutions for Computer and Cyber Security, , IGI Global, Hershey PA, USA; Gupta, B.B., Agrawal, D.P., Yamaguchi, S., (2016) Handbook of Research on Modern Cryptographic Solutions for Computer and Cyber Security, , IGI Global, Hershey PA, USA; Ibtihal, M., Driss, E.O., Hassan, N., Homomorphic encryption as a service for outsourced images in mobile cloud computing environment' (2017) International Journal of Cloud Applications and Computing, 7 (2), pp. 27-40; Kolcz, A., Teo, C.H., Feature weighting for improved classifier robustness (2009) CEAS09: Sixth Conference on Email and Anti-Spam; Lanckriet, G.R., A robust minimax approach to classification' (2003) The Journal of Machine Learning Research, 3, pp. 555-582. , December; Lee, C.-H., Calculating feature weights in naive bayes with kullback-leibler measure (2011) 2011 IEEE 11th International Conference on Data Mining (ICDM, pp. 1146-1151; Lee, W., Stolfo, S.J., Data mining approaches for intrusion detection (1998) USENIX Security Symposium, pp. 79-93; Lee, W., A data mining framework for building intrusion detection models (1999) Proceedings of the 1999 IEEE Symposium on Security and Privacy, pp. 120-132; Lee, W., Adaptive intrusion detection: A data mining approach' (2000) Artificial Intelligence Review, 14 (6), pp. 533-567; Liu, W., Chawla, S., A game theoretical model for adversarial learning', in data mining workshops (2009) ICDMW'09, IEEE International Conference on, pp. 25-30; Liu, W., Chawla, S., Mining adversarial patterns via regularized loss minimization' (2010) Machine Learning, 81 (1), pp. 69-83; Lowd, D., Meek, C., Adversarial learning (2005) Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining, pp. 641-647; Metsis, V., Spam filtering with naive bayes-which naive bayes? (2006) CEAS 2006-The Third Conference on Email and Anti-Spam, , 27-28 July 2006, Mountain View, California, USA DBLP; Nath, S.V., Crime pattern detection using data mining' (2006) Web Intelligence and Intelligent Agent Technology Workshops, 2006, WI-IAT 2006 Workshops, 2006 IEEE/WIC/ACM International Conference on, pp. 41-44; Negi, P., Mishra, A., Gupta, B.B., Enhanced cbf packet filtering method to detect ddos attack in cloud computing environment' (2013) Computer Science, 10 (1), pp. 142-146; Stergiou, C., Psannis, K.E., Kim, B.G., Gupta, B., Secure integration of iot and cloud computing' (2016) Future Generation Computer Systems, 78, pp. 964-975. , Springer; Tavallaee, M., A detailed analysis of the kdd cup 99 data set (2009) Proceedings of the Second IEEE International Conference on Computational Intelligence for Security and Defense Applications, CISDA'09, pp. 53-58. , IEEE Press, Piscataway, NJ, USA; Thuraisingham, B., (2003) Web Data Mining and Applications in Business Intelligence and Counter-Terrorism, , CRC Press, Boca Raton; Zhou, Y., Adversarial support vector machine learning (2012) Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 1059-1067","Li, G.; College of Communication and Art Design, China; email: li.guofu@usst.edu.cn",,,"Inderscience Publishers",,,,,1751648X,,,,"English","Int. J. Innovative Comput. Appl.",Article,"Final","",Scopus,2-s2.0-85051264865
"Hanson P.J., Truax L., Saranchak D.D.","57203174028;57203165417;57203171241;","IOT honeynet for military deception and indications and warnings",2018,"Proceedings of SPIE - The International Society for Optical Engineering","10643",,"106431A","","",,3,"10.1117/12.2305071","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050816339&doi=10.1117%2f12.2305071&partnerID=40&md5=c86ed3c44119cd5516e8bda7e2dee054","Concurrent Technologies Corporation, 100 CTC Drive, Johnstown, PA  15904-1935, United States","Hanson, P.J., Concurrent Technologies Corporation, 100 CTC Drive, Johnstown, PA  15904-1935, United States; Truax, L., Concurrent Technologies Corporation, 100 CTC Drive, Johnstown, PA  15904-1935, United States; Saranchak, D.D., Concurrent Technologies Corporation, 100 CTC Drive, Johnstown, PA  15904-1935, United States","Honeyman, named for the American Revolutionary War spy and source of disinformation, is an IoT distributed deception platform (DDP), aka ""honeynet"", based approach to military deception and indications and warning (I&W) generation. While DDP approaches have evolved from single honeypots to complex network architectures and have resolved previous challenges associated with revealing a DDP's signature or ""fingerprint"" including virtual device information, and therefore have become applicable for IoT uses, these approaches are still bounded in their application to cybersecurity purposes only. For example, data positioned as cyber-bait is meant only to draw in a cyber attacker but not to influence a strategic level of decision-making such as military or national security decisions. Additionally, monitoring within the DDP gathers data to model attackers' cyber behavior and patterns for explicit purpose of identifying new offensive cyber techniques and thwarting new attacks. Honeyman combines a proxy military logistics and readiness reporting IoT comprised of a mixture of virtual and physical devices with non-cyber information operations for military deception and to stimulate nation-state adversary behavior within the DDP. A machine learning (ML)-based traffic analysis model leverages observations within the honeynet to forecast an adversary's physical military activity thereby providing critical I&W. Further research is needed to optimize the combination of physical and virtual IoT devices for best deception performance, to evolve the tradecraft of dynamic cyber-bait, and to refine appropriate ML-based I&W models. © 2018 SPIE.","Cyberbait; DDP; Deep learning; Generative adversarial networks; Honeyman; Honeynet; I&W; IoT","Complex networks; Decision making; Deep learning; National security; Network architecture; Network security; Adversarial networks; Cyber information; Cyberbait; Honeyman; Honeynet; Military activities; Military logistics; Physical devices; Internet of things",,,,,"Chang, A., (2014) Warring State China's Cybersecurity Strategy, , Center for a New American Security (December); Carter, A., (2015) The Department of Defense Cyber Security Strategy, , Department of Defense (April); Osborn, K., DIUx accelerates AI development for predictive maintenance on F-16s (2017) Defense Systems, , https://defensesystems.com/articles/2017/11/15/air-force-c3-iot-f16.aspx, 17 November (25 February 2018); Junor, L., The defense readiness reporting system: A new tool for force management (2005) Joint Forces Quarterly; Harrison, T., (2014) Rethinking Readiness, 8 (3). , Center for Strategic and Budgetary Assessments Strategic Studies Quarterly (Fall); Keragala, D., (2016) Detecting Malware and Sandbox Evasion Techniques, , https://www.sans.org/reading-room/whitepapers/forensics/detecting-malware-sandbox-evasion-techniques-36667, SANS Institute, 16 January; Chin, W., Markatos, E., Antonatos, S., Ioannidis, S., (2009) HoneyLab: Large-scale Honeypot Deployment and Resource Sharing, , IEEE; Park, K., Woo, S., Moon, D., Choi, H., (2017) Secure Cyber Deception Architecture and Decoy Injection to Mitigate the Insider Threat, , Symmetry; Han, W., Zhao, Z., Doupe, A., Ahn, G., (2016) HoneyMix: Toward SDN-based Intelligent Honeynet, , ACM; Pa, Y.M.P., Suzuki, S., Yoshioka, K., Matsumoto, T., Kasama, T., Rossow, C., (2015) IoTPOT: Analysing the Rise of IoT Compromises; Luo, T., Xu, Z., Jin, X., Jia, Y., Ouyang, X., (2016) IoTCandyJar: Towards An Intelligent-Interaction Honeypot for IoT Devices; Grieves, M., (2014) Digital Twin: Manufacturing Excellence Through Virtual Factory Replication, , Michael W. Grieves, LLC; James, J., Mabry, F., St Leger, A., Huggins, K., (2012) Flowing Valued Information and Cyber-Physical Situational Awareness, , United States Military Academy, Network Science Center (18 December); Yong, S.Z., Zhu, M., Frazzoli, E., Resilient state estimation against switching attacks on stochastic cyber-physical systems (2015) IEEE 54th Annual Conference on Decision and Control, , (December); Goodfellow, I., NIPS 2016 tutorial: Generative adversarial networks (2016) Neural Information Processing Systems Conference, , [cs.LG] (3 Apr); Dowling, S., Optimizing IoT cyber attack analytics with adaptive honeynets (2016) IEEE World Congress on Internet Security; Tyworth, M., Giacobe, N.A., Mancuso, V., Dancy, C., The distributed nature of cyber situation awareness (2012) IEEE International Multi-Disciplinary Conference on Cognitive Methods in Situation Awareness and Decision Support; Krishnaprasad, P., (2017) Capturing Attacks on IoT Devices with a Multi-purpose IoT Honeypot, , Indian Institute of Technology Kanpur, (May)",,"Dudzik M.C.Ricklin J.C.","The Society of Photo-Optical Instrumentation Engineers (SPIE)","SPIE","Autonomous Systems: Sensors, Vehicles, Security, and the Internet of Everything 2018","16 April 2018 through 18 April 2018",,138055,0277786X,9781510617971,PSISD,,"English","Proc SPIE Int Soc Opt Eng",Conference Paper,"Final","",Scopus,2-s2.0-85050816339
"Molina-Markham A.D.","36722006700;","Probabilistic models for assured position, navigation, and timing",2018,"Proceedings of SPIE - The International Society for Optical Engineering","10643",,"106430N","","",,,"10.1117/12.2301254","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050815607&doi=10.1117%2f12.2301254&partnerID=40&md5=bb51c5a123e9961dcd768dd612846be6","MITRE Corporation, 202 Burlington Road, Bedford, MA, United States","Molina-Markham, A.D., MITRE Corporation, 202 Burlington Road, Bedford, MA, United States","Position, navigation, and timing (PNT) user equipment produces position, velocity, and time (PVT) estimates by combining measurements from multiple Global Navigation Satellite Systems (GNSS) and from additional sensors. PVT estimates are computed using linear estimators or Bayesian filters. However, because linear estimators and Bayesian filters are susceptible to adversarial manipulation, it is challenging to assess the trust of PVT estimates that rely on these approaches. We investigate the suitability of open-universe probabilistic models OUPMs introduced by Milch and Russell as a foundation to design PVT assurance metrics and adaptive PVT estimators. These estimators output PVT information together with trust assessments of PVT inputs and outputs. OUPMs model structural uncertainty (object uncertainty and relational uncertainty) necessary to measure assurance when the availability of sensors and the absence of adversaries cannot be guaranteed. We describe the challenges of designing PVT assurance metrics using traditional methods, and we illustrate how OUPMs represented as probabilistic programs allow us to address these challenges. In particular, we provide concrete examples of how to combine multiple sources of information to compute assurance assessments using the Texas Spoofing Test Battery. Furthermore, we demonstrate how to leverage PVT assurance metrics to design adaptive PVT estimators designed to operate through attacks. © 2018 SPIE.","Assurance models; Navigation and timing; Position; Probabilistic programming","Navigation; Timing circuits; Global Navigation Satellite Systems; Model structural uncertainties; Navigation and timing; Position; Probabilistic models; Probabilistic programming; Probabilistic programs; Relational uncertainties; Global positioning system",,,,,"Ho, Y., Lee, R., A Bayesian approach to problems in stochastic estimation and control (1964) IEEE Transactions on Automatic Control, 9, pp. 333-339. , (Oct.); Kalman, R.E., A new approach to linear filtering and prediction problems (1960) Journal of Basic Engineering, 82 (1), pp. 35-45; Carpenter, J., Clifford, P., Fearnhead, P., Improved particle filter for nonlinear problems (1999) Sonar and Navigation IEE Proceedings-Radar, 146, pp. 2-7. , (Feb.); Betz, J.W., (2015) Engineering Satellite-Based Navigation and Timing: Global Navigation Satellite Systems, Signals, and Receivers, , John Wiley & Sons; Wesson, K.D., Shepard, D.P., Bhatti, J.A., Humphreys, T.E., An evaluation of the vestigial signal defense for civil GPS anti-spoofing (2011) ION GNSS; Milch, B., Russell, S., Extending Bayesian networks to the open-universe case (2010) Heuristics, Probability and Causality: A Tribute to Judea Pearl., , College Publications; Psiaki, M.L., Humphreys, T.E., GNSS spoofing and detection (2016) Proceedings of the IEEE, 104 (6), pp. 1258-1270; Humphreys, T.E., Bhatti, J.A., Shepard, D.P., Wesson, K.D., The Texas spoofing test battery: Toward a standard for evaluating GPS signal authentication techniques (2012) Proceedings of the ION GNSS Meeting; Li, X., Chan, C.Y., Wang, Y., A reliable fusion methodology for simultaneous estimation of vehicle sideslip and yaw angles (2016) IEEE Transactions on Vehicular Technology, 65, pp. 4440-4458. , (June); Zhong, M., Guo, J., Cao, Q., On designing PMI kalman filter for INS/GPS integrated systems with unknown sensor errors (2015) IEEE Sensors Journal, 15, pp. 535-544. , (Jan.); Medeiros, C.B., Wanderley, M.M., Multiple-model linear kalman filter framework for unpredictable signals (2014) IEEE Sensors Journal, 14, pp. 979-991. , (Apr.); Kramer, J., Kandel, A., Robust small robot localization from highly uncertain sensors (2011) IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews), 41, pp. 509-519. , (July); Urbina, D.I., Giraldo, J.A., Cardenas, A.A., Tippenhauer, N.O., Valente, J., Faisal, M., Ruths, J., Sandberg, H., Limiting the impact of stealthy attacks on industrial control systems (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1092-1105. , ACM, New York, NY, USA; Urbina, D.I., Giraldo, J., Cardenas, A.A., Valente, J., Faisal, M., Tippenhauer, N.O., Ruths, J., Sandberg, H., Survey and new directions for physics-based attack detection in control systems (2016) NIST GCR, , 16-010; Kaestner, R., Maye, J., Pilat, Y., Siegwart, R., Generative object detection and tracking in 3d range data (2012) 2012 IEEE International Conference on Robotics and Automation, pp. 3075-3081. , (May); Chilamkurti, N., Emerging innovations in wireless networks and broadband technologies (2016) IGI Global; Getoor, L., Taskar, B., (2007) Introduction to Statistical Relational Learning, , MIT Press; Pearl, J., Fusion, propagation, and structuring in belief networks (1986) Artificial Intelligence, 29, pp. 241-288. , (Sept.); Cussens, J., Logic-based formalisms for statistical relational learning (2007) Introduction to Statistical Relational Learning [16]; Halpern, J.Y., An analysis of first-order logics of probability (1990) Artificial Intelligence, 46, pp. 311-350. , (Dec.); Raedt, L.D., Kersting, K., Natarajan, S., Poole, D., Statistical relational artificial intelligence: Logic, probability, and computation (2016) Synthesis Lectures on Artificial Intelligence and Machine Learning, 10 (2), pp. 1-189; Milch, B., Marthi, B., Russell, S., Sontag, D., Ong, D.L., Kolobov, A., BLOG: Probabilistic models with unknown objects (2007) Statistical Relational Learning, p. 373; Milch, B., Marthi, B., Sontag, D., Russell, S.J., Ong, D.L., Kolobov, A., Approximate inference for infinite contingent Bayesian networks (2005) AIStats, , 10th (2005); Milch, B.C., (2006) Probabilistic Models with Unknown Objects, , PhD thesis, Citeseer; Milch, B., Russell, S., (2012) General-purpose MCMC Inference over Relational Structures, , arXiv preprint arXiv; Russell, S., Unifying logic and probability (2015) Commun. ACM, 58, pp. 88-97. , (June); Wu, Y., Li, L., Russell, S., Bodik, R., (2016) Swift: Compiled Inference for Probabilistic Programming Languages, , arXiv preprint arXiv; Li, L., BayesianLogic/blog; Li, L., Russell, S.J., (2013) The Blog Language Reference, , tech. rep., Technical Report UCB/EECS-2013-51, EECS Department, University of California, Berkeley; (2001) Vulnerability Assessment of the Transportation Infrastructure Relying on the Global Positioning System, , tech. rep., John A. Volpe National Transportation Systems Center (Aug.); Brown, R.G., Receiver autonomous integrity monitoring (1996) Global Positioning System: Theory and Applications, 2, pp. 143-165; James, G., Witten, D., Hastie, T., Tibshirani, R., (2013) An Introduction to Statistical Learning, 112. , Springer; (2012) E-Handbook of Statistical Methods, , NIST/SEMATECH; Getting Started J Google Maps Elevation API; Introduction to the Google Maps Roads API J Google Maps Roads API; Ghahramani, Z., Probabilistic machine learning and artificial intelligence (2015) Nature, 521, p. 452. , (May); Gal, Y., (2016) Uncertainty in Deep Learning, , PhD thesis, University of Cambridge; McAllister, R., Gal, Y., Kendall, A., Van Der Wilk, M., Shah, A., Cipolla, R., Weller, A.V., Concrete problems for autonomous vehicle safety: Advantages of Bayesian deep learning (2017) International Joint Conferences on Artificial Intelligence, , Inc; Mansinghka, V., Selsam, D., Perov, Y., (2014) Venture: A Higher-order Probabilistic Programming Platform with Programmable Inference, , arXiv preprint arXiv; Tolpin, D., Van De Meent, J.-W., Yang, H., Wood, F., Design and implementation of probabilistic programming language anglican (2016) Proceedings of the 28th Symposium on the Implementation and Application of Functional Programming Languages, 6. , ACM; Kulkarni, T.D., Kohli, P., Tenenbaum, J.B., Mansinghka, V., Picture: A probabilistic programming language for scene perception (2015) Proceedings of the Ieee Conference on Computer Vision and Pattern Recognition, pp. 4390-4399; Binder, J., Koller, D., Russell, S., Kanazawa, K., Adaptive probabilistic networks with hidden variables (1997) Machine Learning, 29, pp. 213-244. , (Nov.); Yang, M., Shesheng, G., Wei, W., Unscented particle filter based Gaussian process regression for IMU/BDS train integrated positioning (2016) 2016 IEEE Information Technology, Networking, Electronic and Automation Control Conference, pp. 1070-1073. , (May)","Molina-Markham, A.D.; MITRE Corporation, 202 Burlington Road, United States; email: amolinamarkham@mitre.org","Dudzik M.C.Ricklin J.C.","The Society of Photo-Optical Instrumentation Engineers (SPIE)","SPIE","Autonomous Systems: Sensors, Vehicles, Security, and the Internet of Everything 2018","16 April 2018 through 18 April 2018",,138055,0277786X,9781510617971,PSISD,,"English","Proc SPIE Int Soc Opt Eng",Conference Paper,"Final","",Scopus,2-s2.0-85050815607
"Nikkarila J.-P., Åkesson B., Kuikka V., Hämäläinen J.","56830446100;7102928991;56830522900;14053876600;","Modelling closed national networks: Effects in cyber operation capabilities",2018,"European Conference on Information Warfare and Security, ECCWS","2018-June",,,"323","329",,2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050812169&partnerID=40&md5=19ef48cb92c3ba784135e429c7472ebf","Finnish Defence Research Agency, Riihimäki, Finland","Nikkarila, J.-P., Finnish Defence Research Agency, Riihimäki, Finland; Åkesson, B., Finnish Defence Research Agency, Riihimäki, Finland; Kuikka, V., Finnish Defence Research Agency, Riihimäki, Finland; Hämäläinen, J., Finnish Defence Research Agency, Riihimäki, Finland","We introduce a mathematical model to describe how operational capabilities are affected when a nation closes their national networks. When considering defensive capabilities, we define capability as a probability for denying adversarial operations in a friendly network so that the overall system (Cf. critical infrastructure) remains operative. We define an operation as a set of actions that are conducted against one specific subsystem. The overall system is considered to be operative when at least predefined number (M) of subsystems is operative. The probability of having exactly k operative subsystems out of N is given by the probability mass function of the Poisson binomial distribution. The probability of subsystem i being operative depends on whether it is under attack or not. Under normal conditions, the subsystem is operative with a certain probability. When the subsystem is under attack, the probability of a successful computer network defense operation of the subsystem is described as a probability for denying the operation in at least one of its step. Different subsystems are assumed to be independent. The assumption of independent subsystems is made in order to describe the solution in a closed form. It is acknowledged that a more sophisticated model is required in order to describe the effects of a closed national network in more detail. Nevertheless, the model proposed in this article extends the analysis of how a closed national network affects the operational capabilities in the overall system level. The closing process is a well-documented course of development as Russia is likely to implement ‘RuNet 2020’. The model may be used to form and improve situation awareness as the process evolves. In order to further extend the analysis it is likely that one has to consider subsystems individually and allow them to be interdependent. Furthermore, then one has to consider also effects hierarchically, introduce network modelling and study time dependency. However, one may utilize parts of this study when further deepening the analysis as described. © 2018 Curran Associates Inc. All rights reserved.","Asymmetric frontlines; Closed network nation; Cyber domain; Modeling military capability; Modelling critical infrastructure; RuNet","Computer crime; Poisson distribution; Public works; Asymmetric frontlines; Closed network nation; Cyber domain; Military capability; RuNet; Critical infrastructures",,,,,"Cioffi-Revilla, C., Mathematical contributions to the scientific understanding of war (1989) Mathematical and Computer Modelling, 12 (4-5), pp. 561-575. , Issues; Cioffi-Revilla, C., Dacey, R., The probability of war in then-crises problem: Modeling new alternatives to wright's solution (1988) Synthese, 76 (2), pp. 285-305. , August 1988; Kuikka, V., Suojanen, M., Modeling the impact of technologies and systems on military capabilities (2014) Journal of Battlefield Technology, 17 (2), pp. 9-16; Kuikka, V., Nikkarila, J.-P., Suojanen, M., A technology forecasting method for capabilities of a system of systems (2015) PICMET Conference, , 2015; Kuikka, V., Nikkarila, J.-P., Suojanen, M., Dependency of military capabilities on technological development (2015) Journal of Military Studies, 6 (2); Kuikka, V., Number of system units optimizing the capability requirements through multiple system capabilities (2016) Journal of Applied Operational Research, 8 (1), pp. 26-41; Kukkola, J., Nikkarila, J.-P., Ristolainen, M., Asymmetric frontlines' of the cyber battlefields (2017) ICCRTS 2017: 22nd Command and Control Research &amp; Technology Symposium, , November 6-8, 2017, Los Angeles USA; Kukkola, J., Nikkarila, J.-P., Ristolainen, M., Shaping cyberspace: A predictive analysis of adversarial cyber capabilities (2017) IST-145/RSM-030 Specialists’ Meeting on Predictive Analytics and Analysis in The Cyber Domain, , October 10-11, 2017, Sibiu, Romania; Kukkola, J., Ristolainen, M., Nikkarila, J.-P., Confrontation with closed network nation open network society’s choices and consequences (2017) MILCOM 2017: Military Communications and Innovation: Priorities for The Modern Warfight, , October 23-25, 2017, Baltimore, MD, USA; Kukkola, J., Ristolainen, M., Nikkarila, J.-P., (2017) GAME CHANGER: Structural Transformation of Cyberspace, , book (Finnish Defence Research Agency Publications 10) published by Finnish Defence Research Agency; Nikkarila, J.-P., Ristolainen, M., Runet 2020' - deploying traditional elements of combat power in cyberspace? (2017) ICMCIS 2017: International Conference on Military Communications and Information Systems, , May 15-16, 2017, Oulu, Finland; Poisson Binomial Distribution, , https://en.wikipedia.org/wiki/Poisson_binomial_distribution; Ristolainen, M., Should ‘runet 2020’ be taken seriously? contradictory views about cybersecurity between Russia and the west (2017) Journal on Information Warfare, 16 (4), pp. 113-131; Suojanen, M., Kuikka, V., Nikkarila, J.-P., Nurmi, J., An example of scenario-based evaluation of military capability areas – an impact assessment of alternative Systems on Operations (2015) IEEE International Systems Conference, , April 13-15, 2015, Vancouver, BC, Canada",,"Josang A.","","Curran Associates Inc.","17th European Conference on Cyber Warfare and Security, ECCWS 2018","28 June 2018 through 29 June 2018",,138026,20488602,9781911218852,,,"English","European Conf. Inf. Warfare Security, ECCWS",Conference Paper,"Final","",Scopus,2-s2.0-85050812169
"Thomas S., Tabrizi N.","57203112891;53364389900;","Adversarial Machine Learning: A Literature Review",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","10934 LNAI",,,"324","334",,3,"10.1007/978-3-319-96136-1_26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050565487&doi=10.1007%2f978-3-319-96136-1_26&partnerID=40&md5=84d9502e635230af16592cabddf4e9b2","East Carolina University, Greenville, NC  27858, United States","Thomas, S., East Carolina University, Greenville, NC  27858, United States; Tabrizi, N., East Carolina University, Greenville, NC  27858, United States","Machine learning is becoming more and more utilized as a tool for businesses and governments to aid in decision making and automation processes. These systems are also susceptible to attacks by an adversary, who may try evading or corrupting the system. In this paper, we survey the current landscape of research in this field, and provide analysis of the overall results and of the trends in research. We also identify several topics which can better define the categorization. © 2018, Springer International Publishing AG, part of Springer Nature.","Adversarial machine learning; Literature survey","Artificial intelligence; Data mining; Decision making; Pattern recognition; Surveys; Automation process; Literature reviews; Literature survey; Learning systems",,,,,"Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I.P., Tygar, J.D., Adversarial machine learning (2011) Proceedings of the 4Th ACM Workshop on Security Artificial Intelligence, pp. 43-58; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks. In: Proceedings-2016 IEEE Symposium on Security and Privacy (2016) SP, 2016, pp. 582-597; Papernot, N., McDaniel, P., Goodfellow, I., Transferability in machine learning: From phenomena to black-box attacks using adversarial samples (2016) Corr Abs/1605, p. 07277; Agrawal, R., Srikant, R., Mining sequential patterns (1995) Proceedings of the Eleventh International Conference on Data Engineering; Biggio, B., Fumera, G., Roli, F., Adversarial pattern classification using multiple classifiers and randomisation (2008) SSPR /SPR 2008. LNCS, Vol. 5342, pp. 500-509. , https://doi.org/10.1007/978-3-540-89689-0_54, da Vitoria Lobo, N., et al. (eds.), Springer, Heidelberg; Agrawal, R., Srikant, R., Mining sequential patterns (1995) Proceedings of the Eleventh International Conference on Data Engineering; Villacorta, P.J., Pelta, D.A., Exploiting adversarial uncertainty in robotic patrolling: A simulation-based analysis (2012) IPMU 2012 Part IV. CCIS, 300, pp. 529-538. , https://doi.org/10.1007/978-3-642-31724-8_55, Greco, S., et al. (eds.), Springer, Heidelberg; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings. In: Proceedings-2016 IEEE European Symposium Security Privacy (2016) EURO S P, 2016, pp. 372-387; Kumar, A., Mehta, S., A survey on resilient machine learning (2017) Corr, Abs/1707, p. 03184","Thomas, S.; East Carolina UniversityUnited States; email: thomass08@students.ecu.edu","Perner P.","","Springer Verlag","14th International Conference on Machine Learning and Data Mining in Pattern Recognition, MLDM 2018","15 July 2018 through 19 July 2018",,216139,03029743,9783319961354,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","",Scopus,2-s2.0-85050565487
"Clark G.W., Jr., Doran M.V.","57194649256;7005039519;","Machine learning security vulnerabilities in cyber-physical systems",2018,"IMCIC 2018 - 9th International Multi-Conference on Complexity, Informatics and Cybernetics, Proceedings","2",,,"41","46",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050206499&partnerID=40&md5=7569175320b115031a080f2b79528678","Department of Computer Science, School of Computing, University of South Alabama, Mobile, AL  36608, United States","Clark, G.W., Jr., Department of Computer Science, School of Computing, University of South Alabama, Mobile, AL  36608, United States; Doran, M.V., Department of Computer Science, School of Computing, University of South Alabama, Mobile, AL  36608, United States","Machine learning is increasingly being used in cyber-physical systems that include robots, autonomous vehicles, and military drones. As these cyber-physical systems are capable of inflicting harm on humans, the security of the machine learning components of these systems should be examined. This paper reviews the current research in the field of adversarial machine learning including attack surface, threat models, attack methods, and defenses. It analyzes how this research can be applied to cyber-physical systems and extends upon a previously developed embedded system attack classification to include attacks on machine learning, and provides scenarios of such attacks. Finally, future work for experimentation on machine learning attacks is proposed. © 2018 International Institute of Informatics and Systemics IIIS. All rights reserved.","Artificial intelligence; Autonomous vehicles; Cybersecurity; Machine learning; Robotics","Artificial intelligence; Cyber Physical System; Learning systems; Machine components; Military vehicles; Robotics; Attack classifications; Attack methods; Autonomous Vehicles; Cyber security; On-machines; Security vulnerabilities; Threat models; Embedded systems",,,,,"Domingos, P., A few useful things to know about machine learning (2012) Communications of the ACM, 55 (10), pp. 78-87; Simmhan, Y., Cloud-based software platform for big data analytics in smart grids (2013) Computing in Science & Engineering, 15 (4), pp. 38-47; Lee, J., Bagheri, B., Kao, H.-A., Recent advances and trends of cyber-physical systems and big data analytics in industrial informatics International Proceeding of Int Conference on Industrial Informatics (INDIN), pp. 1-6; Mearian, L., Self-driving cars could create 1GB of data a second (2013) Computerworld, 23; Louridas, P., Ebert, C., Machine learning (2016) IEEE Software, 33 (5), pp. 110-115; Kaelbling, L.P., Littman, M.L., Moore, A.W., Reinforcement learning: A survey (1996) Journal of Artificial Intelligence Research, 4, pp. 237-285; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I.P., Tygar, J.D., Adversarial machine learning (2011) Proceedings of the 4th ACM Workshop on Security and Artificial Intelligence, pp. 43-58; Papernot, N., McDaniel, P., Sinha, A., Wellman, M., (2016) Towards the Science of Security and Privacy in Machine Learning, , arXiv Preprint; Barreno, M., Nelson, B., Sears, R., Joseph, A.D., Tygar, J.D., Can machine learning be secure? Proceedings of the 2006 ACM Symposium on Information, Computer and Communications Security, pp. 16-25; Barreno, M., Nelson, B., Joseph, A.D., Tygar, J.D., The security of machine learning (2010) Machine Learning, 81 (2), pp. 121-148; Biggio, B., Security evaluation of support vector machines in adversarial environments (2014) Support Vector Machines Applications, pp. 105-153. , Springer; Biggio, B., Fumera, G., Roli, F., Security evaluation of pattern classifiers under attack (2014) IEEE Transactions on Knowledge and Data Engineering, 26 (4), pp. 984-996; Mozaffari-Kermani, M., Sur-Kolay, S., Raghunathan, A., Jha, N.K., Systematic poisoning attacks on and defenses for machine learning in healthcare (2015) IEEE Journal of Biomedical and Health Informatics, 19 (6), pp. 1893-1905; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) Security and Privacy (EuroS&P), 2016 IEEE European Symposium On, pp. 372-387. , IEEE; Nelson, B., Query strategies for evading convex-inducing classifiers (2012) Journal of Machine Learning Research, 13 (MAY), pp. 1293-1332; Biggio, B., Evasion attacks against machine learning at test time Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 387-402; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint; Szegedy, C., (2014) Intriguing Properties of Neural Networks, , arXiv preprint; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-box Attacks Using Adversarial Samples, , arXiv preprint; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., (2016) Practical Black-box Attacks Against Deep Learning Systems Using Adversarial Examples, , arXiv preprint; Nelson, B., Exploiting machine learning to subvert your spam filter (2008) LEET, 8, pp. 1-9; Colbaugh, R., Glass, K., Predictive defense against evolving adversaries Intelligence and Security Informatics (ISI), 2012 IEEE International Conference On, pp. 18-23; Goodfellow, I.J., Shlens, J., Szegedy, C., (2015) Explaining and Harnessing Adversarial Examples, , arXiv preprint; Papp, D., Ma, Z., Buttyan, L., Embedded systems security: Threats, vulnerabilities, and attack taxonomy Privacy, Security and Trust (PST), 2015 13th Annual Conference On, pp. 145-152; Morante, S., Victores, J.G., Balaguer, C., Cryptobotics: Why robots need cyber safety (2015) Frontiers in Robotics and AI, 2, p. 23; Knight, W., (2017) The Latest Driverless Cars Dont Need a Programmer Either; Petit, J., Stottelaar, B., Feiri, M., Kargl, F., Remote attacks on automated vehicles sensors: Experiments on camera and lidar (2015) Black Hat Europe, 11; Baron, E., (2016) Fully Autonomous Cars Get Lift from Gov. Jerry Brown",,"Horne J.Savoie M.Callaos N.C.Horne J.Sanchez B.Gill T.G.","International Institute of Informatics and Systemics (IIIS)","International Institute of Informatics and Systemics, IIIS","9th International Multi-Conference on Complexity, Informatics and Cybernetics, IMCIC 2018","13 March 2018 through 16 March 2018",,137350,,9781941763766,,,"English","IMCIC - Int. Multi-Conf. Complex., Informatics Cybern., Proc.",Conference Paper,"Final","",Scopus,2-s2.0-85050206499
"Strickland L., Day M.A., Demarco K., Squires E., Pippin C.","57192208023;53363364700;54893501100;57202790124;26656082500;","Responding to unmanned aerial swarm saturation attacks with autonomous counter-swarms",2018,"Proceedings of SPIE - The International Society for Optical Engineering","10635",,"106350Y","","",,7,"10.1117/12.2305086","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050195031&doi=10.1117%2f12.2305086&partnerID=40&md5=dfce98783b3912a55bcfb6d5b6ebe877","Georgia Tech Research Institute, 250 14th St., Atlanta, GA, United States","Strickland, L., Georgia Tech Research Institute, 250 14th St., Atlanta, GA, United States; Day, M.A., Georgia Tech Research Institute, 250 14th St., Atlanta, GA, United States; Demarco, K., Georgia Tech Research Institute, 250 14th St., Atlanta, GA, United States; Squires, E., Georgia Tech Research Institute, 250 14th St., Atlanta, GA, United States; Pippin, C., Georgia Tech Research Institute, 250 14th St., Atlanta, GA, United States","Autonomous unmanned aerial vehicles (UAVs) present an increasingly viable threat vector to the Defense com-munity. Existing response systems are vulnerable to saturation attacks of large swarms of low-cost autonomous vehicles. One method of reducing this threat is the use of an intelligent counter swarm with tactics, navigation and planning capabilities for engaging the adversarial swarm. Though previous studies exist that have produced libraries of basic fighter tactics employable by unmanned fixed-wing aircraft, we are aware of little prior work that explores close-in tactical engagements at a large scale (teams of at least size 10). We examine existing technologies that can be applied in fixed-wing swarm-versus-swarm engagement, including classic pursuit-evasion strategies and the application of Lanchester's laws for attrition calculations. Our recent studies center on lever- A ging existing manned fighter combat doctrine, and on the benefits of collaboration. We consider experiments in close-air combat against adversaries capable of destroying aerial targets. The following work employs both a Monte Carlo analysis in a simulation environment to measure the effectiveness of several autonomous tactics, as well as an analysis of live flight experiments in swarm competitions with up to 10 vs. 10 scenarios. © 2018 SPIE.","Autonomous UAV; Machine Learning; Motion Control; Multiagent Systems; Swarm Robotics","Antennas; Fixed wings; Flight simulators; Interoperability; Learning systems; Monte Carlo methods; Motion control; Multi agent systems; Robots; Unmanned aerial vehicles (UAV); Autonomous UAV; Autonomous unmanned aerial vehicles; Autonomous Vehicles; Monte carlo analysis; Planning capability; Saturation attacks; Simulation environment; Swarm robotics; Swarm intelligence",,,,,"Day, M., Multi-Agent Task Negotiation among UAVs to Defend Against Swarm Attacks Thesis, Monterey, , California. Naval Postgraduate School (Mar. 2012). 1.1; Cobb, B.J., (2011) Adaptive Discrete Event Simulation for Analysis of Harpy Swarm Attack, p. 11. , PhD thesis, Monterey, California. Naval Postgraduate School; Sanchez, R., (2018) Russia Uses Missiles and Cyber Warfare to Fight off 'Swarm of Drones' Attacking Military Bases in Syria, p. 11; Raley, G.C., Lewellyn, A.H., Phalanx integrated maintenance system (1996) Naval Engineers Journal, 108 (2), pp. 65-67. , 1.1; Burgin, G.H., Fogel, L., Phelps, J., An adaptive maneuvering logic computer program for the simulation of one-on-one air-to-Air combat (1975) Volume 1: General Description,"" Contractor Report CR-2582, NASA, p. 12. , Sept; Burgin, G.H., Sidor, L., (1988) Rule-based Air Combat Simulation, 12. , tech. rep., DTIC Document; Jones, R.M., Laird, J.E., Constraints on the design of a high-level model of cognition (1997) Proceedings of the Nineteenth Annual Conference of the Cognitive Science Society, pp. 358-363. , 1.2; Jones, R.M., Laird, J.E., Nielsen, P.E., Coulter, K.J., Kenny, P., Koss, F.V., Automated intelligent pilots for combat ight simulation (1999) AI Magazine, 20 (27). , Mar.). 1.2; Spicer, R., Martin, L., (1972) Tactics Ii: Maneuver Logic for Computer Simulation of Dogfight Engagements, , Scientific Report R-979-PR, RAND, Santa Monica CA, USA ). 1.2; Hague, D.S., Heuristic approach to the development of ratings and tactics applicable to the one-onone aerial combat (dogfight) encounter (1977) Technical Report NASA-CR-152000, Aerophysics Research Corp, , Bellevue, WA, United States ( July 1.2; McManus, J.W., Goodrich, K.H., Application of artificial intelligence (ai) programming techniques to tactical guidance for fighter aircraft (1989) Proceedings of the 1989 AIAA Guidance, Navigation, and Control Conference], 3525, American Institute of Aeronautics and Astronautics, , Boston, MA, United States ( Aug. 1.2; Sprinkle, J., Eklund, J.M., Kim, H.J., Sastry, S., Encoding aerial pursuit/evasion games with fixed wing aircraft into a nonlinear model predictive tracking controller (2004) Decision and Control, 2004. CDC. 43rd IEEE Conference on, 3, pp. 2609-2614. , IEEE ).1.2; Eklund, J.M., Sprinkle, J., Sastry, S., Implementing and testing a nonlinear model predictive tracking controller for aerial pursuit/evasion games on a fixed wing aircraft (2005) Proceedings of the 2005, American Control Conference, 2005, pp. 1509-1514. , IEEE ( 1.2; Virtanen, K., Raivio, T., Hämälaïnen, R.P., Modeling pilot's sequential maneuvering decisions by a multistage in uence diagram (2004) Journal of Guidance, Control, and Dynamics, 27 (4), pp. 665-677. , 1.2; Virtanen, K., Karelahti, J., Raivio, T., Modeling air combat by a moving horizon in uence diagram game (2006) Journal of Guidance, Control, and Dynamics, 29 (5), pp. 1080-1091. , 1.2; You, D.-I., Shim, D.H., Design of an aerial combat guidance law using virtual pursuit point concept,"" proceedings of the institution of mechanical engineers, part g (2015) Journal of Aerospace Engineering, 229, pp. 792-813. , (Apr; Järmark, B., Merz, A., Breakwell, J., The variable-speed tail-chase aerial combat problem (1981) Journal of Guidance, Control, and Dynamics, 4, pp. 323-328. , May 1.2; Hillberg, C., Järmark, B., Pursuit-evasion between two realistic aircraft (1984) Journal of Guidance, Control, and Dynamics, 7 (6), pp. 690-694. , 1.2; Merz, A.W., To pursue or to evade-that is the question (1985) Journal of Guidance, Control, and Dynamics, 8, pp. 161-166. , Mar. 1.2; Austin, F., Carbone, G., Hinz, H., Lewis, M., Falco, M., Game theory for automated maneuvering during air-to-Air combat (1990) Journal of Guidance, Control, and Dynamics, 13, pp. 1143-1149. , Nov.). 1.2; Greenwood, N., A differential game in three dimensions: The aerial dogfight scenario (1992) Dynamics and Control, 2 (2), pp. 161-200. , 1.2; Smith, R.E., Dike, B.A., Learning novel fighter combat maneuver rules via genetic algorithms (1995) International Journal of Expert Systems, 8 (3), pp. 247-276. , 1.2; Smith, R.E., Dike, B., Mehra, R., Ravichandran, B., El-Fallah, A., Classifier systems in combat: Two-sided learning of maneuvers for advanced fighter aircraft (2000) Computer Methods in Applied Mechanics and Engineering, 186, pp. 421-437. , June 1.2; Smith, R.E., Dike, B.A., Ravichandran, B., El-Fallah, A., Mehra, R.K., The fighter aircraft lcs: A case of different lcs goals and techniques (2000) Learning Classifier Systems, 1813, pp. 283-300. , Springer Berlin Heidelberg, Berlin, Heidelberg ( 1.2; Smith, R.E., Dike, B.A., Ravichandran, B., El-Fallah, A., Mehra, R.K., Discovering novel fighter combat maneuvers: Simulating test pilot creativity (2002) Creative Evolutionary Systems, pp. 467-486. , Bentley, P. J., and Corne, D. W., eds., Morgan Kaufmann Publishers Inc., San Francisco, CA, USA ( 1.2; Smith, R., El-Fallah, A., Ravichandran, B., Mehra, R., Dike, B., The fighter aircraft lcs: A real-world, machine innovation application (2004) Applications of Learning Classifier Systems, 150, pp. 113-142. , Springer Berlin Heidelberg, Berlin, Heidelberg ( 1.2; McGrew, J.S., (2008) Real-Time Maneuvering Decisions for Autonomous Air Combat, , PhD thesis, Massachusetts Institute of Technology ( 1.2; McGrew, J.S., How, J.P., Williams, B., Roy, N., Air-combat strategy using approximate dynamic programming Journal of Guidance, Control, and Dynamics, 33, pp. 1641-1654. , (Sept. 2010). 1.2; Ma, Y., Ma, X., Song, X., A case study on air combat decision using approximated dynamic programming (2014) Mathematical Problems in Engineering; Mulgund, S., Harper, K., Krishnakumar, K., Zacharias, G., Air combat tactics optimization using stochastic genetic algorithms (1998) Systems, Man, and Cybernetics, 1998. 1998 IEEE International Confer-ence on, 4, pp. 3136-3141. , IEEE ( 1.2; Mulgund, S., Harper, K., Zacharias, G., Large-scale air combat tactics optimization using genetic algorithms (2001) Journal of Guidance, Control, and Dynamics, 24 (1), pp. 140-142. , 1.2; Ernest, N.D., Genetic Fuzzy Trees for Intelligent Control of Unmanned Combat Aerial Vehicles, , PhD thesis, University of Cincinnati (Mar. 2015). 1.2; Ha, J.-S., Chae, H.-J., Choi, H.-L., A stochastic game-theoretic approach for analysis of multiple cooperative air combat (2015) 2015 American Control Conference (ACC, pp. 3728-3733. , IEEE (July). 1.2; Gaertner, U., (2013) UAV Swarm Tactics: An Agent-Based Simulation and Markov Process Analysis, , Master's thesis, Naval Postgraduate School, Dept. of Operations Research, Monterey CA (). 1.2.1; Feigin, P.D., Pinkas, O., Shinar, J., A simple markov model for the analysis of multiple air combat (1984) Naval Research Logistics Quarterly, 31, pp. 413-429. , Sept.). 1.2.2, 1.2.3; Hague, D., An introduction to co-kill probability estimation in the m on n encounter during combat aircraft maneuvers (1979) Guidance and Control Conference], Guidance, Navigation, and Control and Co-located Conferences, American Institute of Aeronautics and Astronautics, , Aug.). 1.2.2; Hague, D.S., Multiple-tactical aircraft combat performance evaluation system (1981) Journal of Aircraft, 18, pp. 513-520. , July). 1.2.2; Hague, D.S., Correlation of ight test and analytic m-on-n air combat exchange ratios (1983) Journal of Aircraft, 20, pp. 877-881. , Oct.). 1.2.2; Collins, A.J., (2012) Colonel Blotto Games and Lancaster's Equations: A Novel Military Modeling Combination, , (Mar.). 1.2.3; Taylor, J.G., Brown, G.G., Canonical methods in the solution of variable-coefficient lanchester-type equations of modern warfare (1976) Operations Research, 24 (1), pp. 44-69. , 1.2.3; Guelman, M., A qualitative study of proportional navigation (1971) IEEE Transactions on Aerospace and Elec-tronic Systems, 4, pp. 637-643. , 2.1.2; Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.A., Veness, J., Bellemare, M.G., Graves, A., Ostrovski, G., Human-level control through deep reinforcement learning (2015) Nature, 518 (7540), p. 529. , 2.2; Silver, D., Huang, A., Maddison, C.J., Guez, A., Sifre, L., Van Den Driessche, G., Schrittwieser, J., Lanctot, M., Mastering the game of go with deep neural networks and tree search (2016) Nature, 529 (7587), pp. 484-489. , 2.2; Mnih, V., Badia, A.P., Mirza, M., Graves, A., Lillicrap, T., Harley, T., Silver, D., Kavukcuoglu, K., Asynchronous methods for deep reinforcement learning (2016) International Conference on Machine Learning, pp. 1928-1937. , 2.2, 3.2; Schulman, J., Levine, S., Abbeel, P., Jordan, M., Moritz, P., Trust region policy optimization (2015) International Conference on Machine Learning, pp. 1889-1897. , 2.2; Schulman, J., Wolski, F., Dhariwal, P., Radford, A., Klimov, O., (2017) Proximal Policy Optimization Algorithms, , arXiv preprint ). 2.2; Lillicrap, T.P., Hunt, J.J., Pritzel, A., Heess, N., Erez, T., Tassa, Y., Silver, D., Wierstra, D., (2015) Continuous Control with Deep Reinforcement Learning, , arXiv preprint ). 2.2; Hessel, M., Modayil, J., Van Hasselt, H., Schaul, T., Ostrovski, G., Dabney, W., Horgan, D., Silver, D., (2017) Rainbow: Combining Improvements in Deep Reinforcement Learning, , arXiv preprint ). 2.2; Demarco, K., Squires, E., (2017) Scrimmage (Simulating Collaborative Robots in Massive Multi-Agent Game Execution, , (Aug).3.1.1; Berndt, J., Jsbsim: An open source ight dynamics model in c++ (2004) AIAA Modeling and Simulation Technologies Conference and Exhibit, p. 4923. , 3.2; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9 (8), pp. 1735-1780. , 3.2; Kingma, D.P., Ba, J., (2014) Adam: A Method for Stochastic Optimization, , arXiv preprint ).3.2; Balch, T., Arkin, R.C., Behavior-based formation control for multirobot teams (1998) IEEE Transactions on Robotics and Automation, 14 (6), pp. 926-939. , 4.1; Fiorini, P., Shiller, Z., Motion planning in dynamic environments using velocity obstacles (1998) The Inter-national Journal of Robotics Research, 17 (7), pp. 760-772. , 4.1; (1995) Operations Research: Deterministic Optimization Models, , Prentice Hall, Inc., Engle-wood Cliffs, NJ, 1st ed. (). 4.1,3; Toon, J., (2017) Swarms of Autonomous Aerial Vehicles Test New Dogfighting Skills, , (Apr).2; Day, M.A., Clement, M.R., Russo, J.D., Davis, D.T., Chung, T.H., Multi-uav software systems and simulation architecture (2015) 2015 International Conference on Unmanned Aircraft Systems (ICUAS, pp. 426-435. , IEEE (June). 4.1; Chung Timothy, H., Jones Kevin, D., Day Michael, A., Jones, M., Clement, M., (2013) 50 Vs. 50 by 2015: Swarm Vs. Swarm Uav Live-y Competition at the Naval Postgraduate School, , 4.1; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826. , 4.2; Szegedy, C., Reed, S., Erhan, D., Anguelov, D., Ioffe, S., (2014) Scalable, High-Quality Object Detection, , arXiv preprint ).4.2; Huang, J., Rathod, V., Sun, C., Zhu, M., Korattikara, A., Fathi, A., Fischer, I., Guadarrama, S., Speed/accuracy trade-offs for modern convolutional object detectors (2017) IEEE CVPR, , 4.2; Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G.S., Devin, M., (2016) Tensor Ow: Large-Scale Machine Learning on Heterogeneous Distributed Systems, , arXiv preprint 4.2; Hu, T., Huang, M., A new stereo matching algorithm for binocular vision (2009) Proceedings of the 2009 International Conference on Hybrid Information Technology, pp. 42-44. , ACM (4.2; Vondrick, C., Patterson, D., Ramanan, D., Efficiently scaling up crowdsourced video annotation (2013) International Journal of Computer Vision, 101 (1), pp. 184-204. , 5.4; Tian, Y., Li, X., Wang, K., Wang, F.-Y., Training and testing object detectors with virtual images (2018) IEEE/CAA Journal of Automatica Sinica, 5 (2), pp. 539-546. , 5.4; Hu, G., Peng, X., Yang, Y., Hospedales, T.M., Verbeek, J., Frankenstein: Learning deep face representations using small data (2018) IEEE Transactions on Image Processing, 27 (1), pp. 293-303. , 5.4; Rozantsev, A., Lepetit, V., Fua, P., On rendering synthetic images for training an object detector (2015) Computer Vision and Image Understanding, 137, pp. 24-37. , 5.4; Graves, A., (2016) Adaptive Computation Time for Recurrent Neural Networks, , arXiv preprint ). z; Busoniu, L., Babuska, R., De Schutter, B., A comprehensive survey of multiagent reinforcement learning (2008) IEEE Trans. Systems, Man, and Cybernetics, Part C, 38 (2), pp. 156-172. , 6.2; Bansal, T., Pachocki, J., Sidor, S., Sutskever, I., Mordatch, I., (2017) Emergent Complexity Via Multi-Agent Competition, , arXiv preprint 6.2; Hüttenrauch, M., Šošić, A., Neumann, G., (2017) Guided Deep Reinforcement Learning for Swarm Systems, , arXiv preprint 6.2; Li, Q., Du, X., Huang, Y., Sykora, Q., Schoellig, A.P., (2017) Learning of Coordination Policies for Robotic Swarms, , [cs] (Sept). 6.2","Day, M.A.; Georgia Tech Research Institute, 250 14th St., United States; email: michael.day@gtri.gatech.edu","Pham T.Kolodny M.A.Wiegmann D.M.","The Society of Photo-Optical Instrumentation Engineers (SPIE)","SPIE","Ground/Air Multisensor Interoperability, Integration, and Networking for Persistent ISR IX 2018","16 April 2018 through 18 April 2018",,137846,0277786X,9781510617810,PSISD,,"English","Proc SPIE Int Soc Opt Eng",Conference Paper,"Final","",Scopus,2-s2.0-85050195031
"Premlatha B., Pradeep Reddy K., Manoj Someswar G.","57202930059;57222625280;57202920543;","Security evaluation of pattern classifier under attack",2018,"Compusoft","7","2",,"2664","2692",,2,"10.6084/ijact.v7i2.709","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049829409&doi=10.6084%2fijact.v7i2.709&partnerID=40&md5=10e82a15d0e96304f5d38fa2128076bc","Department of Computer Science and Engineering, Tirumala Engineering college, Hyderabad, Telangana State, India; Global Research Academy-Scientific and Industrial Research Organisation (Autonomous), Hyderabad, Telangana State, India","Premlatha, B., Department of Computer Science and Engineering, Tirumala Engineering college, Hyderabad, Telangana State, India; Pradeep Reddy, K., Department of Computer Science and Engineering, Tirumala Engineering college, Hyderabad, Telangana State, India; Manoj Someswar, G., Global Research Academy-Scientific and Industrial Research Organisation (Autonomous), Hyderabad, Telangana State, India","Pattern classification systems are commonly used in adversarial applications, like biometric authentication, network intrusion detection, and spam filtering, in which data can be purposely manipulated by humans to undermine their operation. As this adversarial scenario is not taken into account by classical design methods, pattern classification systems may exhibit vulnerabilities, whose exploitation may severely affect their performance, and consequently limit their practical utility. Extending pattern classification theory and design methods to adversarial settings is thus a novel and very relevant research direction, which has not yet been pursued in a systematic way. In this paper, we address one of the main open issues: evaluating at design phase the security of pattern classifiers, namely, the performance degradation under potential attacks they may incur during operation. We propose a framework for empirical evaluation of classifier security that formalizes and generalizes the main ideas proposed in the literature, and give examples of its use in three real applications. Reported results show that security evaluation can provide a more complete understanding of the classifier's behavior in adversarial environments, and lead to better design choices. © 2018, An international journal of advanced computer technology.",,,,,,,"Rodrigues, R.N., Ling, L.L., Govindaraju, V., 'Robustness of Multimodal Biometric Fusion Methods against Spoof Attacks, ' (2009) J. Visual Languages and Computing, 20 (3), pp. 169-179; Johnson, P., Tan, B., Schuckers, S., 'Multimodal Fusion Vulnerability to Non-Zero Effort (Spoof) Imposters, ' (2010) Proc. IEEE Int'l Workshop Information Forensics and Security, pp. 1-5; Fogla, P., Sharif, M., Perdisci, R., Kolesnikov, O., Lee, W., 'Polymorphic Blending Attacks, ' (2006) Proc. 15th Conf. USENIX Security Symp; Wittel, G.L., Wu, S.F., 'On Attacking Statistical Spam Filters, ' (2004) Proc. First Conf. Email and Anti-Spam; Lowd, D., Meek, C., 'Good Word Attacks on Statistical Spam Filters, ' (2005) Proc. Second Conf. Email and AntiSpam; Kolcz, A., Teo, C.H., 'Feature Weighting for Improved Classifier Robustness, ' (2009) Proc. Sixth Conf. Email and Anti-Spam; Skillicorn, D.B., 'Adversarial Knowledge Discovery, ' (2009) IEEE Intelligent Systems, 24 (6). , Nov./Dec; Fetterly, D., (2007) 'Adversarial Information Retrieval: The Manipulation of Web Content, ', , ACM Computing Rev; Duda, R.O., Hart, P.E., Stork, D.G., (2000) Pattern Classification, , Wiley-Interscience Publication; Dalvi, N., Domingos, P., Mausam, Sanghai, S., Verma, D., 'Adversarial Classification, ' (2004) Proc. 10th ACM SIGKDD Int'l Conf. Knowledge Discovery and Data Mining, pp. 99-108; Barreno, M., Nelson, B., Sears, R., Joseph, A.D., Tygar, J.D., 'Can Machine Learning be Secure'' (2006) Proc. ACM Symp. Information, Computer and Comm. Security (ASIACCS), pp. 16-25; Cardenas, A.A., Baras, J.S., 'Evaluation of Classifiers: Practical Considerations for Security Applications, ' (2006) Proc. AAAI Workshop Evaluation Methods for Machine Learning; Laskov, P., Lippmann, R., 'Machine Learning in Adversarial Environments, ' (2010) Machine Learning, 81, pp. 115-119; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B., Tygar, J.D., 'Adversarial Machine Learning, ' (2011) Proc. Fourth ACM Workshop Artificial Intelligence and Security, pp. 43-57; Barreno, M., Nelson, B., Joseph, A., Tygar, J., 'The Security of Machine Learning, ' (2010) Machine Learning, 81, pp. 121-148; Lowd, D., Meek, C., 'Adversarial Learning, ' (2005) Proc. 11th ACM SIGKDD Int'l Conf. Knowledge Discovery and Data Mining, pp. 641-647; Laskov, P., Kloft, M., 'A Framework for Quantitative Security Analysis of Machine Learning, ' (2009) Proc. Sec ond ACM Workshop Security and Artificial Intelligence, pp. 1-4; (2007) NIPS Workshop Machine Learning in Adversarial Environments for Computer Security, , http://mlsnips07.first.fraunhofer.de/; (2012) Dagstuhl Perspectives Workshop Mach. Learning Methods for Computer Sec, , http://www.dagstuhl.de/12371/; Narasimhamurthy, A.M., Kuncheva, L.I., 'A Framework for Generating Data to Simulate Changing Environments, ' (2007) Proc. 25 th Conf. Proc. the 25th IASTED Int'l Multi-Conf.: Artificial Intelligence and Applications, pp. 415-420; Rizzi, S., 'What-If Analysis, ' (2009) Encyclopedia of Database Systems, pp. 3525-3529. , Springer; Newsome, J., Karp, B., Song, D., 'Paragraph: Thwarting Signature Learning by Training Maliciously, ' (2006) Proc. Ninth Int'l Conf. Recent Advances in Intrusion Detection, pp. 81-105; Globerson, A., Roweis, S.T., 'Nightmare at Test Time: Robust Learning by Feature Deletion, ' (2006) Proc. 23rd Int'l Conf. Machine Learning, pp. 353-360; Perdisci, R., Gu, G., Lee, W., 'Using an Ensemble of One-Class SVM Classifiers to Harden Payload-Based Anomaly Detection Systems, ' (2006) Proc. Int'l Conf. Data Mining, pp. 488-498; Chung, S.P., Mok, A.K., 'Advanced Allergy attacks: Does a Corpus Really Help, ' (2007) Proc. 10th Int'l Conf. Recent Advances in Intrusion Detection (RAID '07), pp. 236-255; Jorgensen, Z., Zhou, Y., Inge, M., 'A Multiple Instance Learning Strategy for Combating Good Word Attacks on Spam Filters, ' (2008) J. Machine Learning Research, 9, pp. 1115-1146; Cretu, G.F., Stavrou, A., Locasto, M.E., Stolfo, S.J., Keromytis, A.D., 'Casting out Demons: Sanitizing Training Data for Anomaly Sensors, ' (2008) Proc. IEEE Symp. Security and Privacy, pp. 81-95; Nelson, B., Barreno, M., Chi, F.J., Joseph, A.D., Rubinstein, B.I.P., Saini, U., Sutton, C., Xia, K., 'Exploiting Machine Learning to Subvert Your Spam Filter, ' (2008) Proc. First Workshop Large-Scale Exploits and Emergent Threats, pp. 1-9; Rubinstein, B.I., Nelson, B., Huang, L., Joseph, A.D., Lau, S.-H., Rao, S., Taft, N., Tygar, J.D., 'Antidote: Understanding and Defending against Poisoning of Anomaly Detectors, ' (2009) Proc. Ninth ACM SIGCOMM Internet Measurement Conf. (IMC '09), pp. 1-14; Kloft, M., Laskov, P., 'Online Anomaly Detection under Adversarial Impact, ' (2010) Proc. 13th Int'l Conf. Artificial Intelligence and Statistics, pp. 405-412; Dekel, O., Shamir, O., Xiao, L., 'Learning to Classify with Missing and Corrupted Features, ' (2010) Machine Learning, 81, pp. 149-178; Biggio, B., Fumera, G., Roli, F., 'Design of Robust Classifiers for Adversarial Environments, ' (2011) Proc. IEEE Int'l Conf. Systems, Man, and Cybernetics, pp. 977-982; Biggio, B., Fumera, G., Roli, F., 'Multiple Classifier Systems for Robust Classifier Design in Adversarial Environments, ' (2010) Int'l J. Machine Learning and Cybernetics, 1 (1), pp. 27-41; Biggio, B., Corona, I., Fumera, G., Giacinto, G., Roli, F., 'Bagging Classifiers for Fighting Poisoni ng Attacks in Adversarial Environments, ' (2011) Proc. 10th Int'l Workshop Multiple Classifier Systems, pp. 350-359; Biggio, B., Fumera, G., Roli, F., Didaci, L., 'Poisoning Adaptive Biometric Systems, ' (2012) Proc. Joint IAPR Int'l Conf. Structural, Syntactic, and Statistical Pattern Recognition, pp. 417-425; Biggio, B., Nelson, B., Laskov, P., 'Poisoning Attacks against Support Vector Machines, ' (2012) Proc. 29th Int'l Conf. Machine Learning; Kearns, M., Li, M., 'Learning in the Presen ce of Malicious Errors, ' (1993) SIAM J. Computing, 22 (4), pp. 807-837; Cardenas, A.A., Baras, J.S., Seamon, K., 'A Framework for the Evaluation of Intrusion Detection Systems, ' (2006) Proc. IEEE Symp. Security and Privacy, pp. 63-77; Biggio, B., Fumera, G., Roli, F., 'Multiple Classifier Systems for Adversarial Classification Tasks, ' (2009) Proc. Eighth Int'l Workshop Multiple Classifier Systems, pp. 132-141; Brückner, M., Kanzow, C., Scheffer, T., 'Static Prediction Games for Adversarial Learning Problems, ' (2012) J. Machine Learning Research, 13, pp. 2617-2654; Adler, A., 'Vulnerabilities in Biometric Encryption Systems, ' (2005) Proc. Fifth Int'l Conf. Audio-and Video-Based Biometric Person Authentication, pp. 1100-1109; Efron, B., Tibshirani, R.J., (1993) An Introduction to the Bootstrap, , Chapman & Hall; Drucker, H., Wu, D., Vapnik, V.N., 'Support Vector Machines for Spam Categorization, ' (1999) IEEE Trans. Neural Networks, 10 (5), pp. 1048-1054. , Sept; Sebastiani, F., 'Machine Learning in Automated Text Categorization, ' (2002) ACM Computing Surveys, 34, pp. 1-47; Chang, C.-C., Lin, C.-J., (2001) 'LibSVM: A Library for Support Vector Machines, ', , http://www.csie.ntu.edu.tw/~cjlin/libsvm/; Nandakumar, K., Chen, Y., Dass, S.C., Jain, A., 'Likelihood Ratio-Based Biometric Score Fusion, ' (2008) IEEE Trans. Pattern Analysis and Machine Intelligence, 30 (2), pp. 342-347. , Feb; Biggio, B., Akhtar, Z., Fumera, G., Marcialis, G., Roli, F., 'Robustness of Multi-Modal Biometric Verification Systems under Realistic Spoofing Attacks, ' (2011) Proc. Int'l Joint Conf. Biometrics, pp. 1-6; Biggio, B., Akhtar, Z., Fumera, G., Marcialis, G.L., Roli, F., 'Security Evaluation of Biometric Au thentication Systems under Real Spoofing Attacks, ' (2012) IET Biometrics, 1 (1), pp. 11-24; Wang, K., Stolfo, S.J., 'Anomalous Payload-Based Network Intrusion Detection, ' (2004) Proc. Seventh Symp. Recent Advances in Intrusion Detection (RAID), pp. 203-222; Schölkopf, B., Smola, A.J., Williamson, R.C., Bartlett, P.L., 'New Support Vector Algorithms, ' (2000) Neural Computation, 12 (5), pp. 1207-1245; Ingham, K., Inoue, H., 'Comparing Anomaly Detection Techniques for http, ' (2007) Proc. 10th Int'l Conf. Recent Advances in Intrusion Detection, pp. 42-62; Sculley, D., Wachman, G., Brodley, C.E., 'Spam Filtering Using Inexact String Matching in Explicit Feature Space with on-Line Linear Classifiers, ' (2006) Proc. 15th Text Retrieval Conf; (2009), Encyclopedia of Biometrics, S.Z. Li, and A.K. Jain, eds., Springer US; Biggio, B., Fumera, G., Roli, F., 'Adversarial Pattern Classification Using Multiple Classifiers and Randomisation, ' (2008) Proc. Joint IAPR Int'l Workshop Structural, Syntactic, and Statistical Pattern Recognition, pp. 500-509",,,,"National Institute of Science Communication and Information Resources (NISCAIR)",,,,,23200790,,,,"English","Compusoft",Article,"Final","",Scopus,2-s2.0-85049829409
"Asadi N., Rege A., Obradovic Z.","57212911015;56165469100;57156081500;","Assessment of group dynamics during cyber crime through temporal network topology",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","10899 LNCS",,,"401","407",,1,"10.1007/978-3-319-93372-6_44","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049797748&doi=10.1007%2f978-3-319-93372-6_44&partnerID=40&md5=010c8ac315149a63abbd8a5d5feddd3b","Computer and Information Sciences Department, Temple University, Philadelphia, United States; Department of Criminal Justice, Temple University, Philadelphia, United States","Asadi, N., Computer and Information Sciences Department, Temple University, Philadelphia, United States; Rege, A., Department of Criminal Justice, Temple University, Philadelphia, United States; Obradovic, Z., Computer and Information Sciences Department, Temple University, Philadelphia, United States","Understanding group dynamics can provide valuable insight into how the adversaries progress through cyberattacks and adapt to any disruptions they encounter. However, capturing the characteristics of such dynamics is a difficult task due to complexities in the formation and focus of the adversarial team throughout the attack. In this study, we propose an approach based on concepts and measures of social network theory. The results of experiments performed on observations at the US Industrial Control Systems Computer Emergency Response Team’s (ICS-CERT) Red Team-Blue Team cybersecurity training exercise held at Idaho National Laboratory (INL) show that the team dynamics can be captured and characterized using the proposed approach. Moreover, we provide an analysis of the shifts in such dynamics due to the adversarial team’s adaptation to disruptions caused by the defenders. © 2018, Springer International Publishing AG, part of Springer Nature.","Group dynamics; Machine learning; Network theory","Circuit theory; Computation theory; Computer control systems; Group theory; Intelligent control; Learning systems; Computer emergency response teams; Cyber security; Cyber-attacks; Group dynamics; Idaho national laboratories; Industrial control systems; Temporal networks; Training exercise; Dynamics",,,,,"Rege, A., Obradovic, Z., Asadi, N., Singer, B., Masceri, N., A temporal assessment of cyber intrusion chains using multidisciplinary frameworks and methodologies (2017) 2017 International Conference on Cyber Situational Awareness, Data Analytics and Assessment (Cyber SA), Pp. 1–7. IEEE, June; Rege, A., Obradovic, Z., Asadi, N., Parker, E., Masceri, N., Singer, B., Pandit, R., Using a real-time cybersecurity exercise case study to understand temporal characteristics of cyberattacks (2017) Sbp-Brims 2017. LNCS, pp. 127-132. , https://doi.org/10.1007/978-3-319-60240-016, Lee, D., Lin, Y.-R., Osgood, N., Thomson, R. (eds.), Springer, Cham; Cloppert, M., (2009) Security Intelligence: Attacking the Cyber Kill Chain, , http://digital-forensics.sans.org/blog/2009/10/14/security-intelligence-attacking-the-kill-chain, Accessed 2 Feb 2014; Colbaugh, R., Glass, K., Proactive Defense for Evolving Cyber Threats (2012) San-Dia National Laboratories [SAND2012-10177], , https://fas.org/irp/eprint/proactive.pdf, Accessed 15 Feb 2017; Leclerc, B., Crime scripts (2016) Environmental Criminology and Crime Analysis; Krause, J., Croft, D.P., James, R., Social network theory in the behavioural sciences: Potential applications (2007) Behav. Ecol. Sociobiol., 62 (1), pp. 15-27; Rokach, L., Maimon, O., Clustering methods (2005) Data Mining and Knowledge Discovery Handbook, pp. 321-352. , https://doi.org/10.1007/0-387-25465-X15, Maimon, O., Rokach, L. (eds.), Springer, Boston; Schneider, R., (2011) Survey of Peaks/Valleys Identification in Time Series, , University of Zurich, Switzerland; Ellens, W., Kooij, R.E., (2013) Graph Measures and Network Robustness, , arXiv preprint arXiv","Asadi, N.; Computer and Information Sciences Department, United States; email: nima.asadi@temple.edu","Bisgin H.Thomson R.Hyder A.Dancy C.","The Army Research Office;The National Science Foundation;The Office of Naval Research","Springer Verlag","11th International Conference on Social Computing, Behavioral-Cultural Modeling, and Prediction conference and Behavior Representation in Modeling and Simulation, SBP-BRiMS 2018","10 July 2018 through 13 July 2018",,215559,03029743,9783319933719,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","",Scopus,2-s2.0-85049797748
"Kılınç H., Vaudenay S.","57191333336;22434023500;","Secure contactless payment",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","10946 LNCS",,,"579","597",,2,"10.1007/978-3-319-93638-3_33","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049772654&doi=10.1007%2f978-3-319-93638-3_33&partnerID=40&md5=f31db20620ba872078a7dff3bbdd989e","EPFL, Lausanne, Switzerland","Kılınç, H., EPFL, Lausanne, Switzerland; Vaudenay, S., EPFL, Lausanne, Switzerland","A contactless payment lets a card holder execute payment without any interaction (e.g., entering PIN or signing) between the terminal and the card holder. Even though the security is the first priority in a payment system, the formal security model of contactless payment does not exist. Therefore, in this paper, we design an adversarial model and define formally the contactless-payment security against malicious cards and malicious terminals including relay attacks. Accordingly, we design a contactless-payment protocol and show its security in our security model. At the end, we analyze EMV-contactless which is a commonly used specification by most of the mobile contactless-payment systems and credit cards in Europe. We find that it is not secure against malicious cards. We also prove its security against malicious terminals in our model. This type of cryptographic proof has not been done before for the EMV specification. © Springer International Publishing AG, part of Springer Nature 2018.",,"Security of data; Contact less; Contactless payment; Credit cards; Formal security models; Payment systems; Relay attack; Security model; Specifications",,,,,"Contactless Payment Market by Solution (Payment Terminal, Mobile Payment, Transaction and Data Management, Security and Fraud Management), Service (Pro-Fessional, Managed), Payment Mode (Mobile Handsets, Smart Cards), Vertical-Global Forecast to 2021, , https://www.marketsandmarkets.com/Market-Reports/contactless-payments-market-1313.html; EMV Acquirer and Terminal Security Guidelines; EMV Contactless Specifications for Payment Systems, Book C-2: Kernel 2 Specification; EMV Integrated Circuit Card Specifications for Payment Systems, Book 2: Security and Key Management; (2014) EMV Contactless Specifications for Payment Systems, Version 2.4; Avoine, G., Bultel, X., Gambs, S., Gérault, D., Lafourcade, P., Onete, C., Robert, J.-M., A terrorist-fraud resistant and extractor-free anonymous distance-bounding protocol (2017) Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, pp. 800-814. , ACM; Bond, M., Choudary, M.O., Murdoch, S.J., Skorobogatov, S., Anderson, R., Be prepared: The EMV preplay attack (2015) IEEE Secur. Priv., 13 (2), pp. 56-64; Bond, M., Choudary, O., Murdoch, S.J., Skorobogatov, S., Anderson, R., Chip and skim: Cloning EMV cards with the pre-play attack (2014) 2014 IEEE Symposium on Security and Privacy (SP), pp. 49-64. , IEEE; Boureanu, I., Mitrokotsa, A., Vaudenay, S., Secure and lightweight distance-bounding (2013) Lightsec 2013. LNCS, 8162, pp. 97-113. , https://doi.org/10.1007/978-3-642-40392-7_8, Avoine, G., Kara, O. (eds.), Springer, Heidelberg; Boureanu, I., Vaudenay, S., Optimal proximity proofs (2015) Inscrypt 2014. LNCS, 8957, pp. 170-190. , https://doi.org/10.1007/978-3-319-16745-9_10, Lin, D., Yung, M., Zhou, J. (eds.), Springer, Cham; Brands, S., Chaum, D., Distance-bounding protocols (Extended abstract) (1994) EUROCRYPT 1993. LNCS, 765, pp. 344-359. , https://doi.org/10.1007/3-540-48285-7_30, Helleseth, T. (ed.), Springer, Heidelberg; Bultel, X., Gambs, S., Gérault, D., Lafourcade, P., Onete, C., Robert, J.-M., A prover-anonymous and terrorist-fraud resistant distance-bounding protocol (2016) Proceedings of the 9Th ACM Conference on Security & Privacy in Wireless and Mobile Networks, pp. 121-133. , ACM; Chandran, N., Goyal, V., Moriarty, R., Ostrovsky, R., Position based cryptography (2009) CRYPTO 2009. LNCS, 5677, pp. 391-407. , https://doi.org/10.1007/978-3-642-03356-8_23, Halevi, S. (ed.), Springer, Heidelberg; Chothia, T., Garcia, F.D., de Ruiter, J., van den Breekel, J., Thompson, M., Relay cost bounding for contactless EMV payments (2015) FC 2015. LNCS, 8975, pp. 189-206. , https://doi.org/10.1007/978-3-662-47854-7_11, Böhme, R., Okamoto, T. (eds.), Springer, Heidelberg; Clulow, J., Hancke, G.P., Kuhn, M.G., Moore, T., So near and yet so far: Distance-bounding attacks in wireless networks (2006) ESAS 2006. LNCS, 4357, pp. 83-97. , https://doi.org/10.1007/11964254_9, Buttyán, L., Gligor, V.D., Westhoff, D. (eds.), Springer, Heidelberg; Cremers, C., Rasmussen, K.B., Schmidt, B., Capkun, S., Distance hijacking attacks on distance bounding protocols (2012) 2012 IEEE Symposium on Security and Privacy (SP), pp. 113-127. , IEEE; Drimer, S., Murdoch, S.J., Keep your enemies close: Distance bounding against smartcard relay attacks (2007) USENIX Security Symposium, 312; Francillon, A., Danev, B., Capkun, S., Relay attacks on passive keyless entry and start systems in modern cars (2011) NDSS; Francis, L., Hancke, G., Mayes, K., Markantonakis, K., Practical NFC peer-to-peer relay attack using mobile phones (2010) Rfidsec 2010. LNCS, 6370, pp. 35-49. , https://doi.org/10.1007/978-3-642-16822-2_4, Ors Yalcin, S.B. (ed.), Springer, Heidelberg; Kılınç, H., Vaudenay, S., Efficient public-key distance bounding protocol (2016) ASIACRYPT 2016. LNCS, 10032, pp. 873-901. , https://doi.org/10.1007/978-3-662-53890-6_29, Cheon, J.H., Takagi, T. (eds.), Springer, Heidelberg; Kılınç, H., Vaudenay, S., Contactless access control based on distance bounding (2017) ISC 2017. LNCS, 10599, pp. 195-213. , https://doi.org/10.1007/978-3-319-69659-1_11, Nguyen, P., Zhou, J. (eds.), Springer, Cham; Markantonakis, K., Francis, L., Hancke, G., Mayes, K., Practical relay attack on contactless transactions by using NFC mobile phones (2012) Radio Frequency Identification System Security: Rfidsec, 12, p. 21; Roland, M., Langer, J., (2013) Cloning Credit Cards: A Combined Pre-Play and Downgrade Attack on EMV Contactless, , WOOT; Vaudenay, S., On modeling terrorist frauds (2013) Provsec 2013. LNCS, 8209, pp. 1-20. , https://doi.org/10.1007/978-3-642-41227-1_1, Susilo, W., Reyhanitabar, R. (eds.), Springer, Heidelberg; Vaudenay, S., On privacy for RFID (2015) Provsec 2015. LNCS, 9451, pp. 3-20. , https://doi.org/10.1007/978-3-319-26059-4_1, Au, M.-H., Miyaji, A. (eds.), Springer, Cham; Vaudenay, S., Private and secure public-key distance bounding: Application to NFC payment (2015) FC 2015. LNCS, 8975, pp. 207-216. , https://doi.org/10.1007/978-3-662-47854-7_12, Böhme, R., Okamoto, T. (eds.), Springer, Heidelberg; Vaudenay, S., Sound proof of proximity of knowledge (2015) Provsec 2015. LNCS, 9451, pp. 105-126. , https://doi.org/10.1007/978-3-319-26059-4_6, Au, M.-H., Miyaji, A. (eds.), Springer, Cham; Weiß, M., (2010) Performing Relay Attacks on ISO 14443 Contactless Smart Cards Using NFC Mobile Equipment, , Master’s thesis in Computer Science, University of Munich","Kılınç, H.; EPFLSwitzerland; email: handan.kilinc@epfl.ch","Susilo W.Yang G.","Australian Government Department of Defence Science and Technology;Cryptography - Open Access Journal by MDPI;DATA61;et al;School of Computing and Information Technology;Springer","Springer Verlag","23rd Australasian Conference on Information Security and Privacy, ACISP 2018","11 July 2018 through 13 July 2018",,215579,03029743,9783319936376,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85049772654
"Barbar M., Sui Y., Zhang H., Chen S., Xue J.","57202886844;54788439800;57202801696;35241832100;7202881461;","Live path CFI against control flow hijacking attacks",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","10946 LNCS",,,"768","779",,1,"10.1007/978-3-319-93638-3_45","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049771195&doi=10.1007%2f978-3-319-93638-3_45&partnerID=40&md5=63f31c6e214464b01ede0832e066122a","University of Technology Sydney, Sydney, Australia; University of Newcastle, Callaghan, Australia; CSIRO/Data61, Sydney, Australia; University of New South Wales, Sydney, Australia","Barbar, M., University of Technology Sydney, Sydney, Australia; Sui, Y., University of Technology Sydney, Sydney, Australia; Zhang, H., University of Newcastle, Callaghan, Australia; Chen, S., CSIRO/Data61, Sydney, Australia; Xue, J., University of New South Wales, Sydney, Australia","Through memory vulnerabilities, control flow hijacking allows an attacker to force a running program to execute other than what the programmer has intended. Control Flow Integrity (CFI) aims to prevent the adversarial effects of these attacks. CFI attempts to enforce the programmer’s intent by ensuring that a program only runs according to a control flow graph (CFG) of the program. The enforced CFG can be built statically or dynamically, and Per-Input Control Flow Integrity (PICFI) represents a recent advance in dynamic CFI techniques. PICFI begins execution with the empty CFG of a program and lazily adds edges to the CFG during execution according to concrete inputs. However, this CFG grows monotonically, i.e., edges are never removed when corresponding control flow transfers become illegal. This paper presents LPCFI, Live Path Control Flow Integrity, to more precisely enforce forward edge CFI using a dynamically computed CFG by both adding and removing edges for all indirect control flow transfers from indirect callsites, thereby raising the bar against control flow hijacking attacks. © Springer International Publishing AG, part of Springer Nature 2018.","Control Flow Integrity","Data flow analysis; Security of data; Control flow graphs; Control flows; Control-flow integrities; Indirect control; Path control; Flow graphs",,,,,"Shacham, H., The geometry of innocent flesh on the bone: Return-into-libc without function calls (on the x86) (2007) CCS 2007, pp. 552-561; Schuster, F., Tendyck, T., Liebchen, C., Davi, L., Sadeghi, A.-R., Holz, T., Counterfeit object-oriented programming: On the difficulty of preventing code reuse attacks in C++ applications (2015) S&P 2015, pp. 745-762; Abadi, M., Budiu, M., Erlingsson, Ú., Ligatti, J., Control-flow integrity principles, implementations, and applications (2009) ACM Trans. Inf. Syst. Secur., 13 (1), pp. 4:1–4:40; Niu, B., Tan, G., Per-input control-flow integrity (2015) CCS 2015; Evans, I., Long, F., Otgonbaatar, U., Shrobe, H., Rinard, M., Okhravi, H., Sidiroglou-Douskos, S., Control jujutsu: On the weaknesses of fine-grained control flow integrity (2015) CCS 2015, pp. 901-913; Sui, Y., Xue, J., SVF: Interprocedural static value-flow analysis in LLVM (2016) CC 2016, pp. 265-266; Ding, R., Qian, C., Song, C., Harris, B., Kim, T., Lee, W., Efficient protection of path-sensitive control security (2017) USENIX Security 2017, pp. 131-148; Sinnadurai, S., Zhao, Q., Wong, W.-F., (2008) Transparent Runtime Shadow Stack: Protection against Malicious Return Address Modifications; Erlingsson, Ú., Abadi, M., Vrable, M., Budiu, M., Necula, G.C., XFI: Software guards for system address spaces (2006) OSDI 2006, pp. 75-88; Tice, C., Roeder, T., Collingbourne, P., Checkoway, S., Erlingsson, Ú., Lozano, L., Pike, G., Enforcing forward-edge control-flow integrity in GCC & LLVM (2014) USENIX Security 2014, pp. 941-955; Zhang, C., Carr, S.A., Li, T., Ding, Y., Song, C., Payer, M., Song, D., VTrust: Regaining trust on virtual calls (2016) NDSS 2016; Jang, D., Tatlock, Z., Lerner, S., SafeDispatch: Securing C++ virtual calls from memory corruption attacks (2014) NDSS 2014; Haller, I., Göktaş, E., Athanasopoulos, E., Portokalidis, G., Bos, H., ShrinkWrap: VTable protection without loose ends (2015) ACSAC 2015, pp. 341-350; Fan, X., Sui, Y., Liao, X., Xue, J., Boosting the precision of virtual call integrity protection with partial pointer analysis for C++ (2017) ISSTA 2017, pp. 329-340; Barbar, M., Sui, Y., Zhang, H., Chen, S., Xue, J., Live path control flow integrity (2018) ICSE 2018; Sui, Y., Xue, J., On-demand strong update analysis via value-flow refinement (2016) FSE 2016, pp. 460-473; Castro, M., Costa, M., Harris, T., Securing software by enforcing data-flow integrity (2016) OSDI 2016, pp. 147-160; Kuznetsov, V., Szekeres, L., Payer, M., Candea, G., Sekar, R., Song, D., Code-pointer integrity (2014) OSDI 2014, pp. 147-163","Barbar, M.; University of Technology SydneyAustralia; email: mbarbar@runbox.com","Susilo W.Yang G.","Australian Government Department of Defence Science and Technology;Cryptography - Open Access Journal by MDPI;DATA61;et al;School of Computing and Information Technology;Springer","Springer Verlag","23rd Australasian Conference on Information Security and Privacy, ACISP 2018","11 July 2018 through 13 July 2018",,215579,03029743,9783319936376,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","",Scopus,2-s2.0-85049771195
"Chen Y., Wang W., Zhang X.","57202790123;56948560600;9238032200;","Randomizing SVM against adversarial attacks under uncertainty",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","10939 LNAI",,,"556","568",,2,"10.1007/978-3-319-93040-4_44","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049373377&doi=10.1007%2f978-3-319-93040-4_44&partnerID=40&md5=79ecfb0170aa4b909f1fcbe396e29fec","Columbia University, New York, United States; Beijing Jiaotong University, Beijing, China; King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia","Chen, Y., Columbia University, New York, United States; Wang, W., Beijing Jiaotong University, Beijing, China; Zhang, X., King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia","Robust machine learning algorithms have been widely studied in adversarial environments where the adversary maliciously manipulates data samples to evade security systems. In this paper, we propose randomized SVMs against generalized adversarial attacks under uncertainty, through learning a classifier distribution rather than a single classifier in traditional robust SVMs. The randomized SVMs have advantages on better resistance against attacks while preserving high accuracy of classification, especially for non-separable cases. The experimental results demonstrate the effectiveness of our proposed models on defending against various attacks, including aggressive attacks with uncertainty. © Springer International Publishing AG, part of Springer Nature 2018.","Adversarial learning; Randomization; Robust SVM","Data mining; Support vector machines; Adversarial environments; Adversarial learning; Data sample; High-accuracy; Randomization; Robust SVM; Various attacks; Learning algorithms",,,,,"Alabdulmohsin, I.M., Gao, X., Zhang, X., Adding robustness to support vector machines against adversarial reverse engineering (2014) CIKM, pp. 231-240; Barreno, M., Nelson, B., Sears, R., Joseph, A.D., Tygar, J.D., Can machine learning be secure? (2006) Proceedings of the 2006 ACM Symposium on Information, Computer and Communications Security, pp. 16-25; Bi, J., Zhang, T., Support vector classification with input data uncertainty (2004) NIPS, pp. 161-168; Biggio, B., Security evaluation of support vector machines in adversarial environments (2014) Support Vector Machines Applications, pp. 105-153. , https://doi.org/10.1007/978-3-319-02300-74, Ma, Y., Guo, G. (eds.), Springer, Cham; Biggio, B., Nelson, B., Laskov, P., Support vector machines under adversarial label noise (2011) Proceedings of the 3Rd Asian Conference on Machine Learning, pp. 97-112; Brückner, M., Kanzow, C., Scheffer, T., Static prediction games for adversarial learning problems (2012) J. Mach. Learn. Res., 13 (1), pp. 2617-2654; Dalvi, N., Domingos, P., Sanghai, M., Verma, D., Adversarial classification (2004) SIGKDD, pp. 99-108; Dekel, O., Shamir, O., Xiao, L., Learning to classify with missing and corrupted features (2010) Mach. Learn., 81 (2), pp. 149-178; Globerson, A., Roweis, S., Nightmare at test time: Robust learning by feature deletion (2006) ICML, pp. 353-360; Großhans, M., Sawade, C., Brückner, M., Scheffer, T., Bayesian games for adversarial regression problems (2013) ICML, pp. 55-63; Xu, H., Caramanis, C., Mannor, S., Robustness and regularization of support vector machines (2009) J. Mach. Learn. Res., 10, pp. 1485-1510; Xu, L., Crammer, K., Schuurmans, D., Robust support vector machine training via convex outlier ablation (2006) AAAI, pp. 536-542; Zhou, Y., Kantarcioglu, M., Thuraisingham, B., Xi, B., Adversarial support vector machine learning (2012) SIGKDD, pp. 1059-1067","Zhang, X.; King Abdullah University of Science and Technology (KAUST)Saudi Arabia; email: xiangliang.zhang@kaust.edu.sa","Webb G.I.Phung D.Ganji M.Rashidi L.Tseng V.S.Ho B.","Deakin University as the host institution;Trusting Social;University of Melbourne","Springer Verlag","22nd Pacific-Asia Conference on Advances in Knowledge Discovery and Data Mining, PAKDD 2018","3 June 2018 through 6 June 2018",,214589,03029743,9783319930398,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85049373377
[No author name available],[No author id available],"7th International Conference on Artificial Intelligence and Mobile Services, AIMS 2018 Held as Part of the Services Conference Federation, SCF 2018",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","10970 LNCS",,,"","",259,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049370959&partnerID=40&md5=2c61da6620186628b626d7d6226c2342",,"","The proceedings contain 20 papers. The special focus in this conference is on Artificial Intelligence and Mobile Services. The topics include: Relaxed event-triggered control of networked control systems under denial of service attacks; sentiment analysis based on hybrid bi-attention mechanism in mobile application; automotive diagnostics as a service: An artificially intelligent mobile application for tire condition assessment; AICDS: An infant crying detection system based on lightweight convolutional neural network; exploring trends of lung cancer research based on word representation; effective facial obstructions removal with enhanced cycle-consistent generative adversarial networks; applied analysis of social network data in personal credit evaluation; deep neural network based frame reconstruction for optimized video coding; detection and tracking of moving objects for indoor mobile robots with a low-cost laser scanner; multi-modal multi-scale speech expression evaluation in computer-assisted language learning; using It/Is applications to empower physically challenged individuals to enjoy a high quality of life; From global to local: A context-embedded LSTM recurrent network for local content popularity prediction; Matching low-quality photo to DSLR-quality with deep convolutional networks; learning frame-level recurrent neural networks representations for query-by-example spoken term detection on mobile devices; plant identification based on image set analysis; economic index forecasting via multi-scale recursive dynamic factor analysis; sub goal oriented A* search; towards efficient mobile augmented reality in indoor environments.",,,,,,,,,"Yang Y.Zhang L.Zou Y.Aiello M.","","Springer Verlag","7th International Conference on Artificial Intelligence and Mobile Services, AIMS 2018 Held as Part of the Services Conference Federation, SCF 2018","25 June 2018 through 30 June 2018",,214859,03029743,9783319943602,,,"English","Lect. Notes Comput. Sci.",Conference Review,"Final","",Scopus,2-s2.0-85049370959
"Liu Q., Liu T., Wen W.","57202841899;57201036884;55301112800;","Understanding adversarial attack and defense towards deep compressed neural networks",2018,"Proceedings of SPIE - The International Society for Optical Engineering","10630",,"106300Q","","",,1,"10.1117/12.2305226","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049314043&doi=10.1117%2f12.2305226&partnerID=40&md5=5ad4980f1d92ba36cc94536a0c65b177","Florida International University, Miami, FL, United States","Liu, Q., Florida International University, Miami, FL, United States; Liu, T., Florida International University, Miami, FL, United States; Wen, W., Florida International University, Miami, FL, United States","Modern deep neural networks (DNNs) have been demonstrating a phenomenal success in many exciting appli- cations such as computer vision, speech recognition, and natural language processing, thanks to recent machine learning model innovation and computing hardware advancement. However, recent studies show that state-of- the-art DNNs can be easily fooled by carefully crafted input perturbations that are even imperceptible to human eyes, namely ""adversarial examples"", causing the emerging security concerns for DNN based intelligent systems. Moreover, to ease the intensive computation and memory resources requirement imposed by the fast-growing DNN model size, aggressively pruning the redundant model parameters through various hardware-favorable DNN techniques (i.e. hash, deep compression, circulant projection) has become a necessity. This procedure further complicates the security issues of DNN systems. In this paper, we first study the vulnerabilities of hardware-oriented deep compressed DNNs under various adversarial attacks. Then we survey the existing mitigation approaches such as gradient distillation, which is originally tailored to the software-based DNN systems. Inspired by the gradient distillation and weight reshaping, we further develop a near zero-cost but effective gradient silence (GS) method to protect both software and hardware-based DNN systems against adversarial attacks. Compared with defensive distillation, our gradient salience method can achieve better resilience to adversarial attacks without additional training, while still maintaining very high accuracies across small and large DNN models for various image classification benchmarks like MNIST and CIFAR10. © 2018 SPIE.","adversarial example; attack and defense; deep compression; deep neural network","Computer hardware; Distillation; Hardware; Intelligent systems; Learning algorithms; Natural language processing systems; Network security; Speech recognition; adversarial example; attack and defense; Computing hardware; Input perturbation; Machine learning models; Memory resources; Model parameters; Software and hardwares; Deep neural networks",,,,,"Hinton, G., Deng, L., Yu, D., Dahl, G.E., Mohamed, A.-R., Jaitly, N., Senior, A., Sainath, T.N., Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups (2012) IEEE Signal Processing Magazine, 29 (6), pp. 82-97; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), p. 436; Chen, W., Wilson, J., Tyree, S., Weinberger, K., Chen, Y., Compressing neural networks with the hashing trick (2015) International Conference on Machine Learning, pp. 2285-2294; Cao, Z., Long, M., Wang, J., Yu, P.S., (2017) Hashnet: Deep Learning to Hash by Continuation, , arXiv preprint arXiv:1702. 00758; Han, S., Mao, H., Dally, W.J., (2015) Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Hu-man Coding, , arXiv preprint arXiv:1510. 00149; Han, S., Pool, J., Tran, J., Dally, W., Learning both weights and connections for Efficient neural network (2015) Advances in Neural Information Processing Systems, pp. 1135-1143; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R., (2013) Intriguing Properties of Neural Networks, , arXiv preprint arXiv:1312. 6199; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint arXiv:1412. 6572; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Machine Learning at Scale, , arXiv preprint arXiv:1611. 01236; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a defense to adversarial perturbations against deep neural networks (2016) Security and Privacy (SP), 2016 IEEE Symposium on, pp. 582-597. , IEEE; Hinton, G.E., Salakhutdinov, R.R., Reducing the dimensionality of data with neural networks (2006) Science, 313 (5786), pp. 504-507; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition, , arXiv preprint arXiv:1409. 1556; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9; Cheng, Y., Yu, F.X., Feris, R.S., Kumar, S., Choudhary, A., Chang, S.-F., An exploration of pa-rameter redundancy in deep networks with circulant projections (2015) Proceedings of the IEEE International Conference on Computer Vision, pp. 2857-2865; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) 2016 IEEE European Symposium on Security and Privacy (EuroS&P), pp. 372-387. , IEEE; Weinberger, K., Dasgupta, A., Langford, J., Smola, A., Attenberg, J., Feature hashing for large scale multitask learning (2009) Proceedings of the 26th Annual International Conference on Machine Learning, pp. 1113-1120. , ACM; LeCun, Y., (1998) The Mnist Database of Handwritten Digits, , http://yann.lecun.com/exdb/mnist/; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images",,"Ternovskiy I.V.Chin P.","The Society of Photo-Optical Instrumentation Engineers (SPIE)","SPIE","Cyber Sensing 2018","17 April 2018 through 18 April 2018",,137201,0277786X,9781510617711,PSISD,,"English","Proc SPIE Int Soc Opt Eng",Conference Paper,"Final","",Scopus,2-s2.0-85049314043
[No author name available],[No author id available],"2nd International Symposium on Cyber Security Cryptography and Machine Learning, CSCML 2018",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","10879 LNCS",,,"","",286,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049015382&partnerID=40&md5=61e196926311ee6a77182c20df4a08e8",,"","The proceedings contain 23 papers. The special focus in this conference is on Cyber Security Cryptography and Machine Learning. The topics include: Secured Data Gathering Protocol for IoT Networks; towards Building Active Defense Systems for Software Applications; secure Non-interactive User Re-enrollment in Biometrics-Based Identification and Authentication Systems; brief Announcement: Image Authentication Using Hyperspectral Layers; brief Announcement: Graph-Based and Probabilistic Discrete Models Used in Detection of Malicious Attacks; intercepting a Stealthy Network; privacy in e-Shopping Transactions: Exploring and Addressing the Trade-Offs; Detection in the Dark – Exploiting XSS Vulnerability in C&C Panels to Detect Malwares; a Planning Approach to Monitoring Computer Programs’ Behavior; efficient Construction of the Kite Generator Revisited; one-Round Secure Multiparty Computation of Arithmetic Streams and Functions: (Extended Abstract); brief Announcement: Gradual Learning of Deep Recurrent Neural Network; brief Announcement: Adversarial Evasion of an Adaptive Version of Western Electric Rules; brief Announcement: Deriving Context for Touch Events; using Noisy Binary Search for Differentially Private Anomaly Detection; distributed Web Mining of Ethereum; an Information-Flow Control Model for Online Social Networks Based on User-Attribute Credibility and Connection-Strength Factors; detecting and Coloring Anomalies in Real Cellular Network Using Principle Component Analysis; self-stabilizing Byzantine Tolerant Replicated State Machine Based on Failure Detectors; brief Announcement: Providing End-to-End Secure Communication in Low-Power Wide Area Networks; privacy via Maintaining Small Similitude Data for Big Data Statistical Representation.",,,,,,,,,"Dinur I.Dolev S.Lodha S.","","Springer Verlag","2nd International Symposium on Cyber Security Cryptography and Machine Learning, CSCML 2018","21 June 2018 through 22 June 2018",,214569,03029743,9783319941462,,,"English","Lect. Notes Comput. Sci.",Conference Review,"Final","",Scopus,2-s2.0-85049015382
"Li P., Zhao W., Liu Q., Liu X., Yu L.","57200645230;7403942668;57001286200;57202691744;57197737079;","Poisoning machine learning based wireless IDSs via stealing learning model",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","10874 LNCS",,,"261","273",,5,"10.1007/978-3-319-94268-1_22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049012916&doi=10.1007%2f978-3-319-94268-1_22&partnerID=40&md5=db4a01463fd2695f67a132005d45bad7","National University of Defense Technology, Changsha, Hunan  410073, China","Li, P., National University of Defense Technology, Changsha, Hunan  410073, China; Zhao, W., National University of Defense Technology, Changsha, Hunan  410073, China; Liu, Q., National University of Defense Technology, Changsha, Hunan  410073, China; Liu, X., National University of Defense Technology, Changsha, Hunan  410073, China; Yu, L., National University of Defense Technology, Changsha, Hunan  410073, China","Recently, machine learning-based wireless intrusion detection systems (IDSs) have been demonstrated to have high detection accuracy in malicious traffic detection. However, many researchers argue that a variety of attacks are significantly challenging the security of machine learning techniques themselves. In this paper, we study two different types of security threats which can effectively degrade the performance of machine learning based wireless IDSs. First, we propose an Adaptive SMOTE (A-SMOTE) algorithm which can adaptively generate new training data points based on few existing ones with labels. Then, we introduce a stealing model attack by training a substitute model using deep neural networks (DNNs) based on the augmented training data in order to imitate the machine learning model embedded in targeted systems. After that, we present a novel poisoning strategy to attack against the substitute machine learning model, resulting in a set of adversarial samples that can be used to degrade the performance of targeted systems. Experiments on three real data sets collected from wired and wireless networks have demonstrated that the proposed stealing model and poisoning attacks can effectively degrade the performance of IDSs using different machine learning algorithms. © 2018, Springer International Publishing AG, part of Springer Nature.",,"Artificial intelligence; Deep neural networks; Embedded systems; Intrusion detection; Detection accuracy; Machine learning models; Machine learning techniques; Malicious traffic; Poisoning attacks; Security threats; Wired and wireless; Wireless intrusion detections; Learning algorithms",,,,,"Tsai, C.F., Hsu, Y.F., Lin, C.Y., Lin, W.Y., Intrusion detection by machine learning: A review (2009) Expert Syst. Appl. Int. J., 36 (10), pp. 11994-12000. , https://doi.org/10.1016/j.eswa.2009.05.029; Kloft, M., Laskov, P., Online anomaly detection under adversarial impact (2010) Proceedings of the AISTATS 2010, pp. 405-412; Liu, Q., Li, P., Zhao, W., Cai, W., Yu, S., Leung, V.C.M., A survey on security threats and defensive techniques of machine learning: A data driven view (2018) IEEE Access, 6, pp. 12103-12117. , https://doi.org/10.1109/ACCESS.2018.2805680; Barreno, M., Nelson, B., Sears, R., Joseph, A.D., Tygar, J.D., Can machine learning be secure? (2006) Proceedings of the ASIACCS 2006, pp. 16-25. , https://doi.org/10.1145/1128817.1128824; Zhao, M., An, B., Gao, W., Zhang, T., Efficient label contamination attacks against black-box learning models (2017) Proceedings of the IJCAI 2017, pp. 3945-3951. , https://doi.org/10.24963/ijcai.2017/551; Wittel, G.L., Wu, S.F., On attacking statistical spam filters (2004) Proceedings of the CEAS 2004, , http://www.ceas.cc/papers-2004/170.pdf; Hu, W., Tan, Y., (2017) Generating Adversarial Malware Examples for Black-Box Attacks Based on GAN, , https://arxiv.org/abs/1702.05983; Tramèr, F., Zhang, F., Juels, A., Reiter, M.K., Ristenpart, T., (2016) Stealing Machine Learning Models via Prediction Apis, pp. 601-618; Shokri, R., Stronati, M., Song, C., Shmatikov, V., Membership inference attacks against machine learning models (2017) In: Proceedings of the Symposium on Security and Privacy, pp. 3-18. , https://doi.org/10.1109/SP.2017.41, 2017; Biggio, B., Nelson, B., Laskov, P., Poisoning attacks against support vector machines (2012) Proceedings of the ICML 2012, pp. 1467-1474; Biggio, B., Fumera, G., Roli, F., Didaci, L., Poisoning adaptive biometric systems (2012) Springer, Heidelberg, 7626, pp. 417-425. , https://doi.org/10.1007/978-3-642-34166-346; Li, P., Liu, Q., Zhao, W., Wang, D., Wang, S., (2018) BEBP: An Poisoning Method against Machine Learning Based Idss, , https://arxiv.org/abs/1803.03965; Rubinstein, B.I., Nelson, B., Huang, L., Joseph, A.D., Lau, S., Rao, S., Taft, N., Tygar, J.D., Antidote: Understanding and defending against poisoning of anomaly detectors (2009) Proceedings of the IMC 2009, pp. 1-14. , https://doi.org/10.1145/1644893.1644895, ACM, New York; Chawla, N.V., Bowyer, K.W., Hall, L.O., Kegelmeyer, W.P., Smote: Synthetic minority over-sampling technique (2002) J. Artif. Intell. Res., 16 (1), pp. 321-357. , https://doi.org/10.1613/jair.953; Song, J., Takakura, H., Okabe, Y., Eto, M., Inoue, D., Nakao, K., Statistical analysis of honeypot data and building of Kyoto 2006+ dataset for NIDs evaluation (2011) Proceedings of the BADGERS 2011, pp. 29-36. , https://doi.org/10.1145/1978672.1978676, ACM, New York; Almomani, I., Al-Kasasbeh, B., Al-Akhras, M., WSN-DS: A dataset for intrusion detection systems in wireless sensor networks (2016) J. Sens., 2016 (2), pp. 1-16. , https://doi.org/10.1155/2016/4731953; Ambusaidi, M.A., He, X., Nanda, P., Tan, Z., Building an intrusion detection system using a filter-based feature selection algorithm (2016) IEEE Trans. Comput., 65 (10), pp. 2986-2998. , https://doi.org/10.1109/TrustCom.2014.15; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical black-box attacks against machine learning (2017) Proceedings of the ASIACCS 2017, pp. 506-519. , https://doi.org/10.1145/3052973.3053009s, ACM, New York","Zhao, W.; National University of Defense TechnologyChina; email: wtzhao@nudt.edu.cn","Cheng W.Li W.Chellappan S.","","Springer Verlag","13th International Conference on Wireless Algorithms, Systems, and Applications, WASA 2018","20 June 2018 through 22 June 2018",,214369,03029743,9783319942674,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","",Scopus,2-s2.0-85049012916
"Dong Y., Zhu P., Liu Q., Chen Y., Xun P.","57202685823;8915653700;57001286200;36656939000;57192209263;","Degrading Detection performance of wireless IDSs through poisoning feature selection",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","10874 LNCS",,,"90","102",,1,"10.1007/978-3-319-94268-1_8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048999905&doi=10.1007%2f978-3-319-94268-1_8&partnerID=40&md5=5469e896451557d3a160d9f0509d780a","National University of Defense Technology, Changsha, 410073, China; Changsha University, Changsha, 410022, China","Dong, Y., National University of Defense Technology, Changsha, 410073, China; Zhu, P., National University of Defense Technology, Changsha, 410073, China, Changsha University, Changsha, 410022, China; Liu, Q., National University of Defense Technology, Changsha, 410073, China; Chen, Y., National University of Defense Technology, Changsha, 410073, China; Xun, P., National University of Defense Technology, Changsha, 410073, China","Machine learning algorithms have been increasingly adopted in Intrusion Detection Systems (IDSs) and achieved demonstrable results, but few studies have considered intrinsic vulnerabilities of these algorithms in adversarial environment. In our work, we adopt poisoning attack to influence the accuracy of wireless IDSs that adopt feature selection algorithms. Specifically, we adopt the gradient poisoning method to generate adversarial examples which induce classifier to select a feature subset to make the classification error rate biggest. We consider the box-constrained problem and use Lagrange multiplier and backtracking line search to find the feasible gradient. To evaluate our method, we experimentally demonstrate that our attack method can influence machine learning, including filter and embedded feature selection algorithms using three benchmark network public datasets and a wireless sensor network dataset, i.e., KDD99, NSL-KDD, Kyoto 2006+ and WSN-DS. Our results manifest that gradient poisoning method causes a significant drop in the classification accuracy of IDSs about 20%. © 2018, Springer International Publishing AG, part of Springer Nature.","Adversarial examples; Feature selection; Gradient poisoning; IDS","Artificial intelligence; Classification (of information); Constraint theory; Intrusion detection; Lagrange multipliers; Learning algorithms; Learning systems; Network security; Wireless sensor networks; Adversarial environments; Adversarial examples; Backtracking line search; Box constrained problems; Classification error rate; Embedded feature selections; Feature selection algorithm; Intrusion Detection Systems; Feature extraction",,,,,"Grosse, K., Papernot, N., Manoharan, P., Backes, M., McDaniel, P., (2016) Adversarial perturbations against deep neural networks for malware classification; Xu, W., Qi, Y., Evans, D., Automatically evading classifiers (2016) Proceedings of the 2016 Network and Distributed Systems Symposium; Tibshirani, R., Regression shrinkage and selection via the lasso (1996) J. R. Stat. Soc. Ser. B (Methodol.), 58, pp. 267-288; Hoerl, A.E., Kennard, R.W., Ridge regression: Biased estimation for nonorthogonal problems (1970) Technometrics, 12 (1), pp. 55-67; Zou, H., Hastie, T., Regularization and variable selection via the elastic net (2005) J. R. Stat. Soc.: Ser. B (Stat. Methodol.), 67 (2), pp. 301-320; Ambusaidi, M.A., He, X., Nanda, P., Tan, Z., Building an intrusion detection system using a filter-based feature selection algorithm (2016) IEEE Trans. Comput., 65 (10), pp. 2986-2998; Abraham, A., Jain, R., Thomas, J., Han, S.Y., D-SCIDS: Distributed soft computing intrusion detection system (2007) J. Netw. Comput. Appl., 30 (1), pp. 81-98; Chebrolu, S., Abraham, A., Thomas, J.P., Feature deduction and ensemble design of intrusion detection systems (2005) Comput. Secur., 24 (4), pp. 295-307; Chen, Y., Abraham, A., Yang, B., Feature selection and classification using flexible neural tree (2006) Neurocomputing, 70 (1-3), pp. 305-313; Mukkamala, S., Sung, A.H., Significant feature selection using computational intelligent techniques for intrusion detection (2005) Advanced Methods for Knowledge Discovery from Complex Data, pp. 285-306. , https://doi.org/10.1007/1-84628-284-511, Bandyopadhyay, S., Maulik, U., Holder, L.B., Cook, D.J. (eds.), Springer, London; Barreno, M., Nelson, B., Sears, R., Joseph, A.D., Tygar, J.D., Can machine learning be secure? (2006) Proceedings of the 2006 ACM Symposium on Information, Computer and Communications Security, pp. 16-25; Liu, Q., Li, P., Zhao, W., Cai, W., Yu, S., A survey on security threats and defensive techniques of machine learning: A data driven view (2018) IEEE Access, 99 (1); Wittel, G.L., Wu, S.F., (2004) On Attacking Statistical Spam Filters, , CEAS; Šrndic, N., Laskov, P., Detection of malicious pdf files based on hierarchical document structure (2013) Proceedings of the 20Th Annual Network & Distributed System Security Symposium, pp. 1-16; Biggio, B., Fumera, G., Roli, F., Security evaluation of pattern classifiers under attack (2014) IEEE Trans. Knowl. Data Eng., 26 (4), pp. 984-996; Xiao, H., Biggio, B., Brown, G., Fumera, G., Eckert, C., Roli, F., Is feature selection secure against training data poisoning? (2015) International Conference on Machine Learning, pp. 1689-1698; Song, J., Takakura, H., Okabe, Y., Eto, M., Inoue, D., Nakao, K., Statistical analysis of honeypot data and building of Kyoto 2006+ dataset for NIDS evaluation (2011) Proceedings of the First Workshop on Building Analysis Datasets and Gathering Experience Returns for Security, pp. 29-36. , ACM; Almomani, I., Al-Kasasbeh, B., Al-Akhras, M., WSN-DS: A dataset for intrusion detection systems in wireless sensor networks (2016) J. Sens., 2016 (2), pp. 1-16; Kuncheva, L.I., A stability index for feature selection (2007) Artificial Intelligence and Applications, pp. 421-427","Zhu, P.; National University of Defense TechnologyChina; email: pdzhu@nudt.edu.cn","Cheng W.Li W.Chellappan S.","","Springer Verlag","13th International Conference on Wireless Algorithms, Systems, and Applications, WASA 2018","20 June 2018 through 22 June 2018",,214369,03029743,9783319942674,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","",Scopus,2-s2.0-85048999905
"Kesarwani M., Kaul A., Singh G., Deshpande P.M., Haritsa J.R.","57202646952;57202643737;57209127676;57225685450;7003832747;","Collusion-resistant processing of SQL range predicates",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","10828 LNCS",,,"211","227",,,"10.1007/978-3-319-91458-9_13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048976184&doi=10.1007%2f978-3-319-91458-9_13&partnerID=40&md5=80a83a8ddb2e8fa5d3b7c8e46f186a87","IBM India Research Lab, Bangalore, India; KENA Labs, New Delhi, India; Indian Institute of Science, Bangalore, India","Kesarwani, M., IBM India Research Lab, Bangalore, India; Kaul, A., IBM India Research Lab, Bangalore, India; Singh, G., IBM India Research Lab, Bangalore, India; Deshpande, P.M., KENA Labs, New Delhi, India; Haritsa, J.R., Indian Institute of Science, Bangalore, India","Prior solutions for securely handling SQL range predicates in outsourced cloud-resident databases have primarily focused on passive attacks in the Honest-but-Curious adversarial model, where the server is only permitted to observe the encrypted query processing. We consider here a significantly more powerful adversary, wherein the server can launch an active attack by clandestinely issuing specific range queries via collusion with a few compromised clients. The security requirement in this environment is that data values from a plaintext domain of size N should not be leaked to within an interval of size H. Unfortunately, all prior encryption schemes for range predicate evaluation are easily breached with only O(log2ψ) range queries, where ψ= N/ H. To address this lacuna, we present SPLIT, a new encryption scheme where the adversary requires exponentially more – O(ψ) – range queries to breach the interval constraint, and can therefore be easily detected by standard auditing mechanisms. The novel aspect of SPLIT is that each value appearing in a range-sensitive column is first segmented into two parts. These segmented parts are then independently encrypted using a layered composition of a Secure Block Cipher with the Order-Preserving Encryption and Prefix-Preserving Encryption schemes, and the resulting ciphertexts are stored in separate tables. At query processing time, range predicates are rewritten into an equivalent set of table-specific sub-range predicates, and the disjoint union of their results forms the query answer. A detailed evaluation of SPLIT on benchmark database queries indicates that its execution times are well within a factor of two of the corresponding plaintext times, testifying to its efficiency in resisting active adversaries. © Springer International Publishing AG, part of Springer Nature 2018.",,"Petroleum reservoir evaluation; Query languages; Query processing; Routers; Auditing mechanism; Benchmark database; Collusion resistant; Encryption schemes; Interval constraint; Layered composition; Range predicates; Security requirements; Cryptography",,,,,"Agrawal, R., Kiernan, J., Srikant, R., Xu, Y., Order-preserving encryption for numeric data (2004) Proceedings of ACM SIGMOD Conference; Arasu, A., Blanas, S., Eguro, K., Kaushik, R., Kossmann, D., Ramamurthy, R., Venkatesan, R., Orthogonal security with cipherbase (2013) Proceedings of CIDR Conference; Bajaj, S., Sion, R., TrustedDB: A trusted hardware based outsourced database engine (2011) PVLDB, 4 (12), pp. 1359-1362; Bellare, M., Ristenpart, T., Rogaway, P., Stegers, T., (2009) Format-preserving encryption, 5867, pp. 295-312. , https://doi.org/10.1007/978-3-642-05445-7_19, Jacobson, M.J., Rijmen, V., Safavi-Naini, R. (eds.) SAC 2009. LNCS, Springer, Heidelberg; Boldyreva, A., Chenette, N., Lee, Y., O’Neill, A., (2009) Order-Preserving Symmetric Encryption, 5479, pp. 224-241. , https://doi.org/10.1007/978-3-642-01001-9_13, Joux, A. (ed.) EUROCRYPT 2009. LNCS, Springer, Heidelberg; Boldyreva, A., Chenette, N., O’Neill, A., (2011) Order-preserving encryption revisited: Improved security analysis and alternative solutions, 6841, pp. 578-595. , https://doi.org/10.1007/978-3-642-22792-9_33, Rogaway, P. (ed.) CRYPTO 2011. LNCS, Springer, Heidelberg; Chi, J., Hong, C., Zhang, M., Zhang, Z., (2017) Fast multi-dimensional range queries on encrypted cloud databases, 10177, pp. 559-575. , https://doi.org/10.1007/978-3-319-55753-3_35, Candan, S., Chen, L., Pedersen, T.B., Chang, L., Hua, W. (eds.) DASFAA 2017. LNCS, Springer, Cham; Demertzis, I., Papadopoulos, S., Papapetrou, O., Deligiannakis, A., Garofalakis, M., Practical private range search revisited (2016) Proceedings of ACM SIGMOD Conference; Hacigümüs, H., Iyer, B.R., Li, C., Mehrotra, S., Executing SQL over encrypted data in the database-service-provider model (2002) Proceedings of ACM SIGMOD Conference; Hore, B., Mehrotra, S., Tsudik, G., A privacy-preserving index for range queries (2004) Proceedings of VLDB Conference; Kerschbaum, F., Frequency-hiding order-preserving encryption (2015) Proceedings of CCS Conference; Li, J., Omiecinski, E.R., (2005) Efficiency and security trade-off in supporting range queries on encrypted databases, 3654, pp. 69-83. , https://doi.org/10.1007/11535706_6, Jajodia, S., Wijesekera, D. (eds.) DBSec 2005. LNCS, Springer, Heidelberg; Li, R., Liu, A.X., Wang, A.L., Bruhadeshwar, B., Fast range query processing with strong privacy protection for cloud computing (2014) PVLDB, 7 (14), pp. 1953-1964; Popa, R.A., Li, F.H., Zeldovich, N., An ideal-security protocol for order-preserving encoding (2013) Proceedings of IEEE Symposium on Security and Privacy; Popa, R.A., Redfield, C.M.S., Zeldovich, N., Balakrishnan, H., CryptDB processing queries on an encrypted database (2012) Commun. ACM, 55 (9), pp. 103-111; Tu, S., Kaashoek, M.F., Madden, S., Zeldovich, N., Processing analytical queries over encrypted data (2013) PVLDB, 6 (5), pp. 289-300; Wong, W.K., Kao, B., Cheung, D.W., Li, R., Yiu, S., Secure query processing with data interoperability in a cloud database environment (2014) Proceedings of ACM SIGMOD Conference; Xu, J., Fan, J., Ammar, M.H., Moon, A.B., Prefix-preserving IP address anonymization: Measurement-based security evaluation and a new cryptography-based scheme (2002) Proceedings of ICNP Conference; https://aws.amazon.com/ec2/pricing/; http://dsl.cds.iisc.ac.in/publications/report/TR/TR-2016-01.pdf; http://www.tpc.org/tpcds/","Haritsa, J.R.; Indian Institute of ScienceIndia; email: haritsa@iisc.ac.in","Pei J.Sadiq S.Li J.Manolopoulos Y.","","Springer Verlag","23rd International Conference on Database Systems for Advanced Applications, DASFAA 2018","21 May 2018 through 24 May 2018",,213579,03029743,9783319914572,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85048976184
"Atakhodjaev I., Bosworth B.T., Grubel B.C., Kossey M.R., Villalba J., Cooper A.B., Dehak N., Foster A.C., Foster M.A.","57202629553;24342742000;57193081525;56593211200;36667707200;57193082759;16202714800;36731109600;7202971357;","Investigation of deep learning attacks on nonlinear silicon photonic PUFs",2018,"Optics InfoBase Conference Papers","Part F93-CLEO_QELS 2018",,,"","",2,,"10.1364/CLEO_QELS.2018.FM1G.4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048927651&doi=10.1364%2fCLEO_QELS.2018.FM1G.4&partnerID=40&md5=4f1cf4966b1d46c423be6c730a0a8755","Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD  21218, United States","Atakhodjaev, I., Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD  21218, United States; Bosworth, B.T., Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD  21218, United States; Grubel, B.C., Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD  21218, United States; Kossey, M.R., Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD  21218, United States; Villalba, J., Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD  21218, United States; Cooper, A.B., Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD  21218, United States; Dehak, N., Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD  21218, United States; Foster, A.C., Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD  21218, United States; Foster, M.A., Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD  21218, United States","We demonstrate that nonlinear silicon photonic Physical Unclonable Functions (PUFs) are resistant to adversarial deep learning attacks. We find that this resistance is rooted in the optical nonlinearity of the silicon photonic PUF token. © OSA 2018.",,"Nonlinear optics; Photonic devices; Silicon photonics; Nonlinear silicon photonics; Optical nonlinearity; Deep learning",,,,,"Ru¨hrmair, U., Hilgers, C., Urban, S., Weiershäuser, A., Dinter, E., Forster, B., Jirauschek, C., 'Optical PUFs Reloaded.' (2013); Maes, R., Verbauwhede, I., (2010) Physically unclonable functions: a study on the state of the art and future research directions; Pappu, R., Recht, B., Taylor, J., Gershenfeld, N., Physical One-Way Functions (2002) Science, 297; Horstmeyer, R., Judkewitz, B., Vellekoop, I.M., Assawaworrarit, S., Yang, C., 'Physical key-protected one-time pad' (2013) Scientific Reports, 3, p. 3543; Grubel, B.C., Bosworth, B.T., Kossey, M.R., Sun, H., Cooper, A.B., Foster, M.A., Foster, A.C., 'Silicon photonic physical unclonable function, ' (2017) Opt. Express, 25, pp. 12710-12721; Grubel, B.C., Bosworth, B.T., Kossey, M.R., Cooper, A.B., Foster, M.A., Foster, A.C., Information-Dense Nonlinear Photonic Physical Uncloneable Function, , 1711.02222; Ru¨hrmair, U., Sehnke, F., So¨lter, J., Dror, G., Devadas, S.J., (2010) Schmidhuber: Modeling Attacks on Physical Unclonable Functions, , ACM CCS; LeCun, Y., Bengio, Y., Hinton, G., (2015) Deep learning. Nature, 521, pp. 436-444","Foster, M.A.; Department of Electrical and Computer Engineering, United States; email: mark.foster@jhu.edu",,"","OSA - The Optical Society","CLEO: QELS_Fundamental Science, CLEO_QELS 2018","13 May 2018 through 18 May 2018",,139968,,9781557528209,,,"English","Opt. InfoBase Conf. Pap",Conference Paper,"Final","",Scopus,2-s2.0-85048927651
[No author name available],[No author id available],"13th EAI International Conference on Security and Privacy in Communication Networks, SecureComm 2017",2018,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST","239",,,"","",1189,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046534948&partnerID=40&md5=d038f7760ab1611fc894e6fdea3895b1",,"","The proceedings contain 68 papers. The special focus in this conference is on Security and Privacy in Communication Networks. The topics include: Lambda obfuscation; turing obfuscation; all your accounts are belong to us; SDN-based kernel modular countermeasure for intrusion detection; linkFlow: Efficient large-scale inter-app privacy leakage detection; Exposing LTE security weaknesses at protocol inter-layer, and inter-radio interactions; achieve efficient and privacy-preserving proximity detection scheme for social applications; Disrupting SDN via the data plane: Low-rate flow table overflow attack; VCIDS: Collaborative intrusion detection of sensor and actuator attacks on connected vehicles; enhancing android security through app splitting; understanding adversarial strategies from bot recruitment to scheduling; mending wall: On the implementation of censorship in India; A deep learning based online malicious URL and DNS detection scheme; Visual analysis of android malware behavior profile based on PMCGdroid: A pruned lightweight APP call graph; inferring implicit assumptions and correct usage of mobile payment protocols; HSTS measurement and an enhanced stripping attack against HTTPS; defining and detecting environment discrimination in android apps; query recovery attacks on searchable encryption based on partial knowledge; H2DoS: An application-layer DoS attack towards HTTP/2 Protocol; Optimizing TLB for access pattern privacy protection in data outsourcing; Very short intermittent DDoS Attacks in an unsaturated system; an efficient trustzone-based in-application isolation schema for mobile authenticators; a program manipulation middleware and its applications on system security; cross-site input inference attacks on mobile web users; BKI: Towards accountable and decentralized public-key infrastructure with blockchain; VaultIME: Regaining user control for password managers through auto-correction.",,,,,,,,,"Ghorbani A.Ren K.Zhu S.Zhang A.Lin X.","","Springer Verlag","13th EAI International Conference on Security and Privacy in Communication Networks, SecureComm 2017","22 October 2017 through 25 October 2017",,213179,18678211,9783319788159,,,"English","Lect. Notes Inst. Comput. Sci. Soc. Informatics Telecommun. Eng.",Conference Review,"Final","",Scopus,2-s2.0-85046534948
"Liang X., Shetty S., Tosh D., Foytik P., Zhang L.","57195358870;8970891400;55220635700;55923281600;54390558200;","Towards a trusted and privacy preserving membership service in distributed ledger using intel software guard extensions",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","10631 LNCS",,,"304","310",,5,"10.1007/978-3-319-89500-0_27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046000482&doi=10.1007%2f978-3-319-89500-0_27&partnerID=40&md5=a514ad275abcffa7bbb7d267ffbfced8","Institute of Information Engineering, Chinese Academy of Sciences, Beijing, 100093, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, 100190, China; College of Engineering, Tennessee State University, Nashville, TN  37209, United States; Virginia Modeling Analysis and Simulation Center, Old Dominion University, Norfolk, VA  23529, United States; Department of Computer Science, Norfolk State University, Norfolk, VA  23504, United States","Liang, X., Institute of Information Engineering, Chinese Academy of Sciences, Beijing, 100093, China, School of Cyber Security, University of Chinese Academy of Sciences, Beijing, 100190, China, College of Engineering, Tennessee State University, Nashville, TN  37209, United States; Shetty, S., Virginia Modeling Analysis and Simulation Center, Old Dominion University, Norfolk, VA  23529, United States; Tosh, D., Department of Computer Science, Norfolk State University, Norfolk, VA  23504, United States; Foytik, P., Virginia Modeling Analysis and Simulation Center, Old Dominion University, Norfolk, VA  23529, United States; Zhang, L., Institute of Information Engineering, Chinese Academy of Sciences, Beijing, 100093, China","Distributed Ledger Technology (DLT) provides decentralized services by removing the need of trust among distributed nodes and the trust of central authority in the distributed system. Transactions across the whole network are visible to all participating nodes. However, some transactions may contain sensitive information such as business contracts and financial reports, or even personal health records. To protect user privacy, the architecture of distributed ledger with membership service as a critical component can be adopted. We make a step towards such vision by proposing a membership service architecture that combines two promising technologies, distributed ledger and Intel Software Guard Extensions (SGX). With SGX remote attestation and isolated execution features, each distributed node can be enrolled as a trusted entity. We propose security properties for membership service in distributed ledger and illustrate how SGX capabilities help to achieve these properties in each phase of membership service, including member registration, enrollment, transaction signing and verifying and transacting auditing. The SGX enabled membership service could enhance the support of privacy preservation, and defense capabilities against adversarial attacks, with scalability and cost effectiveness. © Springer International Publishing AG, part of Springer Nature 2018.","Channel; Distributed ledger; Intel SGX; Membership service; Privacy; Security","Cost effectiveness; Network architecture; Channel; Distributed ledger; Intel SGX; Membership service; Security; Data privacy",,,,,"Hyperledger-Blockchain Technologies for Business, , https://www.hyperledger.org; Information Security - Wikipedia, , https://en.wikipedia.org/wiki/Informationsecurity; Intel Architecture Instruction Set Extensions Programming Reference, , https://software.intel.com/sites/default/files/managed/07/b7/319433-023.pdf; Introduction - Sawtooth Lake Latest Documentation, , https://intelledger.github.io/introduction.html; Private Blockchain White Paper, , http://www.multichain.com/download/MultiChain-White-Paper.pdf; Anati, I., Gueron, S., Johnson, S., Scarlata, V., Innovative technology for CPU based attestation and sealing (2013) Proceedings of the 2Nd International Workshop on Hardware and Architectural Support for Security and Privacy, 13; Cachin, C., Architecture of the Hyperledger blockchain fabric (2016) Workshop on Distributed Cryptocurrencies and Consensus Ledgers; Camenisch, J., Lysyanskaya, A., A signature scheme with efficient protocols (2003) SCN 2002. LNCS, 2576, pp. 268-289. , https://doi.org/10.1007/3-540-36413-7_20, Cimato, S., Persiano, G., Galdi, C. (eds.), Springer, Heidelberg; Jain, P., Desai, S., Kim, S., Shih, M.W., Lee, J., Choi, C., Shin, Y., Han, D., OpenSGX: An open platform for SGX research (2016) Proceedings of the Network and Distributed System Security Symposium, San Diego, CA; Jia, X., Auditing the Auditor: Secure Delegation of Auditing Operation over Cloud Storage, , https://eprint.iacr.org/2011/304.pdf, Technical report, IACR Cryptology ePrint Archive, Accessed 10 Aug 2016; Johnson, S., Scarlata, V., Rozas, C., Brickell, E., McKeen, F., (2016) Intel Software Guard Extensions: EPID Provisioning and Attestation Services, , White Paper; Kaptchuk, G., Miers, I., Green, M., Managing secrets with consensus networks: Fairness, ransomware and access control (2017) IACR Cryptology Eprint Archive, 2017 (201); Kosba, A., Miller, A., Shi, E., Wen, Z., Papamanthou, C., Hawk: The blockchain model of cryptography and privacy-preserving smart contracts (2016) 2016 IEEE Symposium on Security and Privacy (SP), pp. 839-858; Liang, X., Shetty, S., Tosh, D., Kamhoua, C., Kwiat, K., Njilla, L., ProvChain: A blockchain-based data provenance architecture in cloud environment with enhanced privacy and availability (2017) International Symposium on Cluster, Cloud and Grid Computing. IEEE/ACM; Lind, J., Eyal, I., Pietzuch, P., Sirer, E.G., (2016) Teechan: Payment Channels Using Trusted Execution Environments; McKeen, F., Alexandrovich, I., Berenzon, A., Rozas, C.V., Shafi, H., Shanbhogue, V., Savagaonkar, U.R., Innovative instructions and software model for isolated execution (2013) HASP@ ISCA, p. 10; Milutinovic, M., He, W., Wu, H., Kanwal, M., Proof of luck: An efficient blockchain consensus protocol (2016) Proceedings of the 1St Workshop on System Software for Trusted Execution, , ACM; Nakamoto, S., (2008) Bitcoin: A Peer-To-Peer Electronic Cash System; van Renesse, R., A Blockchain Based on Gossip?-A Position Paper; Tramer, F., Zhang, F., Lin, H., Hubaux, J.P., Juels, A., Shi, E., Sealed-glass proofs: Using transparent enclaves to prove and sell knowledge (2017) 2017 IEEE European Symposium on Security and Privacy (EuroS&P), pp. 19-34; Walport, M., Distributed ledger technology: Beyond blockchain (2016) UK Gov. Off. Sci.; Zhang, F., Cecchetti, E., Croman, K., Juels, A., Shi, E., Town crier: An authenticated data feed for smart contracts (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 270-282. , ACM","Zhang, L.; Institute of Information Engineering, China; email: zhanglingchen@iie.ac.cn","Qing S.Liu D.Mitchell C.Chen L.","","Springer Verlag","19th International Conference on Information and Communications Security, ICICS 2017","6 December 2017 through 8 December 2017",,212979,03029743,9783319894997,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","",Scopus,2-s2.0-85046000482
"Chang W., Mohaisen A., Wang A., Chen S.","25824579600;14027298300;56367065800;9338029700;","Understanding adversarial strategies from bot recruitment to scheduling",2018,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST","238",,,"397","417",,5,"10.1007/978-3-319-78813-5_20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045991939&doi=10.1007%2f978-3-319-78813-5_20&partnerID=40&md5=c30d64cd9f84e163ddd7cdc9adf0f577","George Mason University, Fairfax, United States; The University of Central Florida, Orlando, United States","Chang, W., George Mason University, Fairfax, United States; Mohaisen, A., The University of Central Florida, Orlando, United States; Wang, A., George Mason University, Fairfax, United States; Chen, S., George Mason University, Fairfax, United States","Today botnets are still one of the most prevalent and devastating attacking platforms that cyber criminals rely on to launch large scale Internet attacks. Botmasters behind the scenes are becoming more agile and discreet, and some new and sophisticated strategies are adopted to recruit bots and schedule their activities to evade detection more effectively. In this paper, we conduct a measurement study of 23 active botnet families to uncover some new botmaster strategies based on an operational dataset collected over a period of seven months. Our analysis shows that different from the common perception that bots are randomly recruited in a best-effort manner, bots recruitment has strong geographical and organizational locality, offering defenses a direction and priority when attempting to shut down these botnets. Furthermore, our study to measure dynamics of botnet activity reveals that botmasters start to deliberately schedule their bots to hibernate and alternate in attacks so that the detection window becomes smaller and smaller. © ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering 2018.","Behavioral analysis; Botnets; Distributed denial of service","Denial-of-service attack; Network security; Behavioral analysis; Best effort; Botnets; Cyber criminals; Detection windows; Distributed denial of service; Large scale Internet; Measurement study; Botnet",,,,,"(2014), http://bit.ly/1kM2Vos; (2014), http://bit.ly/1noDUlI; Four Years of Darkseoul Cyberattacks against South Korea Continue on Anniversary of Korean War, , http://bit.ly/1fbGlFm, June 2013; Opusa Threatens Banks, Government, , http://bit.ly/1kP3Urt, May 2013; McDougall, P., Microsoft: Kelihos Ring Sold ‘botnet-as-a-service’, , http://ubm.io/MtCSr7, September 2011; Vicario, M., Four Ways Cybercriminals Profit from Botnets, , http://bit.ly/1e1SIiP, November 2010; Wang, A., Mohaisen, A., Chang, W., Chen, S., Delving into internet DDoS attacks by botnets (2015) IEEE DSN 2015; Ioannidis, J., Bellovin, S., (2002) Implementing Pushback: Router-Based Defense against Ddos Attacks; Chen, Y., Kwok, Y., Hwang, K., MAFIC: Adaptive packet dropping for cutting malicious flows to push back DDoS attacks (2005) ICDCS 2005; Kang, M., Gligor, V.D., Routing bottlenecks in the internet: Causes, exploits, and countermeasures (2014) Proceedings of ACM SIGSAC 2014; (2014) Wikipedia: Carna Botnet, , http://bit.ly/1slx1E6; Starr, M., (2014) Fridge Caught Sending Spam Emails in Botnet Attack, , http://bit.ly/1j5Jac1; Thomas, M., Mohaisen, A., Kindred domains: Detecting and clustering botnet domains using DNS traffic (2014) Proceedings of WWW 2014; Andrade, M., Vlajic, N., Dirt jumper: A key player in today’s botnet-for-DDoS market (2012) Worldcis 2012; Song, L., Jin, Z., Sun, G., Modeling and analyzing of botnet interactions (2011) Proc. Phys. A, 390 (2), pp. 347-358; Li, Z., Goyal, A., Chen, Y., Paxson, V., Towards situational awareness of large-scale botnet probing events (2011) IEEE TIFS, 6 (1), pp. 175-188; Wang, P., Sparks, S., Zou, C., An advanced hybrid peer-to-peer botnet (2010) TDSC; Cho, C., Caballero, J., Grier, C., Paxson, V., Song, D., Insights from the inside: A view of botnet management from infiltration (2010) LEET; Binsalleeh, H., Ormerod, T., Boukhtouta, A., Sinha, P., Youssef, A., Debbabi, M., Wang, L., On the analysis of the Zeus botnet crimeware toolkit (2010) IEEE PST 2010; Caballero, J., Poosankam, P., Kreibich, C., Song, D., Dispatcher: Enabling active botnet infiltration using automatic protocol reverse-engineering (2009) Proceedings of ACM CCS 2009; Lee, C.P., Dagon, D., Gu, G., Lee, W., A taxonomy of botnet structures (2007) Proceedings of ACM ACSCA 2007; Jing, L., Yang, X., Kaveh, G., Hongmei, D., Botnet: Classification, attacks, detection, tracing, and preventive measures (2009) JWCN; Mohaisen, A., Alrawi, O., AV-Meter: An evaluation of antivirus scans and labels (2014) DIMVA 2014. LNCS, 8550, pp. 112-131. , https://doi.org/10.1007/978-3-319-08509-87, Dietrich, S. (ed.), Springer, Cham; Stone-Gross, B., Cova, M., Cavallaro, L., Gilbert, B., Szydlowski, M., Kemmerer, R., Kruegel, C., Vigna, G., Your botnet is my botnet: Analysis of a botnet takeover (2009) Proceedings of ACM CCS 2009; Gu, G., Perdisci, R., Zhang, J., Lee, W., Botminer: Clustering analysis of network traffic for protocol-and structure-independent botnet detection (2008) Proceedings of USENIX Security 2008; Digital Envoy: Digital Element Services, , http://www.digitalenvoy.net/; Xie, Y., Yu, F., Achan, K., Panigrahy, R., Hulten, G., Osipkov, I., Spamming botnets: Signatures and characteristics (2008) SIGCOMM 2008; Maertens, M., Asghari, H., van Eeten, M., van Mieghem, P., A time-dependent SIS-model for long-term computer worm evolution (2016) Proceedings of IEEE CNS 2016; Rajab, M., Zarfoss, J., Monrose, F., Terzis, A., My botnet is bigger than yours (Maybe, better than yours): Why size estimates remain challenging (2007) Proceedings of USENIX Hotbots 2007; Xie, Y., Yu, F., Achan, K., Gillum, E., Goldszmidt, M., Wobber, T., How dynamic are IP addresses? (2007) ACM SIGCOMM CCR 2007; Caballero, J., Grier, C., Kreibich, C., Paxson, V., Measuring pay-per-install: The commoditization of malware distribution (2011) Proceedings of USENIX Security 2011; Bacher, P., Holz, T., Kotter, M., Wicherski, G., (2005) Know Your Enemy: Tracking Botnets; Baecher, P., Koetter, M., Holz, T., Dornseif, M., Freiling, F., The nepenthes platform: An efficient approach to collect malware (2006) RAID 2006. LNCS, 4219, pp. 165-184. , https://doi.org/10.1007/118562149, Zamboni, D., Kruegel, C. (eds.), Springer, Heidelberg; Abu Rajab, M., Zarfoss, J., Monrose, F., Terzis, A., A multifaceted approach to understanding the botnet phenomenon (2006) IMC 2006; Karasaridis, A., Rexroad, B., Hoeflin, D., Wide-scale botnet detection and characterization (2007) Proceedings of USENIX Hotbots 2007; Barford, P., Yegneswaran, V., An inside look at botnets (2007) Proceedings of Malware Detection. ADIS, 27, pp. 171-191. , https://doi.org/10.1007/978-0-387-44599-18, Christodorescu, M., Jha, S., Maughan, D., Song, D., Wang, C. (eds.), Springer, Heidelberg; Holz, T., Steiner, M., Dahl, F., Biersack, E., Freiling, F.C., Measurements and mitigation of peer-to-peer-based botnets: A case study on storm worm (2008) USENIX LEET 2008; Shin, S., Gu, G., Conficker and beyond: A large-scale empirical study (2010) Proceedings of ACM ACSAC 2010; Chang, W., Mohaisen, A., Wang, A., Chen, S., Measuring botnets in the wild: Some new trends (2015) ACM ASIACCS 2015","Mohaisen, A.; The University of Central FloridaUnited States; email: mohaisen@ucf.edu","Ghorbani A.Lin X.Ren K.Zhu S.Zhang A.","","Springer Verlag","13th EAI International Conference on Security and Privacy in Communication Networks, SecureComm 2017","22 October 2017 through 25 October 2017",,213179,18678211,9783319788128,,,"English","Lect. Notes Inst. Comput. Sci. Soc. Informatics Telecommun. Eng.",Conference Paper,"Final","",Scopus,2-s2.0-85045991939
[No author name available],[No author id available],"13th EAI International Conference on Security and Privacy in Communication Networks, SecureComm 2017",2018,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST","238",,,"","",1189,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045991194&partnerID=40&md5=c80b581aeea7b5260f532dfd8c36fadb",,"","The proceedings contain 68 papers. The special focus in this conference is on Security and Privacy in Communication Networks. The topics include: Lambda obfuscation; turing obfuscation; all your accounts are belong to us; SDN-based kernel modular countermeasure for intrusion detection; linkFlow: Efficient large-scale inter-app privacy leakage detection; Exposing LTE security weaknesses at protocol inter-layer, and inter-radio interactions; achieve efficient and privacy-preserving proximity detection scheme for social applications; Disrupting SDN via the data plane: Low-rate flow table overflow attack; VCIDS: Collaborative intrusion detection of sensor and actuator attacks on connected vehicles; enhancing android security through app splitting; understanding adversarial strategies from bot recruitment to scheduling; mending wall: On the implementation of censorship in India; A deep learning based online malicious URL and DNS detection scheme; Visual analysis of android malware behavior profile based on PMCGdroid: A pruned lightweight APP call graph; inferring implicit assumptions and correct usage of mobile payment protocols; HSTS measurement and an enhanced stripping attack against HTTPS; defining and detecting environment discrimination in android apps; query recovery attacks on searchable encryption based on partial knowledge; H2DoS: An application-layer DoS attack towards HTTP/2 Protocol; Optimizing TLB for access pattern privacy protection in data outsourcing; Very short intermittent DDoS Attacks in an unsaturated system; an efficient trustzone-based in-application isolation schema for mobile authenticators; a program manipulation middleware and its applications on system security; cross-site input inference attacks on mobile web users; BKI: Towards accountable and decentralized public-key infrastructure with blockchain; VaultIME: Regaining user control for password managers through auto-correction.",,,,,,,,,"Ghorbani A.Lin X.Ren K.Zhu S.Zhang A.","","Springer Verlag","13th EAI International Conference on Security and Privacy in Communication Networks, SecureComm 2017","22 October 2017 through 25 October 2017",,213179,18678211,9783319788128,,,"English","Lect. Notes Inst. Comput. Sci. Soc. Informatics Telecommun. Eng.",Conference Review,"Final","",Scopus,2-s2.0-85045991194
"Alagic G., Gagliardoni T., Majenz C.","9841808500;55867502300;55801444900;","Unforgeable quantum encryption",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","10822 LNCS",,,"489","519",,10,"10.1007/978-3-319-78372-7_16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045928606&doi=10.1007%2f978-3-319-78372-7_16&partnerID=40&md5=880e057c41402dcaa1203a51ba368c20","Joint Center for Quantum Information and Computer Science, University of Maryland, College Park, MD, United States; National Institute of Standards and Technology, Gaithersburg, MD, United States; IBM Research, Zurich, Switzerland; Institute for Logic, Language and Computation, University of Amsterdam, Amsterdam, Netherlands; Centrum for Wiskunde en Informatica, Amsterdam, Netherlands","Alagic, G., Joint Center for Quantum Information and Computer Science, University of Maryland, College Park, MD, United States, National Institute of Standards and Technology, Gaithersburg, MD, United States; Gagliardoni, T., IBM Research, Zurich, Switzerland; Majenz, C., Institute for Logic, Language and Computation, University of Amsterdam, Amsterdam, Netherlands, Centrum for Wiskunde en Informatica, Amsterdam, Netherlands","We study the problem of encrypting and authenticating quantum data in the presence of adversaries making adaptive chosen plaintext and chosen ciphertext queries. Classically, security games use string copying and comparison to detect adversarial cheating in such scenarios. Quantumly, this approach would violate no-cloning. We develop new techniques to overcome this problem: we use entanglement to detect cheating, and rely on recent results for characterizing quantum encryption schemes. We give definitions for (i) ciphertext unforgeability, (ii) indistinguishability under adaptive chosen-ciphertext attack, and (iii) authenticated encryption. The restriction of each definition to the classical setting is at least as strong as the corresponding classical notion: (i) implies$$\mathsf {INT\text {-}CTXT}$$, (ii) implies$$\mathsf {IND\text {-}CCA2}$$, and (iii) implies$$\mathsf {AE}$$. All of our new notions also imply$$\mathsf {QIND\text {-}CPA}$$ privacy. Combining one-time authentication and classical pseudorandomness, we construct symmetric-key quantum encryption schemes for each of these new security notions, and provide several separation examples. Along the way, we also give a new definition of one-time quantum authentication which, unlike all previous approaches, authenticates ciphertexts rather than plaintexts. © 2018, International Association for Cryptologic Research.",,"Authentication; Quantum entanglement; Authenticated encryption; Chosen ciphertext attack; Ciphertext query; Indistinguishability; Pseudorandomness; Quantum encryption; Security notion; Symmetric keys; Cryptography",,,,,"Aaronson, S., Gottesman, D., Improved simulation of stabilizer circuits. CoRR (2004) Quant-Ph/0406196; Aharonov, D., Ben-Or, M., Eban, E., Interactive proofs for quantum computations (2010) Proceedings of the Innovations in Computer Science - ICS 2010, Tsinghua University, Beijing, China, 5–7 January 2010, pp. 453-469; Alagic, G., Broadbent, A., Fefferman, B., Gagliardoni, T., Schaffner, C., St. Jules, M., Computational security of quantum encryption (2016) ICITS 2016. LNCS, 10015, pp. 47-71. , https://doi.org/10.1007/978-3-319-49175-23, Nascimento, A.C.A., Barreto, P. (eds.), Springer, Cham; Alagic, G., Gagliardoni, T., Majenz, C., Unforgeable quantum encryption (2017) Cryptology Eprint Archive, Report 2017/960, , https://eprint.iacr.org/2017/960; Alagic, G., Majenz, C., Quantum non-malleability and authentication (2017) CRYPTO 2017. LNCS, 10402, pp. 310-341. , https://doi.org/10.1007/978-3-319-63715-011, Katz, J., Shacham, H. (eds.), Springer, Cham; Ambainis, A., Bouda, J., Winter, A., Non-malleable encryption of quantum information (2009) J. Math. Phys, 50 (4); Ambainis, A., Mosca, M., Tapp, A., de Wolf, R., Private quantum channels (2000) 41St Annual Symposium on Foundations of Computer Science, FOCS 2000, Redondo Beach, California, USA, 12–14 November 2000, pp. 547-553; Barak, B., Cs127 course notes, Chap. 6 (2017) Accessed 7 Sept, , http://www.boazbarak.org/cs127/chap06 CCA.pdf; Barnum, H., Crépeau, C., Gottesman, D., Smith, A.D., Tapp, A., Authentication of quantum messages (2002) Proceedings of the 43Rd Symposium on Foundations of Computer Science (FOCS 2002), Vancouver, BC, Canada, 16–19 November 2002, pp. 449-458; Bellare, M., Namprempre, C., Authenticated encryption: Relations among notions and analysis of the generic composition paradigm (2000) ASI-ACRYPT 2000. LNCS, 1976, pp. 531-545. , https://doi.org/10.1007/3-540-44448-341, Okamoto, T. (ed.), Springer, Heidelberg; Boneh, D., Zhandry, M., Quantum-secure message authentication codes (2013) EUROCRYPT 2013. LNCS, 7881, pp. 592-608. , https://doi.org/10.1007/978-3-642-38348-935, Johansson, T., Nguyen, P.Q. (eds.), Springer, Heidelberg; Boneh, D., Zhandry, M., Canetti, R., Garay, J.A., Secure signatures and chosen ciphertext security in a quantum computing world (2013) CRYPTO 2013. LNCS, 8043, pp. 361-379. , https://doi.org/10.1007/978-3-642-40084-121, Springer, Heidelberg; Brandão, F.G.S.L., Harrow, A.W., Horodecki, M., Local random quantum circuits are approximate polynomial-designs (2016) Commun. Math. Phys., 346 (2), pp. 397-434; Broadbent, A., Jeffery, S., Quantum homomorphic encryption for circuits of low T-gate complexity (2015) CRYPTO 2015. LNCS, 9216, pp. 609-629. , https://doi.org/10.1007/978-3-662-48000-730, Gennaro, R., Robshaw, M. (eds.), Springer, Heidelberg; Broadbent, A., Wainewright, E., Efficient simulation for quantum message authentication (2016) ICITS 2016. LNCS, 10015, pp. 72-91. , https://doi.org/10.1007/978-3-319-49175-24, Nascimento, A.C.A., Barreto, P. (eds.), Springer, Cham; Divincenzo, D.P., Leung, D.W., Terhal, B.M., Quantum data hiding (2002) IEEE Trans. Inf. Theory, 48 (3), pp. 580-598; Dulek, Y., Schaffner, C., Speelman, F., Quantum homomorphic encryption for polynomial-sized circuits (2016) CRYPTO 2016. LNCS, 9816, pp. 3-32. , https://doi.org/10.1007/978-3-662-53015-31, Robshaw, M., Katz, J. (eds.), Springer, Heidelberg; Dupuis, F., Nielsen, J.B., Salvail, L., Secure two-party quantum evaluation of uni-taries against specious adversaries (2010) CRYPTO 2010. LNCS, 6223, pp. 685-706. , https://doi.org/10.1007/978-3-642-14623-737, Rabin, T. (ed.), Springer, Heidelberg; Dupuis, F., Nielsen, J.B., Salvail, L., Actively secure two-party evaluation of any quantum operation (2012) CRYPTO 2012. LNCS, 7417, pp. 794-811. , https://doi.org/10.1007/978-3-642-32009-546, Safavi-Naini, R., Canetti, R. (eds.), Springer, Heidelberg; Gagliardoni, T., Hülsing, A., Schaffner, C., Semantic security and indistinguishability in the quantum world (2016) CRYPTO 2016. LNCS, 9816, pp. 60-89. , https://doi.org/10.1007/978-3-662-53015-33, Robshaw, M., Katz, J. (eds.), Springer, Heidelberg; Garg, S., Yuen, H., Zhandry, M., New security notions and feasibility results for authentication of quantum data (2017) CRYPTO 2017. LNCS, 10402, pp. 342-371. , https://doi.org/10.1007/978-3-319-63715-012, Katz, J., Shacham, H. (eds.), Springer, Cham; Gottesman, D., (1998) The Heisenberg Representation of Quantum Computers. Arxiv Quant-Ph/9807006; Gottesman, D., Uncloneable encryption. Quantum Inf (2003) Comput, 3 (6), pp. 581-602; Hayden, P., Leung, D.W., (2016) Mayers, D.W.: The Universal Composable Security of Quantum Message Authentication with Key Recyling. Arxiv Quant-Ph/1610.09434; Katz, J., Lindell, Y., (2014) Introduction to Modern Cryptography, , 2nd edn. CRC Press, Boca Raton; Nielsen, M.A., Chuang, I.L., (2011) Quantum Computation and Quantum Information: 10Th Anniversary Edition, , 10th edn. Cambridge University Press, New York; Portmann, C., Quantum authentication with key recycling (2017) EUROCRYPT 2017. LNCS, 10212, pp. 339-368. , https://doi.org/10.1007/978-3-319-56617-712, Coron, J.-S., Nielsen, J.B. (eds.), Springer, Cham; Shrimpton, T., A characterization of authenticated-encryption as a form of chosen-ciphertext security (2004) IACR Cryptology Eprint Archive 2004:272; Winter, A.J., Coding theorem and strong converse for quantum channels (1999) IEEE Trans. Inf. Theory, 45 (7), pp. 2481-2485","Alagic, G.; Joint Center for Quantum Information and Computer Science, United States; email: galagic@umd.edu","Nielsen J.B.Rijmen V.","","Springer Verlag","37th Annual International Conference on the Theory and Applications of Cryptographic Techniques, EUROCRYPT 2018","29 April 2018 through 3 May 2018",,212999,03029743,9783319783710,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85045928606
"Iyengar S., Vidanage S.","7202158185;57201632769;","Campaigning through the media: Was 1992 really different?",2018,"The New American Politics: Reflections on Political Change and the Clinton Administration",,,,"51","66",,,"10.4324/9780429496202","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045465341&doi=10.4324%2f9780429496202&partnerID=40&md5=b157bcce9a8760229ae4fd9c67777119","UCLA, United States","Iyengar, S., UCLA, United States; Vidanage, S., UCLA, United States","Reporters, scholars, and general observers of the political scene unanimously regarded the 1992 election campaign as distinctive. The “standard operating procedures” followed by political campaigns became irrelevant as the candidates discovered new forms of campaign communication. Local news, talk-show, and call-in programs replaced network news and the Washington-New York press corps as the “flagship” outlets for campaign messages. The candidates relied less on attack advertising. Voters seemed more responsive to information about the candidates’ political capabilities and policy positions and less interested in matters of personality and character. Reporters abandoned their passive role as recorders of campaign events in favor of a more “adversarial” stance, and campaign messages became legitimate targets for journalistic interpretation and criticism. © 1995 Taylor & Francis.",,,,,,,,,,,"Taylor and Francis",,,,,,9780429964756; 9780813319735,,,"English","The New American Politics: Reflections on Political Change and the Clinton Administration",Book Chapter,"Final","",Scopus,2-s2.0-85045465341
"Kwon H., Yoon H., Choi D.","57197769092;15061371300;8660876600;","Friend-safe adversarial examples in an evasion attack on a deep neural network",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","10779 LNCS",,,"351","367",,,"10.1007/978-3-319-78556-1_20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044452538&doi=10.1007%2f978-3-319-78556-1_20&partnerID=40&md5=1eb4616c4038506d2a17d7ccfa5f1b58","Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea; Kongju National University, Gongju-si, South Korea","Kwon, H., Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea; Yoon, H., Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea; Choi, D., Kongju National University, Gongju-si, South Korea","Deep neural networks (DNNs) perform effectively in machine learning tasks such as image recognition, intrusion detection, and pattern analysis. Recently proposed adversarial examples—slightly modified data that lead to incorrect classification—are a severe threat to the security of DNNs. However, in some situations, adversarial examples might be useful, i.e., for deceiving an enemy classifier on a battlefield. In that case, friendly classifiers should not be deceived. In this paper, we propose adversarial examples that are friend-safe, which means that friendly machines can classify the adversarial example correctly. To make such examples, the transformation is carried out to minimize the friend’s wrong classification and the adversary’s correct classification. We suggest two configurations of the scheme: targeted and untargeted class attacks. In experiments using the MNIST dataset, the proposed method shows a 100% attack success rate and 100% friendly accuracy with little distortion (2.18 and 1.53 for each configuration, respectively). Finally, we propose a mixed battlefield application and a new covert channel scheme. © Springer International Publishing AG, part of Springer Nature 2018.","Adversarial example; Covert channel; Deep neural network; Evasion attack","Chromium compounds; Cryptography; Image recognition; Intrusion detection; Adversarial example; Covert channels; Evasion attack; Mnist dataset; Pattern analysis; Deep neural networks",,,,,"Schmidhuber, J., Deep learning in neural networks: An overview (2015) Neural Netw, 61, pp. 85-117; Simonyan, K., Zisserman, A., (2014) Very deep convolutional networks for large-scale image recognition; Hinton, G., Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups (2012) IEEE Sig. Process. Mag., 29 (6), pp. 82-97; Potluri, S., Diedrich, C., Accelerated deep neural networks for enhanced Intrusion Detection System (2016) 2016 IEEE 21St International Conference on Emerging Technologies and Factory Automation; Collobert, R., Weston, J., A unified architecture for natural language processing: Deep neural networks with multitask learning (2008) In: Proceedings of the 25Th International Conference on Machine Learning; Silver, D., Mastering the game of Go with deep neural networks and tree search (2016) Nature, 529 (7587), pp. 484-489; Szegedy, C., (2013) Intriguing properties of neural networks; McDaniel, P., Papernot, N., Celik, Z.B., Machine learning in adversarial settings (2016) IEEE Secur. Privacy, 14 (3), pp. 68-72; Lecun, Y., Cortes, C., Burges, C.J.C., (2010) MNIST Handwritten Digit Database, 2. , http://yann.lecun.com/exdb/mnist, AT&T Labs; Papernot, N., Distillation as a defense to adversarial perturbations against deep neural networks (2016) 2016 IEEE Symposium on Security and Privacy; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) 2017 IEEE Symposium on Security and Privacy; Smeets, M., Koot, M., Covert Channels (2006) Research Report for RPI University of Amsterdam Msc in System and Network Engineering; Barreno, M., The security of machine learning (2010) Mach. Learn., 81, pp. 121-148; Biggio, B., Nelson, B., Laskov, P., (2012) Poisoning attacks against support vector machines; Mozaffari-Kermani, M., Systematic poisoning attacks on and defenses for machine learning in healthcare (2015) IEEE J. Biomed. Health Inform., 19 (6), pp. 1893-1905; Yang, C., (2017) Generative poisoning attack method against neural networks; Papernot, N., The limitations of deep learning in adversarial settings (2016) 2016 IEEE European Symposium on Security and Privacy; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Deepfool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Biggio, B., Fumera, G., Roli, F., Security evaluation of pattern classifiers under attack (2014) IEEE Trans. Knowl. Data Eng., 26 (4), pp. 984-996; Cortes, C., Vapnik, V., Support vector machine (1995) Mach. Learn, 20 (3), pp. 273-297; Kleinbaum, D.G., Klein, M., (2010) Introduction to Logistic Regression, pp. 1-39. , https://doi.org/10.1007/978-1-4419-1742-3_1, Springer, New York; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and harnessing adversarial examples; Abadi, M., (2016) Tensorflow: Large-scale machine learning on heterogeneous distributed systems; Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324; Kingma, D., Ba, J., (2014) Adam: A method for stochastic optimization; Goodfellow, I., Generative adversarial nets (2014) Advances in Neural Information Processing Systems; Odena, A., Olah, C., Shlens, J., (2016) Conditional image synthesis with auxiliary classifier GANs","Choi, D.; Kongju National UniversitySouth Korea; email: sunchoi@kongju.ac.kr","Kim H.Kim D.",,"Springer Verlag","20th International Conference on Information Security and Cryptology, ICISC 2017","29 November 2017 through 1 December 2017",,212119,03029743,9783319785554,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","",Scopus,2-s2.0-85044452538
"Raj S., Pullum L., Ramanathan A., Jha S.K.","57194457254;7004505147;57204334274;57218716753;","SAT YA: Defending against adversarial attacks using statistical hypothesis testing",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","10723 LNCS",,,"277","292",,,"10.1007/978-3-319-75650-9_18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042553265&doi=10.1007%2f978-3-319-75650-9_18&partnerID=40&md5=01da19386ee4ee2d0dec2e1816eccd34","Computer Science Department, University of Central Florida, Orlando, FL, United States; Computational Science and Engineering Division, Oak Ridge National Laboratory, Oak Ridge, TN, United States","Raj, S., Computer Science Department, University of Central Florida, Orlando, FL, United States; Pullum, L., Computational Science and Engineering Division, Oak Ridge National Laboratory, Oak Ridge, TN, United States; Ramanathan, A., Computational Science and Engineering Division, Oak Ridge National Laboratory, Oak Ridge, TN, United States; Jha, S.K., Computer Science Department, University of Central Florida, Orlando, FL, United States","The paper presents a new defense against adversarial attacks for deep neural networks. We demonstrate the effectiveness of our approach against the popular adversarial image generation method DeepFool. Our approach uses Wald’s Sequential Probability Ratio Test to sufficiently sample a carefully chosen neighborhood around an input image to determine the correct label of the image. On a benchmark of 50,000 randomly chosen adversarial images generated by DeepFool we demonstrate that our method SAT YA is able to recover the correct labels for 95.76% of the images for CaffeNet and 97.43% of the correct label for GoogLeNet. © Springer International Publishing AG, part of Springer Nature 2018.",,"Testing; Image generations; Input image; Sequential probability ratio test; Statistical hypothesis testing; Deep neural networks",,,,,"Denton, E.L., Chintala, S., Fergus, R., Deep generative image models using a Laplacian pyramid of adversarial networks (2015) Advances in Neural Information Processing Systems, pp. 1486-1494; Fawzi, A., Fawzi, O., Frossard, P., (2015) Analysis of classifiers’ Robustness to Adversarial Perturbations; Fawzi, A., Fawzi, O., Frossard, P., Fundamental limits on adversarial robustness (2015) Proceedings of ICML, Workshop on Deep Learning; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances in Neural Information Processing Systems, pp. 2672-2680; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples; Grosse, K., Manoharan, P., Papernot, N., Backes, M., McDaniel, P.D., (2017) On the (Sta-Tistical) Detection of Adversarial Examples, , http://arxiv.org/abs/1702.06280, CoRR abs/1702.06280; Hendrik Metzen, J., Genewein, T., Fischer, V., Bischoff, B., (2017) On Detecting Adversarial Perturbations, , February; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems 25, pp. 1097-1105. , http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf, Pereira, F., Burges, C.J.C., Bottou, L., Weinberger, K.Q. (eds.), Curran Associates Inc., New York; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Machine Learning at Scale; Mirza, M., Osindero, S., (2014) Conditional Generative Adversarial Nets; Miyato, T., Maeda, S.I., Koyama, M., Nakae, K., Ishii, S., (2015) Distributional Smoothing with Virtual Adversarial Training; Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P., DeepFool: A simple and accurate method to fool deep neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582; Muller, M.E., A note on a method for generating points uniformly on n-dimensional spheres (1959) Commun. ACM, 2 (4), pp. 19-20. , http://doi.acm.org/10.1145/377939._377946; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 427-436; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: From Phenomena to Black-Box Attacks Using Adversarial Samples; Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B., Swami, A., The limitations of deep learning in adversarial settings (2016) 2016 IEEE European Symposium on Security and Privacy (EuroS&P), pp. 372-387; Raj, S., Ramanathan, A., Pullum, L.L., Jha, S.K., Testing autonomous cyber-physical systems using fuzzing features derived from convolutional neural networks (2017) ACM SIGBED International Conference on Embedded Software (EMSOFT). ACM, Seoul; Ramanathan, A., Pullum, L.L., Hussain, F., Chakrabarty, D., Jha, S.K., Integrating symbolic and statistical methods for testing intelligent systems: Applications to machine learning and computer vision (2016) 2016 Design, Automation & Test in Europe Conference & Exhibition (DATE), pp. 786-791; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Fei-Fei, L., ImageNet large scale visual recognition challenge (2015) Int. J. Comput. Vis. (IJCV), 115 (3), pp. 211-252; Sabour, S., Cao, Y., Faghri, F., Fleet, D.J., (2015) Adversarial Manipulation of Deep Representations; Shaham, U., Yamada, Y., Negahban, S., (2015) Understanding Adversarial Training: Increasing Local Stability of Neural Nets through Robust Optimization; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S.E., Anguelov, D., Erhan, D., Rabinovich, A., (2014) Going Deeper with Convolutions, , http://arxiv.org/abs/1409.4842, CoRR abs/1409.4842; Wald, A., (1947) Sequential Analysis, , Wiley, Hoboken","Raj, S.; Computer Science Department, United States; email: sraj@cs.ucf.edu","Imine A.Fernandez J.M.Logrippo L.Marion J.-Y.Garcia-Alfaro J.","","Springer Verlag","10th International Symposium on Foundations and Practice of Security, FPS 2017","23 October 2017 through 25 October 2017",,211059,03029743,9783319756493,,,"English","Lect. Notes Comput. Sci.",Conference Paper,"Final","",Scopus,2-s2.0-85042553265
[No author name available],[No author id available],"10th International Symposium on Foundations and Practice of Security, FPS 2017",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","10723 LNCS",,,"","",318,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042529567&partnerID=40&md5=8a6914e30e28725fb192224d7cd963d3",,"","The proceedings contain 20 papers. The special focus in this conference is on Foundations and Practice of Security. The topics include: Monitoring of security properties using beepbeep; more lightweight, yet stronger 802.15.4 security through an intra-layer optimization; ObliviousDB: Practical and efficient searchable encryption with controllable leakage; ethereum: State of knowledge and research perspectives; bounding the cache-side-channel leakage of lattice-based signature schemes using program semantics; extinguishing ransomware - a hybrid approach to android ransomware detection; deception in information security: Legal considerations in the context of German and European law; SAT YA: Defending against adversarial attacks using statistical hypothesis testing; attack graph-based countermeasure selection using a stateful return on investment metric; relationship-based access control for resharing in decentralized online social networks; weighted factors for evaluating anonymity; Secure protocol of ABAC certificates revocation and delegation; formal analysis of combinations of secure protocols; Formal analysis of the FIDO 1.x protocol; a roadmap for high assurance cryptography; privacy-preserving equality test towards big data; multi-level access control, directed graphs and partial orders in flow control for data secrecy and privacy; generation of applicative attacks scenarios against industrial systems.",,,,,,,,,"Imine A.Fernandez J.M.Logrippo L.Marion J.-Y.Garcia-Alfaro J.","","Springer Verlag","10th International Symposium on Foundations and Practice of Security, FPS 2017","23 October 2017 through 25 October 2017",,211059,03029743,9783319756493,,,"English","Lect. Notes Comput. Sci.",Conference Review,"Final","",Scopus,2-s2.0-85042529567
[No author name available],[No author id available],"2nd International Conference on Intelligent Information Technologies, ICIIT 2017",2018,"Communications in Computer and Information Science","808",,,"","",336,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041584607&partnerID=40&md5=049c3db47589fa812aa8417effff4cdb",,"","The proceedings contain 26 papers. The special focus in this conference is on Intelligent Information Technologies. The topics include: Efficient and robust secure in-network aggregation in wireless sensor networks; context-aware conditional probabilistic hyper-exponential reputation technique for mitigating byzantine attacks; Illumination and communication using LED as light source in underground mines; leveraging social networks for smart cities: A case-study in mitigation of air pollution; smart garbage bin systems – A comprehensive survey; contextual pattern clustering for ontology based activity recognition in smart home; E-FPROMETHEE: An entropy based fuzzy multi criteria decision making service ranking approach for cloud service selection; Workflow scheduling using IOT enabled reputation of service providers in the cloud; SCICS: A soft computing based intelligent communication system in VANET; Data consumption pattern of MQTT protocol for IoT applications; Classification and recommendation of competitive programming problems using CNN; a generic context-aware service discovery architecture for IoT services; understanding how adversarial noise affects single image classification; Top-k category search for an IP address-product network; booking based smart parking management system; VIBI: A braille inspired password entry model to assist person with visual impairments; a rehabilitation therapy for autism spectrum disorder using virtual reality; data access in heterogeneous data sources using object relational database; Optimization of UAV video frames for tracking; failure recovery using segment protection in software defined networks; spectrum sensing based heed routing performance enhancement strategy for cognitive radio sensor networks; Improved recommendation filtering component resilient to trust distortion attacks in a MANET.",,,,,,,,,"Venkataramani G.P.Sankaranarayanan K.Mukherjee S.Arputharaj K.Sankara Narayanan S.","","Springer Verlag","2nd International Conference on Intelligent Information Technologies, ICIIT 2017","20 December 2017 through 22 December 2017",,208649,18650929,9789811076343,,,"English","Commun. Comput. Info. Sci.",Conference Review,"Final","",Scopus,2-s2.0-85041584607
"Zhou P., Chang R.K.C., Gu X., Fei M., Zhou J.","56523808800;7403713440;24831969300;56503241800;35436693500;","Magic Train: Design of Measurement Methods against Bandwidth Inflation Attacks",2018,"IEEE Transactions on Dependable and Secure Computing","15","1","7360157","98","111",,5,"10.1109/TDSC.2015.2509984","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040734775&doi=10.1109%2fTDSC.2015.2509984&partnerID=40&md5=568a170b87b8b243e65103822cc372c8","School of Mechatronic Engineering and Automation, Shanghai University, Shanghai, 200072, China; Department of Computing, Hong Kong Polytechnic University, Hong Kong, Hong Kong; School of Information Science and Engineering, East China University of Science and Technology, Shanghai, 200237, China; Institute for Infocomm Research, Singapore, 138632, Singapore","Zhou, P., School of Mechatronic Engineering and Automation, Shanghai University, Shanghai, 200072, China; Chang, R.K.C., Department of Computing, Hong Kong Polytechnic University, Hong Kong, Hong Kong; Gu, X., School of Information Science and Engineering, East China University of Science and Technology, Shanghai, 200237, China; Fei, M., School of Mechatronic Engineering and Automation, Shanghai University, Shanghai, 200072, China; Zhou, J., Institute for Infocomm Research, Singapore, 138632, Singapore","Bandwidth measurement is important for many network applications and services, such as peer-to-peer networks, video caching and anonymity services. To win a bandwidth-based competition for some malicious purpose, adversarial Internet hosts may falsely announce a larger network bandwidth. Some preliminary solutions have been proposed to this problem. They can either evade the bandwidth inflation by a consensus view (i.e., opportunistic bandwidth measurements) or detect bandwidth frauds via forgeable tricks (i.e., detection through bandwidth's CDF symmetry). However, smart adversaries can easily remove the forgeable tricks and report an equally larger bandwidth to avoid the consensus analyses. To defend against the smart bandwidth inflation frauds, we design magic train, a new measurement method which combines an unpredictable packet train with estimated round-trip time (RTT) for detection. The inflation behaviors can be detected through highly contradictory bandwidth results calculated using different magic trains or a train's different segments, or large deviation between the estimated RTT and the RTT reported by the train's first packet. Being an uncooperative measurement method, magic train can be easily deployed on the Internet. We have implemented the magic train using RAW socket and LibPcap, and evaluated the implementation in a controlled testbed and the Internet. The results have successfully confirmed the effectiveness of magic train in detecting and preventing smart bandwidth inflation attacks. © 2017 IEEE.","Network measurement; Network security; Packet train","Distributed computer systems; Network security; Peer to peer networks; Anonymity service; Bandwidth measurements; Consensus analysis; Measurement methods; Network applications; Network measurement; New Measurement Method; Packet trains; Bandwidth",,,,,"Luo, X., Chan, E.W.W., Chang, R.K.C., Design and implementation of TCP data probes for reliable and metric-rich network path monitoring (2009) Proc. USENIX Annu. Tech. Conf., p. 4; Manish, J., Constantinos, D., End-to-end available bandwidth: Measurement methodology, dynamics, relation with TCP throughput (2002) ACM SIGCOMM Comput. Commun. Rev., 32 (4), pp. 295-308; Constantinos, D., Parameswaran, R., David, M., What do packet dispersion techniques measure (2001) Proc. Annu. Joint Conf. IEEE Comput. Commun. Soc., pp. 905-914; Crovella, M.E., Carter, R.L., (1995) Dynamic Server Selection in the Internet, , Boston Univ. Comput. Sci. Dept., Tech. Rep. TR-95-014; Paxson, V., End-to-end internet packet dynamics (1999) IEEE/ACM Trans. Netw., 7 (3), pp. 277-292. , Jun; Qiu, D., Srikant, R., Modeling and performance analysis of bittorrent-like peer-to-peer networks (2004) ACM SIGCOMM Comput. Commun. Rev., 34 (4), pp. 367-378; Hei, X., Liang, C., Liang, J., Liu, Y., Ross, K.W., A measurement study of a large-scale P2P IPTV system (2007) IEEE Trans. Multimedia, 9 (8), pp. 1672-1687. , Dec; Dingledine, R., Mathewson, N., Syverson, P., Tor: The secondgeneration onion router (2004) Proc. 13th Conf. USENIX Security Symp., p. 21; Snader, R., Borisov, N., A tune-up for Tor: Improving security and performance in the Tor network (2008) Proc. Netw. Distrib. Syst. Security Symp.; Snader, R., Borisov, N., Eigenspeed: Secure peer-to-peer bandwidth evaluation (2009) Proc. 8th Int. Workshop Peer-to-Peer Syst., p. 9; Karame, G., Danev, B., Bannwart, C., Capkun, S., On the security of end-to-end measurements based on packet-pair dispersions (2013) IEEE Trans. Inf. Forensics Security, 8 (1), pp. 149-162. , Jan; Mitchell, E., (2014) Dailymotion.com Redirects to Fake AV Threat, , http://www.invincea.com/2014/01/dailymotion-com-redirects-to-fake-av-threat/, [Online]. Available; Overlier, L., Syverson, P., Locating hidden servers (2006) Proc. IEEE Symp. Security Privacy, pp. 100-114; Bauer, K., McCoy, D., Grunwald, D., Kohno, T., Sicker, D., Low-resource routing attacks against (2007) Tor Proc. ACM Workshop Privacy Electron. Soc., pp. 11-20; Biryukov, A., Pustogarov, I., Weinmann, R.-P., Trawling for Tor hidden services: Detection, measurement, deanonymization (2013) Proc. IEEE Symp. Security Privacy, pp. 80-94; Karame, G., Capkun, S., (2009) On the Security of End-to-end Network Measurements, , http://www.syssec.ethz.ch/research/SecurityEndtoEnd.pdf, [Online]. Available; Devera, M., (2004) Htb Traffic Shaper, , http://luxik.cdi.cz/~devik/qos/htb/, [Online]. Available; (2013), http://www.netlimiter.com/, Netlimiter [Online].Available; (2014), http://www.netequalizer.com/, Netequalizer [Online]. Available; (2012) Linux Programmer's Manual-raw, (7). , http://man7.org/linux/man-pages/man7/raw.7.html, [Online]. Available; (2013), http://sourceforge.net/projects/libpcap/, The libpcap project [Online]. Available; Comer, D.E., (2008) Computer Networks and Internets, , Prentice Hall Press Upper Saddle River, NJ, USA; Crovella, M., (1996) Measuring Bottleneck Link Speed in Packetswitched Networks, , http://www.cs.bu.edu/~crovella/src/bprobe/Tools.html, [Online]. Available; Jacobson, V., (1997) Pathchar: A Tool to Infer Characteristics of Internet Paths, , http://www.caida.org/tools/utilities/others/pathchar/, [Online]. Available; Saroiu, S., Gummadi, P.K., Gribble, S.D., Sprobe: A fast technique for measuring bottleneck bandwidth in uncooperative environments (2002) Proc. IEEE Int. Conf. Comput. Commun.; Mah, B.A., (2005) Pchar: Atool for Measuring Internet Path Characteristics, , http://www.kitchenlab.org/www/bmah/Software/pchar/, [Online]. Available; Chan, E.W.W., Chen, A., Luo, X., Mok, R.K.P., Li, W., Chang, R.K.C., Trio: Measuring asymmetric capacity with three minimum round-trip times (2011) Proc. ACM CoNEXT Conf.; Chan, E.W.W., Chen, A., Luo, X., Mok, R.K.P., Li, W., Chang, R.K.C., (2013) G.992.5: Asymmetric Digital Subscriber Line 2 Transceivers (ADSL2)-extended Bandwidth ADSL2 (ADSL2plus), , http://www.itu.int/rec/T-REC-G.992.5/e, [Online]. Available; Carter, R.L., Crovella, M.E., Measuring bottleneck link speed in packet-switched networks (1996) Perform. Eval., 27, pp. 297-318; Pasztor, A., Veitch, D., The packet size dependence of packet pair like methods (2002) Proc. IEEE Int. Workshop Quality Serv., pp. 204-213; Dovrolis, C., Ramanathan, P., Moore, D., Packet-dispersion techniques and a capacity-estimation methodology (2004) IEEE/ACM Trans. Netw., 12 (6), pp. 963-977. , Dec; Kapoor, R., Chen, L.-J., Lao, L., Gerla, M., Sanadidi, M., Capprobe: A simple and accurate capacity estimation technique (2004) Proc. ACM SIGCOMM, pp. 67-78; Chen, L.-J., Sun, T., Wang, B.-C., Sanadidi, M., Gerla, M., Pbprobe: A capacity estimation tool for high speed networks (2008) Comput. Commun., 31 (17), pp. 3883-3893; Croce, D., En-Najjary, T., Urvoy-Keller, G., Biersack, E.W., Capacity estimation of ADSL links (2008) Proc. ACM CoNEXT Conf.; Chan, W.E.W., Luo, X., Chang, R.K.C., AMinimum-delay-differencemethod for mitigating cross-traffic impact on capacity measurement (2009) Proc. ACMCoNEXT Conference, pp. 205-216; Jansen, R., Miller, A., Syverson, P., Ford, B., From onions to shallots: Rewarding Tor relays with TEARS (2014) Proc. Workshop Hot Topics Privacy Enhancing Technol.; Karame, G.O., Towards trustworthy network measurements (2013) Proc. Int. Conf. Trust Trustworthy Comput., pp. 83-91; Zhou, P., Jiang, S., Irissappane, A., Zhang, J., Zhou, J., Teo, J.C.M., Toward energy-efficient trust system through watchdog optimization for wsns (2015) IEEE Trans. Inf. Forensics Security, 10 (3), pp. 613-625. , Mar; Zhou, P., Jiang, S., Irissappane, A., Zhang, J., Zhou, J., Teo, J.C.M., (2011) Open Flow, , http://archive.openflow.org/, [online]; Zhou, P., Chang, R.K.C., Gu, X., Fei, M., Zhou, J., (2015) Supplemental Material to Magic Train: Design of Measurement Methods Against Bandwidth Inflation Attacks, , http://zpbrent.github.io/SupplementalMaterial/MagicTrainSupple.pdf, [online]; Beizer, B., (1995) Black-Box Testing: Techniques for Functional Testing of Software and Systems, , Hoboken NJ USA: Wiley; Bland, J.M., Altman, D.G., Statistics notes: Measurement error (1996) Bmj, 313 (744). , 21 Sep; Postel, J., (1981) RFC 793: Transmission Control Protocol, , Sep. Updated by: 1122 3168, 6093 6528; Augustin, B., Friedman, T., Teixeira, R., Measuring multipath routing in the internet (2011) IEEE/ACM Trans. Netw., 19 (3), pp. 830-840. , Jun; Mirkovic, J., Dietrich, S., Dittrich, D., Reiher, P., (2004) Internet Denial of Service: Attack and Defense Mechanisms (Radia Perlman Computer Networking and Security), , London U.K.: Pearson Education; (2012) TCP Option 8, Timestamp, , http://www.networksorcery.com/enp/protocol/tcp/option008.htm, RFCSourceBook [Online]. Available; Braden, R., (1989) RFC 1122: Requirements for Internet Hosts-communication Layers, , Oct. Updated by: 1349 4379, 5884, 6093, 6298, 6633 6864; Hanley, J.A., McNeil, B.J., The meaning and use of the area under a receiver operating characteristic (roc) curve (1982) Radiology, 143 (1), pp. 29-36; Lockwood, J.W., McKeown, N., Watson, G., Gibb, G., Hartke, P., Naous, J., Raghuraman, R., Luo, J., NetFPGA-an open platform for Gigabit-rate network switching and routing (2007) Proc. IEEE Int. Conf. Microelectron. Syst. Educ., pp. 160-161; Avramopoulos, I.C., Rexford, J., Stealth probing: Efficient data-plane security for IP routing (2006) Proc. USENIX Annu. Tech. Conf, p. 25. , General Track; Goldberg, S., Xiao, D., Tromer, E., Barak, B., Rexford, J., Path-quality monitoring in the presence of adversaries (2008) ACM SIGMETRICS Perform. Eval. Rev., 36, pp. 193-204; Avramopoulos, I., (2006) Secure Data Delivery in Adversarial Networks, , Princeton, NJ, USA: Princeton Univ. Press; Snader, R., Borisov, N., Improving security and performance in the Tor network through tunable path selection (2011) IEEE Trans. Dependable Secure Comput., 8 (5), pp. 728-741. , Sep; Ghosh, M., Richardson, M., Ford, B., Jansen, R., A TorPath to TorCoin: Proof-of-bandwidth altcoins for compensating relays (2014) Proc. Workshop Hot Topics Privacy Enhancing Technol.","Gu, X.; School of Information Science and Engineering, China; email: xjing.gu@ecust.edu.cn",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,15455971,,,,"English","IEEE Trans. Dependable Secure Comput.",Article,"Final","",Scopus,2-s2.0-85040734775
"Ahlawat P., Dave M.","55479897300;7006803538;","An attack model based highly secure key management scheme for wireless sensor networks",2018,"Procedia Computer Science","125",,,"201","207",,15,"10.1016/j.procs.2017.12.028","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040700147&doi=10.1016%2fj.procs.2017.12.028&partnerID=40&md5=0c9a7b1bf3d55de03418c3ba6bd451cc","Department of Computer Engineering, National Institute of Technology, Kurukshetra, Haryana, India","Ahlawat, P., Department of Computer Engineering, National Institute of Technology, Kurukshetra, Haryana, India; Dave, M., Department of Computer Engineering, National Institute of Technology, Kurukshetra, Haryana, India","Wireless sensor network (WSN) security is a critical issue due to its inherent characteristic and unattended operation which makes it vulnerable to many attacks. Key management plays a fundamental role for providing security services to such networks. In this paper, we aim to reduce the node capture impact by incorporating an efficient adversarial model for cellular model of WSN. The adversarial model exploits several vulnerabilities present in the network such as high node density, placement of the sink node, neighbour influence factor to compute the compromise probability of each cell. It then defines the hash chain length for each cell with different rekey interval to increase the network resistance against node capture attack. The proposed scheme is compared with other existing schemes in terms of the probability of key compromise and the number of links rekeyed. The results confirm its effectiveness in increasing the WSN security. © 2018 The Authors. Published by Elsevier B.V.","Attack model; Key management scheme; Node capture attack; Rekeying; Wireless sensor network","Sensor nodes; Wireless sensor networks; Attack model; Inherent characteristics; Key management schemes; Network resistance; Node capture attack; Re-keying; Secure key management scheme; Security services; Network security",,,,,"He, X., Neidermeier, M., Meer, H., Dynamic key management in wireless sensor network: A survey (2013) Journal of Network and Computer Applications, 36, pp. 612-622; Aikyildiz, I.F., Su, W., Sankarasubramaniam, Cayir, E., Wireless sensor networks: A survey (2002) Computer Networks, 38 (4), pp. 393-422; Zhang, J., Varadharajan., Wireless sensor network key management survey and taxonomy (2010) Journal of Network and Computer Applications, 33, pp. 63-75; Eschenauer, L., Gligor, V., A key-management scheme for distributed sensor networks (2002) Proceedings of 9th ACM Conference on Computer and Communications Security, pp. 41-47; Chan, H., Perrig, A., Song, D., Random key predistribution schemes for sensor networks (2003) Proceedings of 2003 IEEE Symposium on Security and Privacy, pp. 197-213. , California, USA; Du, W., Deng, J., Han, Y.S., Chen, S., Varshney, P.K., A key management scheme for wireless sensor networks using deployment knowledge (2004) INFOCOM 2004. Twenty-third AnnualJoint Conference of the IEEE Computer and Communications Societies, 1. , (March) IEEE; Bechkit, W., Challal, Y., Bouadallah, A., A new class of hash chain based key predistribution scheme for WSN (2013) Computer Communications, 36, pp. 243-255; Ehdaie, M., Alexiou, N., Ahmadian, M., Aref, M.R., Papadimitratos, P., 2D Hash Chain robust Random Key Distribution scheme (2016) Information Processing Letters, 116 (5), pp. 367-372; Kůr, J., Matyáš, V., Švenda, P., Two improvements of random key predistribution for wireless sensor networks (2012) International Conference on Security and Privacy in Communication Systems, pp. 61-75. , September Springer Berlin Heidelberg; Yu, W., A pairwise key management scheme based on hash function for wireless sensor networks (2010) IEEE Second Inter. Workshop on Education Technology and Computer Science; Shan, T., Liu, C., Enhancing the key pre-distribution scheme on wireless sensor networks (2008) IEEE Asia-Pacific Conf. Services Computing, IEEE Computer Society; Mishra, A., Turuk, A., Adversary information gathering model for node capture attack in wireless sensor networks (2011) International Conference on Devices and Communications, ICDeCom2011, pp. 1-5; Bonaci, T., Bushnell, L., Poovendran, R., Node capture attacks in wireless sensor networks: A system theoretic approach (2010) Proceedings of 49th IEEE Conference on Decision and Control, CDC 2010, pp. 6765-6772. , IEEE; De, P., Liu, Y., Das, S., Deployment-aware modeling of node compromise spread in wireless sensor networks using epidemic theory (2009) ACM Transactions on Sensor Networks, 5 (3), pp. 1-33; Tague, P., (2009) Identifying, Modeling, and Mitigating Attacks in Wireless Ad-hoc and Sensor Networks. Ph.D. Thesis, , University of Washington Washington, USA 2009; Tague, P., Slater, D., Rogers, J., Poovendran, R., Evaluating the vulnerability of network traffic using joint security and routing analysis (2009) IEEE Transactions on Dependable and Secure Computing, 6, pp. 111-123; Wu, G., Chen, X., Obaidet, M.S., Lin, C., A high efficient node capture attack algorithm in wireless sensor network based on route minimum key set (2012) Security and Communication Networks, 6, pp. 230-238; Lin, C., Wu, G., Enhancing the attacking efficiency of the node capture attack in WSN: A matrix approach (2013) Journal of Supercomputing, 66 (2), pp. 989-1007; Lin, C., Wu, G., Qiu, T., Deng, J., A low cost node capture algorithm for wireless sensor networks (2015) International Journal of Communication Systems, , DOI: 10.1002/dac.3097; Chen, X., Makki, K., Yen, K., Pissinou, N., Attack distribution modeling and its applications in sensor network security (2007) EURASIP Journal on Wireless Communications and Networking, 2008, pp. 1-11; Yu, C.-M., Li, C.-C., Lu, C.-S., Kuo, S.-Y., An application driven attack probability based deterministic pair-wise key predistribution scheme for non uniformly deployed sensor networks (2011) International Journal of Sensor Networks, 9 (2), pp. 89-106; Biswas, S., Haque, M.M., Rashwand, S., Misic, J., Fast, seamless rekeying in wireless sensor networks (2009) Distributed Computing Systems Workshops, 2009. ICDCS Workshops' 09. 29th IEEE International Conference on, pp. 166-171. , June IEEE; Ahlawat, P., Dave, M., An improved hybrid key management scheme for wireless sensor networks (2016) Parallel, Distributed and Grid Computing (PDGC), 2016 Fourth International Conference on, pp. 253-258. , December IEEE; Lin, C., Qiu, T., Obaidat, M.S., Yu, C.W., Yao, L., Wu, G., MREA: A minimum resource expenditure node capture attack in wireless sensor networks (2016) Security and Communication Networks; Ahlawat, P., Dave, M., A Hybrid Approach for Path Vulnerability Matrix on Random Key Predistribution for Wireless Sensor Networks (2017) Wireless Personal Communications, 94 (4), pp. 3327-3353","Ahlawat, P.; Department of Computer Engineering, India; email: priyankaahlawat@nitkkr.ac.in","Singh A.K.Jimson J.","","Elsevier B.V.","6th International Conference on Smart Computing and Communications, ICSCC 2017","7 December 2017 through 8 December 2017",,133386,18770509,,,,"English","Procedia Comput. Sci.",Conference Paper,"Final","All Open Access, Gold",Scopus,2-s2.0-85040700147
"Ravishankar M., Vijay Rao D., Kumar C.R.S.","57194009004;56099050800;57190246096;","Game theoretic software test-bed for cyber security analysis of critical infrastructure",2018,"Defence Science Journal","68","1",,"54","63",,3,"10.14429/dsj.68.11402","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039800229&doi=10.14429%2fdsj.68.11402&partnerID=40&md5=9b542dfb684d3efaabb6754dfce59b9d","DRDO-Defence Institute of Advanced Technology, Pune, 411 025, India; DRDO-Institute for Systems Studies and Analyses, Delhi, 110054, India","Ravishankar, M., DRDO-Defence Institute of Advanced Technology, Pune, 411 025, India; Vijay Rao, D., DRDO-Institute for Systems Studies and Analyses, Delhi, 110054, India; Kumar, C.R.S., DRDO-Defence Institute of Advanced Technology, Pune, 411 025, India","National critical infrastructures are vital to the functioning of modern societies and economies. The dependence on these infrastructures is so succinct that their incapacitation or destruction has a debilitating and cascading effect on national security. Critical infrastructure sectors ranging from financial services to power and transportation to communications and health care, all depend on massive information communication technology networks. Cyberspace is composed of numerous interconnected computers, servers and databases that hold critical data and allow critical infrastructures to function. Securing critical data in a cyberspace that holds against growing and evolving cyber threats is an important focus area for most countries across the world. A novel approach is proposed to assess the vulnerabilities of own networks against adversarial attackers, where the adversary's perception of strengths and vulnerabilities are modelled using game theoretic techniques. The proposed game theoretic framework models the uncertainties of information with the players (attackers and defenders) in terms of their information sets and their behaviour is modelled and assessed using a probability and belief function framework. The attack-defence scenarios are exercised on a virtual cyber warfare test-bed to assess and evaluate vulnerability of cyber systems. Optimal strategies for attack and defence are computed for the players which are validated using simulation experiments on the cyber war-games testbed, the results of which are used for security analyses. © 2018, DESIDOC.","Belief functions; Critical infrastructure; Cyber war-games testbed; Game theory; Negotiations","Computer crime; Computers; Equipment testing; Game theory; Military applications; National security; Public works; Security systems; Software testing; Testbeds; Uncertainty analysis; Belief function; Cascading effects; Cyber war; Information communication technology; Interconnected computer; Negotiations; Optimal strategies; Security analysis; Critical infrastructures",,,,,"Amoroso, E.G., (2010) Cyber Attacks: Protecting National Infrastructure, , BH, Elsevier; Cyber Attacks on Critical Infrastructure Insights from Wargaming., , https://warontherocks.com/2017/07/cyber-attacks-on-criticalinfrastructure-insights-from-war-gaming/, Accessed on 21 September 2017; Cyber Attacks Against Critical Infrastructure., , https://ics-cert.us-cert.gov/alerts/IR-ALERT-H-16-056-01, Accessed on 21 September 2017; The Real Cyber Threat, , http://www.thehindu.com/opinion/lead/lead-article-by-mk-narayanan-on-aadhaar-bill-the-cyberthreat-is-very-real/article8371335.ece, Accessed on 21 September 2017; https://thewire.in/118541/national-security-case-aadhaar/, [Accessed on 21 September 2017]; Gueye, A., (2011) A Game Theoretical Approach to Communication Security., , University of California, Berkeley, (PhD Thesis); Lin, F.Y.S., Yen, H.H., Chen, P.Y., Maximization of network survivability considering degree of disconnectivity (2011) Proceedings of 7th International Wireless Communications and Mobile Computing Conference, , June; Alpcan, T., Baser, T., Network Security: A Decision and Game-theoretic Approach. 1st Ed, , Cambridge University Press, November 2010; Alpcan, T., Baser, T., A game theoretic analysis of intrusion detection in access control systems (2004) Proceedings of the 43rd IEEE Conference on Decision and Control; Shiva, S., Roy, S., Dasgupta, D., Game theory for cyber security (2010) Proceedings of the Sixth Annual Workshop on Cyber Security and Information Intelligence Research., , ACM. New York, USA; Roy, S., Ellis, C., Shiva, S., Dasgupta, D., Shandilya, V., Wu, Q., A survey of game theory as applied to network security (2010) 43rdHawaii International Conference on System Sciences; Shiva, S., Roy, S., Bedi, H., Dasgupta, D., Wu, Q., A stochastic game model with imperfect information in cyber security (2010) 5th International Conference on I-warfare and Security; Tadelis, S., (2013) Game Theory: An Introduction, , Princeton University, ISBN: 9780691129082; Duncan, R.D., Raiffa, H., Games and decisions: Introduction and critical survey (1957) Courier Corporation, , ISBN: 9780486659435; Ravishankar, M., Rao, D.V., Kumar, C.R.S., A game theoretic approach to modelling jamming attacks in delay tolerant networks (2017) Def. Sci. J., 67 (3), pp. 282-290; Ramirez-Marquez, J.E., Rocco, C.M., Levitin, G., Optimal network protection against diverse interdictor strategies (2011) Reliability Eng. Sys. Safety., 96 (3), pp. 237-282; Chen, P.Y., Shih, I.J., Lin, F.Y.S., Maximization of multi-round network survivability under considerations of the defender's defensive messaging strategies (2013) International Conference on MOBILe Wireless MiddleWARE, Operating Systems and Applications; Bier, V.M., Oliveros, S., Samuelson, L., Choosing what to protect: Strategic defensive allocation against an unknown attacker (2007) J. Public Economic Theory, 9 (4), pp. 563-587; Dighe, N.S., Zhuang, J., Bier, V.M., Secrecy in defensive allocations as a strategy for achieving more cost-effective (2009) Int. J. Performability Eng., 5 (1), pp. 31-43; Shafer, G., Kaufmann, M., (1990) Readings in Uncertain Reasoning.; Colbert, E., Kott, A., Cyber-security of SCADA and other industrial control systems (2017) Proceedings of 12th International Conference on Cyber Warfare and Security, USA; Sommestad, T., Hallberg, J., Cyber security exercises and competitions as a platform for cyber security experiments Secure IT Systems, p. 7617. , Edited by Jøsang A., Carlsson B. NordSec 2012. Lecture Notes in Computer Science., Springer, Berlin, Heidelberg; Siaterlis, C., Perez-Garcia, A., Masera, M., Using an emulation Test-bed for operational cyber security exercises ICCIP 2011: Critical Infrastructure Protection v, pp. 185-199; Kennedy, D., O'Gorman, J., Metasploit, K.D., (2011) The Penetration Tester's Guide, , No Starch Press, ISBN: 978-1593272883; Chappel, L., (2012) Wireshark Network Analysis: The Official Wireshark Certified Network Analyst Study Guide, , Chappel University; Berger, J.O., (2013) Statistical Decision Theory: Foundations, Concepts, and Methods, , Springer Science & Business Media; Ingre, Y., Yadhav, A., Performance analysis of NSL-KDD dataset using ANN Proceedings of 2015 International Conference on Signal Processing and Communication Engineering Systems (SPACES); Colin, C., Ho, T., Experience-weighed attraction learning in normal form games (1999) Econometrica, 67 (4), pp. 827-874; Vulnerability Metrics, , https://nvd.nist.gov/vuln-metrics/cvss, Accessed on 21 September 2017",,,,"Defense Scientific Information and Documentation Centre",,,,,0011748X,,DSJOA,,"English","Def. Sci. J.",Article,"Final","",Scopus,2-s2.0-85039800229
"Chondros N., Roussopoulos M.","35316992400;13906276100;","Developing IntegrityCatalog, a software system for managing integrity-related metadata in digital repositories",2018,"Software - Practice and Experience","48","1",,"45","64",,,"10.1002/spe.2515","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037739307&doi=10.1002%2fspe.2515&partnerID=40&md5=f1b52d3bca3b95b160780f8b0213d9dd","Department of Informatics and Telecommunications, University of Athens, Athens, 157 84, Greece","Chondros, N., Department of Informatics and Telecommunications, University of Athens, Athens, 157 84, Greece; Roussopoulos, M., Department of Informatics and Telecommunications, University of Athens, Athens, 157 84, Greece","Digital repositories must periodically check the integrity of stored objects to assure users of their correctness. Prior solutions calculate integrity metadata and require the repository to store it alongside the actual data objects. To safeguard and detect damage to this metadata, prior solutions rely on widely visible media (unaffiliated third parties) to store and provide back digests of the metadata to verify it is intact. However, they do not address recovery of the integrity metadata in case of damage or adversarial attack. We introduce IntegrityCatalog, a novel software system that can be integrated into any digital repository. It collects all integrity-related metadata in a single component and treats them as first class objects, managing both their integrity and their preservation. We introduce a treap-based persistent authenticated dictionary managing arbitrary length key/value pairs, which we use to store all integrity metadata, accessible simply by object name. Additionally, IntegrityCatalog is a distributed system that includes a network protocol that manages both corruption detection and preservation of this metadata, using administrator-selected network peers with 2 possible roles. Verifiers store and offer attestations on digests and have minimal storage requirements, while preservers efficiently synchronize a complete copy of the catalog to assist in recovery in case of a detected catalog compromise on the local system. We present our approach in developing the prototype implementation, measure its performance experimentally, and demonstrate its effectiveness in real-world situations. We believe the implementation techniques of our open-source IntegrityCatalog will be useful in the construction of next-generation digital repositories. Copyright © 2017 John Wiley & Sons, Ltd.","digital repositories; integrity checking; software system","Computer software; Computer system recovery; Digital storage; Network protocols; Open source software; Digital repository; Distributed systems; Implementation techniques; Integrity checking; Prototype implementations; Real world situations; Software systems; Storage requirements; Metadata",,,,,"(2009) Etsi ts 101 903: Xml advanced electronic signatures (xades), , http://uri.etsi.org/01903/v1.4.1/ts_101903v010401p.pdf; Gondrom, T., Brandner, R., Pordesch, U., (2007) Evidence Record Syntax (ERS), , http://www.ietf.org/rfc/rfc4998.txt, RFC 4998 (Proposed Standard); Haber, S., Kamat, P., A content integrity service for long-term digital archives, , http://www.hpl.hp.com/techreports/2006/HPL-2006-54.html, Technical Report HPL-2006-54, Hewlett Packard Laboratories May 18 2006; Maniatis, P., Rosenthal, D.S.H., Roussopoulos, M., Baker, M., Giuli, T., Muliadi, Y., Preserving peer replicas by rate-limited sampled voting (2003) Proceedings of the nineteenth ACM Symposium on Operating Systems Principles, Operating Systems Review, 5, 37. , ACM Press, New York; Song, S., JáJá, J., (2007) New techniques for ensuring the long term integrity of digital archives, 228. , http://doi.acm.org/10.1145/1248460.1248470, Paper presented at DG.O, ACM International Conference Proceeding Series, Cushing JB, Pardo TA eds., Digital Government Research Center,, Philadelphia, Pennsylvania, USA; (2016) European open science cloud, , http://ec.europa.eu/research/openscience/index.cfm?pg=open-science-cloud; Naor, M., Yung, M., Universal one-way hash functions and their cryptographic applications (1989) Proceedings of the 21st Annual Symposium on Theory of Computing (STOC'89), , ACM Association for Computing Machinery, New York; Menezes, A.J., van Oorschot, P.C., Vanston, S., (1996) Handbook of Applied Cryptography, , http://www.cacr.math.uwaterloo.ca/hac/, Boca Raton, FL, USA, CRC Press; Merkle, R., (1987) A digital signature based on a conventional encryption function, , CRYPTO; Driscoll, J.R., Sarnak, N., Sleator, D.D., Tarjan, R.E., (1986) Making data structures persistent, , Paper presented at ACM Symposium on Theory of Computing (STOC'86);, ACM Press, Baltimore, USA; Anagnostopoulos, A., Goodrich, M.T., Tamassia, R., Persistent authenticated dictionaries and their applications (2001) Lect Notes Comput Sci, 2200, pp. 379-393. , http://link.springer-ny.com/link/service/series/0558/bibs/2200/22000379.htm; Aragon, C.R., Seidel, R.G., (1989) Randomized search trees, , Paper presented at 30th Annual Symposium on Foundations of Computer Science, IEEE, Research Triangle Park, North Carolina, USA;; Seidel, C.R., Aragon, R.G., Randomized search trees (1996) Algorithmica, 16, pp. 464-497; Austern, M.H., Stroustrup, B., Thorup, M., Wilkinson, J., Untangling the balancing and searching of balanced binary search trees (2003) Softw Pract Exp, 33 (13), pp. 1273-1298. , http://dx.doi.org/10.1002/spe.564; Zobel, J., Moffat, A., Sacks-Davis, R., Storage management for files of dynamic records (1993) Proceedings of the 4th Australian Database Conference, (ADC), , Griffith University, Brisbane, Queensland, Australia;; Williams, H., Zobel, J., Heinz, S., Self-adjusting trees in practice for large text collections (2001) Softw Pract Exp, 31 (10), pp. 925-939. , http://dx.doi.org/10.1002/spe.394; Parrish, A., Dixon, B., Cordes, D., Vrbsky, S., Lusth, J., Implementing persistent data structures using c++ (1998) Softw Pract Exp, 28 (15), pp. 1559-1579. , http://dx.doi.org/10.1002/(SICI)1097-024X(19981225)28:15<1559::AID-SPE214>3.0.CO;2-7; Maniatis, P., Baker, M., Secure history preservation through timeline entanglement (2002) Proceedings of the 11th USENIX Security Symposium (SECURITY-02), , USENIX Association, Berkeley, CA, USA; (2013) Clueweb12 dataset (the lemur project), , http://www.lemurproject.org/clueweb12; (2002) Secure Hash Standard, , http://csrc.nist.gov/publications/fips/fips180-2/fips180-2.pdf, National Institute for Standards and Technology, pub-NISTadr; Harrison, Implementation of the substring test by hashing (1971) CACM: Comm ACM, 14, pp. 777-779; Rabin, M.O., (1981) Fingerprinting by random polynomials, , Center for Research in Computing Technology, Harvard University; Karp, R., Efficient randomized pattern-matching algorithms (1987) IBM J Res Dev, 31 (2), pp. 249-260; Schwarz, T., Miller, E., (2006) Store, forget, and check: Using algebraic signatures to check remotely administered storage, , Paper presented at 26th IEEE International Conference on Distributed Computing Systems (26th ICDCS'06);, IEEE Computer Society, Lisboa, Portugal; Zlotnick, F., (2006) ZFS: The last word in file systems, , Paper presented at The Conference on High Speed Computing;, LANL/LLNL/SNL, Salishan Lodge, Gleneden Beach, Oregon; Zhang, Y., Rajimwale, A., Arpaci-Dusseau, A.C., Arpaci-Dusseau, R.H., End-to-end data integrity for file systems: A ZFS case study (2010) FAST, pp. 29-42. , http://www.usenix.org/events/fast10/tech/full_papers/zhang.pdf, In, Burns RC, Keeton K, eds., USENIX, San Jose, CA, USA;; Papamanthou, C., Tamassia, R., Triandopoulos, N., Authenticated hash tables based on cryptographic accumulators (2016) Algorithmica, 74 (2), pp. 664-712; Crosby, S.A., (2009) Efficient tamper-evident data structures for untrusted servers, , PhD Thesis., Rice University; Crosby, S.A., Wallach, D.S., Super-efficient aggregating history-independent persistent authenticated dictionaries (2009) ESORICS, Lecture Notes in Computer Science, vol. 5789, pp. 671-688. , In, Backes M, Ning P, eds., Saint-Malo, France, Springer; Clarke, I., Sandberg, O., Wiley, B., Hong, T.W., (2000) Freenet: a distributed anonymous information storage and retrieval system, , Paper presented at International Workshop on Design Issues in Anonymity and Unobservability, Berkeley, CA, USA;; Adya, A., Bolosky, W.J., Castro, M., FARSITE: Federated, available, and reliable storage for an incompletely trusted environment (2002) Proceedings 5th Symposium on Operating System Design and Implementation (5th OSDI'02), Culler, DE, Druschel, P eds., USENIX Association, Boston, Massachusetts, , USA; Waldman, M., Rubin, A.D., Cranor, L.F., Publius: A robust, tamper-evident, censorship-resistant Web publishing system (2000) Proceedings of the Ninth USENIX Security Symposium, August 14–17, 2000, Denver, Colorado, , http://www.usenix.org/publications/library/proceedings/sec2000/waldman.html, USENIX ed. USENIX pub-USENIXadr; Chang, H.T., Chang, Y.M., Hsiao, S.Y., Scalable network file systems with load balancing and fault tolerance for web services (2014) J Syst Softw, 93, pp. 102-109; Wong, W.H.L., Ng, J.K.Y., Scalable peer-to-peer networking architecture: Divine (2006) Softw Pract Exp, 36 (13), pp. 1467-1487. , https://doi.org/10.1002/spe.730; Quinlan, S., Dorward, S., Venti: A new approach to archival data storage (2002) Proceedings of the FAST'02 Conference on File and Storage Technologies (FAST-02), , USENIX Association, Berkeley, CA; Kubiatowicz, J., Bindel, D., Chen, Y., Oceanstore: An architecture for global-scale persistent storage (2000) ASPLOS, pp. 190-201. , http://dl.acm.org/citation.cfm?id=378993, In, Rudolph L, Gupta A, eds., Cambridge, MA, USA, ACM Press; Dabek, F., Kaashoek, M.F., Karger, D.R., Morris, R., Stoica, I., Wide-area cooperative storage with CFS (2001) SOSP, pp. 202-215. , https://doi.org/10.1145/502034.502054; Cox, L.P., Murray, C.D., Noble, B., Pastiche: Making backup cheap and easy (2002) Proceedings of the 5th ACM Symposium on Operating System Design and Implementation (OSDI-02), , Operating Systems Review, ACM Press New York; Cox, L.P., Noble, B.D., Samsara: Honor among thieves in peer-to-peer storage (2003) Proceedings of the nineteenth ACM Symposium on Operating Systems Principles, Operating Systems Review, 5, 37. , ACM Press, New York; Subbiah, A., Blough, D., An approach for fault tolerant and secure data storage in collaborative work environments (2005) StorageSS, pp. 84-93. , https://doi.org/10.1145/1103780.1103793, In, Atluri V, Samarati P, Yurcik W, Brumbaugh L, Zhou Y, eds., ACM; Goodson, G.R., Wylie, J.J., Ganger, G.R., Reiter, M.K., (2004) Efficient byzantine-tolerant erasure-coded storage, , https://doi.org/10.1109/DSN.2004.1311884, Paper presented at 2004 International Conference on Dependence System and Networks, IEEE Computer Society;; Haeberlen, A., Mislove, A., Druschel, P., (2005) Glacier: Highly durable, decentralized storage despite massive correlated failures, , http://www.usenix.org/events/nsdi05/tech/haeberlen.html, In NSDI, USENIX;; Rosenthal, D.S., Rosenthal, D.C., Miller, E.L., Adams, I.F., Storer, M.W., Zadok, E., (2012) The economics of long-term digital storage. Memory of the World in the Digital Age, , Vancouver, BC; Rosenthal, D.S., Vargas, D.L., Distributed digital preservation in the cloud (2013) Int J Digit Curation, 8 (1), pp. 107-119; Lillibridge, M., Elnikety, S., Birrell, A., Burrows, M., Isard, M., (2003) A cooperative internet backup scheme, , http://www.usenix.org/events/usenix03/tech/lillibridge.html, Paper presented at USENIX Annual Technical Conference, General Track, USENIX, San Antonio, Texas, USA;; Wang, C., Wang, Q., Ren, K., Cao, N., Lou, W., Toward secure and dependable storage services in cloud computing (2012) IEEE Trans Serv Comput, 5 (2), pp. 220-232; Yu, Y., Niu, L., Yang, G., Mu, Y., Susilo, W., On the security of auditing mechanisms for secure cloud storage (2014) Futur Gener Comput Syst, 30, pp. 127-132; Chen, L., Using algebraic signatures to check data possession in cloud storage (2013) Futur Gener Comput Syst, 29 (7), pp. 1709-1715; Xiao, D., Yang, Y., Yao, W., Wu, C., Liu, J., Yang, Y., Multiple-file remote data checking for cloud storage (2012) Comput Secur, 31 (2), pp. 192-205; He, J., Zhang, Y., Huang, G., Shi, Y., Cao, J., Distributed data possession checking for securing multiple replicas in geographically-dispersed clouds (2012) J Comput Syst Sci, 78 (5), pp. 1345-1358; Shah, M., Swaminathan, R., Baker, M., Privacy-preserving audit and extraction of digital contents (2008) IACR Cryptology ePrint Archive, p. 186. , http://eprint.iacr.org/2008/186; Worku, S.G., Xu, C., Zhao, J., He, X., Secure and efficient privacy-preserving public auditing scheme for cloud storage (2014) Comput Electr Eng, 40 (5), pp. 1703-1713; Zhu, Y., Hu, H., Ahn, G.J., Yau, S.S., Efficient audit service outsourcing for data integrity in clouds (2012) J Syst Softw, 85 (5), pp. 1083-1095; Samanthula, B.K., Elmehdwi, Y., Howser, G., Madria, S., A secure data sharing and query processing framework via federation of cloud computing (2015) Inf Syst, 48, pp. 196-212; Muniswamy-Reddy, K.K., Macko, P., Seltzer, M.I., Provenance for the cloud (2010) FAST, 10, pp. 14-15; Hasan, R., Sion, R., Winslett, M., The case of the fake picasso: Preventing history forgery with secure provenance (2009) FAST, 9, pp. 1-14; Nakamoto, S., (2008) Bitcoin: A peer-to-peer electronic cash system; Wood, G., Ethereum: A secure decentralised generalised transaction ledger (2014) Ethereum Project Yellow Paper, 151, pp. 1-32","Roussopoulos, M.; Department of Informatics and Telecommunications, Greece; email: mema@di.uoa.gr",,,"John Wiley and Sons Ltd",,,,,00380644,,SPEXB,,"English","Software Pract Exper",Article,"Final","",Scopus,2-s2.0-85037739307
"An L., Yang G.-H.","56585307900;7405751358;","Improved adaptive resilient control against sensor and actuator attacks",2018,"Information Sciences","423",,,"145","156",,71,"10.1016/j.ins.2017.09.042","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029703636&doi=10.1016%2fj.ins.2017.09.042&partnerID=40&md5=b1e53bf2fe2a0644eb55f029f3f51226","College of Information Science and Engineering, Northeastern University, Shenyang, 110819, China; State Key Laboratory of Synthetical Automation of Process Industries, Northeastern University, Liaoning, Shenyang, 110819, China","An, L., State Key Laboratory of Synthetical Automation of Process Industries, Northeastern University, Liaoning, Shenyang, 110819, China; Yang, G.-H., College of Information Science and Engineering, Northeastern University, Shenyang, 110819, China, State Key Laboratory of Synthetical Automation of Process Industries, Northeastern University, Liaoning, Shenyang, 110819, China","In this paper, an improved adaptive resilient control scheme is proposed for mitigating adversarial attacks in cyber-physical systems (CPSs). By introducing a two-step backstepping approach, an adaptive bound estimation mechanism and a Nussbam function with faster growth rate, the effects of unknown sensor and actuator attacks are successfully mitigated. An exponentially-decaying barrier Lypunov function is used to constrain state variables. Compared with the existing results where only uniform ultimate boundedness is achieved, the developed controller guarantees that the closed-loop system is asymptotically stable and simultaneously the state constraints are not violated even in the presence of the time-varying sensor and actuator attacks. Simulation results are presented to verify the efficacy of the proposed scheme. © 2017 Elsevier Inc.","Actuator attacks; Adaptive control; Asymptotic stability; Resilient control; Sensor attacks; State constraints","Actuators; Asymptotic stability; Backstepping; Closed loop systems; Embedded systems; Adaptive bound estimation; Adaptive Control; Asymptotically stable; Back-stepping approaches; Cyber physical systems (CPSs); Resilient control; State constraints; Uniform ultimate boundedness; Adaptive control systems",,,,,"Amin, S., Crdenas, A.A., Sastry, S.S., Safe and secure networked control systems under denial-of-service attacks (2009) Hybrid Systems: Computation and Control, pp. 31-45. , Springer-Verlag Berlin, Germany; Ao, W., Song, Y.D., Wen, C.Y., Adaptive cyber-physical system attack detection and reconstruction with application to power systems (2016) IET Control Theory Appl., 10, pp. 1458-1468; Corona, I., Giacinto, G., Roli, F., Adversarial attacks against intrusion detection systems: taxonomy, solutions and open issues (2013) Inf. Sci., 239, pp. 201-225; Dolk, V.S., Tesi, P., De Persis, C., Heemels, W.P.M.H., Event-triggered control systems under denial-of-service attacks (2017) IEEE Trans. Control Netw. Syst.; Guo, Z.Y., Shi, D.W., Johansson, K.H., Shi, L., Optimal linear cyber-attack on remote state estimation (2017) IEEE Trans. Control Netw. Syst.; Hudaa, S., Miah, S., Hassand, M.M., Islamc, R., Yearwood, J., Alrubaian, M., Ahmad almogren, defending unknown attacks on cyber-physical systems by semi-supervised approach and available unlabeled data (2017) Inf. Sci., 379, pp. 211-228; Jin, X., Haddad, W.M., Yucelen, T., An adaptive control architecture for mitigating sensor and actuator attacks in cyber-physical systems (2017) IEEE Trans. Autom. Control; Kwon, C., Hwang, I., Cyber attack mitigation for cyber-physical systems: hybrid system approach to controller design (2016) IET Control Theory Appl., 10, pp. 731-741; Krstic, M., Kanellakopoulos, I., Kokotovic, P.V., (1995) Nonlinear and Adaptive Control Design, , Wiley New York; Liu, M., Daniel, W.C.H., Shi, P., Adaptive fault-tolerant compensation control for markovian jump systems with mismatched external disturbance (2015) Automatica, 58, pp. 5-14; Lin, W., Qian, C.J., Adaptive control of nonlinearly parameterized systems: the smooth feedback case (2002) IEEE Trans. Autom. Control, 47, pp. 1249-1266; Li, X.J., Yang, G.-H., Robust adaptive fault-tolerant control for uncertain linear systems with actuator failures (2012) IET Control Theory Appl., 6, pp. 1544-1551; Li, Y.M., Tong, S.C., Adaptive neural networks decentralized FTC design for nonstrict-feedback nonlinear interconnected large-scale systems against actuator faults (2017) IEEE Trans. Neural Netw. Learning Syst.; Li, Y.M., Ma, Z., Tong, S.C., Adaptive fuzzy output-constrained fault-tolerant control of nonlinear stochastic large-scale systems with actuator faults (2017) IEEE Trans. Cyber.; Li, Y.Z., Shi, L., Chen, T.W., Detection against linear deception attacks on multi-sensor remote state estimation (2017) IEEE Trans. Control Netw. Syst.; Liu, Y.J., Tong, S.C., Barrier Lyapunov functions for Nussbaum gain adaptive control of full state constrained nonlinear systems (2017) Automatica, 76, pp. 143-152; Liu, Y.J., Lu, S.M., Li, D.J., Adaptive controller design-based ABLF for a class of nonlinear time-varying state constraint systems (2017) IEEE Trans. Syst. Man Cyber. Syst., 47, pp. 1546-1553; Liu, Y.J., Lu, S.M., Tong, S.C., Neural network controller design for an uncertain robot with time-varying output constraint (2017) IEEE Trans. Syst. Man Cyber. Syst., 47, pp. 2060-2068; Mo, Y.L., Sinopoli, B., (2009) Secure Control against Replay Attacks, in Allerton Conf. on Communications, Control and Computing, , Urbana-Champaign, IL; Mo, Y.L., Chabukswar, R., Sinopoli, B., Detecting integrity attacks on SCADA systems (2014) IEEE Trans. Control Syst. Tech., 22, pp. 1369-1407; Tee, K.P., Ge, S.Z.S., Tay, E.H., Barrier Lyapunov functions for the control of output-constrained nonlinear systems (2009) Automatica, 45, pp. 918-927; Tong, S.C., Huo, B.Y., Li, Y.M., Observer-based adaptive decentralized fuzzy fault-tolerant control of nonlinear large-scale systems with actuator failures (2014) IEEE Trans. Fuzzy Syst., 22, pp. 1-15; Tong, S.C., Wang, T., Li, Y.M., Fuzzy adaptive actuator failure compensation control of uncertain stochastic nonlinear systems with unmodeled dynamics (2014) IEEE Trans. Fuzzy Syst., 22, pp. 563-574; Wang, C.L., Wen, C.Y., Lin, Y., Adaptive actuator failure compensation for a class of nonlinear systems with unknown control directions (2015) IEEE Trans. Autom. Control; Wei, D., Ji, K., Resilient industrial control system (RICS): concepts, formulation, metrics, and insights (2010) Proc. of 3rd Intl. Symp. on Resilient Control Systems (ISRCS), pp. 1-8; Wei, J., Mendis, G.J., A deep learning-based cyber-physical strategy to mitigate false data injection attack in smart grids (2016) IEEE Cyber-Physical Secur. Resil. Smart Grids (CPSR-SG), Joint Workshop on; Wu, J., Chen, T.W., Design of networked control systems with packet dropouts (2007) IEEE Trans. Autom. Control, 52, pp. 1314-1319; Wang, J.X., Liu, Z.X., Zhang, S.G., Zhang, X., Defending collaborative false data injection attacks in wireless sensor networks (2014) Inf. Sci., 254, pp. 39-53; Wang, W., Wen, C., Adaptive actuator failure compensation control of uncertain nonlinear systems with guaranteed transient performance (2010) Automatica, 46, pp. 2082-2091; Yucelen, T., Haddad, W.M., Feron, E.M., Adaptive control architectures for mitigating sensor attacks in cyber-physical systems (2016) Cyber-Physical Syst., 2, pp. 24-52; Zhou, J., Wen, C., Zhang, Y., Adaptive backstepping control of a class of uncertain nonlinear systems with unknown backlash-like hysteresis (2004) IEEE Trans. Autom. Control, 49, pp. 1751-1759; Zhu, M.H., Martnez, S., On the performance analysis of resilient networked control systems under replay attacks (2014) IEEE Trans. Autom. Control, 59, pp. 804-808; Zhu, Q.Y., Basar, T., Robust and resilient control design for cyber-physical systems with an application to power systems (2011) Proc. 50th IEEE Conf. Decision and Control and European Control Conference, Orlando, FL, USA, pp. 4066-4071","Yang, G.-H.; College of Information Science and Engineering, China; email: yangguanghong@ise.neu.edu.cn",,,"Elsevier Inc.",,,,,00200255,,ISIJB,,"English","Inf Sci",Article,"Final","",Scopus,2-s2.0-85029703636
"Truong A., Etesami S.R., Etesami J., Kiyavash N.","35238783600;55845944700;55006058300;13104840200;","Optimal Attack Strategies Against Predictors - Learning from Expert Advice",2018,"IEEE Transactions on Information Forensics and Security","13","1","7954673","6","19",,5,"10.1109/TIFS.2017.2718488","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021809302&doi=10.1109%2fTIFS.2017.2718488&partnerID=40&md5=b3dec8e73f693e2e6ca0b8398c2cad29","Department of Industrial and Enterprise Systems Engineering, University of Illinois at Urbana-Champaign, Urbana, IL  61801, United States; Department of Electrical Engineering, Princeton University, Princeton, NJ  08644, United States; Coordinated Science Laboratory, Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana, IL  61801, United States; Industrial and Enterprise Systems Engineering, University of Illinois at Urbana-Champaign, Urbana, IL  61801, United States","Truong, A., Department of Industrial and Enterprise Systems Engineering, University of Illinois at Urbana-Champaign, Urbana, IL  61801, United States; Etesami, S.R., Department of Electrical Engineering, Princeton University, Princeton, NJ  08644, United States; Etesami, J., Department of Industrial and Enterprise Systems Engineering, University of Illinois at Urbana-Champaign, Urbana, IL  61801, United States; Kiyavash, N., Coordinated Science Laboratory, Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana, IL  61801, United States, Industrial and Enterprise Systems Engineering, University of Illinois at Urbana-Champaign, Urbana, IL  61801, United States","Motivated by many real-world examples, such as recommendation systems or sensor fusion, and aiming to capture the influence of malicious experts who intentionally degrade the performance of learning systems, we analyze optimal adversarial strategies against the weighted average prediction algorithm in the learning with expert advice framework. All but one expert is honest and the malicious expert's goal is to sabotage the performance of the algorithm by strategically providing dishonest recommendations. We formulate the problem as a Markov decision process and analyze it under various settings. For the logarithmic loss, somewhat surprisingly, we prove that the optimal strategy for the adversary is the greedy policy, i.e., lying at every step. For the absolute loss, in the 2-experts, discounted cost setting, we prove that the optimal strategy is a threshold policy, where the malicious expert tells the truth until he earns enough weight and then lies afterwards. We extend the results to the infinite horizon problem and find the exact thresholds for the stationary optimal policy. Finally, we use a mean field approach in the N-experts setting to find the optimal strategy when the predictions of the honest experts are independent and identically distributed. We justify our results using simulations throughout this paper. © 2017 IEEE.","dynamic programming; expert advice; Learning algorithm; malicious experts; Markov decision process; threshold policy; weighted average prediction","Dynamic programming; Education; Forecasting; Markov processes; Optimal systems; Statistical methods; Expert advice; malicious experts; Markov Decision Processes; Threshold policies; Weighted averages; Learning algorithms",,,,,"Vovk, V.G., Aggregating strategies (1990) Proc. 3rd Annu. Workshop Comput. Learn. Theory (COLT), pp. 371-386. , San Francisco, CA, USA; Littlestone, N., Warmuth, M.K., The weighted majority algorithm (1989) Proc. 30th Annu. Symp. Found. Comput. Sci., pp. 212-261. , Research Triangle Park, NC, USA, Feb; Cesa-Bianchi, N., Lugosi, G., (2006) Prediction, Learning, and Games., , Oakland, CA, USA: Cambridge Univ. Press; Cesa-Bianchi, N., Freund, Y., Helmbold, D., Haussler, D., Schapire, R.E., Warmuth, M.K., How to use expert advice (1993) Proc. 25th Annu. ACM Symp. Theory Comput. (STOC), pp. 427-485. , New York, NY, USA, May; Douceur, J.R., The sybil attack (2002) Proc. Int. Workshop Peer-to-Peer Syst., pp. 251-260. , London, U.K; Freund, Y., Schapire, R.E., A decision-theoretic generalization of on-line learning and an application to boosting (1995) Proc. 2nd Eur. Conf. Comput. Learn. Theory (EuroCOLT), pp. 23-37. , London, U.K; Kalai, A., Vempala, S., Efficient algorithms for online decision problems (2005) J. Comput. Syst. Sci., 71 (3), pp. 291-307; Kleinberg, R., Niculescu-Mizil, A., Sharma, Y., Regret bounds for sleeping experts and bandits (2010) Mach. Learn., 80 (2-3), pp. 245-272; Kanade, V., McMahan, B., Bryan, B., Sleeping experts and bandits with stochastic action availability and adversarial rewards (2009) Proc. 12th Int. Conf. Artif. Intell. Statist., pp. 272-279. , Clearwater Beach, FL, USA; Rooij, S.D., Erven, T.V., Grünwald, P.D., Koolen, W.M., Follow the leader if you can, hedge if you must (2014) J. Mach. Learn. Res., 15 (15), pp. 1281-1316; Newsome, J., Karp, B., Song, D., Paragraph: Thwarting signature learning by training maliciously (2006) Proc. 9th Int. Conf. Recent Adv. Intrusion Detection, pp. 81-105. , Berlin, Germany; Chung, S.P., Mok, A.K., Allergy attack against automatic signature generation (2006) Proc. 9th Int. Conf. Recent Adv. Intrusion Detection, pp. 61-80. , Berlin, Germany; Huang, L., Joseph, A.D., Nelson, B., Rubinstein, B.I.P., Tygar, J.D., Adversarial machine learning (2011) Proc. 4th ACM Workshop Secur. Artif. Intell., pp. 43-58. , New York, NY, USA; Cao, Q., Sirivianos, M., Yang, X., Pregueiro, T., Aiding the detection of fake accounts in large scale social online services (2012) Proc. 9th USENIX Conf. Netw. Syst. Des. Implement., p. 15. , Berkeley, CA, USA; Tran, N., Min, B., Li, J., Subramanian, L., Sybil-resilient online content voting (2009) Proc. 6th USENIX Symp. Netw. Syst. Des. Implement., pp. 15-28. , Berkeley, CA, USA; Govindan, K., Mohapatra, P., Trust computations and trust dynamics in mobile AdHoc networks: A survey (2012) IEEE Commun. Surveys Tuts., 14 (2), pp. 279-298. , 2nd Quart; Resnick, P., Sami, R., The information cost of manipulationresistance in recommender systems (2008) Proc. 2008 ACM Conf. Recommender Syst., pp. 147-154. , New York, NY, USA; Yu, H., Shi, C., Kaminsky, M., Gibbons, P.B., Xiao, F., Dsybil: Optimal sybil-resistance for recommendation systems (2009) Proc. 30th IEEE Symp. Secur. Privacy, pp. 283-298. , Washington, DC, USA; Venkataraman, S., Blum, A., Song, D., Limits of learning-based signature generation with adversaries (2008) Proc. Netw. Distrib. Syst. Secur. Symp. (NDSS), pp. 287-297. , San Diego, CA, USA; Nelson, B., Exploiting machine learning to subvert your spam filter (2008) Proc. 1st Usenix Workshop Large-Scale Exploits Emergent Threats, pp. 71-79. , Berkeley, CA, USA; Cover, T.M., Behavior of sequential predictors of binary sequences (1965) Proc. 4th Prague Conf. Inf. Theory, Statist. Decision Funct. Random Process., pp. 263-272. , Prague, Czech Republic; Gravin, N., Peres, Y., Sivan, B., Towards optimal algorithms for prediction with expert advice (2016) Proc. 27th Annu. ACM-SIAM Symp. Discrete Algorithms, pp. 528-547. , Philadelphia, PA, USA; Abernethy, J., Warmuth, M.K., Yellin, J., When random play is optimal against an adversary (2008) Proc. 21th Annu. Workshop Comput. Learn. Theory (COLT), pp. 437-446. , Helsinki, Findland; Bellman, R., A Markovian decision process (1957) J. Math. Mech., 6 (5), pp. 679-684. , Apr; Howard, A.R., (1960) Dynamic Programming and Markov Processes., , Cambridge, MA, USA: MIT Press; Truong, A., Kiyavash, N., Optimal adversarial strategies in learning with expert advice (2013) Proc. 52th IEEE Conf. Decision Control, pp. 7315-7320. , Florence, Italia, Dec; Blackwell, D., Discounted dynamic programming (1965) Ann. Math. Statist., 36 (1), pp. 226-235; Fudenberg, D., Tirole, J., (1991) Game Theory., , Cambridge, MA, USA: MIT Press; Osborne, M.J., Rubinstein, A., (1994) A Course in Game Theory., , Cambridge, MA, USA: MIT Press","Truong, A.; Department of Industrial and Enterprise Systems Engineering, United States; email: truong3@illinois.edu",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,15566013,,,,"English","IEEE Trans. Inf. Forensics Secur.",Article,"Final","",Scopus,2-s2.0-85021809302
"Fadaee S.S., Ghaemi M.S., Soufiani H.A., Sundaram R.","56419965800;57200296305;55699679000;24308811000;","Chiron: A robust recommendation system with graph regularizer",2018,"Advances in Intelligent Systems and Computing","578",,,"367","376",,,"10.1007/978-3-319-59162-9_38","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019230833&doi=10.1007%2f978-3-319-59162-9_38&partnerID=40&md5=ad8ef78e22b01e3846240760a4c36b49","College of Computer and Information Science, Northeastern University, Boston, United States; École Polytechnique de Montréal, Montreal, Canada; Columbia Business School, New York City, United States","Fadaee, S.S., College of Computer and Information Science, Northeastern University, Boston, United States; Ghaemi, M.S., École Polytechnique de Montréal, Montreal, Canada; Soufiani, H.A., Columbia Business School, New York City, United States; Sundaram, R., College of Computer and Information Science, Northeastern University, Boston, United States","Recommendation systems have been widely used by commercial service providers for giving suggestions to users. Collaborative filtering (CF) systems, one of the most popular recommendation systems, utilize the history of behaviors of the aggregate user-base to provide individual recommendations and are effective when almost all users faithfully express their opinions. However, they are vulnerable to malicious users biasing their inputs in order to change the overall ratings of a specific group of items. CF systems largely fall into two categories -neighborhood-based and (matrix) factorization-based - and the presence of adversarial input can influence recommendations in both categories, leading to instabilities in estimation and prediction. Although the robustness of different collaborative filtering algorithms has been extensively studied, designing an efficient system that is immune to manipulation remains a challenge. We propose a novel hybrid recommendation system with an adaptive graph user/item similarity-regularization - Chiron. Chiron ties the performance benefits of dimensionality reduction (via factorization) with the advantage of neighborhood clustering (through regularization). We demonstrate, using extensive comparative experiments, that Chiron is resistant to manipulation by large and lethal attacks. © Springer International Publishing AG 2018.",,"Collaborative filtering; Factorization; Collaborative filtering algorithms; Collaborative filtering systems; Commercial services; Comparative experiments; Dimensionality reduction; Estimation and predictions; Hybrid recommendation; Performance benefits; Recommender systems",,,,,"MovieLens. http://grouplens.org/datasets/movielens/; Agarwal, A., Anandkumar, A., Jain, P., Netrapalli, P., Tandon, R., Learning sparsely used overcomplete dictionaries via alternating minimization (2013) Corr Abs/1310, p. 7991. , http://arxiv.org/abs/1310.7991; Belkin, M., Niyogi, P., Sindhwani, V., Manifold regularization: A geometric framework for learning from labeled and unlabeled examples (2006) J. Mach. Learn. Res, 7, pp. 2399-2434. , http://dl.acm.org/citation.cfm?id=1248547.1248632; Bennett, J., Lanning, S., Netflix, N., The netflix prize (2007) KDD Cup and Workshop in Conjunction with KDD; Burke, R., Mobasher, B., Williams, C., Bhaumik, R., Classification features for attack detection in collaborative recommender systems (2006) Proceedings of the 12Th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD 2006; Cai, D., He, X., Han, J., Huang, T.S., Graph regularized non-negative matrix factorization for data representation (2011) IEEE Trans. Pattern Anal. Mach. Intell, 33 (8), pp. 1548-1560; Cosley, D., Lam, S.K., Albert, I., Konstan, J.A., Riedl, J., Is seeing believing? How recommender system interfaces affect users’ opinions (2003) Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI 2003, pp. 585-592. , NY, USA, ACM, New York; Lam, S.K., Riedl, J., Shilling recommender systems for fun and profit (2004) Proceedings of the 13Th International Conference on World Wide Web, WWW 2004, NY, pp. 393-402. , ACM, New York; Lee, J., Sun, M., Lebanon, G., A comparative study of collaborative filtering algorithms (2012) Corr Abs/1205, p. 3193. , http://arxiv.org/abs/1205.3193; Lee, J., Sun, M., Lebanon, G., Prea: Personalized recommendation algorithms toolkit (2012) J. Mach. Learn. Res, 13 (1), pp. 2699-2703; Mehta, B., Unsupervised shilling detection for collaborative filtering (2007) AAAI 2007, 2, pp. 1402-1407. , Proceedings of the 22nd National Conference on Artificial Intelligence,. AAAI Press; Mehta, B., Hofmann, T., A survey of attack-resistant collaborative filtering algorithms (2008) IEEE Data Eng. Bull, 31 (2), pp. 14-22; Mehta, B., Nejdl, W., Attack resistant collaborative filtering (2008) SIGIR 2008, pp. 75-82. , Proceedings of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,, NY, USA, ACM, New York; Mobasher, B., Burke, R., Bhaumik, R., Williams, C., Toward trustworthy recommender systems: An analysis of attack models and algorithm robustness. (2007) ACM Trans. Internet Technol, 7 (4), p. 23; O’Mahony, M., Hurley, N., Silvestre, G., Promoting recommendations: An attack on collaborative filtering (2002) Database and Expert Systems Applications. Lecture Notes in Computer Science, 2453, pp. 494-503. , Springer, Heidelberg; Resnick, P., Sami, R., Manipulation-resistant recommender systems through influence limits (2008) Sigecom Exchanges, 7 (3). , http://dblp.uni-trier.de/db/journals/sigecom/sigecom7.html#ResnickS08; Zhang, S., Ouyang, Y., Ford, J., Makedon, F., Analysis of a low-dimensional linear model under recommendation attacks (2006) Proceedings of the 29Th Annual International ACM SIGIR Conference on Research and Development in Information Retrievalsigir 2006; Zhou, D., Bousquet, O., Lal, T.N., Weston, J., Schölkopf, B., Learning with local and global consistency (2004) Advances in Neural Information Processing Systems 16, pp. 321-328. , http://papers.nips.cc/paper/2506-learning-with-local-and-global-consistency.pdf, Thrun, S., Saul, L.K., Schölkopf, B. (eds.), . MIT Press","Sundaram, R.; College of Computer and Information Science, United States; email: koods@ccs.neu.edu","Kurzynski M.Wozniak M.Burduk R.","","Springer Verlag","10th International Conference on Computer Recognition Systems, CORES 2017","22 May 2017 through 24 May 2017",,191709,21945357,9783319591612,,,"English","Adv. Intell. Sys. Comput.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85019230833
"Khan Z., Lehtomäki J., Vasilakos A.V., MacKenzie A.B., Juntti M.","55421908300;6603165008;57200495061;8327665000;7004091452;","Adaptive wireless communications under competition and jamming in energy constrained networks",2018,"Wireless Networks","24","1",,"151","171",,1,"10.1007/s11276-016-1324-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976350930&doi=10.1007%2fs11276-016-1324-x&partnerID=40&md5=e03ab94f58e41c108326b5353880a537","Centre for Wireless Communications, University of Oulu, Erkki Koiso-Kanttilan katu 3, Oulu, 90570, Finland","Khan, Z., Centre for Wireless Communications, University of Oulu, Erkki Koiso-Kanttilan katu 3, Oulu, 90570, Finland; Lehtomäki, J., Centre for Wireless Communications, University of Oulu, Erkki Koiso-Kanttilan katu 3, Oulu, 90570, Finland; Vasilakos, A.V., Centre for Wireless Communications, University of Oulu, Erkki Koiso-Kanttilan katu 3, Oulu, 90570, Finland; MacKenzie, A.B., Centre for Wireless Communications, University of Oulu, Erkki Koiso-Kanttilan katu 3, Oulu, 90570, Finland; Juntti, M., Centre for Wireless Communications, University of Oulu, Erkki Koiso-Kanttilan katu 3, Oulu, 90570, Finland","We propose a framed slotted Aloha-based adaptive method for robust communication between autonomous wireless nodes competing to access a channel under unknown network conditions such as adversarial disruptions. With energy as a scarce resource, we show that in order to disrupt communications, our method forces the reactive adversary to incur higher energy cost relative to a legitimate node. Consequently, the adversary depletes its energy resources and stops attacking the network. Using the proposed method, a transmitter node changes the number of selected time slots and the access probability in each selected time slot based on the number of unsuccessful transmissions of a data packet. On the receiver side, a receiver node changes the probability of listening in a time slot based on the number of unsuccessful communication attempts of a packet. We compare the proposed method with two other framed slotted Aloha-based methods in terms of average energy consumption and average time required to communicate a packet. For performance evaluation, we consider scenarios in which: (1) Multiple nodes compete to access a channel. (2) Nodes compete in the presence of adversarial attacks. (3) Nodes compete in the presence of channel errors and capture effect. © 2016, Springer Science+Business Media New York.","Adaptations; Autonomous nodes; Distributed networks; Energy-constraints; Jamming; Reactive adversary; Robust protocol","Energy resources; Energy utilization; Wireless telecommunication systems; Adaptations; Autonomous nodes; Distributed networks; Energy constraint; Reactive adversary; Robust protocol; Jamming",,,,,"Huang, P., Xiao, L., Soltani, S., Mutka, M., Ning, X., The evolution of MAC protocols in wireless sensor networks: A survey (2013) IEEE Communications Surveys Tutorials, 15 (1), pp. 101-120. , First; Vázquez-Gallego, F., Alonso, L., Alonso-Zarate, J., Modeling and analysis of reservation frame slotted-aloha in wireless machine-to-machine area networks for data collection (2015) Sensors, Special Issue Wireless Sensor Networks and the Internet of Things, 15 (2), pp. 3911-3931; Jeon, W., Jeong, D., Combined channel access and sensing in cognitive radio slotted-aloha networks (2015) IEEE Transactions on Vehicular Technology, 64 (5), pp. 2128-2133; Okada, H., Igarashi, Y., Nakanishi, Y., Analysis and application of framed ALOHA channel in satellite packet switching networks-FADRA method (1977) Electronics Communications of Japan, 60, pp. 72-80; Munari, A., Heindlmaier, M., Liva, G., Berioli, M., The throughput of slotted aloha with diversity (2013) In Proceedings of the 51st annual allerton conference on communication, control, and computing (Allerton) (pp, pp. 698-706; Bajovic, D., Jakovetic, D., Vukobratovic, D., Crnojevic, V.S., Slotted Aloha for networked base stations (2014) In Proceedings of the IEEE international conference on communications workshops (ICC) (pp, pp. 520-526; MacKenzie, A., Wicker, S., Stability of multipacket slotted aloha with selfish users and perfect information (2003) In Proceedings of the twenty-second annual joint conference of the IEEE computer and communications (INFOCOM) (pp, pp. 1583-1590; Wu, H., Zhu, C., La, R., Liu, X., Zhang, Y., Fasa: Accelerated S-ALOHA using access history for event-driven M2M communications (2013) IEEE/ACM Transactions on Networking, 21 (6), pp. 1904-1917; Xu, W., Trappe, W., Zhang, Y., Wood, T., The feasibility of launching and detecting jamming attacks in wireless networks (2005) In Proceedings of the 6th ACM international symposium on mobile ad hoc networking and computing (MobiHoc) (pp, pp. 46-57; Wilhelm, M., Martinovic, I., Schmitt, J.B., Lenders, V., Short paper: Reactive jamming in wireless networks: How realistic is the threat? (2011) Proceedings of the fourth ACM conference on wireless network security (WiSec, pp. 47-52; Raymond, R., Midkiff, S., Denial-of-service in wireless sensor networks: Attacks and defenses (2008) IEEE Pervasive Computing, 7 (1), pp. 74-81; Proano, A., Lazos, L., Selective jamming attacks in wireless networks (2010) In Proceedings of the IEEE international conference on communications (ICC) (pp, pp. 1-6; Richa, A., Scheideler, C., Schmid, S., Zhang, J., An efficient and fair mac protocol robust to reactive interference (2013) IEEE/ACM Transactions on Networking, 21 (3), pp. 760-771; Pelechrinis, K., Iliofotou, M., Krishnamurthy, S., Denial of service attacks in wireless networks: The case of jammers (2011) IEEE Communications Surveys Tutorials, 13 (2), pp. 245-257; Ma, R., Misra, V., Rubenstein, D., An analysis of generalized slotted-aloha protocols (2009) IEEE/ACM Transactions on Networking, 17 (3), pp. 936-949; Law, Y., Palaniswami, M., Hoesel, L., Doumen, J., Hartel, P., Havinga, P., Energy-efficient link-layer jamming attacks against wireless sensor network MAC protocols (2009) ACM Transactions on Sensor Networks, 5 (1), pp. 6:1-6:38; Young, M., Boutaba, R., Overcoming adversaries in sensor networks: A survey of theoretical models and algorithmic approaches for tolerating malicious interference (2011) IEEE Communications Surveys Tutorials, 13 (4), pp. 617-641; King, V., Saia, J., Young, M., Conflict on a communication channel (2011) Proceedings of the 30th annual symposium on Principles of distributed computing (PODC, pp. 277-286; D’Oro, S., Galluccio, L., Morabito, G., Palazzo, S., Chen, L., Martignon, F., Defeating jamming with the power of silence: A game-theoretic analysis (2015) IEEE Transactions on Wireless Communications; Boukerche, A., Li, X., (2005) An agent-based trust and reputation management scheme for wireless sensor networks. In IEEE global telecommunications conference, (GLOBECOM) (Vol. 3, pp. 1–5); Boukerche, A., Ren, Y., A secure mobile healthcare system using trust-based multicast scheme (2009) IEEE Journal on Selected Areas in Communications, 27 (4), pp. 387-399; Ren, Y., Werner, R., Pazzi, N., Boukerche, A., Monitoring patients via a secure and mobile healthcare system (2010) IEEE Wireless Communications, 17 (1), pp. 59-65; Boukerche, A., Cheng, X., Linus, J., Energy-aware data-centric routing in microsensor networks (2003) Proceedings of the 6th ACM international workshop on modeling analysis and simulation of wireless and mobile systems, ser. MSWIM ’03, pp. 42-49; Boukerche, A., (2005) Handbook of algorithms for wireless networking and mobile computing, , (ed), Taylor and Francis Group, CRC Press, Boca Raton; Liu, J., Wan, J., Wang, Q., Deng, P., Zhou, K., Qiao, Y., A survey on position-based routing for vehicular ad hoc networks (2015) Telecommunication Systems, 62 (1), pp. 15-30; Chen, M., Wan, J., Gonzalez, S., Liao, X., Leung, V.C.M., A survey of recent developments in home M2M networks (2014) IEEE Communications Surveys Tutorials, 16 (1), pp. 98-114; Li, X., Li, D., Wan, J., Vasilakos, A.V., Lai, C.-F., Wang, S., A review of industrial wireless networks in the context of Industry 4.0 (2015) Wireless Networks, pp. 1-19; Fang, M., Malone, D., Duffy, K.R., Leith, D.J., (2010) Decentralised learning MACs for collision-free access in WLANs, , http://arxiv.org/abs/1009.4386v1; Rivest, R.L., Network control by bayesian broadcast (1987) IEEE Transactions on Information Theory, 33 (3), pp. 323-328; Dolev, S., Gilbert, S., Guerraoui, R., Newport, C., (2008) Secure communication over radio channels. In Proceedings of the twenty-seventh ACM symposium on Principles of distributed computing (PODC) (pp. 105–114); Mohi, M., Movaghar, A., Zadeh, P., A Bayesian game approach for preventing DoS attacks in wireless sensor networks. In Proceedings of the international conference on communications and mobile (2009) computing, pp. 507-511; Zhang, Z., Wu, J., Deng, J., Qiu, M., (2008) Jamming ACK attack to wireless networks and a mitigation approach. In Proceedings of the IEEE global telecommunications conference (GLOBECOM) (pp. 4966–4970); Chen, J., Sen, S., Chiang, M., Dorsey, D., A framework for energy-efficient adaptive jamming of adversarial communications (2013) In Proceedings of the 47th annual conference on information sciences and systems (CISS) (pp, pp. 1-6; Xiao, Y., Pan, Y., (2009) Emerging wireless LANs, wireless PANs, and wireless MANs: IEEE 802.11, IEEE 802.15, 802.16 wireless standard family, Wiley Series on Parallel and Distributed Computing, , Hoboken, NJ, Wiley; Linnenbank, G., (1997) A power dissipation comparison of the R-TDMA and the slotted-aloha wireless MAC protocols, , http://doc.utwente.nl/20249/, Enschede, Moby Dick Project Report; Anastasi, G., Conti, M., Francesco, M., Passarella, A., Energy conservation in wireless sensor networks: A survey (2009) Ad Hoc Networks, 7 (3), pp. 537-568; Sufyan, N., Saqib, N., Zia, M., Detection of jamming attacks in 802.11b wireless networks (2013) EURASIP Journal on Wireless Communications and Networking, 2013 (1), pp. 1-18","Khan, Z.; Centre for Wireless Communications, Erkki Koiso-Kanttilan katu 3, Finland; email: zaheer@ee.oulu.fi",,,"Springer New York LLC",,,,,10220038,,WINEF,,"English","Wireless Networks",Article,"Final","All Open Access, Green",Scopus,2-s2.0-84976350930
